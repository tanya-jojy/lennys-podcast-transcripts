name: Generate BYL Project Files with Full Transcripts

on:
  push:
    paths:
      - 'index/**'
      - 'episodes/**'
  workflow_dispatch:

jobs:
  generate:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install pyyaml

      - name: Classify and generate project files
        run: |
          cat << 'PYTHON_SCRIPT' > classify_and_generate.py
          import yaml
          import re
          from pathlib import Path
          from datetime import datetime, timezone

          # â”€â”€ Claude.ai Project Hard Limits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          # Per file:       500KB max  â†’ 4,500 lines safe target
          # Total project:  200k tokens â†’ ~8,000 lines total across ALL files
          # Max files:      20 per project
          MAX_LINES_PER_FILE    = 4_500
          MAX_LINES_PER_PROJECT = 8_000

          # â”€â”€ Topic â†’ Project mapping â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          TOPIC_TO_PROJECT = {
            "product-strategy":        1, "product-market-fit":      1, "innovation":              1,
            "business-strategy":       1, "strategy":                1, "founder-mode":            1,
            "entrepreneurship":        1, "bootstrapping":           1, "network-effects":         1,
            "marketplaces":            1, "airbnb":                  1, "stripe":                  1,

            "product-management":      2, "product-development":     2, "product-leadership":      2,
            "prioritization":          2, "okrs":                    2, "decision-making":         2,
            "experimentation":         2, "ab-testing":              2, "agile":                   2,
            "focus":                   2, "google":                  2, "microsoft":               2,

            "growth-strategy":         3, "startup-growth":          3, "product-led-growth":      3,
            "retention":               3, "sales":                   3, "enterprise-sales":        3,
            "marketing":               3, "brand-building":          3, "branding":                3,
            "word-of-mouth":           3, "community-building":      3, "uber":                    3,
            "linkedin":                3,

            "ai":                      4, "machine-learning":        4, "chatgpt":                 4,
            "openai":                  4,

            "leadership":              5, "management":              5, "organizational-design":   5,
            "executive-coaching":      5, "company-culture":         5, "startup-culture":         5,
            "feedback":                5, "influence":               5, "power":                   5,
            "communication":           5, "storytelling":            5, "slack":                   5,

            "hiring":                  6, "recruiting":              6, "team-building":           6,
            "mentorship":              6, "executive-search":        6, "remote-work":             6,
            "work-life-balance":       6, "facebook":                6, "meta":                    6,

            "engineering":             7, "productivity":            7, "time-management":         7,
            "design":                  7, "user-experience":         7, "customer-experience":     7,
            "customer-research":       7,

            "career-development":      8, "career-growth":           8, "personal-development":    8,
            "personal-branding":       8, "personal-transformation": 8, "skill-building":          8,
            "networking":              8, "anxiety-management":      8, "mental-health":           8,
            "stress-management":       8, "psychology":              8, "neuroscience":            8,

            "analytics":               9, "data-analytics":          9,

            "venture-capital":        10, "media-relations":        10,
          }

          MULTI_PROJECT_TOPICS = {
            "experimentation":    [2, 4, 9],
            "ab-testing":         [2, 9],
            "machine-learning":   [4, 9],
            "okrs":               [2, 7],
            "agile":              [2, 7],
            "focus":              [2, 7],
            "slack":              [5, 7],
            "mentorship":         [6, 8],
            "entrepreneurship":   [1, 10],
            "business-strategy":  [1, 10],
            "bootstrapping":      [1, 10],
            "enterprise-sales":   [3, 10],
          }

          PROJECT_NAMES = {
            1:  "Product Strategy & Vision",
            2:  "Product Management & Development",
            3:  "Growth & Revenue",
            4:  "AI & Machine Learning",
            5:  "Leadership & Management",
            6:  "Hiring, Teams & People",
            7:  "Workflow, Productivity & Engineering",
            8:  "Career & Personal Growth",
            9:  "Data, Analytics & Experimentation",
            10: "Venture, Finance & Strategy",
          }

          PROJECT_FILE_PREFIX = {
            1:  "01-product-strategy-vision",
            2:  "02-product-management-development",
            3:  "03-growth-revenue",
            4:  "04-ai-machine-learning",
            5:  "05-leadership-management",
            6:  "06-hiring-teams-people",
            7:  "07-workflow-productivity-engineering",
            8:  "08-career-personal-growth",
            9:  "09-data-analytics-experimentation",
            10: "10-venture-finance-strategy",
          }

          # High-signal guests ranked by relevance to BYL's work
          # These get priority when budget is tight
          PRIORITY_GUESTS = [
            "shreyas-doshi", "marty-cagan", "teresa-torres", "lenny-rachitsky",
            "brian-balfour", "andrew-chen", "claire-vo", "claire-hughes-johnson",
            "will-larson", "maggie-crowley", "bangaly-kaba", "nir-eyal",
            "brian-chesky", "merci-grace", "shishir-mehrotra", "noah-kagan",
            "adam-nash", "casey-winters", "elena-verna", "leah-tharin",
            "kevin-systrom", "rahul-vohra", "ian-mcallister", "aakash-gupta",
            "lenny-rachitsky", "deb-liu", "Gibson-biddle", "ken-norton",
            "jackie-bavaro", "brendan-hufford",
          ]

          # â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

          def count_lines(text):
              return text.count('\n') + 1

          def normalize_tag(tag):
              return re.sub(r'[^a-z0-9]+', '-', tag.lower()).strip('-')

          def relevance_score(t, proj_num):
              """Score a transcript for relevance to a project. Higher = more relevant."""
              score = 0
              # Direct topic match = higher priority
              for tag in t['tags']:
                  norm = normalize_tag(tag)
                  if norm in TOPIC_TO_PROJECT and TOPIC_TO_PROJECT[norm] == proj_num:
                      score += 3
                  elif norm in MULTI_PROJECT_TOPICS and proj_num in MULTI_PROJECT_TOPICS[norm]:
                      score += 2
              # Priority guest boost
              folder = t['dir'].lower()
              for guest in PRIORITY_GUESTS:
                  if guest in folder:
                      score += 2
                      break
              # View count as proxy for quality (if available)
              views = t['meta'].get('view_count', 0)
              if isinstance(views, int) and views > 100000:
                  score += 1
              return score

          def get_projects_for_tags(tags):
              projects = set()
              for tag in tags:
                  norm = normalize_tag(tag)
                  if norm in MULTI_PROJECT_TOPICS:
                      projects.update(MULTI_PROJECT_TOPICS[norm])
                  elif norm in TOPIC_TO_PROJECT:
                      projects.add(TOPIC_TO_PROJECT[norm])
              return projects

          def parse_transcript(filepath):
              try:
                  content = filepath.read_text(encoding='utf-8', errors='replace')
                  parts = content.split('---', 2)
                  if len(parts) >= 3:
                      try:
                          meta = yaml.safe_load(parts[1]) or {}
                      except:
                          meta = {}
                      body = parts[2].strip()
                  else:
                      meta = {}
                      body = content.strip()
                  return meta, body
              except Exception as e:
                  print(f"  WARNING: {filepath}: {e}")
                  return {}, ""

          def get_tags_from_transcript(meta, body, guest_folder):
              tags = []
              for field in ['tags', 'keywords', 'topics', 'categories']:
                  val = meta.get(field)
                  if isinstance(val, list):
                      tags.extend([str(t) for t in val])
                  elif isinstance(val, str):
                      tags.extend([t.strip() for t in val.split(',')])
              folder_norm = normalize_tag(guest_folder)
              if folder_norm in TOPIC_TO_PROJECT:
                  tags.append(folder_norm)
              if not tags:
                  text_to_scan = (
                      str(meta.get('title', '')) + ' ' +
                      str(meta.get('description', '')) + ' ' +
                      body[:3000]
                  ).lower()
                  for topic in TOPIC_TO_PROJECT.keys():
                      if topic.replace('-', ' ') in text_to_scan:
                          tags.append(topic)
              return tags

          def build_transcript_block(t):
              meta  = t['meta']
              guest = meta.get('guest', t['dir'])
              title = meta.get('title', f"Episode: {t['dir']}")
              date  = meta.get('publish_date', 'Unknown')
              url   = meta.get('youtube_url', '')
              block  = f"### {title}\n"
              block += f"**Guest:** {guest} | **Date:** {date}"
              if url:
                  block += f" | [YouTube]({url})"
              block += "  \n\n"
              # Trim transcript body to first 300 lines for density
              body_lines = t['body'].split('\n')
              block += '\n'.join(body_lines[:300])
              if len(body_lines) > 300:
                  block += f"\n\n_[{len(body_lines)-300} additional lines trimmed for context budget]_"
              block += "\n\n---\n\n"
              return block

          def build_header(proj_name, timestamp, total_eps, included_eps, all_proj_topics, index_dir):
              h  = f"# BYL Brain: {proj_name}\n"
              h += f"_Lenny's Podcast â€” {included_eps} of {total_eps} episodes included_\n"
              h += f"_Last updated: {timestamp} | Claude.ai optimised: 4,500 lines/file, 8,000 lines total_\n\n"
              h += "---\n\n## TOPIC INDEX\n\n"
              for topic in all_proj_topics:
                  f = index_dir / f"{topic}.md"
                  if f.exists():
                      h += f"**{topic.replace('-', ' ').title()}**\n\n"
                      # Trim index entries to keep header lean
                      index_lines = f.read_text(encoding='utf-8', errors='replace').split('\n')
                      h += '\n'.join(index_lines[:80])
                      if len(index_lines) > 80:
                          h += f"\n_[truncated]_"
                      h += "\n\n"
              h += "---\n\n## TRANSCRIPTS\n\n"
              return h

          def write_project_files(output_dir, prefix, proj_name, timestamp,
                                   header, ranked_blocks):
              """
              Write files respecting:
              - MAX_LINES_PER_FILE (4,500) per individual file
              - MAX_LINES_PER_PROJECT (8,000) total across ALL files
              Transcripts are included in ranked order until budget exhausted.
              """
              header_lines = count_lines(header)
              transcript_budget = MAX_LINES_PER_PROJECT - header_lines
              transcript_budget = max(0, transcript_budget)

              # Select ranked transcripts within total budget
              selected = []
              used = 0
              skipped = 0
              for block in ranked_blocks:
                  bl = count_lines(block)
                  if used + bl <= transcript_budget:
                      selected.append(block)
                      used += bl
                  else:
                      skipped += 1

              print(f"  Budget: {header_lines} header + {used} transcript = "
                    f"{header_lines + used} / {MAX_LINES_PER_PROJECT} total lines")
              if skipped:
                  print(f"  Trimmed: {skipped} lower-priority episodes excluded")

              # Split into part files at 4,500 lines each
              parts = []
              cur_lines = 0
              cur_blocks = []
              for block in selected:
                  bl = count_lines(block)
                  if cur_lines + bl > MAX_LINES_PER_FILE and cur_blocks:
                      parts.append(cur_blocks)
                      cur_blocks = []
                      cur_lines = 0
                  cur_blocks.append(block)
                  cur_lines += bl
              if cur_blocks:
                  parts.append(cur_blocks)
              if not parts:
                  parts = [[]]

              total_parts = len(parts)
              files_written = []

              for i, part_blocks in enumerate(parts, 1):
                  fname = f"{prefix}.md" if total_parts == 1 else f"{prefix}-part{i}.md"
                  fpath = output_dir / fname

                  with open(fpath, 'w', encoding='utf-8') as f:
                      if i == 1:
                          f.write(header)
                      else:
                          f.write(f"# BYL Brain: {proj_name} â€” Part {i} of {total_parts}\n")
                          f.write(f"_See Part 1 for topic index | Updated: {timestamp}_\n\n---\n\n")
                          f.write("## TRANSCRIPTS (continued)\n\n")
                      for block in part_blocks:
                          f.write(block)

                  lines = count_lines(fpath.read_text(encoding='utf-8', errors='replace'))
                  kb    = fpath.stat().st_size / 1024
                  status = "âœ…" if lines <= MAX_LINES_PER_FILE and kb <= 500 else "âš ï¸"
                  print(f"  {status} {fname}: {lines:,} lines | {kb:.0f} KB")
                  files_written.append(fname)

              return files_written

          # â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

          episodes_dir = Path('episodes')
          output_dir   = Path('byl-projects')
          index_dir    = Path('index')
          output_dir.mkdir(exist_ok=True)

          for f in output_dir.glob('*.md'):
              f.unlink()

          # Parse all transcripts
          all_transcripts = []
          episode_dirs = sorted([d for d in episodes_dir.iterdir() if d.is_dir()])
          print(f"Parsing {len(episode_dirs)} episodes...\n")

          for ep_dir in episode_dirs:
              tf = ep_dir / 'transcript.md'
              if not tf.exists():
                  continue
              meta, body = parse_transcript(tf)
              tags = get_tags_from_transcript(meta, body, ep_dir.name)
              projects = get_projects_for_tags(tags)
              if not projects:
                  projects = {2}
              all_transcripts.append({
                  'dir': ep_dir.name, 'meta': meta,
                  'body': body, 'tags': tags, 'projects': projects,
              })

          print(f"Classified {len(all_transcripts)} transcripts\n")
          timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC')

          for proj_num, proj_name in PROJECT_NAMES.items():
              prefix   = PROJECT_FILE_PREFIX[proj_num]
              relevant = [t for t in all_transcripts if proj_num in t['projects']]

              # Rank by relevance score (highest first)
              ranked = sorted(relevant, key=lambda t: -relevance_score(t, proj_num))

              print(f"\nProject {proj_num:02d}: {proj_name}")
              print(f"  Matched: {len(relevant)} episodes")

              proj_topics  = [k for k, v  in TOPIC_TO_PROJECT.items()    if v  == proj_num]
              multi_topics = [k for k, vl in MULTI_PROJECT_TOPICS.items() if proj_num in vl]
              all_proj_topics = sorted(set(proj_topics + multi_topics))

              header = build_header(
                  proj_name, timestamp, len(relevant), len(ranked),
                  all_proj_topics, index_dir
              )
              ranked_blocks = [build_transcript_block(t) for t in ranked]

              write_project_files(output_dir, prefix, proj_name, timestamp,
                                   header, ranked_blocks)

          # Summary
          print(f"\n{'='*60}\nFINAL OUTPUT\n{'='*60}")
          for f in sorted(output_dir.glob('*.md')):
              lines = count_lines(f.read_text(encoding='utf-8', errors='replace'))
              kb    = f.stat().st_size / 1024
              flag  = "âœ…" if lines <= MAX_LINES_PER_FILE and kb <= 500 else "âŒ"
              print(f"{flag} {f.name}: {lines:,} lines | {kb:.0f} KB")

          PYTHON_SCRIPT

          python classify_and_generate.py

      - name: Commit and push project files
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add byl-projects/
          git diff --staged --quiet || git commit -m "chore: update byl-projects/ claude-optimised [auto]"
          git push

      - name: Notify via Slack
        run: |
          curl -X POST "${{ secrets.SLACK_WEBHOOK_URL }}" \
            -H 'Content-type: application/json' \
            --data "{
              \"text\": \"ðŸ“š *BYL Project Files Updated*\nClaude.ai optimised: 4,500 lines/file max, 8,000 lines total per project.\nðŸ‘‰ https://github.com/${{ github.repository }}/tree/main/byl-projects\"
            }"
