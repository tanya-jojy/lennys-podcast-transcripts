# BYL Brain: AI & Machine Learning (Part 2)
_Auto-generated from Lenny's Podcast Transcripts Archive_
_Last updated: 2026-02-23 00:40 UTC_
_This is part 2 of a multi-part project file._

---

## FULL TRANSCRIPTS

---

## Inside Bolt: From near-death to one of the fastest-growing products in history | Eric Simons
**Guest:** Eric Simons  
**Published:** 2025-03-13  
**YouTube:** https://www.youtube.com/watch?v=L22DtAHLmzs  
**Tags:** growth, acquisition, churn, kpis, roadmap, prioritization, experimentation, analytics, pricing, monetization  

# Inside Bolt: From near-death to one of the fastest-growing products in history | Eric Simons

## Transcript

Lenny Rachitsky (00:00:00):
The rate you're growing is absurd. You're in this cohort of companies that are just growing at rates that we've never seen in the history of startups.

Eric Simons (00:00:05):
The company was on the verge of going under when we launched Bolt, and what ended up happening is, in the first two months it went from zero to 20 million of ARR. And we've already crossed 30 million of ARR, with the current rate we're on, our forecast for the year is we want to get to 100 million of ARR.

Lenny Rachitsky (00:00:22):
This is just non-stop wild shit. How is this possible? What has allowed you to grow this much, this fast, with such a small team?

Eric Simons (00:00:30):
Most importantly, it's been the people. It's rare to find startups where you have the core group of five, six, seven people that have been there for five years plus.

Lenny Rachitsky (00:00:38):
You basically were building a tech first, and then looking for a problem to solve later, which is often what people tell you not to do.

Eric Simons (00:00:44):
I think that's the hard thing about being an entrepreneur. There are periods of time where you have to make judgment calls that are not going to be the consensus view. You got to have confidence in your convictions on how to best play the hand.

Lenny Rachitsky (00:00:54):
A lot of people see these stats, and they sometimes don't see that there was also years and years of work before that.

Eric Simons (00:00:59):
It was kind of like, Bolt's this overnight success, seven years in the making.

Lenny Rachitsky (00:01:05):
Today my guest is Eric Simons. Eric is co-founder and CEO of StackBlitz, which makes a product called Bolt, which is currently neck and neck with Cursor for being the fastest growing product in history. They're currently the number one most popular web AI code app with over three million registered users. Two months after launching last October, they hit 20 million ARR. At the time of this recording, they're approaching 40 million ARR. The story of Bolt is wild. They actually started the company seven years ago, and were about to run out of money and shut down. But they realized the tech that they'd been building for the past seven years, called WebContainer, was perfectly suited for building AI products in a browser. So they launched the product with a tweet, and as Eric describes it, it was an overnight success seven years in the making. If you'd like to better understand the cutting edge of AI coding apps, and where things are going with AI and product building, this episode is a must listen.

(00:02:02):
If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. Also, if you become a yearly subscriber of my newsletter, you now get a year free of Perplexity Pro, Notion, Linear Granola, and Superhuman. Check it out at lennysnewsletter.com.

(00:02:18):
With that, I bring you Eric Simons.

(00:02:22):
This episode is brought to you by Eppo. Eppo is a next generation A-B testing and feature management platform built by alums of Airbnb and Snowflake for modern growth teams. Companies like Twitch, Miro, ClickUp, and DraftKings rely on Eppo to power their experiments. Experimentation is increasingly essential for driving growth, and for understanding the performance of new features, and Eppo helps you increase experimentation velocity while unlocking rigorous deep analysis, in a way that no other commercial tool does.

(00:02:52):
When I was at Airbnb, one of the things that I loved most was our experimentation platform where I could set up experiments, easily troubleshoot issues, and analyze performance all on my own. Eppo does all that and more, with advanced statistical methods that can help you shave weeks off experiment time, and accessible UI for diving deeper into performance, and out-of-the-box reporting that helps you avoid annoying, prolonged analytics cycles. Eppo also makes it easy for you to share experiment insights with your team, sparking new ideas for the A-B testing flywheel.

(00:03:21):
Eppo powers experimentation across every use case, including product, growth, machine learning, monetization, and email marketing. Check out Eppo at geteppo.com/lenny and 10x your experiment velocity. That's get E-P-P-O, .com slash lenny.

(00:03:41):
This episode is brought to you by the Fundrise Flagship fund. Full disclosure, real estate investing is boring. Prediction markets are exciting, meme coins are a thrill ride, even the stock market can swing wildly on a headline. Hello, Deep Zeke. But with real estate investing, there's no drama, or adrenaline, or excuses to refresh your portfolio every few minutes. Just bland and boring stuff like diversification and dividends, so you won't be surprised to learn that the Fundrise Flagship Real Estate Fund is a complete snooze fest. The fund holds $1.1 billion worth of institutional caliber real estate, managed by team of pros focused on steadily growing your net worth for decades to come. See? Boring.

(00:04:24):
That's the point. You can start investing in minutes, and with as little as $10 by visiting fundrise.com/lenny. Carefully consider the investment objectives, risks, charges, and expenses of the Fundrise Flagship Fund before investing. Find this information and more in the fund's prospectus at fundrise.com/flagship. This is a paid ad.

(00:04:49):
Eric, thank you so much for being here and welcome to the podcast.

Eric Simons (00:04:52):
Thank you for having me. Yeah, I'm stoked to be here.

Lenny Rachitsky (00:04:54):
For folks that are not super familiar with Bolt, what is Bolt?

Eric Simons (00:04:58):
It's really simple. You go there, there's a text box, and you tell it what you want to build. Whether it's a web or a mobile app, and so, it's kind of one of these text to app building tools that have become pretty popular over the past few months here. And it's not just building a static site, or something like that, but you can actually build full stack, real software with databases, and hosting and et cetera, just from prompting. And in a ridiculously short period of time, it's not like you're spending hours and hours or days, putting this together. You can get results in like, a minute.

Lenny Rachitsky (00:05:36):
Let's just share some numbers about the scale of what you're building. The rate you're growing is absurd. You're kind in this cohort of companies that are just growing at rates that we've never seen in the history of startups, and you guys are at the edge of that. Share some numbers about how things went when you launched, and where they're at today.

Eric Simons (00:05:53):
Yeah, when we launched, the company was on the verge of going under when we launched Bolt, our company StackBlitz. We'd been around for seven years building web-based development, environment stuff. And so when we launched this we were like, "This would be amazing if this added a 100K of ARR over the next couple of months." And what ended up happening is, in the first two months, we went from zero to 20 million of ARR. And I think we're on month four, or four and a half or something like that at this point, and we've already crossed 30 million of ARR, and we're on the verge of crossing 40. By the time this comes out, it appears that we're going to be at 40 million ARR. So it's just, the scale of the growth of the revenue has been nuts.

(00:06:41):
And of course, that correlates with insane user growth, as well. We've added three million registered users just in the past few months here, and monthly active users is around a million, I think at this point, per month. So it's just been... I've never seen anything, I've been doing startups for 15 years, I've never seen anything like this. Everyone I've talked to, our investors, or et cetera, there's not a lot of corollaries to what's going on here. And it's kind of extraordinary, because our company wasn't doing AI stuff six months ago. We had no AI products, and just out of nowhere we, from almost death of the company to being the number one buy traffic revenue, et cetera, like AI Cogen app, that's totally web-based, in the world. I think the only other startup ahead of us is for Cogen, just in general, would be Cursor, and the option revenue at this point.

(00:07:45):
And so anyways, it's been a heck of a ride. And our team's like 15, 20 people, so it's just dealing with, we're going to be closing on 100,000 customers, and our support team's like three people. So we're trying to scale as fast as we can. So it's just kind of mind-boggling, just the scale of the demand, and how we've had to turn things around to match the demand as best as we can.

Lenny Rachitsky (00:08:14):
Mind-boggling is an excellent way to describe what you just shared. A million monthly active users, you're at 40 million annual recurring revenue, five months into the business. Is that right?

Eric Simons (00:08:26):
Yeah, single digit. Yeah, single digit weeks. That's the current track rate that we're seeing for the thing. Yeah.

Lenny Rachitsky (00:08:33):
I think, are you guys are the fastest growing startup in history?

Eric Simons (00:08:37):
I mean, I think it depends on probably where you peg the number. Because yeah, we're here to just build great products, and just push the limits of what's possible with the technology. And I think that we do our jobs well, kind of crazy things can happen, but I mean, the current track rate we have, we're going to be exceeding the forecast for Q1 with the current rate we're on, and our forecast for the year is we want to get to 100 million of ARR. And now, I think there's been a couple, that would either be on par with Cursor, or ahead of them, or something like that.

(00:09:19):
And I think there's going to be more things like this, too. I don't think that... It just, there's something really, I think a lot of people are in disbelief about it too, where they're like, "This is, okay." And this is from when we were at, got to four million ARR, five million ARR in the first month. I would talk with people and they're like, "Okay, yeah, but that could go to zero." And then it went to 20 the next, "Ah, it could go to zero," but now we're closing on 40.

(00:09:40):
So from my view, I was also very skeptical, as this. I've never seen anything grow like this, right? And so part of me, for like a month I was kind of waking up waiting for the day where it just was like, "Okay, it's over." You know what I mean? This crazy thing happened, and now it's not. But that data just hasn't come. And you see this happening with Cursor, you see this with a lot of these other AI startups. And the value proposition is real. The free market is filled with rational actors. People are coming to these tools because it is solving problems, they're able to do way more for way less cost, than it would otherwise. And that's why I said, I think we're going to see more of this, whether it's in coding or other verticals, or whatever. In a sense, it's almost like maybe the new normal, as AI just continues to get better. But, anyways.

Lenny Rachitsky (00:10:41):
Let's get to a demo of Bolt, so people can actually see what this looks like in action. And as you go through it, if you can even point out stuff that is different from other products in the space, say Lovable, VZERO, Replit, that other folks have heard about, that'd be useful.

Eric Simons (00:10:57):
Awesome. Cool. Yeah, so this is Bolt, you just go to bolt.new. Things that I think are really interesting about Bolt. One is, it's just dead simple. Whether you're logged in or logged out, it's the same UI, it's extremely simple, it's just a text box. And I think that the biggest difference between Bolt and the other stuff out there, it's actually subtle. It's not like something you'd necessarily see in the UI, but it's how fast it is, and how reliable it is.

(00:11:23):
And this is because of how we are actually doing the compute, because what's going on here is when you type into, whether it's Bolt or another product, it has to spin up a dev environment to actually make that application. So there needs to be some operating system somewhere that's running it. Everyone else runs those things on cloud servers, which those can take minutes to boot up, and they often will run into issues, and then you can end up literally stuck and have to contact support to get it done, and get it unstuck.

(00:11:49):
With Bolt, and for the past seven years, what our company's been doing has been building an operating system that runs inside of your browser locally, using your CPU. So we have a very permissive free tier, and it's insanely fast, and it's insanely reliable.

(00:12:02):
So if I want to, just as a quick example of this say, "Make a clone of Spotify," and just hit enter. This thing's already getting to work, and already, on the right here, this is a full dev environment. This is an actual operating system, running inside of my browser. And I can run commands on it, et cetera. And really, what you're seeing down here, this terminal and kind of what's backing it, this is what took us really five, six, seven years to build, and make so reliable. There would not be a Bolt without this technology called WebContainer, that allows us to run an operating system in the browser.

(00:12:38):
Because what's going on here is, our AI agent for Bolt has bidirectional communication with this operating system. It's writing code, it's running the dev server for this thing, it's going to go ahead and spin this up. You can see how fast this is, in a matter of 60 seconds I said, "Make me a Spotify clone," and now we have one. And it looks pretty darn good.

Lenny Rachitsky (00:12:55):
That looks really good.

Eric Simons (00:12:58):
And that's one of the other aspects around Bolt is, this technology we made for the operating system side, the guys that have been working with us for the past five-plus years on it, before this they were actually doing machine learning AI stuff. And so when it came time to write the agent for Bolt, we had just an incredible amount of in-house expertise on how to actually merge these two different technology sets, to have this really reliable experience that produces really beautiful, really functional stuff. So that's based on what's really cool about the Bolt experience.

(00:13:32):
The other thing is, a lot of these products it's like, you can make something, but often you want to actually have a URL where you can share this. Having, maybe even attach a domain to it, or whatever have you. So with Bolt, we actually have built-in integrations with production grade hosting providers like Netlify, and for databases with Supabase.

(00:13:53):
So if I go and just click the deploy button here, this is actually going to run a production build of this project we made here. And again, this is doing this entirely inside of my browser, so it doesn't cost us anything to do this. So again, you can do this for free, and it has gone ahead and deployed this on a real URL, on Netlify. This is live, I can share this with anyone, and if I want to buy the domain spotifyclone.com, and point it at this, I can click this link here. That will kick me into Netlify, I can attach this to my account, buy a domain, point at that thing. And then from there on out, whenever I'm prompting Bolt to make changes to this application and hit deploy, that goes live on my public website.

(00:14:36):
So this is the simplest way to build a web app that's ever existed. That was one of the key realizations I had, a couple of weeks into the thing, I was seeing people use this for personal use cases. Like medical donation sites, or weddings, or whatever. And I was like, "Don't these people know that Wix or Squarespace exists? Should I tell them?" And then it hit me. Those things are so complicated to use. I don't know if you've ever seen just the UI of these things, but they're crazy complicated, and that's just for building a static website. There's no way you could actually build a functional app. And that's like, with Bolt, if we were to sit here for another 30 minutes, we would have streaming. You'd be able to make playlists of different MP3 files, or whatever. You can just keep prompting this thing to keep adding functionality.

(00:15:25):
So that's, I think, some of the cool core experience of both here. I can show you something cool that we just launched, if that would be of interest.

Lenny Rachitsky (00:15:32):
Let's do it.

Eric Simons (00:15:32):
So this is like web apps, right? Web apps are amazing, but often you want to have a native app. And it's hard to build web apps, it's even harder to build native apps, that can actually, that you can then go put in the app store. And so we partnered up with a company called Expo, and their entire business is making, basically, React Native tooling and this ecosystem that makes it super easy to build beautiful apps, and actually get them in the app store.

(00:15:57):
And so right here, I'll zoom in a little bit, we have this little, "Build a mobile app with Expo." So if you click that, we kind of instruct you on how to just prompt mobile apps into existence. So yeah, let's make another Spotify clone that's an actual native mobile app. Let's say, "Make a Spotify clone," go ahead and hit enter. And what this thing's going to do is actually, again, spin up a operating system here, where it's going to boot up the Expo tool chain and actually go and make a mobile app for us.

(00:16:28):
And what's cool about this is, we could actually preview it just in the browser here, but once this thing's done and it boots up, it's going to show a QR code, we're going to be able to scan it, and in real time actually basically have a test flight of this native application that we can try it on our phones, and as we keep prompting you'll see it making changes and stuff. This is kind of the first time that, you don't have to be technical to make production grade web, full-stack web and mobile apps. At this point I've done nothing that requires developer knowledge to do any of this stuff.

(00:17:10):
And I think that's what a lot of people are really excited about with this, and you know, the majority of our audience are people that are not developers, that are using this. They're PMs, they're designers, they're entrepreneurs. Because these are people that have always been great at building products, but previously, the only way that they could get their ideas into coded software was through a developer's fingertips. And now, they can deal with their own, through prompting.

(00:17:37):
So you can see here, we've got this little QR code. I'm going to go ahead and scan the thing.

Lenny Rachitsky (00:17:43):
I'm going to do it, too.

Eric Simons (00:17:43):
Cool.

Lenny Rachitsky (00:17:44):
By the way, I love that you had just enough things to say until it finished. That was pro.

Eric Simons (00:17:50):
Just as I planned, you know? So on my screen it's booting up, it's bundling the JavaScript of this thing, and it's beta. We just launched this last week, by the way. So if you can kind of see on my screen here, I actually have this Spotify looking app, right?

Lenny Rachitsky (00:18:07):
Wow.

Eric Simons (00:18:07):
That, you know.

Lenny Rachitsky (00:18:09):
That looks like, exactly like Spotify.

Eric Simons (00:18:11):
It looks exactly like Spotify, right?

Lenny Rachitsky (00:18:11):
It's good.

Eric Simons (00:18:11):
Yeah.

Lenny Rachitsky (00:18:14):
We're going to be sued right now, so let's be... You're doing too good a job with this. No, that's amazing.

Eric Simons (00:18:24):
Yeah. So it's pretty cool, right? And so what's cool is that, and as you keep prompting on your device, it'll just keep reloading. Without you having to kill the app, you can actually see the functionality getting added. And so, in this use case that you and I have right now, it's like if you and I were building an app together, we could be on other sides of the planet and you could actually be not just seeing a screenshot of the thing, but actually touching it and feeling it, and putting it through its paces.

(00:18:47):
And so a lot of product teams, I mean, this is just changing how people do product development. It's faster to do this than design a whole bunch of Figma frames, necessarily. Right? So.

Lenny Rachitsky (00:18:59):
We're going to spend a lot of time on that. Okay, this is incredible, this whole episode so far is you just blowing my mind and I imagine listeners' minds, just over and over and over. I don't even know where to go with all this, sometimes.

(00:19:09):
You made a really important point, that you worked on this for seven years before you launched Bolt. A lot of people see these stats, zero to 40 million ARR in five-ish months, and they sometimes don't see that there was also years and years of work before that. And the reason that you guys have been so successful is all the work you did that allowed, that built this WebContainer technology, it sounds like. Is there anything there that's worth sharing, you think, of just that part of the journey? I know we'll go through the origin that all, where Bolt came from, but I guess just that WebContainer component specifically. That feels like a huge deal.

Eric Simons (00:19:44):
A hundred percent it is, yeah. And I would say this is, surprisingly to me, it's still one of the contrarian viewpoints of our company. Because over the years it was like, when we first... And that, the WebContainer was the bet, that we made the company on. Just to be clear. StackBlitz was a browser-based, deep technology play on, "Can we make a web assembly based operating system that can boot in a browser, in like a hundred milliseconds, and run full on development tool chains?" That was really it.

(00:20:21):
And we'd gotten the idea for this, and the insight that this might be possible, because back when my co-founder and I came out to the Valley, he and I grew up down the street from each other in Chicago, we wrote code together at 13, and been building stuff ever since. And we came out to the Valley in 2012, and we just had the good fortune of bumping into Dylan Field and Evan Wallace when they were building Figma, in the early days. And that was, I don't think a lot of people know that Figma was also a browser-based deep technology play. Their first pitch for Figma, they didn't have a design tool. Their first pitch was this 3D ball dropping into water, inside of a browser town.

(00:21:00):
And the pitch basically was, "Browsers have this new capability called WebGL," the predecessor to WebAssembly, "and with these things, for the first time, you could actually create a graphics rendering engine, that you could then build a design tool on top of. But you're going to have to write that rendering engine from scratch, because nothing exists that can just compile into WebGL, or whatever. And if you want the performance you need, et cetera, it's going to take us years to do, but if we do it, we think this will change everything for design."

(00:21:35):
And obviously, we know how that story has panned out now. And back in 2017, 2016, 2017, Albert, my co-founder and I, saw the same sort of story begin to play out, but for web development and development environments. And specifically there was some stuff that landed in browsers like WebAssembly, shared memory, service workers, these different APIs. And we were like, "Oh, wow. It should be possible, theoretically, to write an operating system in WebAssembly that could run Node.js, and NPM and all the tool chains on top of it, that you need to do web development."

(00:22:12):
And that would be huge, because setting up developer environments, it's a pain for beginners. A lot of people churn out. The first thing you do when you learn how to code is not even learning how to code, it's how to set up your computer to even start writing the code. If you go join Netflix, or any of these other fan companies, the first month or two is you being onboarded, to run that stuff on your computer and set up your environment. And we're like, "If we could just have that be something, you click a link and it just boots in your browser, that'd be huge."

(00:22:42):
It's also, if you look at the other productivity apps that have really worked on the web, they've all had this compute model, right? Figma, when you open a Figma document, there's not like some cloud VM that gets spun up for you to render the documents. You're dragging things around. It's using your CPU and your memory to do the work. Same thing with Google Docs. That's the only model that's ever scaled to a billion users. And so, when you look at Cloud IDEs, like Cloud 9 was the first one, back in 2009 or so. The way these have always worked is that your browser's basically doing nothing, when you go to that. Every user that gets connected, there has to be a cloud VM that gets spun up for them, and then your browser's just taking your keystrokes, sending it to the server, and then sending back the results of it. And that's how all these other AI code, text to app sort of tools work. They're all using cloud VMs.

(00:23:34):
And the problem is, on a small scale it can work, but as you scale it up, I mean there's not even a 100 million VMs to rent, on the planet. But there are a billion devices that you can run this stuff on. Because that's kind of what we've seen with Bolt where, if you want to build a product that's going to be able to scale to that size, you have to look at all factors and go, "We have to build, make sure the technology provides the best experience, zero latency, transient cost." There's a permissive free tier, because the other problem with the server is, you end up, if you have a free tier, people are mining Bitcoin on it, they're DDoSing people using your servers. So inevitably, you have to nerf these things and roll them back. But if it's all done on the end device, it doesn't matter.

(00:24:18):
So anyways, WebContainer was the key piece, and what we struggled with, it took us four or five years or something, to build WebContainer. What we struggled with for the years after that was just how to build a product around it, because developers loved it, but they weren't using it in ways that they would pay money for. And as much as the nerd side of me wished that that would be enough, that it was like, building cool technology was enough. It's like, "It's not. We're here to build a venture scale company." And so that was kind of why we were high at the end of the journey, where it was like, we're taking shots on goal. And at some point, this got a connected bat, right?

Lenny Rachitsky (00:25:04):
There's a lot of really interesting lessons from this journey, that I think are counterintuitive. One is, you basically were building a tech first, and then looking for a problem to solve later. Which is often what people tell you not to do. And it worked out, in this case.

(00:25:19):
The other interesting takeaway here is, it feels like it's a similar moment to when AJAX came out and then everyone's just like, "Wow, you can build new things here." So it feels like there's a lesson here of just, "If there's a new technology that has enabled, something big that we think may, let's just work there for a while, and see if something comes up."

(00:25:35):
And then I think the other lesson here is just, as a founder, just survive as long as you can. Because you may find something that works.

Eric Simons (00:25:43):
All great points, all great points. Because you're dead right. And fortunately, my co-founder and I had, we had built a lot of unsuccessful stars before this. We spend most of the, or 20 times, churning through ideas on things. So when we had conviction, I was like, "This seems like a technology that will be important." It seems like, the web is the most ubiquitous... The pitch or the theory in our head was like, "The web is the most ubiquitous platform in the world, but yet it has no, you can't use the web to build the web."

(00:26:08):
Every other platform, Mac has Xcode. Windows has Visual Studio. The web had nothing. And we were like, "At a minimum, Google should probably buy this thing from us. It seems like it should probably be part of Chrome," at a minimum. And we thought, "Hey, this could be a huge enabler." The vision of just making it as easy to build full stack applications as using Canva, it just seemed really compelling.

(00:26:43):
But when you do that sort of risky deep technology play, you need to... And we were very good about this, like the previous company Albert and I did, we bootstrapped it all the way through to acquisition, so we understood and we were living hand-to-mouth, to bootstrap that thing. So we understood out of it how to have a low burn rate, and take a lot of shots on goal, and make every dollar stretch beyond what anyone would think is reasonable or possible. And that's how we played our hands with StackBlitz. We didn't raise money for the first two or three years of the company's life. We were bootstrapping it. When we did raise money, we barely spent it. Largely because it was like, "We need to just take a lot of smart bets, and it doesn't make sense."

(00:27:32):
And I would just say generally, until you see pull, just people pulling the product out of your hands, you don't want to be spending money. You should be like, default, no. And when you go and buy software, you should be going, "We're a tiny startup. Can you sell it for half?" Everything you buy, just keep the burn rate as low as possible, because you need as many shots on goal as you can possibly get. Because you have no idea. I think just generally, for startups, that's the right way in my view, to approach it. Unless you're seeing, again, immediate demand and pull, or whatever.

(00:28:02):
But yeah, I think that'd be, maybe the extra context I'd add on top is, I think that we ended up doing a good job of being extremely conservative. During a time in which, during 2020, through 2020 and 2021, which were times where exuberance and growing headcount was like, KPIs of companies. And were things that were being... With lot of emotional force of like, "Hey, you guys ought to be doing this." And I'm glad that we didn't heed the advice, because if we had tripled the company and kicked up the burn rate, there would be no Bolt. We would've gone out of business a lot of time ago.

(00:28:48):
So I think that's the hard thing about being an entrepreneur, I think is you kind of have to... There are periods of time where you have to make judgment calls that are not going to be the consensus view. Maybe years later, it'll become the consensus view, but you got to have confidence in your convictions on how to best play the hand.

Lenny Rachitsky (00:29:15):
There's so many great lessons here, I think just this idea of just staying alive. Dalton came on the podcast, he's a partner at YC Ones, and he just had this phrase, "Just don't die." And that's exactly what you guys did, seven years of just trying it until something worked, and I love that you actually were planning to shut down the company right before you launched Bolt. And I know you launched it with just a tweet, right? That was the launch moment?

Eric Simons (00:29:35):
Yep. Yeah.

Lenny Rachitsky (00:29:37):
Maybe talk about that moment of just, after launch, signs that, "Okay, this is working. Something's different."

Eric Simons (00:29:43):
Yeah, yeah. So day one it was like, there's great reception to the tweet. We were like, "Wow, this is one of the biggest things, launch day reception we've ever seen." And I think on the first day, I think we added 60K of ARR, or something. Which was like, I mean, crazy. Again, we were at 600, so we added 10% in a day. And I remember our dev ops engineer, he was the one who would flag me. He was like, "Guys, we got 60K today. This is crazy." And I was like, "Yeah, yeah. But this is launch day."

(00:30:12):
There's the tech crunch, peak of initiation, in the classic startup-

Lenny Rachitsky (00:30:17):
[Inaudible 00:30:17]-

Eric Simons (00:30:17):
... star, yeah. I was like, "Listen, guys." I'm trying to temper enthusiasm for the team. I'm like, "This is great. Got a lot of work to do." And then the next day we added 80K, or whatever it was, and it just kind of kept going. And all the while, the product we put out, we built a thing in 90 days. We built Bolt in 90. So there's a lot of things that were missing in the product. Like, basic stuff, basic stuff. And which, again, we cut the right corners on the thing to get it online, but we had this just growing influx of people using it, going, "How is there not a mobile responsive view? How are chat messages not," we got to 20 million of ARR without a mobile responsive view, by the way. Just throwing that out there. It was like the iPhone not having copy and paste until iPhone 5, or whatever. That was that, this was that for us, it was like, no mobile. You looked at it on mobile, it was terrible.

(00:31:13):
But there was stuff like that, so we had to just... And then, we're a small team and so, we were completely unprepared for just the growing traffic. And there was a whole bunch, I mean, the list of problems that were happening every single day was nuts. I mean, to start, we had never had a plan on stackblitz.com for more than $9.00. We had one price, nine bucks. And so when we launched Bolt we were like, "Again, we don't think, hopefully people like this, but nine bucks doesn't get you a lot of inference." And so people burn through nine bucks in 48 hours. And they're like, "I want to buy more. How do I buy more? Why won't you take my money?"

(00:31:56):
So it was like, within the week we rolled out just completely new pricing plans, where you could upgrade, which ended up, has kind of now become the standard. All the other guys in the space have copied this. Where prior to Bolt going online, Copilot, all these previous AI things, everyone wanted this Netflix model where there's one price, it's like all you can eat, or whatever. And the problem is, if you do that, you want the inference cost to be kind of low, because you're expecting people to use it a lot. And so you can't do these agentic experience things, it would be too expensive.

(00:32:29):
And what we ended up stumbling into is that, "Okay, actually, people are willing to pay more. People want to pay for more inference, because we've crossed this threshold where you can get a very tangible ROI." You know that this is providing a tremendous amount of value to you. So anyways, that was one thing, and the servers were just melting. Anthropic ran out of GPUs for us. Dario emailed me, he was like, "Listen, we don't have anything more to give you." At the times, where we're like, "How do we deal with..." It was just bananas, for weeks. It felt like in 300, when they're surrounded by 10,000 people, and our team is just doing everything. There's 15, 20 people, just doing everything. My chief of staff and I were doing customer support 95% of the day. Anyways.

(00:33:22):
So yeah, it was a crazy wild time. I mean, it still is. We've had a little bit more time to grow into this. And usually, I mean as a company, to grow into even 20 million ARR, you get a year at least or something, to kind of staff up.

Lenny Rachitsky (00:33:39):
Often, decades.

Eric Simons (00:33:40):
Yeah. So that was as hard, we'd go to people and kind of be like, "What do we do?" And the playbooks we get back are, take six months, or a year, or something. It's like, "This isn't going to work." Which is funny, this is what it's all about. I mean this is, at least for me, that level of intensity, it's challenging. Fun challenges, you know?

Lenny Rachitsky (00:34:08):
Wow, okay. This is just nonstop wild, wild shit. So you mentioned that your team was about 20 people through all of this, you guys are growing at this insane rate, 20 people. How was this possible? What has allowed you to grow this much, this fast, with such a small team? And this 300 visual is interesting, I imagine having these Spartans is a big part of it. Just what has allowed you to do this?

Eric Simons (00:34:40):
Yeah, I think a lot of it again, I mean if you kind of look at where a lot of the other folks, like the Cogen types of app space, have really been struggling, a lot of it has been scaling their servers with stuff. And it was kind of like both this overnight success, seven years in the making. All of this stuff, there's no way, if you rewind to year two, there's no way we could have, we would not be at the growth on DAUs, and revenue, or whatever. There's just no way. And so a lot of it is the technology we made, and most importantly, it's been the people.

(00:35:19):
The people... It's rare to find startups where you have the core group of five, six, seven people, that have been there for five years, plus. That's a pretty rare thing to see in Silicon Valley. It is usually, folks are at a startup for a year or two, they kind of go to another one. You know what I mean? And the problem with the turnover like that is that you can't take really long bets like the one we did. And so we've had, kind of from the get-go, again, this comes back from bootstrapping the previous company. Just having less people, and more context per head. That's just been how we do it, and we feel very strongly about it.

(00:36:00):
And the reason for that is, one, that you can have high levels of trust with anyone you're talking to, because you know that they have a lot of context. It's not like this person's completely in the dark, in some corner of the company that doesn't... You know what I mean? The second thing, everyone has agency to actually get stuff done, front to back. And there's no political community to get stuff approved by, there's no... So when you look at what happened with Bolt, I mean, we had engineers that were, front to back, were on a call with someone running into an issue, going and fixing it. Cooking up the UI on the spot, and landing this thing. Without involving anyone else on the team.

(00:36:41):
So I think it was the culmination of just high trust, and people, we all just have enjoyed working together in the past. Maybe that's why, that's the only reason that anyone would ever stay at a company for that long, or whatever. And so those sorts of stressful situations, I think, are make or break. Those are make or break for any team. And so, I think that what's happened is really, it is a direct reflection of the strength and the bonds of the people that are making this thing, and supporting the thing.

Lenny Rachitsky (00:37:22):
Yeah, I think that's such an important point, that you guys have been working together for many years. Most people won't have that benefit. When you're hiring people, when you hire this initial team, is there anything you look for that you think maybe people aren't looking for enough? Anything you prioritize when you're hiring new folks? Is it this idea that they can do a lot? They can do customer calls, they can do design, they can do engineering?

Eric Simons (00:37:42):
Yeah, for us, and even if the folks were hiring us, hiring people that don't care about the titles, and they don't care about... It's not like they're... People, of course it's people have a career trajectory, and that sort of thing, but they really are motivated by just working on cool things, and are chucking their ego at the door. And they're there to collectively build something great, not just kind of follow, and be the brilliant jerk. Most of the people that we've hired have been in Europe. We're a fully remote company. My co-founder and I are in the Bay Area. It's funny, back in 2018, we rented an office and stuff, and we were commuting into it. Because we thought we'd hire people here, and like a year into it we were like, "What are we doing? You and I are coming to an office for 10 people, we've hired, the people working for us are in Europe, or across the US." And we have one or two other people we've hired that are in the Bay Area at this point.

(00:38:51):
But yeah, I think we kind of look for folks that are intrinsically just trying to build great stuff, and are interested. And then the first people that we hired, the reason that we found them is that they were users of StackBlitz. A lot of people, the majority of people we've hired at the company have been people that actually came from our community, basically. So when we want to hire people, we put out a tweet and say, "Hey, we're hiring an engineer," and then we get DMs or whatever.

(00:39:22):
But yeah, those are the general kind of qualities we look for, though.

Lenny Rachitsky (00:39:28):
I'm excited to chat with Christina Gilbert, the founder of OneSchema, one of our long-time podcast sponsors. Hi, Christina.

Christina Gilbert (00:39:35):
Yes. Thank you for having me on, Lenny.

Lenny Rachitsky (00:39:37):
What is the latest with OneSchema? I know you now work with some of my favorite companies like Ramp, Vanta, Scale and Watershed. I heard that you just launched a new product to help product teams import CSVs from especially tricky systems like ERPs?

Christina Gilbert (00:39:53):
Yes, so we just launched OneSchema FileFeeds, which allows you to build an integration with any system in 15 minutes, as long as you can export a CSV to an SFTP folder. We see our customers all the time getting stuck with hacks, and workarounds, and the product teams that we work with don't have to turn down prospects because their systems are too hard to integrate with. We allow our customers to offer thousands of integrations without involving their engineering team at all.

Lenny Rachitsky (00:40:15):
I can tell you that if my team had to build integrations like this, how nice would it be to be able to take this off my roadmap, and instead use something like OneSchema. And not just to build it, but also to maintain it forever.

Christina Gilbert (00:40:26):
Absolutely, Lenny. We've heard so many horror stories of multi-day outages, from even just a handful of bad records. We are laser focused on integration reliability to help teams end all of those distractions that come up with integrations. We have a built-in validation layer that stops any bad data from entering your system, and OneSchema will notify your team immediately of any data that looks incorrect.

Lenny Rachitsky (00:40:46):
I know that importing incorrect data can cause all kinds of pain for your customers, and quickly lose their trust. Christina, thank you for joining us, and if you want to learn more head on over to oneschema.co, that's oneschema.co.

(00:41:01):
I want to ask a couple more questions about Bolt, and then I want to zoom out, and talk about where things are heading in the future. Let's talk about prioritization. I imagine you guys are just barraged with, as you described, after you launched, you're just barraged with requests. Like you said, there's a million monthly active users. I can't even imagine the feature requests you guys are getting, plus all the stuff you know want to build. Just how do you go about deciding what to prioritize, and what to actually build?

Eric Simons (00:41:28):
There's a lot of things that you just don't even know are possible to do, and so, people aren't going to be necessarily explicitly asking for them. And so there's been kind of a couple of these, where we use our gut instinct on like, "Hey, no one's asking for this, in meaningful numbers at least. But we think this is going to be a big deal."

(00:41:47):
Best example was last week with native mobile app support. That's, by reception, the biggest thing we've ever launched. And it was something that, even internally at the company, some folks were like, "This, I don't know. People are yelling about these other things." And it is, it's always this balance of how much are we just triaging various things, versus that new capabilities, but it was like, "This strikes me as an important one," where we put some chips into the middle of the table on. And had it dead right. It's just this mind-blowing experience, and now, there's just thousands of mobile apps being created a day, that weren't before. And how does that change things? I mean, now there's small businesses that, they would've never made an iPhone app before. It made no sense. It's super expensive. Now, that's not the case.

(00:42:43):
So there's kind of these things where it's like, "Hey, we should go and take bets here." But there's kind of this, I think the best analogy would be like, it's kind of like working at a restaurant, being like a chef. There's some amount of, there's feedback from the customers of, "This thing didn't taste good." And then there's like, "Hey, we've been cooking something interesting, and this tastes... I don't know. This, I think you're going to like this. I think this is a killer dish." And so you kind of have to balance those things.

(00:43:15):
And I think it's actually, largely, a function of just years of experience doing it. I think if you kind of rewound 10 years ago, I would have had really no, I wouldn't have had just the years of getting my butt kicked by the free market, to have cultivated a sense of this stuff. You kind of have to build your own gun and stick for it, I guess is the best way of putting it.

Lenny Rachitsky (00:43:39):
To unpack this a little bit further, do you have a cadence you guys work through to decide what to build, and ship? Do you have a weekly meeting every week? Because I know the answer is probably, really, "It's just chaos constantly, and fires we're putting out constantly." I know that's a lot of it, but is there some kind of process that you guys have for deciding what to build, and how to share it, and just work with the team?

Eric Simons (00:44:02):
We all meet every day. Pretty much the entire team gets on a call, and we just kind of front to back-

Lenny Rachitsky (00:44:07):
You meet, like a Zoom?

Eric Simons (00:44:08):
Yeah, every day at 8:00 AM Pacific, we're on a Zoom for at least an hour-

Lenny Rachitsky (00:44:12):
Every day? The whole company?

Eric Simons (00:44:13):
Pretty much the entire company. Yeah.

Lenny Rachitsky (00:44:14):
Wow. For an hour. Okay.

Eric Simons (00:44:16):
Yeah. And we just go over everything and I think we're going to probably start, as the team's kind of growing, we're going to start splintering off into different syncs, or whatever. But the thing about just having everyone in the same room every day is that, a lot of people will complain that it's... On Twitter, you'll see people say, "Oh, it's the most expensive use of everyone's time," but it's like, "Yep. But there's 0% fidelity loss in that. Everything, every day, is being audited front to back, and being discussed front to back."

(00:44:47):
So when you're in these times of just extreme growth, you want as close to 0% loss, on communications. And so that's how we've been doing it, especially since Bolt went online, and I think it was the week after Bolt went online we were like, "Every day, until we're through this or whatever, we're all getting on a phone call every day, and we're front to back doing this." And again, another reason why more context and less heads, every person at the company is aware of everything else going on at the company. So people can independently be making decisions that are generally, by default, more often correct than not.

Lenny Rachitsky (00:45:33):
That is so interesting. I've never heard that before. Especially for company growing, that is like yours. That is super interesting, that that's what you do.

Eric Simons (00:45:42):
I don't think we're going to do that forever.

Lenny Rachitsky (00:45:44):
Yeah, yeah. Of course.

Eric Simons (00:45:45):
But, yeah.

Lenny Rachitsky (00:45:47):
No, but I think that's a really cool thing to note, that that works. And has worked for you. Where do you, so say you talk about stuff, then where do you put stuff? Where do you put your roadmap? Where do you plan? Just, what tools are kind of in the stack of the company's toolset?

Eric Simons (00:46:01):
Yeah, on the engineering side, we use Linear heavily. On kind of product roadmapping, we're using Notion, and kind of making PRD type stuff in Notion. And we use Figma for design. No, actually, we use Bolt for a lot of design and prototyping at this point, as you can imagine. But yeah, I think that the tooling is nothing crazy. There's nothing crazy sophisticated. I think we'll be investing a lot more, and especially as you start splintering people out of being on the same call every day, so that's where this stuff really starts to matter. Because you don't have a time where you're able to dynamically catch things that weren't going to be brought up.

Lenny Rachitsky (00:46:45):
I love that you guys use PRDs. I love that you even used that term. There's a lot of talk of just like, "Oh, we got Bolt now we got all these tools, we don't need PRDs. We're just going to create a prototype immediately, and that's it." Talk about just why you still find that useful, and just what you put into your PRD, whatever that is for you.

Eric Simons (00:47:01):
Unless there's something that's very sophisticated that we're working on, we tend to keep them pretty light. I like to just have the minimal amount of context possible, that just ensures everyone's on the same page and that the key outcomes for whatever feature that we're working on, are going to be present when we get there. Because the things that, when these arguments get really beefy, you're looking at it at, "God, there's so much stuff to decipher." The problem is, a lot of people are going to gloss over it when it gets kicked to development, or design, or whatever. It's just going to start snowballing into a lot of stuff. It's just better to keep it as simple as you possibly can. At least, that's our approach to the thing. And often it's some of these things are like, "Here's a link to a Bolt."

Lenny Rachitsky (00:47:46):
"And here's what it might look like."

Eric Simons (00:47:51):
Yeah. And not just look like, "Here's kind of a working demo of what it will effectively feel like." And then, be. Because that just, if a picture is worth a thousand words, a live actual demo is worth millions. You can feel it. It's real. And that's what we're seeing, a lot of the businesses that are adopting Bolt now, that's the use case that they're using this for. Is high fidelity prototyping, because it's now faster to make real prototypes using Bolt. Before, it was too expensive. The idea of, "And let's prototype it, the engineers' code a proto..." It's like, that, it would take forever. It would be expensive. And now it's faster to do this with Bolt, in code, and have a real working software product, than dragging around frames and Figma to actually make a static version of it.

Lenny Rachitsky (00:48:43):
So let's actually talk about that. Just how far have companies gotten with Bolt? Prototypes is where everyone's kind of imagining these tools are at. I know that the goal isn't just to make prototypes, it's to build full scale. I imagine, long-term, Salesforce, Atlassian style companies, at scale. What are some examples of products people have built with Bolt that maybe would surprise people, in just how far they've gotten?

Eric Simons (00:49:08):
Yeah, I mean, especially... When you're starting greenfield stuff, you can use Bolt to build... you know. Like Salesforce, as an example. One of the first people that signed up for Bolt was this guy named Paul, and he's an entrepreneur, and doesn't know how to code. Built a CRM in three weeks, that has AI built into it and Stripe for billing, et cetera. He had gotten a quote from an agency for this, it was going to be 30 grand, and take six months. He had done in three weeks, and I think he spent 300 bucks on Bolt for the thing. So it's like, this is... And he's making money off of this. This is his start. Right?

Lenny Rachitsky (00:49:45):
Okay, so he built this, and he's selling it. People are paying to use it.

Eric Simons (00:49:48):
Yeah. Yeah.

Lenny Rachitsky (00:49:48):
Wow.

Eric Simons (00:49:50):
And there's many such cases of this. If you're looking at greenfield projects, 100%. Today with this current state of frontier models, you could absolutely build production grade software. You're not going to get a zero shot, but you're going to spend a couple of days, weeks, whatever. But the cost reduction there, 30 grand versus $300. It's 99% cheaper. Six months versus three weeks. I mean, it's like order of magnitude sort of fashioned delivery on the thing. And those numbers have helped, for the people that we talk to, that are building these full stack apps. People, they go to Upwork, work, they get a quote for five grand. They have it within 50 bucks. It's just nuts, what you're able to do with this thing.

(00:50:35):
And so I think on the flip side, a lot of the existing companies, there are very legitimate use cases where things are greenfield, spun up. A good example is public websites. Marketing pages, landing pages, whatever have you. Folks are adopting Bolt to just power those instead of using Webflow, for example. Because it's like, this is simpler to use than Webflow. And it integrates with the existing design system of the company, and et cetera. And the marketers can update it without knowing how to code, whatever. But then for product development teams, this is most commonly for, again, existing software businesses. They're using this to just accelerate the product development process, and in a way where it's not just like a Greenfield wholesale, "Hey, we're building the entire thing in Bolt," or whatever.

Lenny Rachitsky (00:51:20):
Can Bolt integrate with your existing code base, or not yet?

Eric Simons (00:51:23):
So yeah, we can actually open up repos in Bolt. You can go and use Bolt on your code base. It kind of depends on your setup. And we do have companies, again, that have marketing sites they're using this on, or their admin panel or whatever. And I think it's going to be a use case that we see a lot more people orienting towards. These LLMs are not great, depending on how big your application is, though. These things are not quite there, where if you have something that's a thousand files or something, or more, where you're going to be able to have a really reliable, super reliable experience per se. Within a year, we'll chat a year from now, I suspect the answer is going to be different. So it kind of depends on the size of the app, the scale of the app, and if it's too big, you're looking at the prototyping, just pure acceleration of product development. And if it's not, then you can just do it entirely from Bolt.

Lenny Rachitsky (00:52:24):
So this is useful. So what would you say are the major limitations of Bolt today, where people should just know, "Okay, it's not going to get you here yet. Maybe in the future it will." So it sounds like, if you have a really large existing code base, probably not the best tool yet. What else should people know?

Eric Simons (00:52:39):
I would say that's probably the main one, because I think if you have a large existing code base, you're going to need something like Cursor. And you're going to need to be a developer, meaningfully, to be editing that stuff. I think outside of that, there's a, just like using any other productivity tool, like Photoshop or Figma, or like a DSLR or whatever. There's some level of education, and using the tool, and learning how to use it, that's required to really unlock a lot of the maximum capabilities of the thing.

(00:53:10):
And the people that we see that are most successful with Bolt, outside of developers, the people we see that are most successful are people that are amazing PMs, for example. Because these are people that understand enough about how the technology works, typically, and their job is to direct developers on how to go and improve the product. And go and look into how to actually spec this thing out in a way that's executable, without lossiness in the communication. And when you think about, "Okay, how would you best interact with an AI developer agent?" It's basically that. You really want to be good at defining scope, and helping it go and debug various things, or whatever have you. There's a huge overlap of the skill set of being a rock star PM, and being really good at using, frankly, any of these text to apps or Cogen tools.

Lenny Rachitsky (00:54:08):
I love that you made that point. That's exactly the point I've been trying to make, I have a newsletter post about this. Because when all these tools came out, there was so many people saying, "Okay, PMs are dead. We don't need them anymore. We can just build things so quickly and easily, what's the point?" But I completely see the world the way you see it. The hard part now is, now it's easy to build the thing. Now it's, "What the hell should we build? Can we clearly articulate what it is we want to build?" And then, "Can we just have the taste to know, is this right, is this correct? Is this good? Is this going to solve the problem?" And then it's like, grow it, which is something also PMs think about. So, I completely agree. Basically it feels like PMs are, and a lot of PMs listen to this, so they'll love hearing this. To me, it feels like PMs are the best positioned role to thrive in this world.

Eric Simons (00:54:54):
Zero question. I mean that was, as Bolt was growing and we were like... Because we were a developer product before this, and so we expected the audience to be 100% developers that were using this. And we just kept seeing more and more and more people that were not developers using it, to the point where it's like, 67% of our users are not developers, at this point. And when I started talking to these folks, at first I was just weird, or whatever. It was like, "Well, what's going on here?" But then it just kind of clicked as like, "Oh, well, this is going to change everything. The entire software world order is going to get rewritten, here."

(00:55:30):
Because the way that companies are organized to build software today, totally going to change. The idea that again, PMs are the people that really understand, to the pixel level, what matters into making a great product experience. And often they're having... And listen, I'm a developer, myself. They have to go and harangue the developers to get things to be how they really ought to be, to the smallest levels. And now, how this is going to work, if you fast-forward one, two, five years, whatever. PMs, they're going to be "writing code", quote, unquote, instead of just writing a JIRA ticket and waiting for a developer to do it. The developers are going to be able to work on intellectually challenging tasks that LLMs are not well suited for, and still being augmented by LLMs to do it. But PMs are going to be able to go in and just make the changes themselves.

(00:56:24):
And what blew my mind is, it's not priced in, to any of these companies out there. And it's not reflected in the org charts of all the software companies in the world right now. That is going to completely change. The winners, at least, their org charts are going to completely change, and how they approach building products and shipping products. Completely. And it's starting, this is the beginning.

Lenny Rachitsky (00:56:50):
I want to follow that thread, but first of all, I want to also add, and correct me if you disagree with this. I think when we talk about PMs, that also applies to founders, like product thinking founders-

Eric Simons (00:56:58):
One hundred percent.

Lenny Rachitsky (00:56:59):
... very similar. And then, I think it's also important to note, if you also have engineering skills and design skills, you will be at an advantage. That only helps you. But if you're looking at this triangle of the triad of product, engineering, PM, it feels like the PME skills are the ones that will be most important and valuable. Although it'd be great if you can also be in code, and if you could also design really well.

Eric Simons (00:57:23):
Absolutely. And to me, it's the most exciting mix. I think PMs, designers and entrepreneurs that are non-technical, that's the most exciting thing to me, just because it's a brand new market that's being unlocked here. For the first time ever, these folks can directly code and build the product, themselves. Their vision, directly into the software itself. That's going to change everything. That is changing everything.

Lenny Rachitsky (00:57:48):
So when you talk about how org charts are going to change, what are you imagining there? Is it just fewer engineers, mostly, or what do the future org charts look like?

Eric Simons (00:57:57):
Good question. And I bet you there's going to be some Gartner analysis someday, years from now or whatever that's like, "Here's how the best," some term is applied to how the best companies are organizing. But yeah, I think that we're going to see developers probably being pulled off of a lot of the, generally speaking, pulled off of a lot of user interface type work. I would imagine. Except for the most complicated of those things. And you're going to see designers and PMs really, really leading the charge, and being responsible for crafting those experiences. And perhaps having a developer attached to be reviewing the code and making sure the guiding, the code that they're writing, reviewing those pull requests and et cetera. And I think maybe even the engineers are... Like you pointed out, having engineering skills is not going to hurt you. It's going to make you way more effective.

(00:58:58):
But I do think there's going to be, the leverage that the front engineer is going to have is, it is now insane, it's only going to get more so. And so I could see there just being fewer front engineers attached to, I'm seeing more product and design folks, with one or two engineers or something. And really having a larger matching of pods like that. Something like that strikes me as probably how this is going to start trending towards.

Lenny Rachitsky (00:59:34):
This touches on, we had a researcher from OpenAI in the podcast. She actually started her career, she worked at Anthropic first, as a front-end engineer. And said that once she saw what Clyde could do, for front-end engineering, she's like, "I need to move to a different function." And so she moved into research, because she saw that role disappearing, potentially. And that's exactly what you're saying.

Eric Simons (00:59:57):
Yep.

Lenny Rachitsky (00:59:57):
So let me ask you this, I don't know if you have a clear thesis on this yet, but say, you just had a kid. Say your kid is, in the future, starting school. Let's say your kid was starting college soon. Do you have thoughts on just what skills slash areas you think they should go into, versus avoid, that maybe are popular now and are going to be less popular?

Eric Simons (01:00:19):
Understanding how to leverage these AI tools is key. I wouldn't necessarily, I think maybe getting a basic understanding of how programming works, et cetera, is great.

Lenny Rachitsky (01:00:31):
It's like technical foundations, just understanding how systems work, how coding works.

Eric Simons (01:00:41):
Exactly. But it doesn't have to be, because I think back to if Bolt existed, like Albert and I say this to each other all the time. Since the get-go, StackBlitz, we've been building the thing that we wish we had when we were 13. And heck, for everything we built since then. And especially with Bolt. I mean, I don't know if I would've gone as deep as I did on learning how to code, and being an engineer, if that had been around then. The whole reason we got into it is we had ideas for products, and businesses, that we wanted to build. And coding was just a necessary requirement in order to do that.

(01:01:21):
And that said, I think people need to follow their intrinsic interests. If folks are really interested in really getting in the nitty-gritty of how computers work, and program leaders, or spark and compilers, or whatever, go for it. I think that stuff is still going to be relevant. I don't know if we're going to really have, we'll see, but to the degree that there's AGI where it's like, we don't have to think about anything ever again.

Lenny Rachitsky (01:01:47):
Yeah, that's always the answer here. Do we sell anything?

Eric Simons (01:01:50):
Yeah, it's like if we're at that point, it's kind of... I don't know, I'm not sure. But I think from, at least what I feel like seems like the next at least five years of what we're looking at, I think people are still going to, there's still going to be places to specialize, and really go deep. But I think you want to go into it with the idea, not like, "I'm going to go and learn computer science because I'm going to get a job for sure out of it."

(01:02:18):
I just think that's generally not a good... This is like, my co-founder and I, we didn't go to college. My co-founder dropped out of college after a semester or something, but I didn't go, because I was like, "We're coding," we were doing contracting at the time, making money. And it was like, "This is a lot of," you know, it would've been like a hundred grand of debt by the end of the thing, just for four years of in-state tuition, at U of I. 120 grand, I think, at that time.

(01:02:49):
And lo and behold, I mean there's a huge issue with this. Where people are kind of... There was a prevailing thought by society that going to college in the early 2010s or late two 2000s, that you're going to get a job on the other side. That's going to be high paying. And that just has not been the case for a lot of people. And I think that's just going to continue to be the case. But again, not to deter people from doing it, but you have to go into it being like, "I for sure, this is what I want, and I want to go and be the best that I can possibly be at this thing." You know what I mean?

Lenny Rachitsky (01:03:30):
I like the transfer to your kid is going to be like, "Don't even go to college," potentially.

Eric Simons (01:03:35):
Only if they want to. I think at 18, it's a huge ask. I mean, it's a huge ask, not even at 18. It's like at 17, because you could go apply for colleges. It's just such a huge... Like, a six figure debt commitment to someone who's making $0, or negative dollars, and that young. Unless you really have conviction, it costs nothing to go and explore and learn for free, online.

Lenny Rachitsky (01:04:03):
I want to come back to the skills that you think are going to be most important, and let me try to mirror back a few things you said, that I very much agree with.

(01:04:11):
So it feels like if you want to be successful in the world where AI can build things for you, more and more, what I'm hearing is get good at figuring out what people need and want, what problems they need solved. Get good at articulating it really well to the AI tools. And there's this talk, "You don't need to be a great prompt engineer. You don't need to work on prompting," but it feels like it's more and more important, because you tell it something and it goes off and builds a thing. If you're clear about it, it'll save you a lot of time.

(01:04:42):
So it's be good at figuring out problems people need solved, figure out how to articulate that problem well, and ask for a clear solution. Figure out how to grow the thing, feels like that's still going to be a need, because Bolt's not going to go and find every... I could see that still running paid ads, and stuff like that. But it feels like that's going to be ongoing need.

(01:05:03):
And then I feel like there's this kind of unstuck step, like helping AI get unstuck, and it feels like that's where maybe engineering skills will come in more and more. Thoughts on just that skill?

Eric Simons (01:05:13):
Oh, totally. Yeah. So we actually, two weeks ago I think, we announced this program called Bolt Builders. And it's basically the genius bar at the Apple Store, where as folks are building on Bolt that are not developers, they'll run into some nook or cranny where the AI just cannot figure it out, or whatever. And I think that's just going to continue to be the case for the time to come. That's our position, and that's why we spun up this program.

Lenny Rachitsky (01:05:38):
And these are humans, that help you out.

Eric Simons (01:05:41):
These are humans. And people that we're certifying. And so, in Bolt in the coming weeks or whatever, there's going to be a button where you can just say, "Hey, connect me with a certified expert." And you can chat with them live, and they'll help you get unstuck, and you pay I don't know, 50 bucks an hour. Whatever it is. And then you get unjammed and you keep prompting. And again, I just think this stuff is, it just all seems like gravy to me. Engineers get to focus on difficult challenges, not like cookie cutter, "Let's make another CRUD app," stuff. They get to, debugging is challenging, and fun. And going and working on intellectually stimulating tasks, and all this stuff that's just copy pasta, over and over, all this, error app. It's just like, let the AI do all that kind of crap.

Lenny Rachitsky (01:06:29):
This is a potentially new job, for now at least, just unstuck the AI. Which I think over time, it'll get better and better, and we maybe won't need these people. But I love that it's now AI first, and person second. Versus person building the thing, and then AI. Like when Copilot launched, it was just like, "Cool, here's a little suggestion for this function," and now it's flipped. "Here's everything." And then, "Oh, I don't know what to do here. Help us here." And then, it's like a human suggestion. Isn't that interesting? It's like, human Copilot is flipping it.

Eric Simons (01:06:58):
Totally. Yeah. That's what's wild is, I think Sonnet was really the first model that flipped the equation, because that was really us, and old Cursor, and all these other things. The rapid growth started the second Sonnet went online. We actually tried building Bolt almost exactly a year ago, with the frontier models at the time. Spent a week or two building it. It just didn't work. The output, the code output was not reliable enough. It would constantly, it would be a broken app, or it would look ugly, or whatever. And then we got a sneak peek of the Sonnet stuff in May and we were like, "Oh. Okay, we should take that project back off the shelf and green line it, because this might be it."

(01:07:36):
And lo and behold, that's exactly what has happened. But yeah, that's the big deal that is, kind of under the hood, this is... What's going on here is, a very critical threshold has been passed with LLM's ability to write production grade code and apps that actually look beautiful, and actually function well. It's not perfect, but there's kind of this zero to one moment that's happened where it's like, "Okay, so now, yeah. Now the AI is the first thing," and then you're kind of popping a developer in every now and then, versus the other way around.

Lenny Rachitsky (01:08:11):
I did not know that. I didn't realize that so much of this was unlocked with, like it's sitting on top of Anthropix work, and specifically Sonnet. That was the first model, you're saying, that could code well enough.

Eric Simons (01:08:22):
Yeah, zero question.

Lenny Rachitsky (01:08:24):
Wow.

Eric Simons (01:08:25):
Zero question. Absolutely.

Lenny Rachitsky (01:08:25):
That is fascinating. Just the amount of, I don't know, revenue and business and ecommerce that that one model has unlocked, is insane. I did not realize that.

Eric Simons (01:08:39):
It is. And in retrospect, I'd mentioned, we'd never done an AI product at StackBlitz, and it's tempting. Like when of ChatGPT went online, everyone started adding AI to their products. We just didn't see a clear place for a really added value. So I was not super bullish on, you know, a lot of people were like, "AGI is going to be here in 2023." You know what I mean? There's all this stuff that was being said, and I was like, "I just don't know if I necessarily buy how fast people say that it's going to move." And to a certain degree, that was the correct view.

(01:09:13):
What I didn't really think about though, is if AI, if LLMs are going to get better at a specific vertical, which are going to be the things that it would be. And if you look at law, for example, you want to make the best LLM for looking at case law. The problem with that stuff is, it's not deterministic. The judge's ruling is dependent on society's view of things at the time, political stuff going on, the jury. There's a ton of things, that it's not deterministic. And so you can't really create a lot of training data that's going to be super reliable, and produce really good results. And you can't just make up cases and say, "Theoretically, the judge would say this." Because, I mean, it just doesn't work.

(01:09:57):
Software is deterministic. When you write code and you hit run, it either runs or it doesn't. And that's the key insight Anthropic really had. They just went deep. And then, this is what they're doing, is just reinforcement learning on basically permutating every type of app you could ever build, and just spinning up tens of thousands of cores or whatever to do that. Just building tons of training data, and doing reinforcement learning, and making their LLMs the best in the world at building beautiful, reliable applications. I'm extremely bullish. It makes technical sense why, of anything, LLMs are going to get insanely better at writing code than probably most other types of applications for LLMs. Simply because it's something that can be extremely deterministic, and permutated thousands and thousands and thousands of times per second.

(01:10:54):
And so I think the broader trend here is... And Sonnet has woken everyone up. Google, and Open AI, all the... Everyone is now gunning for coding because, how big is the market opportunity to rewrite the software world order? It's trillions of dollars, or something, right? The world runs on software. So I think that just in a macro, the highest macro view, and why we went and raised money for Bolt. This seems like an extremely clear shot, there's this, you can kind of separate the hype of what people say and blah, blah, blah. When you break it down technically, this makes sense. It makes sense what's going to happen here. And for us, we're like, we are so happy to be well positioned to go and enable people to kind of ride this wave of the innovation that is here in LLMs, and is going to just keep coming, and therefore enable more people to build even crazier amazing software. So that's our world view, at least, of what's going on here at the macro.

Lenny Rachitsky (01:12:05):
And when did Sonnet even come out? It's been a while, right?

Eric Simons (01:12:08):
I think they officially, I think it was in June, when they officially put it online.

Lenny Rachitsky (01:12:12):
So since June, this is the worst it will ever be, the state of AI coding. And it's already this good. And there hasn't been anything, like they haven't launched their new model, since last June. So this tells us just how quickly things are going to start moving once they launch their next model. And as you said, everyone's gunning now for this, because they realized "We're behind on the coding piece." So, wow. This is going to get crazy.

Eric Simons (01:12:40):
I agree. Yeah, it's been, again, there was no blog post that laid all of this out for us. It's just been kind of this-

Lenny Rachitsky (01:12:48):
You just noticed the code was really good, basically.

Eric Simons (01:12:50):
And from there, it's just, we've been piecing together all this other stuff. So it's been kind of the thrill of a murder mystery of, "What is going on here?"

Lenny Rachitsky (01:12:59):
Oh, really.

Eric Simons (01:13:00):
Yeah. You know what I mean?

Lenny Rachitsky (01:13:01):
Just piecing together what you've seen on Anthropic releasing, is that what you mean? What have you been noticing, murder mystery-wise?

Eric Simons (01:13:06):
Well, and then the impacts of Bolt, where we have people that are not technical using this. How are they using it? Why are they doing this? And then, all the stuff we've talked about in this podcast has been the result of nine months of just R&D and seeing the results of it, and then going, "What?" And then digging in, doing another thing and then going, "What," again. And then it just keeps happening, because there's no charted course for this.

Lenny Rachitsky (01:13:31):
It's like an anthropology, if that's the right term, of just watching. It's like an emergent discovery, it sounds like. Versus you had the strategy, "Here, we're going to do this," where a persona to launch this thing will happen?

Eric Simons (01:13:42):
Yeah, a hundred percent. Yeah. I think that that's the best way to put it. It's the best way to put it. It's exactly that. And so it's very interesting to just-

Lenny Rachitsky (01:13:54):
To watch, and be a part of it, I imagine.

Eric Simons (01:13:56):
Yeah, yeah.

Lenny Rachitsky (01:13:57):
And I think as people say, "Okay, these are just toys, they're prototypes, it's not going to work with your existing code, it's not going to scale." It's important to note just what we talked about. This is a model from last June that this is possible on, and everybody's working on the next cutting edge model that will make this even better, and that's going to come real soon. Okay. Amazing.

(01:14:20):
I just have a few more questions to close out this conversation. One is just, what is coming next for Bolt? What are some of the cool new features that'll be launching before this comes out? Maybe right after this comes out, maybe in mid-March?

Eric Simons (01:14:33):
Yeah. Okay. So by the time, and I'm going to go back and tell our engineers, "I said this on this podcast-"

Lenny Rachitsky (01:14:33):
"I've committed. Sorry, guys."

Eric Simons (01:14:40):
This is, I found actually being a leaky faucet on talking on podcasts and stuff, my engineer is like, "How could you tell them..." "You just have to ship it faster, now. You got to make it real," right?

Lenny Rachitsky (01:14:49):
Or we'll get AI on it.

Eric Simons (01:14:52):
No, no. Yeah. But I think for us it's like, again, we've seen a lot of PMs, designers, entrepreneurs, et cetera, using Bolt. And so, we're really looking at better fitting with the tools that folks are using to do those things today. Bolt's not going to replace them, or something. And if you're working at a company, how do you integrate this stuff with your existing business, or your existing product and code base? Because that's the question we often get from people is, "How do I open my," like we're talking to one of the fan companies the other day, and like, "How do we open our production code base in this, that's like 20 years old?" I'm like, "You don't. None of this stuff. That's not what you do. This is for rapid product development in your use case."

(01:15:41):
So the features that we're going to be shipping, I'm pretty stoked about this one, so we've been working on this for a while and we've partnered up with a company called Anima to do this. But basically, so on any Figma URL, when you're looking at a design that you've made, if you just put bolt.new in front of that URL and hit enter, it's going to suck that design into Bolt, and turn it into a full stack app or mobile app, just out of the box.

Lenny Rachitsky (01:16:08):
That is genius.

Eric Simons (01:16:09):
Yeah. It's-

Lenny Rachitsky (01:16:09):
Amazing.

Eric Simons (01:16:10):
It's going to be nuts. Yeah, I mean, it's really fun to use. Because whether you're a developer or designer, or whatever, going and taking that and turning it into an actual coded app. And the thing is, once it's in Bolt, you can just keep prompting from there. You're like, "Yeah, well, add another page here." So you can have things that, where you want pixel perfect design, you can have it, and it'll translate one to one. And it's splitting out the assets. Anima's been doing this since 2017, Figma to code. They've got the best agent in the world for, they're the number one Figma plug-in, or whatever. And so in Bolt, it's going to just work. It's just deeply integrated

Lenny Rachitsky (01:16:53):
So it's bolt.new slash, the Figma URL, to the design.

Eric Simons (01:16:56):
Yep. That's all you got to do.

Lenny Rachitsky (01:16:56):
Amazing.

Eric Simons (01:16:57):
And in Bolt, we're going to also have a little Figma icon in the chat thing. So if you go to Bolt itself, you can click it and then paste the URL, or whatever. But yeah, but it's like that. It's from Figma to full stack app in a click. Literally. That's crazy. So that one's pretty cool.

(01:17:15):
And then the other one that we're working on is an integration with Slack, because often when you're talking about Figmas, like Figma links or whatever, at a company, you're in Slack or whatever. So you're having conversations about, "Hey, we should really add a page to this that does da-da-da." And so we're actually creating a Bolt Slack bot whose job is to basically act like a developer on your team. And so you can be, in a thread, you can be like, "Hey, I think we should a homepage." "Yeah, okay. @Bolt, can you whip this up real quick?" And it'll go and just suck down the entire conversation history so far in your Slack, on the thread or whatever.

(01:17:54):
You'll be like, "Okay, cool. So you kind of want me to take this Figma URL, which I can convert automatically," thanks to the future I just mentioned right before this. "I can just go and convert that thing out of the box, and then you want me to add a page to it, and then do this thing. Got it. I'm going to go do that. Oh, here's the URL where you can open it up and keep prompting." You know what I mean? So it's like having a developer or somebody to kind of kick this thing out. And you're just like, "Go make this thing real quick."

(01:18:15):
So those two things, I think it's, again. You start think about how our company's going to change how they're currently doing product development. And even just like, "Hey, we need to spin up a marketing site. Here's the thing." We're like, "Can you do that, Bolt?" "Yep. Let me go do that." You know what I mean? And that's why I'm kind of excited about those two, in particular, because I think it's going to be well received, and folks are going to be stoked about it. I hope. Knock on wood.

Lenny Rachitsky (01:18:40):
Those are awesome features. I love the Slack piece, because when I think about agents, there's always talk about agents. To me the simplest way to understand it is just a Slack bot, just that AI can talk to you like they're a person in Slack. And I love that's exactly what you're doing. And this is this gigantic feature of just like, "Hey, you just have this engineer now that can go build stuff for you."

(01:18:59):
Let me actually ask you a question along these lines, that I was meaning to ask, but I forgot. Is just, your engineering team, what are they using to build Bolt? I imagine it's a lot of Cursor. How much is Bolt, at this point, involved in building Bolt? And is there any other tools that they found useful, find useful, that are worth highlighting?

Eric Simons (01:19:18):
Yeah, good question. Yeah, we definitely use Cursor. Our folks use Cursor a lot. We use Bolt a lot for the product development process, like a ton, we're using it. And we're doing basically the flow that I described, where if things that need to be Pixel perfect, we're going to Figma for. And often we're taking that and we're pulling that into Bolt, because we've got access to the integration today. So pull that into Bolt and we're saying, "Hey, go add these things or whatever." Or just saying, "Hey, here's a screenshot of our UI, go do da-da-da."

(01:19:47):
Other AI tools that the developers are using. I think those are the primary ones. I mean, I think we've got a subscription to Claude, and ChatGPT, and things like that. But I think for development, Cursor is the main thing,

Lenny Rachitsky (01:20:03):
Yeah, it's cool how few tools, like there's so many AI tools, and it's interesting how few people actually end up using. It's like Cursor, Claude, ChatGPT, and then maybe another tool. Like Bolt.

Eric Simons (01:20:13):
Yeah. Totally.

Lenny Rachitsky (01:20:14):
Okay. Final-ish question. Say somebody is opening up Bolt for the first time. What's something that, imagine you could sit next to every new user that's just trying Bolt for the first time, and you could whisper a tip in their ear to be successful with Bolt. What would that tip be?

Eric Simons (01:20:33):
And this is like, because we have a lot of different types of users. I imagine you're talking about PMs or designers, and that sort of-

Lenny Rachitsky (01:20:39):
Let's do PMs. That's a good one. That's a lot of the audience here.

Eric Simons (01:20:41):
I would say, talk to this thing like you do a Linear ticket, or a JIRA ticket. That would be my advice. And talk to this like you would, like you're talking to one of the developers on your team. And what that means is, be specific on things that matter. And on things where, also, you can let it be creative. You can go to and just say, "Hey, make it prettier." And it does a good job, it actually does a really good job, when you give it just, vibes. So anyway, I think for PMs it's like, you have the skillset. You know how to do this. This is, just think of this as your coworker, your developer coworker.

Lenny Rachitsky (01:21:24):
I love that. Because these tools are so easy, you just go in and it's like tell it a thing, and then, cool. You have a website. It's coded, boom, done. And what I'm hearing here is, take a little time to craft your ask. It may be tempting to just start, "Cool. Build me a serum," and then you're stuck with that first version. And then you're like, "Oh, well, okay. I didn't mean that." So it sounds like your advice is take some time to craft the ask, and be clear about what you want.

Eric Simons (01:21:49):
Yeah, totally. Especially if you have a clear vision of what you're trying to build. And something reasonably sophisticated. And what I recommend everyone to do, if it's your first time trying Bolt and you're like, "What should I have it do, and I don't have an idea"? Tell it to build you a personal website. There's something like magic. You take your LinkedIn copy, and paste your LinkedIn bio and work experience, just like select text, copy, paste it. "I need a website, my name is so-and-so, here's my LinkedIn history. My favorite color is blue, and I like dogs." And then hit paste, right?

Lenny Rachitsky (01:21:49):
"Make it prettier."

Eric Simons (01:22:24):
[inaudible 01:22:24] actor. Yeah. And then, you know what I mean? And then you can hit deploy. And if you don't have a .com yet, now you can. Right? I mean, now you have a real, personalized service. I think there's kind of a moment around that where it's like, "Oh, okay, wow. This," it's zero shot, zero shot 99.999% of the time. You're getting a beautiful personal website that you didn't have before, that would've taken you an hour, on Wix. If not more. And that gives you the taste of, "Oh, okay, cool. So if I really take the time to think this through, and make a PRD, and then put that in piece by piece into this thing, the sky's the limit."

Lenny Rachitsky (01:22:55):
Eric, this has been just insane on so many levels. I have so much to process, I think a lot of listeners do too. Maybe as an actual final question, I saw this story about how when you were starting StackBlitz, or maybe even before StackBlitz, you squatted in the AOL office. Because you had some badge that still worked. Maybe just tell that story.

Eric Simons (01:23:18):
Yeah, that was the thing I was most known for. That happened like 2012, and I was 19 years old, so it's been a very long time. I think I'm 33, now or something.

Lenny Rachitsky (01:23:27):
The statutes of limitations are expended.

Eric Simons (01:23:30):
Yeah, yeah, exactly. But yeah, for a while I was like, "I have to do something more notable than living at AOL. This can't be what I'm known for." But now people are like, "Oh, wait. You're the StackBlitz guy, and you're the AOL guy?"

(01:23:43):
So when I first came out to Silicon Valley, we got into a, I was building a K12 education startup at the time, and this is back during the days where Y Combinator, they only gave you like 20 grand, and so there was this offshoot of Y Combinator called Imagine K12, it was Jeff Ralston who, I think he was CEO of YC a couple of years back. And then Imagine K12 merged into Y Combinator a couple of years after Rob went through it, but anyways, they had an office space at AOL. At the time, AOL was trying to reinvigorate the company and they were like, "Hey, we should get young startup blood in here, so let's rent out office space to teenagers," basically.

(01:24:24):
So I was there, and we ended up running out of money. 20 grand doesn't go very far in the Valley, so three or four months in, we were like, "Oh God, what do we do?" And I was going to the AOL office multiple times a week, because we had access cards to get in to get to the investors' offices. And I realized, I was like, "You know, they have couches here, and they have food. There's ramen that you can microwave, and there's a gym where there's a shower, and even you can do laundry." And then, so I was like, "I don't know, maybe while I figure this out, I'll just live out of here." And so that's what I ended up doing for, I think, four or five months. I was living out of this headquarters over on Page Mill in El Camino, in Palo Alto.

(01:25:12):
And then, I got away with it for a while just because the guards, the security guards, they worked 12-hour shifts. And so the guys that, when I was there at night... And I was coding, all day every day, basically. So the guys at night just were like, "Dang, this guy works really hard." And then in the morning they'd be like, "Wow, this guy is working really hard." And I became friends with some of them, and then eventually, I think there were also a whole bunch of Stanford students that I think they put bunks in one of the aisles. It was just started getting out control, so I think they started cracking down. And then one morning, at like 4:00 in the morning, a guard came in and threw me out.

(01:25:52):
I'm from Chicago. I don't know anyone. At that point I'm like, "I know no one in the Bay Area." So I went to a Starbucks, which was not open. I slept on the table outside of the thing. And I think I hit up one of the other entrepreneurs that was in the program. I was like, "Do you have a couch? I think I kind of need it, at this point." Yeah, the press got wind of it, and it was this worldwide story. But I lived on a dollar a day. That was the crazy thing. My burn rate was a dollar a day, at that time.

Lenny Rachitsky (01:26:22):
What did you use that dollar for?

Eric Simons (01:26:25):
This is back when McDonald's had the Dollar Menu. Literally. So it was like, I occasionally would go and get a cheeseburger or whatever. Yeah, it was ultimate scrappiness.

Lenny Rachitsky (01:26:41):
You're technically homeless. From homeless, to one of the fastest growing startups in history. Eric, what a journey. This is such an interesting point in time of your life, and of just tech. No matter what happens, I'm sure you'll be extremely successful, but it's such an interesting just point in that journey. And I'm thankful that you made time to share it with us.

Eric Simons (01:27:01):
It's always good to just have the perspective of, you should start companies to keep the mindset that you're doing it to have fun. So, stoked to see where this goes, one way or the other. It's going to be interesting.

Lenny Rachitsky (01:27:16):
Eric, final questions. Where can folks find online if they want to reach out, maybe follow up on some stuff you shared, and how can listeners be useful to you?

Eric Simons (01:27:23):
Yeah, totally. I mean, yeah, so bolt.new is the website, over on Twitter, I'm @ericsimons40 on Twitter, and I think our Twitter account is @boltdotnew, not with a period. It's like, B-O-L-T-D-O-T-N-E-W. And yeah, I'm curious to hear what folks think. I mean, this is, again, we are learning so much from the people that are coming and trying this thing out and giving their feedback. And within the first meeting of it going online, we were not the experts on how use the tool anymore, and it's been that way ever since. And so, I love hearing from folks on what they want to see next, and how this is helping them. And where they run into problems, like where we need to go and fix things. So my email address is Eric@stackblitz.com. That's Eric with a C. So I'd love to hear from anyone, whether it's a DM on Twitter, or an email.

Lenny Rachitsky (01:28:18):
Amazing. Eric, thank you so much for being here.

Eric Simons (01:28:21):
Awesome. Thank you so much for having me. This is a blast.

Lenny Rachitsky (01:28:23):
Bye, everyone.

(01:28:26):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review, as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com.

(01:28:46):
See you in the next episode.

---

## Taking control of your career | Ethan Evans (Amazon)
**Guest:** Ethan Evans  
**Published:** 2024-01-14  
**YouTube:** https://www.youtube.com/watch?v=GB0P0_nFPTA  
**Tags:** growth, analytics, conversion, hiring, leadership, management, vision, market, persona, design  

# Taking control of your career | Ethan Evans (Amazon)

## Transcript

Ethan Evans (00:00:00):
People think invention takes all this time, but you only need two hours once a month. The thing is, once you have one good idea, it often takes years to express that.

(00:00:09):
So you had the idea to have a newsletter. I know some of the history of your newsletter. You've been working on the expression of that idea for years now. Jeff and Amazon had ideas like, "Let's have Prime shipping." Prime is still getting better and still being worked on. It's a 20 some year old idea. The Kindle, a decades old idea now still getting better. The point here is you don't need very many good ideas to be seen as tremendously inventive.

Lenny (00:00:38):
Today my guest is Ethan Evans. Ethan is a former vice president at Amazon, executive coach, and course creator focused on helping leaders grow into executives. Ethan spent 15 years at Amazon, helped invent and run Prime Video, the Amazon Appstore, Prime Gaming, and Twitch Commerce, which alone is a billion-dollar business for Amazon. He led global teams of over 800, helped draft one of Amazon's 14 core leadership principles, holds over 70 patents, and currently spends his time executive coaching and running courses to help people advance in their career, build leadership skills, and succeed in senior roles.

(00:01:14):
In our conversation, Ethan shares an amazing story of when he failed on an important project for Jeff Bezos and what he learned from that experience. We spent some time on something called The Magic Loop, which is a very simple idea that I guarantee will help you get promoted and advance in your career. We also get into a bunch of other career advice, primarily for senior ICs, any managers. We get into advice for standing out in interviews, plus some of Amazon's most important and impactful leadership principles and much more. I learned a lot from Ethan and I'm excited to bring you this episode. With that, I bring you Ethan Evans after a short word from our sponsors. 

(00:01:50):
Let me tell you about our product called Sidebar. The best way to level up your career is to surround yourself with extraordinary peers. This gives you more than a leg up. It gives you a leap forward. This worked really well for me in my career and this is the Sidebar ethos. When you have a trusted group of peers, you can discuss challenges you're having, get career advice, and just gut check how you're thinking about your work, your career, and your life. This was a big trajectory changer for me, but it's hard to build this trusted group of peers. 

(00:02:20):
Sidebar is a private, highly vetted leadership program, where senior leaders are matched with peer groups to lean on for unbiased opinions, diverse perspectives, and raw feedback. Guided by world-class programming and facilitation, Sidebar enables you to get focused tactical feedback at every step of your career journey. 

(00:02:39):
If you're a listener of this podcast, you're already committed to growth. Sidebar is the missing piece that catalyze your career. 93% of members a sidebar helped them achieve a significant positive change in their career. Why spend a decade finding your people when you can meet them at Sidebar today? Join thousands of top senior leaders who have taken the first step to career growth from companies like Microsoft, Amazon, and Meta, by visiting sidebar.com/lenny. That's sidebar.com/lenny. 

(00:03:12):
Let me tell you about a product called Sprig. Next gen Product teams like Figma and Notion rely on Sprig to build products that people love. Sprig is an AI powered platform that enables you to collect relevant product experience insights from the right users so you can make product decisions quickly and confidently.

(00:03:32):
Here's how it works. It all starts with Sprig's precise targeting, which allows you to trigger in-app studies based on users' characteristics and actions taken in product. Then Sprig's AI is layered on top of all studies to instantly surface your product's biggest learnings. Sprig's surveys enables you to target specific users to get relevant and timely feedback. Sprig replays enables you to capture targeted session clips to see your product experience firsthand. 

(00:03:58):
Sprig's AI is a game changer for product teams. They're the only platform with product level AI, meaning it analyzes data across all of your studies to centralize the most important product opportunities, trends, and correlations in one real-time feed. Visit sprig.com/lenny to learn more and get 10% off. That's sprig.com/lenny. 

(00:04:26):
Ethan, thank you so much for being here and welcome to the podcast.

Ethan Evans (00:04:30):
Lenny, thank you a ton for having me. I'm super excited to talk about some of the things we have teed up today and to help people.

Lenny (00:04:37):
The first thing I thought we could chat about is The Magic Loop. So you wrote this guest post from my newsletter sometime earlier this year. It is, I don't know if you know this, but it's currently the sixth most popular post of all time on my newsletter across 300 plus posts. Did you expect this advice to resonate the way that it did, and why do you think it resonated as much as it did?

Ethan Evans (00:04:59):
So the competitive part of me really wants to analyze spots one to five and figure out, do they have an unfair advantage that they had more time? But I was very hopeful that the advice would resonate that way, because I put a lot of work into simplifying it and making it really easy to understand and follow. So I'm very pleased it has, but I was hopeful it would do so well.

Lenny (00:05:24):
Well, I will say sometimes they keep growing, so this isn't necessarily the terminal point for the post.

Ethan Evans (00:05:28):
The final position. Yeah.

Lenny (00:05:30):
Okay. So for people that haven't read this post, or maybe for folks that have and maybe could use a refresher, let's spend a little time here. Could you just briefly describe this idea of The Magic Loop that you wrote about?

Ethan Evans (00:05:40):
Yeah, absolutely. So The Magic Loop is how to grow your career in almost any circumstance, even with a somewhat difficult manager. It does assume that you're working in some environment, normally as an entrepreneur or with a boss. But the basic idea of The Magic Loop is five steps and they're very easy.

(00:06:01):
The first one is you have to be doing your current job well. It's not possible to really grow your career if you're not considered at least performing at a solid level. Now, it doesn't mean you have to be the star on the team at this point, but what you can't have is your boss wishing that you were different. Like, "Ethan's not very good." So you have to talk to your manager and find out how you're doing and address any problems. So step one is do your job well.

(00:06:31):
Then step two is ask your boss how you can help. Speaking as a manager, and I've talked to hundreds of managers, very few people go and ask their manager, "What can I do to help you? What do you need?" And so just asking sets you apart, and it begins to build a relationship that we're on the same team, that I'm here as a part of your organization to make you successful, not just myself. 

(00:06:53):
Step three is whatever they say, do it. So you dig a big hole. If you say, "What could I do to help you?" And they say, "Well, we really need someone to take out the tray sheets day," and you're like, "Oh, I didn't mean that. I wanted exciting work. I don't want to do sort of this maintenance work or whatever." So do what they ask, help out even if it's not your favorite work. 

(00:07:14):
Once you've done that though, and maybe you do that a couple times, the fourth step is where the magic comes in. You go back to your manager and say, "Hey, I'm really enjoying working with you. I'm wondering is there some way I could help you that would also help me reach my goal?" And whether that goal is to change roles or get a raise or get a promotion, you say, "My goal is I'd really like to learn this new skill. Is there something you need that would also help me learn this new skill?" And the reason this works is managers help those who help them. It's just human nature. We all do that.

(00:07:52):
Generally, they're very open to meeting you halfway and saying, "Sure, I need this. We can rearrange it. We can find a way to meet your goals over time." Now for step four to work, you do have to know what is your goal, so you have to be clear on what it is you want. Well, that part's up to you. 

(00:08:15):
And then step five is the easiest step of all. It's just repeat. So like lather, rinse, repeat with your shampoo. Step five is once you're working with your manager towards your goal and discussing where you're going, and you're helping each other, the magic of the loop is just go around and around.

Lenny (00:08:31):
I was going to ask you, why is it that you call it The Magic Loop? Also, we kind of dived right in, but what is the goal of this? I guess it's pretty clear maybe at this point of this helps you advance in your career, but whatever you want to share along those lines.

Ethan Evans (00:08:43):
Yeah, okay. Very fair. So I called it The Magic Loop because I pioneered it with my audience a few years ago. And it works so well, that people were writing back in and saying, "How do I turn this off? I'm in over my head now. My boss has asked me to do all these cool things, and I feel like I can't catch up, and I've already been promoted once and I need time to digest it." And it just seemed like it worked like magic. It worked in almost every circumstance. 

(00:09:15):
There are of course exceptions where you have very exploitative managers who are like, "Oh, it's great. You're working harder, keep doing that, and they won't do anything for you." But those are rare. And then the purpose, yeah, to help you get satisfaction in your career. A lot of people are unhappy with their jobs. Many people want to move up a level or get paid more. Not everyone. Some people want to change what they're doing, they're bored. This is a path to all of that, because it's forming a partnership with your leadership to say, "Look, I'll help you, but I need you also to help me." And most good managers are very open to that.

Lenny (00:09:52):
When we were working on this, one of the pieces of feedback I had was I feel like I could just tell my manager, "Hey, I want to grow my career. What can we work on to help me get there?" And your feedback was like, most managers are not that good and not that thoughtful about their employee's careers. Can you just talk a little bit about that? People may be hearing this and be like, "Why do I need to do this? This seems like a lot of work."

Ethan Evans (00:10:15):
If you have a great manager, you may not need to do nearly as much formality. They may have given you good feedback, so you don't need to ask for feedback. They may have offered you opportunities to step up, and you've said yes to some and maybe no to others. That's fantastic. I designed The Magic Loop for the people who either don't know what to do or their manager is either not that good or just very busy.

(00:10:37):
Remember, lots of managers have great intentions to help their employees, but they get busy with their own lives, their own work, all the things they're focused on, even also their own career. The manager is often busy thinking about their own needs, and so they mean to get to you next week, and next week drifts on for a year.

Lenny (00:11:00):
What has come up since this has come out that you would want to either add to, or tweak, or help people better understand? I imagine there's some criticism. I imagine there's a lot of, "Yes, yes, yes. This really works."

Ethan Evans (00:11:12):
Two things I'd love to clarify. The first is many people ask me, "Why do I have to do this? Shouldn't my manager notice what I'm doing? Shouldn't my manager help with my career? Shouldn't my manager be planning for me?" And what I say about that is what your manager should do and $4 will get you a cup of coffee at Starbucks. 

(00:11:36):
The point of this loop is it's in your control. It is true that a good manager would do all those things I just mentioned, but not all managers are good and some of them need some help. And the thing I would just say about The Magic Loop is it's in your control.

(00:11:52):
And so you can be upset that your manager isn't perfect, but move on from that and take control of your own situation. That's the first thing I'd say. The other big extension I would make is look, if you are a manager or a leader of any type, you can initiate The Magic Loop from your side, so you can talk to your employees and say, "Hey, what are your career goals? Would you like to form a partnership where you step up to new challenges and I help you get to your goals?"

(00:12:26):
I had a lot of success forming this kind of partnership with my employees, where as they saw growth and success, they really leaned in and like, "This system works. You're actually investing in me now. I'll work extra hard." And I'm like, "Yes, and we can grow your team or grow your opportunity," and it was very win-win.

Lenny (00:12:46):
To give people a little bit of social proof, you mentioned some of the folks you've worked with on this. Can you share some stories, or stats, or anything to help people understand how helpful this ended up being to folks you've worked with?

Ethan Evans (00:12:58):
Yeah, absolutely. I'll tell one story from each end of the spectrum. And what I mean there is entry-level people and then high level executive leaders. I had an entry-level person write me back and say, "Look, when I learned about The Magic Loop, I was at a company and not doing very well. I started applying it. They offered me a $30,000 raise and a bigger job. And I turned it down because I got hired at this other company that was offering me even more, and I went there. And they've promoted me also," and he was one of the people who wrote in and said, his exact words were, "A year ago I was made redundant." So he is in the UK, redundant is their word for laid off. "A year ago I was made redundant. I got this first job and I got an offer for an increased salary, and then I got the second job and I got an increase when I joined that was even bigger." And he was in that situation of, "Mow I need to sort of slow down and digest all of that."

(00:14:05):
On the complete other end, one of my best people I ever worked with joined my team at Amazon as what we would call an SDE II, which in Amazon is a level five employee. He grew with me kind of following this process to a senior engineer. Then he switched to management and ran a small team. Then he became a senior manager and he relocated with my organization. He opened a new office in another city, was eventually promoted to director running his own office of a couple hundred people. And this was over the course of about eight years. He went from a mid-level engineer to an executive with a team of 800 people. Now he was a very hard worker, but over this eight years we just saw all this progress.

(00:14:56):
And then eventually he moved on. He founded his own startup, sold that, and now works as an executive vice president at one of the major online banks. And so his career in some sense has exceeded mine, but during that eight year span, he just grew so much. And this is the process we followed.

Lenny (00:15:19):
Wow, those are excellent examples. What levels does this help you with? At what level is this most useful, and then does it kind of taper out it? I don't know if you get to VP level, do you still try using Magic Loop?

Ethan Evans (00:15:33):
So I think it works anywhere from the start of your career to pretty far into it. I think at my level, I finished my career as a vice president at Amazon. It does peter out in the sense of the active. And what I mean by that is you're still doing the same thing, but you don't have to talk about it. Your managers are expecting you to step up and recognize challenges. They're expecting you to ask for resources when you need them, and you don't sort of have this level of explicit conversation around, what can I help you with? They're expecting you to anticipate what's needed.

(00:16:09):
So in the newsletter we did together, I wrote about how over time, you go from asking your manager, "How can I help?" To suggesting to your manager, "These are some things I see that seem like they need to be done. Would you like me to do them?" To just seeing what needs to be done and sort of keeping your leader in the loop and saying, "Hey, I noticed that we have this problem. I fixed it. I noticed we have this opportunity. I've started program against it." I think at the executive level, it's much more you being proactive and just keeping your leader in the loop.

Lenny (00:16:44):
I think in the post, the way you described this step is this is advanced mode. Don't jump straight to this. Don't just start suggesting things, because you may get it wrong.

Ethan Evans (00:16:53):
Yeah, well, it's all a matter of rapport and trust. A huge part of career success is how much trust you have, mutual respect with your leadership. When they're confident that you're going to make the right decisions, they're confident to let you go. But yeah, when you're brand new or you're new to a manager, if you just jump in, you may either not work on the things they value or even find yourself working across purposes, and that isn't the right place to start.

Lenny (00:17:19):
Awesome. Okay. Just to close out this conversation. You touched on this, but why is it that you think this is so important and effective? Why do you think this works so well? People may not recognize, "I see this is the key to this."

Ethan Evans (00:17:31):
Well, I think it's two things. First, I mentioned how rare it is for managers to be offered help. If you're a manager, you'll recognize this. If not, feel free to talk to any manager, whether your own or somebody else. Ask them how much they worry and how much they feel overwhelmed and wish someone would give them a hand. Management can be a lonely job, because you feel like you're responsible for everything. So having an ally, it's just a huge weight off people's shoulders.

(00:18:01):
And then I think a lot about social engineering. The social engineering's here is just the simple, "You help me, I'll help you." It doesn't have to be exploitative, it's just we help those people who help us, and that's built into human survival. 

(00:18:18):
And I think this loop works so well because it's just leaning a little bit into that behavior. So many relationships with managers are oppositional. You tell me what to do, and I'm kind of like a kid in high school who's trying to figure out how do I skip as many classes as possible and turn in as little homework and still get by with a D? That relationship won't build your career.

(00:18:45):
Some people approach their jobs as my goal is to do the least I can and still collect my paycheck. That's an approach if you're okay with where you are. It's not what I coach though. I assume people want to grow.

Lenny (00:19:02):
Okay, so maybe it's just as a closing question, for people that are listening and want to start putting this into practice slash are stuck in their career and are just like, "Okay, I see. Here's something I can do." Could you just again summarize the loop briefly?

Ethan Evans (00:19:15):
Sure. Step one, make sure you're doing your current job well. The way I explain this is when you go to your manager and ask, "What could I do to help?" You don't want their answer, even if they don't say it quite so bluntly to be, "Do your F-ing job." You need to be doing that already. So be doing a good job.

(00:19:34):
And unfortunately, a good job is in the eyes of your manager in this case. You may think I'm doing great work, but if your manager doesn't, they're the ones you need to build as an ally here. 

(00:19:46):
Once you have that, go ask how you can help, do whatever you're asked, and then go back to your manager and suggest or ask, "I would like to meet this goal. Can I keep helping you? What could I take on that you need that would also help me meet this goal?" And that's where you start to try to bring your two sets of aims together. What do you need done, how can I get to my goal? And let's do those things together.

(00:20:11):
And then you just repeat this loop. You build trust, you build the relationship. And with all good managers, and even a lot of moderate managers, they appreciate the help so much, they really lean into that.

Lenny (00:20:23):
I think there's two really important elements of this that you haven't even mentioned necessarily, that I think are part of the reason this works so well. One is this forces you and your manager to identify the gaps that are keeping you from the next level, which it's often vague, and then you get to a performance review, and then your manager's like, "Ethan, you're still not good on this and this and that," and you're like, "You never told me that that's the things you're looking for for me to get promoted." So I think there's this implicit, here's what you need to work on to get to the next level, which I think is part of step four. 

(00:20:53):
And then you actually did touch on this that it's important to share your goal to your manager. Here's what I want. I want to get promoted. A lot of times they don't know that and you helping them understand, "Here's what I want, help me get there." It goes a long way. So there's a lot-

Ethan Evans (00:21:06):
Managers often fall into the trap. They chose to become managers, so they assume one of two things about you. They either assume that you want to keep doing exactly what you're doing forever, just maybe make a little more money.

(00:21:16):
So you're an artist, you want to keep drawing forever. You're a lawyer, you want to keep writing contracts forever. Or they assume that, "Hey, I became a manager. I'm very proud of my career. That must be what you want."

(00:21:29):
And these assumptions are natural, right? We tend to view by default that our path is great and everyone would want to be us. Now of course, some good managers don't do that. But if you clarify and express your goals, you remove that ambiguity.

Lenny (00:21:45):
I actually had a period in my career where I specifically did not want to get promoted. I was very happy where I was, and I just wanted to keep doing this awesome IC role. Is that something at all you see where people are just like, "I'm good. I don't need to get promoted," and then is this helpful in that in any way or is it not as big a deal?

Ethan Evans (00:22:02):
So first, I reached a point in my career where I was no longer pursuing promotion either, and I wanted to do other things. So I've lived that myself and I've used the same loop, but I used it to go do what I wanted to say, "This is now what I want, and how do we get there? How do we create a role where I'm adding value appropriate to my level, but I'm doing this other work that's fun?" I moved into gaming and I really wanted to do that.

(00:22:25):
Second, I think it is still helpful because there's something you want probably. Maybe you want to work on different kinds of projects or maybe you want to work with a different higher performance team. Or maybe you want to rebalance your life and say, "Hey, I love what I'm doing, but how can I be a star performer for you but within these boundaries?"

(00:22:47):
So if you truly have the perfect job just as it is, you may not need The Magic Loop. But I know so few people if you're like, "Nope, there's absolutely nothing I could improve about my role."

Lenny (00:23:00):
Yeah, I think that your point about your goal doesn't have to be promotion. It could be work on a different part of the org, try something totally... Maybe transition to a new function that could be part of your goal. Awesome. 

(00:23:09):
Okay, so along the same lines of career progression, you work with a lot of senior manager types, kind of the level of L7 and one M2-ish, and you share with me that one of the most frustrating parts of their job in that specific portion of their career is they get stuck at that level and they don't move up, and it becomes really annoying, and they're not sure how to break out of that. What advice you share with folks like that, that may be listening?

Ethan Evans (00:23:36):
Yeah, so it's common to get stuck there, and there are a few reasons for it. First, there are a lot of senior managers. If you think of your average director, they may have six to eight reports. How many more directors are needed? So there's a choke point.

(00:23:52):
Second, that choke point is worse in the current economy, and in the past maybe a lot of companies, Amazon, Google, apple, etc., were growing very rapidly. And so it wasn't just you were waiting for some other director to leave. The teams were getting bigger.

(00:24:07):
I experienced this at Amazon, where over a nine-year period I went from managing six people to 800. And so I went from a senior manager all the way to a vice president, and I described I was, in some sense just riding the elevator. The elevator was going up, and as long as I managed to stay on it, I was going to arrive at vice president.

(00:24:29):
But the other thing that causes people to get stuck is the difference between a senior manager and a director is how you lead and the work you're doing. And you can get as far as senior manager by being really strong in your function and being really good at getting things done. As a director, and as a VP beyond that, it becomes much more about influence, coordination with others, and letting go of being in all the details yourself. And so senior managers really have to change some behavior.

(00:25:03):
I often reference the book by Marshall Goldsmith, What Got You Here Won't Get You There. Not only because it's a great book classically on this problem, but because the title tells the story. All the great traits that got you to this one level won't get you to the next level where you're more expected to be thinking in strategic terms, thinking longer term.

Lenny (00:25:26):
So to someone that may be in that role today and they're not moving up, is there anything they can do? This point about just there's no roles for you, there's only so much you can do there, is the advice just wait until an opportunity arrives? Is it run this Magic Loop until something happens? Is there anything you can do?

Ethan Evans (00:25:42):
I would be honest with people and say some patience is required. At this level, there is some notion of, do we need a director? Do we need a vice president? Do we have a challenge at that level that needs that person? And so promotions at this level, I often teach have two components. The first component is can I eat and do that job? Am I qualified? Do I have the skills? But the second piece is, do we have such a job that needs that?

(00:26:09):
However, there is a lot you can do. A lot is in your control. And what is in your control is to start practicing those next level skills. Start working with your leadership on, where can I take on a strategic project? How can I become more of an inventor? I teach some about how to sort of systematically be inventive. It's not pure magic. Edison said it's 1% inspiration and 99% perspiration. You can learn the 99%, and the 1% isn't as hard then. So you start showing those next level traits. And as I describe it most succinctly, how do you make yourself the person who will be chosen out of the eight?

(00:26:51):
And you can be chosen, there are several ways to move up. Your boss can leave or be let go. They can be promoted to another role. But another way is I coach now, and I have several clients recently. I was just talking to a client yesterday, her two peers were let go. They were all the same level. Her two peers were let go and she was given their teams. And she expressed that her boss had been told, "You have too many senior managers for the size of your organization. We need to do some change in the organization, clean house, and put all your people under the folks who have potential."

(00:27:32):
Well, obviously she must be one of those people, because she still has her job and has more people and more to do. And unfortunately, her peers are shopping for new employment. So be that person, and that's where The Magic Loop comes in. Be that person.

Lenny (00:27:48):
I was just talking actually to a senior PM leader who pointed out that with this kind of lean environment of a lot of flattening of orgs and a lot of layoffs, that this is becoming increasingly hard. Exactly what you're describing. There's just less spots, because companies are running more lean, and so you just kind of have to wait. 

(00:28:06):
I think part of this advice you just shared, which is classic do the job before you have the job makes all the sense in the world. Because once people see that you can do it, obviously they'll feel a lot more comfortable putting you in that position.

Ethan Evans (00:28:18):
And they'll be looking. I always remind people, as a leader, I want the best people under me I can have. It's not that I don't wish to promote you. If you think about my job, this helps people, right? I have selfish motivation to promote you. A lot of people think, "The bosses there holding me down." Well, maybe some bosses are, but why wouldn't I want stronger, more capable direct reports? Why wouldn't I want people under me who can do more of my job? Frankly, that's the only way I can do less of my job.

Lenny (00:28:47):
Plus this pressure you're always getting from your reports. So like, "Hey, I'm ready to get promoted, because this time"... You mentioned this word inventiveness, and I was just listening to Jeff Bezos on Lex Fridman, and I don't know if you heard this, but Jeff Bezos described himself most as an inventor more than anything else that he does. Is that something that you think about? Is that influenced by Jeff Bezos any way, that idea of being an inventor as a leader?

Ethan Evans (00:29:13):
I'll say a couple things about that. First, I know you talked to my old boss, Bill Carr, who wrote Working Backwards. What I don't know is if he shared with you that after he published it, he actually realized there was a better title. He wishes that he had called the book The Invention Machine, because what Jeff was trying to do with Amazon was create the most inventive company, the company that would systematically out-invent others. And so while Working Backwards is a great title, Bill and Jeff think they should have called it the Invention Machine.

(00:29:47):
When I joined Amazon, I did not think of myself as an inventor, but I saw that we had these leadership principles think big and invent and simplify that pushed on that. And I said, "I'm in trouble. I don't know how to do this." And I sat down and thought about that. What am I going to do? It seems like that's required. And I figured out how to become systematically inventive. So I now hold over 70 patents as one benchmark of inventiveness, and they were all created during my 15 years at Amazon. 

(00:30:22):
And the way I did that, inventiveness actually isn't that hard. I teach about this. And to invent systematically, first you do need to be somewhat of an expert in whatever area you want to invent. So Lenny, if you and I say let's get together and we're going to invent cancer drugs, we have the problem that neither of us, as far as I know is a biologist, a doctor. We don't have the right background, we don't know what we're doing. So we would just be fumbling around I guess with a bathtub full of chemicals hoping. It's probably not going to work out that well. So you have to be something of a knowledgeable expert.

(00:30:56):
But then the second thing people don't do is they don't spend dedicated time actually thinking. They feel like, "Invention is just going to come to me." When I want to invent, I get away from all my devices. I go in a room with the problem I have, and I force myself to actually concentrate on what do I know and how can I invent? And the most straightforward way to invent is not to somehow come up with something completely new, but instead to put together two things that exist. 

(00:31:28):
And so my example of this, I have a patent I talk about a lot for a drone delivery for Amazon, but the drone doesn't fly from the warehouse. Instead, a truck with no top drives slowly around the neighborhood, and the drones go back and forth from the truck. As opposed to the driver stopping at every house, you can have four or six drones hitting everything in the neighborhood. 

(00:31:55):
And the way I came up with this idea is one day I was thinking about drones and delivery, but I loved military history. And so I was thinking also about an aircraft carrier and I was thinking, is there a way to have an aircraft carrier for drones? And from that, it was very quick for the light bulb to go on and say, well, what about a truck? 

(00:32:17):
And so I have this patent, and we haven't seen this become reality yet. I'm waiting for my idea to become part of Amazon's drone delivery system, but I think ultimately it will.

Lenny (00:32:32):
That is badass. I'm imagining returns come back to the truck. We're using that rope thing that just captures them with that little hook.

Ethan Evans (00:32:42):
Yeah. Well, there's no reason... Same thing. When you want to return something as opposed to taking it to the UPS Store or whatever, you just put it on your porch, and then on your phone, on your app, maybe you take a picture of it so that the drone can recognize the box or you put it in a designated spot, and you push a button and the drone takes your return away. Yes, there's no reason.

Lenny (00:33:03):
Can't wait for that. And it takes your dog backs in it sometimes, part of it.

Ethan Evans (00:33:09):
My dog's too heavy, thank you.

Lenny (00:33:11):
My dog's not. There's an owl in our backyard that we sometimes worry he is going to come grab our dog on. This idea of invention, this is really interesting. I didn't plan to talk about this, but for someone like say a PM on a team that wants to get better at invention, innovation, big thinking, is there a practice you find helpful here? Is it block off two hours, get a pen and paper, and just think about the specific two adjacent things working together?

Ethan Evans (00:33:34):
So that's part of the process, is put in dedicated time. The interesting thing I would say is you don't need that much time. Two hours is great, but you only need two hours once a month. People think invention takes all this time. The thing is once you have one good idea, it often takes years to express that.

(00:33:52):
So you had the idea to have a newsletter. I know some of the history of your newsletter. You've been working on the expression of that idea for years now. Jeff and Amazon had ideas like, "Let's have Prime shipping." Well, Prime is still getting better and still being worked on. It's a 20 some year old idea. The Kindle a decade's old idea now still getting better. 

(00:34:16):
So the point here is you don't need very many good ideas to be seen as tremendously inventive. Like Elon Musk, Tesla, he can kind of dust off his hands and be like, "I am now an Edison-like inventor." So he keeps doing it, but you don't need that many inventions.

Lenny (00:34:36):
This touches on something else Jeff Bezos shared on the podcast that most of his innovation and work is in the optimizing phase. It's not the here's the idea, it's the making it cheaper, and better, and faster. And that's where most of the good stuff comes from. In this point of Tesla, Elon had this idea, and now the hard work is actually making it scalable and cheap enough for people to use, not just an electric car.

Ethan Evans (00:34:59):
With the idea of Jeff saying that invention is really a lot of the incremental and optimization, I completely agree with that. To invent well, you need a base idea, but then there's so much of the work is making that idea real.

(00:35:15):
And again, Prime is a great example of this. The Amazon Prime program was a great example of, okay, we want fast free shipping. We want this program. That was a one-time idea that they did build, but now Prime has expanded. First it was two-day in the US, then one-day in the US, now it's same day in the US. But also they added Prime Video, Prime Music, Prime Gaming. There's actually something like 25 things you get free with Prime. Most people have no idea, because you get free photo storage and this ongoing list. And all of that is that incremental optimization to make it better, better, better, better. And of course Jeff's goal, which you probably heard him say, was to make Prime a no-brainer, to where you would be irresponsible really not to be a member.

Lenny (00:36:06):
I know you have an awesome Jeff Bezos story that I want to get to, but before we do that, one more question along this line of career advice and progression. So I read somewhere that you've interviewed over 2,500 people over the course of your career. And so kind of going back to the beginning of a career, or at least getting a job, what have you found is most helpful in standing out as a candidate when you're interviewing, and essentially getting hired? What advice do you have for people that may be going through an interview process right now?

Ethan Evans (00:36:33):
There's a lot of evidence that suggests that the number one and two factors in any interview are appearance and enthusiasm. And it doesn't mean you have to be beautiful, but show up somewhere looking like you're interested in the job, not in your pajamas. And most importantly, be enthusiastic. People want to work with people that want to work with them. So if you seem very judgmental of the company and like you have to sell me on it, you're going to turn them off. I look at every interview of whether or not I really want this job, I might've decided I don't want the job. I still want the offer.

(00:37:10):
And so I come to any interview I do leaned in and talking about how excited I am to be a part of this opportunity and what I know about the company. Beyond those cosmetics, the biggest thing I see particularly at higher levels is people talk about what they have done but not why it mattered. They don't talk about the impact.

(00:37:32):
See, a leader is not hiring someone to just do work. They're hiring someone because they have a problem or a need. And so if you can show them, "Look, here's the things I've done that have made a difference. Here's the things I've done that have helped my past employers where I've had an impact." So I didn't just do work. That makes you a worker. Someone who has an impact is more of a leader.

(00:37:57):
And leader doesn't need to mean people manager, just a higher level, that I have done something that solve the big problem, and here's how it changed the company or customer outlook. That's what I'm looking for in an interview, is are you bringing me an understanding of the business that shows you contributed to the business, or are you just telling me how hard you worked?

Lenny (00:38:19):
Awesome. On that first piece, now that most interviews I imagine over Zoom, in terms of enthusiasm and looking professional, is there anything you've found that people may not be thinking about in those two buckets?

Ethan Evans (00:38:33):
Yeah. Show the person full-time dedication. So unless you really don't have any choice, don't take an interview from a car, don't have your camera off. Eye contact is still a real thing. Body language is still a real thing. Gestures like I'm making now with my hands, they're part of your presentation.

(00:38:53):
So be fully present and try to project through the camera a little bit of I'm excited to be a part of this and I appreciate the opportunity. I often tell people the best way to prep for an interview might be a good night's sleep and a pot of coffee, that being fully engaged and energetic is a huge lever.

Lenny (00:39:18):
Awesome. And I think basically, the feedback there is don't over obsess with the content. There's a lot of value in just how you come across.

Ethan Evans (00:39:27):
Yeah, 100%.

Lenny (00:39:29):
Let me tell you about a product called Arcade. Arcade is an interactive demo platform that enables teams to create polished on-brand demos in minutes. Telling the story of your product is hard, and customers want you to show them your product, not just talk about it or gate it. That's why product four teams such as Atlassian, [inaudible 00:39:49], and Retool use Arcade to tell better stories within their homepages, product change logs, emails, and documentation.

(00:39:56):
But don't just take my word for it. Quantum Metric, the leading digital analytics platform created an interactive product tour library to drive more prospects. With Arcade, they achieved a 2x higher conversion rate for demos and saw five times more engagement than videos. On top of that, they built the demo 10 times faster than before.

(00:40:14):
Creating a product demo has never been easier. With browser-based recording, Arcade is the no-code solution for building personalized demos at scale. Arcade offers product customization options, designer approved editing tools, and rich insights about how your viewers engage every step of the way. Ready to tell more engaging product stories that drive results? Head to arcade.software/lenny and get 50% off your first three months. That's arcade.software/lenny.

(00:40:44):
Now let's take a little trip to failure corner. This is something that I do more and more on this podcast, talk about people's failures in their career and their learnings. And apparently you have a great story of failing the great Jeff Bezos and surviving to tell the tale. Could you share that story?

Ethan Evans (00:41:00):
I do. It's both a highlight and a low light. So I had been at Amazon about six years. I had become a director, and I was responsible for launching Amazon's app store.

(00:41:14):
And so we were building an Android-based app store to go on Google phones and eventually on the Kindle tablets. And we got to launch day. And at that time, Jeff used to write a letter introducing new products. He would write a letter that said, "Dear customers, today Amazon's proud to launch blah blah, blah, and it's got these great features and I hope you really enjoy it. Thanks Jeff." And we would take down all the sales stuff on www.amazon.com and that letter would fill the whole screen. 

(00:41:48):
And so he had written a Jeff letter, and this Jeff letter emphasized a particular feature of our product that he really liked. So that something that made it a little different.

(00:42:00):
And that specific thing was we had a button called test drive that you could click on and it would open the app in a simulator in your web browser, so you could check out the app and interact with it before putting it on your phone. So he thought this was really cool and he was all about it. 

(00:42:19):
Well, my team had built all this technology. We had test drive working. It was kind of a hard piece of technology if you think about simulating any of thousands of arbitrary apps. And we worked all night to launch it, and it wasn't quite working at 6:00 AM. We were still debugging.

(00:42:38):
Now you know engineers very well. And I'm sure most of your listeners know about engineers, even if that's not their discipline. We always think we're this close to finding the last bug. 

(00:42:49):
So about 6:15 AM, I get a message from Jeff that says, "Hey, I woke up, where's the letter?" Because it was supposed to go live at 6:00 AM, right after the markets in New York would've opened at 9:00 AM Eastern. And he says, "Where's the letter?" And I write him back and I say, "Well, we're working on a few problems." And what I'm thinking in my head is, "Get in the shower, get in the shower. I just need 20 minutes, get in the shower."

Lenny (00:43:18):
For Jeff to get in the shower.

Ethan Evans (00:43:20):
Yeah. And 30 seconds later, I have an email back that says, "What problems?" And at this point I have to start explaining, and I end up explaining that we're having a problem with a database, and we're debugging this database problem. And he's like, "Wait, there's a database in your design? We're trying to eliminate all Oracle databases and move to AWS. Why do you even have this?" And he is just getting more and more frustrated and angry.

(00:43:49):
And he starts copying in my boss, and my boss's boss who's with Jeff Wilke, the CEO of retail. And they start asking me questions. And it's just this snowballing, but 7:30 in the morning, Jeff is clearly angry. And there's this list of other people waking up and feeling like, "Well Jeff is angry, so my job is to be even more angry," and it's just raining in on me.

Lenny (00:44:14):
Oh man. 

Ethan Evans (00:44:15):
So what did I do? The interesting thing is what do you do when the future richest man in the world is mad at you? He wasn't quite richest man in the world yet, but he was headed there.

(00:44:26):
So the first thing I did was I owned it. I said, "Yes, it's not working. It's my fault. I will deal with it." I took ownership. And the second thing I did was start updating him very proactively and saying, "Here's where we are." 8:00 AM, "This is exactly where we are. This is what we're going to do and the next hour, and this is when you'll get your next update. I will update you again at 9:00 AM, so here's our plan."

(00:44:55):
And even though Jeff had sort of lost trust in me, like it's down, and it's not right, and I'm mad, given that he agreed with the plan, he was willing to give me 60 minutes. And then I would update him again and say, "Okay, this is what we've done and this is what we're going to do, and we'll update you again at 10:00 AM." So I was buying life one hour at a time.

(00:45:17):
Now the other thing I did, and this is a good thing about Amazon, as more and more leaders got copied into this angry thread, they started reaching out in back channel and saying, "We've all been under Jeff's Eye of Sauron, we know it's miserable. What can we do to help?" And essentially Andy Jassy's organization, which was AWS at that time, and his CTO, a guy named Werner Vogels said, "You're having a database problem, let's get you some principal engineers from the AWS database team." 

(00:45:54):
And these principal engineers showed up at 9:00 AM roughly, and they looked at our design. We had made some fundamental mistakes in our database usage and they said, "It's too complicated to fix this. We're just going to give you 500 AWS machines so that your crappy design will run anyway. That's the immediate fix." And I'm like, "Okay, well I guess if you have 500 databases lying around because you're AWS, it's a great solution," and that's what they did.

(00:46:27):
So the next step is we fixed the problem. A bunch of us worked together very hard to get the problem all fixed. Now it took all day, and Jeff was still frustrated because the opportunity to sort of control the messaging and the media by having his letter up had passed. People had noticed our launch and the articles had been written, and so Jeff was still very mad.

(00:46:52):
So we fixed the problem, but Jeff now had no trust in us. The weekend went by. He was using the system looking for bugs because he is like, "This team's not reliable now. Ethan's not reliable. I better check it myself." So you have the CEO checking on you.

(00:47:11):
And he found a problem and emailed me like Saturday night at 9:00 like, "I was doing this and it broke." And luckily I was able to tell him exactly what happened by 9:30. Anyway, the next part of the story is that following week, I had a meeting with him on another topic.

(00:47:32):
So I was part of this small group that was trying to figure out how to build a competing browser. You may not remember, but Amazon had a browser called Silk for a while. And I was invited to this meeting, but I wasn't a critical participant. So you may know this idea from Scrum where they say some people are pigs and some are chickens, and the chickens are sort of observers. I was a chicken in this meeting, and that turns out to be a great analogy because I was thinking, should I chicken out and not go? I could skip this meeting with the CEO who's angry at me. But when I had that thought, I realized if I can't face the CEO, I'd better pack my desk. That's the end. 

(00:48:13):
So I went to this meeting early, and Jeff always sat in the same chair, so I knew where he would sit when he came in. So I sat down right next to his chair and I thought, "I don't know, let's find out."

(00:48:24):
And so the meeting goes by, and of course in my mind Jeff is totally ignoring me, not even looking at me. But I think that's just me projecting, because remember I wasn't central to the meeting.

(00:48:35):
So at the end of the meeting, everybody gets up to leave. He turns and looks at me and says, "So how are you doing? I bet it's been a hard week." And I thought, "Oh, okay, we're going to talk." And I said, "Yeah," I just sort of answered him with, "Of course it's been hard, but here's what we're doing and here's what we're going to do in the future." And we had a very human conversation. And I didn't believe Jeff would've forgotten that I let him down, but it was clear he had forgiven it. 

(00:49:05):
So I was still going to have to, as it turns out, re-earn his trust. But the thing I did that's key for people to learn from is it's really easy to flame. He had been flaming me, writing angry emails. Angry emails are easy. Sitting three feet from someone and being angry with them face-to-face is hard. And when faced with, I can either start ranting at this person who reports to me, or I can say something nice, he chose to say something nice, and that rebuilt our relationship.

(00:49:42):
So the end of the story is two years later, I was promoted to vice president. So even though I had failed the CEO on this very public launch where he was very definitely mad at me, I re-earned the trust, I showed I had learned the lessons of how to launch more reliably without outages, and I was promoted.

(00:50:07):
And so I share that story because I think what I want people to understand is if I can get away with publicly failing one of the richest and most famous inventors on earth, and then get promoted and finish my career at Amazon very successfully, you can dig out of any hole. You just have to manage it right.

Lenny (00:50:30):
That is an amazing story. So there's a lot of lessons that I want to pull on here. One is just if you get caught in a situation like this where something completely fails, what I took down as you were talking, one is admit, yes, this is a huge problem, own it. This is like, don't try to deflect.

(00:50:47):
Two is the way I describe what you did here, is something I call prioritizing and communicating, where you prioritize, "Here's what we need to do," and then communicate. "Here's our priorities." And I love that you have this every hour, "Here's the latest, here's the latest." So make people understand you are on it and you'll continue to keep them updated. I imagine one of the worst fears is I have no idea what's happening here. I'm going to go in and start micromanaging.

Ethan Evans (00:51:11):
You're exactly right. I'm trying to hold off micromanagement. I'm trying to give them, "Okay, I believe with this and I can wait an hour," and then I can wait an another hour because that team seems to be on it. So I'm trying to rebuild trust one hour at a time, and avoid having three or four levels of management all come in and start helping.

Lenny (00:51:31):
Then I love this other piece of advice of meet them in person, try to take it offline essentially, which I know you did later. But that's such a good point that it's hard to be as mad, and angry, and flamey in person. People are just going to be like, "Okay, I get it. Let's try to figure this out." Amazing. Is there anything else? Those are the three that I took away. Just like if you're caught in that situation in the moment, is there anything else that you found to be really helpful?

Ethan Evans (00:51:55):
I mean, work hard and fast, right? You do have to fix the problem. My team had been up all night. I had to start sending people home to sleep in shifts. We had to pull in all this help. And so it was a very hard weekend.

(00:52:10):
When you have a mistake, it's on you to pull out the stops, even if it's uncomfortable to recover from it. And again, this is not the time to be like, "Well, it's the weekend now, and my team, we'll hit it Monday." I'd have been out the door so fast, I would've had the comic Wile E. Coyote skid marks as I bumped down the street. So I would say that's important. It's part of showing ownership.

Lenny (00:52:39):
The other part of this is something I went through for a while when I was starting to become a more senior leader is I had a lot of imposter syndrome, and this fear that if I messed up, everything would crumble. People would see that I don't actually know what I'm doing, and I'm not really ready for this level of seniority. And so there's this fear of one big mistake, it's over. Clearly this was an example of a huge mistake and it was not over for you. Is there any lessons there that you take away of you can mess up and still do well, even if it's this level of mistake?

Ethan Evans (00:53:11):
I think a lot of people in my position would've quit. They would've let the shame... I was just a little bit bullheaded where I'm like, "Yeah, I messed up. But I know I'm still a good person and a good worker. Yes, I made a mistake, but I'm going to move on." Part of the story I haven't told that you might enjoy is I mentioned that Jeff Wilke was Jeff's number two at that point. Jeff Bezos, number two person, and he was my skip level. 

(00:53:38):
Well, during this process, he came physically into our offices and he wanted to talk to me, and my manager who was vice president said, "Hey Jeff, this is my team. I own it. If you have any criticism, say it to me. You don't mean to talk to my team." And Jeff Wilke said to my boss, whose name was Paul, "Paul, that's excellent leadership. I really appreciate what you're doing. Please step out of the way. I want to talk to Ethan. You're doing a great job, Paul. Now step aside." And then he kind of read me the riot act.

(00:54:15):
And the rest of that funny story is I was so happy with how well my meeting with Jeff Bezos went, I patted myself on the back and like, "I'm going to go face Jeff Wilke now. I'm going to schedule a meeting with him and do the same thing. I've got this down."

(00:54:31):
So I go to meet with Jeff Wilke, figuring I'm going to run the same playbook. I'm going to look him in the eye and all will be forgiven. And Jeff Wilke looks at me and says, "Ethan, when you launched this, did you know you were gambling with the result? Did you know it might not work?" And I said, "Yes. We had a media commitment to launch on that day, and I thought shooting for the date was more important than perfect certainty."

(00:54:55):
And he said, "Well, two things. First, you were wrong. You were wrong to prioritize date over our reputation. You let Amazon down in public and that was a mistake." He said, "Second though, at least you knew you were gambling. If you hadn't known you were gambling, we'd be discussing your departure." And I'm like, "Okay." Here I thought I was rolling in this meeting like I'm going to run my relationship playbook. And he's evaluating whether or not to keep me.

(00:55:25):
The bullheadedness is even after he had told me he had been considering firing me, I'm like, "Well he isn't. So I'm just going to go forward." And a lot of that stubbornness of sure I made a mistake, but I'm not going to live in shame about it, I think is what people can take away. I think a lot of people feel they're more dead in the water than they are. 

(00:55:53):
Because everybody makes mistakes, right? I mean Jeff and Fire Phone, that'll be an albatross around his neck. Jeff and Fire Phone will be a phrase of anybody who knows Amazon for the rest of his life.

Lenny (00:56:08):
Yeah, we talked about it on the Working Backwards podcast, and why didn't Working Backwards work for the Fire Phone, we talked about it. I love that these quotes and lines are so seared in your brain. You can remember it like word for word exactly what-

Ethan Evans (00:56:20):
Well, I've relived that moment many times.

Lenny (00:56:26):
And then just along the lines of working your way out of the hole, is essentially what you did just succeed for two years and do great, and that was the key there?

Ethan Evans (00:56:34):
No, I think I did have to learn. I've always been sort of an operational cowboy, meaning I like to go fast and loose. I prioritize speed, and I really had to step back and say, "Okay, Amazon at this level and scale doesn't like that." So I've taught myself a new phrase which was fear the New York Times headline. Be aware that if Amazon is down, it goes up on every news website immediately. And so if Amazon has some kind of mistake, it's on Wall Street Journal and CNN.

(00:57:07):
And so as a leader, I had to think, is what I'm doing going to generate a New York Times headline? Because if it is, I'd better be really careful. And that's what I taught myself is you can't be paralyzed, but I taught my whole team, we don't want to be in the New York Times for the wrong thing. And that was the lesson

Lenny (00:57:32):
Along the lines of lessons, last question here, what's something that you took away from the way you approached it that you should have changed or should have done differently, that you've done differently since? Obviously don't... You mentioned this idea of don't promise a date that you're not that certain you're going to hit. I guess is there anything along those lines?

Ethan Evans (00:57:52):
I have two things here. First, Amazon loved in the past, they loved surprise launches. They love the idea of we're going to be quiet, quiet, quiet. Because basically it was a reaction I think to Microsoft where they felt Microsoft always talked about what was coming and then pushed the dates back. And so there was this whole thing about vaporware. And Amazon wanted to be the other way, which is we won't say anything and then it will just be there. The problem I came to say is the biggest thing I learned with surprise launches is that you're surprised by what doesn't work. 

(00:58:23):
And so I shifted the approach to let's do a lot of beta testing. We always, even if others don't agree quite and say, "You're right, we're not going to have a surprise launch." Some of our beta testers, even if they sign NDAs are going to leak. And that's a better outcome than launching something that doesn't work. That's one lesson.

(00:58:46):
The other lesson is this thing that broke in front of Jeff Bezos, ultimately it was a new college graduate engineer who wrote that code. And he had been left alone to write part of our user interface, but he had written it in such a way that it didn't scale. Now we didn't give him any help or oversight. We left him on his own, because we were busy focusing on other pieces of the problem.

(00:59:20):
And shortly after the disaster, he left the company. And the mistake I made was not reaching out to him and really reassuring him of, "Yes, you wrote the bug, but that's not on you. The system failed you and we don't see you. Bugs happen."

(00:59:38):
So the thing I regret in this whole thing is not realizing that even though no one in the team ever yelled at him or whatever, he knew it was his bug, and he obviously saw me and others sort of taking a beating. And so he left, and I wish he hadn't done that. And I wish more than that I had stepped in. I didn't realize what he was feeling.

Lenny (01:00:05):
It's interesting, the lesson there isn't catch that person sooner, and notice these links in the chain that may break. But it's more just be there for that human that have this challenge, that people may not be focusing on.

Ethan Evans (01:00:19):
Because we lost a good person, and he probably felt very bad about it. And we all feel bad when we make mistakes. That can't be prevented. But he felt undue responsibility I think, and that I really regret.

Lenny (01:00:35):
This is actually a really good example of ownership. You mentioned this term ownership and that connects to... Amazon has these leadership principles. I think there's 14 of them. One of them is around ownership. And apparently you helped craft the actual language for that principle, which I think is a huge deal with Amazon. I imagine very few people have a say over how to define, and describe, and say these principles. Could you just talk about this principle that you contributed to, how it came to be that you helped actually write it?

Ethan Evans (01:01:08):
Amazon is now kind of on its fourth version in my mind, maybe there's more. But its fourth major revision of its leadership principles over its 25 plus year history.

(01:01:18):
And when it was going from version one to version two, Jeff and his leadership team sat down together. And actually in version one, there were three different lists. They were leadership principles and core values, and something else I don't remember. And they were like, "Three lists is stupid. Let's make one list."

(01:01:36):
Well ownership, the term had been a part of one of those lists, but when they merged everything, they took it out. And this guy Jeff Wilke I mentioned, the number two and the leader of retail, he brought a bunch of us a bunch of his directors. He brought the proposed list to us in a meeting and said, "Hey, this is the proposed new version, do you have any comment?" And we all sat around and talked and said, "Where's ownership? Ownership is missing." So we told him, he said, "Look, ownership is missing. We think it should be there." And he said, "Well, why don't you propose a draft?"

(01:02:15):
And so about a half dozen of us sat around and roughed out a draft of how we felt ownership should be written. And I proposed these six words, which are, "An owner never says that's not my job." Maybe that's seven words.

(01:02:36):
So I propose this specific language as a part of it and we sent off this draft. And months go by, we hear nothing. And then one day the leadership principles are announced and ownership is back in. It's been modified, but that, "An owner never says that's not my job," is a part of the leadership principle, and it's remained to this debt. 

(01:02:58):
And what I love about that is because Amazon has one and a half million employees who live by these leadership principles, it's probably the most impactful thing I've ever written.

Lenny (01:03:11):
Wow. So those seven words are the most impactful thing you've ever written. I love that and I totally get that. I'm looking at the principles right now and it comes right at the end of that principle. We'll link to the 14 leadership principles. Is there another principle that you really love or one or two? I don't know. It's probably hard to pick your favorites.

Ethan Evans (01:03:28):
I'm a huge proponent of bias for action. Bias for action says speed matters in business and many decisions are reversible. And so it's important to go faster. 

(01:03:41):
And I think people don't understand that in a competitive environment, being right is good, but being quick is necessary. Because if there are 10 startups working on an idea, some of them will gamble, and they'll make bad gambles, and they'll go out of business. But some of them will gamble and make an early bet and be right. And if you are not moving quickly, you'll be beaten by the people who maybe got lucky. 

(01:04:05):
And so you've got to have a process that values speed, values, what can we do today? What can we commit to today? So I really like bias for action. Now that is what got me in trouble with Jeff, right? I was willing to gamble. So it has to be in balance, but that's my other favorite.

Lenny (01:04:25):
Again, the Jeff Bezos interview with Lex Fridman, he was talking about how with Blue Origin, with the way Amazon, he thought about Amazon is customer obsession. That was the core goal and differentiator of Amazon. With Blue Origin, he wants it to be decisiveness. It's basically leaning into this bias for action fully, which is really interesting.

Ethan Evans (01:04:44):
I saw that part of the interview and I thought, "Wow, that's exactly right." Because again, rockets blow up and they have people on them. You've got to get it right, but you also have to keep moving, because there's always one more thing you can safety test. So how do you balance it?

Lenny (01:05:04):
Yeah, it's interesting. With rockets, that's the one that you pick. It's pretty bold to be all move forward kind of thing. So this principle, again, going back to ownership, so you basically suggested this phrase, "You didn't hear anything," and all of a sudden it becomes part of the whole thing. Did that feel weird that they never told you, or I don't know if they gave you credit for that, or it's like, no, it's great?

Ethan Evans (01:05:24):
Yeah, I wouldn't even claim credit for it, except I kept a copy of the email that says, "Ethan thinks it should say blah." I have the written proof. Because it's not about the credit. I'm very happy and proud that those words were kept. But in Amazon, I doubt if Jeff knows I wrote those words. It's not like I've ever told him, "Hey, do you know you kept my words?" That's not appropriate. It's just a fun anecdote.

(01:05:55):
And it does show, I guess something people can learn from that though, you can influence way up in a company if your ideas are good. And also, when we challenged, Jeff Wilke was a strong opinionated leader who didn't necessarily always love being challenged.

(01:06:15):
And so when we first told him, "Well, we think you're missing ownership," he was like, "You're staying that the whole S team can't get its leadership principles right?" I mean it wasn't exactly that way, but he was very much like, "Well, is this really necessary? Why do you think it's necessary?" And his challenge to us to write it was kind of framed as, "Well if you're so sure it's good, show us." But again, I'm stubborn and I'm like, "All right, let's write it." And we did.

Lenny (01:06:47):
That's funny. That's not a great example of leadership where he is like, "Hey guys, I need your feedback on this thing. But no, don't actually tell me anything's wrong."

Ethan Evans (01:06:57):
Well, yeah. I mean for a bunch of directors to kind of critique the work of people two levels higher, he wanted it, but then he's sort of naturally resistant to it if we're kind of poking at his baby.

Lenny (01:07:14):
It's unlikely that there's something huge missing and it turns out there was.

Ethan Evans (01:07:18):
Yeah.

Lenny (01:07:19):
And I guess just on these principles, people may not know this, but this is where disagree and commit comes from. It's actually have backbone, disagree, and commit. We talked about this on the podcast about working backwards. I also love leaders are right a lot. That comes up a lot and I love that, to be successful, you need to be right. You can't just project confidence. You can't just be in a bunch of meetings and ship things. You need to be right to be successful.

Ethan Evans (01:07:42):
And that one's been rewritten to carefully say, it's always interesting what is the history of the edits, which you wish you could see the edit history on these. That one got modified to say something about leaders actively work to disconfirm their beliefs.

(01:07:58):
And the key there is it was trying to get at the idea that you've got to be very open and always be questioning, "Yes, I think I'm right, but what's the new evidence? What am I learning? What's changing?" And in fact, it also says they seek diverse perspectives.

(01:08:20):
And that was a way of getting at what's called DEI, diversity, equity, and inclusion. That's a subtle nod towards if everyone in the room is a 50-year-old white man, you may not really be making the right overall decision for Amazon's customer base. You may be making the one for 50-year-old white suburban Seattleites. And so it's just some of these, every word in those has been studied as an individual word inside the company.

Lenny (01:08:52):
Amazing. Okay. Let's move on to the final area I wanted to spend a little time on, and this is called contrarian corner. I'm curious if you have any contrarian opinions about things basically that other people believe that you don't believe, something you see that many people don't see. Is there anything that comes to mind?

Ethan Evans (01:09:11):
Yeah, I think a place where I'm currently very contrarian is the return to office movement. Many leaders at my level appear or publicly favor the need to get back into the office potentially full-time. 

(01:09:27):
And I'm contrarian on this because of innovation. Specifically, I looked it up, you can check my facts on Wikipedia. The first purpose-built office, the first building ever built to be an office was built in 1726 in London. And so we're about 300 years into learning how to use offices well.

(01:09:51):
And what that means is offices aren't going to get much better. What's the last major thing you can think of that got better in offices? You might say well open offices, but a lot of people would say that's not even a good idea. These big rows of desks and loud pits.

(01:10:06):
With working from home, we've only been doing that for a few years since the pandemic began and at all since the internet started 20 years ago. Which one is likely to have more opportunity for improvement? There's so many things we haven't explored with remote work. And I think the people who say, "Back to the office, it's because we know it works," well we know what it is, but I have so much more faith in the opportunity to improve the remote experience. And so I think long-term, it's going to triumph.

(01:10:40):
The one other place where I'm a huge contrarian is doing business on a handshake. I understand companies need lawyers, and I have an attorney for certain things. But I coach people. Most of the people I coach, there's no NDA in place. There's no contract in place. They pay me through PayPal and I do good coaching for them.

(01:11:01):
I think too much of the world is contract driven, and we've lost the idea of your word being your bond, and you can actually trust me to follow through on my commitments. And I'm a contrarian there.

(01:11:14):
I realize I will occasionally get burnt. Someone will behave in a way, they'll let me down. But I think when we're always suspicious of people, that's a high cost. And the other place I'm contrarian is just doing business on faith.

Lenny (01:11:32):
That reminds me, Sam Altman has a similar philosophy of just trust people and assume it'll all be okay. Sometimes you'll get burned, but on balance, it'll end up being much better for you and for everyone around you. 

Ethan Evans (01:11:42):
I didn't know that Sam had said that, but I strongly agree with it.

Lenny (01:11:45):
Yeah, although he had some challenges recently. I don't know if it's working great, but it ended upgrade for him. So anyway, okay. We've actually reached our very exciting lightning round. Before we get there, is there anything else you wanted to touch on, or share, or leave listeners with?

Ethan Evans (01:12:01):
No, I've really enjoyed this conversation. I could talk about careers forever and I love doing that, but I think we've covered a ton today that will really help people. So I'm good. Let's hit the lightning round.

Lenny (01:12:14):
All right. With that, we reached our very exciting lightning round. Are you ready?

Ethan Evans (01:12:19):
I'm ready.

Lenny (01:12:20):
Ethan, what are two or three books that you've recommended most to other people?

Ethan Evans (01:12:25):
Two or three books. My number one recommendation is a book called Decisive. It's by Chip and Dan Heath, and it's about the science of making better decisions. The reason I recommend it so much is it will make your career better because leaders are decision makers, but also your personal life. So I apply it at least as much in my personal life as I do in my professional life. 

(01:12:47):
My second most recommended book is Leadership and Self Deception, much less known than Decisive, a little bit harder to approach. It's by a group, a research group called the Arbinger Institute, and it's about, the self-deception is we cause a lot of our interpersonal problems while blaming them on others. And it walks through how are you part of the problem you're having with somebody else and what can you do about it?

(01:13:14):
The third and final book was recently brought to me by someone I work with that you know, Jason [inaudible 01:13:21]. That book is The Almanack Of Naval Ravikant. And Naval Ravikant is an angel investor responsible for AngelList. 

(01:13:30):
But what I love about that book is he has a recipe. He really boils down how to be successful while loving what you do. And he says, "No one can be a better version of you." Don't try to copy me and be, "I'm going to be like Ethan, or I'm going to be like Lenny." Instead, figure out what you uniquely do best that you love, because no one can copy you being you. And that's your defensible sort of career value. And I really like that mental model.

Lenny (01:14:03):
Yeah, Naval has so many insightful messages, and you can read all these on his Twitter. We'll link to his Twitter, and someone just made a book out of his tweets basically. He's such an interesting dude.

Ethan Evans (01:14:13):
Yes, that's right.

Lenny (01:14:14):
Awesome. What is a favorite recent movie or TV show you've really enjoyed?

Ethan Evans (01:14:19):
So I grew up on a farm, and so all the Taylor Sheridan, 1923, and Yellowstone, and all of those series, we've watched everything he's put out. We do kind of laugh like, wow. Are you familiar with Yellowstone at all?

Lenny (01:14:37):
Absolutely. A lot of death.

Ethan Evans (01:14:39):
Yeah. At one point my wife and I were watching it, we would start betting. So the episode is starting, how many people will die in this episode? This ranch in Montana, but yet somehow they're always killing people. How does this work?

Lenny (01:14:55):
That's what your life was like, is what I'm hearing. Favorite interview question that you like to ask candidates?

Ethan Evans (01:15:03):
I think my favorite interview question is, "Tell me about a time where you needed to disagree with your management, where you needed to stand up or fight for a position against higher leadership or people in power." Because I think that's really hard to do. I'm normally interviewing leaders, and I think having a bunch of people who just say yes isn't helpful. You need people to have, as you said, have backbone, disagree and commit. So that's what I'm normally looking for.

Lenny (01:15:33):
Awesome. Is there favorite product you've recently discovered that you really love?

Ethan Evans (01:15:38):
It's silly, but my favorite product that I've discovered recently is the Chuckit!, which you use to whip a ball for your dog a quarter mile. It basically extends your arm. And it's just fun to send a ball soaring way further than you could ever throw it. And you feel like, "Wow, look at me. I'm a major league pitcher." Because I have this three foot lever arm and I understand physics. If we look at tech products, there's so many I love. It's too easy to say ChatGPT and stuff, so I won't go there.

Lenny (01:16:16):
Awesome. My dog does not love chasing balls, so I haven't had a reason to buy that, but I've never thought about just the joy of flicking a ball really far. Do you have a favorite life motto that you often come back to, share with folks, find useful in work or in life?

Ethan Evans (01:16:31):
I happen to be a Christian, and the motto that I think about the most is, "To whom much has been given, from him much will be required." And so I think a lot about what is my social responsibility. 

(01:16:44):
I've been very lucky. I grew up on a farm in Ohio now. I wasn't a farm boy, my father was a chemist. But I grew up in upper middle class settings, and I've ended up being extremely successful, able to retire from my job at 50 to kind of coach and teach. What do I owe to pay forward? So those words are obviously ancient spiritual texts, but they're the ones I take away and think the most about. What's my responsibility?

Lenny (01:17:11):
As an example of someone that to whom much has been given, but because he's worked so hard, Jeff Bezos is starting a space business as you know. If you had the chance to go to space, would you go?

Ethan Evans (01:17:22):
Well, I of course saw his interview where he talked about how he thought about the safety and the conversation he had to have with his mother. I would like to go to space. I'm not willing to pay what I think the current tickets are, but I would take the risk. So what's the risk of that ride? One in a hundred, one in 50, even more that you won't come back. I would probably take the gamble.

Lenny (01:17:46):
So you'd be an early adopter? Where along that curve would you be, an early adopter, laggard?

Ethan Evans (01:17:50):
Well, I'm old enough that I remember when the Challenger space shuttle exploded, and I said I would get on the next one and I said, "They're never going to be more careful than the next one, so I'll get on the next one."

(01:18:04):
So I think I would get on any one I was offered because of the chance. Unlike Jeff who claims he wasn't scared, I would probably be really terrified, at least at liftoff. While you're up there, it's great. Everything either goes wrong going up or coming down. It's not the middle.

Lenny (01:18:25):
Ethan, I think we're going to help a lot of people with their career. I think we're going to help them work through failure, become better owners. Thank you so much for being here. Two final questions. Where can folks find you online if they want to reach out? Also, just share what you do now in case people could use that help. And then how can listeners useful to you?

Ethan Evans (01:18:42):
So the best place to find me online, I do all my writing on LinkedIn. It's where the professional community is. So Ethan Evans on LinkedIn. My actual handle there is Ethan Evans VP for my history as a vice president. That's the best place to find me. I do have a Substack newsletter. I do teach through the Maven platform, but all of those are linked off LinkedIn.

(01:19:02):
And really, how readers help me, they comment on what I write, because I miss things. I am one person's perspective. And so I actually have a process where I take in all the comments people write, all the different perspectives, all the different exceptions, or special cases, or examples, and that's how I improve my own thinking is I read every comment and think, "Okay, what did I miss? What could I have said better? How can I incorporate this if I ever talk about this again?"

Lenny (01:19:31):
Just to give you another opportunity to plug the stuff you do now, what do you help people with in case people could value could you use the stuff that you offer? You said you coach, you have a course. What sort of stuff?

Ethan Evans (01:19:40):
I focus on two topics, career development. So how do you row in your career, the whole Magic Loop, and how do you attain promotion or attain a new role raise if that's your goal? And then leadership specifically. I teach a course that's been very popular called Stuck at Senior Manager - Breaking Through To Executive, which is how to get out of that sort of stuck, "I'm working really hard, I'm pretty good. I'm managing 25 or 50 people, but how do I get to the big chair? How do I get to the division level leadership and what do I need to change?" It's that whole what got you here won't get you there. And I love to see people succeed at that. People write me back and say, "I did get a job. I did get promoted, I did get a raise," and that's my fulfillment.

Lenny (01:20:25):
Amazing. Ethan, thank you so much for being here.

Ethan Evans (01:20:29):
Thank you, Lenny. And I got to say, you are very good at this. You're so smooth and you just do a great job interviewing. It's been really been a pleasure.

Lenny (01:20:37):
I really appreciate that, and so are you. Thank you. Bye everyone.

Ethan Evans (01:20:42):
Bye everyone.

Lenny (01:20:44):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review, as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Taking control of your career | Ethan Evans (Amazon)
**Guest:** Ethan Evans 2.0  
**Published:** 2024-01-14  
**YouTube:** https://www.youtube.com/watch?v=GB0P0_nFPTA  
**Tags:** growth, analytics, conversion, hiring, leadership, management, vision, market, persona, design  

# Taking control of your career | Ethan Evans (Amazon)

## Transcript

Ethan Evans (00:00:00):
People think invention takes all this time, but you only need two hours once a month. The thing is, once you have one good idea, it often takes years to express that.

(00:00:09):
So you had the idea to have a newsletter. I know some of the history of your newsletter. You've been working on the expression of that idea for years now. Jeff and Amazon had ideas like, "Let's have Prime shipping." Prime is still getting better and still being worked on. It's a 20 some year old idea. The Kindle, a decades old idea now still getting better. The point here is you don't need very many good ideas to be seen as tremendously inventive.

Lenny (00:00:38):
Today my guest is Ethan Evans. Ethan is a former vice president at Amazon, executive coach, and course creator focused on helping leaders grow into executives. Ethan spent 15 years at Amazon, helped invent and run Prime Video, the Amazon Appstore, Prime Gaming, and Twitch Commerce, which alone is a billion-dollar business for Amazon. He led global teams of over 800, helped draft one of Amazon's 14 core leadership principles, holds over 70 patents, and currently spends his time executive coaching and running courses to help people advance in their career, build leadership skills, and succeed in senior roles.

(00:01:14):
In our conversation, Ethan shares an amazing story of when he failed on an important project for Jeff Bezos and what he learned from that experience. We spent some time on something called The Magic Loop, which is a very simple idea that I guarantee will help you get promoted and advance in your career. We also get into a bunch of other career advice, primarily for senior ICs, any managers. We get into advice for standing out in interviews, plus some of Amazon's most important and impactful leadership principles and much more. I learned a lot from Ethan and I'm excited to bring you this episode. With that, I bring you Ethan Evans after a short word from our sponsors. 

(00:01:50):
Let me tell you about our product called Sidebar. The best way to level up your career is to surround yourself with extraordinary peers. This gives you more than a leg up. It gives you a leap forward. This worked really well for me in my career and this is the Sidebar ethos. When you have a trusted group of peers, you can discuss challenges you're having, get career advice, and just gut check how you're thinking about your work, your career, and your life. This was a big trajectory changer for me, but it's hard to build this trusted group of peers. 

(00:02:20):
Sidebar is a private, highly vetted leadership program, where senior leaders are matched with peer groups to lean on for unbiased opinions, diverse perspectives, and raw feedback. Guided by world-class programming and facilitation, Sidebar enables you to get focused tactical feedback at every step of your career journey. 

(00:02:39):
If you're a listener of this podcast, you're already committed to growth. Sidebar is the missing piece that catalyze your career. 93% of members a sidebar helped them achieve a significant positive change in their career. Why spend a decade finding your people when you can meet them at Sidebar today? Join thousands of top senior leaders who have taken the first step to career growth from companies like Microsoft, Amazon, and Meta, by visiting sidebar.com/lenny. That's sidebar.com/lenny. 

(00:03:12):
Let me tell you about a product called Sprig. Next gen Product teams like Figma and Notion rely on Sprig to build products that people love. Sprig is an AI powered platform that enables you to collect relevant product experience insights from the right users so you can make product decisions quickly and confidently.

(00:03:32):
Here's how it works. It all starts with Sprig's precise targeting, which allows you to trigger in-app studies based on users' characteristics and actions taken in product. Then Sprig's AI is layered on top of all studies to instantly surface your product's biggest learnings. Sprig's surveys enables you to target specific users to get relevant and timely feedback. Sprig replays enables you to capture targeted session clips to see your product experience firsthand. 

(00:03:58):
Sprig's AI is a game changer for product teams. They're the only platform with product level AI, meaning it analyzes data across all of your studies to centralize the most important product opportunities, trends, and correlations in one real-time feed. Visit sprig.com/lenny to learn more and get 10% off. That's sprig.com/lenny. 

(00:04:26):
Ethan, thank you so much for being here and welcome to the podcast.

Ethan Evans (00:04:30):
Lenny, thank you a ton for having me. I'm super excited to talk about some of the things we have teed up today and to help people.

Lenny (00:04:37):
The first thing I thought we could chat about is The Magic Loop. So you wrote this guest post from my newsletter sometime earlier this year. It is, I don't know if you know this, but it's currently the sixth most popular post of all time on my newsletter across 300 plus posts. Did you expect this advice to resonate the way that it did, and why do you think it resonated as much as it did?

Ethan Evans (00:04:59):
So the competitive part of me really wants to analyze spots one to five and figure out, do they have an unfair advantage that they had more time? But I was very hopeful that the advice would resonate that way, because I put a lot of work into simplifying it and making it really easy to understand and follow. So I'm very pleased it has, but I was hopeful it would do so well.

Lenny (00:05:24):
Well, I will say sometimes they keep growing, so this isn't necessarily the terminal point for the post.

Ethan Evans (00:05:28):
The final position. Yeah.

Lenny (00:05:30):
Okay. So for people that haven't read this post, or maybe for folks that have and maybe could use a refresher, let's spend a little time here. Could you just briefly describe this idea of The Magic Loop that you wrote about?

Ethan Evans (00:05:40):
Yeah, absolutely. So The Magic Loop is how to grow your career in almost any circumstance, even with a somewhat difficult manager. It does assume that you're working in some environment, normally as an entrepreneur or with a boss. But the basic idea of The Magic Loop is five steps and they're very easy.

(00:06:01):
The first one is you have to be doing your current job well. It's not possible to really grow your career if you're not considered at least performing at a solid level. Now, it doesn't mean you have to be the star on the team at this point, but what you can't have is your boss wishing that you were different. Like, "Ethan's not very good." So you have to talk to your manager and find out how you're doing and address any problems. So step one is do your job well.

(00:06:31):
Then step two is ask your boss how you can help. Speaking as a manager, and I've talked to hundreds of managers, very few people go and ask their manager, "What can I do to help you? What do you need?" And so just asking sets you apart, and it begins to build a relationship that we're on the same team, that I'm here as a part of your organization to make you successful, not just myself. 

(00:06:53):
Step three is whatever they say, do it. So you dig a big hole. If you say, "What could I do to help you?" And they say, "Well, we really need someone to take out the tray sheets day," and you're like, "Oh, I didn't mean that. I wanted exciting work. I don't want to do sort of this maintenance work or whatever." So do what they ask, help out even if it's not your favorite work. 

(00:07:14):
Once you've done that though, and maybe you do that a couple times, the fourth step is where the magic comes in. You go back to your manager and say, "Hey, I'm really enjoying working with you. I'm wondering is there some way I could help you that would also help me reach my goal?" And whether that goal is to change roles or get a raise or get a promotion, you say, "My goal is I'd really like to learn this new skill. Is there something you need that would also help me learn this new skill?" And the reason this works is managers help those who help them. It's just human nature. We all do that.

(00:07:52):
Generally, they're very open to meeting you halfway and saying, "Sure, I need this. We can rearrange it. We can find a way to meet your goals over time." Now for step four to work, you do have to know what is your goal, so you have to be clear on what it is you want. Well, that part's up to you. 

(00:08:15):
And then step five is the easiest step of all. It's just repeat. So like lather, rinse, repeat with your shampoo. Step five is once you're working with your manager towards your goal and discussing where you're going, and you're helping each other, the magic of the loop is just go around and around.

Lenny (00:08:31):
I was going to ask you, why is it that you call it The Magic Loop? Also, we kind of dived right in, but what is the goal of this? I guess it's pretty clear maybe at this point of this helps you advance in your career, but whatever you want to share along those lines.

Ethan Evans (00:08:43):
Yeah, okay. Very fair. So I called it The Magic Loop because I pioneered it with my audience a few years ago. And it works so well, that people were writing back in and saying, "How do I turn this off? I'm in over my head now. My boss has asked me to do all these cool things, and I feel like I can't catch up, and I've already been promoted once and I need time to digest it." And it just seemed like it worked like magic. It worked in almost every circumstance. 

(00:09:15):
There are of course exceptions where you have very exploitative managers who are like, "Oh, it's great. You're working harder, keep doing that, and they won't do anything for you." But those are rare. And then the purpose, yeah, to help you get satisfaction in your career. A lot of people are unhappy with their jobs. Many people want to move up a level or get paid more. Not everyone. Some people want to change what they're doing, they're bored. This is a path to all of that, because it's forming a partnership with your leadership to say, "Look, I'll help you, but I need you also to help me." And most good managers are very open to that.

Lenny (00:09:52):
When we were working on this, one of the pieces of feedback I had was I feel like I could just tell my manager, "Hey, I want to grow my career. What can we work on to help me get there?" And your feedback was like, most managers are not that good and not that thoughtful about their employee's careers. Can you just talk a little bit about that? People may be hearing this and be like, "Why do I need to do this? This seems like a lot of work."

Ethan Evans (00:10:15):
If you have a great manager, you may not need to do nearly as much formality. They may have given you good feedback, so you don't need to ask for feedback. They may have offered you opportunities to step up, and you've said yes to some and maybe no to others. That's fantastic. I designed The Magic Loop for the people who either don't know what to do or their manager is either not that good or just very busy.

(00:10:37):
Remember, lots of managers have great intentions to help their employees, but they get busy with their own lives, their own work, all the things they're focused on, even also their own career. The manager is often busy thinking about their own needs, and so they mean to get to you next week, and next week drifts on for a year.

Lenny (00:11:00):
What has come up since this has come out that you would want to either add to, or tweak, or help people better understand? I imagine there's some criticism. I imagine there's a lot of, "Yes, yes, yes. This really works."

Ethan Evans (00:11:12):
Two things I'd love to clarify. The first is many people ask me, "Why do I have to do this? Shouldn't my manager notice what I'm doing? Shouldn't my manager help with my career? Shouldn't my manager be planning for me?" And what I say about that is what your manager should do and $4 will get you a cup of coffee at Starbucks. 

(00:11:36):
The point of this loop is it's in your control. It is true that a good manager would do all those things I just mentioned, but not all managers are good and some of them need some help. And the thing I would just say about The Magic Loop is it's in your control.

(00:11:52):
And so you can be upset that your manager isn't perfect, but move on from that and take control of your own situation. That's the first thing I'd say. The other big extension I would make is look, if you are a manager or a leader of any type, you can initiate The Magic Loop from your side, so you can talk to your employees and say, "Hey, what are your career goals? Would you like to form a partnership where you step up to new challenges and I help you get to your goals?"

(00:12:26):
I had a lot of success forming this kind of partnership with my employees, where as they saw growth and success, they really leaned in and like, "This system works. You're actually investing in me now. I'll work extra hard." And I'm like, "Yes, and we can grow your team or grow your opportunity," and it was very win-win.

Lenny (00:12:46):
To give people a little bit of social proof, you mentioned some of the folks you've worked with on this. Can you share some stories, or stats, or anything to help people understand how helpful this ended up being to folks you've worked with?

Ethan Evans (00:12:58):
Yeah, absolutely. I'll tell one story from each end of the spectrum. And what I mean there is entry-level people and then high level executive leaders. I had an entry-level person write me back and say, "Look, when I learned about The Magic Loop, I was at a company and not doing very well. I started applying it. They offered me a $30,000 raise and a bigger job. And I turned it down because I got hired at this other company that was offering me even more, and I went there. And they've promoted me also," and he was one of the people who wrote in and said, his exact words were, "A year ago I was made redundant." So he is in the UK, redundant is their word for laid off. "A year ago I was made redundant. I got this first job and I got an offer for an increased salary, and then I got the second job and I got an increase when I joined that was even bigger." And he was in that situation of, "Mow I need to sort of slow down and digest all of that."

(00:14:05):
On the complete other end, one of my best people I ever worked with joined my team at Amazon as what we would call an SDE II, which in Amazon is a level five employee. He grew with me kind of following this process to a senior engineer. Then he switched to management and ran a small team. Then he became a senior manager and he relocated with my organization. He opened a new office in another city, was eventually promoted to director running his own office of a couple hundred people. And this was over the course of about eight years. He went from a mid-level engineer to an executive with a team of 800 people. Now he was a very hard worker, but over this eight years we just saw all this progress.

(00:14:56):
And then eventually he moved on. He founded his own startup, sold that, and now works as an executive vice president at one of the major online banks. And so his career in some sense has exceeded mine, but during that eight year span, he just grew so much. And this is the process we followed.

Lenny (00:15:19):
Wow, those are excellent examples. What levels does this help you with? At what level is this most useful, and then does it kind of taper out it? I don't know if you get to VP level, do you still try using Magic Loop?

Ethan Evans (00:15:33):
So I think it works anywhere from the start of your career to pretty far into it. I think at my level, I finished my career as a vice president at Amazon. It does peter out in the sense of the active. And what I mean by that is you're still doing the same thing, but you don't have to talk about it. Your managers are expecting you to step up and recognize challenges. They're expecting you to ask for resources when you need them, and you don't sort of have this level of explicit conversation around, what can I help you with? They're expecting you to anticipate what's needed.

(00:16:09):
So in the newsletter we did together, I wrote about how over time, you go from asking your manager, "How can I help?" To suggesting to your manager, "These are some things I see that seem like they need to be done. Would you like me to do them?" To just seeing what needs to be done and sort of keeping your leader in the loop and saying, "Hey, I noticed that we have this problem. I fixed it. I noticed we have this opportunity. I've started program against it." I think at the executive level, it's much more you being proactive and just keeping your leader in the loop.

Lenny (00:16:44):
I think in the post, the way you described this step is this is advanced mode. Don't jump straight to this. Don't just start suggesting things, because you may get it wrong.

Ethan Evans (00:16:53):
Yeah, well, it's all a matter of rapport and trust. A huge part of career success is how much trust you have, mutual respect with your leadership. When they're confident that you're going to make the right decisions, they're confident to let you go. But yeah, when you're brand new or you're new to a manager, if you just jump in, you may either not work on the things they value or even find yourself working across purposes, and that isn't the right place to start.

Lenny (00:17:19):
Awesome. Okay. Just to close out this conversation. You touched on this, but why is it that you think this is so important and effective? Why do you think this works so well? People may not recognize, "I see this is the key to this."

Ethan Evans (00:17:31):
Well, I think it's two things. First, I mentioned how rare it is for managers to be offered help. If you're a manager, you'll recognize this. If not, feel free to talk to any manager, whether your own or somebody else. Ask them how much they worry and how much they feel overwhelmed and wish someone would give them a hand. Management can be a lonely job, because you feel like you're responsible for everything. So having an ally, it's just a huge weight off people's shoulders.

(00:18:01):
And then I think a lot about social engineering. The social engineering's here is just the simple, "You help me, I'll help you." It doesn't have to be exploitative, it's just we help those people who help us, and that's built into human survival. 

(00:18:18):
And I think this loop works so well because it's just leaning a little bit into that behavior. So many relationships with managers are oppositional. You tell me what to do, and I'm kind of like a kid in high school who's trying to figure out how do I skip as many classes as possible and turn in as little homework and still get by with a D? That relationship won't build your career.

(00:18:45):
Some people approach their jobs as my goal is to do the least I can and still collect my paycheck. That's an approach if you're okay with where you are. It's not what I coach though. I assume people want to grow.

Lenny (00:19:02):
Okay, so maybe it's just as a closing question, for people that are listening and want to start putting this into practice slash are stuck in their career and are just like, "Okay, I see. Here's something I can do." Could you just again summarize the loop briefly?

Ethan Evans (00:19:15):
Sure. Step one, make sure you're doing your current job well. The way I explain this is when you go to your manager and ask, "What could I do to help?" You don't want their answer, even if they don't say it quite so bluntly to be, "Do your F-ing job." You need to be doing that already. So be doing a good job.

(00:19:34):
And unfortunately, a good job is in the eyes of your manager in this case. You may think I'm doing great work, but if your manager doesn't, they're the ones you need to build as an ally here. 

(00:19:46):
Once you have that, go ask how you can help, do whatever you're asked, and then go back to your manager and suggest or ask, "I would like to meet this goal. Can I keep helping you? What could I take on that you need that would also help me meet this goal?" And that's where you start to try to bring your two sets of aims together. What do you need done, how can I get to my goal? And let's do those things together.

(00:20:11):
And then you just repeat this loop. You build trust, you build the relationship. And with all good managers, and even a lot of moderate managers, they appreciate the help so much, they really lean into that.

Lenny (00:20:23):
I think there's two really important elements of this that you haven't even mentioned necessarily, that I think are part of the reason this works so well. One is this forces you and your manager to identify the gaps that are keeping you from the next level, which it's often vague, and then you get to a performance review, and then your manager's like, "Ethan, you're still not good on this and this and that," and you're like, "You never told me that that's the things you're looking for for me to get promoted." So I think there's this implicit, here's what you need to work on to get to the next level, which I think is part of step four. 

(00:20:53):
And then you actually did touch on this that it's important to share your goal to your manager. Here's what I want. I want to get promoted. A lot of times they don't know that and you helping them understand, "Here's what I want, help me get there." It goes a long way. So there's a lot-

Ethan Evans (00:21:06):
Managers often fall into the trap. They chose to become managers, so they assume one of two things about you. They either assume that you want to keep doing exactly what you're doing forever, just maybe make a little more money.

(00:21:16):
So you're an artist, you want to keep drawing forever. You're a lawyer, you want to keep writing contracts forever. Or they assume that, "Hey, I became a manager. I'm very proud of my career. That must be what you want."

(00:21:29):
And these assumptions are natural, right? We tend to view by default that our path is great and everyone would want to be us. Now of course, some good managers don't do that. But if you clarify and express your goals, you remove that ambiguity.

Lenny (00:21:45):
I actually had a period in my career where I specifically did not want to get promoted. I was very happy where I was, and I just wanted to keep doing this awesome IC role. Is that something at all you see where people are just like, "I'm good. I don't need to get promoted," and then is this helpful in that in any way or is it not as big a deal?

Ethan Evans (00:22:02):
So first, I reached a point in my career where I was no longer pursuing promotion either, and I wanted to do other things. So I've lived that myself and I've used the same loop, but I used it to go do what I wanted to say, "This is now what I want, and how do we get there? How do we create a role where I'm adding value appropriate to my level, but I'm doing this other work that's fun?" I moved into gaming and I really wanted to do that.

(00:22:25):
Second, I think it is still helpful because there's something you want probably. Maybe you want to work on different kinds of projects or maybe you want to work with a different higher performance team. Or maybe you want to rebalance your life and say, "Hey, I love what I'm doing, but how can I be a star performer for you but within these boundaries?"

(00:22:47):
So if you truly have the perfect job just as it is, you may not need The Magic Loop. But I know so few people if you're like, "Nope, there's absolutely nothing I could improve about my role."

Lenny (00:23:00):
Yeah, I think that your point about your goal doesn't have to be promotion. It could be work on a different part of the org, try something totally... Maybe transition to a new function that could be part of your goal. Awesome. 

(00:23:09):
Okay, so along the same lines of career progression, you work with a lot of senior manager types, kind of the level of L7 and one M2-ish, and you share with me that one of the most frustrating parts of their job in that specific portion of their career is they get stuck at that level and they don't move up, and it becomes really annoying, and they're not sure how to break out of that. What advice you share with folks like that, that may be listening?

Ethan Evans (00:23:36):
Yeah, so it's common to get stuck there, and there are a few reasons for it. First, there are a lot of senior managers. If you think of your average director, they may have six to eight reports. How many more directors are needed? So there's a choke point.

(00:23:52):
Second, that choke point is worse in the current economy, and in the past maybe a lot of companies, Amazon, Google, apple, etc., were growing very rapidly. And so it wasn't just you were waiting for some other director to leave. The teams were getting bigger.

(00:24:07):
I experienced this at Amazon, where over a nine-year period I went from managing six people to 800. And so I went from a senior manager all the way to a vice president, and I described I was, in some sense just riding the elevator. The elevator was going up, and as long as I managed to stay on it, I was going to arrive at vice president.

(00:24:29):
But the other thing that causes people to get stuck is the difference between a senior manager and a director is how you lead and the work you're doing. And you can get as far as senior manager by being really strong in your function and being really good at getting things done. As a director, and as a VP beyond that, it becomes much more about influence, coordination with others, and letting go of being in all the details yourself. And so senior managers really have to change some behavior.

(00:25:03):
I often reference the book by Marshall Goldsmith, What Got You Here Won't Get You There. Not only because it's a great book classically on this problem, but because the title tells the story. All the great traits that got you to this one level won't get you to the next level where you're more expected to be thinking in strategic terms, thinking longer term.

Lenny (00:25:26):
So to someone that may be in that role today and they're not moving up, is there anything they can do? This point about just there's no roles for you, there's only so much you can do there, is the advice just wait until an opportunity arrives? Is it run this Magic Loop until something happens? Is there anything you can do?

Ethan Evans (00:25:42):
I would be honest with people and say some patience is required. At this level, there is some notion of, do we need a director? Do we need a vice president? Do we have a challenge at that level that needs that person? And so promotions at this level, I often teach have two components. The first component is can I eat and do that job? Am I qualified? Do I have the skills? But the second piece is, do we have such a job that needs that?

(00:26:09):
However, there is a lot you can do. A lot is in your control. And what is in your control is to start practicing those next level skills. Start working with your leadership on, where can I take on a strategic project? How can I become more of an inventor? I teach some about how to sort of systematically be inventive. It's not pure magic. Edison said it's 1% inspiration and 99% perspiration. You can learn the 99%, and the 1% isn't as hard then. So you start showing those next level traits. And as I describe it most succinctly, how do you make yourself the person who will be chosen out of the eight?

(00:26:51):
And you can be chosen, there are several ways to move up. Your boss can leave or be let go. They can be promoted to another role. But another way is I coach now, and I have several clients recently. I was just talking to a client yesterday, her two peers were let go. They were all the same level. Her two peers were let go and she was given their teams. And she expressed that her boss had been told, "You have too many senior managers for the size of your organization. We need to do some change in the organization, clean house, and put all your people under the folks who have potential."

(00:27:32):
Well, obviously she must be one of those people, because she still has her job and has more people and more to do. And unfortunately, her peers are shopping for new employment. So be that person, and that's where The Magic Loop comes in. Be that person.

Lenny (00:27:48):
I was just talking actually to a senior PM leader who pointed out that with this kind of lean environment of a lot of flattening of orgs and a lot of layoffs, that this is becoming increasingly hard. Exactly what you're describing. There's just less spots, because companies are running more lean, and so you just kind of have to wait. 

(00:28:06):
I think part of this advice you just shared, which is classic do the job before you have the job makes all the sense in the world. Because once people see that you can do it, obviously they'll feel a lot more comfortable putting you in that position.

Ethan Evans (00:28:18):
And they'll be looking. I always remind people, as a leader, I want the best people under me I can have. It's not that I don't wish to promote you. If you think about my job, this helps people, right? I have selfish motivation to promote you. A lot of people think, "The bosses there holding me down." Well, maybe some bosses are, but why wouldn't I want stronger, more capable direct reports? Why wouldn't I want people under me who can do more of my job? Frankly, that's the only way I can do less of my job.

Lenny (00:28:47):
Plus this pressure you're always getting from your reports. So like, "Hey, I'm ready to get promoted, because this time"... You mentioned this word inventiveness, and I was just listening to Jeff Bezos on Lex Fridman, and I don't know if you heard this, but Jeff Bezos described himself most as an inventor more than anything else that he does. Is that something that you think about? Is that influenced by Jeff Bezos any way, that idea of being an inventor as a leader?

Ethan Evans (00:29:13):
I'll say a couple things about that. First, I know you talked to my old boss, Bill Carr, who wrote Working Backwards. What I don't know is if he shared with you that after he published it, he actually realized there was a better title. He wishes that he had called the book The Invention Machine, because what Jeff was trying to do with Amazon was create the most inventive company, the company that would systematically out-invent others. And so while Working Backwards is a great title, Bill and Jeff think they should have called it the Invention Machine.

(00:29:47):
When I joined Amazon, I did not think of myself as an inventor, but I saw that we had these leadership principles think big and invent and simplify that pushed on that. And I said, "I'm in trouble. I don't know how to do this." And I sat down and thought about that. What am I going to do? It seems like that's required. And I figured out how to become systematically inventive. So I now hold over 70 patents as one benchmark of inventiveness, and they were all created during my 15 years at Amazon. 

(00:30:22):
And the way I did that, inventiveness actually isn't that hard. I teach about this. And to invent systematically, first you do need to be somewhat of an expert in whatever area you want to invent. So Lenny, if you and I say let's get together and we're going to invent cancer drugs, we have the problem that neither of us, as far as I know is a biologist, a doctor. We don't have the right background, we don't know what we're doing. So we would just be fumbling around I guess with a bathtub full of chemicals hoping. It's probably not going to work out that well. So you have to be something of a knowledgeable expert.

(00:30:56):
But then the second thing people don't do is they don't spend dedicated time actually thinking. They feel like, "Invention is just going to come to me." When I want to invent, I get away from all my devices. I go in a room with the problem I have, and I force myself to actually concentrate on what do I know and how can I invent? And the most straightforward way to invent is not to somehow come up with something completely new, but instead to put together two things that exist. 

(00:31:28):
And so my example of this, I have a patent I talk about a lot for a drone delivery for Amazon, but the drone doesn't fly from the warehouse. Instead, a truck with no top drives slowly around the neighborhood, and the drones go back and forth from the truck. As opposed to the driver stopping at every house, you can have four or six drones hitting everything in the neighborhood. 

(00:31:55):
And the way I came up with this idea is one day I was thinking about drones and delivery, but I loved military history. And so I was thinking also about an aircraft carrier and I was thinking, is there a way to have an aircraft carrier for drones? And from that, it was very quick for the light bulb to go on and say, well, what about a truck? 

(00:32:17):
And so I have this patent, and we haven't seen this become reality yet. I'm waiting for my idea to become part of Amazon's drone delivery system, but I think ultimately it will.

Lenny (00:32:32):
That is badass. I'm imagining returns come back to the truck. We're using that rope thing that just captures them with that little hook.

Ethan Evans (00:32:42):
Yeah. Well, there's no reason... Same thing. When you want to return something as opposed to taking it to the UPS Store or whatever, you just put it on your porch, and then on your phone, on your app, maybe you take a picture of it so that the drone can recognize the box or you put it in a designated spot, and you push a button and the drone takes your return away. Yes, there's no reason.

Lenny (00:33:03):
Can't wait for that. And it takes your dog backs in it sometimes, part of it.

Ethan Evans (00:33:09):
My dog's too heavy, thank you.

Lenny (00:33:11):
My dog's not. There's an owl in our backyard that we sometimes worry he is going to come grab our dog on. This idea of invention, this is really interesting. I didn't plan to talk about this, but for someone like say a PM on a team that wants to get better at invention, innovation, big thinking, is there a practice you find helpful here? Is it block off two hours, get a pen and paper, and just think about the specific two adjacent things working together?

Ethan Evans (00:33:34):
So that's part of the process, is put in dedicated time. The interesting thing I would say is you don't need that much time. Two hours is great, but you only need two hours once a month. People think invention takes all this time. The thing is once you have one good idea, it often takes years to express that.

(00:33:52):
So you had the idea to have a newsletter. I know some of the history of your newsletter. You've been working on the expression of that idea for years now. Jeff and Amazon had ideas like, "Let's have Prime shipping." Well, Prime is still getting better and still being worked on. It's a 20 some year old idea. The Kindle a decade's old idea now still getting better. 

(00:34:16):
So the point here is you don't need very many good ideas to be seen as tremendously inventive. Like Elon Musk, Tesla, he can kind of dust off his hands and be like, "I am now an Edison-like inventor." So he keeps doing it, but you don't need that many inventions.

Lenny (00:34:36):
This touches on something else Jeff Bezos shared on the podcast that most of his innovation and work is in the optimizing phase. It's not the here's the idea, it's the making it cheaper, and better, and faster. And that's where most of the good stuff comes from. In this point of Tesla, Elon had this idea, and now the hard work is actually making it scalable and cheap enough for people to use, not just an electric car.

Ethan Evans (00:34:59):
With the idea of Jeff saying that invention is really a lot of the incremental and optimization, I completely agree with that. To invent well, you need a base idea, but then there's so much of the work is making that idea real.

(00:35:15):
And again, Prime is a great example of this. The Amazon Prime program was a great example of, okay, we want fast free shipping. We want this program. That was a one-time idea that they did build, but now Prime has expanded. First it was two-day in the US, then one-day in the US, now it's same day in the US. But also they added Prime Video, Prime Music, Prime Gaming. There's actually something like 25 things you get free with Prime. Most people have no idea, because you get free photo storage and this ongoing list. And all of that is that incremental optimization to make it better, better, better, better. And of course Jeff's goal, which you probably heard him say, was to make Prime a no-brainer, to where you would be irresponsible really not to be a member.

Lenny (00:36:06):
I know you have an awesome Jeff Bezos story that I want to get to, but before we do that, one more question along this line of career advice and progression. So I read somewhere that you've interviewed over 2,500 people over the course of your career. And so kind of going back to the beginning of a career, or at least getting a job, what have you found is most helpful in standing out as a candidate when you're interviewing, and essentially getting hired? What advice do you have for people that may be going through an interview process right now?

Ethan Evans (00:36:33):
There's a lot of evidence that suggests that the number one and two factors in any interview are appearance and enthusiasm. And it doesn't mean you have to be beautiful, but show up somewhere looking like you're interested in the job, not in your pajamas. And most importantly, be enthusiastic. People want to work with people that want to work with them. So if you seem very judgmental of the company and like you have to sell me on it, you're going to turn them off. I look at every interview of whether or not I really want this job, I might've decided I don't want the job. I still want the offer.

(00:37:10):
And so I come to any interview I do leaned in and talking about how excited I am to be a part of this opportunity and what I know about the company. Beyond those cosmetics, the biggest thing I see particularly at higher levels is people talk about what they have done but not why it mattered. They don't talk about the impact.

(00:37:32):
See, a leader is not hiring someone to just do work. They're hiring someone because they have a problem or a need. And so if you can show them, "Look, here's the things I've done that have made a difference. Here's the things I've done that have helped my past employers where I've had an impact." So I didn't just do work. That makes you a worker. Someone who has an impact is more of a leader.

(00:37:57):
And leader doesn't need to mean people manager, just a higher level, that I have done something that solve the big problem, and here's how it changed the company or customer outlook. That's what I'm looking for in an interview, is are you bringing me an understanding of the business that shows you contributed to the business, or are you just telling me how hard you worked?

Lenny (00:38:19):
Awesome. On that first piece, now that most interviews I imagine over Zoom, in terms of enthusiasm and looking professional, is there anything you've found that people may not be thinking about in those two buckets?

Ethan Evans (00:38:33):
Yeah. Show the person full-time dedication. So unless you really don't have any choice, don't take an interview from a car, don't have your camera off. Eye contact is still a real thing. Body language is still a real thing. Gestures like I'm making now with my hands, they're part of your presentation.

(00:38:53):
So be fully present and try to project through the camera a little bit of I'm excited to be a part of this and I appreciate the opportunity. I often tell people the best way to prep for an interview might be a good night's sleep and a pot of coffee, that being fully engaged and energetic is a huge lever.

Lenny (00:39:18):
Awesome. And I think basically, the feedback there is don't over obsess with the content. There's a lot of value in just how you come across.

Ethan Evans (00:39:27):
Yeah, 100%.

Lenny (00:39:29):
Let me tell you about a product called Arcade. Arcade is an interactive demo platform that enables teams to create polished on-brand demos in minutes. Telling the story of your product is hard, and customers want you to show them your product, not just talk about it or gate it. That's why product four teams such as Atlassian, [inaudible 00:39:49], and Retool use Arcade to tell better stories within their homepages, product change logs, emails, and documentation.

(00:39:56):
But don't just take my word for it. Quantum Metric, the leading digital analytics platform created an interactive product tour library to drive more prospects. With Arcade, they achieved a 2x higher conversion rate for demos and saw five times more engagement than videos. On top of that, they built the demo 10 times faster than before.

(00:40:14):
Creating a product demo has never been easier. With browser-based recording, Arcade is the no-code solution for building personalized demos at scale. Arcade offers product customization options, designer approved editing tools, and rich insights about how your viewers engage every step of the way. Ready to tell more engaging product stories that drive results? Head to arcade.software/lenny and get 50% off your first three months. That's arcade.software/lenny.

(00:40:44):
Now let's take a little trip to failure corner. This is something that I do more and more on this podcast, talk about people's failures in their career and their learnings. And apparently you have a great story of failing the great Jeff Bezos and surviving to tell the tale. Could you share that story?

Ethan Evans (00:41:00):
I do. It's both a highlight and a low light. So I had been at Amazon about six years. I had become a director, and I was responsible for launching Amazon's app store.

(00:41:14):
And so we were building an Android-based app store to go on Google phones and eventually on the Kindle tablets. And we got to launch day. And at that time, Jeff used to write a letter introducing new products. He would write a letter that said, "Dear customers, today Amazon's proud to launch blah blah, blah, and it's got these great features and I hope you really enjoy it. Thanks Jeff." And we would take down all the sales stuff on www.amazon.com and that letter would fill the whole screen. 

(00:41:48):
And so he had written a Jeff letter, and this Jeff letter emphasized a particular feature of our product that he really liked. So that something that made it a little different.

(00:42:00):
And that specific thing was we had a button called test drive that you could click on and it would open the app in a simulator in your web browser, so you could check out the app and interact with it before putting it on your phone. So he thought this was really cool and he was all about it. 

(00:42:19):
Well, my team had built all this technology. We had test drive working. It was kind of a hard piece of technology if you think about simulating any of thousands of arbitrary apps. And we worked all night to launch it, and it wasn't quite working at 6:00 AM. We were still debugging.

(00:42:38):
Now you know engineers very well. And I'm sure most of your listeners know about engineers, even if that's not their discipline. We always think we're this close to finding the last bug. 

(00:42:49):
So about 6:15 AM, I get a message from Jeff that says, "Hey, I woke up, where's the letter?" Because it was supposed to go live at 6:00 AM, right after the markets in New York would've opened at 9:00 AM Eastern. And he says, "Where's the letter?" And I write him back and I say, "Well, we're working on a few problems." And what I'm thinking in my head is, "Get in the shower, get in the shower. I just need 20 minutes, get in the shower."

Lenny (00:43:18):
For Jeff to get in the shower.

Ethan Evans (00:43:20):
Yeah. And 30 seconds later, I have an email back that says, "What problems?" And at this point I have to start explaining, and I end up explaining that we're having a problem with a database, and we're debugging this database problem. And he's like, "Wait, there's a database in your design? We're trying to eliminate all Oracle databases and move to AWS. Why do you even have this?" And he is just getting more and more frustrated and angry.

(00:43:49):
And he starts copying in my boss, and my boss's boss who's with Jeff Wilke, the CEO of retail. And they start asking me questions. And it's just this snowballing, but 7:30 in the morning, Jeff is clearly angry. And there's this list of other people waking up and feeling like, "Well Jeff is angry, so my job is to be even more angry," and it's just raining in on me.

Lenny (00:44:14):
Oh man. 

Ethan Evans (00:44:15):
So what did I do? The interesting thing is what do you do when the future richest man in the world is mad at you? He wasn't quite richest man in the world yet, but he was headed there.

(00:44:26):
So the first thing I did was I owned it. I said, "Yes, it's not working. It's my fault. I will deal with it." I took ownership. And the second thing I did was start updating him very proactively and saying, "Here's where we are." 8:00 AM, "This is exactly where we are. This is what we're going to do and the next hour, and this is when you'll get your next update. I will update you again at 9:00 AM, so here's our plan."

(00:44:55):
And even though Jeff had sort of lost trust in me, like it's down, and it's not right, and I'm mad, given that he agreed with the plan, he was willing to give me 60 minutes. And then I would update him again and say, "Okay, this is what we've done and this is what we're going to do, and we'll update you again at 10:00 AM." So I was buying life one hour at a time.

(00:45:17):
Now the other thing I did, and this is a good thing about Amazon, as more and more leaders got copied into this angry thread, they started reaching out in back channel and saying, "We've all been under Jeff's Eye of Sauron, we know it's miserable. What can we do to help?" And essentially Andy Jassy's organization, which was AWS at that time, and his CTO, a guy named Werner Vogels said, "You're having a database problem, let's get you some principal engineers from the AWS database team." 

(00:45:54):
And these principal engineers showed up at 9:00 AM roughly, and they looked at our design. We had made some fundamental mistakes in our database usage and they said, "It's too complicated to fix this. We're just going to give you 500 AWS machines so that your crappy design will run anyway. That's the immediate fix." And I'm like, "Okay, well I guess if you have 500 databases lying around because you're AWS, it's a great solution," and that's what they did.

(00:46:27):
So the next step is we fixed the problem. A bunch of us worked together very hard to get the problem all fixed. Now it took all day, and Jeff was still frustrated because the opportunity to sort of control the messaging and the media by having his letter up had passed. People had noticed our launch and the articles had been written, and so Jeff was still very mad.

(00:46:52):
So we fixed the problem, but Jeff now had no trust in us. The weekend went by. He was using the system looking for bugs because he is like, "This team's not reliable now. Ethan's not reliable. I better check it myself." So you have the CEO checking on you.

(00:47:11):
And he found a problem and emailed me like Saturday night at 9:00 like, "I was doing this and it broke." And luckily I was able to tell him exactly what happened by 9:30. Anyway, the next part of the story is that following week, I had a meeting with him on another topic.

(00:47:32):
So I was part of this small group that was trying to figure out how to build a competing browser. You may not remember, but Amazon had a browser called Silk for a while. And I was invited to this meeting, but I wasn't a critical participant. So you may know this idea from Scrum where they say some people are pigs and some are chickens, and the chickens are sort of observers. I was a chicken in this meeting, and that turns out to be a great analogy because I was thinking, should I chicken out and not go? I could skip this meeting with the CEO who's angry at me. But when I had that thought, I realized if I can't face the CEO, I'd better pack my desk. That's the end. 

(00:48:13):
So I went to this meeting early, and Jeff always sat in the same chair, so I knew where he would sit when he came in. So I sat down right next to his chair and I thought, "I don't know, let's find out."

(00:48:24):
And so the meeting goes by, and of course in my mind Jeff is totally ignoring me, not even looking at me. But I think that's just me projecting, because remember I wasn't central to the meeting.

(00:48:35):
So at the end of the meeting, everybody gets up to leave. He turns and looks at me and says, "So how are you doing? I bet it's been a hard week." And I thought, "Oh, okay, we're going to talk." And I said, "Yeah," I just sort of answered him with, "Of course it's been hard, but here's what we're doing and here's what we're going to do in the future." And we had a very human conversation. And I didn't believe Jeff would've forgotten that I let him down, but it was clear he had forgiven it. 

(00:49:05):
So I was still going to have to, as it turns out, re-earn his trust. But the thing I did that's key for people to learn from is it's really easy to flame. He had been flaming me, writing angry emails. Angry emails are easy. Sitting three feet from someone and being angry with them face-to-face is hard. And when faced with, I can either start ranting at this person who reports to me, or I can say something nice, he chose to say something nice, and that rebuilt our relationship.

(00:49:42):
So the end of the story is two years later, I was promoted to vice president. So even though I had failed the CEO on this very public launch where he was very definitely mad at me, I re-earned the trust, I showed I had learned the lessons of how to launch more reliably without outages, and I was promoted.

(00:50:07):
And so I share that story because I think what I want people to understand is if I can get away with publicly failing one of the richest and most famous inventors on earth, and then get promoted and finish my career at Amazon very successfully, you can dig out of any hole. You just have to manage it right.

Lenny (00:50:30):
That is an amazing story. So there's a lot of lessons that I want to pull on here. One is just if you get caught in a situation like this where something completely fails, what I took down as you were talking, one is admit, yes, this is a huge problem, own it. This is like, don't try to deflect.

(00:50:47):
Two is the way I describe what you did here, is something I call prioritizing and communicating, where you prioritize, "Here's what we need to do," and then communicate. "Here's our priorities." And I love that you have this every hour, "Here's the latest, here's the latest." So make people understand you are on it and you'll continue to keep them updated. I imagine one of the worst fears is I have no idea what's happening here. I'm going to go in and start micromanaging.

Ethan Evans (00:51:11):
You're exactly right. I'm trying to hold off micromanagement. I'm trying to give them, "Okay, I believe with this and I can wait an hour," and then I can wait an another hour because that team seems to be on it. So I'm trying to rebuild trust one hour at a time, and avoid having three or four levels of management all come in and start helping.

Lenny (00:51:31):
Then I love this other piece of advice of meet them in person, try to take it offline essentially, which I know you did later. But that's such a good point that it's hard to be as mad, and angry, and flamey in person. People are just going to be like, "Okay, I get it. Let's try to figure this out." Amazing. Is there anything else? Those are the three that I took away. Just like if you're caught in that situation in the moment, is there anything else that you found to be really helpful?

Ethan Evans (00:51:55):
I mean, work hard and fast, right? You do have to fix the problem. My team had been up all night. I had to start sending people home to sleep in shifts. We had to pull in all this help. And so it was a very hard weekend.

(00:52:10):
When you have a mistake, it's on you to pull out the stops, even if it's uncomfortable to recover from it. And again, this is not the time to be like, "Well, it's the weekend now, and my team, we'll hit it Monday." I'd have been out the door so fast, I would've had the comic Wile E. Coyote skid marks as I bumped down the street. So I would say that's important. It's part of showing ownership.

Lenny (00:52:39):
The other part of this is something I went through for a while when I was starting to become a more senior leader is I had a lot of imposter syndrome, and this fear that if I messed up, everything would crumble. People would see that I don't actually know what I'm doing, and I'm not really ready for this level of seniority. And so there's this fear of one big mistake, it's over. Clearly this was an example of a huge mistake and it was not over for you. Is there any lessons there that you take away of you can mess up and still do well, even if it's this level of mistake?

Ethan Evans (00:53:11):
I think a lot of people in my position would've quit. They would've let the shame... I was just a little bit bullheaded where I'm like, "Yeah, I messed up. But I know I'm still a good person and a good worker. Yes, I made a mistake, but I'm going to move on." Part of the story I haven't told that you might enjoy is I mentioned that Jeff Wilke was Jeff's number two at that point. Jeff Bezos, number two person, and he was my skip level. 

(00:53:38):
Well, during this process, he came physically into our offices and he wanted to talk to me, and my manager who was vice president said, "Hey Jeff, this is my team. I own it. If you have any criticism, say it to me. You don't mean to talk to my team." And Jeff Wilke said to my boss, whose name was Paul, "Paul, that's excellent leadership. I really appreciate what you're doing. Please step out of the way. I want to talk to Ethan. You're doing a great job, Paul. Now step aside." And then he kind of read me the riot act.

(00:54:15):
And the rest of that funny story is I was so happy with how well my meeting with Jeff Bezos went, I patted myself on the back and like, "I'm going to go face Jeff Wilke now. I'm going to schedule a meeting with him and do the same thing. I've got this down."

(00:54:31):
So I go to meet with Jeff Wilke, figuring I'm going to run the same playbook. I'm going to look him in the eye and all will be forgiven. And Jeff Wilke looks at me and says, "Ethan, when you launched this, did you know you were gambling with the result? Did you know it might not work?" And I said, "Yes. We had a media commitment to launch on that day, and I thought shooting for the date was more important than perfect certainty."

(00:54:55):
And he said, "Well, two things. First, you were wrong. You were wrong to prioritize date over our reputation. You let Amazon down in public and that was a mistake." He said, "Second though, at least you knew you were gambling. If you hadn't known you were gambling, we'd be discussing your departure." And I'm like, "Okay." Here I thought I was rolling in this meeting like I'm going to run my relationship playbook. And he's evaluating whether or not to keep me.

(00:55:25):
The bullheadedness is even after he had told me he had been considering firing me, I'm like, "Well he isn't. So I'm just going to go forward." And a lot of that stubbornness of sure I made a mistake, but I'm not going to live in shame about it, I think is what people can take away. I think a lot of people feel they're more dead in the water than they are. 

(00:55:53):
Because everybody makes mistakes, right? I mean Jeff and Fire Phone, that'll be an albatross around his neck. Jeff and Fire Phone will be a phrase of anybody who knows Amazon for the rest of his life.

Lenny (00:56:08):
Yeah, we talked about it on the Working Backwards podcast, and why didn't Working Backwards work for the Fire Phone, we talked about it. I love that these quotes and lines are so seared in your brain. You can remember it like word for word exactly what-

Ethan Evans (00:56:20):
Well, I've relived that moment many times.

Lenny (00:56:26):
And then just along the lines of working your way out of the hole, is essentially what you did just succeed for two years and do great, and that was the key there?

Ethan Evans (00:56:34):
No, I think I did have to learn. I've always been sort of an operational cowboy, meaning I like to go fast and loose. I prioritize speed, and I really had to step back and say, "Okay, Amazon at this level and scale doesn't like that." So I've taught myself a new phrase which was fear the New York Times headline. Be aware that if Amazon is down, it goes up on every news website immediately. And so if Amazon has some kind of mistake, it's on Wall Street Journal and CNN.

(00:57:07):
And so as a leader, I had to think, is what I'm doing going to generate a New York Times headline? Because if it is, I'd better be really careful. And that's what I taught myself is you can't be paralyzed, but I taught my whole team, we don't want to be in the New York Times for the wrong thing. And that was the lesson

Lenny (00:57:32):
Along the lines of lessons, last question here, what's something that you took away from the way you approached it that you should have changed or should have done differently, that you've done differently since? Obviously don't... You mentioned this idea of don't promise a date that you're not that certain you're going to hit. I guess is there anything along those lines?

Ethan Evans (00:57:52):
I have two things here. First, Amazon loved in the past, they loved surprise launches. They love the idea of we're going to be quiet, quiet, quiet. Because basically it was a reaction I think to Microsoft where they felt Microsoft always talked about what was coming and then pushed the dates back. And so there was this whole thing about vaporware. And Amazon wanted to be the other way, which is we won't say anything and then it will just be there. The problem I came to say is the biggest thing I learned with surprise launches is that you're surprised by what doesn't work. 

(00:58:23):
And so I shifted the approach to let's do a lot of beta testing. We always, even if others don't agree quite and say, "You're right, we're not going to have a surprise launch." Some of our beta testers, even if they sign NDAs are going to leak. And that's a better outcome than launching something that doesn't work. That's one lesson.

(00:58:46):
The other lesson is this thing that broke in front of Jeff Bezos, ultimately it was a new college graduate engineer who wrote that code. And he had been left alone to write part of our user interface, but he had written it in such a way that it didn't scale. Now we didn't give him any help or oversight. We left him on his own, because we were busy focusing on other pieces of the problem.

(00:59:20):
And shortly after the disaster, he left the company. And the mistake I made was not reaching out to him and really reassuring him of, "Yes, you wrote the bug, but that's not on you. The system failed you and we don't see you. Bugs happen."

(00:59:38):
So the thing I regret in this whole thing is not realizing that even though no one in the team ever yelled at him or whatever, he knew it was his bug, and he obviously saw me and others sort of taking a beating. And so he left, and I wish he hadn't done that. And I wish more than that I had stepped in. I didn't realize what he was feeling.

Lenny (01:00:05):
It's interesting, the lesson there isn't catch that person sooner, and notice these links in the chain that may break. But it's more just be there for that human that have this challenge, that people may not be focusing on.

Ethan Evans (01:00:19):
Because we lost a good person, and he probably felt very bad about it. And we all feel bad when we make mistakes. That can't be prevented. But he felt undue responsibility I think, and that I really regret.

Lenny (01:00:35):
This is actually a really good example of ownership. You mentioned this term ownership and that connects to... Amazon has these leadership principles. I think there's 14 of them. One of them is around ownership. And apparently you helped craft the actual language for that principle, which I think is a huge deal with Amazon. I imagine very few people have a say over how to define, and describe, and say these principles. Could you just talk about this principle that you contributed to, how it came to be that you helped actually write it?

Ethan Evans (01:01:08):
Amazon is now kind of on its fourth version in my mind, maybe there's more. But its fourth major revision of its leadership principles over its 25 plus year history.

(01:01:18):
And when it was going from version one to version two, Jeff and his leadership team sat down together. And actually in version one, there were three different lists. They were leadership principles and core values, and something else I don't remember. And they were like, "Three lists is stupid. Let's make one list."

(01:01:36):
Well ownership, the term had been a part of one of those lists, but when they merged everything, they took it out. And this guy Jeff Wilke I mentioned, the number two and the leader of retail, he brought a bunch of us a bunch of his directors. He brought the proposed list to us in a meeting and said, "Hey, this is the proposed new version, do you have any comment?" And we all sat around and talked and said, "Where's ownership? Ownership is missing." So we told him, he said, "Look, ownership is missing. We think it should be there." And he said, "Well, why don't you propose a draft?"

(01:02:15):
And so about a half dozen of us sat around and roughed out a draft of how we felt ownership should be written. And I proposed these six words, which are, "An owner never says that's not my job." Maybe that's seven words.

(01:02:36):
So I propose this specific language as a part of it and we sent off this draft. And months go by, we hear nothing. And then one day the leadership principles are announced and ownership is back in. It's been modified, but that, "An owner never says that's not my job," is a part of the leadership principle, and it's remained to this debt. 

(01:02:58):
And what I love about that is because Amazon has one and a half million employees who live by these leadership principles, it's probably the most impactful thing I've ever written.

Lenny (01:03:11):
Wow. So those seven words are the most impactful thing you've ever written. I love that and I totally get that. I'm looking at the principles right now and it comes right at the end of that principle. We'll link to the 14 leadership principles. Is there another principle that you really love or one or two? I don't know. It's probably hard to pick your favorites.

Ethan Evans (01:03:28):
I'm a huge proponent of bias for action. Bias for action says speed matters in business and many decisions are reversible. And so it's important to go faster. 

(01:03:41):
And I think people don't understand that in a competitive environment, being right is good, but being quick is necessary. Because if there are 10 startups working on an idea, some of them will gamble, and they'll make bad gambles, and they'll go out of business. But some of them will gamble and make an early bet and be right. And if you are not moving quickly, you'll be beaten by the people who maybe got lucky. 

(01:04:05):
And so you've got to have a process that values speed, values, what can we do today? What can we commit to today? So I really like bias for action. Now that is what got me in trouble with Jeff, right? I was willing to gamble. So it has to be in balance, but that's my other favorite.

Lenny (01:04:25):
Again, the Jeff Bezos interview with Lex Fridman, he was talking about how with Blue Origin, with the way Amazon, he thought about Amazon is customer obsession. That was the core goal and differentiator of Amazon. With Blue Origin, he wants it to be decisiveness. It's basically leaning into this bias for action fully, which is really interesting.

Ethan Evans (01:04:44):
I saw that part of the interview and I thought, "Wow, that's exactly right." Because again, rockets blow up and they have people on them. You've got to get it right, but you also have to keep moving, because there's always one more thing you can safety test. So how do you balance it?

Lenny (01:05:04):
Yeah, it's interesting. With rockets, that's the one that you pick. It's pretty bold to be all move forward kind of thing. So this principle, again, going back to ownership, so you basically suggested this phrase, "You didn't hear anything," and all of a sudden it becomes part of the whole thing. Did that feel weird that they never told you, or I don't know if they gave you credit for that, or it's like, no, it's great?

Ethan Evans (01:05:24):
Yeah, I wouldn't even claim credit for it, except I kept a copy of the email that says, "Ethan thinks it should say blah." I have the written proof. Because it's not about the credit. I'm very happy and proud that those words were kept. But in Amazon, I doubt if Jeff knows I wrote those words. It's not like I've ever told him, "Hey, do you know you kept my words?" That's not appropriate. It's just a fun anecdote.

(01:05:55):
And it does show, I guess something people can learn from that though, you can influence way up in a company if your ideas are good. And also, when we challenged, Jeff Wilke was a strong opinionated leader who didn't necessarily always love being challenged.

(01:06:15):
And so when we first told him, "Well, we think you're missing ownership," he was like, "You're staying that the whole S team can't get its leadership principles right?" I mean it wasn't exactly that way, but he was very much like, "Well, is this really necessary? Why do you think it's necessary?" And his challenge to us to write it was kind of framed as, "Well if you're so sure it's good, show us." But again, I'm stubborn and I'm like, "All right, let's write it." And we did.

Lenny (01:06:47):
That's funny. That's not a great example of leadership where he is like, "Hey guys, I need your feedback on this thing. But no, don't actually tell me anything's wrong."

Ethan Evans (01:06:57):
Well, yeah. I mean for a bunch of directors to kind of critique the work of people two levels higher, he wanted it, but then he's sort of naturally resistant to it if we're kind of poking at his baby.

Lenny (01:07:14):
It's unlikely that there's something huge missing and it turns out there was.

Ethan Evans (01:07:18):
Yeah.

Lenny (01:07:19):
And I guess just on these principles, people may not know this, but this is where disagree and commit comes from. It's actually have backbone, disagree, and commit. We talked about this on the podcast about working backwards. I also love leaders are right a lot. That comes up a lot and I love that, to be successful, you need to be right. You can't just project confidence. You can't just be in a bunch of meetings and ship things. You need to be right to be successful.

Ethan Evans (01:07:42):
And that one's been rewritten to carefully say, it's always interesting what is the history of the edits, which you wish you could see the edit history on these. That one got modified to say something about leaders actively work to disconfirm their beliefs.

(01:07:58):
And the key there is it was trying to get at the idea that you've got to be very open and always be questioning, "Yes, I think I'm right, but what's the new evidence? What am I learning? What's changing?" And in fact, it also says they seek diverse perspectives.

(01:08:20):
And that was a way of getting at what's called DEI, diversity, equity, and inclusion. That's a subtle nod towards if everyone in the room is a 50-year-old white man, you may not really be making the right overall decision for Amazon's customer base. You may be making the one for 50-year-old white suburban Seattleites. And so it's just some of these, every word in those has been studied as an individual word inside the company.

Lenny (01:08:52):
Amazing. Okay. Let's move on to the final area I wanted to spend a little time on, and this is called contrarian corner. I'm curious if you have any contrarian opinions about things basically that other people believe that you don't believe, something you see that many people don't see. Is there anything that comes to mind?

Ethan Evans (01:09:11):
Yeah, I think a place where I'm currently very contrarian is the return to office movement. Many leaders at my level appear or publicly favor the need to get back into the office potentially full-time. 

(01:09:27):
And I'm contrarian on this because of innovation. Specifically, I looked it up, you can check my facts on Wikipedia. The first purpose-built office, the first building ever built to be an office was built in 1726 in London. And so we're about 300 years into learning how to use offices well.

(01:09:51):
And what that means is offices aren't going to get much better. What's the last major thing you can think of that got better in offices? You might say well open offices, but a lot of people would say that's not even a good idea. These big rows of desks and loud pits.

(01:10:06):
With working from home, we've only been doing that for a few years since the pandemic began and at all since the internet started 20 years ago. Which one is likely to have more opportunity for improvement? There's so many things we haven't explored with remote work. And I think the people who say, "Back to the office, it's because we know it works," well we know what it is, but I have so much more faith in the opportunity to improve the remote experience. And so I think long-term, it's going to triumph.

(01:10:40):
The one other place where I'm a huge contrarian is doing business on a handshake. I understand companies need lawyers, and I have an attorney for certain things. But I coach people. Most of the people I coach, there's no NDA in place. There's no contract in place. They pay me through PayPal and I do good coaching for them.

(01:11:01):
I think too much of the world is contract driven, and we've lost the idea of your word being your bond, and you can actually trust me to follow through on my commitments. And I'm a contrarian there.

(01:11:14):
I realize I will occasionally get burnt. Someone will behave in a way, they'll let me down. But I think when we're always suspicious of people, that's a high cost. And the other place I'm contrarian is just doing business on faith.

Lenny (01:11:32):
That reminds me, Sam Altman has a similar philosophy of just trust people and assume it'll all be okay. Sometimes you'll get burned, but on balance, it'll end up being much better for you and for everyone around you. 

Ethan Evans (01:11:42):
I didn't know that Sam had said that, but I strongly agree with it.

Lenny (01:11:45):
Yeah, although he had some challenges recently. I don't know if it's working great, but it ended upgrade for him. So anyway, okay. We've actually reached our very exciting lightning round. Before we get there, is there anything else you wanted to touch on, or share, or leave listeners with?

Ethan Evans (01:12:01):
No, I've really enjoyed this conversation. I could talk about careers forever and I love doing that, but I think we've covered a ton today that will really help people. So I'm good. Let's hit the lightning round.

Lenny (01:12:14):
All right. With that, we reached our very exciting lightning round. Are you ready?

Ethan Evans (01:12:19):
I'm ready.

Lenny (01:12:20):
Ethan, what are two or three books that you've recommended most to other people?

Ethan Evans (01:12:25):
Two or three books. My number one recommendation is a book called Decisive. It's by Chip and Dan Heath, and it's about the science of making better decisions. The reason I recommend it so much is it will make your career better because leaders are decision makers, but also your personal life. So I apply it at least as much in my personal life as I do in my professional life. 

(01:12:47):
My second most recommended book is Leadership and Self Deception, much less known than Decisive, a little bit harder to approach. It's by a group, a research group called the Arbinger Institute, and it's about, the self-deception is we cause a lot of our interpersonal problems while blaming them on others. And it walks through how are you part of the problem you're having with somebody else and what can you do about it?

(01:13:14):
The third and final book was recently brought to me by someone I work with that you know, Jason [inaudible 01:13:21]. That book is The Almanack Of Naval Ravikant. And Naval Ravikant is an angel investor responsible for AngelList. 

(01:13:30):
But what I love about that book is he has a recipe. He really boils down how to be successful while loving what you do. And he says, "No one can be a better version of you." Don't try to copy me and be, "I'm going to be like Ethan, or I'm going to be like Lenny." Instead, figure out what you uniquely do best that you love, because no one can copy you being you. And that's your defensible sort of career value. And I really like that mental model.

Lenny (01:14:03):
Yeah, Naval has so many insightful messages, and you can read all these on his Twitter. We'll link to his Twitter, and someone just made a book out of his tweets basically. He's such an interesting dude.

Ethan Evans (01:14:13):
Yes, that's right.

Lenny (01:14:14):
Awesome. What is a favorite recent movie or TV show you've really enjoyed?

Ethan Evans (01:14:19):
So I grew up on a farm, and so all the Taylor Sheridan, 1923, and Yellowstone, and all of those series, we've watched everything he's put out. We do kind of laugh like, wow. Are you familiar with Yellowstone at all?

Lenny (01:14:37):
Absolutely. A lot of death.

Ethan Evans (01:14:39):
Yeah. At one point my wife and I were watching it, we would start betting. So the episode is starting, how many people will die in this episode? This ranch in Montana, but yet somehow they're always killing people. How does this work?

Lenny (01:14:55):
That's what your life was like, is what I'm hearing. Favorite interview question that you like to ask candidates?

Ethan Evans (01:15:03):
I think my favorite interview question is, "Tell me about a time where you needed to disagree with your management, where you needed to stand up or fight for a position against higher leadership or people in power." Because I think that's really hard to do. I'm normally interviewing leaders, and I think having a bunch of people who just say yes isn't helpful. You need people to have, as you said, have backbone, disagree and commit. So that's what I'm normally looking for.

Lenny (01:15:33):
Awesome. Is there favorite product you've recently discovered that you really love?

Ethan Evans (01:15:38):
It's silly, but my favorite product that I've discovered recently is the Chuckit!, which you use to whip a ball for your dog a quarter mile. It basically extends your arm. And it's just fun to send a ball soaring way further than you could ever throw it. And you feel like, "Wow, look at me. I'm a major league pitcher." Because I have this three foot lever arm and I understand physics. If we look at tech products, there's so many I love. It's too easy to say ChatGPT and stuff, so I won't go there.

Lenny (01:16:16):
Awesome. My dog does not love chasing balls, so I haven't had a reason to buy that, but I've never thought about just the joy of flicking a ball really far. Do you have a favorite life motto that you often come back to, share with folks, find useful in work or in life?

Ethan Evans (01:16:31):
I happen to be a Christian, and the motto that I think about the most is, "To whom much has been given, from him much will be required." And so I think a lot about what is my social responsibility. 

(01:16:44):
I've been very lucky. I grew up on a farm in Ohio now. I wasn't a farm boy, my father was a chemist. But I grew up in upper middle class settings, and I've ended up being extremely successful, able to retire from my job at 50 to kind of coach and teach. What do I owe to pay forward? So those words are obviously ancient spiritual texts, but they're the ones I take away and think the most about. What's my responsibility?

Lenny (01:17:11):
As an example of someone that to whom much has been given, but because he's worked so hard, Jeff Bezos is starting a space business as you know. If you had the chance to go to space, would you go?

Ethan Evans (01:17:22):
Well, I of course saw his interview where he talked about how he thought about the safety and the conversation he had to have with his mother. I would like to go to space. I'm not willing to pay what I think the current tickets are, but I would take the risk. So what's the risk of that ride? One in a hundred, one in 50, even more that you won't come back. I would probably take the gamble.

Lenny (01:17:46):
So you'd be an early adopter? Where along that curve would you be, an early adopter, laggard?

Ethan Evans (01:17:50):
Well, I'm old enough that I remember when the Challenger space shuttle exploded, and I said I would get on the next one and I said, "They're never going to be more careful than the next one, so I'll get on the next one."

(01:18:04):
So I think I would get on any one I was offered because of the chance. Unlike Jeff who claims he wasn't scared, I would probably be really terrified, at least at liftoff. While you're up there, it's great. Everything either goes wrong going up or coming down. It's not the middle.

Lenny (01:18:25):
Ethan, I think we're going to help a lot of people with their career. I think we're going to help them work through failure, become better owners. Thank you so much for being here. Two final questions. Where can folks find you online if they want to reach out? Also, just share what you do now in case people could use that help. And then how can listeners useful to you?

Ethan Evans (01:18:42):
So the best place to find me online, I do all my writing on LinkedIn. It's where the professional community is. So Ethan Evans on LinkedIn. My actual handle there is Ethan Evans VP for my history as a vice president. That's the best place to find me. I do have a Substack newsletter. I do teach through the Maven platform, but all of those are linked off LinkedIn.

(01:19:02):
And really, how readers help me, they comment on what I write, because I miss things. I am one person's perspective. And so I actually have a process where I take in all the comments people write, all the different perspectives, all the different exceptions, or special cases, or examples, and that's how I improve my own thinking is I read every comment and think, "Okay, what did I miss? What could I have said better? How can I incorporate this if I ever talk about this again?"

Lenny (01:19:31):
Just to give you another opportunity to plug the stuff you do now, what do you help people with in case people could value could you use the stuff that you offer? You said you coach, you have a course. What sort of stuff?

Ethan Evans (01:19:40):
I focus on two topics, career development. So how do you row in your career, the whole Magic Loop, and how do you attain promotion or attain a new role raise if that's your goal? And then leadership specifically. I teach a course that's been very popular called Stuck at Senior Manager - Breaking Through To Executive, which is how to get out of that sort of stuck, "I'm working really hard, I'm pretty good. I'm managing 25 or 50 people, but how do I get to the big chair? How do I get to the division level leadership and what do I need to change?" It's that whole what got you here won't get you there. And I love to see people succeed at that. People write me back and say, "I did get a job. I did get promoted, I did get a raise," and that's my fulfillment.

Lenny (01:20:25):
Amazing. Ethan, thank you so much for being here.

Ethan Evans (01:20:29):
Thank you, Lenny. And I got to say, you are very good at this. You're so smooth and you just do a great job interviewing. It's been really been a pleasure.

Lenny (01:20:37):
I really appreciate that, and so are you. Thank you. Bye everyone.

Ethan Evans (01:20:42):
Bye everyone.

Lenny (01:20:44):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review, as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Improve strategy, influence, and decision-making by understanding your brain | Evan LaPointe
**Guest:** Evan LaPointe  
**Published:** 2024-08-11  
**YouTube:** https://www.youtube.com/watch?v=GECtyEj9UPA  
**Tags:** growth, retention, metrics, roadmap, prioritization, experimentation, analytics, conversion, monetization, subscription  

# Improve strategy, influence, and decision-making by understanding your brain | Evan LaPointe

## Transcript

Evan LaPointe (00:00:00):
The brain is like a college campus that has different departments in it. Most people rely on their history department way too much. If you instead send things to the more experimental, open-minded science department, the more creative art department, you get dramatically better answers.

Lenny Rachitsky (00:00:13):
I know you have a bunch of awesome advice on becoming more influential.

Evan LaPointe (00:00:16):
It's almost like you're playing Elden Ring or some video game. The starting point is to choose your character. Hey, I'm the devil's advocate approach, or I'm the break it and see if it still stands after I hit it really hard with a sledgehammer kind of guy, your personality kind of has a natural fit.

Lenny Rachitsky (00:00:30):
How do we create better relationships within our teams?

Evan LaPointe (00:00:33):
It's critical to ask what kind of experience am I? Not how good am I at my job, how much do I know, how critical am I to this process, but am I a miserable experience? If the answer is yes, don't worry too much about the other pieces yet. You got to fix that first.

Lenny Rachitsky (00:00:48):
I'm really excited for this episode. I think it's going to be unlike any other conversation I've had on this podcast.

Evan LaPointe (00:00:52):
Then here's the surprise ending.

Lenny Rachitsky (00:00:58):
Today, my guest is Evan LaPointe. Evan is the founder of CORE Sciences, which teaches companies and individuals how our brains actually work, and through that lens, how to more effectively work with other people on teams, how to build better products, how to grow your business, and how to make smarter and faster decisions. Evan is a four-time founder, including founding a company called Satellite, which is the fourth largest analytics product on the internet today, which was acquired by Adobe where he later ran product strategy and innovation for Adobe's digital business.

(00:01:31):
In our conversation, Evan shares a simple way to understand how our brains work, and through that framework, how we can get better at vision work, influence, running meetings, having more focus and building better and more productive relationships with our colleagues. This conversation is a beautiful mix of science, theory, and also, a ton of very actionable and concrete things you can do to be more effective in your work. If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. It's the best way to avoid missing future episodes and helps the podcast tremendously. With that, I bring you Evan LaPointe. Evan, thank you so much for being here. Welcome to the podcast.

Evan LaPointe (00:02:16):
Thanks very much for having me. I'm excited to share some stuff with people.

Lenny Rachitsky (00:02:19):
I am really excited for this episode because one, I think it's going to be unlike any other conversation I've had on this podcast. Two, I think it's going to really stretch our brains as we learn about how the brain works. Three, I think it's really going to make an impact on how people work and how they relate to other people and work with other people. I thought it'd be great to start by laying a little bit of foundation for people to get a sense of just what they need to understand about how the brain works before we get into how we can actually apply some of the stuff. Could you just share some of the stuff that is really important for us to know about how the brain works?

Evan LaPointe (00:02:53):
The brain is like a big galaxy. There's a National Geographic quote that we throw up in all of our programs that when we train teams, for example, that says the brain is more complex than any known structure in the universe. It's easy to read a sentence like that and just run straight away from the problem. I think that's important for people to not run away from this problem but more run toward it. It's our job to translate the complexity of the brain into really simple, straightforward systems that you can remember. The three or four main systems to stack on top of each other like layers, start with the fact that the brain has systems. I think of it like the brain is like a college campus that has different departments in it, and your brain has a science department responsible for open-minded experimentation.

(00:03:39):
It has an art department in it responsible for creative boundless thinking. It has a history department designed for looking stuff up that you already know. If you think about sending your thoughts to the right department on the campus or just different departments, you're going to get super different responses back from your brain. Where we're stuck largely is most people rely on their history department way too much. That's because the brain is actually built to conserve energy, and that's the lowest energy form of generating an answer to a question that the brain can pull off. If you instead send things to the more experimental, open-minded science department, the more creative art department, the humanities department of your compassion, et cetera, you get totally different answers. Certainly, if you ever build products as a company or offer services, those departments are going to give you dramatically better answers than the reference material just in your history department.

Lenny Rachitsky (00:04:35):
This episode is brought to you by Webflow. We're all friends here, so let's be real for a second. We all know that your website shouldn't be a static asset, it should be a dynamic part of your strategy that drives conversions, that's business 101. Here's a number for you, 54% of leaders say web updates take too long. That's over half of you listening right now. That's where Webflow comes in. Their visual-first platform allows you to build, launch, and optimize webpages fast. That means you can set ambitious business goals and your site can rise to the challenge. Learn how teams like Dropbox, IDEO and Orange Theory. Trust Webflow to achieve their most ambitious goals today at webflow.com.

(00:05:21):
This episode is brought to you by Explo, a game-changer for customer-facing analytics and data reporting. Are your users craving more dashboards, reports and analytics within your product? Are you tired of trying to build it yourself? As a product leader, you probably have these requests in your roadmap, but the struggle to prioritize them is real. Building analytics from scratch can be time-consuming, expensive and a really challenging process, enter Explo. Explo is a fully white-labeled embedded analytics solution designed entirely with your user in mind. Getting started is easy. Explo to any relational database or warehouse, and with its low- code functionality, you can build and style dashboards in minutes. Once you're ready, simply embed the dashboard or report into your application with a tiny code snippet. The best part, your end users can use Explo's AI features for their own report and dashboard generation, eliminating customer data requests for your support team. Build and embed a fully white-labeled analytics experience in days. Try it for free at explo.co/lenny. That's E-X-P-L-O, dot, C-O, slash, Lenny.

Evan LaPointe (00:06:34):
That's the first thing is that the brain has these departments and systems in it and it also has pathways. The pathways thing is really important to understand because there's a likelihood that thought will go down certain pathways in each of our brains. Some of that has to do with personality, which predisposes us to have a higher-anxiety or a lower-anxiety response or a higher-creativity or lower-creativity response. You can also be more intentional with these pathways, and that's a big component of self-awareness is to know what are my preferences and then am I actually letting those preferences take over in the situation or might be more intentional steering down the pathways to activate these best regions and systems of the brain. The simplest way to keep track of the systems is there's three, there's three really big ones.

(00:07:25):
There probably are more than three that you can learn about, but the ones we want to have everybody learn about are your safety system, your reward system, and your purpose system. Out of those three, two of them sound really real and one of them sounds like fantasy, to most people. The safety system is pretty obvious to most people. When we're scared, afraid, uncertain, we have doubt, we're resentful, angry, apathetic, etc. This system of our brain is trying to restore our standing in the universe, like I need to get out of this stress, out of this danger, out of this anger, etc. you have an objective that, that part of your brain, that system sets, and you go chase that objective, like I want to get safe. If you're in a meeting, a practical everyday situation, and you're exposed to a statement that makes you feel unsafe, your objective now actually isn't to contribute to the meeting productively anymore.

(00:08:19):
Your brain's objective is to get back to safety. The same thing of rewards that if somebody says you'll get something, if you do this, which is the opposite of safety, that if you don't do this, something bad will happen, then yeah, your brain gets into this pursuit, desire state, which seems great and can be great in a lot of cases, but also, can be pretty narrow. When you hear people say, "That's not my job." That's actually the reward system speaking, saying, "I get rewarded for the things in this list and this thing that you're talking about is not on my reward list and I therefore am not interested in it." I have an easier time pushing away from it because the reward system of the brain is more transactional in a conceptual way. Then you get to this vague and ridiculous sounding purpose system.

(00:09:08):
Until you realize what purpose is, and we've all felt it, if you understand the impact of the thing that you're doing and you understand and care about the people that are impacted by your actions, those are the conditions for purpose, and that can be really big. Like curing cancer, I understand the impact on the people, that's huge. It can also be like I'm writing an email, I understand the impact of this email and the people affected by it. You can feel purpose at this tiny little grain of sand level of your life, not just at the whole beach and shoreline level, and we teach people that, that's super important. That's the foundational layer. Then on top of that, there are a few layers that have to do with your focus because the brain can dramatically shift focus from open mindedness to deep, deep focus.

(00:09:55):
Then there's the final layer of ability, which is less science- y, less neuroscience, and more just practical that your ability is regulated by how much reality you know, like do you have the context for the decision or you just know you're supposed to make the decision? People with context have higher ability than people without. The same thing with imagination and logic that if you push those boundaries in your mind further, your ability increases almost disproportionately to how much you've pushed, so these layers just stack on. I think it's approachable, it's simple. It's like, we can all understand, is my safety reward or purpose system active right now? What is my level of focus? What level of connection with reality, reason and imagination do I have right now? Then there's your output as a human or as a team, and all these things are like levers we can pull, which is super fun.

Lenny Rachitsky (00:10:49):
Amazing. Just to summarize here, so we have these three systems, safety, reward, purpose, then our level of focus, and then there's the ability, are we able to actually do the job? Those are the puzzle pieces.

Evan LaPointe (00:11:02):
Exactly.

Lenny Rachitsky (00:11:03):
Where I want to take this is when we work with other people, working with other people is very hard, and some of the struggles people have at work in building product, in running a company and building teams, hiring, all these things, is they often get really frustrated by the way other people operate. Some people want to just start building a thing, some people want to really think about it. Some people are very customer qualitative, anecdote focused, some people are very metrics focused. Some people are very collaborative, want to work in groups, some people are very, I want to work alone. Just first of all, we just talked about here's how the brain works and then there's this idea of people work very differently. Can you just talk a bit about just this idea of why people behave so differently in an effort to help us learn to work better with people that are just like, "Oh, that's so strange. This person wants to just their billing.

Evan LaPointe (00:12:02):
Maybe one of the worst pieces of propaganda that people walk around with in their minds is the phrase we're more similar than we are different. My theory on why we walk around with that phrase or why we're told that phrase, if we zoom in on the situations where we hear that is that we have this theory, it's easier to get along with people that are like us. If we fantasize that this person is like me, then I might get along with them better. When in fact, we should probably be building the muscle that we have the capacity to get along with people that are extremely different than we are. That fourth piece that we talk about in our coursework when we train managers, for example, is personality. We talk about your brain systems, your brain focus, your brain's ability, which sort of paints the picture that humans might be similar to each other and we can activate these things kind of unilaterally.

(00:12:54):
Then we have to drop this bomb at the end, which is, and here's why that doesn't work consistently across different types of people. I know you took our profile, our big five-based profile, and that's just one tool out of many that can help a person understand where on these various spectrum of personality traits and motivations they sit. We often use the metaphor in our training of culinary school that we're more culinary school for human performance instead of cooking class. That helps people conceptualize that I'm used to going to cooking classes in my training, here's how to do a one-on-one, here's how to offer feedback, here's a framework for generating product ideas through to prioritization and backlog. We're like, "Well, what's going on beneath the surface? What are the underlying principles and forces at work that all the stuff that comes to life on the surface really originates from?"

(00:13:50):
In this culinary school metaphor, one of the things that's really important for a chef is to actually understand what are my preferences? What do I like to eat? Because if I don't know what I like, then I assume everybody else likes what I like, then I'm not going to be a very dynamic chef. I'm going to be like, "Everybody likes lots of salt and acidity in their dishes." Then you're going to go to Germany and open a restaurant and be like, "That is absolutely not what we're looking for in this cuisine." Self-awareness is a really important step, not just of culinary school, but for everybody. You sit somewhere on a spectrum, your brain has these pathways and these traffic cops directing traffic in your mind. You have to start with square one with yourself and understand, am I prone to try to say things politely, and so that they're received well? Or am I prone to be super blunt and direct and maybe even mean and harsh? Am I prone to sit back in conversations and let things happen, or am I prone to take over?

(00:14:48):
Am I prone to go to intellectual abstract thinking and try to deconstruct ideas or am I prone to stay very pragmatic? If you don't know who you are and you think that the universe resembles you, then you're going to get super lost in that broader spectrum. I think the big five, I mean there's a bunch of models. You have Myers-Briggs, disk, etc. They're just all imperfect ways of measuring personality, but also, useful despite the fact that they're imperfect and especially useful if you take a growth mentality instead of a justification mentality to reading them. If you say, "okay, I'm low in politeness, I'm super direct." Your justification mentality of that would be like, "Yeah, damn right. I'm awesome that everybody knows what I really mean and how I really feel.' Versus the growth thing, which is like, well, maybe there are situations where I can try a little harder than 0% to phrase things in a way that if we work backwards from the outcome, we want to choose our actions right now, would these actions so direct actually increase or reduce the probability of that outcome?

(00:15:54):
That's when we become more dynamic chefs, more dynamic people. Personality is a broad spectrum and self-awareness is the starting point for the whole thing. The big five model gives you a really good list of attributes to scan yourself through, and then you should be making a game plan for how to do that. Then you can turn your attention to the network of humans you're a part of and say, "Okay, well in what ways, because I'm me, am I so different than these other minds?" How can we create a mesh mentality where thought shifts among the group to fit most naturally? In product work, especially, whether you're a founder, entrepreneur, thinking about product at that level and your team at that level, or you're in the thick of product work pushing your mind and other people's minds to get this right, then you're going to benefit a lot from understanding these traits and these differences.

Lenny Rachitsky (00:16:48):
I think the big unlock here for a lot of people is that the reason you are struggling, getting something done, working with someone, being successful at your company, with your manager, with a partner in your team, is they have a very different way of their brain operating, and so they think in a very different way, they react in different ways. You may think the entire world thinks the way you do, but they don't, and these tests help you see that. To make this super concrete for people, are there a couple of examples or wins you often find that you can share of just ways to use this to become better in your job, say this week? Whether with meetings or convincing someone of something, anything along these lines?

Evan LaPointe (00:17:28):
I think one more layer would be helpful to this, especially if you're a leader or a manager, which is the business world isn't just hand-to-hand combat between a bunch of individuals on the blank matrix loading screen. You're actually in a habitat as a company and your team is like a habitat. I think of companies and teams, almost like little terrariums that we're inside of, and is this terrarium set up with sand and a heat lamp and we're a bunch of frogs, like we're going to turn into frog bacon, simply because we're in this habitat? A lot of it is you want to actually create a habitat or an environment that's predisposed to high-functioning thinking and high-functioning interaction between people.

(00:18:15):
Because if the habitat is working against all of you to begin with, then all the hand-to-hand combat that's going to show up is actually largely a function of you just being in this heat lamp, dry, devoid of life, devoid of productive ways to grapple. That's where a lot of teams and companies sit today, especially more established teams. They've either lost their way in the habitat and haven't really set the scene for good, kind of thinking and interaction, or they just never had that to begin with. Some of this stuff, like when you've talked to a couple of other people in the past, your conversation, the Canva conversation, the Figma conversation both come to mind as like it is super obvious the energy that has gone into the habitat to predispose people to high function.

Lenny Rachitsky (00:19:09):
You're referring to in my interviews with the folks from Figma and Canva.

Evan LaPointe (00:19:13):
Exactly right.

Lenny Rachitsky (00:19:14):
I see. Oh, say more about that mean.

Evan LaPointe (00:19:17):
You think about the, even in the Canva context of coaches instead of managers. I love this, let me back up for just a second. There's a great quote, I think Dan Pink has summarized the problem better than anybody when he said, "There's a mismatch between what science knows and what business does." In that gap, it says, "Well, what is it that business is doing that science knows better?" You can almost look at this as an equation of science knows minus what your business does equals dysfunction. That is a pretty crystal-clear thing. If you take this managers versus coaches, they're taking intuitively, I think. I don't know if they're neuroscientists, but intuitively, I think a lot of great founders understand humans don't work a certain way, and this whole paradigm of managers seems to be failing a lot. This whole paradigm, like mantra, fail faster. Seems to be failing a lot, and mission statements seem to fail a lot.

(00:20:22):
You look at this, science knows business does as a lens to examine yourself through and stuff that fails very often is worth a look. When you look at, okay, do we really want managers, because that seems to fail a lot? Or is there a paradigm that works better for human beings that activates more human potential and hit the nail on the head? If you do the math of Canva, what science knows versus what Canva does, whether they know they're doing it scientifically right or not, the math equals zero. There's no difference between what science knows and what business does in that case. Also, the Figma conversation, I loved the phrase from that conversation, imagination is a hypothesis generation engine, I think is what the word was.

Lenny Rachitsky (00:21:13):
Oh, the Dylan. Yeah, the chat with Dylan.

Evan LaPointe (00:21:14):
I loved that idea. Because when we talk about imagination as a part of ability, we talk about imagination's capacity to generate alternatives for you, that's its purpose. It's not just to doodle in the margins in the middle of boring meetings. That's part of it, it's a side benefit. When you look at imagination's purpose, if you have a great imagination, you always have a lot of choices in life. Mickey Mouse was a choice. It was like a new alternative way to send messages through a talking mouse. Like, that's okay, that's interesting. The other part of the hypothesis generation engine that we focus a lot on is it's not just the ability to generate choices and hypotheses, but it's also the ability to load them into your Oculus headset and walk around a world in which that choice already has been executed. That's akin to vision in a sense that do you have a really good ability to load that one branch of this imaginative tree, this one hypothesis into a simulation and then explore what the world looks like with this in place?

(00:22:23):
If you look at this coaching thing, it's going on at Canva instead of managing, you load that in the simulator and you're like, "Boy, this looks pretty nice. This is higher-performance thing." With advocacy instead of regulation, we have growth. There's a whole bunch of aspects that are inherent in that approach where science, and if you ask a neuroscientist, would that work better? They'd be like, "Oh, hell, yeah. That would work way better." Because it activates this in the brain, it reduces cortisol, it does all these things that science knows work much better. There's a whole list of stuff from very deep to very tactical of things we can do differently that reduce the gap between what you're doing and what science knows and the dysfunction just shrinks and shrinks and shrinks as you do those things.

Lenny Rachitsky (00:23:16):
Are there things that you've found people can change in the way they work based on the way the brain operates, whether it's run better meetings, be better influence? What are some things people can try to do this week that will make them more successful at their work or working with colleagues?

Evan LaPointe (00:23:32):
In the list of what science knows and what business does, everything is in there. Culture is in there, meetings are in there, goals are in there, deadlines are in there, team dynamics, all this stuff is in there. We'll probably just pick a few things out of that very long list. Meetings are a good one. Meetings, I forget what the statistic is, but it's some insane 12-figure amount of, no, not 12, nine-figure, no, 12-figure, hundreds of billions' amount of waste is caught in meetings. We spend gazillions of dollars on waste of time and meetings. For us, like in our programs, the average delta is between 10 and 20%. People save anywhere from a full half of a day to a full day per week of work as a result of just cleaning up the way they're using meetings. Some of that is just the design of meetings, like treat meetings like a product and treat them workflows that should be organized and used intentionally, but a lot of it is inside the meeting, like what's the tactic?

(00:24:38):
Here's something super tactical, which is, meetings, generally speaking, are a combination of priming and decision making, if you look at meetings through the lens of the phases that they are. A lot of meetings skip the priming step altogether. They launched directly into decision making. It would be safe to skip the priming step if we began the meeting under the assumption that everybody here is on the same page, has the same information, and generally speaking, intends for the same outcome. I think that's a ludicrous assumption for most meetings, and yet most people are actually shocked to find out that we're not on the same page even though we literally never have been, and as long as you're on day two plus of working together. It's a crazy thing that we don't do priming, and priming can be simple. It can even be done in the invite. One of the things that's crazy about Outlook and Google is you can put a very terrible useless meeting into Outlook and it will never look at it and be like, this is probably useless.

(00:25:46):
Just like you can go into Trello and put the dumbest project in the company's history into Trello, it will ingest anything you put into it without any discernment as to its value. Now, imagine we're going to have to do this ourselves for now until a better calendar comes out, but imagine if Outlook or Google Calendar or Cron, which now is part of Notion, would just be like, "Uh, uh, uh. What is the point of this meeting?" You could say, "Okay, this is here. This meeting is about the generation of options or creative problem solving or very tactical problem solving or efficiency seeking, or what is the category of conversation we are about to have? What are some of the basic principles that should apply? Are we honoring sacred cows or are we eating sacred cows in this meeting? What is the mode mentality, the priming? How can we all say this is the mindset and the ultimate purpose that applies to the meeting?"

(00:26:52):
You can write that and you can read that in under three minutes. It's not some arduous process. Amazon does it in an arduous process, they're known for that. That's wisdom to know, like we need priming. They're wise enough to realize the need for it. They make that a very robust execution. It doesn't have to be that robust. Skipping priming is pretty bad. Other meetings get the priming and the decision-making backwards. We start to open the meeting. You've heard of diamond-shaped thinking, let's open the meeting with expansionary thought and let's end the second half of the meeting with convergence. Well, we start the meeting instead with convergence, realize that we can't reconcile the various party in the room, their needs for convergence.

(00:27:39):
Then you might hear in the middle of a meeting like, "Well, let's start over again and remember why we're all here." We do the priming in the second half of the meeting just in time for the meeting to end. That's a super obvious thing that people can do, but that people very rarely do in priming. I'm happy to generate a list so we don't have to talk through everything, but maybe make some little PDFs or something that people can download that say, "Here's what great priming looks like." Then when you move to the decision making, here's what great decision making looks like, and that way, you can have a little bit of a guide, and again, do your own math, what science knows what we're doing in this meeting. We're skipping a bunch of steps, that's growing the probability of dysfunction or things will going wrong, and let's shrink that probability instead of growing it.

Lenny Rachitsky (00:28:28):
Amazing. That'd be sweet if you have that. We'll definitely link to that on the show notes. The advice here is make sure when you're starting a meeting, running a meeting, prime everyone around the problem we're trying to solve or we're trying to get out of this meeting, the context, versus just diving into decision making.

Evan LaPointe (00:28:44):
Very notably, the principles that apply. I think that's really, really important, not just what we're here to do, but how we can think about this best. You can even have a debate about the principles, and it's way better to have a debate about the principles than it is to have a debate about the tactics that are rooted in the fact that you have super misaligned principles. If somebody is trying to make the decision with speed in mind and another person is trying to make the decision with accuracy in mind, it is completely inevitable that they're about to have a cat fight in the meeting. It's not resolvable until they come back and revisit the fact that deeper down, we are approaching this in a completely different mentality with completely different objectives.

Lenny Rachitsky (00:29:31):
Awesome. If you end up having these PDFs of waste to prime successfully, that'd be great.

Evan LaPointe (00:29:36):
For sure. Will do.

Lenny Rachitsky (00:29:38):
Okay, great. Other things that people can do to work with better. I know you have some advice on how to influence more effectively. I know you have some advice around strategy and vision, so maybe we go into those two directions.

Evan LaPointe (00:29:50):
Let's start with strategy and vision, because I think it's nice to be better at strategy and vision before you start influencing people. What you'll encounter in life, in your mind, is ideas are swirling. Whether you're generating those ideas or other people are, is your brain is going to sort those ideas into believed, believable, kind of conceivable and inconceivable. You can come up with your own words for that, but that's like a starting point, which is if somebody says something you've already experienced, it's something that is believed to your brain. If we said we should implement an OKR framework and you've experienced it in a prior workplace or you've read all about Google doing it, then you're going to be like, "Yeah, we should. It would clean up a lot of junk around here. Okay, great." Your brain is already in a yes.

(00:30:47):
If it's believable, maybe you're reading Harvard Business Review and you're reading about things that your business has never done, that you've never done, but there's all this evidence that it works and it makes sense to you mechanically, so you're like, "Okay, yeah, I find that believable." Now we're leaning toward yes, or we're still in the yes bucket. Now we get into these unbelievable, yet maybe conceivable. These are the things that seem to be far-fetched. Going back to the Canva conversation, the conversation with Uri that you had. Most of the things that are totally believed by these leaders are unbelievable to most other leaders. We don't need managers? I don't believe it. Now we've shifted the mind from inbuilt kind of tailwind to inbuilt headwind. This is why minds struggle with strategy and with vision, is that every mind based on personality we talked about earlier, that line of demarcation between believed, we all have different lived experience, so the more experience you have, the more believed you have.

(00:32:03):
Then the believable and then the unbelievable, but yet conceivable, these lines shift a lot from person to person. An idea that totally makes sense to Uri, he's probably been in a thousand meetings where other people are like, "That'll never work." Even though obviously, science knows, for example, it totally will. One of the great benefits of science in culinary school is let's not reinvent ideas that are already proven. We already know that certain things activate people's purposeful state and the full brain that seeks comprehension seats deeper problem solving, seeks human connection. Those are known things, and the same thing as the debate about the value of design sits in the strategy and vision. How do we know there's an ROI to a better design here? Well, if you could disprove that instead of proving it, because the last million people who asked this question proved it.

(00:32:54):
If you could disprove it, you'd probably win a Nobel prize for being the first human to disprove something that is like ironclad. Like, we're done. We're done with this debate. That, I think is what we have to recognize in ourselves. Big part of self-awareness is where our unbelievable threshold begins, where our believable threshold ends. Then the inconceivable is like, get out of my office level stuff. A lot of the vision thinking and dialogue that happens inside of businesses directly activates people's inconceivable response without any self-awareness that, that's a personal problem, not a objective problem. I think it's a really, really important thing for companies and individuals to invest in themselves to kind of say, "Do I have the capacity to recognize the situation that I find inconceivable, but that could be totally wrong?" Then we can avoid the months potentially of arguing that sit between us and experimentation.

Evan LaPointe (00:34:00):
... that sit between us and experimentation. So I think that's the starting point for that. And if we were to do paint by numbers on that, what dominoes do you want to knock down? Know your personality, what you're looking for in the Big-5 model which we lean into is openness. If you are low in openness, your brain essentially has abstract, creative, intellectual, complex thinking wired to the pain systems of the brain. That's how your wiring is. As soon as things get abstract, not only are you like, I don't like this, you have a much more visceral negative response to these types of ideas, and you are now going into your pain cave while somebody else in the room may have all that abstract, creative, exploratory thinking wired to their reward systems.

(00:34:55):
So that's something to really know, and vulnerability is the best approach to this because if you think about the domino two, once you know this stuff, then the question is how do we socialize this knowledge in a team? Let's say it's a C suite, a leadership team, a founder and co-founder and the rest of the leadership team. And we work a lot with YC companies on this here, because it's super important. As they hire people, every incremental hire is an increment of psychological diversity, and it changes everything about how these conversations go.

(00:35:27):
So knowing this, okay, what are our options to socialize this knowledge? Vulnerability is the best option. But Bren Brown will sell vulnerability for its own sake, not everybody buys selling vulnerability for its own sake, because it's a scary thing. But it gets a little less scary when we consider how much scarier our alternatives are. I can pretend to hide this, that's my other option, or I can not hide it, be a Tasmanian devil, and then be unapologetic. So those are your three options, and when you realize I can be vulnerable, I can attempt to hide it, or I can be unapologetic, those other two options are ruinous compared to vulnerability.

Lenny Rachitsky (00:36:13):
The thing you said about openness and not being good at big vision, brainstorming, super resonates with me, because that's exactly me. So I took your test, what is it called? What do you call this test, by the way?

Evan LaPointe (00:36:27):
CORE identity is what we call it.

Lenny Rachitsky (00:36:28):
CORE identity test.

Evan LaPointe (00:36:29):
Yeah.

Lenny Rachitsky (00:36:30):
Okay, cool, and we'll link to it in the show notes.

Evan LaPointe (00:36:32):
Okay.

Lenny Rachitsky (00:36:32):
So I took, it's basically the Big-5, agreeableness, conscientiousness, extraversion, openness, and formerly known as neuroticism, now called need for stability. I'm looking at it right here. And I'm actually, and I knew this about myself, I'm pretty low on openness, which I don't like to see, but it very much aligns with exactly what you said, I'm not great at big vision thinking. Like when people propose, say a designer on my team proposes this whole redesign big vision rethink of the way we, I'm like, no. It's my pain cave, like you said, and that's exactly what this test reflects.

(00:37:10):
So I think it's a really powerful example of just understanding this is the way your brain is going to respond to things that are totally out there, inconceivable, or how would you call it? Somewhat conceivable but not necessarily believable, and that being aware that that's how your brain works is really powerful, being aware other people have a very different experience with that is very powerful. And your advice here is one, this combination of this habitat, create this habitat where you have all these versions of people's ways of thinking, where some people are in their happy cave when they're thinking big, and then along those lines, your point about vulnerably sharing, hey, this is me, I am low in openness, people need to understand this on my team, and let's work together to not let that hinder us. Is that right?

Evan LaPointe (00:38:04):
Yeah, absolutely. I mean, because if you think about these ideas as pegs in holes, we're going to take a creativity shaped peg and try to put it through a more pragmatic shaped hole, there's a translation problem there, and it's a huge burden. If the team actually needs to be innovative, it's a huge burden just in terms of time spent on that translation, to translate the visionary strategic ideas that are accurate but are inconceivable into ideas that feel believable for those who need that more grounded thing.

(00:38:45):
And of course the most common scenario here is ROI, which is the classic question to ask about any idea, what's the ROI? Well, if the idea is inherently generating nth order effects instead of first order effects, like what is the ROI of having fresh flowers in the lobby of a Four Seasons hotel? There's two possibilities for the Four Seasons, they either have an answer to that question which satisfies the pragmatic shaped hole, or they have said in their habitat, we don't ask those types of questions because they're a huge waste of time.

(00:39:28):
And if you're thinking about a competitive market, most of the people that you interview are in highly competitive markets, the team that spends less time translating satisfactory language before they move, which inevitably they'll move, and sometimes they'll move because the market forces them to. They spend so much time locked up in the ROI conversation or the justification, the translation conversation, that eventually customers start leaving, employees start leaving, and they're like, oh, okay, it's becoming more believable now. Well, because moved out of the realm of ideas into the physical world that we can see right in front of us.

(00:40:05):
And that team, because they got stuck in the translation phase instead of the experimentation phase, has a huge disadvantage in the market, and if you're competing head-to-head with one team, this is what I loved about the Figma conversation, that habitat inherently is built for speed because the habitat itself, words are tattooed to your brain that are like, we will not spend time in the translation phase, we will not spend much time. And we see this a lot in the interplay between finance departments, product departments, and things like that, where an overpowered CFO can start asking questions for which there are no answers, that just we're dragging the team into a different language that is much more literal than the more experiential language of the business, so you can see this play out all the time.

(00:40:59):
But I think vulnerability is great because if you are sitting in a meeting, you Lenny, and you say, this is not my thing, basically everything you're saying is inconceivable, now I'm being honest with you, nobody's going to hate you for being honest, they're actually going to be glad that you are honest about the gap instead of glad that you are super certain that you are the right human to index off of in the decision-making process.

Lenny Rachitsky (00:41:26):
And the thing you recommend being open about is this is my personality, this is my CORE identity, I don't know the language you'd use, but it's not I think all this is inconceivable, it's I think all this is inconceivable because this is the way I think.

Evan LaPointe (00:41:41):
Absolutely, yeah, unpack the detail, for sure.

Lenny Rachitsky (00:41:42):
Got it.

Evan LaPointe (00:41:43):
Yeah, I mean tell people, this takes my brain, all this abstract and creative future-centric thinking that's not rooted in the concrete is where my brain goes, alarms go off and I'm like, I need something concrete. So if you can give me something concrete, I'm more comfortable, but at this point I have to maybe move into a lot of trust, and trust may be my alternative to agreement, right?

Lenny Rachitsky (00:42:10):
Yeah. And there's also, I imagine, what I always do is I recognize, hey, I'm not amazing at this, let me push myself to be more open to these things and find partners that are really good at this and let them drive the ship more.

Evan LaPointe (00:42:26):
Yeah, and it's great, one of the things that's so cool about the YC teams that we work with is they're so sophisticated and so smart. So even though they might run into this roadblock, A, they're going to do exactly what you just said and they're going to push themselves. You may notice in your profile the dot that you scored is surrounded by rings that represent how hard it is for you to push yourself to think in different ways, to think beyond the home base way of your brain working.

(00:42:55):
Now at a certain point your brain breaks and you move into foreign territory, and there's a level of, I mean, if you are a very conservative person and somebody's like, "Let's go to Burning Man," that will break your brain. You don't go all the way to the other side of the spectrum necessarily.

Lenny Rachitsky (00:43:13):
For the record, I've been four times, even though I'm apparently low in openness.

Evan LaPointe (00:43:17):
Perfect, and there's lots of reasons to go.

Lenny Rachitsky (00:43:20):
Got married at Burning Man. Makes me feel better about my low percentile.

Evan LaPointe (00:43:25):
But you're pushing your brain. I mean, Burning Man's actually a great example because there are a bunch of different reasons you might go. And if you go for one reason, then you're exposed to the other reasons. And that may be interesting, and you may kind of venture closer to those other reasons. You may be like, I'm going to stay in my reason bubble within the greater context of this place.

(00:43:44):
So there's a whole bunch of... And business is no different, you can say, okay, I'm going to push myself, and I may get into these places that go beyond my brain's flexibility, where the elastic band reaches its limits, and then from there I'll trust people and I'll have people, what I was going to mention about the YC founders is so many of them are so smart that they're really able to efficiently translate what they see beyond where your band stretches into the language you feel comfortable with, quickly. Other teams do that really badly and they just accuse you of, "Why can't you see this?" And then you get even more stuck.

Lenny Rachitsky (00:44:26):
How much shift have you seen in people, say they take this test and they're like, as I am, 23rd percentile in openness, do you see people move meaningfully across this if they work on these sorts of things, or is this just like, here's who you are, you're not going to change significantly?

Evan LaPointe (00:44:41):
Personally I'm more concerned with the effect on teams than on people, because if you look at this through the... I've been a four time founder, and if I look at this through how is my company working? How are my teams working? I don't need all the individuals to get to perfect, I need, especially in cases where there's this translation issue where a team is working on something and some part of that team is saying, "Let's stop here and let's dwell here." If they can move enough that the team, the effect on the team is now freed up, that's what we really feel as a business.

(00:45:23):
So to answer your question directly, people can move a lot, especially through the first three rings of that range that we depict, really, really well. Self-awareness is actually kind of the key, and self-awareness and self-consciousness, the difference here is that self-awareness is simply being intentional with your brain, whereas self-consciousness is being worried about your brain. We don't want people to be worried about their brains and insecure, we just want you to say, this is a situation in which my brain can work this way, and this is a situation where I want to push myself.

(00:45:56):
So it's being intentional, and we talked a little bit before this episode about this instinct versus intellect duality in the mind, and essentially you're just using your intellect to either verify or improve your instinct. You're always going to have instinctive responses about risk and fear and uncertainty and doubt and need for data, and all these types of things, but then your intellect can come in and watch that part of your brain thinking and say, you're super worried about the risk of this, but it's actually pretty low stakes for us to jump in and try. So your need to stabilize that is a little misplaced, and your intellect, that's really what you're doing is saying, how much do people change? I don't really worry too much about how much they change, it's more about how much they can spot with their intellect something that's misfit to the situation, and then take what they're motivated to do, and what they choose to do, and separate them. It doesn't matter if we change your motivations, if your choice of behavior and your underlying motivation can be different from each other, that's awesome, those people are super. And we all know people like that, where you're like, I know this person is uncomfortable right now, but they're totally making it work, and I really appreciate that.

Lenny Rachitsky (00:47:12):
Yeah, part of the reason I ask is, I was talking to you about this before we started recording, I want 99th percentile at all these, I just want to nail this. And I know that's not how it works, I know you have strengths, you have weaknesses, you can't be amazing at everything. But that's funny my mind goes there.

(00:47:28):
Just to close the loop on this advice around getting better at vision and strategy, if I were to reflect back what I'm hearing its be very self-aware about what you are not strong at, say openness. Is that specifically the one to focus on if you're trying to figure out how to get better vision and strategy?

Evan LaPointe (00:47:46):
So there's a whole bunch of stuff... Well, let me try to make the list simple. Openness is the biggest one because it is essentially your tolerance of vision and strategy, and the lower that is, the lower you will tolerate the abstract pieces of the puzzle, for sure. The outlandish and purely creative and rules-breaking components of strategy and vision, lack of precedence, those types of things. Now the other thing to look out for is as your conscientiousness rises, which is essentially your desire to be efficient, effective, busy, not waste time.

Lenny Rachitsky (00:48:23):
I'm high on that one.

Evan LaPointe (00:48:25):
Yeah, structured and organized, that is another contributor in the negative, which is it's objectively great to be a conscientious person, there are so many benefits, until we have to waste time productively, or we have to break order in organization. And then that strength that four days a week, or 28 days a month is great for you, on those days where we go and have the offsite and say, what if we blew it all up, to your example of new design, new website, blow it all up, start over again, different direction, that's where the conscientiousness is going to be like, why are we doing this? Why are we having this conversation? What's the need? This is inefficient, I could be spending my time doing something else.

(00:49:09):
And sometimes that'll express itself even in meetings of, I was in a meeting one time after we were acquired, this was eight or nine years ago now, and when you're a founder and you get acquired, there's a new flavor of habitat that you find yourself in with very new rituals. And one of the rituals that I find myself around a lot was the ritual of saying, we can't talk about this for the rest of our lives. And we would be about six minutes into a meeting when somebody would drop the, "We can't talk about this for the rest of our lives" line, and I would look at my watch and be like, "I didn't realize that you were terminal, I mean, why are you even in this meeting if you're about to die?"

(00:49:53):
Because my take on this is we are super far away from the rest of our lives right now, why are you saying that we can't talk about something for six minutes when the diminishing return of added information in the priming of this meeting, to use that again, you knowing X quadruples your decision quality, and you are resisting knowing X. Now we're going to hit a point where you knowing Y, Z, etc, we've hit a diminishing return and now I'm improving your decision quality by 1% instead of by 4x. But we haven't established any sensitivity in this room to the diminishing return curve of incremental thought and incremental information. And this is like a new habitat, I'm like, in this habitat do people really hate thought? Do people really consider themselves to be the police that watch the mean streets of intellectualism for any activity? It's just kind of crazy. But yeah, that's kind of the practical side of this, is you got to watch out and you got to be careful, and that's why I habitat is such a big deal because that's a perfect example of a well-intentioned room with mostly people that are there for the right reasons and the right outcomes, but where this normalness of saying a phrase like that, or saying, "I disagree." Same meeting person goes, "I completely disagree," and I was like, "With everything?" "Absolutely everything." And I go, so let's look at the meta, the overhead camera of this meeting.

(00:51:33):
This was the initiation of combat, that's what the brain is seeing. All the brains in the room are like, oh, fight, right? And now what are our objectives? My objective now becomes win, their objective, because they've taken a huge risk of saying, I disagree with everything, becomes win, and because they are disagreeing with a lot of stuff that they don't understand, the inevitability is they're about to be annihilated in this room where they have both said, we can't talk about this forever, and now put all of their chips onto the table to say, "I completely disagree," instead of, "I have a question," or, "Can we pull that thread?" Or, "I don't see how these dots connect."

(00:52:15):
So that on a super tactical level, there's things we say that activate the amygdala, the combat mode of the brain, versus a different choice of phrase which is going to activate the prefrontal cortex which is like, "Hey Lenny, you're connecting these two dots, I'm not seeing how they're connected," logic, now let's activate the prefrontal cortex with this sentence instead of, "Lenny, that's dumb, I completely disagree," let's activate the amygdala instead.

Lenny Rachitsky (00:52:43):
I want to talk about this habitat point you're making which I think is really important, but just to close the loop on the strategy vision piece, so just to give people some very tactical advice is, basically understand your personality, maybe take this CORE identity test, or something like that, understand if you're low in openness and high-end conscientiousness, maybe you're not amazing at vision and it's going to be hard for you to think big and think of it-

Evan LaPointe (00:53:06):
Yeah, your brain is just going to feel agitated when you're around vision. But, I mean, you can still do it, right? You can still ask people to translate. The key tactic is, okay, it's not this you're predestined to suck, it's more if you're low and openness, especially if you're also high in conscientiousness, then recognize your native language for ideas is a mismatch for the native language of vision and really, really good strategy.

(00:53:35):
And then you can be open about that and you can ask for some translations, and you can ask for... I mean, trust doesn't have to be non-participation, you can actually say, it would help me trust if you could explain this gap. A great example would be a second order effect, why should we have awesome documentation? How are we going to make more money if we have awesome documentation? Great question, don't be hostile in the way you asked it, but just help me understand, what thread are we pulling? Well, we're pulling this thread of customer satisfaction, retention, recommendation, et cetera, Stripe is really good at this, especially from the early days, that great documentation justifies all sorts of second order effects that then will lead us to this first order effect you're asking about.

Lenny Rachitsky (00:54:20):
Awesome, okay, that's really great. And I was going to go one direction, but I want to talk about this real quick. Something that comes up a lot on this podcast is the power of leaning into strengths and not feeling like you have to be amazing at everything, and that in this example, I have a low openness, high conscientiousness, I can still be very successful in the role by, in my opinion, leaning into things I'm actually really strong at, say conscientiousness, and I'm also high in agreeableness. I don't like the sound of that. Thoughts on just, it's okay if you're not amazing at vision because your openness is low, but you can be better at other stuff and together you can be really successful no matter how your personality.

Evan LaPointe (00:55:03):
Absolutely right, yeah. I mean, the truth is we look at, taking that Canva example of coaches and managers, not only does that change the way an employee feels about the way this connection they have is invested in them, but it also changes inherently a lot of the meeting dynamics and teaming dynamics from hierarchical feeling things manager to more mesh based intellect. And within the mesh, you don't have to worry too much about the hierarchy anymore. You can say, this is the nature of my contribution.

(00:55:39):
So even in the vision and strategy piece, maybe your contributions to idea generation, there are going to be some, and they're probably going to be good. But those are not ideas to protect in the state that you brought them to the table, they're ideas to set on the table so that people can surround them and improve them. And then as other people contribute ideas that aren't as natural to you, kind of just realize we're not in the phase yet of judging and ranking and prioritizing these ideas, that's not where we are in the overall storyline. So let it happen, and then if you can improve those ideas, improve them.

(00:56:15):
And once ideas have that early stage, that kind of like what Jony Ive described as the infancy of an idea, when it's really weak and delicate and susceptible, if you can nurture that idea to adolescence where it has a little bit of ability to defend itself, then now you're in a situation where your conscientiousness can start to think about things like how would we resource this? What sequencing makes the most sense? What is the ROI of these things relative to each other? And consider the second and third order effects, and so on. And what would the project plans, and to your point of being both conscientious and agreeable, you are this master of coordination and alignment naturally.

(00:56:56):
So when that phase of the project begins and we have to get people bought in, high functioning together, getting on the same page, staying focused, getting the project done, all of the people that were good at the beginning with all the vision and strategy, they are just a complete disaster in that phase. That's just how things really work in the real world, and I think we're so, again, focused, like we talked about at the beginning, we alluded to the fact you have to unpack enough complexity. I love the Einstein quote, " Make things as simple as possible but no simpler," and we've made things way simpler than possible in business by saying this is the right way of doing the whole thing.

(00:57:41):
It's like, no, no, no, if you've ever lived a day in real life, building a real product, the dynamics shift a lot throughout the course of product life cycle, as an example, or really any life cycle as an example. And the peak humans as the dynamics shift are very different, peak humans. Lenny is awesome here, contributes here 10%, contributes here 98%. Evan contributes 98% here, please get Evan out of the room when it comes to these meetings, that's great. And yes, we should lean into our strengths, but not so much that we don't know our weaknesses, because another human strength on your team is the patch for the bug of your weakness. And we run buggy software in companies and we say, "Oh, I am leaning into my strengths, I don't need to worry about my weaknesses," well, then you become the person who needs everything translated into your language because when your weakness flares its head up, it slows everybody else down.

(00:58:41):
So it's really, just from an operations business fluidity perspective, a team that is highly unaware of its weaknesses is going to have a lot of slowness and a lot of problems as a result of that. They don't have to fix all their weaknesses, but be aware of them and know who is a patch to your weakness.

Lenny Rachitsky (00:58:58):
Evan, this is so interesting. I love that we're digging deep on this. Is there one tactical thing you could recommend for someone to become better at openness in, say, a brainstorming experience when they're doing vision, or when they're low at this, say me.

Evan LaPointe (00:59:13):
I think the best exercise for a conscientious person especially to feel more open is to become obsessed with reverse engineering. And it's to say, there's two forms of reverse engineering that I think are really helpful here. Number one would be reverse engineering against a desired outcome, to truly understand the inputs that generate that outcome. And if we think about that at a big level, like, okay, we want to win a market, what are the real inputs to deconstruct that outcome and understand what our strategy should look like to attack all of the most relevant inputs that generate that outcome? I think that's the specific form.

(00:59:55):
And then at a super tactical level, if you want to give feedback to somebody, and let's say, for me, I'm low in politeness, you're probably much higher in politeness than I am, and I struggled for years with feedback to generate the intended outcome. I delivered the feedback, but the delivery wasn't the intended outcome, and the way that I delivered it actually reduced the probability of the intended outcome because I was being too impolite, too direct in many cases, too harsh. And what does harshness do to the brain? Well, that's crystal clear. So what I was doing and what science knows were very different things, and that's why I failed in those cases.

(01:00:35):
But as soon as I started closing the gap and realized I need to try harder to think about the story arc of this feedback, that becomes clearest to me how to do it when I have the intended outcome in mind for the feedback, I really would like this person to start turning the corner on this particular way of thinking. If you and I worked together and it was about openness, we'd be like, what are some things that I could do right now to increment and set the stage for a big shift in openness as time goes on that you are bought into? And that's a very, if I'm impolite and be like, "Lenny, what's your problem? Why can't you do this? Everybody else can do this."

(01:01:13):
Your willingness to start turning that corner, I mean, it may be there, the safety system is activated, like, oh, bad things could happen if I don't do this, but I don't want your safety system to motivate this change.I mean, in most cases, that's an optics based change instead of a material change that will occur. And that's why a lot of people, accountability is a great example, asking for accountability is the best way to not get it, because asking for accountability activates people's safety systems, or especially saying, "I'm going to hold people accountable." Then everybody's like, oh, great, we should set up a whole movie set of facade houses that pretend everything's great with no substance behind them, and that's why so many companies end up that way. But yeah, I would say that's the tactical.

(01:01:58):
The second thing to understand about openness and reverse engineering is just situational awareness. Very few conscientious people spend, in my opinion, as a very open person, enough time immersing themselves in the reality that is every day situational awareness necessary to do their job. Simplest example of this is how many executives have ever talked to N greater than five customers? That is a... Because, well, I'm busy. I got a lot of stuff to do, I don't have time to go take a world tour, which is like we don't have the rest of our lives to talk about this. I'm not asking you to take a world tour, I'm asking you to stuff into your brain enough situational awareness that the decisions you make every day that affect all those people you're not talking to are considering those people that you're not talking to.

(01:02:49):
So less about an intended specific outcome in this case, and more about, do I really know the... I would think about this as if we think about aeronautical engineering, do I actually have an understanding of the conditions, the flight conditions, that I'm in every day in order to fly really well? And the answer to that for a lot of people is no. So reverse engineering is probably the whole category. I don't know if that makes enough tactical sense, I'm happy to be more descriptive, but that's the category I think is have you reversed engineered how to get outcomes and have you reversed engineered to predispose your mind to come up with really good ideas and good decisions, as opposed to come up with decisions that are super disconnected from reality.

(01:03:37):
Great example being PLG, I mean, if you haven't done enough situational awareness work, you have no idea if PLG is a remotely viable strategy for growing your business. If it's remotely relevant strategy for growing your business. And company after company after company has leadership team obsessed with this concept that in principle we should be able to let people just sign up and swipe a credit card and onboard and great. No, we have a hyper technical solution, that is never going to happen, or that's not the way they do budget, or there could be any number of ways that that's not going to work out, and those are just some concrete examples.

Lenny Rachitsky (01:04:18):
This episode is brought to you by Eppo. Eppo is a next generation AB testing and feature management platform built by alums of Airbnb and Snowflake for modern growth teams. Companies like Twitch, Miro, ClickUp, and DraftKings rely on Eppo to power their experiments. Experimentation is increasingly essential for driving growth and for understanding the performance of new features, and Eppo helps you increase experimentation velocity while unlocking rigorous deep analysis in a way that no other commercial tool does.

(01:04:49):
When I was at Airbnb, one of the things that I loved most was our experimentation platform, where I could set up experiments easily, troubleshoot issues, and analyze performance all on my own. Eppo does all that and more, with advanced statistical methods that can help you shave weeks off experiment time, and accessible UI for diving deeper into performance and out of the box reporting that helps you avoid annoying prolonged analytic cycles. Eppo also makes it easy for you to share experiment insights with your team, sparking new ideas for the AB testing flywheel. Eppo powers experimentation across every use case, including product, growth, machine learning, monetization, and email marketing. Check out Eppo at geteppo.com/Lenny, and 10x your experiment velocity. That's geteppo.com/Lenny.

(01:05:38):
It feels like there's a fractal of stuff we could talk about and endless threads of things that I want to dig into. Let me shift a little bit to influence, we mentioned this a little bit earlier. I know you have a bunch of awesome advice on how to build your skill at becoming more influential, that's something a lot of listeners of the podcast, or product managers, also founders, need the skill. Who doesn't need to become better influencers? What can we learn about how to become better influencers?

Evan LaPointe (01:06:05):
We'll probably unpack a second topic and open up an off ramp here right at the beginning, but there's two things, there's influence itself and then there's relationships, and we should probably talk a little bit about relationships. Trying to exert influence through a dysfunctional relationship is not going to go great. And most human beings, especially when they go to work, are pretty out of sorts when it comes to relationships.

(01:06:36):
And you even hear crazy mantra like we have to each other to work together, which are like, good luck with that. I mean, just watch a text message pop up on a phone of a person who doesn't like you and watch their response time to the text message, or their Slack message, or whatever. I mean, you're talking about you've built in a multi-day, at least multi-hour delay into responsiveness purely because the relationship isn't good, and then you compound that effect over whatever size your company is. That's massive operational inefficiency just because I don't want to respond to Evan right now. So that's the one piece.

(01:07:19):
Now assuming the relationship is in place, and we'll come back to that and talk about that because a whole very actionable framework to unpack, assuming the relationship is good, I think the starting point for influence is to choose your character and choose your mode. It's almost like you're playing Elden Ring or some video game, and you're going to be like, am I going to influence him this way as the hero or the exemplar of these things, or am I going to influence through back channels, what is my character? And everybody for your personality has a natural fit for the character you're going to select as this mode of influence, and then you're going to pick a speed of influence, which is slow, moderate, or fast.

Evan LaPointe (01:08:00):
Then you're going to pick a speed of influence, which is slow, moderate, or fast. The habitat can help a lot with this. If a founder is listening to this and you haven't created a habitat where fast influence is easy and the permission isn't there, then you're slowing the company down inadvertently by just not clarifying this with the team. So slow influence is the we'll let them find out the hard way influence. They're going off a cliff, we know they're going off a cliff. And a lot of times we find ourselves in what's called the Abilene paradox.

(01:08:39):
The Abilene paradox is where everybody in the room knows it's a bad idea, but we're all like "We're in." And the classic Abilene paradox kind of if you look up memes on Google, it'll be like the dad thinks that the kids might want to go camping. Mom doesn't want to go camping, the kids don't want to go camping. Dad also doesn't really want to go camping, but everybody's like, "Dad probably wants us to go camping, so let's give it a go." And they all go and don't enjoy it. And we see that play out all the time.

(01:09:09):
And a lot of people will just say, "I can't do anything. I don't have any influence in this case. We're just going to let him fail and they'll learn." Or this impolite person like me giving feedback the wrong way years in the past, I'm not going to sit Evan down and talk to him about this. He'll figure out on his own through failure that this doesn't work. And that can take months, that can take years, that can take a lifetime for people to learn the slow way. And it is a form of influence. You are being intentional to say, I think the world will create enough failure that adaptation will occur. That is a form of influence, just the slowest one.

(01:09:48):
And a lot of people listening probably realize, "Oh, that's what I'm doing. How can I go way faster than just letting things fail?" So that's where moderate influence comes in. And a great book to read for a moderate influence is the Challenger Sale. And in the Challenger Sale, what we're looking at is the concept of teaching people something. And then when they live with this new knowledge, they'll see things that they weren't seeing before. So for example, in the feedback example that we can keep using over and over again through this is, "Hey Evan, you might want to notice people's body language while you're saying these things and here's some signs to look out for that when you've done this and you get this, that's probably a sign that people are bought in and still with you. And when you see this, that's probably a sign that people are pushing back."

(01:10:37):
And you can ask this question in that moment and you'll probably hear answers like this. So you're like giving somebody a tool that their future is going to unpack. And the Challenger Sale kind of assumes a long enough sales cycle where you're not going to land the sale in the meeting, you're not trying to close them right there. You'll teach them some stuff and you'll, "Hey, if you see this stuff, that's a pretty clear sign that you need to take action. So why don't we call you in 30 days, and 30 days later we get on phone, "Hey, have you been seeing this?" And they'll go, "Everywhere I look, I can't not see it now."

(01:11:13):
And that's how you influence a person in a few days, a few weeks, maybe a few months at worst, way faster than letting them fail.

Lenny Rachitsky (01:11:22):
We actually had, I don't know if you know this, we had the author of that book on the podcast, Matt Dixon, I think his name. And the Challenger Sale, the idea there is challenge their perspective and view on what is actually real about the market and what they need.

Evan LaPointe (01:11:36):
Exactly. Yeah. I think yes, there's the challenge component to it, but I think the underappreciated piece of that methodology is that you're still letting that person see the world, but you've given them new information that is breaking some calcification in their brain challenge. It's not the moment of the challenge where all the magic happens. There's moments that occur later that continue kind of putting that calcium, lime and rust melting formula on this expectation or this kind of decision in their mind to the point where sometimes they'll turn around and be like, "Thank you for even telling me this."

Lenny Rachitsky (01:12:19):
So the advice here is if you're trying to influence someone, try to figure out what they don't know. Find information that you know they may not know because once they know that and they may be like, "Oh wow, I totally see what you're saying."

Evan LaPointe (01:12:33):
Yeah, exactly right. And let them know it and let them live with it. Don't cram it down their throat and make them accept it If they live with it just a little bit, even just a couple days, that might be enough to come back to a much softer conversation.

Lenny Rachitsky (01:12:47):
Does this connect to what you said earlier, which I love this idea of pick a character, like pick your influence style based on your personality, whether it's back channeling and that makes me think of a very specific person. He's coming on the podcast actually, he's this Jedi that just gets people aligned but very behind the scenes, very the meetings before the meetings. So that's one character or it's just telling a compelling story probably in a deck. Or there's other character I guess. Does this idea of sharing information, is that a type of character or is that just something that everyone should just do because a really effective strategy?

Evan LaPointe (01:13:27):
I like the idea of intentionality in just about everything. Are we letting trade winds push us into certain things or are we actually making choices? And I think that step of being intentional about your style and this kind of notion of a character is a wise step to take so that you can kind of have some guardrails as you go through this and some consistency. It helps other people understand the role you're playing in influence. If you are consistently coming from the same place, you're about that style, like I want to try to influence this organization by doing this way and you're going to see that from me over and over and over again.

(01:14:07):
You kind of have given yourself a little permission and also you can get some buy-in from people. If you do want be more the barbarian kind of approach, you can say, "Hey, I'm the devil's advocate approach, or I'm the break it and see if it still stands after I hit it really hard with a sledgehammer kind of guy." Is it okay if I do that over and over and over again? And now you've bought future you the permission to approach things in certain ways that would yield meaningfully different influence outcomes, like meaningfully different. I was able to do this and it accelerated something.

Lenny Rachitsky (01:14:40):
So the way I am hearing this is there are many ways to get what you want, think about your personality style and find the path that is most aligned with the way you operate.

Evan LaPointe (01:14:52):
Exactly.

Lenny Rachitsky (01:14:52):
Whether it's behind the scenes, whether it's a compelling story. Awesome. So this character is basically figure out what your... It kind of comes back to leverage your strengths, what are you good at? And use that channel to convince people of the thing you want them to be convinced of.

Evan LaPointe (01:15:08):
Yep, absolutely.

Lenny Rachitsky (01:15:11):
My mind goes to what are the list of ways, what are the character options in this list when I'm opening up the game and choosing? You went through a few, but just to give people like, oh, okay, I see I could try it this way. Is there a small list you could share of just like here's ways you could try approaching influence.

Evan LaPointe (01:15:27):
Probably the dimensions are most valuable to people. I would say one of the dimensions is compassion, which is do I want to influence by trying to help people, by trying to make sure that we get it right and that people get value. And then the permission I'm seeking there is can I ask questions about why are we not thinking about the user right now? Why are we not concerned with the value they're getting and challenge us in that way?

(01:15:59):
I think there are characters based on logic and even belief, which is I would like to be the one to insert more knowledge and insert more causality into conversations and challenge causality in conversations to make us think harder and challenge what we believe and break up the sacred cows of the stuff we walked in the meeting with so that we feel differently about things walking out of meetings.

(01:16:27):
So I think there's a bunch of different very useful dimensions. One could be very creativity based. If you follow this big five format, they're kind of spelled out for you. Enthusiasm, interesting dimension. I want to challenge us through the lens of what do people get excited about? What makes people feel good? Does this make people feel good? And are there tweaks we could make to the product or this marketing campaign or whatever.

(01:16:54):
Look at what Siki just did with Runway. I mean I love that guy so much and there's so many components of his character and obviously the characters he surrounded himself with that contribute to really next level stuff. And they're definitely challenging each other using these dimensions of compassion to be the character of caregiver or the character of protector. And so there's a bunch of different ways you could turn those dimensions into characters.

(01:17:28):
But I think when you see the value of each of those perspectives, especially in product, I'm a really big fan of product. If you have dysfunctionally high compassion, dysfunctionally high openness, you have internal rewards and motivations to explore regions of product that other minds aren't exploring as intuitively. And you don't have to have the whole deck to be amazing at product. But you have some unfair advantages if you are super prone to reverse engineering just by your nature. You are going to be more situationally aware and probably make a series of vastly better decisions than the team that has a lot less situational awareness than you do. It's a huge advantage.

(01:18:16):
But when it comes to the concept of influence. I mean figuring out these dimensions that define who you are and then using them to kind of say, "I want the permission to ask a series of questions and challenge our thinking through this very intuitive strength that I have." Can we all see the value in that or do I need to further sell myself? And then you'll find you can take on that character and play that role really well.

Lenny Rachitsky (01:18:45):
I imagine the ultimate unlock is that combined with what is that person's personality style and what is the best way they receive information, which is a little harder. Because you can't force them to take some tests and you can't make them give you the results. But I know a lot of teams do these tests together as a team and share the results. And so it's I guess a reminder of just that's really powerful if you and your team, especially the execs at company.

Evan LaPointe (01:19:09):
Yeah, exactly. And when you move into this vulnerability out of your three choices state, we don't need a bunch of data for that to work really well. If you said, "Hey, I'm not super strong at this," and the rest of the room was like, well "Wait, this other person's super awesome at this, why don't not the two of you work together," then it's like under 30 seconds we've unlocked potential that wasn't there.

(01:19:34):
So you want to get business.... I kind of think of extending the video game metaphor. Not only are we choosing our characters or we are a certain character, but the business has a difficulty setting that we chose based on the habitat. And I've worked in and with way too many companies where we are playing the game in nightmare and every enemy takes a thousand shotgun shells to bring down instead of just switching the difficulty setting to easy, which is like the enemies somehow become our friends as we go through this journey.

(01:20:06):
I mean, it really can be that transformative, especially with a case like yours that you talked about. Okay, I am not as high in openness. I'm very high in conscientiousness. If I can admit this and ask different types of questions, everybody else in the room will be like the difficulty setting of this just went to zero and the speed of it just went to way higher than it used to be.

(01:20:32):
And we underestimate this kind of less concrete part of the business world. And I mean that's the genesis of this whole business that I was crazy enough to start after starting other companies in the past, which is like we are underestimating how much of our operational reality is a function of our human reality. And are we doing enough? Are we doing the right things to close the gap between what science knows and what business does? And do we even know what the science is? Have we educated ourselves to close the gap? And then it becomes super obvious, oh, this makes a lot of sense to be open and find the patch to my bug. And here we go.

Lenny Rachitsky (01:21:13):
This fractal of topics continues to grow. I'm trying to contain it. There's three things I want to try to talk about in the rest of our chat, that stuff we've touched on that I think will be really useful to people. One is relationships. You mentioned there's more to talk about there just how to build great relationships. Two is I want to come back to the habitat and building a habitat that is very conducive to innovation and speed and success and those sorts of things. And then I want to talk about focus. We talked a bit about just how important focus is and how differently our brains operate in different states of focus. So maybe we start with the relationship piece just because that connects to what we were just talking about of how do we strengthen relationships, create better relationships within our teams.

Evan LaPointe (01:21:53):
Yeah, so we were talking about relationships kind of as this off ramp or this kind of sidecar to influence. And real quickly the fast mode of influence and relationships goes really well together. So we talked about the slow and the moderate. The fast mode of influence is cognitive dissonance. It's essentially saying in the moment, I'm not going to wait for you to experience anything. It's saying in the moment, how does this formula compute? Explain to me, Evan, how you being too blunt in feedback is going to end up in a human being changing. Why do you believe that?

(01:22:29):
And especially it's that second phrase of why do you believe that drill below the behavior down into the belief. What do you believe that has you doing this? And then we can explore how preposterous the belief itself is, which then bubbles up to the surface level of this.

(01:22:47):
And if in the environment, the habitat's a huge component of this as our relationships, which is if you have great relationships where people trust each other enough to have this kind of cognitive dissonance conversation, and we have a habitat that is very clear that we are free to discuss cognitive dissonance and logical disconnects, that is really important to do. Then you activate fast influence mode basically. So that's a really important thing. And then as you transition to relationships, well what are... The question that everybody kind of glosses over in my opinion is what is a relationship? I don't know how you feel about answering that question, but it's a really hard-

Lenny Rachitsky (01:23:31):
I would just go to ChatGPT. What is a relationship?

Evan LaPointe (01:23:33):
Exactly, right. Yeah. At this point we have some help that we didn't use to have. But the other thing that goes along with what is a relationship is how good is my relationship with person X? Like, you and I both know Shreyas and how good is our relationship? I would say it's awesome. Why is it awesome? I don't know. It just feels great. So let's double click on a good definition and a good framework because once you actually know why a relationship feels great, that example or why a relationship feels super difficult, now we can start to build some strategies, some actual action plans for them.

(01:24:14):
So what we propose to people is if you take that third component of your brain ability, that is one piece of your relationships, especially your professional relationships. So if you know an engineer and you have an idea of something you want to build and they have the ability to build it, their ability and their utility to you is a function of your relationship and it will contribute to the positive or negative force that you feel in that relationship. Like, wow, this person has a lot of ability. My appreciation is higher, my faith in them is higher, my cooperation with them is higher.

(01:24:50):
If you question a person's ability or they've proven that ability is kind of unreliable, those things start to kind of vector downwards and we will pick on Shreyas through this as a good example? Because I think most of the people watching also know him. What is his ability? What is his utility? As high as I've ever seen. I mean every conversation he's intellectually conceptually additive to. You're better after you've talked to him every time. At least that's been my experience with him.

(01:25:20):
And we all know people like that, with various fields and various abilities. So that's one piece that's really important. And why as an individual, it's so important to invest in your ability because it is so integral to every relationship you have, particularly professional relationships and your ability, knowledge, your reasoning, your imagination, your skill set, these are all incrementable facets of you.

(01:25:50):
And that's really, really key. Now here's the plot twist. Your ability is actually not the most important part of a relationship, biologically speaking. There's two more that matter quite a bit more. And the surprise ending is that the third one matters the most, which is scary in some cases.

(01:26:11):
The second factor of relationships is trust. So trust in the brain. If we go very primitive back to the amygdala that we talked about earlier, trust is simply risk. Human level risk and trust can span from strongly negative to strongly positive in a relationship. And we felt that full range with different people in our lives. Strongly negative trust is the brain saying, this person is dangerous to me. They're very likely to try to undermine me. They're very likely to not deliver something. Personal harm will occur by essentially kind of interacting in this relationship.

(01:26:51):
And then on the other side of trust, we kind of try to create some levels to this to keep it clean. And the fractal continues to grow a little bit, but we'll try to keep this simple. But I like to think of trust one, two and three. Three distinct levels of trust. And trust one is, let's say we're having a cookout. Trust one is Lenny, could you please bring the chips, ideally sealed, but it's a delegation of a simple non-critical task knowing that it is likely to get done and get done decently well. But it's not like this huge level of trust. It's the people that we work with where this type of delegation, and especially if people delegate under the thesis of "I want to do the high value work, so let me put the low value work on other people." That's all the low value work that we put on other people, and it allows us to purify our focus on the high value work, and we don't need all the low value work to go beautifully well or be artistically brilliant.

(01:27:53):
So trust two is when we step up to almost like "I need to do this myself. Is there anybody who could do it as well as me?" That there's no risk to me having them do it instead of me doing it. And that's where you get true scalability of teams. So if you can trust people enough, your brain's assessment of risk of giving this task to someone else or giving this knowledge even to somebody else, that they'll treat it the way you would treat it, is a significantly higher positive trust that you can feel in a relationship.

(01:28:26):
And then finally, trust three is when we do hit these breakpoints in our brain where we say the way your mind works is beyond the way my mind works on this topic. So the classic example at the cookout would be if Wolfgang Puck was a neighbor, we're going to have Wolfgang Puck do all the most critical stuff and maybe even set up the music and the decor and whatever. Or another example would be like when Steven Spielberg has John Williams score a film, he's not hoping John will do it as well as Steven would do it. He's saying, "Just send me the bill. Try not to go too crazy." But he is not going to sit down with the invoice and be like, "Why did you need 13 horns instead of 11?" John just gets to do what John does because there's so much trust in this kind of beyond my event horizon kind of risk. It would be riskier for me to do it than for him to do it or her to do it, right?

(01:29:25):
So that's kind of the level, but that matters more to a human being because the safety system, if it activates, your utility is sunk. So if you're an awesome engineer but you damage people, it doesn't matter that you're an awesome engineer because in the social network, the mesh of your organization, you are a node that has a protective covering around it. Information is not flowing to you the way it would normally, and delegation is not flowing to you and access is not flowing to you the way it would normally. So you are a kind of protected, deactivated, sequestered node of the mesh at this point in time. And a lot of people really don't get that.

Lenny Rachitsky (01:30:12):
Yeah, that's a really good way of visualizing.

Evan LaPointe (01:30:16):
And then here's the surprise ending. The last piece of every relationship that you have is appeal. Appeal is how your brain interprets the shared experiences you have with other people. Whether or not you look forward to being around that person, whether or not you like their style, the feel of what shared experiences really are. And if you think about, let's pick on Shreyas one last time. What is his ability and utility? Off the charts. To what extent can he be trusted? Trust three, off the charts. Will he ever damage somebody? I mean, not to my knowledge. He may have some really dark past that we don't know about, but as far as I've seen, not a lot of damage in his wake. And then thirdly, what kind of experience is he? He's an extraordinarily positive experience. So he naturally accumulates great relationship after great relationship after great relationship.

(01:31:15):
And again, if you're that great engineer with a ton of ability, now let's flip the middle dimension. And we trust you a lot, but you're a horrible experience. Are you coming to our offsite? Are you in this meeting? No, you're gone. We don't want you there. You're like a hurricane. So biologically speaking, the biggest bug in our programming as we transfer this to the business context is what makes the most sense in business is the most, if it's a meritocracy, the best people with the best knowledge that we can trust should be in the room and we will fight it with every fiber of our being if they're a terrible experience. And that's a bummer. And what's funny is you can flip it. We all either have friends or know people who have friends that you cannot trust, they have no ability to speak of, but they're a super awesome experience. What a great friend.

(01:32:16):
So how is it that we get this thing completely flipped? And I think that's the thing. As you parse that list, as anybody listening parses that list, it's critical to ask what kind of experience am I? That is where to start? Not how good am I at my job? How much do I know? How critical am I to this process? But am I a miserable experience? And if the answer is yes, don't worry too much about the other pieces yet, you got to fix that first.

(01:32:48):
And to this point of the profile, as you parse the profile, you'll find things like obviously not a pleasant experience, like being really impolite, obviously not a pleasant experience, being super overbearing and assertive, obviously not a pleasant experience, being hyper low in openness and enacting out of that and telling everybody they're overcomplicating everything all the time. Not a great experience for people who are actually well-intentioned trying to get it right. So there's concrete things that you can do with this knowledge in mind.

Lenny Rachitsky (01:33:16):
This last piece makes me think about why some of the most effective PMs are the PMs that bring a lot of energy and positivity to the team and just get people excited, which is such a soft skill, but such a powerful thing you can do for your team because people kind of look to you to lead them. I had a PM I was working with in every meeting, he is like, "This is going to be awesome." He just comes right in every meeting, "Oh, who's ready to make some decisions," and it really changes everything. And so this is amazing advice.

(01:33:46):
So basically if you want better relationships, which will make you a better influencer, start with what kind of experience am I, when people work with me, ask me for stuff, ask me questions, and you shared a bunch of specific things you can do.

(01:34:03):
Something I always tell people is just try to smile, just look happy. That makes a big difference.

Evan LaPointe (01:34:07):
Look happy.

Lenny Rachitsky (01:34:10):
Bring energy, look happy. Just try to be excited. Yeah, so if you want to build better relationships which have all these amazing trickle down effects, your advice is think about the experience you are to other people when they work with you, work on trust and ideally get to the place that third level of you are doing it better than them. But that's a high bar for all things. And then the last thing is, are you actually amazing? Work in your abilities, that's kind of the last piece.

Evan LaPointe (01:34:38):
Yeah, exactly. And it's not that none of these become unimportant because the other are kind of the gateways. I mean your relationships require all three, especially your professional relationships. So yeah, it's more just like if experience is the only thing undermining you when you're otherwise very trustworthy and very skilled and able, that's a shame. Just fix it.

(01:35:03):
And there's a whole bunch of ways to go about that. But I like to leave that to people to explore that creatively. Like well, "Oh gosh, okay, I can change this to this to this." On the trust thing, do you hurt people? I mean, that's it. Do people have a reason to believe that you are risky or dangerous? And unfortunately in a lot of habitats, the habitat itself either allows or even rewards people that are super untrustworthy to play the system in advance of the system. And as you talk to Jeffrey about the power conversation, the worse the habitat, the more his suggestions work.

Lenny Rachitsky (01:35:47):
I could see that.

Evan LaPointe (01:35:49):
And the reason that he's correct, he used the phrase, "This is how the world always has been, is how it is, and it's how it always will be." Well, it's how the normal dysfunctional world always has been, is and will be. And if you want people in your organization to rise on merit and for influence to work to generate better decision-making, make better products, have a better company, move faster, et cetera, you need to create a habitat where what Jeffrey's observed about the normal dysfunctional world largely doesn't work within your habitat. So if it's effective for people to harm each other in your habitat, you are performing at a much lower level than if harming each other was extremely ineffective. And that's up to you as a leader, as a manager, et cetera. And then of course, skill is what it is. It's your ability to convert your intents into outcomes.

Lenny Rachitsky (01:36:48):
I'm glad you're talking about habitat, that's exactly where I wanted to go. So just two more things I want to spend our time on, habitat and focus, how to create more space for focus and get better focus. So you've touched on this many times at this point, this idea of a habitat. I think another way to think about this is the culture of your company. Is that right?

Evan LaPointe (01:37:06):
Exactly.

Lenny Rachitsky (01:37:06):
Okay, cool. So are there a few things you could recommend to people to create a habitat that is conducive of good stuff?

Evan LaPointe (01:37:15):
Let's start at the start here. So in the difference between what science knows and business does, let's kind of zero in on the fact that the way most companies approach culture has a very shaky track record. Like if mission, vision, values was an airline, you would not allow any family to fly on that airline. It does not arrive at most of its intended destinations. That is just a super important starting point because I'm going to kill a sacred cow here while we talk about this. And I don't want anybody to feel like I'm trying to be mean or anything. It's just it's worth looking at stuff that doesn't work and wondering if there's something that could work a lot better. So if we look at habitat and culture, it's really about what people believe. It's what people believe is acceptable, permissible, productive, and the biggest flaw in people's approach to culture. And interestingly enough, even at YC, they talk about this mission, vision, values, culture, stuff that comes later, let some stuff happen with the business that comes later. They're right to say that if that's the paradigm you're going to use because it's not going to work either way. So you might as well do it later.

(01:38:31):
But if you're going to do it the right way and investigate human beliefs, and we talked about priming for example, culture is just the macro priming of the entire business of what your central belief systems are and then the permission that forms from those belief systems. So if you've done that really well, you should do that right at the very beginning. In what way should we approach this company, building this, working together, et cetera? That would be really, really helpful to get right from day one. And the belief system that people have, there are two approaches to changing people's beliefs.

(01:39:10):
Mission, vision, values is what we call a performative approach. Meaning I'm going to come up with some expression of an inspiring mission, inspiring values and inspiring vision, and it's going to be performed well enough. It's going to be like if we were busking in the park, this is going to be a cool enough mission, vision, values that people throw some change into my guitar case and they buy into it, they gather around. And I think that's just completely the wrong approach because we're hoping to inspire people. We're hoping to be artistically talented enough to pull that off. The other approach is to be deductive, logically deductive, which is centrally speaking. There is hopefully a market out there that's glad our company exists, who is glad we exist, why are they glad we exist? And that's shifting our mission into something that we call your role, the role you play in the world around you.

(01:40:08):
Who is glad you exist? Why are they glad you exist? And that is a fact. That is not an inspiring idea. That is like, okay, we work with this company that does AI-based optical character recognition, document ingestion, et cetera. Why is the world glad that they exist? Well, because we get 95% of the documents scanned into structured data that normally people have to transfer by hand. That's pretty compelling. Why is the world glad Warby Parker exists? Because before you used to choose between looking dumb and it being cheap and looking cool and it being expensive, and now you can look cool and it's cheap. The world's really glad we exist.

(01:40:50):
Now that's true. I don't need you to be inspired to believe that that is true. And now everything that we're going to think about for the rest of our beliefs, we're going to deduce from that. So we're just going to use logic to build our culture, not inspiration. So this next thing we need to figure out is how can we understand the specific value that's created when we play this role in the world? We save people money, we save people time, we open up markets, we help people explore possibilities and potential they couldn't tap into otherwise, etc.

(01:41:21):
So what's the role of Core? People are glad we exist because we tap into potential they had no access to before. And at the team level, at the company level, that could be a really big deal. So we know that and we say, "Okay, well gosh, that implies so much." There's so much we got to do now what value does that produce? And then I could say, okay, once we understand the definition of value, which comes out of our role, now we can change the definition of done. So a lot of teams talk about bias to action. And hamsters have bias to action. They get up out of their straw and they turn that wheel as hard as they possibly can and they go absolutely nowhere. But if you understand the role you play-

Evan LaPointe (01:42:01):
But if you understand the role you play in the world, and you understand the value you produce in terms of time savings, cost savings, upside, whatever it is that you do, then you can say, "We should have a bias to impact, not a bias to action. We shouldn't just do stuff, we should have an effect that has the result of value creation. We should save people time." And now when you're a product team, looking at this, and you're saying, "Well, here's a cool new idea, Lenny, let's do this." You can now use that as a habitat level permission to be like, "Oh, how does that produce value for people? How does that make people go faster, save time, get smarter, do something they couldn't do otherwise?" And then you can still use that exact same vocabulary when you go sell it to them, "This is how it makes you faster, smarter, more efficient, save cost."

(01:42:50):
So it's like really logical deduction. And if people think that we should do something, build a product that doesn't create value. Now instead of being inspiring, we can be logical. We don't build things that produce no value, that is not a priority until we can turn it into something that does produce value. So you're turning culture into something highly usable, in getting away from performative culture into logical deductive culture. And I think that's really, really the key for most people is to say, "Let's understand why the world's glad we exist." That's why we have a team, that's why we have customers. And what does that imply about our standards for ourselves when we execute in value creation? Even down to the email. If I send some wonky email reply to somebody's question and it doesn't produce value for them, I'm not done. I need to finish the job until it produces value for them.

(01:43:43):
Quality standards are baked into this, that again is implied. Would I be happy that Warby Parker exists, if they shipped me something that's a two out of 10 in quality? No. So we can't make things that are two out of 10. And everybody has a belief. There are plenty of people that probably interview at Warby Parker that think, two out of 10 is perfectly fine, just get it to them. And no, we need an antibody to that belief. We have decision-making intelligence, which everybody believes we should go fast, break stuff, or we should be super slow, and get everything right and wherever in between. That's a fun one to talk about. And then finally, you have a teaming dynamic belief, which is essentially every single human's belief of what is acceptable treatment of other human beings. What state does that put the other human in?

(01:44:35):
And a lot of people, particularly like I'll pick on myself with the low politeness, will spend years thinking, "I'm giving honest feedback quickly. This is efficient." And you're like, "How is it efficient when it takes people six months instead of six minutes to act on your feedback because they just don't like you so much, and you have this appeal problem that keeps you out of all the rooms?" Actually your utility, which, your politeness is a utility transferred mechanism, but we don't want you in the room. So you're not a business benefit in this case. So that's kind of the starting point. That's ground zero of habitat is do not build an habitat on the roots of inspiration. It doesn't work. It can work, right? If you do it super inspiring stuff and you're super inspiring people, then you probably have the artistic ability to pull that off. But even then, you'd still be better off if you would do it through logical deduction instead of inspiration.

Lenny Rachitsky (01:45:36):
Say someone is like, "Okay, I'm going to improve my habitat, I'm going to improve my company culture. Or I'm just going to start setting up a good habitat." What's something they can do? What can they do today, this week, to just start to do that? Is it, sit down and think about what is the value we provide? Why do we exist? Is there something else you'd recommend?

Evan LaPointe (01:45:54):
So the brain craves an answer to the question, why am I doing this? And not only are there things we should start doing, but I like to deepen the commitment in people's minds to what we should start doing, by thinking of it as, we should start doing things that we've been negligent in doing, right? Not just, oh, this would be even better, but we are actually causing some habitat problems by being negligent in certain things. So the primary thing that people are negligent in is answering the question, why should I do this, to their team. And saying, you should do this because it's your job is a form of negligence, right? You're not actually answering that question in any useful way. Because I could also answer that in the safety way, which I sort of just did by saying, it's your job. I'm implying that there's a consequence. But I could be like, because if you don't, here's the specific bad things that will happen.

(01:46:52):
You could be giving them a why in terms of reward, because, oh, if you do this, you get this, or if we do this, we get this. But you could also be giving them a purposeful answer to why, which is not a form of negligence, which is to say, because our work actually matters. There are people out there waiting on us to ship this product to improve their situation, and they also want us to get it right at the same time. So bias to impact through that lens. We do need to ship this. It needs to happen, and it needs to be right, or at least right enough in its first version.

(01:47:28):
So if you have been negligent, and we all have at times, right? I'm not trying to judge, but I'm trying to convict, right? To build some conviction, to build some commitment. If you have been negligent in answering to all these minds that work with you, why we're even doing this. That's the starting point, is make sure everybody knows why. And that why is a shared why across the team. And not just the Simon Sinek big picture why? I mean, very specific why. That for my team, when we build training materials, when we look at it through that lens of, if we get this right, this is what happens to teams, and companies, and products and their customers.

(01:48:12):
There's a through line at the big deal and that's why we can't do it this way, or that's why we should get more obsessed with quality, and why we should get more interdependent as a team and stop doing things that are just our own ideas. But say, "Hey Lenny, I'm thinking about doing it this way. Is there anything you'd add before I hit go?" And then you'd be like, "Oh, I think it would be 10% better if you did it this way." And then now our product is 10% better. So that's kind of the square one is ask yourself, when's the last time our team had a conversation about why we're even doing any of this? What value it produces? Who is affected by our decisions? And if that hasn't happened in a while, that's not good.

Lenny Rachitsky (01:48:57):
Is another way to think about this, your mission, is that a term?

Evan LaPointe (01:49:02):
Yeah, I think it's an alternative to mission, I try... And I don't want to stomp all over mission, vision, values because I think they can work. But I think it's easier for people to conceptualize the importance of their work, if they understand, we are playing a role, not fulfilling a mission. And role implies obligation. There's no obligation in mission, unless you feel the inspiration so powerfully. And these differences are subtle, but neurologically, it's different. If I tell your brain, "Here are the people counting on you to get this right, Lenny." Your brain activates a region called the anterior insular cortex, which starts to think about other people in the context of the solution you're creating.

(01:49:45):
And if I say, "We are here to change people's lives through this," in a more general sense, your prefrontal cortex will still activate to solve the problem, but your anterior insular cortex will not, to more deeply consider the humans affected by the problem. So you're kind of adding to the toolkit of what the brain will bring to the table to generate solutions. And if you activate more good regions of the brain, you get better solutions. So I lean into this. Personally, I'm like, "You really don't need a mission statement. You need to understand the role you play, and people need to have some response, some physiological, like, 'I get it, to my actions impact people.'" And if they don't have a response, you should go find a human who does, for sure.

Lenny Rachitsky (01:50:35):
One last thread I want to follow, focus. You have some really cool advice on how to help. And this just comes from everybody wants to get better focus. Everyone wants their team to have more time for focus. Everyone wants their engineers to sit there and build things faster, their designers to get stuff done. And it all comes from getting really good at focus and creating space for focus on your team. What advice do you have for folks that want to personally learn to focus better, and to help their team have more time for focus, get stuff done essentially?

Evan LaPointe (01:51:10):
I mean, isn't this the question? Because this is where it all ends, right? First things first, let's look at the neuroscience that we have available to us. Which is, the study of focus either is or is tightly associated with the study of what's called brain waves. That's becoming a lot more popular. We're seeing it even in athletes, like professional golfers, or studying how their brain waves are focused on the golf shot and which mode to put the brain into to play golf at the highest level. Same thing applies to work. There's a bunch of different kind of bands of brain waves. Most of them actually are when you're asleep. So your REM cycles, your deep sleep cycles, your kind of drowsy cycles, those are brain waves. You can feel your brain turning off, you can feel your brain turning on when you dream. But when you're awake, there's really three primary modes that your brain is in.

(01:52:03):
The nerdy side of this, kind of the nerdy language is alpha, beta and gamma. Those are the distinct ranges of brain activity, and they basically represent how focused your brain is. So alpha is quite simply daydreaming. So your brain is very quiet and empty. Easy metaphor is if you're in your house at night and everything's quiet, you hear things that you don't hear during the daytime, and that's what alpha is like in the brain. Your brain is actually working subconsciously a lot. But when you're busy, which is beta, your brain is too noisy to hear any of those little creaks and pops in the house. But when you're in alpha, you hear stuff.

(01:52:41):
So the most common setting for alpha for most people is the shower. So it unlocks this mystery of like, why do I have all these ideas in the shower? Well, it's because your brain is in alpha. It hears these little creaks and pops inside of the attic, and it unpacks them. He goes, "Oh, that's an interesting idea," it comes out of nowhere. It can be driving, gardening, car washing, cycling, whatever. As long as there's not too much cognitive load, then you can be daydreaming. And I'll come back to this in a second because there's a big permission problem at the habitat level for some of these focus levels.

(01:53:14):
Beta is productivity mode. So if you've ever seen somebody with a poster on their back wall that says, "Get shit done," that's basically just a poster that says beta on it. I love beta. And answer emails, have meetings, write code. And there are some gamma code, deeper thinking scenarios where you're writing code, delivering presentations, making presentations. So much of our workday is beta, and it's just... I mean, some of us have an infinite amount of demand for beta work. There's just a never ending stream of stuff we could do and get done.

(01:53:55):
And then gamma is your brain's intense focus. So if you're learning something really complicated, you're learning thermodynamics in college or something like that, and you're just like, "Wow, this is not easy." And you have to really push your brain to grapple with these concepts, connect the dots, even remember certain things, that's gamma. And we feel that sometimes at work, that here's a problem, a complex issue that we could tackle in beta by slapping duct tape on it, or we could tackle in gamma by reverse engineering, and going deep. And that's where we start to connect the dots that we talked about earlier, that focus and reverse engineering are related. That in beta, you have no intention to learn anything new to get something done, to think more deeply to get something done, to reconsider an existing process, or structure, or framework in your mind to get something done, you're going to utilize those things to get something done.

(01:54:52):
Gamma is where we go, "I would normally do it this way. I can see why that's not the right way. I need to make something new. I need to break my framework and build a brand new one right now to do something." So we generally spend too much time in beta in work, and that's both a judgment call, because I certainly have my own opinion about beta. I call it the conscientiousness crisis, which is conscientiousness wants beta, openness wants gamma. I'm kind of thinking of tying these pieces together. And it's not that conscientiousness is inherently a crisis, but when you meet teams that haven't done any innovation, haven't rethought the market, have become insensitive to changes in the environment around them, have become insensitive to their own employee problems and are still just kind of like this locomotive that keeps on going, irrespective of what's going on around it. It's that heads-down form of conscientious beta, that feels like, "Now's not the time, let's stay focused, let's stay focused," et cetera.

(01:55:53):
So we don't want to get rid of beta, we got a lot of work to do. But let's put a rule of thumb out there for people to explore, because it's going to be subjective to every team and every company. But as a rule of thumb, if 25% of your year is spent in gamma and alpha, you're probably a lot better off than the teams who spend less than 25% of their year thinking deep, and being in this more daydreaming mode. So what I wanted to circle back on is, how could we possibly daydream productively? Well, that's preposterous. And this is where you can build in your mind... And I do have another PDF for this, if people want to see it.

(01:56:32):
But you can build in your mind a 3 x 3 grid where we have the safety system, reward, and purpose system in columns. We have alpha, beta and gamma in rows, and we basically have a list of nine channels that the brain can activate to generate different types of thinking. And most of the companies out there, most of the teams out there, are primarily, all their programming comes from safety beta and reward beta. How can I be busy to get rewards, ROI, customers, deals, whatever? Even promotions, more self-centered kind of rewards? And beta safety, which would be, how can I be busy? Optics, manage my reputation, avoid risk, that sort of stuff?

(01:57:19):
The crisis is basically realizing, spending too much time in those two out of our nine available boxes, is probably not generating anywhere near the ideal outcomes. And if we could instead shift to the purposeful column by answering that brain's craving for why, with an answer that explains, it's not about you, it's not about us, it's about other people are counting on us to get this stuff right, does that matter to you? Because for most people, they're like, "Yeah, that's actually really cool. I can have an impact on real stuff happening in other people's lives and in the world outside of me?" So that that activates, now all of a sudden we can say, okay, let's look at alpha across the top row.

(01:58:06):
Alpha safety is when you get in the shower, and all of your anxieties, worries, et cetera, come out of nowhere, out of the attic of your mind. What happens in alpha reward? It's when you have these breakthroughs of how to get a deal, how to win something. It's daydreaming, but your brain is primed to daydream in a certain way, whether it's about anxiety or anger, or whether it's about rewards you care about. If it's purpose, this is where from a vision perspective, a possibilities product perspective, you're going to have all sorts of crazy cool ideas pop into your mind if you've primed your brain to being purposeful and then you daydream.

(01:58:44):
And you can do this in the middle of a day. Certain companies, it's easier than others. But if you can push away from your desk, and just go sit in a park or something for 10 minutes, 20 minutes and calm your brain down, listen, something cool will probably happen in your brain. I can't guarantee that, but you have to experiment with it to find out how it works for you. And then the same thing for gamma, when you hear phrases like, "We can't talk about this for the rest of our lives," that is the gamma prevention team kicking the door down and saying, "We're here to get you back into beta. Everybody, put your hands behind your backs," sort of a thing.

(01:59:22):
And that's where the habitat and the focus kind of matters because you will not ever get a gamma idea from a beta mind. You will never get an alpha idea from a beta mind. So if your business needs some breakthrough, daydreaming, interesting ideas in order to create adjacencies to build new products, to seek new markets, to better fulfill the role you're playing within this market, then team has to have permission to enter that intellectual focused state, or that you're turning that channel off. You're taking that off of the programming available through your particular subscription.

(02:00:04):
And the same thing applies to gamma. The habitat basically needs to establish that gamma is a viable channel for a lot of work, and there's permission to go into it. You can certainly overdo it. That's why I say 25%, you don't need to spend half of your year, three-quarters of your year in gamma. It bonkers how smart you can be if you spend three or four hours in an afternoon in that deep-focused state, you'll just do stuff you'd never do. And if you can get the team to have off-sites that are gamma-focused, everybody's scatter and be alone, and do this stuff that are gamma and alpha-focused, that are productive and you bring ideas back. You're just simply going to generate thinking and outcomes that you wouldn't otherwise. And it may be that 10 percent's right for you. It may be that 30 percent's right for you, depending on how dynamic your market and customer base are. But just to challenge yourself with the question.

Lenny Rachitsky (02:00:58):
This stuff is so fascinating, I wish we had another hour just to dig deep into this. Because it feels like just this alone is going to really transform the way companies operate. So let's try to give people something tactical they can do to create more space for alpha and gamma waves. And essentially your advice is, a fourth of your time should be spent, if possible, in alpha and gamma time. Is that right?

Evan LaPointe (02:01:22):
Yeah, I think that probably is overabundance, in all honesty. But if you think about it through the lens of a quarter, if you're going to be on a set of cadences, and this is probably the tactical advice. It's like, look at your cadences and say, at the quarter level, that's probably the right level of fidelity for most people to look at their calendars in terms of what big stuff should we be doing? Because six months is usually too long to do anything big. Too much has happened in the world. Year is definitely too long to wait for a cadence to kind of kick in. So quarterly is really good. And what's nice is when we cluster our gamma time on this quarterly cadence, we can take a lot of the stuff that would be what we call calendar invaders, these random conversations that come up out of nowhere. And we can be like, "Well, we're getting ready to have an offsite, this quarter's offsite in two weeks. Can this idea wait until then to be processed?"

(02:02:16):
So you kind of get this nice little black hole effect, where a lot of distractions have a new home, because you've actually said, "We're going to distinctly do stuff." You're saying, "Yes, but not now," to a lot of distractions. But yeah, I think that's the ideal cadence. And that, for some teams, it needs to be maybe a half a day or a full day. You'll figure it out based on your own business. But what per quarter is a necessary amount of time for us to break beta and go into deep thinking analysis mode? How healthy is our operation? How smart are we being? Are we delivering value? What needs to be reevaluated from the market's experience, the customer's experience, the team's experience? Let's look at these different views of the business, and make some prioritized decisions about, we're going to make specific improvements this quarter for these areas.

(02:03:10):
And then even once a week, maybe just find half a day if you can, maybe, but maybe less than half a day, couple hours to be in gamma, once a week. And you'll kind of feel it out from there. But the reason the rule of thumb of 25 is out there is 25 is kind of the risk point. Because most people will be like, "We're not even spending 5%." Or the perfectionist team might be like, "We're 50." So if you're far away from that rule of thumb, that's a pretty good indicator it's a good time to audit yourself.

Lenny Rachitsky (02:03:42):
When you hear the term, deep work, is that generally referring to gamma time?

Evan LaPointe (02:03:47):
Yeah, people can use that term in a couple of ways. I think a lot of people call deep work, don't bother me beta, which could be one. And other teams might call gamma deep work, but that's probably more appropriate. I think, don't bother me beta is for some teams, they need to be told, "No, no, use this time not just to not be interrupted, but to think differently about problems. To think about is the architecture even right? Is the way we are thinking about this even right?" Not just get a lot of stuff done.

Lenny Rachitsky (02:04:18):
Yeah. So it's not just sitting in your email and write documents, it's actually try to think about bigger problems, things that are challenging your brain, not just like, "I'm just productive getting stuff done, getting stuff done." Awesome. Something that worked really well for me, similar to what you just recommended is having, I had two blocks of time during the week that were two hours or three hours long, where it's just, "Don't bother me, deep work time." So I had it I think Wednesday morning and Friday morning for two or three hours. And actually in the calendars, if you book something during this time, I'll slap you. And that worked really well. And nobody complained.

(02:04:54):
We covered a lot. Here's the things we've covered. I was just taking notes and all the advice that you've shared, how to help people run better meetings, how to get better at developing vision for their team, and company, and product, how to be a better influencer. How to build better relationships, how to create a better culture for your company, how to create more focus and more productive focus. That's a lot. I'm very proud of our conversation. Before we get to a very short lightning round, because we've gone pretty long, I want to keep it short.

Evan LaPointe (02:05:22):
Sure.

Lenny Rachitsky (02:05:22):
Is there anything else you want to share, leave listeners with that you think might be helpful before we close-

Evan LaPointe (02:05:28):
No, I don't think we need... I mean, there's certainly a lot more that we could talk about, but I think we don't want to melt any minds. So we want people to kind of walk away and be like, "I can do that, I can do that, I can do that." So definitely pick two or three wins. I kind of call them pots of ocean to boil instead of oceans to boil. So get a few pots of ocean to boil first, and focus on that for sure. And definitely make one of those pots, if it's a problem area for you, what kind of experience you are. I mean, that's central to everything. Everything else works better in the whole system once you've boiled that pot of the ocean, and then things get easier.

(02:06:05):
And then I guess the only last thing I would add is, think of everything we've talked today. It might help to put some language to it as floor risers and ceiling risers. Because your company has a horizon of performance that you're heading into, and there's a bottom end of that range and a top end of that range. So as you get better at meetings, not only are you increasing... You're raising the floor to get rid of bad meetings and waste, and you might be saving a ton of time or converting useless time into useful time, but you also might be raising the ceiling.

(02:06:35):
And I would be really specific with yourself and your team about, which outcome are you chasing? Is it both? Is it one or the other? And say, we're actually trying to raise the floor so that our performance never goes below a certain range. We get faster, smarter as a result, fewer mistakes. Or are we actually trying to uncap a ceiling that we're dealing with right now, especially around things like strategy and vision? If we feel that those conversations always end up feeling like inconceivable arguments, we have a ceiling on our business's performance. As a result of that, can we raise that ceiling and explore a higher horizon of performance for the business?

Lenny Rachitsky (02:07:12):
Amazing. Evan, with that, we've reached our very exciting and very quick lightning round. Are you ready?

Evan LaPointe (02:07:18):
Yes, let's do it.

Lenny Rachitsky (02:07:20):
All right, so let's start with what are two or three books that you've recommended most to other people?

Evan LaPointe (02:07:26):
Well, the obvious first one is Never Split the Difference. I recommend that book to everybody in the universe. I think if you haven't read it yet, you shouldn't get your driver's license. For those who don't know, it was written by Chris Voss, he was an FBI hostage negotiator. And it explores how to negotiate with people, and not just hostages, but your colleagues, your parents, your wife, like everybody. And there's some very surprising technique in there that is unexpected, not trying to get people to agree with you, but getting them to say no, more often. Instead of saying, "Hey, Lenny, are you willing to do this?" Say, "Hey, Lenny, are you opposed to doing this?" And it's just this reversal. And "I'm giving you the out," is the way he explains it. There's a whole bunch of other technique, but the more of that technique is in a team, the better. The better the team does. That's a no-brainer.

(02:08:16):
The second one I would say, since we've kind of covered this topic a little bit about habitat today. If you enjoy reading books that are sort of root canals, but you're better off because you read them, there's a book called Never... not Never Split the Difference, there's a book called The Person and the Situation. It was written by some researchers, some psychological researchers. And what it explores is the difference between how personality influences your behavior, and how the situation you're in, or like we talked about, the habitat you're in, influences your behavior. And if you're not yet convinced that either of those matters, like, "Oh, it doesn't. I'll do what I do regardless of the habitat, or I'll do what I do regardless of who I am," that book will melt the face off of that existing mental model conclusively. It's really valuable knowledge to understand the mechanics of how the situation influences a person, and how the personality influences the person.

(02:09:12):
And then I guess the last, maybe we'll put a fork in the road of a choose your own adventure. If you're a real student of the game, and you want go 10,000 leagues under the sea on this stuff, there's a series of books called the Cambridge Fundamentals of Neuroscience. You can find it on Amazon. A lot of them, you can just get on your Kindle for a lot cheaper than the library-decorating version of it, but that is bonkers. It talks about how your brain applies to intelligence, emotionality, relationships. It's incredible knowledge. If you instead want to keep it more in the part of the world you experience and can see and not the brain. Thaler wrote a book called Misbehaving. It was kind of the major book about behavioral economics.

(02:09:58):
And again, we spend a lot of time in companies talking about the way people should act, instead of the way people do act. And behavioral economics is essentially the version of economics that's about how people do act, not how people should act. So I think that's a great field of study. And then again, Robert Greene's whole library is super valuable, especially Human Nature, if you're into that. He's a little darker of an author, certainly kind of doesn't pull punches about human nature. So those are all great books to explore.

Lenny Rachitsky (02:10:28):
Do you have a favorite product you recently discovered that you really love?

Evan LaPointe (02:10:31):
I look more at the category level of products. I really like products that have great ergonomics. A lot of people underestimate the value of what it feels like to use the product. Are things in the right place at the right time? I just started this newsletter that's kind of like, how do you break all of what we do in a bite-sized pieces for people who are super interested in this stuff to get something weekly? And it exposed me to Beehiiv, which is a very well-designed newsletter platform, high ergonomics. I don't ever find anything hard to find. I can get things to work the way I want them to work.

(02:11:07):
So just, I like that example. And I remember even back to when I was obsessed with finding the perfect backpack to travel with, and then you find these brands where you're going through security, and you didn't even know it, but there's a pocket designed for your phone in exactly the place you would want the pocket for your phone to be. And you're just like, "That's so great. I love that this team designed this pocket just in the right spot." So that's really my focus is ergonomics in product.

Lenny Rachitsky (02:11:32):
Final question. I saw you tweeted that people are telling you that you look like JD Vance, which is hilarious. Do you think this will be a net benefit or a net hurdle?

Evan LaPointe (02:11:42):
It'll be an incredible benefit to Halloween, because it's totally clear what I'm going to do for Halloween. Yeah, I mean, I guess I'm going to have to see what people in the street... Fortunately I live in Park City, so I don't run across a lot of people in the street who want to yell at people. But if I lived in Chicago or something like that, I would've no doubt somebody would come up and throw something at me. But yeah, I'm neutral on the topic so far, minus the Halloween bonus.

Lenny Rachitsky (02:12:09):
We'll see. We'll see how your life changes. Evan, this has been amazing. There's so much richness to this conversation. And like I said, we've covered basically everything people want to get better at as product manager, you could say. Two final questions. Where can folks find the stuff that you do to dig deeper, to learn more, to learn more deeply from you? And two, how can listeners be useful to you?

Evan LaPointe (02:12:31):
Yeah, I mean, they can certainly find a lot of the stuff we do on our website, core-sciences.com. Find a link to that profile you talked about on there, which can be super fun to take and insightful. The newsletter, all the stuff that we do, you can kind of find out there. And then certainly Twitter. I mean, I've always been really prickly about people that get on Twitter to post only and not to interact. I'm kind of the opposite. I really love people's questions and pushback. And just yesterday, I probably spent way longer than I should have out of my portfolio management approach to time, just on a thread where I was talking to this really interesting woman about this debate almost, about the probability of people doing things based on their beliefs, which was... And then we had some kind of bystanders watching the whole thing happen, and I had a meeting with a good friend Rod afterwards, where we talked about how that all went.

(02:13:28):
So I love to talk to people and answer questions, and I'm sure people will have plenty of questions that they'd love to dive deeper into. So I'm on Twitter for sure. And then how you can help me. I mean, fortunately for me, I'm in the business of helping other people, whether those are individuals, teams, companies. So the most helpful thing to me is you helping yourself. So if you find our content valuable, if you want to have awesome managers or anything like that in this sort of science-based, kind of more efficient approach to getting there would be interesting, then reach out. We don't bite. We're pretty easy to work with. And that would be super fun to have a conversation about what your team needs.

Lenny Rachitsky (02:14:08):
Evan, thank you so much for being here.

Evan LaPointe (02:14:10):
Thanks for having me. This has been really cool. Yeah.

Lenny Rachitsky (02:14:12):
Same for me. Bye everyone. Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review, as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Failure
**Guest:** Failure  
**Published:** 2023-12-13  
**YouTube:** https://www.youtube.com/watch?v=9euy9gC48lc  
**Tags:** growth, retention, acquisition, metrics, roadmap, iteration, a/b testing, experimentation, conversion, monetization  

# Failure

## Transcript

Lenny (00:00:02):
Today we've got another very special compilation episode. Something I've been pulling on more and more with the podcast and the newsletter, in case you've noticed, is failure. Normally I spend a lot of time researching how the best companies and the best product leaders operate, but you can learn a lot and often a lot more from failure. And so what we've done with this episode is we've looked at all of the past episodes we've done and pulled out all the most interesting and insightful stories of failure and turned it into this very focused episode on failure. I hope that you find this useful and interesting. Let us know what you think in the comments on YouTube or on lennysnewsletter.com, or just let me know on Twitter. If you like this, we'll keep doing this. If not, we'll, probably not. Either way, I hope you enjoy. Before we dive in, here is a short word from our wonderful sponsors.

(00:00:52):
Let me tell you about a product called Sendbird. The all-in-one communications API platform designed for both web and mobile apps. In a world saturated with multi-channel communication, product teams are discovering the effectiveness of in-app communication with Sendbird, businesses can elevate their in-app experience with decluttered and branded communication featuring AI-powered chatbots, one-way messages, chat, video calls and livestream capabilities, all tailored for commerce, marketing and top-tier support. Forward-thinking companies such as Hinge, Patreon, Yahoo, Accolade, and more use Sendbird to build in-app communication experiences that drive engagement, conversion, and retention. In-app communication has the highest conversion, highest engagement, and highest satisfaction of any communication channel. And when it comes to investing in this channel, trust Sendbird to take your in-app communication experience to the next level. Start today with Sendbird's free plan and as a listener of Lenny's Podcast, you'll get an additional two months of unlimited usage and access to all premium features, including creating your very own generative AI chatbot. Visit sendbird.com/Lenny to begin your free journey. That's sendbird.com/Lenny.

(00:02:08):
This episode is brought to you by Eppo. Eppo is a next-generation, A/B testing and feature management platform built by alums of Airbnb and Snowflake for modern growth teams. Companies like Twitch, Miro, ClickUp and DraftKings rely on Eppo to power their experiments. Experimentation is increasingly essential for driving growth and for understanding the performance of new features. And Eppo helps you increase experimentation velocity while unlocking rigorous deep analysis in a way that no other commercial tool does.

(00:02:38):
When I was at Airbnb, one of the things that I loved most was our experimentation platform where I could set up experiments, easily, troubleshoot issues, and analyze performance all on my own. Eppo does all that and more with advanced statistical methods that can help you shave weeks off experiment time, an accessible UI for diving deeper into performance, and out-of-the-box reporting that helps you avoid annoying prolonged analytic cycles. Eppo also makes it easy for you to share experiment insights with your team, sparking new ideas for the A/B testing flywheel. Eppo powers experimentation across every use case, including product, growth, machine learning, monetization, and email marketing. Check out Eppo at geteppo.com/lenny and 10 X your experiment velocity. That's geteppo.com/lenny.

(00:03:26):
All right. First up, we've got Katie Dill, who is head of design at Stripe and former head of design at Airbnb and Lyft sharing this amazing story of how the entire design team at Airbnb basically rebelled against her soon after she joined and what she learned from that experience.

Katie Dill (00:03:42):
I'm happy to talk about it because frankly, it was the biggest learning experience of my leadership career, or at least that happened in one moment, and it happened in my early days at Airbnb. So I was hired to take on the experience design organization, that's basically the product design team, which was 10 people at the time.

(00:04:02):
And so they had been reporting directly to one of the founders and they were going to start reporting to me. And during my interview process, I learned a lot about what was working and what wasn't working and some of the trials and tribulations with the design organization and its collaboration with others. So it seemed like there was room for improvement in how engineering and product management and design all work together. And there was also really low engagement scores in the design team.

(00:04:29):
And so I came in ready to go and excited to try to help make some change based on all the things that I had learned from various leaders and people across the company. And I came in swinging ready to go, and then about a month into my time there, I got a meeting on my calendar. Thursday 8:30 AM, was an hour and a half with half of the design team, so that was five people, and our HR partner.

Lenny (00:05:00):
Oh, no. That's never a good sign.

Katie Dill (00:05:01):
Usually it's [inaudible 00:05:01]. Yeah. And I remember this so vividly. I remember walking into the office and all the rooms in Airbnb's office are very unique spaces that look like Airbnbs, but of course this was the one room with all white walls and just a gray flat rectangle table. And I walked into the room and there were five of them seated around the table and they had a pack of papers in front of them, and they went on taking turns quietly reading from the papers all the things that they saw that I was doing wrong and all the things that they didn't like about me. And it was a really hard moment there. I went through all the usual stages of grief when one hears feedback, which is just immediate want to respond to be like, "Oh, well there was a good reason for that." And, "That's not how it actually was," and, "This is why I did that."

(00:05:59):
But luckily I had, thank goodness, I had the sense to just listen and not respond in that way. Clearly, what they were telling me is that that was one of the things that was missing. And so I heard them out and took it all in. And regardless of each individual thing, what was very clear was that the missing piece, the theme that was across all of that is that I hadn't earned their trust. So whether how right or how wrong what I was doing was is the key piece is that I wasn't bringing the team along with me. They had no idea that they could trust in what I was trying to build and what I was trying to shape and that I cared about them and that I had their best interest and shared goals at heart. And that was absolutely my fault.

(00:06:45):
And in retrospect, as hard as that was, I'm very grateful and very amazed that they could come together and share that with me. It can be hard to bring feedback forward like that.

(00:06:57):
And so it was an extremely valuable learning experience and I took from that to then immediately shift how I was operating. And really a key part in building trust was to listen, to hear out what the individuals on the team were setting out to do, what they cared about, what motivated them. And so I started to make pretty fast change and still moving in the direction that was necessary for the org to make the really large impact in how we were operating, but bringing folks along with me. You can inflict change on people, but if you want to do it with them, really trust is the key element there.

(00:07:37):
And then a couple of months later, we had the best engagement scores in the company. So it actually, it did objectively improve the situation and since then taken that on into next steps in other companies that I've joined and just think about instead of coming in swinging, come in listening, so that you can really set out to make change that actually has true positive impact on the folks around you and you bring along with you.

Lenny (00:08:04):
Next up, Paul Adams, chief product Officer at Intercom, sharing the nightmare experience of freezing on stage in front of thousands of people, having to walk off stage, and then people hearing him curse because the mic was still on, and then how he recovered. Plus a few stories of building some of Google's most infamous product failures.

Paul Adams (00:08:24):
Some things have happened in work, are very memorable at the time and they don't really scar you. This goes in the book that have scarred for life. Yeah, let's go long story short, I was at Facebook just over a decade ago, loved it at the time. I think it was a great place to be at the time. And basically San Francisco, I did a lot of talks for Facebook internally and externally. Facebook had a keynote slot, always have a keynote slot at Cannes, the world's biggest advertising festival. And the year prior, Zuck had been interviewed. He was the speaker, he'd been interviewed, gotten a hard time on privacy. It didn't go well, as well as they'd hoped.

(00:09:00):
So the next year they asked me to do it, maybe it was the Irish accent that made the offer come my way. And yeah, I got out into front the stage of the world's biggest advertising stage, and I'd say I was like three or four minutes into the talk, a talk I'd given, a very similar talk that I'd given lots of times.

(00:09:19):
And I just froze. I couldn't remember what I was supposed to say. It was the first ever time in my life I'd rehearsed a talk word for word. Usually, I have talking points and I'd ad lib and things get mixed around and it's kind of informal. This was media trained, do not say the wrong thing kind of talk. And I just could not remember what to say. I had some version of a panic attack, walked off stage, I was still mic'd up, cursed. I was laughing. I was like, "Geez, are they laughing at me. Oh my God, this is..." But I can manage to turn it around, I walked back out, I'd kind of been disarmed internally in my head, and the rest of it went well. And I was famous that night out in Cannes afterwards on whatever the seafront, it's just like ros everywhere. I was famous and infamous for my performance.

Lenny (00:10:13):
I feel like you lived the worst nightmare that everybody has when they're thinking about giving a talk. And I think what's interesting is you survived, and I think that's a really interesting lesson is you could freeze in front of thousands of people, walk off stage, and then it works out okay.

Paul Adams (00:10:30):
And it all happened organically, I guess, or very naturally. But yeah, ever since then, every time I walk out onto a conference talk stage, still today, I ask myself, I have this tiny doubt in the back of my head. It's never happened since. But yeah, I think you have to go with it with these things. When life kind of throws you these whatever curve balls you have got to kind of adapt, and it's not that big a deal. None of these things are that big a deal. At the end of the day you kind of move on, live and learn. Yeah, but I still hope it doesn't happen again.

Lenny (00:11:02):
I also hate public speaking and I always fear this is exactly what's going to happen to me. And so I think this is nice to hear that even when the worst possible thing basically happens, things can survive.

Paul Adams (00:11:13):
You can turn it around. Yeah.

Lenny (00:11:15):
A second area I wanted to hear from is your time at Google and there's a couple products you worked on at Google. Both of them were not what you'd call big successes, and then there's kind of a transition to Facebook, which was also kind messy. Can you just share a couple stories from that time?

Paul Adams (00:11:31):
Yeah. Similar to the walking off stage thing, you live and learn, and I was at Google for four years. I was at Facebook for two and a half years or so. At Google I worked on a lot of failed social projects like you mentioned, Google Buzz, Google, and later Google+. I think a lot of the motivation for those projects came from a place of fear. It didn't come from a place of let's make a great product for people,.let's really understand the things people struggle with when communicating with family and friends. That's really, really try and create something wonderful. It came from a place of fear.

(00:12:10):
And so during those times I learned I think how not to lead in places. And by the way, I should say at the time in Google, there was other things happening that were amazing, like Google building Google Maps. Incredible product, one of my favorite products. I think one of the best products ever made. They were building Android. I was in the mobile team, in the mobile apps team at the time that Android came out. So incredibly good product. So I just happened to be in the social side, which wasn't as good.

(00:12:37):
And yeah, Google Buzz was kind of a privacy disaster, and Google+ similar. And so kind of halfway through I kind of published research about groups, and I've done a ton of research. An interesting kind of side note there is at the time I asked, I was working in the research, in the US team as a researcher, I was being asked to do a lot of tactical research, like usability study type stuff, like can people use these products? And I ended up doing a lot of formative research as well in the same session. So I'd kind of say to the team like, "Hey, I'll do the research, I'll answer your questions, but also I'm going to do this other thing, and I'm going to take 20 minutes doing that."

(00:13:16):
And so what we used to do is, what I used to do with people was map out their social network, all the people in it, their family, their friends, how they communicate. We'd map on all the channels, we'd talk about what worked well, what didn't. And we did this with dozens and dozens of people over the course of maybe 18 months. And the same pattern emerged every single time, which was people need way better ways to communicate with small groups of family and friends. And I kind of look back now and go like WhatsApp, or it maybe iMessage if everyone's on Apple, but really obvious in hindsight, but at the time, not obvious. And so we kind of tried to build a product around that called Google+, but again, it was kind of came from the wrong place. And so halfway through the research that I've done, all this research had been made public through a conference talk and Zuck and Facebook noticed, got in touch, one thing led to another and I left and joined Facebook, which was an amazing thing for me, personally.

(00:14:13):
Facebook was amazing, an amazing place at the time and exciting. And they were trying to do things for the other reasons, the kind of good reasons, like, "Hey, let's build an amazing product for people."

Lenny (00:14:22):
And this was during Google+ being built? You basically shifted.

Paul Adams (00:14:26):
Yeah, midway, I'm stressed to even telling you about it. The project hadn't been launched. It was still under wraps. It was highly confidential. Google had done a lot of things at the time that were the first for them. I don't know if they've done them since, but things like everyone worked in Google+ was sent to a different building. That building had a different key card. If you didn't work on Google+, you could not get in. All sorts of counter-cultural things at the time. And as a result, there was a lot of antagonism internally for Google+. And so when I left in the middle of the project, leaving with all of the plans in my head to the enemy, some people saw me as a traitor, understandably. Other people thought I was enlightened. It depends on who you talked to, but it was the right thing for me to do. But at the time it was a hard thing to do.

Lenny (00:15:17):
I know there's also a lot of scrutiny in what you took with you and the process.

Paul Adams (00:15:23):
When I left, Google kind of assumed that I was one of the spies. I was quarantined when I told them I was leaving. They forensically analyzed my laptop, all sorts of stuff like that. So it was pretty intense. Looking back, I can understand why that happened, but the root cause for me is that the project has been run from a place of fear, competitive fear, which I don't think leads to good things.

Lenny (00:15:53):
So one of the themes through the stories you just shared is, let's say failure is... I don't want to make it that harsh, but just things not working out. And I'm curious as a product leader, how important you think that is for people to go through if you think that's something that is almost a good thing. And I guess just is there anything there that you find helpful as a coach, as a mentor, as someone, to people that are trying to become basically you?

Paul Adams (00:16:19):
It very, very... It still is. It still is. I've personally failed so many times. There are two stories and the Google one is long deep tentacles. There are two stories. I've failed a ton of times like at Intercom. I remember when I was at Facebook, I was very happy and I knew I wanted to [inaudible 00:16:39] the co-founders of Intercom and they're trying to persuade me to join Intercom. It was like 10 person company at the time. But Owen said something to me at that time, which has stuck with me ever since. He said, "At Facebook you can design the product, but at Intercom you can design the company." And that was extremely appealing to me, a great pitch. He's like, "Just design the company with us that you want to work in."

(00:17:03):
And so part of that was a company that embraces failure that says it's okay to try things. I'm a big believer in big bets, higher risk, higher reward. I don't get as excited about incremental things. Now I haven't said that, there's of course a place for that too, especially as companies get bigger. But I get excited about big bets and if you make big bets, you're going to get a lot of it wrong. So a lot of the principles that we built here at Intercom, on building software, we have a principle called ship to learn, and we've actually changed it since, still on the wall here. Ship fast, ship early, ship often is what it says now. Used to say ship to learn. Ship fast, ship early, ship often. It's like in that idea is the idea of failure. It's not going to go right, and it's going to go wrong more often than not. But if you ship early and fast and learn fast, you can change fast, and you can improve fast. And that's the kind of culture that we as much as possible try to embrace and teach people. But it's much easier said than done.

Lenny (00:18:05):
Especially when you're in the moment. Like Go damn, it, everything's going to fall apart. I really messed this one up.

Paul Adams (00:18:09):
Yeah. And there's a trade-off with quality that people really struggle with. We've high standards of ourselves. A lot of Intercom comes from a design founder background. We value the craft a lot. We never want to be embarrassed by what we ship. So there's a real tension there, a real trade-off where people have these high standards, which we encourage and we encourage them to ship fast and learn and make mistakes. It's a constant kind of tension that we're navigating.

Lenny (00:18:38):
Next up, we have Tom Conrad, who is chief product officer at Quibi and engineering leader at Pets.com. Two of the most memorable failures in product history, sharing his lessons from those wild experiences. Tom is currently CEO of Zero Longevity Science, which is a killer business and an app in case you haven't come across it. I'd definitely check it out. Here's Tom.

(00:19:00):
You brought up this phrase of notable disasters and I want to talk about that. You've worked at two of the most famous notable disasters of product companies, Pets.com and Quibi. I think it's really rare someone sees the inside of so much hype and then such a fall at a company. And so I just want to spend some time in these two areas, and maybe the way to set it up is just what's a lesson you took away from each of these two experiences that you've taken with you to future work, and maybe advice you share with people?

Tom Conrad (00:19:30):
Probably the biggest lesson, it's not really about the specifics of the business. The biggest lesson really is these things make you better. In some instances, actually I think in both instances, they became kind of dominoes that opened doors for me in my own ambition and my own sort of professional life that maybe just wouldn't have opened at all if I hadn't gone to those companies and learned those things and had those experiences. And frankly, even in the case of Pets.com, like even the high profile nature of it, I could have worked at one of a thousand e-commerce websites in 1999. And when I went on to some subsequent job interview or something and talked about my experience, I had never heard of the thing that you worked on, but everybody certainly heard about Pets.com.

(00:20:17):
It's a pretty funny example too of how some struggles are timeless. That was 23, 24 years ago now. And while as a leadership team, we made, I'm sure, all kinds of mistakes. One of the things that happened was that there were three kind of over-funded pet e-commerce sites, and we all raised in excess of $50 million, which is a tremendous amount of money now. It was a tremendous amount of money then, and we all thought it was a zero-sum game and that we as one player started to spend on promotion or to spend irrationally on national broadcast television advertising. We all did, and it became this kind of unwinnable arms race. So there is, I think a fundamental lesson about having an excess of investment can be its own albatross or lead you to make decisions that maybe would be unwise.

(00:21:28):
And then of course, it's just like timing is really important. Chewy is a online pet store. It's worth $9 billion today. They were a private company and bought by PetSmart and then spun back out. But when they were bought by PetSmart, they were acquired for 3 billion, biggest e-commerce acquisition of all time. And while I think it's probably unfair to compare, Chewy who executed exceptionally well over a decade, grew their business brick by brick, and turned it into something really remarkable. To Pets.com, which was in a very, very different moment in time and tried to go to market in a really different way.

(00:22:07):
The critique that is often leveled at Pets.com or at least at the time, was like, this is just a stupid business. They're shipping dog food around. You could never make that work, and that's just wrong. You absolutely can make it work. Probably can't make it work when 80% of the country on the internet is still on dial up. It's really, really early.

Lenny (00:22:25):
I saw a stat I think you shared somewhere that you took Pets.com from nothing, to a public company, to completely out of business in 19 months.

Tom Conrad (00:22:33):
Yeah, yeah, I think that's about right. The other thing that's forgotten in the tale is that we actually didn't go bankrupt. We shut the company down and returned the remaining balance to the investors, which no public company had ever done before. And the leadership team just reached the conclusion that given the way market conditions had evolved, there was just no way we were going to be able to get more capital into the company. And it was a company that required additional investment to get to profitability. And so it was better to wind down early, take the money that we had in the bank and get it back to investors than to just spend every last penny on what was sort of a fruitless attempt to salvage it.

Lenny (00:23:22):
Did not know that. Let's talk about Quibi. What went wrong there? Do you think there was a path to Quibi having worked out? Any big lessons that you took away from that experience that you bring with you?

Tom Conrad (00:23:33):
The kind of miraculous thing about Quibi for me was it relit my enthusiasm for the industry for doing this work. I had left in, I think it was December of 2018, and I thought that maybe I was just done making software. I had done it for a really long time, I had done it for twenty-five years or something. And I had changed a lot. The industry had changed a lot, and I thought maybe I just didn't have the same passion for it that I had a decade before. And it also seemed like maybe it'd be fun to have another chapter of my life that was just completely different. And I had a whole list of things that I thought I might want to do. They were really, they were kind of ridiculous. Maybe I want to be a pastry chef. Maybe I want to be a landscape photographer. Maybe I want to learn to make bad music to put up on SoundCloud or something. Really the only thing they had in common were they were all things that I knew nothing about. People would be like, "Oh, you think you might want to be a pastry chef? Do you like to bake?" And I'd be like, "No, I don't know anything about baking." "Oh, you might landscape photography. Do you take photos?" "No, I don't make photos."

(00:24:41):
But I was kind of committed to the bit, actually to the point where when TechCrunch interviewed me about my departure from Snapchat, I was like, "I'm out. I'm going to do something else entirely." So that story is very much out there. But a few months after my last day at Snap, I got a call from Meg Whitman and Jeffrey Katzenberg who were starting up, it was called New TV at the time.

(00:25:07):
And the pitch was, "We're going to try to take the best of mobile and Silicon Valley and Consumer Tech and sort of weld it to the best of Hollywood-style content production to build something completely bespoke and purpose-made for consumption on the phone." They were looking for both technology leadership and product leadership and wanted to know if I was interested in one or both. And I took the meeting, even though I wasn't really taking these kinds of calls from anybody. It just seemed like who's going to pass up the opportunity to have lunch with the two of them? So I listened to the pitch and politely declined and told them that I was going to be a pastry chef or something. And we kept doing that every couple of months for seven months. We'd go to lunch, they would give me an update on the progress they were making, and I would decline the invitation to get involved somehow.

(00:26:05):
And then late in that year, I went to lunch one more time and Meg explained that they brought on someone to lead technology and they brought another person to lead product, and both of them really truly for reasons that are completely disconnected from Quibi itself, both of them had left after about six weeks. And Meg's like, "We've raised all this money, and we've told the world that we're shipping this product in about a year. We got an awful lot to do, and I really could use some help, and I would consider it a personal favor if you would come and spend just a couple of days a week helping." She's like, "I'll continue to look for someone who actually wants the job, but it'd be great if you could help me get this off the ground."

(00:26:53):
And my wife is a freelance writer, marketing strategist and loves her life as a freelance contributor. And she's like, "You should do this. Why not? It's two days a week, it's just a few months. What's the worst thing that could happen? Maybe you'll like it." And I'm like, "No, no. Here's the thing that will happen. I won't do it two days a week. It will immediately be three days, then four days, then five days, then six days. I just know myself." And she's like, "No." She's like, "Just on Wednesday night at six o'clock, close your Quibi laptop and be like, all they're paying me for is for Tuesday and Wednesday and then open it back up on Tuesday morning. That's all you've got to do."

(00:27:35):
Well, she's right about most things and she's wrong about this. I fell deeply into it right away, and it was just so fun to get to build a team from scratch and to design and build a product from scratch and to take advantage of all of the sort of modern software architecture stuff that had come into being over the course of the 15 years since we had started Pandora. And I'm embarrassed about some of the what happened with Quibi for sure, but I'm super grateful for the experience, because I just really fell in love with the industry again and was reminded of just how rewarding it can be to build something and to try to put it out there even if you stumble pretty mightily along the way.

Lenny (00:28:28):
Is there something that you took away from that experience that taught you what to try to avoid, to try to pull towards?

Tom Conrad (00:28:36):
I think I sort of misunderstood or misjudged companies sometimes by thinking about them really focused on the product execution. If you find an interesting problem that people care about and you solve that problem in a really beautiful, elegant, delightful way, that's 10 times better than anything else that they can get in that same space, they'll tell their friends and all the rest will take care of itself. And so that was always my ambition. Find a thing that I cared about building, do a great job building it in a delightful way, go really deep on listening to people and their feedback and iterate your way to success and breaking through that membrane that we all strive to get across, the really great word of mouth.

(00:29:27):
But I think the thing I've come to better appreciate is that companies are also, they're kind of a math problem that describes how you take investment and pour them into the equation, and out the other side comes returns on some time horizon. And yes, there are variables in that equation that are influenced by the product that you build and all of the little details and decisions that you make about making that product great. But if the equation is fundamentally broken or a big swing in and of itself, no amount of iteration and execution can get you out of the failed outputs of the broken equation.

(00:30:14):
And I think Quibi made a bet that you could build an entirely bespoke content library that was sufficiently scaled to get people to subscribe and retain for a couple billion dollars. It was a huge amount of money, but we made 70 shows in 18 months, which is more content than all of the major broadcast networks combined made in a single year. So it was a pretty major accomplishment. And we made a bet that we would augment those sort of episodic and serialized or Hollywood style shows with a bunch of daily content that we produce at the level of network television, nightly news, and so forth that would be an alternative to some of the sort of daily content that you might otherwise get on YouTube. And that was going to be about a third of the content spend.

(00:31:19):
One super interesting thing that no one talks about is that all of that content was designed to be made day of or day before it aired. So there was no back catalog of it, and it was all designed to be shot in these professional studios that we built out, and it was really expensive. Like I said, it was a third of the investment we were going to make in content, almost half the investment we were going to be making content. And we launched two weeks into Covid, and we couldn't make any of that content except literally in the garages of the host's homes. And so we had this thing that was supposed to seem really set apart from YouTube that literally now was being made exactly YouTube content, which is sort of like self-produced at home with very little sort of the support infrastructure of Hollywood.

(00:32:10):
Now you can argue, I think the content on YouTube is really, really exceptional in this category, and maybe we were never going to do better than that. But I think what was really fundamentally broken with Quibi was that the actual foundational equation of can you make enough premium content that's totally bespoke and made for the service and takes advantage of the nature of the phone, is that enough content to get people to sign up and retain, and can you do that for a couple billion dollars? And I think the answer is no. The library has to be much, much bigger and you have to have, like any company, you have to have sufficient time and energy to iterate on the content format itself. Our roadmap really wanted to innovate on the content format. And so I think part of what happened is pretty quickly it became clear that the math was just wrong. It wasn't going to take 2 billion, it was going to take six or eight or 10 billion. And the risk reward profile of betting 10 billion on the format was just more than anyone can stomach.

Lenny (00:33:20):
Next up, we've got Sri Batchu, former head of growth at Ramp who shares something that I've thought about ever since we had this conversation, which is this idea that when you fail, make sure you fail conclusively to make this failure an actual learning that you can build off of versus just a waste of time. Here's Sri.

Sri Batchu (00:33:38):
Growth experiments in my history are typically like 30%-ish success rate. So the vast majority of things that you try don't work. And so you want to create a culture where people aren't afraid to take risks and aren't afraid to fail. And for me, failure is not that you didn't drive revenue, failure is not learning. So it's really important that you learn when you fail. And so we celebrate failure as long as you're learning, and you can only learn if you've designed the right test and you failed conclusively, because otherwise I think many of us have been in situations where there's intuition that something might work and it doesn't work, and then you end up doing it over and over for years because every time a new executive or somebody else has the same idea, you try it again. And it's because you haven't been able to design the test to fail conclusively.

(00:34:31):
It's hard to do. But at the end of the day, there's only two ways to make an experiment successful. Either you have a very large M or you have a very significant treatment, which is what you're doing in the experiment itself. And in B2B, you don't usually have the luxury of large M, which you [inaudible 00:34:54] consumer.

(00:34:54):
Facebook can get [inaudible 00:34:56] in two hours. A B2B company could take two years to get to the same number of touch points. And so to counteract that, I recommend people just trying to maximize the treatment effect, which is like if you have a hypothesis that you're testing, just throw all of the possible tactics and resources that you think would move that needle because you can always cost rationalize later if it works.

(00:35:22):
And so just maximize the treatment effect. And if with all of that it didn't work, then you can say, "Hey, we're not going to try this again because we literally did try everything that we could to test this hypothesis. And if it doesn't work in the best version, and it's expensive as it is, this is not worth spending more time on." But if it does work, great. Then you do another version of the test with half the tactics or whichever tactics you think work better or worse and you optimize over time.

Lenny (00:35:49):
Is there an example you could share when you did that?

Sri Batchu (00:35:53):
Account-based marketing is something that is very common in enterprise software where you've selected certain customers that you think are high priority and you're saying, "I want to touch them in as many nuanced ways possible to see if that drives conversion." And this is something I've seen tried many times where people do it, but they kind of do it halfway where they're like, okay, tried these three things. Conversion of the control group wasn't higher, and so we think it is not going to work. And then a new go-to-market executive comes and they have to do it again. They have to do it again. They have to do it again. It's like a very common one wherever this happens. And so when we did it at Ramp, we did exactly what I just described, which is like, let's really be thoughtful about the experiment design, both in terms of maximizing the number of people as well as maximizing the number of ways and types of ways that we're effectively touching these target customers to show the value one way or the other.

Lenny (00:37:03):
So what it sounds like is the hypothesis isn't like this email will have a big impact on conversion. It's like this strategy of coming after customers is what we're testing.

Sri Batchu (00:37:15):
That's the example there. And I think for example, if you had the... This kind of framework is more important for cross-functional, larger scale, bigger tests rather than an email modification. But we can even use it on a micro example like an email modification where you are like, "Okay, I think this particular email is underperforming because it's not talking to this part of the customer's pain point or journey or what have you." And you could just, the simplest test would be, okay, let me make some tweaks to the text and edit that, and that could be the end of that test. And if that doesn't work, you're like, "Oh, maybe those weren't the right text edits. Let me do a different text edits or whatever."

(00:38:02):
And that's fine, that's low cost. It's not the end of the world and it's for you to be wrong there. But an alternative that you could do is like, "Oh, what are all of the things that I could change about this email in the same test?" Is it the trigger of the email? Is it the text content of the email? Is it additional personalization? Is it the design of the email? Trying to think of what are all of the various levers that you think could be wrong and put them all together to test your hypothesis of this touch point is wrong, and how do I improve that?

Lenny (00:38:34):
Well, obviously the downside of that is you, if it doesn't work, you don't know if it's like, oh, maybe it was this thing could have worked in the subject.

Sri Batchu (00:38:40):
Yeah, so there's always trade-offs on this, but what you're hoping is you've done a complete refresh where you did all the things that you thought were intuitive that should work. And if it doesn't work, then you're like, okay, maybe my hypothesis wrong. But you're right. There's always going to be a challenge if maybe the execution is wrong. And I did too many things potentially in that case.

Lenny (00:39:01):
Our next story is from JZ, who is a colleague of mine at Airbnb, head of product at Webflow when we recorded this episode, and this is her sharing the story of one of the biggest product misses at Airbnb.

(00:39:13):
You've seen a lot of new PMs, and you've seen these PMs succeed, you've seen some fail. What are the most common mistakes that you find new PMs make in this experience of helping new PMs get into the field?

Jiaona Zhang (JZ) (00:39:27):
I think something that is really hard to untrain, but I think every human does it, is you jump to solutions. And so one of the biggest things I see, not just in my course, but also just as a PM and some of the mistakes that you make as a PM is the idea of you get really attached to a solution, a way of implementing something, something that you can see in your head that you want to build. And so that's the first thing I really want to like unteach in our course.

(00:39:50):
And so a lot of people will literally come in, they'll be like, "I want to build X startup," or, "I want to do this thing," or, "I am in blank school, and I've been doing a lot of research on this particular area." And so untraining that and being like, "Hey, we're going to go out there. We are not going to think at all about the thing that you want to build, but instead we're going to be focused on users and people in the real world and their problems. And the first step is to understand their problems and then understand if there's an opportunity here as opposed to, hey, you want to build X thing for Y person." So that's the biggest mistake that you really have to unteach and retrain thinking around.

Lenny (00:40:25):
So let's go to the other side of this question. We talked about what mistakes new PMs make. I'm curious, what's the biggest product mistake that you've made?

Jiaona Zhang (JZ) (00:40:34):
Wow, that's a good one. It's so interesting. I feel like as product people we're always making mistakes and we're always learning. Maybe I'll give an example from Airbnb since you and I were both there.

(00:40:43):
 And this one does stand out to me. So we're working on this concept called Airbnb Plus. If you took a step back, what we're really trying to do is to be like, "Hey, not everyone trusts Airbnb in terms of it's a platform. It's not like it's managed inventory, it's not a hotel. How do you go in and really make sure that we're all the Airbnbs are meeting the quality bar?" But I do think we were very solution first, and I think we're also competitor afraid at the time. So it was during a time where there were managed marketplaces, there were the Saunders out there, and I think that as a company we're very much like, "Oh, look at this. What are we going to do in the world of managed marketplaces?"

(00:41:19):
And so we went really hard down the solution space. We essentially were like, "Let's go inspect our inventory. Let's actually try to manage our inventory more." And really what we should have done is taken a step back and be like, "What's the real problem?" The real problem is people want to know what they're getting themselves into. We need to represent the homes a lot better. And I think the other piece here that's really important is what, as a company, is there strategic strength? And what's in your wheelhouse? So for example, Airbnb, we weren't that strong in operations. We again, we're this platform with this marketplace. And so if you don't have that muscle and then you're asking the company, the teams to essentially build it from the ground up, that's really, really difficult. Not to mention the unit economics. Are the unit economics actually going to work, even as you scale?

Lenny (00:42:03):
Yeah, I feel like Airbnb Plus is an untold story that somebody should tell, and that could be its own podcast, I guess.

Jiaona Zhang (JZ) (00:42:09):
You and I can tell it.

Lenny (00:42:10):
We could tell it. This could be Airbnb Plus the hidden, the story. As you said, the problem it was trying to solve was people don't really trust, they don't want to even consider Airbnb. Like, "No, I don't want to stay in someone's home. I don't know what it'll be. It's unpredictable." And so as an outsider, it felt like a really clever approach. We're going to get them, we're going to make sure they're awesome. There's a minimum bar. And I guess this is the question is do you think it was just like this is never possible because we'll never make money as a business doing this, because we don't make that much booking and investing time, resources, sending people pillows, all that stuff is ever going to be economical. Or do you think there was a path, and it was just not executed well?

Jiaona Zhang (JZ) (00:42:51):
I think there wasn't really a clear path. I think there was [inaudible 00:42:55]. Exactly. And it was more just like if you understood, again, this is my point around unit economics, there are things where I think you have magical thinking around unit economics. You're like, "Well, when we get to the scale of X, it's all going to work out. We can make these things happen." I think you actually need to really make sure the unit economics work right at the beginning. So that is definitely one lesson.

(00:43:14):
And I think the other thing is, and going back to the spirit of what are you trying to achieve. If you're trying to achieve this idea of really knowing the quality of the place, and for a platform like Airbnb, the right way to go about doing is through our reviews, through our guest reviews, which are essentially free as opposed to literally sending out inspectors.

(00:43:32):
And I think that the other things are if you can get signal on what are the things around quality that people care about? Is it cleaning? Is it the, "Hey, I'm locked out." And I think that there are other solutions besides inspection that then get at that. So for example, it is actually cheaper to go send everyone a lockbox than to deploy an inspector and go look at your property, right? It is actually cheaper to maybe do a partnership with a bunch of cleaners in different local areas, and then get that as part of the feat as opposed to doing inspection.

(00:44:04):
So again, it's really about what are you really trying to achieve? What is the user problem in each of these areas, and can you target that problem with the particular listing that you're looking at? And so yeah, I personally don't believe the unit economics ever would've really worked out. I think we should have known that, or we should have dug into that more at the very beginning, and then to get very tailored instead of one blunt instrument to solve it all. Hey, we're going to go inspect. It's like, what is the problem for this listing, and what's the best solution to fix that problem?

Lenny (00:44:33):
Our second to last story is from Gina Gotthilf, who was an early growth leader at Duolingo. She's currently COO of Latitud, and this is her sharing a wide-ranging and important point about how everyone has both an A side and a B side to their career, and people often only share their A side. So this is Gina sharing her B side.

Gina Gotthilf (00:44:53):
We are very encouraged in our lives, especially professionally, to talk about our A side all the time because that's what impresses people. That's what opens doors, that's what allows us to keep growing, and it's so important. So it means that a lot of what you hear in podcasts and on stage ends up being the Instagramable version of someone or a company or a country's trajectory. It's just the highlights. And when I talk about my A side, it's very impressive. I did things like, we'll talk about, I met President Obama, I worked on the Mike Bloomberg presidential campaign. I helped Duolingo scale from three to 200 million users. I worked with Tumblr, helping them scale Latin America, Andreesen Horowitz invested in my company, etc.

(00:45:34):
But between all of those highlights, there were so many B moments that get shoved under the rug because it's just easier for me and it's more impressive for others. But I really like to highlight those because I think that most of us have a lot of B moments every day, every week, every month, and every period of our lives. And it's easy to think that things aren't just not going to work out for us because we're in one of those B moments if we don't recognize them as moments.

Lenny (00:45:59):
I love this concept. We're going to talk as you expected about a lot of your A side stuff. Is there any example of a B side story of your life that would be interesting to share?

Gina Gotthilf (00:46:09):
Look, I think those are the most interesting because they're funny or ridiculous. I had a lot of B sides, and I still do. For example, I had no idea what I wanted to do. I actually wanted to be. I thought I wanted to be an actress. I either wanted to be that person in Sea World, who goes like this with a dolphin. This is before Sea World was canceled. Or I wanted to be an actress. I applied to schools. I didn't get into any Ivy League. I didn't get into any of the top schools I wanted to go to. When I got to college, I actually ended up dropping out because I got so depressed, incredibly depressed, couldn't get out of bed depressed. Ironically, I dropped out of Reed College, which is the same college that Steve Jobs dropped out of. So I was just destined for greatness. I knew it at that moment.

Lenny (00:46:53):
It all makes sense looking backwards, as he said.

Gina Gotthilf (00:46:55):
Totally. I was dropping out, being like, "Yes, this is exactly the path." No, I was miserable. I thought there was no path forward. And I finally went back and graduated. The college counselor looked at my curriculum and said, "What have you even done with your life? There's nothing to show for." And it was shocking because I was always the overachiever who wants to do the maximum curriculum and ace all of my classes and do whatever. I did three diplomas in high school, the international, the American, the Brazilian.

(00:47:22):
And so that for me, I think my one learning there that has stuck with me, and I think it can work for other people too, is that it's not just about doing things that actually matter and learning. It's about being able to tell the story, and it's about understanding what other people perceive as valuable. I applied to a hundred companies. I didn't hear back from most of them. I finally got an internship at kind a tier B/C digital marketing agency in New York City because I wanted to live in New York so badly. And they forgot to apply for my visa on time. So I lost my visa and had to go back to Brazil, and then I ended up leaving that organization to go work for another one. And I won't even go into the details of the shadiness of that company that I worked for, but then they ended up laying me off. So I lost my visa again, had to go back home, found another opportunity, got fired that time. So there was just a lot of rockiness in my start that I don't think you would imagine when you see someone up on stage leading a conference for 5,000 people. That I think is important.

(00:48:26):
And even when I started working for Tumblr, I was like, "This is it. I made it. This is a really interesting company. This is going to work out." That was super rocky because it was an early stage startup. So for example, they couldn't figure out how to wire money to Brazil. So I was not paid for six months. And at one point, me and my colleagues were trying to get money out of the teller to pay contractors because we had no money to pay them, and we borrowed money from people. And finally they also laid me off because they decided to sell to Yahoo.

(00:48:54):
And then I had to figure out what am I going to do? No one's going to hire me. I've been fired and laid off so many times. So this is all before I started an agency to help US-based tech companies and startups grow in Latin America because I figured I was in this really great place to make that happen. And it eventually worked for, well-known companies such as Duolingo. At the time they weren't well-known. They were a tiny little startup. They didn't have an Android app. And that's how I started working with Duolingo because their head of marketing connected with someone they had worked with at Flickr and said, "I noticed Tumblr grew a lot in Brazil last year. Can you recommend a company or an agency to help?" And they said, "This girl." And I was twenty-six. And so that's how they connected me with Duolingo. And I started helping them grow in Brazil as a consultant. They were like, "This is great. Can you help us grow in Chile, Argentina?" And I was like, "Yes." They were like, "How about Mexico?" And I was like, "Yes." Did I know anything about these places, Lenny? Did I know people there? No, but you can figure it out.

(00:49:51):
And then they ended up asking me to come on full time, do that across the world, Japan, China, Korea, Turkey, Spain, France, et cetera. And then to own growth, which ended up meaning communications, social media, government partnerships, anything to grow. And then eventually became an A/B testing growth engine with engineers and PMs and designers of which I knew nothing about.

(00:50:15):
And even after that, I left Duolingo five years later, didn't know what to do with my life. You'd think, "Oh wow, you have it figured out now. You left Duolingo, you have the world in front of you." And I'm like, "Maybe I can finally go work for nonprofits," which is what I actually wanted to do in the first place. Tried a hand at that. Had a couple of experiences before going to work for the Mike Bloomberg campaign.

(00:50:36):
Working for the Mike Bloomberg campaign is impressive. But you know what? Mike Bloomberg didn't win. He's not the president. So that was not a successful campaign if you really look at it. And yeah, Latitud seems like it's a really promising path, but there's A days and B days. So it's just a lot of that. And just staying resilient and believing in yourself and getting back on the horse when you fall on your face.

Lenny (00:51:00):
Amazing. That's such an important message. I think one of the threads from what you're describing, something that I think about a lot is people kind of underestimate how long their career is. There's just so much time to do stuff and for things to start to work. This going to sound really fancy, but I think Marcus Aurelius has this quote about how our life is actually very long. We just use it really badly and we just waste a lot of our time.

Gina Gotthilf (00:51:21):
I think you're so right, Lenny, and I love that because people are going around being like, "Life is short, life is short." But that's so true. We waste so much time. But also I think we don't recognize how much opportunity we have in front of us. And as a 26-year-old, I definitely thought my career was over. I was like, "I blew it." And looking back, it's funny.

Lenny (00:51:40):
Yeah, I know exactly what you mean. I spent nine years at my first job at a random company in San Diego in a startup. I was like, "What am I doing here so long?" And it turned out that was really useful for the thing I did next. And then eventually, wow, things started to really take off. So I think that's a really good lesson for people. It's just a long time. This is my fourth career. I've switched careers many times. I was an engineer then. I was a founder. Then I was a product manager, and whatever this is. Whatever you call this thing.

Gina Gotthilf (00:52:06):
I guess me, too. I was an operator. I was a consultant. Well, I was an employee. I was a consultant. Then I was an operator, which is a fancy way to say employee at a startup. And then now I'm a founder and a VC and an angel and whatever this is..

Lenny (00:52:22):
Awesome. Awesome. So I think that's a really important takeaways. Just there's a lot of time to do stuff and don't stress if things aren't moving as fast as you want. I'm curious, what's a mess-up or a big mistake maybe that you made or your teammate that was like, "Oh wow, that was a big waste of time."

Gina Gotthilf (00:52:38):
Yeah, look, a lot of things didn't work out. More than 50% of our A/B tests didn't work out. We made bets that didn't make sense. I will say though, that in the spirit of A and B sides, I, and I think in general, we are really good at forgetting the B stuff. I talk so much about all the stuff that worked that it's hard to remember all of those moments that didn't actually work. And the thing that I tend to talk about, which is this mistake that we made as the growth team is almost like one of those, when you get asked in an interview, what's your biggest weakness, and you're like, "I'm a perfectionist." It's like one of those things that actually makes you sound good because it's the story about how my team really wanted to implement badges. We spent a lot of time playing all the games that were popular at the time, trying to understand how those gamification growth hacks that we could find in those apps would potentially overlay onto Duolingo and how we would do that.

(00:53:35):
And badges was just pervasive in all of the top games. And so it seemed like a no-brainer, but since we ranked all of our experiments in terms of ROI and return being like how many users we think we're going to get from this DAUs, and time investments, it never made sense to focus on this because we thought that the time sink would be too high. So I actually ended up not letting the team run this experiment for six months so that we focused on lower hanging fruit. So that's a mistake on my end.

(00:54:04):
Then we decided to run this experiment in the most lean way possible. We're like, "You know what? There's MVEs. There's minimum viable experiments. We don't have to run a whole badges thing. We can just do something more simple and actually see if that leads to growth in an interesting way, and then we'll know."

(00:54:20):
And we ran this very simple experiment that was like, you signed up and then you get a badge. And it was like this girl with a balloon. I don't know, she was happy or whatever. And of course in retrospect, it led to no results, because no one is proud of signing up. It's not an exciting moment, and you don't even have badges to collect. You can't show it to other people. None of the things that make badges compelling were there, but we were like, "Okay, well, we tested it didn't work." And then we moved on.

(00:54:42):
So we moved on for another, I don't know, eight months and we didn't look back. And then when we did look back, first of all at that point we discovered that we hadn't been dogfooding, which also was embarrassing. Looking back, we hadn't been dogfooding in the growth team. We just come up with hypotheses. We were super careful about prioritizing them and making sure that we were doing the best possible write ups and all these things. But the dogfooding piece, I didn't come from a product background. I was a marketer and I didn't really understand the term dogfooding, but when we thought, we had a conversation, we were like, "You know what? If we had just tested that, we would've all known that this was a super lame badge." And I was like, "Why are we not testing our experiments?" And so that became part of our practice.

(00:55:26):
It's still relevant. I just had a conversation yesterday with engineers at Latitud. I haven't explained what we built yet, where we're building it. Maybe we'll get there, but I was talking yesterday, [inaudible 00:55:35] at Latitud, and they're awesome. In terms of product team, we have the number eight employee at NewBank. You might've heard of NewBank, but it's this massive banking fintech in Latin America. And we have people from other fintechs. And then we have this guy who was a lead PM at Twilio, and I was explaining to them why we should be dogfooding. And they were all like, "Oh yeah, we should dogfood." It's just easy to forget stuff like that.

(00:55:58):
So that was a mistake that we could have probably gotten to the growth that we got to with badges much earlier on. And not only did we get to growth with badges, but it became this amazing treasure trove of opportunity because once you have badges and people want them, you can now ask people to do anything. Go find friends, go buy things, whatever it is. And so we impacted almost all metrics across the company positively, including some we hadn't expected, but it's easy to talk about a mistake that ended up being a win. So that's why I compared it to the interview thing in the beginning. But we tried making Duolingo a social app really early on and failed. It was called Dual Duels. Dual Duels. You could duel.

Lenny (00:56:42):
Very clever.

Gina Gotthilf (00:56:43):
Yeah, I know we were clever, but people didn't use it and we didn't figure out why. We tried making a Duolingo for schools platform. We couldn't get it to pick up. I went and watched dueling go in China and it got downloaded by a million people in the first day, and then the app got blocked because of the government, and then we couldn't figure out what to do. And then everyone rated the app like one star because it didn't work. And so then we had a lot of trouble actually recovering from that. We launched Duolingo in India and didn't realize because we couldn't have unless we went there, which we finally did, that most people set their phone UI in India to English, because typing in Hindi is hard. And of course there's a lot of languages throughout India, and we were making it so that when you downloaded Duolingo, whatever UI you open your app, your phone was set to, we offered not that language for you to learn. That was your base language. So we were telling people learn French, Spanish, German from English, and they were all trying to learn English, so they didn't find what they were looking for and they left. There were so many mistakes and luckily I think we were able to bounce back from most of them in terms of how Duolingo was doing today.

Lenny (00:57:53):
And our final story is from Maggie Crowley VP of product at Toast, and one of the most beloved episodes of the podcast. This is Maggie sharing something a little bit different, her favorite interview question about failure and what it tells you about the person you're interviewing. Plus a story of her own product failure. Here's Maggie.

Maggie Crowley (00:58:12):
A question I ask in every product interview is, what's the worst product you've ever shipped? And that's because I don't think you're a good PM if you haven't shipped something that's really shitty. You just haven't had enough reps, you haven't done it enough times. And it's not only that you've done it, but that you can admit it and which one it is. That's so important.

(00:58:34):
I remember... It was so dumb. I'm still so mad about this that we did this. I won't name which team, which company, I'm not going to call that out, but we decided we needed to do a rewrite red flag number one of existing product, and engineer who I'd worked with many times, we had a really good relationship and this person was like, "Yeah, yeah, it's going to take six months. No problem." Core part of the product, been around for forever. One of those things that the code is still the code written by the founders kind of thing.

(00:59:07):
It didn't take six months. It took two and a half years. It still wasn't done. It almost never... It went on for so much longer than it should have. It took us forever to get to feature parody. It was the worst project. So many people rotated in and out of it. Everyone thought it was dumb. Sunk cost fallacy, just the worst. And it's because, A, we got arrogant and we thought we could do it. B, we skipped discovery. We didn't really write a one pager. We just went for it. We didn't do enough technical and design research into what the requirements would actually have to be. And there you have it.

Lenny (00:59:46):
And did not work out, or was it a huge success in the end and it changed the trajectory of the business?

Maggie Crowley (00:59:50):
Absolutely not. But you know what? I didn't get fired, so it's fine.

Lenny (00:59:54):
I feel like I've gone through those experiences and then three, four years later, it's like another... Maybe this rewrite and redesign may work. We haven't updated this thing in a long time.

Maggie Crowley (01:00:04):
Just don't do it. Don't rewrite. If anyone ever tells you to do a rewrite, don't do it. A side-by-side rewrite, nope.

Lenny (01:00:11):
Yeah, I've never had... What I run into is once you get too far down a redesign slash rewrite, everyone's building in that new world, and then you launch, and experiment's negative, and then it's just like, "Oh, we just got to launch it. We're going to call it back. We're going to figure out how to get back to neutral someday."

Maggie Crowley (01:00:26):
Yeah yeah. Don't do that.

Lenny (01:00:28):
Good times.

(01:00:29):
And that is a wrap. I hope you enjoy these stories of failure. I want to give a huge special thank you to all of our amazing guests for being vulnerable and sharing these stories of failure in their career. I hope you leave this episode with a new perspective on how setbacks and challenges and failure can often be exactly what you need to get to the next step of your career or your life. If you've got a great story to tell about failure, I'd love to hear it. Leave a comment either on YouTube or on Lennysnewsletter.com or just DM me on Twitter. Or you could reach out at LennyRachitzky.com and click the big contact button. Thank you for listening. Bye, everyone.

---

## How to build trust and grow as a product leader | Fareed Mosavat (Reforge, Slack, Instacart, Pixar)
**Guest:** Fareed Mosavat  
**Published:** 2022-10-23  
**YouTube:** https://www.youtube.com/watch?v=oo0jSep7pzc  
**Tags:** growth, activation, onboarding, metrics, roadmap, experimentation, analytics, conversion, monetization, hiring  

# How to build trust and grow as a product leader | Fareed Mosavat (Reforge, Slack, Instacart, Pixar)

## Transcript

Fareed Mosavat (00:00:00):
You can't do homework. You can't do exercises. You can't do fake stuff. You have to work on real products at real companies with real customers, with real data to get better at product management. So any kind of training, mentorship, reading, et cetera that you do is just a layer on top of that. The real acceleration happens from doing it and getting more reps. There are ways that I think great PMs use to go faster on this loop, but you still have to do the work. At the core is you have to actually execute and deliver great products, and you have to do it over, and over, and over again.

Lenny (00:00:40):
Fareed Mosavat is the Chief Development Officer at Reforge where he's been for over two and a half years. Before that, he spent three and a half years at Slack leading a lot of their growth efforts, about a year at Instacart leading a number of their key growth analytics and product efforts. He's a GM at Zynga, he's VP of Product at Runkeeper, and something that I only learned during our chat is that he spent six years at Pixar doing character simulation, rigging, and building 3D animation tools. In our conversation, we focus on the journey of becoming a great PM, including crossing the canyon from IC to manager, the importance of expanding your scope, and how to create opportunities where you get more responsibility as a PM. Fareed is such an A-plus human full of so much insight, and I'm really excited for you to learn from him. With that, I bring you Fareed Mosavat.

Lenny (00:01:32):
This episode is brought to you by Coda. Coda is an all-in-one doc that combines the best of documents, spreadsheets, and apps in one place. I actually use Coda every single day. It's my home base for organizing my newsletter writing. It's where I plan my content calendar, capture my research, and write the first drafts of each and every post. It's also where I curate my private knowledge repository for paid newsletter subscribers, and it's also how I manage the workflow for this very podcast.

Lenny (00:01:59):
Over the years, I've seen Coda evolve from being a tool that makes teams more productive to one that also helps bring the best practices across the tech industry to life with an incredibly rich collection of templates and guides in the Coda Doc Gallery, including resources from many guests on this podcast, including Shreyas, Gokul, and Shishir, the CEO of Coda. Some of the best teams out there, like Pinterest, Spotify, Square, and Uber, use Coda to run effectively and have published their templates for anyone to use. If you're ping-ponging between lots of documents and spreadsheets, make your life better, and start using Coda. You can take advantage of a special limited-time offer just for startups. Head over to coda.io/lenny to sign up and get $1,000 credit on your first statement. That's C-O-D-A.io/lenny to sign up and get $1,000 in credit on your account.

Lenny (00:02:59):
I'm excited to chat with my friend, John Cutler, from podcast sponsor Amplitude. Hey, John.

John Cutler (00:03:03):
Hey, Lenny. Excited to be here.

Lenny (00:03:05):
John, give us a behind-the-scenes at Amplitude. When most people think of Amplitude, they think of product analytics, but now you're getting into experimentation and even just launched a CDP. What's the thought process there?

John Cutler (00:03:16):
Well, we've always thought of Amplitude as being about supporting the full product loop. Think collect data, inform, vet, ship experiments, and learn. That's the heart of growth to us. So the big aha was seeing how many customers were using Amplitude to analyze experiments, use segments for outreach, and send data to other destinations. Experiment and CDP came out of listening to and observing our customers.

Lenny (00:03:37):
Supporting growth and learning has always been Amplitude's core focus, right?

John Cutler (00:03:41):
Yeah. So Amplitude tries to meet customers where they are. We just launched starter templates and have a great scholarship program for startups. There's never been a more important time for growth.

Lenny (00:03:50):
Absolutely agree. Thanks for joining us, John, and head to amplitude.com to get started.

Lenny (00:03:58):
Fareed, welcome to the podcast.

Fareed Mosavat (00:04:01):
Thanks for having me, Lenny. I'm super excited to be here.

Lenny (00:04:03):
So to set a little context for listeners that aren't super familiar with you, can you give us just a 45-second overview of your career and all the wonderful things that you've done?

Fareed Mosavat (00:04:14):
Great. Hi. I'm Fareed Mosavat. I live in Berkeley, California with my wonderful wife and two children, but I've been a product leader across a variety of different companies over the course of my career. Today, I am the chief development officer at Reforge where I help run all of our content teams, parts of our operations, and our partnerships with wonderful experts like yourself.

Lenny (00:04:33):
Awesome. What about all the other things you've done?

Fareed Mosavat (00:04:35):
So, previous to this, I spent almost four years as the director of product for a team called Lifecycle at Slack that is effectively a growth team. We're responsible for the self-service business at Slack all the way from first sign up, first team creation through to the first invites, activation, expansion, modernization, and even connecting the dots with our SMB sales team to help nurture some of those small self-service teams into larger commitments through our sales team.

Fareed Mosavat (00:05:02):
I came to that through a variety of different growth and product leadership roles at a bunch of different startups on larger companies. I built one of the first growth teams at Instacart for about a year and a half in the middle of their acceleration. I was VP of Product at a company called Runkeeper before that in Boston, health and fitness tracking company. I was a general manager at Zynga. I got there through a startup that I was an engineer at, basically started as an engineer, ended as a head of product over the course of a couple of years, and then got acquired into Zynga, and actually started my career with almost seven years at Pixar Animation Studios working on visual effects, software tools, and other creative tech to try and solve problems for a bunch of wonderful films you've probably seen or your kids have seen.

Lenny (00:05:45):
Please tell us the films that you worked at. I had no idea that you worked at Pixar.

Fareed Mosavat (00:05:48):
I am credited on Finding Nemo, Cars, Wally, and Up.

Lenny (00:05:55):
What? I did not know any of this.

Fareed Mosavat (00:05:57):
Yeah. Yeah. Basically, I started there right out of college. I was super interested in computer graphics. I'd actually been an intern there, was very lucky to be interested in that in the moment where they were really accelerating the growth of the company going from like the whole company is working on one film to like, "Okay. We're trying to release a film every 18 months." So they really scaled up, and I had been studying computer graphics, and then I was an engineer focused on computer graphics and a little bit of research on that in college, was an intern there, and joined, and just got to see a fun growth period at that company, and really, I think in a lot of ways is the root of why I love doing product management because everything I worked on was at the intersections of interesting creative problems, interesting technical problems, and interesting storytelling problems.

Fareed Mosavat (00:06:45):
So, in a lot of ways, it was like... I think if I connect the dots backwards to the Steve Jobsism is the beginning of how I got interested in solving high-level strategic problems across a bunch of different people doing different kinds of work and maybe how I got relatively good at it. It was because even as an engineer, I was sitting in the middle of those pieces, but I got bored, which sounds crazy, and decided to jump into a startup that nobody had ever heard of that had eight employees in 2006, and the rest is history from there.

Lenny (00:07:17):
Yeah. I wasn't planning to talk about Pixar, but I am so curious. One more question there. What's something that you learned from Pixar that has informed the way that you build products or think about product or your career?

Fareed Mosavat (00:07:28):
At the foundation of it is when I first got there, I thought what was important was modeling how things work in the real world. They're making things look right, so to speak. What I learned there is that actually, you're trying to deliver an end experience, and product, and story to your viewers, to your audience. It doesn't actually matter what's real. It matters what you see on the screen. It matters the emotion that it creates, the story that it creates, how it reinforces all of the other pieces. So the technical pieces were just a means to that end. So, of course, we used real physics and real math behind the scenes to do stuff, but if you had to box the numbers to make it look right, that's the right thing to do.

Fareed Mosavat (00:08:15):
So I remember as I was working on early effects, bubbles, sand, so this kind of stuff, I was trying to do things the way it would really work, and then the camel would look at it, and almost the first lesson I learned there was like, "No. What matters is the end result, the end product, the end feeling." I feel like I go back to that a lot as I think about product development not just from an engineering and technical standpoint, but from what's in your strategy doc isn't that important. It's actually just an input into the end experience that you're trying to deliver for customers. When we're thinking about content development in our programs, it's not important that all of the principles fit perfectly together into this MEC framework. It matters that you help people solve actual problems. What's the end goal that you're looking for? I feel like that's the lesson that I just keep going back to for my time there.

Lenny (00:09:06):
It's a great segue to Reforge, which I want to spend a little bit of time on. Folks that listen to this podcast know that I'm a huge fan, and we have a lot of Reforge alumni on this podcast.

Fareed Mosavat (00:09:15):
Yeah.

Lenny (00:09:16):
So a couple questions there. One, you said you're a chief development officer. Is that your title?

Fareed Mosavat (00:09:20):
Yes.

Lenny (00:09:21):
What is it that you do as a chief development officer?

Fareed Mosavat (00:09:23):
It's funny because in a lot of ways, it's not a made-up title, but trying to figure out how a role that I ended up sliding into as I grew my engagement with the company, how do we describe what it is? So I think what's unique about Reforge versus a traditional software startup, or a SaaS company, or all the other things you see is that we're not just a software company. Of course, we have a website. Go to it. You see things, you deliberate, but we also build a lot of stuff and experiences that fit into that. We build content. We build programs today. We're going to build all kinds of other content. We have live cohort experiences that are designed and thoughtful, and we build and try to make, solve certain customer problems.

Fareed Mosavat (00:10:08):
We have a member slack that we try to design to solve certain problems. We have the people like yourself and a lot of the guests that you've had on the podcast like Elena, or Adam Fishman, or Casey who plugged into our system to help us build all of those things because at the end of the day, our job is to help unlock the expertise that's locked in the heads of the greatest operators in the world. So who do we work with? How do we develop that content? How do we make their ideas shine? How do we solve real member problems? How do we help people do work?

Fareed Mosavat (00:10:38):
A lot of that is a product experience that in some ways, like a Pixar movie, there's the technical aspects and the UX aspects, but there's also all of the content, and the partners that we work with, and those pieces. I own all of that piece, like the production, content, the new product experiences, and all of the pieces that fit in there. So we have a team of really talented, amazing people that work on these things, and I lead those teams.

Lenny (00:11:02):
It's interesting how that comes back to your Pixar experience of the combination of intersection of art and technology.

Fareed Mosavat (00:11:09):
Yeah.

Lenny (00:11:09):
That's so interesting. Okay. Never thought about it that way. Yeah.

Fareed Mosavat (00:11:12):
Like we said, it's easier to connect the dots in reverse than moving forward. I have always been not that precious about titles, career roles, et cetera. I've really found myself drawn to, "Is this an interesting problem that I believe I can bring something valuable to the table? Can I help solve this in some meaningful way, and will I learn something great and new from this role?" At every step, I made those decisions. I've gone up and down the title stack from VP down to ICPM, from engineer to product, from product to this new thing and content. In every single one, I think it's a lot about, "What are you bringing to the table to help solve that problem? What are you taking away from the job and learning from it, and how do you turn that into the next step?"

Lenny (00:11:57):
Awesome, and we're going to chat about a lot of those learnings from your experience going through these career journeys, but one last question on Reforge. Just like how big is Reforge at this point? How many cohorts? How many students? How many people work there? What's the operation scale at this point?

Fareed Mosavat (00:12:11):
It's hard to count how many employees because it's growing so fast. I believe we are at just around 150 total employees across the whole company right now.

Lenny (00:12:19):
Wow.

Fareed Mosavat (00:12:20):
That doesn't include our executives and residents, subject matter experts, and the partners we work with. That's full-time employees working on the business. Of course, we have a large product development, product design, engineering, and data teams, but also the teams that I run. We call them strategy leads, content producers, content strategists, content designers, building all of that content as well as our partners team and operations team. So it's a relatively large company at this point. When I first started working with it, it was a scrappy operation of just a handful of folks, but we've grown quite a bit of over the last year.

Fareed Mosavat (00:12:51):
With that, we support, I believe, now 19 total cohort-based programs across product, engineering, marketing, and growth-related topics as well as a bunch of new experiences that we're working on for the coming future here in the next year. We have well over 10,000 active members on the platform, about a dozen executives and residents that work to help us deliver those programs, and hundreds of partners. We call them experts and operators in the space who contribute to our programs in different ways either as guests or as mentors, or helping us develop content behind the scenes.

Lenny (00:13:25):
Awesome, and I taught a couple guest lectures this past cohort. I think my second ever lesson was with you. You were the teacher?

Fareed Mosavat (00:13:32):
Yes. Yeah. We talked about instant buy, I think they're called, but I can't remember the name.

Lenny (00:13:37):
Instant book. Close, close.

Fareed Mosavat (00:13:38):
Instant book, sorry.

Lenny (00:13:38):
Yeah.

Fareed Mosavat (00:13:38):
On the Reforge platform for experimentation and testing program, which was, yeah, actually, also my first program that I helped lead at Reforge, and I think you were my first guest.

Lenny (00:13:47):
Oh my god.

Fareed Mosavat (00:13:47):
So, thanks. Thanks for not making me look bad.

Lenny (00:13:51):
Thank you. So what's cool about your background working at Reforge and all the companies you worked at is that you've seen a lot of PM careers go well and PM careers go not so well. So what I want to spend our time on is talking through just the career development journey for product managers and in particular, the challenges that PMs face trying to become better PMs and just why it's innately tricky to become better as a product manager. It's such a weird job to get better at. So my first question is actually, why is it so hard to become better as a PM? Why is it innately a tricky thing to develop as a PM?

Fareed Mosavat (00:14:28):
One of the trickiest bits about it is that there's no clear, obvious pre-training you can do that gives you a baseline set of understanding that you can use to be a product manager. People come from MBAs, people come from certain kinds of majors in college, et cetera, but it's not engineering where like, "Okay. With a couple of weeks of bootcamp or a couple of years of a computer science education, I have some foundational knowledge that helps me go from zero to one in my first job." Not only does it help me break in because I have a credential that helps me land that job, and we can talk about why landing your first PM job is so hard, but also, there's not a lot of stuff that one-to-one directly correlates to the work you're going do on a day-to-day basis.

Fareed Mosavat (00:15:11):
I think there's an idea that Naval Ravikant talked about on Twitter and in blog posts a long time ago, this concept of specific knowledge that can only be gathered by actually doing the work. A lot of product management, really, is like that. You get better by doing it, and so you start in the same place, if that makes sense. Of course, there are different skills and intellectual capacities, et cetera that help different people be more successful at it, but at the end of the day, you don't know if a PM is going to be great until they start doing that work. So I think that's one of the pieces that's very hard.

Fareed Mosavat (00:15:41):
The second is the thing I just alluded to, which is breaking in and getting your first role. It's just a very difficult situation for a lot of companies, and there are a couple of different paths to it, but none of them are straightforward. There's no clear linear path, except for maybe being a Stanford or Harvard grad, top-tier school grad, NCS with an internship, goes to Google to do an APM program. There are a couple of these things that are surefire, but I don't think they guarantee success, and they are actually very limited in terms of the number of people that they let into the business.

Fareed Mosavat (00:16:13):
So I think this is what makes it so hard is that there's not any upfront training you can really do to prepare yourself or even knock down the door to break in. But then, also, it's not clear there's a lot of training within a company that would help you be successful generally on the job of product management. You can learn how to be a good PM at Google, you can learn to be a good PM at Facebook, but it is up to each individual PM to figure out how to generalize what they're doing to move from different kinds of product across different kinds of product work as they get more senior to solve bigger problems, et cetera.

Fareed Mosavat (00:16:51):
So what we tried to do at Reforge is we are focused on helping people accelerate that learning loop. It's not, "Hey, if you take this class, now you're qualified to be a PM." It's not really like that. I don't know if that's possible. I hope it will be someday, but it is very difficult. I think it's more, "Hey, we want to help you when you encounter certain kinds of problems, not have to solve them from first principles, but following the footsteps of the people who have done great work in the past, generalize those lessons." But at the end of the day, you still have to get down and do the work.

Fareed Mosavat (00:17:25):
You can't do homework, you can't do exercises, you can't do fake stuff. You have to work on real products at real companies with real customers, with real data to get better at product management. So any kind of training, mentorship, reading, et cetera that you do is just a layer on top of that. The real acceleration happens from doing it and getting more reps. There are ways that I think great PMs use to go faster on this loop, but you still have to do the work. At the core is you have to actually execute and deliver great products, and you have to do it over, and over, and over again.

Lenny (00:18:03):
Yes. Let's absolutely dig into that. Let me put out a couple mental models that I'm thinking as you're talking.

Fareed Mosavat (00:18:07):
Sure.

Lenny (00:18:08):
One is just if you think about a pie chart of a great PM's career and/or investments they make along their career journey, how do you break up that pie chart? Like some percentage is doing the work, some percentage is courses, maybe some percentage is books. So just putting that out there in case that's useful to think about, and then the other is thinking about the trajectory of a PM on a line chart, and what are these inflection points that you've seen most impact the career trajectory of a PM?

Fareed Mosavat (00:18:34):
So let's start at the first one, the pie chart idea. What percent is spent on different things? Unsurprisingly because Reforge is all about growth loops, I think of this in terms of a loop actually, which is like, "What is that learning or career acceleration, or ability acceleration loop? At the core, again, at the top of the loop is execution. You have to have a real problem. You're working on with real customers that you want to solve in some way. So, you're executing. You're delivering. You're learning at the beginning. It's all about execution. So we'll start with the pie chart at the beginning. It's almost all execution.

Fareed Mosavat (00:19:06):
What are the problems you give a junior or brand new PM? Known problem, known solution. "Please work with engineering and design to deliver that thing on time, and then tell us what happened." So it's like a very tightly constrained problem. As you level up, then some of these things become more unknowns. So there's execution, but I think the next step that great product managers do is they think about how to generalize that execution a little bit. So it's not just, "Okay. Now, I know what the best settings page for Slack is." It's, "What generalizations did you make? What are the things that you can take that are applicable to other stuff?"

Fareed Mosavat (00:19:49):
Some of that is execution-oriented, how to best work with engineers, how to iterate on designs, what customers do and don't do, rules of thumb, those kinds of things. I think that's where reading courses, et cetera can help because sometimes by bringing other... or one-on-one conversations with experts, et cetera. There are a whole bunch of different ways, but is that the generalization step? "Hey, I did this thing. Oh, other people have done something similar. How do I connect the dots on that? How do I make this experience bigger than what I've just done and lead me to help solve other problems?"

Lenny (00:20:23):
These are things you're doing in your head, basically. You're just developing frameworks, mental models, things that you're just taking with you to the next project in your mind.

Fareed Mosavat (00:20:31):
Exactly. So, to use an example, there was a time at Instacart where we were working on onboarding, brand new onboarding and activation flow for customers. We tried a lot of different stuff. We tried the slimmest, fastest, lowest friction, least number of steps path in, and then we had this hypothesis about helping people get set up. So we took the opposite approach, which was a really long onboarding with a bunch of different steps and wanted to see, "Was that more effective or less effective?"

Fareed Mosavat (00:20:59):
The generalization is, "Oh, for products that had a high bar to activation, sometimes more set up and higher friction, good friction could actually help those customers be successful. There are other kinds of products that are high-intent where they know what they need to do to have simple actions where lowering friction might be the right thing." So, that's a generalization. It's a generalization of, "Oh, I learned a thing." It's a hypothesis about how that might generalize other kinds of products or other kinds of problems that you approach. I think some of that can come from seeing it from the outside, listening to a podcast, hearing you say it, taking a course, et cetera. But at the end of the day, you have to experience it to see how it applies to the world.

Fareed Mosavat (00:21:42):
Then, the next bit is communication, and I think this is a bit that a lot of product managers, obviously, and any job miss, but you can't just do the work. You have to actually communicate the work. You have to talk about what you're doing, what you've generalized, what you've learned so that you can hit the next step, which is scale your opportunities. Go from smaller known problem, known solution to maybe known problem, unknown solution type of work, which is the next step.

Fareed Mosavat (00:22:08):
Then, eventually, to where you want to be as a senior, great, high-level individual contributor PM to the not quite known problem, maybe a goal with a set of problems and unknown solutions, unknown problems, unknown solutions, where you're actually identifying customer problems and moving towards on that. So scaling up your opportunity, and then executing again. I think of this as a loop of learning, and so of course, the percentages change over time as you move more senior in your career, but also, depending on where you're at in the step that the percentages change.

Lenny (00:22:40):
Got it. So, just to recap, execute, just do the work, just ship.

Fareed Mosavat (00:22:44):
Yeah.

Lenny (00:22:44):
Generalize learnings from shipping to build up your gut feeling of what will work and not work.

Fareed Mosavat (00:22:49):
Exactly.

Lenny (00:22:50):
Learn to communicate things you're doing, and then scale the things that you're executing based on this gut feeling you're building, and communicate that out, and just continue. Do you think scaling take on more scope or have more impact? Is that how you think about scaling, that last piece?

Fareed Mosavat (00:23:06):
Yeah. I think it's one moving from knowns to unknowns.

Lenny (00:23:08):
Great.

Fareed Mosavat (00:23:09):
So like you're being given a hairier, harder to untangle types of problems with more unknowns and more autonomy. I think the second is, yeah, of course, with... although I think for the beginning of your career, you tend to go deeper. So it's like, "Okay. I'm going to work on growth, let's say, or core product, or zero-to-one products, or technical scaling, whatever it is. I'm going to go deeper on that," and then over time, that turns into width, but this is why the generalization step is important.

Fareed Mosavat (00:23:39):
If you want to be a product leader, you cannot be seen solely as a specialist in that certain kind of product work, and so the generalization step is really important. If you want to move from growth to core product, you need to show that you're not just running experiments and driving numbers up. You need to show and communicate that you're learning deeper lessons about how customer psychology works, and what products people resonate with, and how to think about the business more holistically, and then communication. No one knows what you're thinking if you don't tell them. So if you don't communicate, you don't have control over those scaled opportunities. Usually, your manager, or the organization, or the company does. Maybe by switching jobs, you have some control, but you need to earn that right. You need to communicate. That's why I think there's pieces of the loop you can control and pieces that are externalized.

Lenny (00:24:25):
I'm curious, in your own career, what the biggest inflections of growth have been either in terms of learning, or impact, or just opportunity?

Fareed Mosavat (00:24:33):
The first big one was when I switched from being an engineer to being a product... I didn't even know it was product management, but a product leader of some kind. I think there are two things that happen. One is you got to be doing this stuff, but often, somebody needs to see it. The scale opportunity piece of the step often requires someone from outside to notice that you're doing something really well and trust you with a bigger opportunity. I think of this as sponsorship, not mentorship. I don't necessarily find that in my career. I've had a lot of managers where I'm like, "Wow, their day-to-day help was super awesome at helping me be a better leader."

Fareed Mosavat (00:25:10):
I hope that I've been that for some people, but I don't have a ton of examples of that in my career. But what I do have is a couple examples of people who deeply trusted me to solve big problems, and I don't know. I'm lucky to have had that or otherwise, but one was a CEO of that startup who's now a venture capitalist. His name is Nabeel Hyatt. I was like, "Hey, you seem to understand the data better than anybody here. You're solving these problems. Help us figure out what we're going to do next," which now we call product management.

Lenny (00:25:36):
But he was at, by the way?

Fareed Mosavat (00:25:38):
it was called Conduit Labs.

Lenny (00:25:39):
Okay. Yeah.

Fareed Mosavat (00:25:39):
It's a game company. Then, eventually, I was the director of product for our Boston studio. The next was at Slack. I was an ICPM working on activation and growth on a team of three or four other PMs, and there were a couple of moments where by communicating my work and talking through how I was solving problems, people noticed that I knew what I was doing and gave me bigger and bigger opportunities. One of those was Merci Grace, who I think has been on your pod and was a wonderful sponsor for me. Then, again, when Merci left, April Underwood, who's the CPO, said, "It seems like you have a handle on this. I'd like you to take on a bigger range of problems across all of this growth and not just the modernization piece that I've been working on before." So I think in each of those steps it's about creating trust and knowing that you have a sponsor there, someone who's going to go to bat for you.

Lenny (00:26:25):
I really love this point of sponsorship. We haven't talked a lot about this on the podcast. There's a lot of talk of finding a coach or having a manager that teaches you how to do the job, but this idea of just getting to a place where someone gives you an opportunity to shine, and that's been really big in my career just like certain managers just, "Here, Lenny. You take this, and let's see what you can do."

Fareed Mosavat (00:26:44):
Yeah.

Lenny (00:26:45):
Is there anything else you can recommend to folks to create opportunities for sponsorship? You talked about communication, executing well. Is that just the core of it, like doing a great job and communicating the great job you're doing?

Fareed Mosavat (00:26:57):
This idea that it's what you do and that's multiplied by your ability to show that work and communicate it, and that's the impact that you can have, but you have to have not just impact on the customers, but also on the organization. I think it is impact on the organization, changing the way people think about problems, helping generalize what works and what doesn't work, bringing learnings to the table.

Fareed Mosavat (00:27:18):
For me, I've worked a lot on growth, and I've treated a huge part of my job as not just moving the numbers, but also teaching the organization how our growth model works, how the pieces fit together, what our customers care about, what's working, what's not working, and that creates a lot of, A, leverage in other parts of the organization because they can do better work by having more information, but also, B, trust. Trust from leadership, trust from your peers, and otherwise.

Fareed Mosavat (00:27:44):
So, now, how do you get to that? Some of it is just luck. Someone has got to believe in you. You can create your luck by being good at communicating and solving hard problems. I think the other piece is knowing when you go into an organization, "Is this a role that's important to the company? Is it on the list?" I think it is easier to find sponsors, communicate, and create leverage if the thing you're working on is in the top four or five most important things the company is working on. I find myself drawn to those kinds of problems, and I think that's one way because then, all of a sudden, CEOs notice what you're working on, heads of product notice what you're working on, and your peers notice what you're working on.

Fareed Mosavat (00:28:22):
The other bit is curiosity. I think to be in the seat where people want to sponsor you, I think you have to show a handle on not just what you're doing, but how that relates to all of the things around you. So I call this going two stack levels up, two stack levels down in terms of your curiosity and what you understand, and also, knowing what's to the left and what's to the right. So let's use the example of if I'm working on activation on growth, let's say, or monetization. It doesn't matter. One of those two pieces. When I say two stack levels down, I like to understand how we build customers, how it works in Stripe, what are our dunning policies, what are the technical things that work and don't work in the pieces maybe down to the database. Right?

Fareed Mosavat (00:29:08):
It's like technical curiosity, those kinds of things, but also mental models for what's above you. How do we grow? How does modernization fit into that? What are the trade-offs versus free growth versus paid growth? How important is this to the company? How does it fit into our long-term strategy? Those kinds of things. So it's like the strategic things above you. I like two stack levels because it's like you should understand your boss's priorities and your boss's boss's priorities. Eventually, that means you have to know what the board is thinking, right? Then, left and right is, "What are the core product teams working on that I could help advise on in terms of modernization or they could advise me on what they're thinking and what might be coming next? How do we fit together with the enterprise part of the business even though I'm working on self-serve? How do I think about sales? Do they have input, like interesting customer conversations or input?

Fareed Mosavat (00:29:58):
It's this curiosity like walking around, getting to know what people are doing, and being seen as an expert. Are you the desk people go to when they have questions? Are you a person that people ask the opinion when you're trying to figure out how the dots connect? I have found for me, maybe this is just because this is a strength of mine, that connecting the dots of how the whole company works and how all the pieces fit together has been one of the ways that I've driven that sponsorship. I think for each individual, you have to figure out what your superpower is and where you can be actually top 10%, and then lean into opportunities and also problems that help you show that and shine it that way.

Lenny (00:30:34):
That is such cool advice. I think what's cool about that is I imagine you just go to your manager and even just ask, "Hey, I'd love to understand just what are your highest priorities, and then what are your manager's?" Just ask these questions. Just that alone I think communicates a lot about how much you care and your interest there, and that creates trust, even if you don't do a ton with it, and knowing what your manager cares about is just going to help in so many other ways just like, "Okay. This matters to them. I'm going to make sure to do a good job there."

Fareed Mosavat (00:31:00):
Absolutely.

Lenny (00:31:01):
So that is a really cool framework.

Fareed Mosavat (00:31:02):
Not only do a good job there, but I'm going to figure out how to communicate what I'm doing to be only the parts that are important and matter to them. I'm going to know that when I hit a certain decision that needs to be made, whether I need their input or not. There are all these different pieces like understanding when to be heads-down, when to be heads-up, when to communicate, when not to, but I think understanding how all the pieces fit together, you really just try, and I always think of it as trying to build a mental model of how the company works, and what's important to it, and what's the equation, so to speak, or what are all the boxes, and then figure out like, "How is my work creating leverage in that?" I find that when you are thinking at that level, people tend to trust you.

Lenny (00:31:44):
The core of trust is people. Your manager and their leaders need to feel like you will do a good job and a bigger responsibility, and what gives them trust? Oh, they do a good job, or they're curious, and excited, and understand all these things that they need to understand. So it all makes sense, and I'm always weary of asking PMs to do more work. It's such a busy, long hours job already, and what's cool about these things you're talking about is it's not necessarily a lot more work. It's just a little bit of research and a little bit of digging and thinking.

Fareed Mosavat (00:32:12):
Yeah. I think the hard part of this is I have not figured out how to do this well in a remote environment without throwing a lot of one-on-ones on people's calendars because sometimes you figured this out just by hearing conversations, hang out at lunch, and asking questions, and those kinds of things, but it's certainly not impossible. You just have to work out a little more,

Lenny (00:32:31):
Just more Zooms.

Fareed Mosavat (00:32:32):
Yeah.

Lenny (00:32:33):
This episode is brought to you by Vanta, helping you streamline your security compliance to accelerate growth. If your business stores any data in the cloud, then you've likely been asked or you're going to be asked about your SOC 2 compliance. SOC 2 is a way to prove your company's taking proper security measures to protect customer data and builds trust with customers and partners, especially those with serious security requirements. Also, if you want to sell it to the enterprise, proving security is essential. SOC 2 can either open the door for bigger and better deals or it can put your business on hold. If you don't have a SOC 2, there's a good chance you won't even get a seat at the table, but getting a SOC 2 report can be a huge burden, especially for startups. It's time-consuming, tedious, and expensive.

Lenny (00:33:20):
Enter, Vanta. Over 3,000 fast growing companies use Vanta to automate up to 90% of the work involved with SOC 2. Vanta can get you ready for security audits in weeks instead of months, less than a third of the time that it usually takes. For a limited time, Lenny's Podcast listeners get $1,000 off Vanta. Just go to vanta.com/lenny. That's V-A-N-T-A.com/lenny to learn more and to claim your discount. Get started today.

Lenny (00:33:50):
So I know something you spend a lot of time thinking about is the transition from an ICPM to a manager, and you have this really epic post that I think you call the Product Leader Canyon that you think of this as a canyon that a lot of PMs don't cross. So I want to spend a little bit of time here. Can you maybe just talk about what this canyon is, and why it exists?

Fareed Mosavat (00:34:08):
Yeah. We talked a little bit about the first of very hard part in product management career development, which is like, "How do I land my first job?" Not a pro at that. We can talk about that more, but then this path from IC to more senior IC working on bigger problems that have more business impact, et cetera, it's a relatively straightforward path. We just talked about some of the ways that you do that. You get a deeper understanding across a wider range of business problems. You solve more unknowns versus being handed problems to solve, et cetera, and you do that by being good at your job. You do that by being good at your job basically as a solo product manager on an island.

Fareed Mosavat (00:34:48):
We talked about communication and those kinds of things, but at the end of the day, like we described, most of the work is execution. Most of the work is partnering with your engineering manager, partnering with your designer and your team to build stuff and deliver stuff. You've gotten there by being really good at that. Right? You've gotten there by getting in the weeds, getting in the details, sweating what matters, working hard at it. So someone says, "We'd love for you to lead this team." Great. It's really easy to look at that and say, "Okay. Now, instead of owning free to paid conversion, I own growth overall."

Fareed Mosavat (00:35:28):
The first thing you do is start to figure out, "What are the most interesting and valuable projects that I can work on? As an IC, I can only have one person on my team to go dive in and work on those things to make a lot of leverage." This can create a little bit of a spiral of failure because it's the hard job. The IC part of the job is really hard. So, now, I gave you more work across more things, and you're already working 56 hours a week. Now, you got to keep track of more projects across more teams and more people, and maybe you kept the two or three most critical ones to yourself.

Fareed Mosavat (00:36:04):
So that's one angle is learning about, yes, it's probably the right thing in the near term for you to focus, and work on this, and be really directive about what to do, and get in every single detail, and make sure you deliver the best product. But long run, you've taken a learning opportunity away from someone else, and you've taken the opportunity for you to be a leveraged person that is more valuable than just their time away as well. So I think that's one piece that drives a lot of failures, just this like, "Okay. Now, I have more problems to work on. I'm going to go deeper on it," and handing the people on your team the least interesting, least leveraged, least fun stuff to do, thinking that's how you get to like, "Oh, now, I get to work on the fun projects, and the interesting and high-leverage ones, and I'll leave all the other ones to other people."

Lenny (00:36:51):
I think you call this the manager death spiral. Is that the same?

Fareed Mosavat (00:36:55):
Yeah. Yeah, manager death spiral.

Lenny (00:36:56):
Yeah.

Fareed Mosavat (00:36:56):
This is not unique to product management. This happens in almost every leadership role. You're in a position. You have broader responsibility. You got there by being the best IC on the team probably, so your instincts are to, "I see a bunch of important stuff," and do management stuff too. Right?

Lenny (00:37:15):
People may be like, "Oh, shit. How do I avoid this death spiral?" Do you have any advice? Maybe you'll get there, but just how do you avoid this death spiral of keeping all the good stuff and just not scaling yourself?

Fareed Mosavat (00:37:24):
I think the first is, honestly, just you have to start trusting other people, which is not common to where you've been till today, but you have to start trusting. You have to shift from doer to editor is the way I think about it. You have to shift from, "My job is to do the work," to, "My job is to make the work better. My job is to plus the work, to review the work, to help other people solve problem." Sometimes that's by being directive. Right?

Fareed Mosavat (00:37:51):
Sometimes that's by letting them run because you're like, "Lenny, you're great. Please go solve this problem. Call me when you have a problem." If you have people that are in that upper quadrant of like they understand the problem, they have the level of experience to solve it, it's maybe not 100% important. Maybe it is. That kind of thing. Then, there's the coach in the middle, which is like, "How do I help make that work better?" They have to start figuring out like, "Where is each person on your team in their expertise, and what level of input is the highest leverage for me?"

Fareed Mosavat (00:38:24):
I actually think of it as start thinking in terms of being lazy, "What's the least amount of work I could do to make this thing as good as possible?" versus, "How do I do as much work as possible to make sure it's great?" So it's like looking in terms of ROI. The other is just hiring, bringing on great people you trust, making sure you're staffed appropriately, and there's just a second bit. I think one of the bigger mistakes that new ICs make on teams, that they still treat problems the same way they did as ICs, which normally, when you run a pod, basically, your job is, "How do I deliver the most value with the resources I have?"

Fareed Mosavat (00:38:57):
When you're a leader, it's now your job to propose, "What are the resources we need to have the most impact on this problem?" I think I personally have messed this up a bunch of times where at the end of the core, I'll be like, "Yeah, but we only had four engineers, and this is what we could do." I'm like, "That wasn't what we asked you to do. We asked you to solve this problem. So adding four more people was what you needed or you needed the marketing team to do X, Y, and Z." You need to go out and do that work now. It is not just your job to get what you can get done with the resources in front of you. It's your job to marshal resources both inside your org and across your organization. I think that's another big area that's related to the trust bit because, again, it's this habit of, "Oh, I got here by doing everything myself." You have to start realizing that your job is to convince other people to do work too.

Lenny (00:39:49):
Awesome. So, going back to the canyon. So the first piece was essentially over-focusing on just being too good at the thing you're already doing versus going broader, is that right?

Fareed Mosavat (00:39:59):
Mm-hmm. Yeah. So it's like, "Hey, how do I maximize my output? I can do this myself faster than I can explain it to someone else, so I'll just do it," and then finding that you're blocking your team because you're in the middle of every single decision, finding that you're totally overworked, and finding that people aren't learning or growing because those opportunities have been taken from them. So what do you do to break that? You have to just slowly start to give up, trust, do that. So I think that's the one bit is that death spiral of what's getting stuff done.

Lenny (00:40:31):
No, no. You can curse all you want. That's all good.

Fareed Mosavat (00:40:33):
Okay. Great. Oh, you've just... Well, be careful with "all you want."

Lenny (00:40:36):
Nobody has cursed yet on this podcast, and it's all allowed.

Fareed Mosavat (00:40:40):
Okay.

Lenny (00:40:41):
It's the internet. I don't know.

Fareed Mosavat (00:40:41):
We'll solve that.

Lenny (00:40:42):
Okay.

Fareed Mosavat (00:40:43):
Don't worry. I think the other is what I call the four types of product work, and I think this is not always right at the manager stage. But for every great product leader, you go from being an expert in some type of product work, and I'll describe what those are, to now owning a portfolio of work across a bunch of different dimensions. So the way I think about product work, and Casey Winters and I worked on this framework together, a lot of it comes from him. So I don't want to oversay it, but it's all part of our product strategy program at Reforge is first, feature work, adding new features, product experiences, et cetera into a product in order to drive engagement with your existing customer base and solve a wider range of problems.

Fareed Mosavat (00:41:24):
The second is growth work. "How do I help my customers or a broader range of customers connect with the experiences we already have, and drive acceleration and either top-line growth, or modernization, or whatever the most important metrics are. I think you've had many guests on to talk about growth type work. The third is related to growth, but I think is slightly different, which is what we call product market fit expansion. So it's not exactly feature work, which is like, "Hey, now that I use your product more, I have this thing I need in order to keep using it because I'm a power seller," those kinds of things. But instead, we want to attract a whole new sub-segments of markets to the product by adding something.

Fareed Mosavat (00:42:05):
There are two forms of product market fit expansion. There's either taking the same product and finding a new audience. Things like internationalization or vertical like, "I'm going to sell the same product to a different vertical because we're a verticalized product." The other is selling a different product to the same audience. This is what bundling strategies basically look like. Right? So adding new marketing tools to a marketing suite, et cetera that attract a different kind of customer and that either drive upsell or drive new audiences to come to that.

Fareed Mosavat (00:42:34):
So that's the third kind of product work, and then there's the fourth that is always forgotten by a lot of PMs which is scaling work. So what is the stuff we're doing that is because we are growing, there's new product work we need to do? Most people think of this as technical scaling, but I actually put things like trust, and safety, and other kinds of what we call user scaling problems in this as well. There are a lot of problems that come up at Airbnb just because instead of having 10 hosts, you have 10,000 hosts. Right? There are a lot of problems at Twitter and Facebook that are well puzzle-sized that are a result of their scale, and I think that's a chunk of work that I put in the same category as technical scaling, which is like, "How do we make sure the product continues to work for the people who are using it?"

Fareed Mosavat (00:43:15):
So the challenge of the four kinds of product work. "Okay. Great. We have a framework. How is that useful, Fareed?" It's not that useful. It is to know what kind you're doing, but I think as you go up the stack of product leadership, you are going from being probably an expert in one of these, so for me, growth, to needing to think about all these other ones, and you've probably never done them before. Right? Maybe you've done two, but how do you lead across a bunch of different things, and how do you make sure not to be over-focused on the one that you care the most about?

Fareed Mosavat (00:43:46):
We've all seen this. Right? It's like growth leader takes over, and everything is a growth problem. Everything is an experiment. Everything should be measured. That's not necessarily true for some of these other kinds of work, and so how do you start to lead, and grow, and build a portfolio across those? I think that's where some of the stuff we talked about before, deep curiosity, looking across, asking a lot of questions, getting to a foundational understanding of what's important there, et cetera is really important.

Lenny (00:44:14):
Got it. So part of this is learning new types of product work. So we're talking about trying to move from IC to manager and the things that get in the way, and so is the advice there just start to learn and understand... Maybe, say, you're doing feature work. You're just building a dashboard for your users. Is your advice there like start thinking about how growth works and understand the growth strategy of the company so that people give you this opportunity of, "Okay. Let's put Fareed on maybe a couple other things here because he already understands a little bit more about growth?"

Fareed Mosavat (00:44:45):
Yeah. I think there's a framework thing, and then there's like, "What practical advice?" So from a framework perspective, I think it's important to ask the question, "For each of the things that I am responsible for, what category does this fall into? What's important about it? What are the right ways to think about building that, given that it is different than what I've built before?" So, some of this, you can do within an org. If you're working on core product stuff, you probably have an adoption problem on one of your products, and there's growth work associated with driving usage of that thing.

Fareed Mosavat (00:45:18):
So I think there's a piece at which even within a certain sub-segment that this can be valuable. You could be working on enterprise, which looks a lot like a lot of scaling work, right, and a lot of feature work, "Get me the right administrative dashboards and these kinds of things," but also, maybe you have a problem that's a growth problem. "How do I drive adoption? How do I actually drive usage? How do I make sure that our new enterprise customers are activated and retained?"

Fareed Mosavat (00:45:43):
So I think at scale, any product leadership work has some pieces of these different kinds, and I think building a mental model for, "What are the other things we need to do? What's the right portfolio allocation across these different types of product work, and do I have enough of a baseline understanding of the different ways to evaluate and think about those and what the goals are in order to drive leadership across work I might not be able to do myself very well?" I am not a good technical PM despite having an engineering background. It's been too long, but I hope that I can lead technical scaling, technical debt restructure on my team or at least understand whether it's important to do or not.

Lenny (00:46:20):
So if you think about this concept of getting through this canyon broadly, it boils down to more scope. Maybe that's the way to think about it. It's like more scope of product work that you work on, being better at different types of work, scaling yourself so that other people can do work on your behalf or within your umbrella, and the point you made about not being satisfied with the resources you have and in helping people understand, "Here's what we could do if we had this many resources," and making the case for that feels like that's the overview. Is that how you think about it?

Fareed Mosavat (00:46:49):
Yeah. I think that's exactly right, and the last one is really important because now, you have moved to owning the impact. As a leader, you now own the business outcome, the impact, the delivery, not some sub-problem or known answer. You have to define the solutions. You have to talk about how many people you need to do them, and you need to figure out what do you need from the rest of the organization to do that. So, yeah. I think those are the three big buckets of things that I see trip people up.

Lenny (00:47:14):
Awesome, and just add plus one to that last point. Just like a lot of PMs end up being victims of the resources they get and like, "Oh, how could I have possibly had this impact with the resources you gave me?" versus, "How do I avoid that and empower myself to help people understand, 'Here's what I need to do this thing that you want me to do. If you think this is important, here's what we need,' and put it on other people's plate?" It doesn't mean you'll get it, but it's important to put that up front.

Fareed Mosavat (00:47:38):
Yeah, and that goes from a "would be nice" and makes you a better... more junior or even senior PM makes you a more effective one. It's extra credit. At the leadership level, it's baseline. The baseline is, "Okay. I believe this is the outcome we need to get to by this time, and this is what it's going to take. Here are the trade-offs. Here's what I need. Here's what I can get you if I can't do that." The reason I drum this one home is I feel like this is the mistake I have made now multiple times in my career, and I can't... At this point, I'm embarrassed to have seen it happen over and over again because you just get caught up in like, "Okay. Here's the team I have. I've got to build a roadmap. I've got to make sure everybody's got work to do," and you say focused on feeding that beast, and you forget to ask, "Is this even the right group to solve this?" Maybe you need a smaller team even, maybe you need a bigger team, or maybe you need different people. I think often, you find yourself victim of the circumstances instead of owning the situation.

Lenny (00:48:39):
I love that. When did you realize this was something you should be doing?

Fareed Mosavat (00:48:42):
I've learned different versions of this lesson now multiple times. I learned it at Instacart. I had a very small team, and we've got a lot done. But honestly, I think I failed to make the case that we should grow it faster and only... It was only when someone was like, "We should add more people." I was like, "Great. Yeah. Let's do that." I don't think I was hurt by that, but I think it was a, "Oh, you have permission. You should have asked," kind of thing. I think at Slack, the lesson I learned was about cross-functional. I think we did a good job of making the case for why we needed new teams or add more things to drive more impact, but I still took a very product approach to solving activation and monetization expansion type problems.

Fareed Mosavat (00:49:25):
What I think is I look at what could have moved the needle more and what it could have made me a more successful leader at that company. It would've been partnering more closely with marketing, for instance, to figure out how we could be working on things together, helping drive their roadmap, and vice versa. Same with sales. Same with the data org. Same with finance. Those kinds of things where I don't think I was driving enough of the high-level outcome I owned, which is driving growth in the self-service business across the other parts of the company that needed to do that. I was a product leader, so I did product work, and I... Lesson learned.

Lenny (00:50:05):
Yeah. Thanks for sharing that. So we've been talking a lot about the regular path, and getting better and accelerating your path as a product leader, and staying on this track. There's also this alternative track that I know you're passionate about, and Reforge just become a beacon, it feels like, of folks that are moving away from working at one company to working at many companies and scaling their impact. I'm curious to hear your thoughts on what you've seen there. There's this large trend of just senior people becoming advisors, writing things, newsletters, for example. I'm curious what you think is happening there and how you think about that.

Fareed Mosavat (00:50:41):
It's interesting. The whys are hard to pin down, but it's definitely happening. I think some of it is maybe COVID-induced, some of it is remote work driving these trends, and some of it is just like there are a lot more leaders who are a lot more in demand. So, just to recap, a trend that I think we are seeing and that has been really interesting is a trend of senior leaders, people with meaningful operating experience, first, diversifying their impact maybe while they're still at a full-time role. Someone like yourself, Lenny, maybe was full-time at Airbnb or a similar company and said, "Hey, I'd like to do some advising, some angel investing, some speaking. Maybe I'll start writing a newsletter on the side," and then moving to this new category that I don't feel like really existed. Maybe it did in certain pockets of executive leadership around tech and startups, but really seeing it in product management of a shift towards, "The best use of my time and my career is to work across a portfolio of problems that a variety of different companies."

Fareed Mosavat (00:51:47):
So we are seeing a larger percentage of our executive network. It's still small, but working on things like newsletters, podcasts, those and the like at the edge of the content creator side, but also, full-time advisors, fractional heads of growth, fractional heads of product one day a week, et cetera. Long-term advisory relationships, running workshops. These kinds of things that are more like a la carte. I think they love it because of the flexibility that it creates for them. They love it because of the high upside and non-linearity of possibility of results now instead of having equity in one company for four years of 100% of my time. It's a portfolio approach to not just the time and energy, but also the upside and opportunities that are there as well as the fact that they're just so in demand.

Fareed Mosavat (00:52:41):
For senior leaders who have been in meaningful seats at well-known companies, you're getting hit up by recruiters all day long, and the decision, "What do I want to spend the next four or five, six years of my life on if it's just one thing?" is a very difficult one. So what we're finding is people seeing, "Hey, you don't need me full-time. What you need is me here a day a week to help your up and coming leaders be awesome." We're just seeing more and more of that in the industry, and it's been a really interesting trend to observe. Of our executives and residents, I would say most now are exploring this kind of advisory, fractional, or otherwise portfolio-based approach to their futures. Whereas most of them came from full-time roles beforehand.

Lenny (00:53:24):
Yeah. A program at Reforge is designed for that. The idea there is, "You don't know what you're going to do next? Come teach a class at Reforge to help some folks out, and then use that as the time to explore what you're going to do next." Right?

Fareed Mosavat (00:53:35):
Yeah. Yeah, it is, and the hypothesis... I was one of the first EIR, so I started as an EIR at the company, and then ended up joining full-time as an executive. The hypothesis was, "Hey, let's give people six months to a year so that they don't just hop from one really high-stress, really difficult job into the next one. We also want great operators teaching and meeting our programs. How do we build a win-win situation?" So what we did was we created the Executive in Residence program as a way to help top operators have a transition point, but I think the hypothesis was that most of them would take on the next VP product role, or CPO role, or CMO type role, and what we're finding is that more and more of them are using that space and time.

Fareed Mosavat (00:54:17):
They are building up their understanding of where they're experts and what their real TEDx value is, and then finding ways to do that across a variety of different companies and organizations versus just the single one, one, because they want to try before they buy, so to speak, in terms of of like even if you do end up somewhere full-time, it's nice to be able to really work with them and get to know them because at the executive level in particular, it's a really high level of commitment, and you have a lot of opportunities, so you want to be really careful about it. But also, two, because it may not be the best use of your energy. When you have a lot of frameworks and you have a lot of broad understanding, you have a lot of examples, your value to the ecosystem is often by helping lots of companies be successful, not just one. I suspect that's how you feel about what you're doing as well.

Lenny (00:55:07):
Yeah. When I started down this path of experimenting with a newsletter back in the day, I called it Project Avoid Getting a Real Job, and what I was trying to do is figure out, "Can I make a living doing this thing even though I don't know if there's any way to make money writing a thing?" My wife is always like, "There's no money in writing. What are you doing? I thought you wanted to start a company, that you wanted to do some advising."

Fareed Mosavat (00:55:28):
Yeah. Well, let me talk about why I think the generalization there's no money in writing is true, but I think it's true because it's... In general, maybe not, but what's happening, I think, is people are figuring out, "What is my specific knowledge," just to tie the knots back to the thing we started at the beginning, "that because I've taken so many reps at this is actually not easily replaceable in a focused area?" So modernization or building zero-to-one paid channels as a marketer, or whatever it is. Just narrow enough that I know I'm one of the five best in the world at or I can make the case that I'm one of the five best in the world at it. You as a company probably can't hire that person because you're too early, don't have enough money, don't have enough clout, et cetera, and that I have generalized enough in my mind that I can actually be really effective in a small amount of time.

Fareed Mosavat (00:56:25):
So what works for you, I don't know a lot about the mechanics of your newsletter, but it's not just writing. You're writing about a very specific set of topics that you have unique experience in that has harnessed a very focused community, and I think we're seeing this across a bunch of different things that there's a lot of sub-expertise. No one can be an expert at company. Some people claim to be, but when you get down to it, I feel like an expert on bottoms-up SaaS activation strategy is like, "I can speak pretty confidently about that. Somebody has a problem in that space, I can usually at an hour accelerate their learning pretty dramatically." I think as we're finding what these things are and people are getting smarter about what they're looking for, I think it opened up this space where you can be the best in the world at a relatively narrow topic and make a real meaningful living out of it.

Lenny (00:57:19):
There's two thoughts I want to go into here, and then I think we should probably wrap up, but one is I do worry there's like... everyone that gets to a certain point, it just exits the career track, and who's left to build things? I worry that just everyone is trying to become an influencer/creator person. So what I wanted to chat about briefly is just downsides of this path in life.

Fareed Mosavat (00:57:41):
Sure.

Lenny (00:57:41):
The other pieces is for folks listening that want to pursue this direction, what could they do to set themselves up? So the first piece is just like, what are the downsides? I'll share a few already. So in this life that I lead now, I get no health insurance benefits. I get no time off. I get no 401(k) matching. None of that. I have to basically pay an absurd amount of money for health insurance and find ways to take time off, invent PTO policies for myself, and all these sorts of things. I've gotten used to it, but it is weird. My wife is also an independent self-employed person, so we both don't have... If we have a child, we have no mat leave, pat leave. We just have to figure that out. I don't know how I would do that. So that comes to mind for me. What else have you seen as the downside of this path?

Fareed Mosavat (00:58:25):
Yeah, the second is it's unclear what the longevity is. How far can you be removed from your full-time experience and still be valuable? This is why I actually think this is a better path than what used to happen, which is all the great operators turned into VCs, venture capitalists. Right? In there, you're pretty disconnected from the ops. I think this advisory type path, I'll leave the creator piece alone because I'm not as familiar with it. But in the advisor path, you are still maybe spending a day a week with these companies. You are still doing. You are helping grow the next generation. I don't like to say generation, but next crop of up and coming leaders. So the question mark for me is longevity. Is it possible to build more and more amazing companies if more and more amazing operators are leaving the full-time workforce?

Fareed Mosavat (00:59:20):
I don't know, but I hope that it's better than what it's been because actually, they're building and doing, et cetera. So I think that's the other question mark and downside, and I think we think about this as part of our ecosystem. I think as long as people are doing, and generalizing, and executing, as I talked about it at the beginning, I think they can still be valuable in a meaningful way and maybe provide access to that kind of knowledge for a broader range of companies. The other is just like if everybody does it, then maybe it's not so unique anymore. So I think there's a question there as well.

Lenny (00:59:55):
The other piece is like you're constantly having to do sales and BD as an advisor like, "Who's the next company?" You're always wondering if there will be more, if they stopped. It's a real part of it.

Fareed Mosavat (01:00:03):
That's why it has not been attractive to me personally, I will say. I like being focused on a singular problem for some amount of time. I do a lot of portfolio-type stuff outside. I advise casually. I do some coaching. Not coaching exactly, but mentorship for a couple of different up and coming product leaders. I do some angel investing, those kinds of things. I like to see what's happening around me, but I do like having an anchor. That's like my main thing, and I don't like selling. It turns out I don't, and so you have to like that, I think, to do some of this stuff. But I think there are things our platform at Reforge will be able to do for these kinds of offers. There's a long period of time to make that easier and easier. No promises, but stay tuned.

Lenny (01:00:46):
Okay, okay. So then, going back maybe as a final question. For folks that are just like, "That sounds great. Maybe in the future, I want to become a full-time advisor, EIR person, writer person," what advice do you have for folks to set their career up for a place where they can get to a place where they can become full-time advisors, let's say?

Fareed Mosavat (01:01:04):
This is this generalized step I talked about in the learn loop. It becomes even more important if what you want to do is not just do your current job well, but be able to communicate why that expertise is valuable to other people, other companies across a wide range of things. So I would say choose your opportunities carefully to be building the right balance of depth and breadth across different things. You need to connect dots, so you do need different data points from different types of product work and different types of organizations because you don't want to be so narrow that only DDC eCommerce company that sell once-a-year purchases or whatever is the only thing you can work on. That's just an example. I could have come up with a bunch of others.

Fareed Mosavat (01:01:51):
You need to have some breadth, right, but it's like same problem, different industry. It's one way to think about depth that's focused. Different problem, same industry is another way to think about it, but you have to come up with a unique intersection that is clearly you are in the top tier of the people who know how to do that. That's a little bit nuanced. There's an art to it I think in some respects, but I think that's an important piece of the puzzle.

Fareed Mosavat (01:02:14):
Second, work at great places. I think this is good advice for almost all product managers in particular, but really, anybody working in tech, for better or for worse, where you worked matters to people for two reasons. One, it's easier to do great work at a place that is fundamentally working. When the tide is rising, there are tons of opportunities to make meaningful, deep, awesome impact. The second is what you talked about. You're going to be in the sales business eventually, and it's a lot easier to sell experience at places people have heard of than places nobody has heard of. Unfortunately, that's I think a big piece of this puzzle as well. I don't have to spend a lot of time talking about what Slack is. You probably don't have to spend a lot of time talking about what Airbnb is. I think that helps, and it is a meaningful piece of the puzzle.

Lenny (01:03:04):
Absolutely. Fareed, I feel like anybody that listen to this episode is going to be a better product manager. I'm very confident of that, and I'm really appreciative.

Fareed Mosavat (01:03:13):
I hope so.

Lenny (01:03:14):
I'm sure of it. So, just to close, where can folks find you online if they want to reach out, learn more, and how can listeners be useful to you?

Fareed Mosavat (01:03:21):
You can find me on Twitter almost most days, F-A-R-3-3-D. That's been my handle since I was a young man.

Lenny (01:03:29):
So complicated.

Fareed Mosavat (01:03:30):
So check me out there. It's just threes instead at Es, right? That's probably my social network of choice and best place to communicate or hear what I'm thinking about or what I'm doing. Obviously, I do a ton of work at Reforge. On our events, I toast a bunch of different things, do a lot of stuff. If you're interested in these kinds of topics, please, I don't want to make this a sales pitch, but we have a lot of programs that are dedicated to deep dives into the problems that we've talked about here. I'm dedicating this next chapter of my career to helping a wider range of product leaders be great at their jobs, and that's what we do for a living. I hope that we can help folks there.

Fareed Mosavat (01:04:06):
As to what people can help me with, I don't know. I'm always looking for people working on interesting stuff or with interesting, unique problems. If you're a founder working on something interesting and you're looking for an advisor, practical advisor, not for me, but we have a wide range of network experts that I'd be happy to connect folks with. If you're a product manager on a team that's looking to figure out how to break through on certain problems, reach out. Maybe we can help with Reforge or maybe I can help individually.

Lenny (01:04:35):
Thanks for being here, Fareed.

Fareed Mosavat (01:04:36):
Yeah. Cheers. Thanks for having me, Lenny. I think what you're doing is wonderful and making a big difference for PMs everywhere, so thank you.

Lenny (01:04:44):
Same. Thanks, man.

Fareed Mosavat (01:04:45):
Cheers.

Lenny (01:04:47):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## The Godmother of AI on jobs, robots & why world models are next | Dr. Fei-Fei Li
**Guest:** Fei Fei  
**Published:** 2025-11-16  
**YouTube:** https://www.youtube.com/watch?v=Ctjiatnd6Xk  
**Tags:** experimentation, hiring, culture, vision, mission, competition, market, persona, design, ui  

# The Godmother of AI on jobs, robots & why world models are next | Dr. Fei-Fei Li

## Transcript

Lenny Rachitsky (00:00:00):
A lot of people call you the godmother of AI. The work you did actually was the spark that brought us out of AI winter.

Dr. Fei Fei Li (00:00:07):
In the middle of 2015, middle of 2016, some tech companies avoid using the word AI because they were not sure if AI was a dirty word. 2017-ish was the beginning of companies calling themselves AI companies.

Lenny Rachitsky (00:00:22):
There's this line, I think, this was when you were presenting to Congress. There's nothing artificial about AI. It's inspired by people. It's created by people, and most importantly, it impacts people.

Dr. Fei Fei Li (00:00:30):
It's not like I think AI will have no impact on jobs or people. In fact, I believe that whatever AI does, currently or in the future, is up to us. It's up to the people. I do believe technology is a net positive for humanity, but I think every technology is a double-edged sword. If we're not doing the right thing as a society, as individuals, we can screw this up as well.

Lenny Rachitsky (00:00:56):
You had this breakthrough insight of just, okay, we can train machines to think like humans, but it's just missing the data that humans have to learn as a child.

Dr. Fei Fei Li (00:01:03):
I chose to look at artificial intelligence through the lens of visual intelligence because humans are deeply visual animals. We need to train machines with as much information as possible on images of objects, but objects are very, very difficult to learn. A single object can have infinite possibilities that is shown on an image. In order to train computers with tens and thousands of object concepts, you really need to show it millions of examples.

Lenny Rachitsky (00:01:36):
Today, my guest is Dr. Fei-Fei Li, who's known as the godmother of AI. Fei-Fei has been responsible for and at the center of many of the biggest breakthroughs that sparked the AI revolution that we're currently living through. She spearheaded the creation of ImageNet, which was basically her realizing that AI needed a ton of clean-labeled data to get smarter, and that data set became the breakthrough that led to the current approach to building and scaling AI models. She was chief AI scientist at Google Cloud, which is where some of the biggest early technology breakthroughs emerged from. She was director at SAIL, Stanford's Artificial Intelligence Lab, where many of the biggest AI minds came out of. She's also co-creator of Stanford's Human-Centered AI Institute, which is playing a vital role in a direction that AI is taking. She's also been on the board of Twitter. She was named one of Time's 100 Most Influential People in AI. She's also United Nations advisory board. I could go on.

(00:02:29):
In our conversation, Fei-Fei shares a brief history of how we got to today in the world of AI, including this mind-blowing reminder that 9 to 10 years ago, calling yourself an AI company was basically a death knell for your brand because no one believed that AI was actually going to work. Today, it's completely different. Every company is an AI company. We also chat about her take on how she sees AI impacting humanity in the future, how far current technologies will take us, why she's so passionate about building a world model and what exactly world models are, and most exciting of all, the launch of the world's first large world model, Marble, which just came out as this podcast comes out. Anyone can go play with this at marble.worldlabs.ai. It's insane. Definitely check it out. Fei-Fei is incredible and way too under the radar for the impact that she's had on the world, so I am really excited to have her on and to spread her wisdom with more people.

(00:03:22):
A huge thank you to Ben Horowitz and Condoleezza Rice for suggesting topics for this conversation. If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. With that, I bring you Dr. Fei-Fei Li after a short word from our sponsors.

(00:03:37):
This episode is brought to you by Figma, makers of Figma Make. When I was a PM at Airbnb, I still remember when Figma came out and how much it improved how we operated as a team. Suddenly, I can involve my whole team in the design process, give feedback on design concepts really quickly and it just made the whole product development process so much more fun. But Figma never felt like it was for me. It was great for giving feedback and designs, but as a builder, I wanted to make stuff. That's why Figma built Figma Make. With just a few prompts, you can make any idea or design into a fully functional prototype or app that anyone can iterate on and validate with customers.

(00:04:15):
Figma Make is a different kind of vibe coding tool. Because it's all in Figma, you can use your team's existing design building blocks, making it easy to create outputs that look good and feel real and are connected to how your team builds. Stop spending so much time telling people about your product vision and instead show it to them. Make code-back prototypes and apps fast with Figma Make. Check it out at figma.com/lenny.

(00:04:40):
Did you know that I have a whole team that helps me with my podcast and with my newsletter? I want everyone on that team to be super happy and thrive in the roles. Justworks knows that your employees are more than just your employees; they're your people. My team is spread out across Colorado, Australia, Nepal, West Africa, and San Francisco. My life would be so incredibly complicated to hire people internationally, to pay people on time and in their local currencies, and to answer their HR questions 24/7. But with Justworks, it's super easy. Whether you're setting up your own automated payroll, offering premium benefits, or hiring internationally, Justworks offer simple software and 24/7 human support from small business experts for you and your people. They do your human resources right so that you can do right by your people. Justworks, for your people.

(00:05:31):
Fei-Fei, thank you so much for being here and welcome to the podcast.

Dr. Fei Fei Li (00:05:34):
I'm excited to be here, Lenny.

Lenny Rachitsky (00:05:36):
I'm even more excited to have you here. It is such a treat to get to chat with you. There's so much that I want to talk about. You've been at the center of this AI explosion that we're seeing right now for so long. We're going to talk about a bunch of the history that I think a lot of people don't even know about how this whole thing started, but let me first read a quote from Wired about you just so people get a sense, and in the intro I'll share all of the other epic things you've done. But I think this is a good way to just set context. "Fei-Fei is one of a tiny group of scientists, a group perhaps small enough to fit around a kitchen table, who are responsible for AI's recent remarkable advances."

(00:06:10):
A lot of people call you the godmother of AI, and unlike a lot of AI leaders, you're an AI optimist. You don't think AI is going to replace us. You don't think it's going to take all our jobs. You don't think it's going to kill us. So I thought it'd be fun to start there, just what's your perspective on how AI is going to impact humanity over time?

Dr. Fei Fei Li (00:06:30):
Yeah, okay, so Lenny, let me be very clear. I'm not a utopian, so it's not like I think AI will have no impact on jobs or people. In fact, I'm a humanist. I believe that whatever AI does, currently or in the future, is up to us. It's up to the people. So I do believe technology is a net positive for humanity. If you look at the long course of civilization, I think we are, and fundamentally, we're an innovative species that we... If you look at from written record thousands of years ago to now, humans just kept innovating ourselves and innovating our tools, and with that, we make lives better, we make work better, we build civilization, and I do believe AI is part of that. So that's where the optimism comes from. But I think every technology is a double-edged sword, and if we're not doing the right thing as a species, as a society, as communities, as individuals, we can screw this up as well.

Lenny Rachitsky (00:07:47):
There's this line, I think, this was when you were presenting to Congress, "There's nothing artificial about AI. It's inspired by people. It's created by people, and most importantly, it impacts people." I don't have a question there, but what a great line.

Dr. Fei Fei Li (00:07:59):
Yeah, I feel pretty deeply. I started working AI two and a half decades ago, and I've been having students for the past two decades and almost every student who graduates, I remind them when they graduate from my lab that your field is called artificial intelligence, but there's nothing artificial about it.

Lenny Rachitsky (00:08:23):
Coming back to the point you just made about how it's kind of up to us about where this all goes, what is it you think we need to get right? How do we set things on a path? I know this is a very difficult question to answer, but just what's your advice? What do you think we should be keeping in mind?

Dr. Fei Fei Li (00:08:36):
Yeah, how many hours do we have?

Lenny Rachitsky (00:08:39):
How do we align AI? There we go. Let's solve it.

Dr. Fei Fei Li (00:08:41):
So I think people should be responsible individuals no matter what we do. This is what we teach our children, and this is what we need to do as grownups as well. No matter which part of the AI development or AI deployment or AI application you are participating in, and most likely many of us, especially as technologists, we're in multiple points. We should act like responsible individuals and care about this. Actually, care a lot about this. I think everybody today should care about AI because it is going to impact your individual life. It is going to impact your community, it's going to impact the society and the future generation. And caring about it as a responsible person is the first, but also the most important step.

Lenny Rachitsky (00:09:37):
Okay, so let me actually take a step back and kind of go to the beginning of AI. Most people started hearing and caring about AI, as what it's called today, just like, I don't know, a few years ago when ChatGPT came out. Maybe it was like three years ago.

Dr. Fei Fei Li (00:09:51):
Three years ago, almost one more month, three years ago.

Lenny Rachitsky (00:09:55):
Wow, okay. And that was ChatGPT coming out. Is that the milestone you have in mind?

Dr. Fei Fei Li (00:09:56):
Yes.

Lenny Rachitsky (00:09:57):
Okay, cool. That's exactly how I saw it. But very few people know there was a long, long history of people working on, it was called machine learning back then and there's other terms, and now it's just everything's AI and there was kind of a long period of just a lot of people working on it. And then there's this what people refer to as the AI winter where people just gave up almost, most people did, and just, okay, this idea isn't going anywhere. And then the work you did actually was essentially the spark that brought us out of AI winter and is directly responsible for the world where now of just AI is all we talk about. As you just said, it's going to impact everything we do. So I thought it'd be really interesting to hear from you just the brief history of what the world was like before ImageNet and just the work you did to create ImageNet, why that was so important, and then just what happened after.

Dr. Fei Fei Li (00:10:44):
It is, for me, hard to keep in mind that AI is so new for everybody when I lived my entire professional life in AI. There's a part of me that is just, it's so satisfying to see a personal curiosity that I started barely out of teenagehood and now has become a transformative force of our civilization. It generally is a civilizational level technology. So that journey is about 30 years or 20 something, 20 plus years, and it's just very satisfying. So where did it all start? Well, I'm not even the first generation AI researcher. The first generation really date back to the '50s and '60s, and Alan Turing was ahead of his time in the '40s by asking, daring humanity with the question, "Is there thinking machines?" And of course he has a specific way of testing this concept of thinking machine, which is a conversational chatbot, which to his standard we now have a thinking machine.

(00:12:02):
But that was just a more anecdotal inspiration. The field really began in the '50s when computer scientists came together and look at how we can use computer programs and algorithms to build these programs that can do things that have been only capable by human cognition. And that was the beginning. And the founding fathers the Dartmouth workshop in the 1956, we have Professor John McCarthy who later came to Stanford who coined the term artificial intelligence. And between the '50s, '60s, '70s, and '80s, it was the early days of AI exploration and we had logic systems, we had expert systems, we also had early exploration of neural network. And then it came to around the late '80s, the '90s, and the very beginning of the 21st century. That stretch about 20 years is actually the beginning of machine learning, is the marriage between computer programming and statistical learning.

(00:13:23):
And that marriage brought a very, very critical concept into AI, which is that purely rule-based program is not going to account for the vast amount of cognitive capabilities that we imagine computers can do. So we have to use machines to learn the patterns. Once the machines can learn the patterns, it has a hope to do more things. For example, if you give it three cats, the hope is not just for the machines to recognize these three cats. The hope is the machines can recognize the fourth cat, the fifth cat, the sixth cat, and all the other cats. And that's a learning ability that is fundamental to humans and remaining animals. And we, as a field, realized, "We need machine learning." So that was up till the beginning of the 21st century. I entered the field of AI literally in the year of 2000. That's when my PhD began at Caltech.

(00:14:33):
And so I was one of the first generation machine learning researchers and we were already studying this concept of machine learning, especially neural network. I remember that was one of my first courses at Caltech is called neural network, but it was very painful. It was still smack in the middle of the so-called AI winter, meaning the public didn't look at this too much. There wasn't that much funding, but there was also a lot of ideas flowing around. And I think two things happened to myself that brought my own career so close to the birth of modern AI is that I chose to look at artificial intelligence through the lens of visual intelligence because humans are deeply visual animals. We can talk a little more later, but so much of our intelligence is built upon visual, perceptual, spatial understanding, not just language per se. I think they're complementary.

(00:15:37):
So I choose to look at visual intelligence and my PhD and my early professor years, my students and I are very committed to a north star problem, which is solving the problem of object recognition because it's a building block for the perceptual world, right? We go around the world interpreting reasoning and interacting with it more or less at the object level. We don't interact with the world at the molecular level. We don't interact with the world as... We sometimes do, but we rarely, for example, if you want to lift a teapot, you don't say, "Okay, the teapot is made of a hundred pieces of porcelain and let me work on this a hundred pieces." You look at this as one object and interact with it. So object is really important. So I was among the first researchers to identify this as a north star problem, but I think what happened is that as a student of AI and a researcher of AI, I was working on all kinds of mathematical models including neural network, including Bayesian network, including many, many models.

(00:16:53):
And there was one singular pain point is that these models don't have data to be trained on. And as a field, we were so focusing on these models, but it dawned on me that human learning as well as evolution is actually a big data learning process. Humans learn with so much experience constantly. In the evolution, if you look at time, animals evolve with just experiencing the world. So I think my students and I conjectured that a very critically-overlooked ingredient of bringing AI to life is big data. And then we began this ImageNet project in 2006, 2007. We were very ambitious. We want to get the entire internet's image data on objects. Now granted internet was a lot smaller than today, so I felt like that ambition was at least not too crazy. Now, it's totally delusional to think a couple of graduate student and a professor can do this.

(00:18:05):
And that's what we did. We curated very carefully, 15 million images on the internet, created a taxonomy of 22,000 concepts, borrowing other researchers' work like linguists work on WordNet, and it's a particular way of dictionarying words. And we combine that into ImageNet and we open-sourced that to the research community. We held an annual ImageNet challenge to encourage everybody to participate in this. We continue to do our own research, but 2012 was the moment that many people think was the beginning of the deep learning or birth of modern AI because a group of Toronto researchers led by Professor Geoff Hinton, participated in ImageNet Challenge, used ImageNet big data and two GPUs from NVIDIA and created successfully the first neural network algorithm that can...

(00:19:12):
It didn't totally solve, but made a huge progress towards solving the problem of object recognition. And that combination of the trio technology, big data, neural network, and GPU was kind of the golden recipe for modern AI. And then fast-forward, the public moment of AI, which is the ChatGPT moment, if you look at the ingredients of what brought ChatGPT to the world technically still use these three ingredients. Now, it's internet-scale data mostly texts is a much more complex neural network architecture than 2012, but it's still neural network and a lot more GPUs, but it's still GPUs. So these three ingredients are still at the core of modern AI.

Lenny Rachitsky (00:20:16):
Incredible. I have never heard that full story before. I love that it was two GPUs was the first. I love that. And now it's, I don't know, hundreds of thousands, right, that are orders of magnitude more powerful.

Dr. Fei Fei Li (00:20:30):
Yep.

Lenny Rachitsky (00:20:31):
And those two GPUs where they just bought, they were like gaming GPUs, they just went to the-

Dr. Fei Fei Li (00:20:34):
Yes.

Lenny Rachitsky (00:20:35):
... GameStar that people use for playing games. As you said, this continues to be in a large way, the way models get smarter. Some of the fastest growing companies in the world right now, I've had them all mostly on the podcast, Mercor and Surge and Scale. They continue to do this for labs, just give them more and more label data of the things they're most excited and interested in.

Dr. Fei Fei Li (00:20:53):
Yeah, I remember Alex Wang from Scale very early days. I probably still has his emails when he was starting Scale. He was very kind. He keeps sending me emails about how image that inspired Scale. I was very pleased to see that.

Lenny Rachitsky (00:21:08):
One of my other favorite takeaways from what you just shared is just such an example of high agency and just doing things that's kind of a meme on Twitter. Just you can just do things. You're just like, okay, this is probably necessary to move AI. And it's called machine learning back then, right? Was that the term most people used?

Dr. Fei Fei Li (00:21:25):
I think it was interchangeably. It's true. I do remember the companies, the tech companies, I am not going to name names, but I was in a conversation in one of the early days, I think is in the middle of 2015, middle of 2016, some tech companies avoid using the word AI because they were not sure if AI was a dirty word. And I remember I was actually encouraging everybody to use the word AI because to me that is one of the most audacious question humanity has ever asked in our quest for science and technology, and I feel very proud of this term. But yes, at the beginning some people were not sure.

Lenny Rachitsky (00:22:12):
What year was that roughly when AI was a dirty word?

Dr. Fei Fei Li (00:22:14):
2016, I think because that was-

Lenny Rachitsky (00:22:15):
2016, less than 10 years ago.

Dr. Fei Fei Li (00:22:18):
That was the changing. Some people start calling it AI, but I think if you look at the Silicon Valley tech companies, if you trace their marketing term, I think 2017-ish was the beginning of companies calling themselves AI companies.

Lenny Rachitsky (00:22:40):
That's incredible. Just how the world has changed.

Dr. Fei Fei Li (00:22:43):
Yes.

Lenny Rachitsky (00:22:43):
Now, you can't not call yourself an AI company.

Dr. Fei Fei Li (00:22:46):
I know.

Lenny Rachitsky (00:22:46):
Just nine-ish years later.

Dr. Fei Fei Li (00:22:48):
Yeah.

Lenny Rachitsky (00:22:49):
Oh, man. Okay. Is there anything else around the history, that early history that you think people don't know that you think is important before we chat about where you think things are going and the work that you're doing?

Dr. Fei Fei Li (00:23:01):
I think as all histories, I'm keenly aware that I am recognized for being part of the history, but there are so many heroes and so many researchers. We're talking about generations of researchers. In my own world, there are so many people who have inspired me, which I talked about in my book, but I do feel our culture, especially Silicon Valley, tends to assign achievements to a single person. While I think it has value, but it's just to be remembered. AI is a field of, at this point, 70 years old and we have gone through many generations. Nobody, no one could have gotten here by themselves.

Lenny Rachitsky (00:23:54):
Okay, so let me ask you this question. It feels like we're always on this precipice of AGI, this kind of vague term people throw around, AGI is coming, it's going to take over everything. What's your take on how far you think we might be from AGI? Do you think we're going to get there on the current trajectory we're on? Do you think we need more breakthroughs? Do you think the current approach will get us there?

Dr. Fei Fei Li (00:24:13):
Yeah, this is a very interesting term, Lenny. I don't know if anyone has ever defined AGI. There are many different definitions, including some kind of superpower for machines all the way to machines can become economically viable agent in the society. In other words, making salaries to live. Is that the definition of AGI? As a scientist, I take science very seriously and I enter the field because I was inspired by this audacious question of, can machines think and do things in the way that humans can do? For me, that's always the north star of AI. And from that point of view, I don't know what's the difference between AI and AGI.

(00:25:10):
I think we've done very well in achieving parts of the goal, including conversational AI, but I don't think we have completely conquered all the goals of AI. And I think our founding fathers, Alan Turing, I wonder if Alan Turing is around today and you ask him to contrast AI versus AGI, he might just shrugged and said, "Well, I asked the same question back in 1940s," so I don't want to get onto a rabbit hole of defining AI versus AGI. I feel AGI is more a marketing term than a scientific term as a scientist than technologist. AI is my north star, is my field's north star, and I'm happy people call it whatever name they want to call it.

Lenny Rachitsky (00:26:05):
So let me ask you maybe this way, like you described, there's kind of these components that from ImageNet and AlexNet took us to where we're today, GPUs essentially, data, label data, just like the algorithm of the model. There's also just the transformer feels like an important step in that trajectory. Do you feel like those are the same components that'll get us to, I don't know, 10 times smarter model, something that's like life-changing for the entire world? Or do you think we need more breakthroughs? I know we're going to talk about world models, which I think is a component of this, but is there anything else that you think is like, oh, this will plateau, or okay, this will take us just need more data, more compute, more GPUs?

Dr. Fei Fei Li (00:26:44):
Oh no, I definitely think we need more innovations. I think scaling loss of more data, more GPUs, and bigger current model architecture is there's still a lot to be done there, but I absolutely think we need to innovate more. There's not a single deeply scientific discipline in human history that has arrived at a place that says we're done, we're done innovating and AI is one of the, if not the youngest discipline in human civilization in terms of science and technology, we're still scratching the surface. For example, like I said, we're going to segue into world models. Today, you take a model and run it through a video of a couple of office rooms and ask the model to count the number of chairs. And this is something a toddler could do or maybe an elementary school kid could do, and AI could not do that, right?

(00:27:50):
So there's just so much AI today could not do, then let alone thinking about how did someone like Isaac Newton look at the movements of the celestial bodies and derive an equation or a set of equations that governs the movement of all bodies, that level of creativity, extrapolation, abstraction. We have no way of enabling AI to do that today. And then let's look at emotional intelligence. If you look at a student coming to a teacher's office and have a conversation about motivation, passion, what to learn, what's the problem that's really bothering you. That conversation, as powerful as today's conversational bots are, you don't get that level of emotional cognitive intelligence from today's AI. So there's a lot we can do better, and I do not believe we're done innovating.

Lenny Rachitsky (00:29:00):
Demis had this really interesting interview recently from DeepMind slash Google where someone asked him just like, "What do you think, how far are we from AGI? What does it look like going through there?" He had a really interesting way of approaching it is if we were to give the most cutting-edge model all the information until the end of the 20th century, see if it could come up with all the breakthroughs Einstein had and so far we're nowhere near that, but they could just-

Dr. Fei Fei Li (00:29:22):
No, we're not. In fact, it's even worse. Let's give AI all the data including modern instruments data of celestial bodies, which Newton did not have, and give it to that and just ask AI to create the 17th century set of equations on the laws of bodily movements. Today's AI cannot do that.

Lenny Rachitsky (00:29:49):
All right. We're ways away is what I'm hearing.

Dr. Fei Fei Li (00:29:50):
Yeah.

Lenny Rachitsky (00:29:51):
Okay, so let's talk about world models. To me, this is just another really amazing example of you being ahead of where people end up. So you were way ahead on, okay, we just need a lot of clean data for AI and neural networks to learn. You've been talking about this idea of world models for a long time. You started a company to build, essentially there's language models. This is a different thing. This is a world model. We'll talk about what that is. And now, as I was preparing for this Elon's talking about world models, Jensen's talking about world models, I know Google's working on this stuff. You've been at this for a long time and you actually just launched something that's going, we're going to talk about right before this podcast airs. Talk about what is a world model? Why is it so important?

Dr. Fei Fei Li (00:30:33):
I'm very excited to see that more and more people are talking about world models like Elon, like Jensen. I have been thinking about really how to push AI forward all my life and the large language models that came out of the research world and then OpenAI and all this, for the past few years, were extremely inspiring even for a researcher like me. I remembered when GPT2 came out, and that was in, I think, late 2020. I was co-director, I still am, but I was at that time full-time co-director of Stanford's Human-Centered AI institute, and I remember it was... The public was not aware of the power of the large language model yet, but as researchers, we were seeing it, we're seeing the future, and I had pretty long conversations with my natural language processing colleagues like Percy Liang and Chris Manning. We were talking about how critical this technology is going to be and the Stanford AI Institute, Human-Centered AI Institute, HAI, was the first one to establish a full research center foundation model.

(00:31:59):
We were, Percy Liang, and many researchers led the first academic paper foundation model. So it was just very inspiring for me. Of course, I come from the world of visual intelligence and I was just thinking there's so much we can push forward beyond language because humans, humans use our sense of spatial intelligence, a world understanding to do so many things and they are beyond language. Think about a very chaotic first responder scene, whether it's fire or some traffic accident or some natural disaster. And if you immerse yourself in those scene and think about how people organize themselves to rescue people, to stop further disasters, to put down fires, a lot of that is movements is spontaneous understanding of objects, worlds, human situational awareness. Language is part of that, but a lot of those situations, language cannot get you to put down the fire.

(00:33:21):
So that is, what is that? I was thinking a lot. And in the meantime, I was doing a lot of robotics research and it dawned on me that the linchpin of connecting the additional intelligence, in addition to language embodied AI, which are robotics, connecting visual intelligence, is the sense of spatial intelligence about understanding the world. And that's when I think it was 2024, I gave a TED talk about spatial intelligence at world models. And I start formulating this idea back in 2022 based on my robotics and computer vision research. And then one thing that was really clear to me is that I really want to work with the brightest technologists and move as fast as possible to bring this technology to life. And that's when we founded this company called World Labs. And you can see the word world is in the title of our company because we believe so much in world modeling and spatial intelligence.

Lenny Rachitsky (00:34:41):
People are so used to just chatbots and that's a large language model. A simple way to understand a world model is you basically describe a scene and it generates an infinitely explorable world. We'll link to the thing you launched, which we'll talk about, but just is that a simple way to understand it?

Dr. Fei Fei Li (00:34:56):
That's part of it, Lenny. I think a simple way to understand a world model is that this model can allow anyone to create any worlds in their mind's eye by prompting whether it's an image or a sentence. And also be able to interact in this world whether you are browsing and walking or picking objects up or changing things as well as to reason within this world, for example, if the person consuming, if the agent consuming this output of the world model is a robot, it should be able to plan its path and help to tidy the kitchen, for example. So world model is a foundation that you can use to reason, to interact, and to create worlds.

Lenny Rachitsky (00:36:00):
Great. Yeah. So robots feels like that's potentially the next big focus for AI researchers and just the impact on the world. And what you're saying here is this is a key missing piece of making robots actually work in the real world, understanding how the world works.

Dr. Fei Fei Li (00:36:17):
Yeah. Well, first of all, I do think there's more than robots. That's exciting. But I agree with everything you just said. I think world modeling and spatial intelligence is a key missing piece of embodied AI. I also think let's not underestimate that humans are embodied agents and humans can be augmented by AI's intelligence. Just like today, humans are language animals, but we're very much augmented by AI helping us to do language tasks including software engineering. I think that we shouldn't underestimate or maybe we tend not to talk about how humans, as an embodied agents, can actually benefit so much from world models and spatial intelligence models as well as robots can.

Lenny Rachitsky (00:37:15):
So the big unlocks here, robots, which a huge deal if this works out, imagine each of us has robots doing a bunch of stuff for us, they help us with disasters, things like that. Games obviously is a really cool example, just like infinitely playable games that you just invent out of your head. And then creativity feels like just like being fun, having fun, being creative, thinking of magic, wild new worlds, and environments.

Dr. Fei Fei Li (00:37:39):
And also design, humans design from machines to buildings to homes and also scientific discovery. There is so much. I like to use the example of the discovery of the structure of DNA. If you look at one of the most important piece in DNA's discovery history is the x-ray diffraction photo that was captured by Rosalind Franklin, and it was a flat 2D photo of a structure that it looks like a cross with diffractions. You can google those photos. But with that 2D flat photo, the humans, especially two important humans, James Watson and Francis Crick, in addition to their other information, was able to reason in 3D space and deduce a highly three-dimensional double helix structure of the DNA. And that structure cannot possibly be 2D. You cannot think in 2D and deduce that structure. You have to think in 3D spatial, use the human spatial intelligence. So I think even in scientific discovery, spatial intelligence or AI-assisted spatial intelligence is critical.

Lenny Rachitsky (00:39:08):
This is such an example of, I think it was Chris Dixon that had this line that the next big thing is going to start off feeling like a toy. When ChatGPT just came out, I remember Sam Altman just tweeted it as like, "Here's a cool thing we're playing with, check it out." Now, it's the fastest growing product to all of history, changed the world. And it's oftentimes the things that just look like, okay, this is cool, that it's a fun to play with that end up changing the world most.

(00:39:33):
This episode is brought to you by Sinch, the customer communications cloud. Here's the thing about digital customer communications. Whether you're sending marketing campaigns, verification codes, or account alerts, you need them to reach users reliably. That's where Sinch comes in. Over 150,000 businesses, including 8 of the top 10 largest tech companies globally use Sinch's API to build messaging, email, and calling into their products. And there's something big happening in messaging that product teams need to know about, Rich Communication Services or RCS. Think of RCS as SMS2.0. Instead of getting texts from a random number, your users will see your verified company name and logo without needing to download anything new.

(00:40:16):
It's a more secure and branded experience. Plus you get features like interactive carousels and suggested replies. And here's why this matters, US carriers are starting to adopt RCS. Sinch is already helping major brands send RCS messages around the world and they're helping Lenny's podcast listeners get registered first before the rush hits the US market. Learn more and get started at sinch.com/lenny. That's S-I-N-C-H.com/lenny.

(00:40:45):
I reached out to Ben Horowitz, who loves what you're doing, a big fan of yours. They're investors I believe in...

Dr. Fei Fei Li (00:40:51):
Yeah, we've known each other for many years, but yes, right now they're investors of World Labs.

Lenny Rachitsky (00:40:57):
Amazing. Okay, so I asked him what I should ask you about and he suggested ask you why is the bitter lesson alone not likely to work for robots? So first of all, just explain what the bitter lesson was in the history of AI and then just why that won't get us to where we want to be with robots.

Dr. Fei Fei Li (00:41:17):
Well, first of all, there are many bitter lessons, but the bitter lessons everybody refers to is a paper written by Richard Sutton who won the Turing Award recently, and he does a lot of reinforcement learning. And Richard has said, if you look at the history, especially the algorithmic development of AI, it turns out simpler model with a ton of data always win at the end of the day instead of the more complex model with less data. I mean, that was actually... This paper came years after ImageNet. That to me was not bitter; it was a sweet lesson. That's why I built ImageNet because I believe that big data plays that role. So why can't bitter lesson work in robotics alone? Well, first of all, I think we need to give credit to where we are today. Robotics is very much in the early days of experimentation.

(00:42:25):
The research is not nearly as mature as say language models. So many people are still experimenting with different algorithms and some of those algorithms are driven by big data. So I do think big data will continue to play a role in robotics, but what is hard for robotics, there are a couple of things. One is that it's harder to get data. It's a lot harder to get data. You can say, well, there's web data. This is where the latest robotics research is using web videos. And I think web videos do play a role. But if you think about what made language model worth a very... As someone who does computer vision and spatial intelligence and robotics, I'm very jealous of my colleagues in language because they had this perfect setup where their training data are in words, eventually tokens, and then they produce a model that outputs words.

(00:43:36):
So you have this perfect alignment between what you hope to get, which we call objective function and what your training data looks like. But robotics is different. Even spatial intelligence is different. You hope to get actions out of robots, but your training data lacks actions in 3D worlds, and that's what robots have to do, right? Actions in 3D worlds. So you have to find different ways to fit a, what do they call, a square in a round hole, that what we have is tons of web videos. So then we have to start talking about adding supplementing data such as teleoperation data or synthetic data so that the robots are trained with this hypothesis of bitter lesson, which is large amount of data. I think there's still hope because even what we are doing in world modeling will really unlock a lot of this information for robots.

(00:44:53):
But I think we have to be careful because we're at the early days of this and bitter lesson is still to be tested because we haven't fully figured out the data for. Another part of the bitter lesson of robotics I think we should be so realistic about is again, compared to language models or even spatial models, robots are physical systems. So robots are closer to self-driving cars than a large language model. And that's very important to recognize. That means that in order for robots to work, we not only need brains, we also need the physical body. We also need application scenarios. If you look at the history of self-driving car, my colleague Sebastian Thrun took Stanford's car to win the first DARPA challenge in 2006 or 2005. It's 20 years since that prototype of a self-driving car being able to drive 130 miles in the Nevada desert to today's Waymo and on the street of San Francisco.

(00:46:17):
And we're not even done yet. There's still a lot. So that's a 20-year journey. And self-driving cars are much simpler robots, they're just metal boxes running on 2D surfaces, and the goal is not to touch anything. Robot is 3D things running in 3D world, and the goal is to touch things. So the journey is going to be, there's many aspects, elements, and of course one could say, well, the self-driving car, early algorithm were pre deep learning era. So deep learning is accelerating the brains. And I think that's true. That's why I'm in robotics, that's why I'm in spatial intelligence and I'm excited by it. But in the meantime, the car industry is very mature and productizing also involves the mature use cases, supply chains, the hardware. So I think it's a very interesting time to work in these problems. But it's true, Ben is right. We might still be subject to a number of bitter lessons.

Lenny Rachitsky (00:47:28):
Doing this work, do you ever just feel awe for the way the brain works and is able to do all of this for us? Just the complexity just to get a machine to just walk around and not hit things and fall, does just give you more respect for what we've already got?

Dr. Fei Fei Li (00:47:44):
Totally. We operate on about 20 watts. That's dimmer than any light bulb in the room I'm in right now. And yet we can do so much. So I think actually the more I work in AI, the more I respect humans.

Lenny Rachitsky (00:48:03):
Let's talk about this product you just launched. It's called Marble, a very cute name. Talk about what this is, why this is important. I've been playing with it, it's incredible. We'll link to it for folks to check it out. What is Marble?

Dr. Fei Fei Li (00:48:14):
Yeah, I'm very excited. So first of all, Marble is one of the first product that World Labs has rolled out. World Labs is a foundation frontier model company. We are founded by four co-founders who have deep technical history. My co-founders, Justin Johnson, Christoph Lassner, and Ben Mildenhall. We all come from the research field of AI, computer graphics, computer vision, and we believe that spatial intelligence and world modeling is as important, if not more, to language models and complementary to language models. So we wanted to seize this opportunity to create deep tech research lab that can connect the dots between frontier models with products. So Marble is an app that's built upon our frontier models. We've spent a year and plus building the world's first generative model that can output genuinely 3D worlds. That's a very, very hard problem.

(00:49:30):
And it was a very hard process and we have a team of incredible, founding team of incredible technologists from incredible teams. And then around just a month or two ago, we saw the first time that we can just prompt with a sentence and the image and multiple images and create worlds that we can just navigate in. If you put it on Google, which we have an option to let you do that, you can even walk around. Even though we've been building this for quite a while, it was still just awe-inspiring and we wanted to get into the hands of people who need it. And then we know that so many creators, designers, people who are thinking about robotic simulation, people who are thinking about different use cases of navigable interactable, immersive worlds game developers will find this useful. So we developed Marble as a first step. It's again, still very early, but it's the world's first model doing this, and it's the world's first product that allows people to just prompt, we call it prompt to worlds.

Lenny Rachitsky (00:51:00):
Well, I've been playing around with it. It is insane. You could just have a little Shire world where you just infinitely walk around middle earth basically, and there's no one there yet, but it's insane. You just go anywhere. There's dystopian world. I'm just looking at all these examples and my favorite part, actually, I don't know if there's a feature or bug, you can see the dots of the world before it actually renders with all the textures. And I just love like, you get a glimpse into what is going on with this model, basically-

Dr. Fei Fei Li (00:51:27):
That is so cool to hear because this is where, as a researcher, I am learning because the dots that lead you into the world was an intentional feature visualization, is not part of the model. The model actually just generates the world. But we were trying to find a way to guide people into the world, and a number of engineers worked on different versions, but we converged on the dot, and so many people, you're not the only one, told us how delightful that experience is, and it was really satisfying for us to hear that this intentional visualization feature that's not just the big hardcore model actually has delighted our users.

Lenny Rachitsky (00:52:19):
Wow. So you add that to make it more, like to have humans understand what's going on-

Dr. Fei Fei Li (00:52:24):
To have fun, yes.

Lenny Rachitsky (00:52:24):
... get more delightful. Wow, that is hilarious. It makes me think about LLMs and the way they, it's not the same thing, but they talk about what they're thinking and what they're doing.

Dr. Fei Fei Li (00:52:32):
Yes, it is. It is.

Lenny Rachitsky (00:52:34):
It also makes me think about just the Matrix. It's exactly the Matrix experience. I don't know if that was your inspiration.

Dr. Fei Fei Li (00:52:42):
Well, like I said, a number of engineers worked on that. It could be their inspiration.

Lenny Rachitsky (00:52:48):
It's in their subconscious. Okay, so just for folks that may want to play around with this, maybe like, what are some applications today that folks can start using today? What's your goal with this launch?

Dr. Fei Fei Li (00:52:59):
Yeah, so we do believe that world modeling is very horizontal, but we're already seeing some really exciting use cases, virtual production for movies, because what they need are 3D worlds that they can align with the camera. So when the actors are acting on it, they can position the camera and shoot the segments really well. And we're already seeing incredible use. In fact, I don't know if you have seen our launch video showing Marble. It was produced by a virtual production company. We collaborated with Sony and they use Marble scenes to shoot those videos. So we were collaborating with those technical artists and directors, and they were saying, this has cut our production time by 40X. In fact, it has to-

Lenny Rachitsky (00:53:00):
40X?

Dr. Fei Fei Li (00:53:59):
Yes, in fact it has to, because we only had one month to work on this project and there were so many things they were trying to shoot. So using Marble really, really significantly accelerated the virtual production for VFX and movies. That's one use cases. We are already seeing our users taking our Marble scene and taking the mesh export and putting games, whether it's games on VR or just fun games that they have developed. We are showing an example of robotic simulation because when I was, I mean I still am a researcher doing robotic training. One of the biggest pain point is to create synthetic data for training robots. And this synthetic data needs to be very diverse. They need to come from different environments with different objects to manipulate. And one path to it is to ask computers to simulate.

(00:55:10):
Otherwise, humans have to build every single asset for robots. That's just going to take a lot longer. So we already have researchers reaching out and wanting to use Marble to create those synthetic environments. We also have unexpected user outreach in terms of how they want to use Marble. For example, a psychologist team called us to use Marble to do psychology research. It turned out some of the psychiatric patients they study, they need to understand how their brain respond to different immersive things of different features. For example, messy scenes or clean scenes or whatever you name it. And it's very hard for researchers to get their hands on these kind of immersive scenes and it will take them too long and too much budget to create. And Marble is a really almost instantaneous way of getting so many of these experimental environments into their hands. So we're seeing multiple use cases at this point. But the VFX, the game developers, the simulation developers as well as designers are very excited.

Lenny Rachitsky (00:56:39):
This is very much the way things work in AI. I've had other AI leaders on the podcast and it's always put things out there early as soon as you can to discover where the big use cases are. The head of ChatGPT told me how, when they first put out ChatGPT, he was just scanning TikTok to see how people were using it and all the things they were talking about, and that's what convinced them where to lean in and help them see how people actually want to use it. I love this last use case for therapy. I'm just imagining heights, people dealing with heights or snakes or spiders, which-

Dr. Fei Fei Li (00:57:11):
It's amazing. A friend of mine last night literally called me and talked about his height scare and asked me if Marble should be used. It's amazing you went straight there.

Lenny Rachitsky (00:57:24):
Because imagining all the exposure therapy stuff, this could be so good for that. That is so cool. Okay, so I should have asked you this before, but I think there's going to be a question of just, how does this differ from things like VO3 and other video generation models? It's pretty clear to me, but I think it might be helpful just to explain how this is different from all the video AI tools people have seen.

Dr. Fei Fei Li (00:57:46):
World Labs' thesis is that spatial intelligence is fundamentally very important, and spatial intelligence is not just about videos. In fact, the world is not passively watching videos passing by. I love, Plato has the allegory of the cave analogy to describe vision. He said that imagine a prisoner tied on his chair, not very humane, but in a cave watching a full life theater in front of him, but the actual life theater that actors are acting is behind his back. It was just lit so that the projection of the action is on a wall of the cave. And then the goal, the task of this prisoner is to figure out what's going on. It's a pretty extreme example, but it really shows, it describes what vision is about, is that to make sense of the 3D world or 4D world out of 2D. So spatial intelligence to me is deeper than only creating that flat 2D world.

(00:59:14):
Spatial intelligence to me is the ability to create, reason, interact, make sense of deeply spatial world, whether it's 2D or 3D or 4D, including dynamics and all that. So World Lab is focusing on that, and of course the ability to create videos per se could be part of this. And in fact, just a couple of weeks ago, we rolled out the world's first real time demoable, real-time video generation on a single H100 GPU. So part of our technology includes that, but I think Marble is very different because we really want creators, designers, developers to have in their hands a model that can give them worlds with 3D structures so they can use it for their work. And that's why Marble is so different.

Lenny Rachitsky (01:00:21):
The way I see it is it's a platform for a ton of opportunity to do stuff. As you described, videos are just like, here's a one-off video that's very fun and cool and you could... And that's it. That's it. And you move on.

Dr. Fei Fei Li (01:00:33):
By the way, we could in Marble, we could allow people to export in video forms. So you could actually, like you said, you go into a world, so let's say it's a hobbit cave. You can actually, especially as a creator, you have such a specific way of moving the camera in a trajectory in the director's mind, and then you can export that from Marble into a video.

Lenny Rachitsky (01:01:02):
What does it take to create something like this? Just how big is the team, how many GPUs you work in? Anything you can share there. I don't know how much of this is private information, but just what does it take to create something like this that you've launched here?

Dr. Fei Fei Li (01:01:12):
It takes a lot of brain power. So we just talk about 20 watts per brain. So from that point of view, it's a small number, but it's actually incredible. It's half billion years of evolution to give us those power. We have a team of 30-ish people now, and we are predominantly researchers and research engineers, but we also have designers and product. We actually really believe that we want to create a company that's anchored in the deep tech of spatial intelligence, but we are actually building serious products. So we have this integration of R&D and productization, and of course, we use a ton of GPUs.

Lenny Rachitsky (01:02:15):
That's the technical thing.

Dr. Fei Fei Li (01:02:17):
Happy to hear.

Lenny Rachitsky (01:02:20):
Well, congrats on the launch. I know this is a huge milestone. I know this took a ton of work.

Dr. Fei Fei Li (01:02:20):
Thank you.

Lenny Rachitsky (01:02:23):
So I just want to say congrats to you and your team. Let me talk about your founder journey for a moment. So you're a founder of this company. You started how many years ago? A couple of years ago, two, three years ago?

Dr. Fei Fei Li (01:02:23):
A year ago.

Lenny Rachitsky (01:02:33):
A year ago?

Dr. Fei Fei Li (01:02:34):
A year plus.

Lenny Rachitsky (01:02:37):
A year? Okay. Wow.

Dr. Fei Fei Li (01:02:37):
Probably, 18 month, yeah.

Lenny Rachitsky (01:02:38):
Okay. What's something you wish you knew before you started this that you wish you could whisper into the ear of Fei-Fei of 18 months ago?

Dr. Fei Fei Li (01:02:46):
Well, I continue to wish I know the future of technology. I think actually that's one of our founding advantage is that we see the future earlier in general than most people. But still, man, this is so exciting and so amazing that what's unknown and what's coming, but I know the reason you're asking me this question is not about the future of technology. Furthermore, look, I did not start a company of this scale at 20-year-old. So I started a dry cleaner when I was 19, but that's a little smaller scale.

Lenny Rachitsky (01:03:30):
We got to talk about that.

Dr. Fei Fei Li (01:03:32):
And then I founded Google Cloud AI and then I founded an institute at Stanford but those are different beasts. I did feel I was a little more prepared as a founder of the grinding journey compared to maybe the 20-year-old founders. But I still, I'm surprised, and it puts me into paranoia sometimes that how intensely competitive AI landscape is from the model, the technology itself, as well as talents. And when I founded the company, we did not have these incredible stories of how much certain talents would cost. So these are things that continue to surprise me and I have to be very alert about.

Lenny Rachitsky (01:04:40):
So the competition you're talking about is the competition for talent, the speed at which just how things are moving.

Dr. Fei Fei Li (01:04:46):
Yeah.

Lenny Rachitsky (01:04:47):
Yeah. You mentioned this point that I want to come back to that if you just look over the course of your career, you were at all of the major collections of humans that led to so many of the breakthroughs that are happening today. Obviously, we talk about ImageNet also just SAIL at Stanford is where a lot of the work happened, Google Cloud, which a lot of the breakthroughs happened. What brought you to those places? Like for people looking for how to advance in their career, be at the center of the future, just is there a through line there of just what pulled you from place to place and pulled you into those groups that might be helpful for people to hear?

Dr. Fei Fei Li (01:05:25):
Yeah, this is actually a great question, Lenny, because I do think about it, and obviously we talked about it's curiosity and passion that brought me to AI, that is more a scientific north star, right? I did not care if AI was a thing or not, so that was one part. But how did I end up choosing in the particular places I work in, including starting World Labs, is I think I'm very grateful to myself or maybe to my parents' genes. I'm an intellectually very fearless person, and I have to say when I hire young people, I look for that because I think that's a very important quality if one wants to make a difference, is that when you want to make a difference, you have to accept that you're creating something new or you're diving into something new. People haven't done that. And if you have that self-awareness, you almost have to allow yourself to be fearless and to be courageous.

(01:06:42):
So when I, for example, came to Stanford, in the world of academia, I was very close to this thing called tenure, which is have the job forever at Princeton. But I chose to come to Stanford because... I love Princeton. It's by alma mater. It's just at that moment there are people who are so amazing at Stanford and the Silicon Valley ecosystem was so amazing that I was okay to take a risk of restarting my tenure clock. Becoming the first female director of SAIL, I was actually relatively speaking a very young faculty at that time, and I wanted to do that because I care about that community. I didn't spend too much time thinking about all the failure cases.

(01:07:46):
Obviously, I was very lucky that the more senior faculty supported me, but I just wanted to make a difference. And then going to Google was similar. I wanted to work with people like Jeff Dean, Jeff Hinton, and all these incredible demists, the incredible people. The same with World Labs. I have this passion. And I also believe that people with the same mission can do incredible things. So that's how it guided my through line. I don't overthink of all possible things that can go wrong because that's too many.

Lenny Rachitsky (01:08:33):
I feel like an important element of this is not focusing on the downside, focusing more on the people, the mission. What gets you excited, what do you think, the curiosity.

Dr. Fei Fei Li (01:08:43):
Yeah. I do want to say one thing to all the young talents in AI, the engineers, the researchers out there, because some of you apply to World Labs, I feel very privileged you considered World Labs. I do find many of the young people today think about every single aspect of an equation when they decide on jobs. At some point, maybe that's the way they want to do it, but sometimes I do want to encourage young people to focus on what's important because I find myself constantly in mentoring mode when I talk to job candidates. Not necessarily recruiting or not recruiting, but just in mentoring mode when I see an incredible young talent who is over-focusing on every minute dimension and aspect of considering a job, when maybe the most important thing is where's your passion? Do you align with the mission? Do you believe and have faith in this team? And just focus on the impact and you can make and the kind of work and team you can work with.

Lenny Rachitsky (01:10:05):
Yeah, it's tough. It's tough for people in the AI space. Now there's so much, so much at them, so much new, so much happening, so much FOMO.

Dr. Fei Fei Li (01:10:11):
That's true.

Lenny Rachitsky (01:10:12):
I could see the stress. And so I think that advice is really important. Just like what will actually make you feel fulfilled in what you're doing, not just where's the fastest growing company, where's the... Who's going to win? I don't know. I want to make sure I ask you about the work you're doing today at Stanford, at the HCI. I think it's the-

Dr. Fei Fei Li (01:10:12):
HAI.

Lenny Rachitsky (01:10:30):
HAI, Human-Centered AI Institute. What are you doing there? I know this is a thing you do on the side still.

Dr. Fei Fei Li (01:10:36):
So yes, HAI, Human-Centered AI Institute was co-founded by me and a group of faculty like Professor John Etchemendy, Professor James Landay, Professor Chris Manning back in 2018. I was actually finishing my last sabbatical at Google and it was a very, very important decision for me because I could have stayed in industry, but my time at Google taught me one thing is AI is going to be a civilization of technology. And it dawned on me how important this is to humanity to the point that I actually wrote a piece in New York Times, that year 2018, to talk about the need for a guiding framework to develop and to apply AI. And that framework has to be anchored in human benevolence, in human centeredness. And I felt that Stanford, one of the world's top university in the heart of Silicon Valley that gave birth to important companies from NVIDIA to Google, should be a thought leader to create this human-centered AI framework and to actually embody that in our research education and policy and ecosystem work.

(01:12:10):
So I founded HAI. Fast-forward, after six, seven years, it has become the world's largest AI institute that does human-centered research, education, ecosystem, outreach, and policy impact. It involves hundreds of faculty across all eight schools at Stanford, from medicine to education, to sustainability to business, to engineering, to humanities to law. And we support researchers, especially at the interdisciplinary area from digital economy, to legal studies, to political science, to discovery of new drugs, to new algorithms to that's beyond transformers. We also actually put a very strong focus on policy because when we started HAI, I realized that Silicon Valley did not talk to Washington DC and or Brussels or other parts of the world.

(01:13:27):
And given how important this technology is, we need to bring everybody on board. So we created multiple programs from congressional bootcamp to AI index report to policy briefing, and we especially participated in policymaking including advocating for a national AI research cloud bill that was passed in the first Trump administration and participating in state level regulatory AI discussions. So there's a lot we did, and I continue to be one of the leaders even though I'm much less involved operationally because I care not only we create this technology, but we use it in the right way.

Lenny Rachitsky (01:14:24):
Wow. I was not aware of all that other work you were doing. As you're talking, I was reminded Charlie Munger had this quote, "Take a simple idea and take it very seriously." I feel like you've done that in so many different ways and stayed with it and it's unbelievable the impact that you've had in so many ways over the years. I'm going to skip the lightning round and I'm just looking to ask you one last question. Is there anything else that you wanted to share? Anything else you want to leave listeners with?

Dr. Fei Fei Li (01:14:52):
I am very excited by AI, Lenny. I want to answer one question that when I travel around the world, everybody asks me is that, if I'm a musician, if I'm a teacher, middle school teacher, if I'm a nurse, if I'm an accountant, if I'm a farmer, do I have a role in AI or is AI just going to take over my life or my work? And I think this is the most important question of AI and I find that in Silicon Valley, we tend not to speak heart-to-heart with people, with people like us and not like us in Silicon Valley, but all of us, we tend to just toss around words like infinite productivity or infinite leisure time or infinite power or whatever. But at the end of the day, AI is about people. And when people ask me that question, it's a resounding yes, everybody has a role in AI.

(01:16:03):
It depends on what you do and what you want. But no technology should take away human dignity and the human dignity and agency should be at the heart of the development, the deployment, as well as the governance of every technology. So if you are a young artist and your passion is storytelling, embrace AI as a tool. In fact, embrace Marble. I hope it becomes a tool for you because the way you tell your story is unique and the world still needs it. But how you tell your story, how do you use the most incredible tool to tell your story in the most unique way is important. And that voice needs to be heard. If you are a farmer near retirement, AI still matters because you are a citizen. You can participate in your community, you should have a voice in how AI is used, how AI is applied.

(01:17:14):
You work with people that you can encourage all of you to use AI to make life easier for you. If you are a nurse, I hope you know that at least in my career, I have worked so much in healthcare research because I feel our healthcare workers should be greatly augmented and helped by AI technology, whether it's smart cameras to feed more information or robotic assistance because our nurses are overworked, overfatigued, and as our society ages, we need more help for people to be taken care of. So AI can play that role. So I just want to say that it's so important that even a technologist like me are sincere about that everybody has a role in AI.

Lenny Rachitsky (01:18:17):
What a beautiful way to end it. Such a tie back to where we started about how it's up to us and take individual responsibility for what AI will do in our lives. Final question, where can folks find Marble? Where can they go, maybe try to join World Labs if they want to? What's the website? Where do people go?

Dr. Fei Fei Li (01:18:34):
Well, World Labs website is www.worldlabs.ai and you can find our research progress there. We have technical blogs. You can find Marble, the product there. You can sign in there. You can find our job posts link there. We're in San Francisco. We love to work with the world's best talents.

Lenny Rachitsky (01:19:02):
Amazing. Fei-Fei, thank you so much for being here.

Dr. Fei Fei Li (01:19:04):
Thank you, Lenny.

Lenny Rachitsky (01:19:06):
Bye everyone.

(01:19:09):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Leaving big tech to build the #1 technology newsletter | Gergely Orosz (The Pragmatic Engineer)
**Guest:** Gergely  
**Published:** 2022-11-17  
**YouTube:** https://www.youtube.com/watch?v=CtB0O0M7YS0  
**Tags:** growth, retention, acquisition, activation, churn, metrics, a/b testing, experimentation, analytics, subscription  

# Leaving big tech to build the #1 technology newsletter | Gergely Orosz (The Pragmatic Engineer)

## Transcript

Gergely Orosz (00:00:00):
In my best year at Uber, I made about 320 or $330,000 in total compensation. And when I quit my job, I was actually thinking, am I crazy? Because I am leaving... Especially in Europe, this is a lot of money [inaudible 00:00:14] this will be similar to something... Someone in a similar position would've made five or 600K in total in the U.S. But now I am making more in compensation that I made at Uber. And the difference is that now my compensation... Well, my earnings keep going up as long as the newsletter is growing, so there's no theoretical cap on this. Of course there's an actual cap, there's churn, growth is slowing over time. But it's very, very strange, because I felt that I was in a really privileged position, just honestly making tons of money, doing a job that I loved. And this was at Uber or as a software engineer. And I'm now doing stuff that I love, and in some strange way, I guess it even pays better.

Lenny (00:00:59):
Welcome to Lenny's Podcast. I'm Lenny, and my goal here is to help you get better at the craft of building and growing products. I interview world class product leaders and growth experts to learn from their hard won experiences building and scaling today's most successful companies. Today my guest is Gergely Orosz. In a sense, Gergely is the me of engineering. He's got the top engineering newsletter on Substack, it's growing really fast, and like me, he does this full time. In this episode, we talk about the life of newslettering full time, like we both do. We get into Gergely's decision to leave his cushy tech job at Uber, to go into this life full-time, what the day-to-day life of a newsletter person is, the pros and cons of this life, what it takes to be successful, and a bunch of advice for how to get started if you're curious about going down this route. This is a pretty unique episode, and it was really fun to do. If you ever thought about writing or going down this creator route, you'll love this episode. With that, I bring you Gergely Orosz.

Lenny (00:02:06):
This episode is brought to you by lemon.io. You've achieved product market fit. You're able to activate, engage, and retain your customers. But you don't have the engineers that you need to move as fast as you want to, because it's hard to find great engineers quickly, especially if you're trying to protect your burden rate. Meet lemon.io. Lemon.io will quickly match you with skilled senior developers who are all vetted, results oriented, and ready to help you grow. And all that at competitive rates. Startups choose lemon.io because they offer only hand-picked developers with three or more years of experience and strong proven portfolios. Only 1% of candidates who apply get in, so you can be sure that they offer you only high quality talent. And if something ever goes wrong, lemon.io offers you a swift replacement, so that you're kind of hiring with a warranty.

Lenny (00:02:55):
To learn more, just go to lemon.io/lenny and find your perfect developer or tech team in 48 hours or less. And if you start the process now, you can claim a special discount exclusively for Lenny's Podcast listeners. 15% off your first four weeks of working with your new software developer. Grow faster with an extra pair of hands. Visit lemon.io/lenny.

Lenny (00:03:20):
This episode is brought to you by Eppo. Eppo is a next generation A/B testing platform built by Airbnb alums for modern growth teams. Companies like Netlify and Tenfold and Cameo rely on Eppo to power their experiments. Wherever you work, running experiments is increasingly essential, but there are no commercial tools that integrate with a modern growth team stack. This leads to wasted time building internal tools, or trying to run your experiments through a clunky marketing tool. When I was at Airbnb, one of the things that I loved about our experimentation platform was being able to easily slice results by device, by country, and by [inaudible 00:03:56]. Eppo does all that and more, delivering results quickly, avoiding annoying prolonged analytics cycles, and helping you easily get to the root cause of any issue you discover. Eppo lets you go beyond basic clickthrough metrics, and instead use your North Star metrics like activation, retention, subscriptions, and payments. And Eppo supports tests on the front end, the back end, email marketing, and even machine learning clients. Check out Eppo at geteppo.com, get E-P-P-O.com, and 10x your experiment velocity.

Lenny (00:04:28):
Gergely, welcome to the podcast.

Gergely Orosz (00:04:35):
It's awesome. Great to be here, Lenny.

Lenny (00:04:36):
So I think this is going to be a pretty special and unique podcast. Your newsletter is the number one technology newsletter on Substack, called the Pragmatic Engineer, by the way. My newsletter is the number one business newsletter on Substack, and so we're connected in this really special, weird way, and I thought it would be pretty fun to just explore this weird path that we're on doing this newsletter thing, and in that, help listeners understand the pros and cons of this life, how to go down this route, what it takes to be successful, all that stuff. But before we get into all that, I'd love for you to spend maybe a minute just giving us a little overview of your career, and how you got to where you are today doing this newsletter, and what you spend your time on now.

Gergely Orosz (00:05:19):
My career started out as what you might consider a pretty typical software engineer career. I graduated from university, I did a computer science degree for a five year program, so I did bachelor's and master's. I worked on the side, I hacked around, built small websites here and there, and during university I worked at a small web agency. And then I worked my way up in the industry. So I started off at a consulting company, we were just building for other companies. I'm originally from Hungary, in Europe. I then moved to UK, which was a big step up for me in terms of just getting access to, I guess, more modern software development. I was at a consulting company there as well. And I moved up to London, which in Europe, I feel it's like the New York of Europe, or even the Silicon Valley, back in the day. Back before Brexit, it was the biggest tech hub.

Gergely Orosz (00:06:11):
I worked at an investment bank there, and then on the side I was always building mobile apps, and I got into Skype. I like to say Skype, but it was Microsoft. They just bought Skype at that point, and it was a lot more startup-y environment, a lot more fast moving. I then moved to another startup where I was a founding engineer of a acquisition. It's a startup called Skyscanner. And then I ended up at Uber at Amsterdam, where I joined as a senior software engineer, and I became a manager, and then a manager of managers, and it was just... I feel, looking back at that part of my career, I just felt really growing all the time, just taking each step one step at a time, which gave me a lot of appreciation for all these levels.

Gergely Orosz (00:06:51):
And then, just as I was on this really good career path, I was on the path to being a senior engineering manager, or who knows, one day I might have had a shot of being their director of engineering as well, I decided to leave Uber. And we'll talk about it a little later in the podcast, but I didn't plan like this, but I started writing a newsletter. And now here I am writing a newsletter where a bunch of people are reading it, and it's a really unexpected turn and a really cool life as well.

Lenny (00:07:19):
Awesome. On the newsletter, just to give people a little bit of context of how big this has gotten, can you share just a couple stats about the growth of the newsletter, the size, and anything else you want to share there?

Gergely Orosz (00:07:30):
Just today I checked and it said 189,000 subscribers. I think the past 90 days has been growing with 80,000 subscribers, so it's almost a thousand people per day, which is incredible. Because these numbers are huge. If you're listening, you're probably thinking, "Wow." And that's how I feel every day as well. But I've been writing a blog for many, many years, and these are numbers I never thought it would be. And the growth just seems to be accelerating. There was a tipping point in April where the newsletter was growing... In the first about nine months of the newsletter, it got to 50,000 subscribers, and then the next five months, or six or seven months, it went up by another a hundred and something thousand subscribers. This was when Substack introduced recommendations, which has been a massive growth engine, and I guess being one of the top publications, I benefited from it. But those numbers are again...

Gergely Orosz (00:08:26):
So this is a paid newsletter as well. So there's a free version and a paid version, and there's thousands of people paying for the newsletter. It's a single digit percentage, but it's a very, very healthy one. And again, it just beat all my expectations. And I guess we're in similar boats, because our newsletter setup, yours and mine, is somewhat similar. We have plenty of differences as well, but I make most of my revenue from subscriptions, and I don't do sponsorships or ads in the newsletter. So if people sign up for the free one, they get articles every now and then, and for the paid one, they get it a lot more and in more depth.

Lenny (00:08:59):
Can you give listeners a sense of just the order of magnitude income you make from this, versus your cushy tech job at Uber? You don't have to share numbers or anything like that.

Gergely Orosz (00:09:09):
Yeah. I'll share a little numbers of my cushy tech job at Uber. I was in Europe, and European tech salaries, or I'll say total compensation, will be lower than for example the U.S., but it'll be higher than let's say regions like India or Indonesia. There's regional differences, and this is true for big tech as well. Uber was a good example on this. But in my best year at Uber, I made about 320 or $330,000 in total compensation. This was after Uber went public, so it includes the stock, the base salary, the bonus, which was very, very good in Europe. And when I quit my job, I was actually thinking, "Am I crazy? Because I'm leaving..." Especially in Europe, this is a lot of money [inaudible 00:09:53] this will be similar to something... Someone in a similar position would've made five or 600 K in total in the U.S.

Gergely Orosz (00:10:00):
So I walked away from that, and I was pretty sure that I'll just [inaudible 00:10:04] a lot less, but I'll enjoy what I'm doing, or I'll have... I'll just give it a go. But now I am making more in compensation that I made at Uber. And the difference is that now my compensation, my earnings, keep going up as long as the newsletter is growing, so there's no theoretical cap on this. Of course there is an actual cap, there's churn, growth is slowing over time, but it's very, very strange, because I felt that I was in a really privileged position, just honestly making tons of money, doing a job that I loved. And this was at Uber or as a software engineer. And I'm now doing stuff that I love, and in some strange way, I guess it even pays better. Part of it is just luck, part of this is situational. I think we're going to talk a bit more about this. But this was very, very surprising and very unexpected for me.

Lenny (00:10:55):
Awesome. That's a great segue to the first thing I want to talk about, but just to frame what I want to spend our time on today, there's these four areas I want to explore. One is your decision to leave and start this life of writing, which is a very non-traditional life. Two is what the life of a paid newsletter person is like. What do you do all day? How do you find time to do this? How do you produce so much content? Three, what it takes to be successful at this. A lot of people... I always say it's easy to start a newsletter, hard to keep it going, and I'm curious what you find is important to be successful. And then four, how do you get started if you want to start your own newsletter?

Lenny (00:11:30):
But before I get into that, I just wanted to add a thought that I had. The way I think about this life in terms of comparing to the old job is, one, it feels instead of one boss, I have thousands of micro bosses, and one of them can fire me and many do every day, but it feels safer than at a tech job where one person can decide. And then the other piece is, assuming it keeps growing, you're getting a raise almost every day, every week, depending on the growth rate, and that's cool.

Gergely Orosz (00:11:57):
That is really cool. I had a spreadsheet that I maintained for the first year of the publication, where I listed, for every article, how much did my annual revenue go up a week later. So tracking what was the impact. And the crazy thing was that, when I wrote a really good article that resonated with people, sometimes it was an article that I thought was mediocre and people still loved it [inaudible 00:12:20] it was a really good article that I put tons of work in, I saw myself getting a raise. And this is just something you just don't get in corporate. I mean, it's by design, and there's a lot of good stuff about it, but I feel that this life, and we'll touch more on this, but there's a lot of surprising things, both good and bad, but this is a really good one. So for doing something awesome, you can just give yourself a raise, especially because this is just like you, mine is also a one person business right now.

Lenny (00:12:49):
Yeah. Okay. So you're at Uber, you're making hundreds of thousands of dollars writing code, it's pretty sweet. Uber's growing. You probably got all these RSUs that are going to keep accumulating. It's pretty good. And you decide, "I'm going to try to make money on the internet writing," which is an obvious way to make a lot of money. Not. And so I'm curious, what got you to leave that job and explore writing and get to this writing path?

Gergely Orosz (00:13:20):
The short of it is, it was a promise to myself, and COVID, and Uber doing layoffs. And the longer version is that, when I joined Uber, before Uber I was... Now we're talking numbers on my old job, but I was working in London as a principal engineer at Skyscanner. Skyscanner was a unicorn, one of the few unicorns in the UK, UK headquartered and all that, and I was making like 90-something thousand pounds in base salary, which is maybe a 120, 130, or $140,000, depends on how the pound is doing, or sometimes these days it's almost just the same. But back then that was a really good... And this was most of it. I got some stock as well. And I thought I was close to the top of the market in London. I knew people, and it seemed this was a really good compensation package.

Gergely Orosz (00:14:05):
And then Uber called me up saying, "Do you want to interview?" I interviewed with them, they gave me an offer, and I negotiated, and they basically doubled my compensation. I was like, wow, this is [inaudible 00:14:16] I knew about Silicon Valley compensation, but I assumed that [inaudible 00:14:20] you're not going to get this, but Uber was getting something closer to that. So I told myself, all right, so I'm getting a really good deal, and most of it is stock, which is... Uber [inaudible 00:14:32] 2016, no-one knew if Uber will go public, although I suspected, because they contacted me to build a payments team so do a SOX compliant payment system. And you need a SOX compliant payment system if you want to go IPO.

Lenny (00:14:44):
That's funny. It reminds me at Airbnb, there's all these people trying to figure out, when are we going to go public? And then there's the team working on SOX stuff and Sarbanes-Oxley, this is good.

Gergely Orosz (00:14:55):
Yeah. So anyway, I said, all right, this is a massive lottery ticket. If it goes in, every year I make two years of salary, pretty much. That's how I was thinking. But if not, again, don't forget I'm in Europe where we're used to not seeing any returns on stock. So European software engineers will not value stock as much, because they just haven't seen success stories. So I told myself, if four years later Uber exits and I make a bunch of money, I owe it to myself to take a risk, because then I'll have four years of savings in my bank, which... Back then I had maybe six months of savings or something. So this was the promise to myself.

Gergely Orosz (00:15:32):
And then I probably would've forgotten about this, but four years later, almost on the dot, COVID starts, and it really hit super hard. We're laying off people, we had to lay off 20% of the engineers. I was already managing a group of about 30 people, I had managers under me, and 20% of the people or 15% had to be let go. And I was thinking to myself, what am I doing here? I looked ahead, Uber was going to have a really bad year, I'm going to have to manage morale. Up to then, I'd helped put together this team, and we had a really good charter, and we had to throw that charter out the window, because it made no sense with the economic reality. So I thought back, and I told myself, if I'll be here, I'll take a risk, and I'll try to do something else. So I was like, all right, let me pull this trigger.

Gergely Orosz (00:16:18):
And my plan was very simple. Leave Uber and start a startup, raise venture capital, because I haven't done that before but it kind of runs in the family. My brother's on his second startup, and he sold his first one to Skyscanner, and now he's building this startup called Craft Docs. It's a really slick document editing system, they just raised their series B. So through him I know [inaudible 00:16:42] startup life is, and I felt I never did that, I always worked at big companies.

Gergely Orosz (00:16:45):
So my plan was [inaudible 00:16:47] leave Uber, raise money, and do something on platform engineering. A classic way that Uber alumni start businesses is, Uber has invested silly amounts of money to build everything custom internally. Everything that you can think of. Our [inaudible 00:17:02] system was custom, our experimentation system, our container, the way we automatically set that up, a lot of the engineering stuff. So a lot of Uber alumni just leave, and whatever they saw there, they just build it for the world to use, because no other company really does what Uber does, because it makes no sense, but a lot of them will pay for.

Gergely Orosz (00:17:20):
That was the plan. But before [inaudible 00:17:22] I wanted to finish a book. I'd been writing this book for, it was coming up to a year, called the Software Engineer's Guidebook, which is just my advice for people to grow professionally in the field. And I figured, all right, let me leave the company, in six months I'll write the book, I'll just use my savings to take a break, and then I'll raise the venture capital. And what happened was, I started to write this book, but I got sidetracked, I started to have fun online in terms of... I was writing on Twitter, on my blog. I accidentally published a book called Building Mobile Apps at Scale. I just did it for a few months.

Gergely Orosz (00:17:58):
And the weird thing was that my plan was that I'm going to just not make any money, and this book, Building Mobile Apps at Scale, and another book that I published about tech resumes, I just wrote these in a few months, they started making money. They made about $100,000 in the first year. And I was like, "That's interesting. People are buying my books." And I self-published it through Gumroad or places where I get to keep I think 90% of the revenue, but still, this was really interesting. And I got to the point where, all right, I should now start a startup. I should do fundraising and do all that. And then I asked myself, why do I really want to do that?

Gergely Orosz (00:18:34):
And the answer was two reasons. One is, I love working in small teams at Uber. I'll be honest, I didn't really enjoy being a manager of managers. It felt a bit too abstract. I didn't like being in the meetings, not doing the work. What I really liked is when we had a small team, and we had this really big vision, and it was us against the world. We were like ten of us, and we were just getting stuff done, we were putting out fires, it was so much fun. So that was one of the reasons I wanted to do startup. I was hoping to recreate this feeling.

Gergely Orosz (00:19:05):
And the other thing, honestly, was money. This was in 2021 before the market crashed. Just doing the maths, if you found a company, and I'll be a CEO and the founder, maybe I'll have a co-founder, this becomes a unicorn, by that time we will have raised five rounds of funding or six, I'll be diluted as hell, but I'll still have let's say 5%. 5% of the billion is still $50 million, after you pay taxes [inaudible 00:19:30] I can buy a bunch of stuff that I don't need. And I was asking myself, all right, and then what? And I was like, after I've bought everything that I don't need, I probably want to share what I know with people, do YouTube videos and write books.

Gergely Orosz (00:19:43):
And I was thinking to myself, so hold on. I would go off and do this for like ten years, because that's how much you need to plan to do it. I need to stop doing what I'm doing right now, because I would owe it to my investors and my team to not spend all day on the internet writing about stuff. And then I want to do it again. So it's reminding me of the story of this fisherman. There's one that goes [inaudible 00:20:08] there's the same thing of, you work really hard to do what you're doing right now. So I decided, let me just try giving this a go. [inaudible 00:20:14]

Lenny (00:20:14):
Wait, what's the story of the fisherman? I think I know what you're talking about, but... [inaudible 00:20:18]

Gergely Orosz (00:20:17):
The story of the fisherman is that, in Mexico, an American businessman sees a fisherman who's just chilling, fishing. And he asks him, "What are you doing all day?" He's like, "I fish for three hours, I hang out with my family, I [inaudible 00:20:32] chill and I sleep in every Saturday and Sunday." He says, "All right, here's what you should be doing. You should fish not three hours, but you should fish five days a week, eight hours a day, sell that fish, turn over a profit, hire more people to do it, then start to be head of all those people, then sell your fishing company." He's like, "Okay. And then what?" "And then you can actually buy an island, and you can just fish for three hours, you can sleep in on Saturdays and sleep on Sundays."

Gergely Orosz (00:21:00):
So I was thinking, look, I have savings. I don't have huge, but I have it for... I can still take a risk. So let me take a risk on writing. And I was thinking originally of just spending more time to finish my book. But what I didn't like about books, even though I was making money, is they're really... It's hard to predict if you're going to be making a living, or there's some people who actually like this excitement, but I didn't like it. I didn't know if today I'm going to be making like 50 bucks or 10 bucks or 300 bucks. So I was like, interesting. There's these paid newsletters which I've been thinking about, and you were one of the few people who shared some of your early numbers, and I figured this could be interesting, because it's recurring revenue.

Gergely Orosz (00:21:41):
And the only reason I was really hesitant to start a paid newsletter, I was thinking about doing so for at least 6 to 12 months, is I was worried about writing every single week something really, really worthwhile reading, and it's a lot of work. But then I looked back and I saw that I wrote three books. [inaudible 00:21:58] I told you I wrote two books, but there was a third one that I also published in a year, and I was like, I'm pretty sure I can write. So for two weeks I collected ideas of what I would write about, and I had this super long list. So I was like, okay, ideas also check.

Gergely Orosz (00:22:10):
And then I just said, screw it, I'm going to take a risk. It's a bit of a more professional risk, and maybe a financial one as well. I'll announce that I'm going to start a paid newsletter. Every week, I'm going to write something really in depth about software engineering. It's going to start next week. And I told myself that I'll... I told my wife as well that I'll do this for six months, and I'll see what happens. If there's traction, it's great. I might have found myself a new job, basically. If not, I'll just refund people. Everyone who bought an annual subscription... I didn't tell this to people, obviously, but for six months I'm going to give it my all. It's basically like a startup. So I told her and my family that it's going to be a lot of work and I might not be around as much, and they supported me, and I took a plunge. I took a big breath and started off. And that's how it went from leaving Uber to starting a venture funded startup to starting to write full time.

Lenny (00:23:05):
Awesome. And we're going to talk about what advice you have for folks that are thinking about starting something like this at the end. What was the period between leaving Uber and starting the newsletter?

Gergely Orosz (00:23:14):
It was pretty much a year, a little bit less than a year. Might have been like ten months or so, but it was a year from when I decided to leave Uber. So Uber did layoffs in April, and it was really stressful. It was the first time I... I didn't lay anyone off, but people on my team were laid off. I wasn't told who's going to be laid off. It was just really stressful. It's weird, in the sense that the people who were let go, obviously worse for them, but I still felt terrible, and I just didn't feel very good about it. I think this was the breaking point. This was the point where I realized that it's not a family, which is weird because it never was, but it kind of felt family-like, but it's just a corporate, and I'm just a number, and this could happen to me, I guess. So I think I lost my sense of the trust in the system, that it'll take care of me, because I saw some of my colleagues who were really good professionals, I'd argue they were better software engineers and managers than me, they got let go because they were in the wrong team.

Gergely Orosz (00:24:08):
So this was April, and in July I went to a holiday, and two weeks in, I just realized I need to leave. And I really had the urge to do somewhere where I'm in charge. And if you're a manager listening to this, you might relate to this. If you're an engineer listening to this, maybe just shut your ears or you'll figure it out eventually. But when I was promoted into management... It wasn't promoting into it, because it was a side step, I didn't get [inaudible 00:24:34] or anything, but it still feels a promotion. They only promote the people who are... Only let people transition who are considered pretty good. I felt this would be a big deal. I'm now a manager. What no one told me is, yes I was a manager, but I was a middle manager. I didn't have too much authority. I didn't even have budget for my team. Someone was underpaid and I couldn't do anything except complain for HR for six months and hope that they'd do something.

Gergely Orosz (00:24:58):
So it was pretty frustrating, because I didn't feel in charge in the sense that I didn't have decision making [inaudible 00:25:02]. And the reason I wanted to do a startup is, I decided I liked being a manager, but I did not how I was not in charge and I couldn't take corporate [inaudible 00:25:12] telling us to do stuff, and then we were telling them no [inaudible 00:25:16] I don't want to do that with my people. So I decided for next job, I could be doing this, but instead I'd like to be in charge. So I'd like to be a founder or someone who's high up, so that I can actually take full responsibility for the things that I want to do or I don't want to do. The short of it is, I decided to leave in July. We have longer notice periods in Europe, so I served a longer notice period, and then left. But it was a year after the decision.

Lenny (00:25:41):
Let's talk about what your life is like these days, writing a newsletter full time. People might be listening and be like, "Man, $300,000 for writing an email a couple times a week, that's pretty sweet." So I want to talk about the good and the bad of this life. So maybe to start, how many posts are you putting out a week?

Gergely Orosz (00:25:59):
I started the newsletter saying I'm going to post once a week. You'll have one pinned up post. And I started to do that, but interesting enough, eventually I upped it to two, so I now promise people two posts a week. There's more in depth and more timeless posts about some software engineering topic on Tuesdays, and there's something that's called the scoop, something a bit more timely, where I reflect or analyze what's going on in the market, interesting stuff I'm hearing. And every now and then there's a bonus post. So I'll say two on average, but the second one came a lot later. But initially in the first few months I was like, I have this one post per week, and it needs to be good.

Gergely Orosz (00:26:37):
And it was interesting, because you would think writing a post a week is not a big deal. It's easy. As you said, let's say you're making 300K just writing one post a week. But it actually was pretty stressful in the beginning, because it turns out to write that post, it takes at least a few days or sometimes even longer. Sometimes it takes a week or two for me to research in terms of talking with people. I chose topics that are not covered, because why would people pay for something that is out there already or well known? Then I need to write [inaudible 00:27:10] a first draft. I get some feedback from people who I trust often, not always, but I often do. And then there's an editing phase where I work with an editor who helps make sure that it's just correct. And all these things add up. Even if I only spend a day researching the stuff, it's a day researching, then I have a draft on day two. Day three I get feedback, on day four it's editing, it's almost a whole week.

Gergely Orosz (00:27:32):
So I was working on parallel things at the same time, and I was often running against the deadline, I was barely finishing it, which is not what I was expecting initially. The first few months I feel was a bit more stressed, but again, the good thing is I cleared my calendar, so I said I'm not talking with anyone, I'm just doing this. So in that sense it was good. But the one thing I realized, if you look at any journalists who's doing stuff full time, and they're writing, not these clickbait articles, but actually in depth. You look at the Washington Post or New York Times, search for their name, and look up the articles that they write, and they're going to be longer articles. They have like one a month. Seriously. You look at the investigative journalist, they might even have less. And they have a bit of a different level, they have to check with legal and all those things, but my editor is a journalist, so he was actually telling me, even back then, "You actually write a lot of original stuff," because a lot of my emails are about five, 6,000 words, which is considered very long.

Lenny (00:28:32):
Yeah. When you said that people listening might be like, one post a week is easy, I think most people are the opposite. They're just like, I can't write anything. I don't have time for any writing. How can you ever write one good thing a week? So I think there's both sides to it. And it's cool that you shared the process. Do you have a specific cadence per post? It's like Monday draft, Tuesday review, Wednesday editor. Is that how you work?

Gergely Orosz (00:28:58):
I write every post over multiple weeks, most of them. Some of them I might be able to write faster, but what I now have is, nowadays I actually write two articles. So I have the Thursday that is the scoop, which actually is a lot easier for me to write, interestingly enough. And my cadence is, on Monday I finish up the last of the post that goes out on Tuesday. It's just small edits, but it's already done pretty much, so it's just a few small tweaks, and maybe I have some feedback coming in. On Tuesday, I publish this post, and I do some free writing. I write about some other ideas that I have that's going to be future posts. On Wednesday, it's my free day in between, where I... It's interesting, because what I feel is, when I don't have pressure, I tend to not do much stuff, which might just... My mind's saying, "You just need to chill." Maybe that's it.

Gergely Orosz (00:29:49):
But one thing I miss from the corporate world... And if you're listening and you're in a job and you're thinking, "Gergely's job is so amazing," one thing that I liked and I really miss about working at Uber is, I actually had a schedule. This is weird, I hated it back then, but I needed to do these things, and whenever you have a pressure, you do it. And this works with my newsletter. I put in the second newsletter I think to have a bit more pressure. Because the second part of Wednesday, I'm already starting to write my Thursday newsletter. On Thursday, I write that Thursday newsletter, and on Friday I'm now writing the next newsletter for Tuesday. So almost every day except for Wednesday, I have a strong pressure to write. Which when people ask, "Gergely, how do you write so much?" Because I did the maths, and I wrote four or five books' worth of content just last year. It's because I have these deadlines, and as you said, I also know that thousands of people are paying me, they have expectations of me.

Gergely Orosz (00:30:46):
And so this is how it's done. If you want to write a book, the easiest way is go to a publisher and sign a contract, not because of the money. In software engineering, you're not going to get much [inaudible 00:30:57] $5,000 or something like that. That's what I was offered initially. But it's the pressure. You absolutely should go to a publisher or have some external... Someone to hold you accountable, and then you'll get it done. And I'll let you in on another secret, or not so secret.

Lenny (00:31:16):
Do tell.

Gergely Orosz (00:31:16):
In my mind, when I started newsletter a year ago in this crossroads, I want to write this book, which I think will be a great book, the Software Engineer's Guidebook, I feel it'll be my summary of my last ten years of what I have to share as advice, but I was worried that it's just a big project that's just going to take months, and I'll lose motivation midway.

Gergely Orosz (00:31:37):
And partially, I went down the newsletter route because I liked how every week I would have to write something, and I had this sneaky idea of, what if I wrote this book where I write some posts that will be part of the book, and then the book will just come together partially. And I've kind of been doing that. I haven't been telling people, but some of the posts are going to be... Not exactly, but the idea is that I have this chapter, and I have this list, have I written about this topic in the newsletter? And you know where I got this idea from? There's the book The Three Musketeers, from Alexander Dumas [inaudible 00:32:12]. And do you know how it was written?

Lenny (00:32:15):
I don't.

Gergely Orosz (00:32:16):
So he wrote the book for a magazine. He was apparently just low on money, and he started to write for this magazine who told them, "All right, we need you to write something that our readers will want, so that they will buy the magazine." I think he was getting a cut of some sales or something. So he needs to write in a way that was interesting, and then cut it off in a way that people would come back and buy the next one. And he wrote a whole book, and that book, when I read it, it's really long, and I was like, hold on, if he could do this, then this is a good strategy. He was writing it because he just needed the money. That's all. And then he wrote a really good book on the way.

Gergely Orosz (00:32:52):
So one big learning for me from newsletters then... I would argue that you can use this not just for newsletters, but any business that you do. If you're going to go out and start a new business, you'll probably have some ideas. And it's not just going to be a newsletter, it's going to be a bunch of other things. If you put in ways that you have to do certain things, put in constraints for the things that you need to do, and then you're going to do that.

Gergely Orosz (00:33:16):
Without that, when you're on your own, when you're entrepreneur, I was a great... I think I was a really diligent employee. I always tried to get my work done, show up on time, I tried to meet all expectations. But what I noticed is, when I started to work for myself, it just went out the window. Almost 15 years of being this star employee who really wants to do well, I found myself upset at myself for not... Just wasting my day. But I fixed it by telling people, "You're going to get this every week," and now I have to do it. I just have no choice.

Lenny (00:33:51):
This episode is brought to you by Vanta, helping you streamline your security compliance to accelerate growth. If your business stores any data in the cloud, then you've likely been asked or you're going to be asked about your SOC 2 compliance. SOC 2 is a way to prove your company's taking proper security measures to protect customer data, and builds trust with customers and partners, especially those with serious security requirements. Also, if you want to sell to the enterprise, proving security is essential. SOC 2 can either open the door for bigger and better deals, or it can put your business on hold. If you don't have a SOC 2, there's a good chance you won't even get a seat at the table. Beginning a SOC 2 report can be a huge burden, especially for startups. It's time consuming, tedious, and expensive.

Lenny (00:34:37):
Enter Vanta. Over 3,000 fast growing companies use Vanta to automate up to 90% of the work involved with SOC 2. Vanta can get you ready for security audits in weeks instead of months, less than a third of the time that it usually takes. For a limited time, Lenny's Podcast listeners get $1,000 off Vanta. Just go to vanta.com/lenny, that's V-A-N-T-A.com/lenny, to learn more and to claim your discount. Get started today.

Lenny (00:35:08):
I definitely wanted to dig into that a little bit deeper, this issue that folks in our line of work run into, which is unstructured time and having to create your own structure. I had the same exact problem when I started this thing, before I even started the newsletter. How do I use my time well? How do I create some kind of deadline for myself? So I'm curious what other tricks you found to help you stay productive and focus, because there's Twitter, there's Instagram, TikTok, there's all these things that pull my attention. And I've learned a couple things I'll share that have been helpful, but I'm curious, what have you found to help you focus and get things out the door? Two posts a week, which is a lot of work.

Gergely Orosz (00:35:49):
So a problem that I have, and this might be unique to newsletters, I'm not sure. I use Twitter for a lot of research. And unfortunately what that means is when I start to write something, it can really pull my attention, because I have Twitter open and then I get a message from someone. It's a little bit like Slack, but I'd argue it can be worse, because also Twitter for me is also something that is very useful in generating people [inaudible 00:36:16] raising awareness. So whenever I tweet, it helps my business. So that's a good thing. But it also justifies for me spending more time on, for example, Twitter than I would want to. So I find that I come up with a method, and it works for a few months, and then I need to change it because my brain just learns to work around it. So I'll tell you a few things that I did, and I'll tell you where I'm at right now, but I use for example apps. I use this app Centered, but I know you're also there.

Lenny (00:36:45):
Yeah. I love that app. Also an investor [inaudible 00:36:49] disclaimer, but I love it.

Gergely Orosz (00:36:51):
Yeah. And I found that helpful, the idea of focused time and [inaudible 00:36:56] turned on, but it might just be me, but after a while I get used to these things, and I find it not as efficient. I found the Pomodoro method for a few months useful, when you have the 25 minute intervals. And the one thing that has never failed me, but I just find it hard to do, is I find it hard to start. I have this benefit that I have all this time... Sorry, there's two things that always work. One is, it's almost time for me to go home, and then I'm super focused. So when I have this external thing, and I know that there's no way [inaudible 00:37:30] I need to focus on basically the deadline. So if you have deadlines, that works.

Gergely Orosz (00:37:36):
The other thing is, if I start to spend three or four minutes doing something focused, and I get the flow of it. So a trick I sometimes do when I'm just, I just don't feel doing anything, is I set a timer of 20 minutes, and then I say, "All right, no distractions." I have a script where I just kill... I use a [inaudible 00:37:57] host file, I just kill all LinkedIn, Twitter, Facebook, whatever sites. So I just cannot reach it. It's just a very simple Python script that I wrote for myself. And then in the first few minutes I'm grumbling, I'm like, "I wish I could do this, I wish I could just look at Twitter to research," but about five minutes in, there's a switch, and I'm now actually heads down and doing it. And this has been the thing that has consistently worked.

Gergely Orosz (00:38:21):
The interesting thing is that I feel guilty a lot of times that I'm not working as hard as I could. And I do wonder if it's guilt, or if it's my mind or body telling me that it just wants a break or it wants to do something else. I still haven't figured it out, but I'm on the way there.

Lenny (00:38:39):
Awesome. That's a really cool trick, the host file trick. So that's [inaudible 00:38:43] something that you have to be technical to do. I imagine there's some chrome extensions that could do that to some extent for folks. But the whole idea there is, force your brain not to have any way to look at something that'll be distracting, by blocking your computer from even being able to go to the site. That's awesome.

Gergely Orosz (00:38:59):
Yeah. So there is definitely going to be extensions that you can use, and on this podcast we'll have a variety of people. If you're a software engineer, it's pretty simple, and even if you're not, you can look it up [inaudible 00:39:10] when you override your host file, you can actually block [inaudible 00:39:13] what you do. And I did this because I wrote a script where I need to run the script, and I need to run the script again to unblock it. And it's kind of cool, because I put it together for myself. So I usually find that the tools that other people use, maybe this is just me or maybe this is software engineers, I don't like them because I feel they're either too opinionated or they're not opinionated enough. So I don't know if this is just the fact that I used to like to build my own tools and my own scripts, because I can, so I found that my scripts worked the best for me.

Gergely Orosz (00:39:44):
But as you said, there's a bunch of really good tools. So my advice to people would be, look up all [inaudible 00:39:50] let's try them out. You won't know until you try them. And again, I had stuff that worked really well for a certain amount of time. I don't know why, maybe I just get bored easily or something, that I just need to rotate. But for example, when I went back to Centered... I have no affiliation by the way, so I'm just telling this. But I really liked how they keep evolving as well to do cooler things. They have a community element where you're competing with people on uninterrupted time and closing stuff. So that to me is a... I'll do one last [inaudible 00:40:23] Centered again. I have no affiliation. What I really liked about Centered is, it allows you to turn on your video camera, and I felt really forced to do work, because I knew that people on the other side of the world might be watching me, even if it was not true.

Lenny (00:40:37):
Yeah. I love that feature. It's centered.app, by the way, if folks want to check it out. So to summarize some of your tips, which I love, Centered, deadlines, totally work for me too. Blocking sites so that you can't get distracted by Twitter and LinkedIn and TikTok and all the things. And I guess that's the three that work best for you.

Gergely Orosz (00:40:55):
Yeah. And the simple thing, start a 20 minute timer, and you say, "For 20 minutes, I need to focus on this thing," on your iPhone or somewhere else. It's just 20 minutes, but during that time you cannot do anything else. And just try it. It works for me, like a charm, once I decide to actually do it.

Lenny (00:41:13):
It's cool Centered does that for you, and it has music and all the things. So I that a lot. Awesome. What do you love most about this life that you lead now, versus what you used to do? And then I'm going to ask you the opposite, but let's start there.

Gergely Orosz (00:41:27):
I really like that it forces me to have my calendar empty, because for so many years my calendar was this giant mess of meetings on top of meetings, and I would barely have any time to actually have focus time. Now I actually have the opposite. I usually have a lot of focus time, and I have very, very few meetings or things. And even now I get a little bit cagey [inaudible 00:41:51] I have this one meeting in the whole day. So I like how it's [inaudible 00:41:55] manage your time [inaudible 00:41:58] so that's the best part.

Gergely Orosz (00:41:59):
And I also like how much in charge I am. Initially it freaked me out, in the sense of how much creative freedom I have. I can write about whatever. I can change a format, I can do this, I can do that. It can be a little bit overwhelming, because I also know that people are going to be reading this, and what are they going to think about it? But I do like that it's very entrepreneurial, so I get to experiment a lot as well, which reminds me a little bit of my old job, because at Uber we also experimented a lot, and obviously more in a corporate setting. But I guess that's just gotten extended. So these are the two favorite things, is the open calendar or very few meetings, and experimenting, trying out stuff and being able to decide what I want to try out.

Lenny (00:42:46):
Plus one on both those. I have a rule of no meetings before 3:00 PM, and it generally works 99% of the time. And the reason I do that is, to your point, if there's a meeting at 11:00, I just can't do anything really deep until that point, and then afterwards I have to get back on track. And having that deep focus time is so important for this work, even though half the time I'm on Twitter and distracted, as long as I get enough time to focus, good things happen. Okay. Opposite. What are some of the most surprising downsides and sucky parts of this path that you've taken?

Gergely Orosz (00:43:24):
One is obviously it's lonely. I do miss... I had a really good team at Uber, and it wasn't just a team, it was the people. I liked... Everyone has different views on remote work. I actually didn't enjoy remote work as much, because I just liked hanging out with people. I guess I'm that more outgoing type, and I really like walking up to the coffee station and having a chat with people, or at lunch sitting next to someone and talking about it. And obviously in some sense it was annoying, because I wanted to get work done, but for the most part I miss it more than I have. And so I miss not having that. I compensate for that by working in a shared workspace, a shared office, which is a techy workspace. So everyone needs to work in tech. So I actually get to say hi to people and have a little small talk.

Gergely Orosz (00:44:08):
The structure is weird, because I felt really guilty for the first few months, because I felt that at Uber I was more productive, because I had to be. I was doing so many things. In a day, I would start my day let's say at 9:00 or at 8:30, and I'd finish it up at, I don't know, 6:00 or 5:30, it depends. I would probably have, on an average day, I would have a good eight meetings, I would finish two or three documents, I would send over this, send over that. I actually have... Looking at my output, now I write a lot, but I wrote a lot. I think I wrote almost as much in terms of emails, chat messages, et cetera. So the downside is, I felt very guilty and a little bit frustrated for myself, for feeling that I'm slacking off. That's one.

Gergely Orosz (00:44:55):
And the other thing, it is surprisingly stressful. So when you start off, it's kind of lonely. Not many people do this, what we do. That's also one of the reasons that we connected, because it's a very small community. And even within the community, I feel, in the newsletter community, it's different. You're all running your own business, and there is some level of competition. So you might not... Because it's a little bit of attention economy as well. People are not going to subscribe or pay for ten newsletters on the same topic, so that makes it a little bit more... It's not the same as when you work in tech, and you just share exactly everything that you do, because you can only win.

Gergely Orosz (00:45:35):
So there's that part, but there's a lot of external validation, so whenever looking at your subscriber numbers, which brings a bunch of stress that I didn't expect. And I'm a successful newsletter [inaudible 00:45:47] I think my success is quite rare. There will be one or two or a handful of people who have similar success, but I'm an outlier. So that's another thing that I think is just good [inaudible 00:45:58] putting out there. And the downside is, you don't really know how well you're doing. External goals are kind of meaningless. Internal goals, either you smash them or you don't reach them. So there's this constant sense of, where am I? How am I, and how do I judge myself? Did I make a mistake for leaving my job? I actually asked myself for several months actually, after I started. Or did I make a good one? And I think for a lot of these questions and doubts, having past professional experience working at a company is really useful to set yourself grounded.

Lenny (00:46:33):
I actually want to ask you about that, but I'll add a couple things that I also find are major downsides of this life, because it's not all rainbows and butterflies. One is, with a paid newsletter especially, but even with a sponsored newsletter, you basically have to get something awesome out every week, in theory for the rest of your life. People are buying an annual plan every day, so that means at least a year you have to write something awesome, if you want to stop. But it's hard to stop, because as you pointed out, the income is very meaningful, and that's a hard thing to give up. And so I'm not sure exactly the exit path that exists for us, where we might have to keep writing something awesome for the rest of our life, but I imagine something will emerge and we'll think of something else that we could do.

Gergely Orosz (00:47:19):
Yeah. And it's a really good example, because for a lot of companies, and I assume a lot of listeners are working in tech, typical thing is you work hard, you build equity at a company or you build the value of the company, and then you can sell that company, and then you can have an exit and you can do whatever. For what we're doing, it's really tied to us. So however much or little my newsletter will make, it'll have a value let's say four or five times the annual revenue as a business, but you cannot really sell it like that and you cannot really walk away.

Gergely Orosz (00:47:49):
So that makes it unique, it makes it harder to compete with, which is cool, but it does not create that much of an exit path unless you start to build a company around it, build an organization that can run without you, for example. This is what a lot of book publishing companies... So basically you build a publishing company where you start to hire people, who start to write some of the articles initially, and then later more of them, but it's not a one-person newsletter any more. Or you keep doing this, until you either stop and then the revenue stops, or you might be able to sell it, but at really under value.

Lenny (00:48:24):
Yeah. I really don't want to manage people. I don't want to have employees. And so building a media company with writers, that doesn't sound too fun, but maybe that's where this goes. That is one route, for sure. The other downside I'll just add is the fact that you have to write something awesome every week, it's hard to take meaningful time off, because if you stop producing great stuff, people leave. And I invented this PTO policy for myself where I take four weeks a year off, where I don't do a newsletter, but that means I can't take more than a week off usually [inaudible 00:48:58] weeks in a row, I don't know, people probably won't care, but it feels like things start to not go great if I just don't keep producing great stuff. So that's another downside, just [inaudible 00:49:08] topic.

Gergely Orosz (00:49:09):
Yeah. But a lot [inaudible 00:49:11] very early. So I think the whole concept of paying users is new, so I think we're going to do a lot of experimentation. And also a lot of it, I think you need to figure out what your needs are. So in the first year, I did not take a holiday in terms of... Or even when I [inaudible 00:49:25] I was writing, and it caused a bit of friction with my family. And now I'm solving it in a different way, so I am planning to take more time off now, and I'm doing it by working ahead with some of the less time sensitive things. But it is tough.

Gergely Orosz (00:49:43):
So a downside we haven't mentioned, but I'm just going to call it out, is holiday. The great thing at... I never felt... Well, I felt a little guilty sometimes taking holiday, but when I want a holiday, I took it off. When I had my son born, at Uber, they gave me a four month paid holiday. I took the whole four months, I just logged off. It was great. It wasn't my company. I was still getting stock. The stock price was independent of mostly what I was doing, just being honest. And that was really, really good. So this might be true, by the way, if you start any business, especially while it's just yourself, it's hard to turn off. And I think most people don't mind, I don't mind, but it gets to you. We should be conscious about burnout as a whole. So you need to solve for that, and I'm starting to solve for that as well.

Lenny (00:50:30):
Yeah. Okay. Enough about the downsides. Overall, it's pretty amazing making hundreds of thousands of dollars writing an email once a week/twice a week. So just to wrap up on that, I'm curious, where do you think this goes long term for you? And then I want to talk about just what it takes to be successful, but before there, do you think this goes long term?

Gergely Orosz (00:50:50):
I stopped making long term plans, because three years ago you would've asked me what I wanted to do, and I was like, "I want to be, I don't know, a manager of managers." And then I became one. And then [inaudible 00:51:01] what is my dream? I would've been like, "It's a stretch, but maybe I want to be a site lead." And I didn't become one per se, but I never thought of writing a newsletter, or now writing a successful newsletter. So I'm going with the flow. I'm seeing this less, by the way, as a newsletter or creator, or creator economy as people like to see it. I see this as a business, and I'm trying to put on that business hat. I'm building a one-person business. I want to make it sustainable, I want to make it successful, and I find that this thinking really helps me detach as well. I can actually enjoy my weekends as opposed to thinking, "I need to write this, or I need to write that." So I also want to make it work for me.

Gergely Orosz (00:51:40):
And I'm not married to the idea of, it always needs to be a newsletter, et cetera. Right now it is, but where I see us going is, I'll keep building the business, I'll keep playing to my strength, which is I love talking with people, I love writing [inaudible 00:51:56] I love software engineering. So this is a great format, but over time it might shift. So I'm keeping my options open. And what I've learned from this journey is, you need to create time for that spark to come. So one of my goals for next few years is to not spend 50 hours a week on a newsletter, which I'm doing right now, but spend 20, and then maybe take a few weeks off and have that spark come. Because the reality is, this newsletter only came because I gave myself six months of unpaid... I'm not going for work, I didn't ask for any LinkedIn emails. And the idea came and the inspiration came and the motivation came.

Lenny (00:52:36):
There's a lot of similarities with my approach. I don't think too far long term. I have no idea what's going to happen. I just take it to... I see where pull is coming from, and if it feels like an interesting opportunity and something that I'd be excited to work on, I explore it, like the podcast for example. And on that point, I will say, once you find that you can spend maybe 20 hours on a newsletter, I guarantee you'll find more work to fill that gap, because that's what I've been doing.

Gergely Orosz (00:53:00):
Yeah. And one last thing to touch on, you said something really important [inaudible 00:53:06] pull, and I want to double down on that. One of the biggest, best things about doing what we do when you're in charge of your time is, you can double down on pulls. So [inaudible 00:53:18] Uber, like I said, my plan was, I'll write this book for six months. Two months in, I just put a draft [inaudible 00:53:24] a really long blog post about mobile engineering, and I got a ton of messages, a lot. I usually used to get like three or four messages on Twitter per day. I got 20 in an hour, people saying, "Can I read the draft?" And I was like, that's interesting. I just felt this pull, of this huge interest of people caring about this. It was this really long blog post about mobile engineering at scale, and someone suggested on a private message, "You could probably turn this into a ebook." And I was like, that's a good idea, because it's a really long blog post. So I said, "It's going to be an ebook, and it'll be pay what you want." And then people started to buy it. And I was like, that's interesting.

Gergely Orosz (00:53:57):
So I didn't have much else to do, so I was able to double down. I said, for the next two months, I'm going to write this book, because it seems there's an interest in it. And [inaudible 00:54:07] I turned it into a book that was free for two months, but I got sponsorship. The point was, I was able to double down on this pull. And same thing with the newsletter. So we're going to talk about how I got the first few thousand subscribers, but the point was, I was able to double down on something that I felt like, this is super interesting, I never expected that people would care about building a large mobile app, more than a few hundred people. Turns out they do. Thousands do.

Lenny (00:54:30):
Let's actually jump to that. Let's talk about just how to get started, for folks that are like, "This is cool. I want to do a newsletter." Let's talk about just how you got started briefly, and then what you think it takes to be successful in the life of a newsletter person. So how'd you actually get your first thousand subscribers?

Gergely Orosz (00:54:51):
I'll tell the story that is kind of true, and people will think it's amazing, and also the real deal behind it.

Lenny (00:54:57):
Okay, great.

Gergely Orosz (00:54:58):
I announced my newsletter, I told people, "I'm going to go full time on this." I had maybe 10,000 Twitter followers and, I don't know, maybe 1,000 on LinkedIn or something that. And people started signing up the next day. I had 100 subscribers in the first day before I published anything. And within six weeks, when I published my [inaudible 00:55:15] I had 1,000 paid subscribers. And this sounds like a fairytale. And if you do this, I guarantee you're not going to get the same results. In fact, you'll probably see way smaller numbers.

Gergely Orosz (00:55:25):
What I didn't tell is that there was at least six years of accidental work behind this. I started a blog six years before... Actually, I've always been blogging since I graduated. I had this personal blog where I just published all sorts of random things about software engineering, but it was really... Sometimes it was about an app that I published, sometimes it was a problem that I came across. It was is all over the place. And I got fed up with this, the blog wasn't going anywhere, and I was just writing for myself, by the way, but I didn't how it was just all over the place.

Gergely Orosz (00:55:56):
And I said, "I'm going to start a blog, it'll be about software engineering and I'll call it The Pragmatic Engineer." I bought the domain, and I read this blog post from Jeff Atwood, who's the founder of Stack Overflow, and back in 2010, or I think in 2007 when I was still in college, he had the most popular blog on the internet for software engineers. It was called Coding Horror, and all the software engineers I knew read it and were drinking it. It was next level wisdom every single week, twice [inaudible 00:56:26] a week. You read it as well?

Lenny (00:56:29):
[inaudible 00:56:29] Yeah. I used to be an engineer, and I was all up in that. And I think Coding Horror came from a... I forget the book, but there's a book with that graphic.

Gergely Orosz (00:56:36):
There's a book, and there's a graphic. Yeah. And he wrote a post which really stuck with me for years. He said, how to be famous on the internet. He said, there's three simple steps. One, write a blog post. Two, do this three times a week. Three, do it for two years. And I guarantee, if you do this, you're going to be famous. And I always thought it's kind of ironic, but the more I read it, the more I thought he actually means something with it. And when I started this blog, The Pragmatic Engineer, I said, "I'm tired of my old blog being all over the place, and there's no focus, and no-one really cares about it. I'm going to do what Jeff Atwood said. I'm going to publish... Okay, it's not going to be twice a week, but every two weeks I'm going to publish an article, and I'll do it for a year." So I started to do this. I published six blog posts about software engineering, going into topics that I [inaudible 00:57:25] research and all that, and then I gave up.

Gergely Orosz (00:57:27):
And I'm saying this because I kind of gave up, and I left it for a few months, but then something interesting happened. I had a huge traffic spike, and it crashed my shared hosting at the time. And it came from a site called Hacker News that I [inaudible 00:57:41] heard about, and people were discussing my posts, and they were adding a lot of things. And I was like, that's interesting. People care about what I wrote six months ago.

Lenny (00:57:49):
What was that post, by the way?

Gergely Orosz (00:57:50):
It was called, "A comment is an invitation for refactoring." I wrote my view that if there's a comment in a code, that means that comment should be deleted and you should just refactor the whole thing. And it exploded on Hacker News. Some people called me an idiot, some people called me absolute wisdom, and it was these two crowds battling it out. And I was like, wow, I actually made software engineers in Silicon Valley argue about my stuff. I saw some of the [inaudible 00:58:17] people, some really high [inaudible 00:58:18] people were really going for [inaudible 00:58:21]. So that's when I thought [inaudible 00:58:23] my writings, some people might read it, it's not guaranteed.

Gergely Orosz (00:58:26):
And I started to write on that blog once every few months, depending on my mood, but I never stopped doing it. And I partially did it [inaudible 00:58:35] always hoped that it would get onto this site called Hacker News. But by the way, for a while, I didn't even know you could submit it, so I never submitted my own things. But the other thing was, I just kind of liked it, and I had this habit, and over years... I had this blog from 2015. For six years I was writing that blog, and in the last year... When I worked at Uber, on the side I wrote about my work, in terms of the things that I could write about, not about the details that we did, but some of the learnings [inaudible 00:59:02] for example, distributed systems. And more and more of these posts just started to just pop up on Hacker News. People would either submit it, or sometimes when I submitted it, it would just do well. And I was thinking, so people... I started to get this validation, people care about what I write.

Gergely Orosz (00:59:16):
And to question of the success of the newsletter, by the time I launched a newsletter, I had a lot of posts that a lot of software engineers read, and there was a very famous post about performance management, how to do performance reviews. I wrote one about the tri-modal nature of software engineering salaries, where I observed that there's three different tiers that are... There's big tech and there's local companies. And I think what happened is, when I announced that I'm going to write this newsletter, I also put it on the blog. A lot of people realize that they... "I've been reading this Pragmatic Engineer, I don't know who is behind it, but I like it. Let me sign up. I do want to get an email every week, instead of the things that were every now and then."

Gergely Orosz (00:59:56):
So there was years of work, and I wish I could tell you how to build a successful newsletter, but the best advice I have is still what Jeff Atwood does, except I have less conviction. But if you start writing, and you do it regularly, two things will happen. First of all, you're going to [inaudible 01:00:11] you write for yourself and you keep improving, you'll be a better writer. That's for sure. If you're lucky or if you're right about stuff, you might start to attract people who think similarly. So step one is get started. Step two is keep it up. And my suggestion is [inaudible 01:00:26] for yourself. The weird thing is, until I started my newsletter, I never thought I would turn this ever into a business, but it always felt rewarding. So I never... If you're starting out writing a newsletter to do what I'm doing one day, it might work out. But interesting enough, I never even thought that this was an opportunity.

Lenny (01:00:48):
So people listening to this that are thinking about, should I explore this life? If you think about your story, you wrote a book, you blogged for a while before this, you worked at Uber for a number of years. In a sense, it comes across a little bit like, there's no way I can be successful if that's the background I need to have. I have to have written things and worked at an awesome tech company. What advice do you give folks that are coming to you being like, "Gergely, should I start a newsletter? Does it make sense for me?" Do you need the background that you have, do you think?

Gergely Orosz (01:01:21):
Don't forget that when I started my blog, I didn't have any of this.

Lenny (01:01:24):
And this is while you were at Uber. This is before you started the newsletter.

Gergely Orosz (01:01:28):
It was before I was at Uber. So I was maybe at Skyscanner, or maybe at Skype, but I was even blogging before. I was talking to conferences before. So my advice really would be, if you're thinking of a newsletter or something similar, start teaching and sharing what you know and what you're observing. This could be a newsletter, this could be a YouTube video, this could be going to meetup. Actually, ten years ago I went to a lot of meetups where I presented all sorts [inaudible 01:01:54] I met a lot of cool people. I would say, share your knowledge one way or the other. And as you're doing it, you're going to learn a lot more.

Gergely Orosz (01:02:01):
So what I find... This is true, when I was a manager, we had to set goals, and I told people there's two types of goals you can set. One is [inaudible 01:02:12] people set this goal, I want to be promoted the next thing, or I want to lead this big project. And those are bad goals, because it's not in your control. So setting a goal that I want to have a successful newsletter with, I don't know, 20,000 subscribers, that's a goal where you're not in charge. A good goal is what you can do. So a good goal for example is, I want to learn this new language in the next year, which I'm going to spend time on, or I want to leave work at 5:00 PM on Fridays to be home with family. So set those goals that you can control.

Gergely Orosz (01:02:41):
And this is how actually my blog started initially. My goal was, I want to write once a month. And I did that for a while, and I was proud about that. Or whenever I learn something, I actually want to share it every now and then. So I would say set those goals, and the rest will come, probably. Again, don't get me wrong, I'm not trying to talk people out of doing it. But for me, a lot of this was luck. And the other thing that I would suggest is be curious, and look at your professional career as well. One thing that definitely helped me is getting pedigree. I come from a small country, from a really good university which no-one knows about, but I didn't grow up in let's say Silicon Valley, so I actually made a subconscious point to try to work my way up. And after I got to let's say JPMorgan in London, I was pretty picky of where I would go next. So that's why, when Skype came along [inaudible 01:03:36] this is great. Everyone knows Skype, I love Skype. And it was same thing with Uber.

Gergely Orosz (01:03:40):
So especially these days, people would not pay nearly as much attention to me if I worked at Small Parts Limited. So there's that part as well. So you need to manage some of these things, figure out what you want to do. For a long time, I pretty much thought that I just want to climb the corporate ladder and prove that I'm good enough at all these companies. I was just doing all this stuff on the side. It's interesting how it's now flipped, and now doing these things, this is my main thing, which used to be my side project.

Gergely Orosz (01:04:07):
And I guess one last advice is, do some side projects. All of this starts as a side project. At work, no-one's really going to appreciate that you're doing a newsletter or this or that. Try stuff on the side, assuming that you have time. Or if you don't have time, try to make time. Because I feel a lot of what we're doing is pretty entrepreneurial, and the only way you're going to get these muscles, if you start some small things.

Lenny (01:04:31):
You talk about the pedigree being important. I think there's also an even deeper point, that you actually need real experience doing real things that scaled and worked and mattered and worked with amazing people, to actually build a foundation to write about, share wisdom from. And that's really important. There's a lot of people starting newsletters and tweeting who haven't done much and don't have a lot of real life experience to share. And I think that's the core of a lot of what we do, is it needs to be based on real things that worked and that you've learned, or that you have access to other people who have learned these things.

Gergely Orosz (01:05:06):
I would say that, but one thing that I'll double down [inaudible 01:05:09] that's a really good observation is, if you're serious, like one day I will want to write a book or a newsletter, it's kind of the same thing, or teach people about stuff, look at the people that you look up to that you actually trust. Maybe it's me a bit or maybe it's you, but it's more likely people like Kent Beck, for example. He's the creator of TDD, and he's written a lot of books. He's one of my favorite people, I think he's coming up 50 or 60 [inaudible 01:05:36] if he listens to this, sorry if... I don't want [inaudible 01:05:38] seem old, but what I love about Kent Beck, is he's been in the middle of it. He has always worked in the industry, and that he wrote about it. But for example, I think he invented or he was a co-inventor of... Was it TDD or extreme program... Anyway, one of these methodologies.

Gergely Orosz (01:05:58):
And then [inaudible 01:05:58] went to work at Facebook. He took a title cut to be a software engineer, and then he hosts the TDD workshop, the test driven development workshop, and no-one showed up at Facebook. And Facebook did no testing, which went against all commercial wisdom. And he took that risk joining this company where he could have been... People would've knelt down to him anywhere else, but he went to this company where he just wanted to learn. He's this lifelong learner. He's right now writing a book. But what I think [inaudible 01:06:26] if you want to be someone who people listen to, yes, do cool and interesting stuff, push yourself to get into places that do these interesting things.

Gergely Orosz (01:06:33):
That's how, when I went to Uber in 2016, it was one of the highest regarded places back in 2016, and in 2017 it was the other way around. But back in 2016, people were turning down Facebook and Google offers to go at Uber, which we all thought would change the world. So you do need to get into those teams that are doing interesting stuff, prove that you can do that, and you'll have a lot more interesting stories to share, that's for sure.

Lenny (01:06:59):
If you had to boil down advice for how to be successful in this life of a newsletter, you had to boil it down to just one or two key pieces of advice, what would you say?

Gergely Orosz (01:07:10):
One is habit of depth in the field, whatever field you do. So this might mean that I think... I don't want to say that if you don't have experience, don't start one, but it's kind of true. So become an expert somewhere, somehow, before you start, because you'll be a lot more credible. I think there's no shortage of reporters and journalists who don't know about stuff, but they can interview people, but that doesn't give anything extra, and I think people feel that.

Gergely Orosz (01:07:38):
So I would say choose a field that you're going to be good at. And you can start on the side, doing this. Assuming you have something, you're someone with experience in the industry or you have insights, wisdom, observations to share, start doing so, in whatever format. I do newsletters. There's actually YouTube, a lot of people are becoming pretty successful on YouTube sharing their thing. Three, have a cadence and stick to it, to some extent, because you do need to keep repeating it. And then four, don't be afraid to try out new things. A good example of a person who did these is Steve Yegge. Steve Yegge is... Have you heard of Steve Yegge?

Lenny (01:08:17):
Yeah. He wrote some epic long...

Gergely Orosz (01:08:19):
He used to work at Amazon, and then at Google he wrote this internal email about platforms, about how Amazon is great at platforms and Google is terrible. And he was really well known at Google, because he wrote stuff inside Google. So he's experienced, knows a lot of stuff, and then he quit Google and he started to do a podcast that's on YouTube. You could check it out, it's called Stevey's Podcast. And what he did is, every week he recorded an episode and he talked about a bunch of his learnings, a lot of stuff, and he was pretty clear up front when he started the first one, he said, "What I'm doing is, I'm going to do this for six months and I'll see if it sticks, see if people care about it or people watch it."

Gergely Orosz (01:08:55):
Now, this guy had a lot of experience, really fun [inaudible 01:08:59] I think it's really fun to listen to. And in the end, it was I think successful. It got a couple thousand or maybe even 10,000 subscribers, but it wasn't this rocket ship. And I think what he did, he just stopped after six months, and he actually started head of engineering at Sourcegraph, he actually went back [inaudible 01:09:15] industry. But what I love about this, it shows that you cannot guarantee having success, but you can do what he did, which is start something, do a cadence, see if it sticks. If not, either pivot or do something else. I feel the world is kind of about that as well.

Gergely Orosz (01:09:30):
If you think about... Take a step back of, what is a successful newsletter? What is a successful podcast? What is a successful YouTube channel? And it's stuff that's interesting. It's either entertaining or educational. But all of these things, you can't really put a finger on. If you watch YouTube, Mr. Beast is someone who you probably came across, I actually like watching his videos and [inaudible 01:09:56] how good he does it, but it's not something you can [inaudible 01:09:59] anyone would have written in a book. So there is a sense of trying to understand what people care about, and a good way to understand is either experiment or observe or just try out stuff.

Lenny (01:10:12):
This is great. I feel like I can boil this down even further from everything you just said, which is, build depth in an area, then write a blog post twice a week for two years, and good things will happen.

Gergely Orosz (01:10:25):
I'm pretty sure. And here's an interesting thought as well, just for closure. I was talking with someone on why my newsletter is so successful. It's really successful, and I honestly don't know why. And this person told me something interesting. This is a person who had a really successful YouTube channel with about 200,000 subscribers, so more than my newsletter. And he said this. He's like, "What I noticed is, you started your blog in 2015, 2016, and I started my YouTube channel in 2019 or something like that. And on YouTube, there's so much quality, there's super high great productions, everyone is doing YouTube." And he said, "You know what I don't see? I don't see many blogs that are writing in depth stuff regularly. I feel everyone went over to YouTube or TikTok. So there is the other angle of the medium." And I'm saying this, not [inaudible 01:11:16] but it might be an advantage. These days, fewer people write, because I think a lot of people find it hard and more people will do videos. And you can take advantage of some of these shifts, which might be good or bad.

Gergely Orosz (01:11:27):
So if you're going to be a really well known person on YouTube, you might get more people watching you, but you'll have a lot more competition. And the last thing is that for me, writing, especially with software engineers, it's really efficient, because I can scan through it. I don't like YouTube videos, especially for learning about stuff, because I can't even scan through the whole thing. It's just really time consuming.

Gergely Orosz (01:11:47):
So I think, decide if you want to do entertainment, which for these podcast listeners, I don't think that's in the question, you're competing with the likes of Spotify and Netflix. Education, which is a little bit more dry, but it's really useful. Or edutainment, which is entertaining education. And once you figure that out, either if it's education or edutainment, you can figure out what format might work both for the medium and for you. And at end of the day, you need to enjoy it. I personally have learned over time to love writing. I love being in the zone. So for me it's not really work, but it's fun. And once you find that thing, whatever that might be, it just makes it easier.

Lenny (01:12:27):
Gergely, it's always so fun talking about newsletter stuff. I don't have many people to talk about this life with. I hope this was useful to people who are exploring this path, thinking about it, or even the different creator path. Just two final questions. Where can folks find you online if they want to reach out or learn more? And how can listeners be useful to you?

Gergely Orosz (01:12:45):
You can find me at pragmaticengineer.com. There is a bunch of stuff listed there from the Twitter, LinkedIn, my talent collective, some of the companies that I invest in, et cetera. Everything's there. And you can also sign up to my newsletter. Listeners being useful to me... If you work in tech, consider signing up to my newsletter. I always tell people we're a complimentary newsletter. If you work in product or have an interest in product [inaudible 01:13:11] newsletter is an awesome choice. With software engineering management, it goes the other way. And it's not just... People are telling me when they're data scientists or even product folks, sometimes they get some value out of it.

Gergely Orosz (01:13:23):
I write this column called the scoop every Thursday. If you hear of any interesting scoop happening, especially relevant for techies, this might be some change in the workplace, like your company is just rolling out agile [inaudible 01:13:36] team at Twitter did, feel free to ping me, just a short search for sending scoop to the Pragmatic Engineer. I treat everything as anonymous, so you can tell me interesting stuff. I'm typically interested in the stuff that you might not read about in the traditional media, but us techies really care about.

Gergely Orosz (01:13:51):
And finally, if you work at Google and you want anonymity to talk to me, just ping me, because one of my next articles will be Google's engineering culture. I wrote one about Facebook, one about Amazon, and I tried to talk with mostly software engineers to get a sense of how these companies work from a software engineer and engineer manager perspective.

Lenny (01:14:11):
Awesome. I hope this comes out before that post comes out, but if not, then enjoy that post. Gergely, thank you so much for being here. This was awesome. And maybe we'll do a V2 as things continue to grow.

Gergely Orosz (01:14:23):
Awesome. It was great being here, Lenny.

Lenny (01:14:27):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review, as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Customer-led growth | Georgiana Laudi (Forget The Funnel)
**Guest:** Gia Laudi  
**Published:** 2022-09-29  
**YouTube:** https://www.youtube.com/watch?v=0FgZ1VVxEBo  
**Tags:** growth, retention, acquisition, activation, onboarding, metrics, kpis, iteration, experimentation, analytics  

# Customer-led growth | Georgiana Laudi (Forget The Funnel)

## Transcript

Georgiana Laudi (00:00:00):
The problem with funnels and pirate metrics and the favorites that I love to pick on are MQLs and SQLs is that nobody knows what those mean. It puts every customer in the same sort of buckets. It assumes that all customers and all products are the same. It puts businesses, or they, I should say, puts businesses at the center of the business versus putting customers at the center. Right? It's about the values of the business, not the value to the customer that's being measured. Also, it just kind of feels gross for people, this idea of pushing people through a funnel. And then probably a particularly relevant for SaaS companies is that recurring revenue businesses, you cannot think about marketing and growth and the business overall as ending an acquisition, otherwise you're not in business anymore. And the vast, vast majority of these models don't take post-acquisition, retention, expansion, all of that into account. So yeah, in a nutshell, funnels are bad.

Lenny (00:01:04):
Welcome to Lenny's Podcast. I'm Lenny, and my goal here is to help you get better at the craft of building and growing products. I interview world-class product leaders and growth experts to learn from their hard-won experiences building and scaling today's most successful companies. Today, my guest is Georgiana Laudi. Georgiana, aka Gia, runs a consultancy called Forget The Funnel, where she works hands on with SaaS companies to help them unlock and accelerate growth.

Lenny (00:01:30):
As you'll hear, she often finds huge unlocks and opportunities often doubling or tripling conversion in various points in their product flows. In our conversation, she shares the exact process that she goes through to help companies figure out where their biggest growth opportunities lie, and also how to execute on them. We chat about how to identify your most important customers, how to very practically map their journey through your flows and set goals, and then execute on your ideas. There's a lot of wisdom and some fun stories packed into this episode. So with that, I bring you Gia.

Lenny (00:02:05):
I'm excited to chat with my friend John Cutler from podcast sponsor Amplitude. Hey, John.

John Cutler (00:02:10):
Hey, Lenny. Excited to be here.

Lenny (00:02:11):
John, give us a behind the scenes at Amplitude. When most people think of Amplitude, they think of product analytics, but now you're getting into experimentation and even just launch a CDP. What's the thought process there?

John Cutler (00:02:23):
What we've always thought of Amplitude is being about supporting the full product loop, think collect data, inform bets, ship experiments, and learn. That's the heart of growth to us. So the big aha was seen how many customers were using Amplitude to analyze experiments, use segments for outreach, and send data to other destinations. Experimenting CDP came out of listening to and observing our customers.

Lenny (00:02:44):
Supporting growth and learning has always been Amplitude's core focus, right?

John Cutler (00:02:48):
Yeah. So Amplitude tries to meet customers where they are. We just launched Starter Templates and have a great scholarship program for startups. There's never been a more important time for growth.

Lenny (00:02:57):
Absolutely agree. Thanks for joining us, John. Head to amplitude.com to get started.

Lenny (00:03:03):
This episode is brought to you by Athletic Greens. I've been hearing about AG1 on basically every podcast that I listened to, like Tim Ferriss and Lex Fridman. So I finally gave it a shot earlier this year, and it has quickly become a core part of my morning routine, especially on days that I need to go deep on writing or record a podcast like this. Here's three things that I love about AG1: One, with a small scoop that dissolves in water, you are absorbing 75 vitamins, minerals, probiotics, and adaptogens. I kind of like to think of it as a safety net for my nutrition in case I've missed something in my diet. Two, they treat AG1 like a software product. Apparently, they're on their 52nd iteration and they're constantly evolving it based on the latest science, research studies, and internal testing that they do. And three, it's just one easy thing that I can do every single day to take care of myself.

Lenny (00:03:58):
Right now it's time to reclaim your health and arm your immune system with convenient daily nutrition. It's just one scoop and a cup of water every day, and that's it. There's no need for a million different pills and supplements to look out for your health. To make it easy, Athletic Greens is going to give you a free one year supply of immune supporting vitamin D and five free travel packs with your first purchase. All you have to do is visit athleticgreens.com/lenny. Again, that's athleticgreens.com/lenny. Take ownership over your health and pick up the ultimate daily nutritional insurance.

Lenny (00:04:33):
Gia, welcome to the podcast.

Georgiana Laudi (00:04:36):
Thanks so much for having me, Lenny.

Lenny (00:04:38):
It's my pleasure. So we actually met over a decade ago, I think, maybe just around a decade in Montreal. I was working on my startup. You were helping companies with their websites, optimize their websites. Then you went on to lead marketing at Unbounce and a bunch of other great stuff. So just to set a little bit of foundation for listeners, can you talk about what you've done in your career in 55 seconds? That's your time box.

Georgiana Laudi (00:05:03):
55 seconds. Okay. So marketing for probably about 20 or so years, which sounds completely ridiculous when I say it, but I started working for my father's retail business in the early 2000s, probably 2000 actually. Worked there for a number of years, and then eventually left and started freelancing, worked at an agency. Terrible. And then actually probably around the time I met you, I had this little catalyst moment where I joined Twitter in late 2008, and I discovered the tech scene and startups. And that was, again, probably around the time that you and I met, maybe 2010 ish. And that was-

Lenny (00:05:43):
2011.

Georgiana Laudi (00:05:43):
And then I... What's that?

Lenny (00:05:45):
2011.

Georgiana Laudi (00:05:46):
2011. See, there you go.

Lenny (00:05:47):
Mm-hmm.

Georgiana Laudi (00:05:48):
So it was right around that time, and then late 2011, I decided supporting five, six companies at a time in their marketing and stuff like that. I was starting to get burnout, I was doing a lot, and I was like, "What would it feel like to sink my teeth into one brand?" So I decided to go in-house and I moved out west, and joined the team at Unbounce. I was there for five years. And then in late 2016, early 2017, I decided it was time to move on, and so I decided to go back independent and just started working with companies and supporting them through marketing and growth and product marketing. And that's what I've been doing ever since.

Georgiana Laudi (00:06:27):
But in mid 2017, I actually paired up with Claire Suellentrop who led marketing at Calendly, and her and I have been working together since about mid 2017. That's when we launched Forget The Funnel, and we started pairing up on working with companies and sort of married her customer research background in my strategy, marketing background. And we developed this framework that we now use when we work with predominantly B2B SaaS companies, is who we work with right now.

Lenny (00:06:57):
Awesome. So we're going to spend a lot of time on what you've learned working with companies through Forget The Funnel. Why did you call it Forget The funnel?

Georgiana Laudi (00:07:04):
Because funnels are gross. I mean, it's a really antiquated idea. It's not just funnels that we sort of take issue with, it's buyers' journeys or even... I remember actually at Startup Fest 2012, I want to say, Dave McClure was talking about pirate metrics and I was like, "Huzzah, marketing has a role post acquisition. Everybody understands now." It was a real moment for me. But the problem with funnels and pirate metrics and the favorites that I love to pick on are MQLs and SQLs is that nobody knows what those mean. It puts every customer in the same sort of buckets. It assumes that all customers and all products are the same. It puts businesses, or they, I should say, puts businesses at the center of the business versus putting customers at the center. It's about the values of the business, not the value to the customer that's being measured.

Georgiana Laudi (00:08:01):
Also, it just kind of feels gross for people, this idea of pushing people through a funnel. And then probably a particularly relevant for SaaS companies is that recurring revenue businesses, you cannot think about marketing and growth and the business overall as ending at acquisition. Otherwise, you're not in business anymore. The vast, vast majority of these models don't take post-acquisition retention, expansion, all of that into account. They also leave the problem stage out. So the world that customers are living in prior to discovering you, which is a really critical, that context is unbelievably valuable, especially for marketing. So to delete that out of the equation is a big problem. So yeah, in a nutshell, funnels are bad.

Lenny (00:08:52):
Okay. So I'm excited to dig into a lot of stuff you've learned, but I have a couple other things I just wanted to talk about to set the foundation.

Georgiana Laudi (00:08:58):
Mm-hmm.

Lenny (00:08:58):
One is, can you talk about some of the impact that you've seen working with companies through the process that you've come up with? What kind of impact have you seen? What kind of numbers have you seen?

Georgiana Laudi (00:09:07):
I would say, far in a way the biggest, most immediate impact of the type of work that we do is realigning with that ideal customer. Generally, the lowest hanging fruit outcome is realigning around better positioning and messaging. And identifying more resonant positioning and messaging that speaks to that context that I was talking about before, before people discover that you even exist, have that moment where they're like, "Oh my god, this has to change. This sucks," ties that in, ties in what they care about and what is valuable about your product and then also that desired outcome. I mean, for those in the know, jobs to be done is a big sort of influence here, but if you can identify that type of information about your customers and get to know them at that level, then you are in a way better position to be able to not only position your product but also use much more powerful messaging.

Georgiana Laudi (00:10:06):
So typically, what we do is, we'll identify those gaps of almost, I mean I shouldn't even say nine times out of 10, 99 times out of a hundred, a company's website is not doing as much as it could do. It's not being as effective from a messaging and positioning standpoint as it could. So websites tend to get update. We will do a lot of overhauls on messaging on a website and improve performance there. One of my favorite examples of that is a social media tool that we worked with where we did really very simple research for them, honestly, identified two different jobs to be done, zeroed in on one of them, and then updated the messaging on the website.

Georgiana Laudi (00:10:46):
We shortened the trial from 30 days to seven. The conversion on the website went up with this new messaging by 89%. But the thing that I love the most about that particular story is that we didn't even touch anything after the signup experience. We hadn't even gotten there and the trial-to-paid conversion rate increased 40%, and we didn't touch it. It was just because a more qualified, better fit customer was coming through the door. So there was more of them and there were better qualified. So that's a really specific example that is very typical of this type of work.

Georgiana Laudi (00:11:19):
There's other examples, though, of product adoption and using that messaging and positioning past the website, even in the product onboarding itself, email and app, whatever, and just making sure that they're getting to and have the calms to get to the parts of the product that they care about the most, which can increase trial-to-paid or product activation. With Autobooks, the product usage of the North Star product usage jumped by 300% or something within quite a short period of time after rolling out email onboarding to support that product experience. I know SparkToro as well, which I think we might end up talking about again when we talk about the process, they doubled their trial-to-paid conversion rate when we worked with them because of post acquisition optimization to their messaging.

Lenny (00:12:01):
I imagine people are listening to this and they're like, "This is what I'm waiting for, some kind of huge win, some huge conversion, a success." I'm curious, how often do you find companies have something like this, like a latent opportunity to double, triple conversion? Everyone's hoping a conversion like this.

Georgiana Laudi (00:12:18):
Oh, boy.

Lenny (00:12:19):
Yeah. What's the general hit rate?

Georgiana Laudi (00:12:22):
So many. I mean I would say, pretty well every company we've ever worked with has... Not pretty well. Every company we've ever worked with has learned something new about their customers that they can apply at some juncture of their customer's experience, whether or not it is in campaigns to reach the right people out in the world, whether or not it's doing a better job with their messaging and positioning on their website, or their go-to market or acquisition strategy on their website using a sandbox account or getting a faux freemium account to let people kick the tires of their product prior to getting on a sales call. That's something that could potentially happen.

Georgiana Laudi (00:13:06):
The post-acquisition experience I'm talking about, it is so often an afterthought somehow where that additional of layer... I think part of the reason why it's an afterthought is because product onboarding in particular, and you've probably heard this too, it tends to be kind of like no man's land. Who owns that? Is it marketing? If it's freemium, in my opinion it should be marketing because freemium is a marketing tool, but not everybody subscribes to that. Not every company would necessarily agree that that's the case. A lot of companies might say, "No, it's product." So we end up seeing a messy middle there because there's no natural handoff. So pretty well, every company that we've worked with has had an opportunity to improve, especially product onboarding and product activation.

Lenny (00:13:53):
Awesome. So basically everybody will benefit from what we're about to talk about.

Georgiana Laudi (00:13:56):
A hundred percent.

Lenny (00:13:56):
Amazing. Great.

Georgiana Laudi (00:13:56):
Yes.

Lenny (00:14:00):
All right. We've got wrap detention as a way to maybe transition into your process. So you're visiting a site once, and I invited you to the Airbnb office we were having a happy hour, and I gave you a tour. You told me later that something you saw while you're walking around the office transformed the way you think about growth and inform the way you think about approaching this problem. Can you talk about that?

Georgiana Laudi (00:14:24):
Yes. This is one of my favorite... It was 2013, so you and I might have met in 2011, and then a couple years later I was in town for a conference and we toured the office, HQ and everything. Of course, it was all stars in my eyes because what a beautiful office too. So it was quite like, I would've remembered it regardless. But we went downstairs, very different from the very polished upstairs. We went downstairs to where your working area was, where the product team was, and there were sheets of paper taped to the wall, a bunch in a row. And it would've been easy to miss because it's kind of chaotic down there, but it was the customer journey of an Airbnb customer through two posts.

Georgiana Laudi (00:15:12):
What struck me, I was like, "Oh that's interesting. I'm in the middle of building one out for us." Leading marketing at Unbounce at the time. And I was interestingly with the customer success, he was also with me. So Ryan Engley was there with me, and it was the perfect sort of that him and I saw it together. It was a customer journey that was focused on the customer. So versus that pirate metrics problem or that the typical buyer's journey problem that I was talking about earlier, it was the complete reverse of that. It was illustrated. The emotional journey was part of it. The role that Airbnb played as a direct touchpoint and also indirect, what was going on in the person's life that had nothing to do outside of Airbnb, which I thought was really interesting.

Georgiana Laudi (00:16:01):
It was like, the beautiful little milestones really encapsulated in a sort of snapshot way, such that anybody walking by it or anybody being reminded that it existed could understand in a glance what the goal was at each of those milestones. I was like, "Well, shit, this is completely through the lens of the customer versus the business and the grossness of the funnel." It's just so far removed from that experience that I was like, "Ryan, look at this. We need this." He was like, "Oh yeah, this is good." I took a picture. Can't find it for the life of me.

Georgiana Laudi (00:16:39):
But we returned back to the office the following week, and co-founder and head of product, head of CS, so Ryan, Carter Gilchrist, who's head of product and co-founder, Ryan, and I, head of marketing, the three of us locked ourselves in the room for two days and made our own. It was a circle. I mean looking back, it's hysterical, but it was sort of democratized to the rest of the team in a way because it had that buy-in. Everybody was like, "Oh yeah. Okay, this makes sense and I understand." It made everybody feel a lot better about what they were doing because it was about value, delivering value at each of the points.

Georgiana Laudi (00:17:13):
So that grossness sort of goes away and we're like, "Oh cool." I don't want to be too kumbaya about it, but it was a bit of a moment. And also, it made communicating with especially the product team and the engineering team a lot easier for me. So we were using a shared language. The rest of the company who aren't necessarily customer facing really understood, I think, at a different level what we were all doing together in KPIs, yada yada yada. So it was amazing. Honestly, I mean I can't credit only that obviously to our growth, but it was a pretty impressive couple years that followed that. I think the alignment that that brought us was huge. Yeah. Anyway, that's the story. Sorry, that wasn't super short, but it was big.

Lenny (00:18:02):
That's great.

Georgiana Laudi (00:18:03):
It was a big thing. Yeah.

Lenny (00:18:05):
We're going to link pictures of this on the show notes. Internally, it was called Project Snow White because it was inspired by-

Georgiana Laudi (00:18:13):
Oh yeah, that's right.

Lenny (00:18:13):
Yeah. It was inspired by Brian reading the biography of Walt Disney, and they needed to create the storyboard basically to create Snow White because it was so complicated to make that movie. It might have been the first animated film with storyboards.

Georgiana Laudi (00:18:24):
Okay.

Lenny (00:18:25):
So it was basically a storyboard of a trip on Airbnb of a host and a guest.

Georgiana Laudi (00:18:30):
That's right.

Lenny (00:18:30):
And in detail, I forget if I told you this, but Airbnb hired a full-time storyboard artist from Pixar to draw these key frames.

Georgiana Laudi (00:18:38):
I think I did know that. I was very grateful to have seen it. I didn't realize at the time, but it changed the way, like you said at the beginning, it changed the way that I thought about marketing because it really made it obvious to not only me, of course, and to everybody, that customer experience layer, that marketers are so good at, has such an incredibly important role in driving revenue. Not just in building awareness, but in playing a major role in helping customers get value and catching them when they fall off and all that kind of stuff. So it changed a lot for us.

Lenny (00:19:19):
And it informed the way that you approach your consultancy with Forget The funnel. So as a transition to talk about that, the way I'm thinking we approach this is, imagine a customer, what is the process you go through? What are the steps? How do you go about helping a company figure out where they should invest, what they're doing right and wrong? I should also mention you're writing a book about this that's going to explain this whole process, that's coming out later in the year.

Georgiana Laudi (00:19:40):
Right. Yeah.

Lenny (00:19:41):
So we'll talk about that at the end as well. I'll turn over to you.

Georgiana Laudi (00:19:46):
Cool. I mean if I go down a rabbit hole and you want to pull me out and have me unpack something, let me know. Well, the process is pretty straightforward. At the highest level, the idea is, understand your best customers, map their experience, like we were just talking about, map their experience through the lens of delivering value to them, make it measurable, and then evaluate what you're doing today that is out of alignment with that. Pretty straightforward. I mean that doesn't sound too hard of a job, of course. But research is an really important part of that. So the story that I was going to use to illustrate this is, there's a company that we work with from time to time. We worked with them at least twice, arguably three times.

Georgiana Laudi (00:20:34):
So Rand Fishkin who was the founder of Moz, he's got a new product. It's an audience research tool called SparkToro. And when they first launched, actually even pre-launched, Rand and Casey came to Claire and I to help with their positioning and messaging as they were going forward to launch. I mean Rand and Casey, they're both very, very thoughtful and they take their time with stuff. So they were just looking for that extra layer of like, "Is this good enough to launch kind of thing?" So we help them with their positioning and messaging. And off they went.

Georgiana Laudi (00:21:08):
About a year later, they came back because though they were doing a decent job generating traffic and interest in SparkToro, I mean Rand is no small fish so he's got a good audience built in, which is fantastic, but those that were getting to the website... Those that were signing up for the product, those weren't issues. But the people that were signing up for their free product weren't converting to paid in the way that they believed they could. So we decided to work with them and basically go to the source and find out, from SparkToro's best customers, what can we learn from them that we can then reflect back in the product experience and the customer experience for them?

Georgiana Laudi (00:21:54):
So I mentioned it before, but we are heavy believers in the jobs-to-be-done theory, which is basically this idea that people don't buy your product, they buy the better version of themselves, yada yada. I don't need to explain any of that. But we use that to guide our research. And with SparkToro, we were in a position, and the purists will hate me saying this, but we were in a position to be able to run surveys. So yes, interviews are ideal always, but we did think that we could learn a ton from surveys to then, if needed, double down with interviews. We didn't end up actually needing to run the interviews because the surface that we ran were pretty decisive and clear in terms of what we learned. So what we did was, we identified SparkToro's best customers. Now, what I mean by best customers is those that get a ton of value from your product as of exist today, pay obviously. They're happy. They're low maintenance. And very importantly, they signed up for your product recently enough that they remember what life was like before.

Georgiana Laudi (00:22:57):
So generally, we say that's in the three to six-month range. Because if you go to somebody that's been your customer for two years, they're just going to fill answers with what they think might have been going on in their life. But if you ask customers who remember what life was like before, you're going to get a lot more interesting responses, a lot more accurate depiction of what was going on. So that's the criteria we went forward. Surveyed their customers. We're trying to uncover from them what was going on in their life when they were seeking out a solution, what happened, what was that trigger moment when they did start seeking a solution, what did they go to, who did they talk with, what were their influences? Which PS, that's what SparkToro does, it helps you identify those.

Georgiana Laudi (00:23:42):
But also, what were they looking for in a solution? What were the must-haves for them versus what were some of the anxieties that they had, some deal breakers, things like that? So basically unpacking what is it that was critical for them in their solution. And then of course, what is it they're able to do now that they weren't able to do before. So that desired outcome. So out of that, we identified a couple of different options, a couple of different jobs, customer jobs, and we have to prioritize one, of course, because if you start right off the bat with like, "Okay, we're going to solve for all of these different customers jobs," then you end up not being as resonant. You can't be as effective. So we focused in on one.

Georgiana Laudi (00:24:23):
And the way that you make a decision on which one you focus on is similar to best customers. So high willingness to pay. There's no question whether or not they would pay for a product like yours. The handholding that they would need would be minor or less so. And I say that understanding full well the difference between product-led and sales-led. I'm not saying that sales-led is not good, but sometimes there's a decision to be made. If you're not set up today to support a sales-led or high touch, then you may want to opt for the more product-led approach. And the reverse is also true if you've got a robust sales team, well then, you might actually be better off leveraging sales more in that scenario and might want to attend towards that. But there's that criteria that you would think through.

Georgiana Laudi (00:25:10):
So willingness to pay, it's really obvious. Maybe the most important one is that they have an urgent problem. So the whole pain killer versus vitamin thing, you always want to be selling a pain killer. So who has an urgent problem that needs solving, not something that they might have a problem with six months down the line? Who has a high retention or even expansion potential is also really advantageous for very obvious reasons. So customers who would have a long-term need for this type of product and even potentially have that need expand or change over time and evolve in ways that you envision the product can help them.

Georgiana Laudi (00:25:47):
And then there's other criteria too. So sometimes you might want to prioritize one customer job over another, if those customers congregate in a way that make them really easy to market to. That's an advantage. Or another advantage, and this was the case for SparkToro, is you have an unfair advantage with this market in some way. So there were two different customer jobs that were coming out of SparkToro. One was more focused on service providers and marketing and the other one was more focused on data. And those data purists and those that really wanted verifiable data, well, SparkToro has an advantage on the marketer side more so than on the data analyst side. So that was another thing too. So with that, we made the call to focus on one of those customer jobs.

Lenny (00:26:35):
Can I ask a question here?

Georgiana Laudi (00:26:37):
Yeah, go.

Lenny (00:26:37):
So there's two parts of this. There's figuring out who you're going to go after and then what problem you're solving for them. Which do you think is more important at this point? Because step one in this process, just to zoom out a little bit, is figure out your customer and what their problems are so that you can actually solve them well. Do you start with here's who we're going to go after and then here's the biggest problem? How do you think about that?

Georgiana Laudi (00:27:01):
They're sort of one in the same. So because we learned from SparkToro's ideal customers, we already know that they're a fit for the product. They're happy, happily paying, prime them out of their golden hands customers. They're the customers that we want more of. So we've already validated that there's a demand from that customer base. Now, what I'm describing about choosing between two different customer jobs is really just, of those ideal customers, which customer job do you want to lean into? It's not that you wouldn't necessarily still be able to solve for that other customer job, it's just not the one that you would lead with. And I always cautious around this too because sometimes with founders, what'll happen is, there's a level set that just because we were prioritizing one customer job in the short term, doesn't mean you can't serve that other customer job down the line.

Georgiana Laudi (00:27:57):
A classic example of that is products that serve both brands and agencies for example. So the customer job for brands will be slightly different than agencies. And if you've got an advantage with one, you would just start with one and then you would go back after it. That's a bit of a level up after the fact. It's not part of the core processes, it's what you would do after. But it doesn't mean you can't solve for the other customer jobs, it just means put one foot in front of the other, do a really good job of one thing first, and then we'll add that on later. I don't know if that a hundred percent answered your question though.

Lenny (00:28:32):
Yeah. Yeah.

Georgiana Laudi (00:28:33):
Okay.

Lenny (00:28:34):
The reason that you start here is... Basically what you're trying to do is help SparkToro, in this example, grow faster.

Georgiana Laudi (00:28:40):
I mean we're trying to help them figure out why they're free-to-paid conversion rate was lower than what they wanted. Right? That was the challenge they came to us with. Our traffic numbers are good. Even our signups on our website, our positioning and messaging on our website is clearly doing a good job. But once people get into the product, there's not enough of them getting to value quickly enough. I mean they still had healthy customer base, but they knew that that number could be increased. So we knew what we were solving for.

Lenny (00:29:11):
Got it. Okay. That helps.

Georgiana Laudi (00:29:13):
Yeah.

Lenny (00:29:14):
So step one here is figure out who do you want to focus on, not just... Because a lot of people would go at this problem like, "Okay, conversion is whatever, 10%, how do we increase? Let's look at this data. Let's look at it. They're bouncing. Let's look at why people are confused." And your approach is, "No, let's focus on the people we really want to get into this product and focus on making them convert, and not focus as much on the general case of conversion."

Georgiana Laudi (00:29:39):
Right. We would get to that though. That's a really important part of the process, but it comes after figuring out who you're even solving for. But it's definitely important to look at those numbers. I mean, I'm not saying don't look at the data. Obviously you have to. They wouldn't have identified a problem had they not been looking at the data. So the challenge that happened so, so often, and I mean this happens with a lot of teams, particularly marketers fall victim to this tactical way of approaching things and piecemealing things, piecemealing campaigns or programs to prove that we're doing something and we're driving up numbers, and they don't take big enough sort of swings. So this is like, zoom out for a second, figure out who is it that you even want coming through the front door. I mean, the social media platform tool that I mentioned, the trial-to-pay conversion rate bumped up 40% because a higher qualified person comes through the front door. So it matters.

Georgiana Laudi (00:30:40):
So if you can zoom out and keep in your mind's eye that ideal customer job, that thing that you're solving for. We're not at personas. We don't care about personas at all. They're important when you start talking about advertising and targeting and that demographic data that you have to know when you're doing advertising and things like that. That is not what I'm describing here at all. I find that jobs be done too helps tie and bond marketing and product and customer success together a lot more because all three of those teams, or arguably four with sales, should all be focused on this theme customer that's not revolutionary. So this is just a sort of helpful way to do that.

Georgiana Laudi (00:31:24):
Product teams know and subscribe for the most part to the jobs-to-be-done theory. So marketers should follow suit, and there's a lot to be gained anyway on the marketing side. So anyway, the short of it basically is that because we knew we were focused on increasing that free-to-pay conversion rate, the next step after the job is the mapping. So it's identifying, okay, for this ideal customer, what are those key milestones in their relationship with our product? What are those big of leaps of faith is how I describe it. I mean I don't need to explain. The Airbnb customer journey tells that story. Where's a value moment in this relationship? Where are they reaching value?

Lenny (00:32:06):
Make some examples of that for folks that are trying to do this for themselves potentially. And then also, how many of these moments would you suggest people have?

Georgiana Laudi (00:32:13):
Yeah. So it completely depends on the product and the customer for that matter. I shouldn't leave that part over it. Obviously that's important. In general though, what we would do is, we'd break it down into a struggle phase and evaluation phase and a growth phase. Struggle phase is, they're experiencing the problem, life sucks, they're using the old way, something's got to happen, they've got to solve this thing. In general, the struggle phase would break down between out in the world experiencing the problem for the first time. So we call that a problem. And generally there would be another one called interest, where it's like, "Okay, now they're starting to shop around. They're getting into solution seeking mode." They might be on your website. They might be on your competitor's websites. They're reading product reviews, things like that. That's interest stage.

Georgiana Laudi (00:33:00):
And then there's the evaluation phase, which generally breaks down, I will say two or three milestones within the evaluation phase. I say two or three because if you have a more complex product, more complex customer is the more likely scenario. There may be more leaps of faith or more milestones, heavier lift for you to take. So we have worked with companies where the evaluation phase has been three or four milestones, I would always default to as few as possible. So if I'm cutting it down to lowest common denominator, I would say a first value would be the first milestone within evaluation. So you want to get them to that product activation really, really quickly. And then value realization is the milestone where you're solving that customer job. So they reach a point with your product where they're like, "Hell yes, this is it." And for the first time, they reach this critical threshold of product engagement. Now, what that product engagement is with your unique product for that specific customer is up for debate, but there still needs to be that moment.

Georgiana Laudi (00:34:08):
And then there's the growth phase, which is about the continued value. So getting to frequency of usage and a healthy building of that habit, getting into a cadence that makes sense. What type of feature usage and end product usage should you want to see there and then on what frequency becomes really important. And then there's another milestone generally after that where you're like, "Okay cool, they're in. They're pro. Now, what else do they need?" What else do they need from a product? And also, how else can we amplify them or work with them to either start teaching our tool to other people? I mean there's all kinds of things that can happen about growth. That's where the promise that exponential growth assess sort of comes into play.

Lenny (00:34:54):
And as people listen to this, just to maybe help if it's not super obvious, what people shouldn't imagine is like a little key frame, a storyboard frame of like, "Here's something your customer is doing." Right?

Georgiana Laudi (00:35:04):
Yeah. We often talk about it and describe it as the story of how I met and fell in love with your product. It's like this documentary of being out in the world, finding it, realizing that like, "Hell yeah, this might actually solve a problem for us. This might be it." Getting that enough value to convince them to keep going to full value realization, to continue value-to-value growth.

Lenny (00:35:28):
This episode is brought to you by Maven. I've been an investor, an advisor, and a customer of Maven from day one. I even taught my product management course through Maven. Maven is a cohort-based learning platform where you learn alongside peers with a direct connection to your instructor. Maven got a ton of courses for product managers, founders, and executives to help them level up in all kinds of ways. Over 10,000 people from Airbnb to Coinbase to Google to Tesla have taken courses from real experts and operators that have spent decades honing their craft.

Lenny (00:36:01):
As part of their fall season, which Maven just launched, there are over 100 new courses starting in the next few weeks. Many of the people I've had on this podcast are teaching courses like Jackie Bavaro on product strategy, Arielle Jackson on startup branding, Emily Kramer on B2B marketing, plus Annie Duke on decision making, Nir Eyal on behavioral design, and how to break into product management with Marily Nika. Check out all of my favorite courses and learn more at maven.com/lenny.

Georgiana Laudi (00:36:31):
Now, again, I'm saying that as if it applies to all customers and products, and that's not actually the case. Sometimes it's more complicated than that, but in general, that is what we have found. So that's what we did for SparkToro customers based on the research that we did. The research that we do, we basically take all the responses, we identify the critical patterns, and that's how we identify the customer job. From those critical patterns, if we segment down just that customer job, we can look at responses and say, "Okay, here's what they're likely doing when they're out in the world experiencing this problem. This is how they described the pain of their current solution. And then here's what they say about how their search for a solution started. Here's what they told us about how they started to do that research or find a solution."

Georgiana Laudi (00:37:17):
And then there's questions that are asked in the research like, "What was the moment that convinced you that our product was going to solve this problem for you?" And the answers to that question are going to tell you what your first value should look like, which of that first product activation experience, whatever language you like to use, what should that look like for them? What parts of the product do you need to push right up to the front of that experience so they can get to it really, really quickly after they sign up?

Georgiana Laudi (00:37:40):
And then value realization obviously would be close to, if not, the desired outcome of that customer job where you're solving that customer job. And then you've got all kinds of... Generally, what happens when I'm going through this process with teams is, all kinds of ideas start to come up about what more they could be doing, even post solving that customer job, especially the product team gets really exciting because they've got all kinds of ideas about where the product can go. So that really helps tie everybody together too.

Georgiana Laudi (00:38:10):
A critical part of that process obviously is identifying we have to measure success along the way. There should be a KPI for each of those stages in that customer journey. And for the most part, they won't be a big surprise on the struggle side of things. People out in the world experience the problem, how are we going to know we're doing a good job reaching them? We bring in new unique website visitors. In general, that would be the measure of success for the problem milestone. And then next piece of the puzzle is like, okay, once they discover that we exist, even if they are visiting, reading product reviews and visiting competitor sites or whatever, we'll know we've done a good job of convincing them that we can help solve their problem and deterring the people that we don't want.

Georgiana Laudi (00:38:53):
We know we've done a good job when the conversion rate on whatever our primary CTA is on our website, whether or not it's start a trial or request a demo, something like that. Generally, the struggle phase is very straightforward in terms of measurement. That's like marketers' bread and butter, that's where they live and breathe all day long. Where things start to change though generally when we're working with companies is helping them figure out how should they be measuring first value or product activation and how should they be measuring actual product engagement. Generally, what we do there is, we can associate basically what they told us brings them the most amount of value with the product attribute or parts of the product that deliver that value. We try to tie the KPI obviously to some sort of meaningful product usage of that key part of the product or product attribute.

Lenny (00:39:49):
Can you share some examples of that? Because that's a really important piece.

Georgiana Laudi (00:39:52):
Yeah. I'll use SparkToro as an example just because it's the one that we started with. So for SparkToro, I don't remember the exact customer job statement necessarily, but for them, what they said were, the parts of the product that gave them a ton of value was two specific features: lists. So being able to organize their findings in a way that made it not only easy for them to organize within their own files but also share because a lot of them were with clients or stakeholders that they want to be able to share with. So lists were a specific feature that honestly, it was in there, but they weren't front loading the product experience with that. I'm not going to say it was hidden, but it wasn't front and center enough. So that was one feature that we could associate with being able to organize the data, being able to continue to build on it and make it usable over time and also share.

Georgiana Laudi (00:40:55):
And then there was another feature as well, which was an exporting feature. Again, it's not that it was hidden, but it wasn't front and center enough. So we tied KPIs to them making use of those features, coupled with obviously the core feature, which is searchability. It was like pairing the search functionality with the list functionality, and then pairing the search functionality with the list functionality, with the export functionality. It's a bit abstract to me just saying the words. It's easier with a visual. But the story is basically, help them use the search functionality first. Right after that, make sure that they're using lists. And if they don't use lists, let's help them get back to using it so that they get to that important critical value moment. And then the same applies for the exporting features that we were talking about.

Lenny (00:41:43):
Got it. And to be clear, you basically said a metric for each of these moments.

Georgiana Laudi (00:41:48):
Yeah, milestones.

Lenny (00:41:50):
Milestones. Yeah.

Georgiana Laudi (00:41:50):
Or just whatever. I mean you have to. I mean it always surprises me when a team is like, "Oh yeah. Yeah, you're right, we don't do that." I'm like, "What? What do you mean?" So at a given milestone, unless they've reached that value moment, you can't keep them on the train to something else. If they haven't even discovered that really, to them, most valued part of their product, you would need to focus on getting them to that value. Otherwise, you can't just keep firing off emails and hoping they're going to jump back into the product as if they're going to care. So a lot of what we'd do is actually proactive customer experiences, whether or not in app or email or whatever tool, to help them get to that moment within the product.

Georgiana Laudi (00:42:32):
And if they don't get to that moment, which is measurable, again, that's why it's a KPI, then we can be reactive in helping them get back in. So identifying, "Okay," not that you would say this like, "it fell off the train," but just helping them nurture them back into, the product didn't really discover that feature if they missed it the first time around. So it's proactive and pushing them forward, but then also catching them if they fall. And the only way to catch them if they fall is if you're measuring something meaningful along the way.

Georgiana Laudi (00:43:02):
We have that storyboard that we were talking about. We also have a map where it's the experience to get them to a certain value moment, but then that win back experience to get them back in should they fall out for any reason. I mean, people get hungry and get distracted, and there's a ton of reasons why. I mean there's a lot of stats on the percentage. I think it's like 70% of people log into an app, log into a product once and never come back. It's wild. So the fact that so many companies don't have some sort of win back or re-engagement always blows my mind.

Lenny (00:43:41):
So just to recap and then we'll keep going with the process. Step one, understand what your customers are going through, figure out the most important customer and their biggest problem, then map out the journey that they go through, the struggle they go through before they discover your product, the steps they go through to evaluate, decide to use your product. And then once they use your product, then continuing to use your product and using it more and more. And then once you figured out these steps... And is a rough number like 10, 12 steps? What's a good number just to put-

Georgiana Laudi (00:44:13):
Oh no, I would hope it's more like six.

Lenny (00:44:16):
Six, okay.

Georgiana Laudi (00:44:17):
I'm always trying to bring it down lowest, only as long as it absolutely needs to be. I mean that goes for all pages, landing pages.

Lenny (00:44:25):
Okay, all right.

Georgiana Laudi (00:44:25):
Same thing for customer journey mask.

Lenny (00:44:27):
Okay. Airbnb had 12, I think. So you're involved in-

Georgiana Laudi (00:44:29):
Yeah.

Lenny (00:44:29):
I liked that. Okay. And then you've come up with a metric to tell you if that step is performing well.

Georgiana Laudi (00:44:36):
If they'd gotten there, did they get to that value?

Lenny (00:44:37):
If they've gotten there. Cool. One last question before we move on to the next step. Can you give two maybe examples of an actual movement, say in SparkToro's case, and then the metric that they use to measure, if they've gotten to that point?

Georgiana Laudi (00:44:52):
Yes. So the measure for success at that tip somebody over into evaluation is performing their first search. So when you're on their website, you perform a search, it's not signing up for a trial or signing up for free, although it does tip you into signing up for free when you perform your first search. So signing up for getting your first search and seeing your first search results is that first measure. And then following that for first value, it is using search again. I mean this is very product specific like I said, but generally, a first search is a kind of an experiment where you're sort of trying the tool on for the first time. Generally, searches start to get better when you do your second and third. So we try to encourage at least five plus.

Georgiana Laudi (00:45:38):
So that first value KPI, I think it was five plus searches, plus at least one list. So it's the combination of those two things that have to happen before somebody's going to really see what this thing does. It's not that they won't get value if they don't use lists, but because we know that SparkToro's ideal customers really get a ton of value out of lists, people can hang out in that stage all day long if they want to. We're not going to worry about them. We're going to worry about the people that really want the actual functionality of the real fully featured tool. So that was the first value, that's how we would know that they got to product activation.

Georgiana Laudi (00:46:21):
And then the next one, as I mentioned before, is a combination of actually three things. So it is conducting a minimum amount of searches within a span of time, creating at least a certain number of lists, I can't remember exactly what it is, and then discovering exporting at least once. And then that is, they've reached a meaningful enough threshold of product engagement. And then value growth was that they do all of that on a regular enough basis so that we know they're not a flight risk basically. So that we know that they're getting continued value from the product. And if they ever fall out of that ongoing engagement measured success, then we can trigger either one-on-one outreach, an email, whatever. I mean obviously it can't be an app because if they're not logging into the app, then you can't reach them. But to help them back in and to say, "Hey, what's up? Can we help? Is there anything that we can do?" And basically be proactive in getting them back in. And then value growth, I believe I think it was expansion or upgrade in their case. I can't remember exactly.

Lenny (00:47:27):
Cool. So you end up with these say, six KPIs.

Georgiana Laudi (00:47:29):
Yeah.

Lenny (00:47:30):
I imagine this becomes goals you track, and then you probably pick one of these to focus on say, per year, per quarter. Awesome.

Georgiana Laudi (00:47:37):
Yeah, hopefully not per year.

Lenny (00:47:38):
Okay, per week.

Georgiana Laudi (00:47:40):
Hopefully short, because I mean I will say that with some of the KPIs, it's very straightforward with new unique website visitors or the website conversion rate. I mean depending on who owns the website, that's not something that should take you a year. You should never be focused on only your website's conversion rate for a year hopefully. But these other KPIs and these other milestones, I mean I have no disillusions about if it impacts the product, obviously there's a lot of implications there. So yes, generally, once you tip over into that sort of in-app and more product experience, timelines vary widely, to say the least.

Lenny (00:48:18):
Okay, cool. Let's move on to the next step.

Georgiana Laudi (00:48:21):
Okay. So after that point, we had a rich voice of customer document that came out of that research. We had a messaging guide for them to use not only in their marketing materials but also through the entire product experience, and also identifying the parts of the product that were so meaningful. Actually, their VP of marketing, the new VP of marketing, Amanda Natividad, actually rolled out checklist. They built a checklist, a product onboarding checklist and also product onboarding emails. And their trial-to-paid doubled. We were like, "Okay, cool, let us know if you need any help or whatever." And they're like, "Oh, we're good. We got this." Checked in two months later and their trial-to-paid had doubled.

Lenny (00:49:03):
I feel like you skipped the important staff of, "Hey, we got KPIs." And then you're like, "Oh, we gave them all this information." So I'd love to spend a little more time on there. You came up with messaging for them, positioning stuff. what happens there?

Georgiana Laudi (00:49:16):
Well, this is the thing. They have a team in place. They've got very highly skilled, a huge team but highly skilled marketer there at the helm. I mean not the list of which is Rand Fishkin, their CEO. So basically, what we did was we gave them, it's like a framework. So it's like, "Here are the bones of this. So got a messaging and positioning guide for you." Generally, I mean when we do them, they're five to seven pages long. They hit on the value prop. They hit on the major competitive advantages. They hit on the major value themes that you want to focus on. Those value themes can be broken down by the emotional benefits and the functional benefits tied to the product attributes that drive that value. So that document, and there's more that goes into it, but that messaging guide basically can be used as the baseline for all kinds of marketing collateral and material, but also email onboarding.

Georgiana Laudi (00:50:16):
So when they're writing their email sequences for whatever it is they're trying to solve for, whatever milestone they're solving for, they can use that as their baseline like, "This is what we're going for. This is the goal here." And that messaging guide rules up to the job to be done. So the job to be done is sort of like the top line. And then we've got that messaging that serves that job to be done. And then we've got the sort of operationalized customer experience with those milestones and KPIs. And then you sort of zoom in on like, where is the experience most broken right now? We already knew that for SparkToro. We knew that we wanted to influence that first early product experience. So that's where we zoomed in and decided on what programs they should roll out. And email onboarding was a natural, as was the checklist.

Lenny (00:51:03):
For folks that want to work on messaging, say kind of just like, "Hey, here's a bunch of messaging advice," any tips for how to message well, how to think about messaging once you have a sense of your journey, maybe some goals, any just pro tips here you could share?

Georgiana Laudi (00:51:21):
Oh, boy. I mean that research and the voice of customer, I mean I'm always going to go back to that. You can guess and you can do use your best judgment. You can use internal stakeholders and the internal team knowledge. And I'm not saying that that is not valuable and that you shouldn't use that at all. You can, but it should never come before learning from and listening to your best ideal customers and using the language that they use. You want to reflect them back to them. That is what is going to show them that you understand the problem that they have and that your product has exactly what it is that they need.

Georgiana Laudi (00:52:06):
The hierarchy of messaging is really important as well. So I mean, there's the classic, sometimes it's hard to see the label from inside the jar, so it's really helpful to get out and be like, "Okay, how do customers see us?" Generally, you can identify the hierarchy of what is important to them, what is the thing that they say is most valuable about their product? What was that aha moment or what was that first value moment? Or what is the thing that makes you stand out over everybody else? And it can literally be a numbers game. If you take a hundred or so survey responses, you can break that down like, "Here's the thing they said they cared about most. Here's the thing they said they cared about second most and third most," not to be so paint by numbers about it, but there's art in the science. But in general, you want to reflect back what they said they care about, not what you think is the coolest thing about your product. That's obviously not the best way to go.

Georgiana Laudi (00:53:05):
That's something that we all inherently know, but it becomes really hard when there's a lot going on and things are changing and the product is evolving and there's a lot of teens and people are coming and going. It's easy to lose sight of that, especially when you're just trying to get shit out the door. So that messaging guide is mentally like, "Okay, here we are. This is my baseline, these are my guardrails for everything that we produce." It's also really handy to hand off to copywriters when you bring in... I mean not just copywriters, lots of people, but particularly when you're producing copy, providing that messaging guide is solar platter for them.

Lenny (00:53:46):
Is this available anywhere, the template that you end up sharing with a customer? Just like, here's a guide, the layout, messaging, recommendations.

Georgiana Laudi (00:53:53):
Oh, we have so many.

Lenny (00:53:55):
Maybe a little-

Georgiana Laudi (00:53:55):
We have so many templates and stuff. Yeah, I'll include a couple links.

Lenny (00:54:01):
Great. I'll put it in the show notes.

Georgiana Laudi (00:54:02):
We got lots of stuff like that. Yeah.

Lenny (00:54:04):
Okay, great. A few final questions around jobs to be done.

Georgiana Laudi (00:54:09):
Yeah.

Lenny (00:54:10):
So you said that they doubled their conversion from free to paid.

Georgiana Laudi (00:54:13):
Yeah.

Lenny (00:54:13):
Amazing. What was their job to be done in the end? And then I just have a few questions about the jobs to be-

Georgiana Laudi (00:54:19):
I think it was when they're struggling to identify opportunities that aren't as obvious. So generally, when you're doing marketing research, you'll end up signing the same things over and over again. And if you are a service provider or if you're in-house for that matter and you're tasked with always coming up with novel and new and more and more and more, you tap that pretty quickly. So what customers were coming to them for was like, "Give me more. I need to impress here. I need more to work with. I need to identify opportunities that I wouldn't otherwise be aware of." Actually that was exactly what it was. I helped me identify opportunities as I wouldn't otherwise be aware of. So the customer job statement is, "When I am in a certain situation, help me," which is filled in by what those things that they're looking, for those motivations, "so I can," which is the desired outcome.

Georgiana Laudi (00:55:18):
The help me was about, I believe it was in a way that is organized and that is shareable and usable over time that I can build on and really rely on over time. And the desired outcome was about, I mean this isn't going to be surprising, but it was about getting stakeholder by hand and getting people on board with, and sharing and looking good, looking like a pro, and doing their job more effectively and driving better results for either their own team or for their clients.

Lenny (00:55:48):
Awesome. We got there. We gloss a little bit over jobs to be done. I imagine many people listening have no idea what this is. So maybe as our final question, can you just explain what this framework is and how folks can learn to use it, or any resources you recommend that comes to mind?

Georgiana Laudi (00:56:07):
Yeah. I mean a heavy influence for us definitely is Bob Moesta, who's one of the original architects of jobs to be done. There are lots of materials online for jobs. I am not the foremost authority in jobs at all. I think jtbd.info is a good website. There's a bunch. Also, Bob Moesta wrote a book called Demand-Side Sales that goes into it. There's also a lot of books written about jobs to be done. When Coffee and Kale is one that a lot of people love. I digress. Point being that what matters is identifying what it is that customers are trying to accomplish. So demographic data doesn't matter. The classic example is, if you look at... Oh, King Charles, now the example has changed. If you look at Ozzy Osbourne, and it was Prince Charles the original, but now it's King Charles, if you look at those two men, they're the exact same age and live in the same area. They both have a dog. They both love cars.

Georgiana Laudi (00:57:04):
From a demographic standpoint, they are identical, but they obviously lead very different lives. What motivates them is very different. So that is where typically personas sort of fall down. So what jobs to be done, to us, is help you figure out what is that desired outcome, what does that better life that customers are seeking out. You were just the vehicle to get them there. That's all it is. I mean there's so many tired analogies so I don't even want to use them but-

Lenny (00:57:34):
Milkshakes maybe.

Georgiana Laudi (00:57:36):
What's that?

Lenny (00:57:37):
The milkshake analogy.

Georgiana Laudi (00:57:38):
The milkshake one, it's not even the analogy. I think that was one of the original job stories that is the milkshake one.

Lenny (00:57:45):
Any other things you want to share about the process that you go through with the companies, things you've learned, before we get to a very exciting lightning round?

Georgiana Laudi (00:57:54):
Yeah. One of the objections that we often get to this type of work is that research takes a long time and that research can often lead to more questions and can slow everything down. You can end up in analysis paralysis, but it doesn't have to be that way. It can be very straightforward, honestly, in a survey scenario. With SparkToro, in just that scenario, I have lots of examples of companies where we ran surveys, it can be a couple of weeks. Two or three weeks, you can actually come out with something solid to move forward with, and you don't get stuck in the bickering or all those stakeholders, the too many cooks in the kitchen. You can come to something decisive. You can get value out of that.

Georgiana Laudi (00:58:47):
The other thing too, the other objection that we get a lot from founders in particular is because they build products to solve a problem that they had, which is cool and it definitely makes you one of the most knowledgeable people about your solution. But products change, markets change, customers change, teams change in a ball. Not everything can live inside of your head, and there's a ton of value in learning and getting inside the heads of your best customers that you may have been really close to the inception of the product. But if any span of time has changed, you'll always learn something new. I've never been in a scenario like this where a founder has not learned something new from their research and been able to leverage it in a way that makes their product experience better.

Lenny (00:59:35):
Awesome. We'll come back to how folks can reach out to you if they want to experience this process, could work with you, learn more. But before we get there, we've gotten into a very exciting lightning round. I've got five quick questions for you. We'll go through them quick, whatever comes to mind. That's what we're doing. Okay, sounds good?

Georgiana Laudi (00:59:50):
Okay.

Lenny (00:59:51):
Okay. What are two or three books that you recommend most to people looking to get better at marketing?

Georgiana Laudi (00:59:58):
I very, very, very rarely read marketing books, but there's two that I think are pretty foundational and recent. So Obviously Awesome by April Dunford. I'm sure you've heard that one a ton. It's kind of required reading, I would say, especially for founders. I told April when she first wrote, I'm like, "I'm going to require every single founder I work with to read your book before we work with them," because it's foundational, you have to know that.

Georgiana Laudi (01:00:23):
And then the other one that I really enjoyed flip side was Hooked by Nir Eyal. That one was great too. But like I said, I don't read many marketing books. The other one that I would be remiss not to mention is ours that we're writing about the process, which is really about the step by step how to do this thing. So as much as we love going through this process with companies, I sort of took a page from April here too, in that telling the process and having people be able to rule this out and do this internally themselves has been wildly gratifying. We do it with a training program and this is our next step in getting out into the world even more. So you absolutely can do this stuff yourself. So that process is later in that book. And then another book that I read recently, which has nothing to do with marketing at all, but was really nice was 4000 Weeks. I don't think-

Lenny (01:01:15):
I'm reading that right now.

Georgiana Laudi (01:01:15):
Oh yeah, I enjoyed it. It was a nice sort of coming back to base a bit. I don't know when I read it. I just finished it a couple of weeks ago. It was just the timing was perfect. I feel like what's going on in the world right now and how everybody's probably feeling right now, it's a good solid read for now.

Lenny (01:01:38):
I'm enjoying it. I just started. I'm glad to-

Georgiana Laudi (01:01:40):
Okay.

Lenny (01:01:41):
Well, you encouraged me to keep reading it.

Georgiana Laudi (01:01:43):
Yeah.

Lenny (01:01:43):
Okay. Favorite recent movie or TV show?

Georgiana Laudi (01:01:46):
I have young kids. I just bought a second property. We're renovating three houses right now. I do not watch movies almost ever. The only thing that I'm currently binging is YouTubers that do DIY interior design and renos. Reason being my partner and I bought a property with four very, very old cottages lakefront, almost like tiny houses, little cottages. We are slowly renovating each of them. So my sort of fill is learning about interior design and DIY home rentals. Yeah.

Lenny (01:02:31):
Who's had the most impact on you in your career?

Georgiana Laudi (01:02:31):
This is the worst question. I hate saying this, but it's probably my dad. I have to say my dad because he's an entrepreneur through and through. And I remember very vividly, I worked for him for I think eight years early in my career. One of the things that he always said was like, "It was the joy of the business." He didn't care what, he's like, "It doesn't matter what you're selling." He could be selling anything, but it was the joy of entrepreneurship. And that really stuck with me. So even when I was in house, I always knew that I needed to do something on my own and be in charge of that journey. His joy in it has impacted me a lot. He was the reason why I knew I was always going to do this.

Georgiana Laudi (01:03:26):
Other than that, I would say I have an incredible network of women that I have been very lucky. We're part of a group that we call Shine Crew. I think I'm supposed to copyright that or something to somebody because I think the term Shine Theory is what it's based on basically. But I'm very, very lucky to be heavily influenced by April Dunford, Tara Robertson, Joanna Wiebe, Talia Wolf. And then obviously my business partner, Claire, obviously changed everything for me. Having that partnership in business, I don't think I would've lasted this long. So yeah, definitely a huge influence for sure.

Lenny (01:04:10):
What's one thing that helps you stay focused and productive during the day?

Georgiana Laudi (01:04:15):
Definitely carving up time, like time blocking. I do a lot of time blocking in advance with a little brain emoji of safeguarding my time. Because we're a small team and we use Slack obviously, something else that we do to protect each other's time is not time stamp, but we put a little code in all of our messages that's either like, "You don't have to listen to this before the end of the day," or, "It's timely," or, "It's no rush," so that we know when we need to mentally process messages in Slack, so we can drop in there just periodically. And then the only other thing that I would say that I do maybe once a month or once a quarter is, we're pretty buttoned up about our time tracking, so we go back and it sort of keeps us honest about how our time is actually spent. And then we can sort of adjust and time block accordingly to make up for the shortcomings of our previous quarter.

Lenny (01:05:10):
That was really clever. I haven't heard of that trick. What's the emoji for "You can do this later"?

Georgiana Laudi (01:05:15):
We actually just use no rush or EOD for end of day, or timely. We do have the alarm emoji, is the "Now. This is going to be dealt with ASAP."

Lenny (01:05:29):
Amazing. Gia, thank you for making time. For this final question, where can folks find you online? How do they pre-order your book? How can they learn more? And then also, just how can listeners be useful to you?

Georgiana Laudi (01:05:39):
Thank you for asking. Twitter is probably the best way. My Twitter handle is atrocious, @ggiiaa is me on Twitter. I'm on LinkedIn every once in a while obviously. My email address is gia@forgetthefunnel.com. So if anybody has any questions, whatever, feel free to email me. If you want any templates or whatever that don't get included in the show notes, just ping me. I've no problem with that. And then forgetthefunnel.com, we've got a book page where there is a wait list for the... Well, we're going to do presale, and then the published physical book will be early in 2023. But we are going to do presale because... Get it in those hands. Why not?

Lenny (01:06:18):
Love it. Gia, thank you for being here.

Georgiana Laudi (01:06:21):
Thank you so much for having me.

Lenny (01:06:24):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## 35 years of product design wisdom from Apple, Disney, Pinterest and beyond | Bob Baxley
**Guest:** Gibson Biddle  
**Published:** 2025-06-12  
**YouTube:** https://www.youtube.com/watch?v=X-83gvgVaWc  
**Tags:** growth, retention, onboarding, churn, prioritization, a/b testing, experimentation, funnel, conversion, monetization  

# 35 years of product design wisdom from Apple, Disney, Pinterest and beyond | Bob Baxley

## Transcript

Lenny (00:04):
Gibson Biddle, whose name is really fun to say, by the way, has directly taught and worked with more PMs than only a handful of other people in the world. Before going full time on teaching, he was VP of product at Netflix and at Chegg, and has written what is almost surely the most popular Medium post on product strategy.

Lenny (00:21):
In our chat, we learned about Gibson's very popular product strategy and prioritization framework, and we go through a bunch of real life case studies from his time in Netflix to see how they apply in the real world. I love how Gibson comes up with such clear and memorable frameworks, which help demystify the vagueness that surround strategy and prioritization. We're really lucky to have Gibson share these with us, and I hope you enjoy it.

Lenny (00:45):
This episode is brought to you by Flat File. Think the last time imported a spreadsheet. Did it work the first time? Chances are it did not. You probably got some weird error, had to try a bunch of things like removing the blank title rows above your column headers, or Googling how to save with UTF-8 encoding. What even is UTF? Who cares? You're just trying to get your file where it needs to go so you can do your actual job.

Lenny (01:07):
Your customers run into the same issues when it matters most, right after signing up for your product. Enter Flat File. Flat File is the data onboarding platform built to take the acute pain out of importing customer data into your product so they can see the magic that you promised them. Flat File is SOC type one and two certified, GDPR compliant, and even HIPAA compliant, ensuring your customers, no matter where in the world they're located, are sharing their data securely and in compliance every step of the way. No more emailing files back and forth. No more help articles that just don't land. Just clean data on day one, when it matters most. Get started importing millions of rows of customer data in minutes at FlatFile.com/Lenny.

Lenny (01:50):
This episode is brought to you by Coda. Coda is an all in one doc that combines the best of documents, spreadsheets, and apps in one place. I actually use Coda every single day. It's my home base for organizing my newsletter writing. It's where I plan my content calendar, capture my research, and write the first drafts of each and every post. It's also where I curate my private knowledge repository for paid newsletter subscribers, and it's also how I manage the workflow for this very podcast.

Lenny (02:15):
Over the years I've seen Coda evolve from being a tool that makes teams more productive to one that also helps bring the best practices across the tech industry to life, with an incredibly rich collection of templates and guides in the Coda doc gallery, including resources for many guests on this podcast, including Shreyas, Gokul, and Shishir, the CEO of Coda. Some of the best teams out there, like Pinterest, Spotify, Square and Uber, use Koda to run effectively and have published their templates for anyone to use.

Lenny (02:43):
If you're ping ponging between lots of documents and spreadsheets, make your life better and start using Coda. You can take advantage of a special limited time offer just for startups. Head over to Coda.io/Lenny to sign up and get a thousand dollar credit on your first statement. That's C-O-D-A.io/Lenny to sign up and get a thousand dollars in credit on your account.

Lenny (03:14):
Gibson, I am so excited to be doing this. We've collaborated on some writing. We've done a couple of fireside chats together, but we've never really dug deep into anything, and so I'm really excited for this opportunity to chat. So, welcome.

Gibson Biddle (03:27):
Great, Lenny. Thanks for having me. It's fun to virtually be in the same place at the same time. Someday we'll do that in person.

Lenny (03:35):
Oh man, I can't wait. For folks that aren't that familiar with you, could you just share a very brief overview of your journey through product?

Gibson Biddle (03:43):
It's hard, because I'm older than dirt, to be very brief, but I'll give my best shot. The intro was, I discovered I loved teaching early. I ran a sailing school, took a year off from college. That was my first startup. And then, the three chapters of my life. The first one was in marketing, so I actually started in the mail room at an ad agency, and then went into account services and created a service that helped name new companies and products, like if you're in the Bay Area, the Versatel, or the Versateller, it's a Bank of America name.

Lenny (04:10):
I've always been so curious about that industry, but that's a discussion for another time.

Gibson Biddle (04:14):
Oh yeah, well, we can come around to that. But at the end of the day, it's all about packaging and positioning and branding. And so, I was curious about that. I got good at it. And then, I lived in Silicon Valley, and I wanted to go into tech, and so I decided to go back to business school, and I went back to Tuck, which is at Dartmouth. It's the only ski... it's the only business school that has its own ski area, which is why I went there. It's in Hanover, New Hampshire.

Lenny (04:35):
Okay, that feels like a product market fit for Gibson.

Gibson Biddle (04:37):
Exactly. And then, after the school, this is the tech journey, I joined Electronic Arts. Punk kid in the right place at the right time. I joined in marketing, and then I switched over to product. It was a great place to learn product. They called it Producer College. I learned a ton, and my first startup was actually a joint venture between Electronic Arts and Disney. We created what's called EA Kits at the beginning, and that became Creative Wonders, and we sold that company to Mr. Wonderful from Shark Tank. He was the CEO of the Learning Company that made Reader Rabbit software and Oregon Trails. That dates me, because most of the listeners have probably played Oregon Trails as a kid.

Lenny (05:13):
Dying of dysentery. That's what I remember.

Gibson Biddle (05:15):
Yeah, yeah. And so, the product roles I grew up into, I call it a muckety muck, but a VP of product or a chief product officer. Joined Netflix in 2005. I left out some failed startups. That's important. It's important to let folks know I had some failed startups, but you can gloss over in the brief version. Netflix 2005, and then 2010 I went back to my heart, which is teaching. Chegg was a textbook rental and homework help company. It continues to exist. We took that public sort of 2014.

Gibson Biddle (05:44):
And then, last five years I stopped direct deposit, and I'm really back to the coda in my career. I'm back to teaching, which I really love to do. So I do talks, workshops all over the world. I do more writing, which really saves my voice, and then experiment with different ways to really try to be helpful to product leaders around the world.

Lenny (06:02):
Awesome. We're going to be spending time digging into some of that stuff. Did you describe this point in your career as stopping direct deposit?

Gibson Biddle (06:08):
I did.

Lenny (06:09):
That's amazing. Wow. I've never heard it that way.

Gibson Biddle (06:14):
At least you understood that.

Lenny (06:15):
I totally get that. Amazing. So, a question I ask folks in your line of work especially is, how many PMs would you say you've helped train, free workshops and advising and online courses, and anything else you've done?

Gibson Biddle (06:28):
I thought it was going to be a, how many PMs does it take to screw in a light bulb? I thought it was going to be a joke. Yeah, yeah. Okay, my SWAG. SWAG is a stupid wild-ass guess, important idea. So, my guess is, in real life I've worked with product leaders where I was in the building with them. It would be like 500 to 1000. When I would manage an organization, there might be 200 or 300 people in it. So, that's in real life.

Gibson Biddle (06:53):
The next one would be via talks, workshops, newsletter. That's probably, I kind of can SWAG my way into that. Probably 50 to 100,000 a year. The reason I sort of know, I'm a feedback freak, so there's a Survey Monkey at the end of everything I do. So for instance, every morning I wake up, it's always feedback for the same talk. I did a Branding for Builders talk for Product School and there'll be like 10 surveys. I've got like 6,000 surveys for that. They're all watching and recording. My guess is, that means like 60,000 people have watched that one video, for instance.

Gibson Biddle (07:26):
Anyways, and then lifetime, it's probably getting into 500,000 to a million. So, that's my SWAG. I could be 2X wrong on either side.

Lenny (07:34):
Okay, a million, potentially.

Gibson Biddle (07:36):
Well, your number's bigger. You could just go off of, what, 115,000 subscribers your newsletter?

Lenny (07:43):
Yeah.

Gibson Biddle (07:44):
You're getting to a billion, Lenny. You're going to get to the next level. 500 million to a billion.

Lenny (07:49):
I feel like the level that you've helped PMs is at a deeper level for most of the folks, especially the courses you've done and things like that. So, it's a little hard to compare. But anyway, that's really impressive, and I feel like when I ask people this question, I feel like this is going to be a high bar to meet.

Lenny (08:04):
So, I'm excited to dig into a lot of the stuff that you've learned along this journey. Maybe the area you spend most of your time on is helping PMs build their product strategy, muscle through your workshops, and you have these legendary Medium posts about product strategy. So, I'd love to spend the majority of our time talking through just helping people build this muscle. And maybe just start, you have this really simple model for describing what product strategy should be for companies: to delight customers in hard to copy margin enhancing ways. So, there's kind of these three parts, customers, hard to copy, margin enhancing. I'd love to just kind of hear your take on each of these three parts, how you came up with this, and then maybe a story or two of how you relied on this and used this at Netflix.

Gibson Biddle (08:42):
Sure. You got the model right. And I mean, the short answer is, I definitely learned it from Reed Hastings when I started at Netflix. Actually, he did a reference check to a friend of mine, checking up on me, and the only question he asked my pal, whose name is John Daz, was, "Hey, John, is Gib ready? Can Gib delight customers?" That was the only question he asked in the reference check.

Gibson Biddle (09:05):
Luckily, I built really delightful kids software. Back then, people were talking about satisfying customers, listening carefully, understanding them, et cetera. And the delight, it just said, no, no, no. The job is to delight customers. Like Peter Thiel, his book, From Zero to One. The job of an entrepreneur at the beginning is just to find out something that's 10X better. Delight is trying to work in that magnitude.

Gibson Biddle (09:28):
The hard to copy part, definitely I learned that. I had a product leader who worked for me, his name was HB Mock. He was focused on the non-member page. That's where people sign up for. They put in their email, their credit card, they would get a free trial. He'd looked like crap, like everything at startups sucks at the beginning, but he put a happy family on the couch on this screen, and that's where you put in your email. And that got a lot more people engaged. And so, it delighted customers, but it was helping to build the business, because more folks were setting up for a free trial.

Gibson Biddle (09:58):
I'm like, that's great HB, but I'll bet my paycheck that within a week, Blockbuster's going to put a happy family on their couch, too. And this is the problem of doing things that are easy to copy. So in the long term, if you can delight customers and create hard to copy advantage, things are just a lot better.

Gibson Biddle (10:17):
And so the last phrase, margin enhancement, that's just a fancy phrase for making money. Margin technically would mean profit. I just gave you example with that non-member page, with the happy family on the couch. It delights folks, it helps build a better business, but in that case, Blockbuster was able to copy it.

Gibson Biddle (10:37):
So, that's the model. The hardest part in that model is, how do you balance delight versus margin? So if Netflix said, hey, everybody, you're paying $20 bucks a day, but you're going to get exactly the same service tomorrow for $5 bucks a month, you'd be just like, this is fricking awesome. You'd be really delighted. But Netflix would not, the business wouldn't work.

Gibson Biddle (10:56):
So, one of the first places we sort of experiment on how to evaluate trade offs between delight and margin, in the old days, Netflix was a DVD by mail company, and if you ask customers what they wanted, then they all said the same thing. I want my new release DVDs faster, right? Back then, most customers would have to wait a week or two or four weeks. Back then, a movie came out in the theater, two months later it came out on DVD. We just couldn't afford to buy for that initial demand. So, the way it worked was, some people got it the next day in the mail, and some people had to wait two months.

Gibson Biddle (11:31):
And so, the A/B test we set up, we said, okay, everybody says they want this, in focus groups and qualitative and surveys. Well, let's A/B test and see what we really learn. So, the AB test was called the Perfect New Release Test. Imagine we're at about a million customers circa 2005. 10,000 peeps are in a test cell. They get their new release DVD the next day in the mail. Awesome, right? And the control gets it whenever. Let's say, average maybe two weeks later.

Gibson Biddle (12:01):
And so, the way we measure delight in this A/B test is, will you improve retention for the folks that are getting their DVD the next day in the mail? That's how we measured, it was retention. When Netflix started, it was like 10% canceled every month. 2005, it was about four and a half percent canceled every month. Today it's about 2% cancel every month. So, I'll just put it back to you. Do you think, when we looked at the AB test results... By the way, you can't get this wrong, Lenny, so just relax.

Lenny (12:35):
Excellent.

Gibson Biddle (12:35):
Do you think the Perfect New Release Experience improved retention?

Lenny (12:40):
My guess is, because you're telling this story, it's going to be a surprise, and I would guess that it did not.

Gibson Biddle (12:45):
Okay, so your guess is we won't see an improvement in retention. And I'm guessing people listening to us right now, there's going to be some folks that, oh, shit, yes, that's what everybody's asking for. Of course we should deliver it to them, right? Well, in this case, both right, right? We saw a very small change in retention. That was the surprise. And so, it went from something like 4.5% canceled in the control. It was 4.45. Very small change. We can measure it.

Gibson Biddle (13:13):
And so, now you get in the math of delight versus margin. If you push this out to all million customers, you would essentially save 5,000 customers. And so, what's the value in saving 5,000 customers? The way we valued it, we said, well we've got 5,000 customers. The lifetime value of a customer then was a hundred bucks. And then we multiplied it by two, which is our word of mouth factor. So our theory was, if you loved it, Lenny, you'd tell your friends about it, you'd rave about it, and you'd bring in one other customer for free into Netflix. And so, we used this 2X word of mouth factor. And so if you do that math, it was worth about a million bucks to us as a company.

Gibson Biddle (13:52):
So now you get into, okay, what's the cost of that additional inventory? And the answer was $5 million bucks. So on one hand, you're bringing in a million bucks of value by retaining more customers, but you're spending $5 million more, so it doesn't seem to make sense.

Gibson Biddle (14:06):
Okay, so easy question. I don't overthink this one, Lenny. Would you roll this out to all customers?

Lenny (14:10):
I would not.

Gibson Biddle (14:11):
You would not. Okay. Can you help build an argument for somebody who would choose to roll it out?

Lenny (14:17):
Oh, no. Give me the hint. I'll take it.

Gibson Biddle (14:18):
The hint was, there was an assumption in my formula. I said 5,000 customers times $100 bucks lifetime value, times a 2X word of mouth. So the argument for why somebody might do it, they disagree with the 2X word of mouth, and what the algorithm is.

Lenny (14:33):
Yeah, I see where this is going. Basically, the experience is so much better that word of mouth increases. It's so delightful.

Gibson Biddle (14:38):
Yeah. Amazon would use a 10X, right? And so, sort of a wash there. You'd probably lean forward and do it. We actually worked hard to try to isolate what that word of mouth factor was. It was really frustrating. And then, the reality was, Barry McCarthy was the CFO. He was apoplectic about the idea of using a 2X, because it means you'll invest more in building a better product. If you let the product team use 10x, Barry's like, "We don't have the money. We don't have the money to spend $5 million on DVDs."

Gibson Biddle (15:03):
Anyways, this is where we sort of refined our thinking about the model of delighting customers in hard to copy, margin enhancing ways. Pop quiz, I know the answer, Lenny, but want everybody else thinking about it. What makes Netflix hard to copy?

Lenny (15:18):
The licensing deals and content that they're creating.

Gibson Biddle (15:22):
Original content, yeah. Keep going.

Lenny (15:24):
Their brand that they've built over time.

Gibson Biddle (15:26):
You trust them with their credit card every month for $20 bucks, right?

Lenny (15:28):
Oh, absolutely. I think I've been a customer for five years.

Gibson Biddle (15:31):
Yeah, yeah. What else makes them hard to copy?

Lenny (15:34):
I imagine, their tech that used to be the ranking algorithm recommendation engine.

Gibson Biddle (15:37):
Yeah, so there's unique technology. Personalization is a great example. You just brought that up. There's only one other idea that I think is... Well, there's probably be two others for Netflix. So keep going, dig deep.

Lenny (15:48):
Maybe, I don't know if this is an answer you're thinking, but just the talent they've built up over time is probably something.

Gibson Biddle (15:53):
That's really interesting. People go to culture, and then I sort of specify, what makes the Netflix product hard to copy? So, I won't allow that one.

Lenny (16:01):
Oh, man.

Gibson Biddle (16:02):
Okay, keep going.

Lenny (16:03):
What makes Netflix hard to copy?

Gibson Biddle (16:05):
I'll give you one clue.

Lenny (16:06):
Okay.

Gibson Biddle (16:06):
What made Facebook wicked hard to copy?

Lenny (16:08):
Their network effects and growth loops.

Gibson Biddle (16:12):
Yeah, yeah. We actually tried to experiment with friends and social, getting movie ideas from your friends. The idea is, your friends were on the network, you wouldn't want to leave. And you'd also get great movie ideas. By the way, that was a failed hypothesis.

Lenny (16:25):
Right, I was just going to say, I remember that did not work out. I don't see it anywhere.

Gibson Biddle (16:28):
Yeah. It did not work out. Yeah, I guess we could make an argument today, every screen in the world is magically prewired so you can watch Netflix anytime, anywhere. There's sort of a kind of flywheel or network effect at work. But anyways, that's great. So, that's just a model. But I have found that model to be helpful in my thinking a bunch of times.

Lenny (16:44):
There's a couple things I wanted to follow up on there, because there's a lot there. One is this idea of testing the ideal almost, and kind of working backwards from that. That's something I always find found really helpful. Is that something that you espouse and find to be really powerful?

Gibson Biddle (16:58):
Honestly, I think of these product strategies as these high level theories, these hypotheses about how you will delight customers in hard to copy, margin enhancing ways. I just gave a failed hypothesis, the social one. You actually brought up a winning hypothesis. Personalization delights customers, because it makes it easier to find movies you'll love. It's hard to copy. Netflix sort of knows the movie tastes of a billion people worldwide. That's 222 members times about five profiles per. And then the margin, this is an interesting one.

Gibson Biddle (17:27):
When Netflix is making an investment in a TV show or movie, they kind of can guess how many people will watch it. So, they guessed that 100 million people would watch Stranger Things, so they were willing to invest $500 million. They guessed that 20 million people would watch BoJack Horseman, I'm a freak, so they're willing to make $100 million. I call that right sizing the investment, but that's how personalization helps Netflix to build margin, or to build a better business.

Gibson Biddle (17:54):
Anyways, back to your original question. I mainly was just trying to find these high level theories and hypotheses that I hoped would delight in hard to copy, margin enhancing ways. The reality was, we'd have 10 ideas and probably six of them would fail, but a lot of value in the three or the four that worked.

Gibson Biddle (18:10):
When we went to TV based systems, we actually couldn't A/B test at first, so we were going back to qual and they were looking over people's shoulders, and focus groups, et cetera. But eventually, Netflix could A/B test what's a good experience on a TV based system. They have server based systems now where they can create different experiences for different folks. So I guess my short answer was, so hard to find these product strategies that worked. There was no notion of building a perfect experience of all these things together, so we just took it one theory at a time.

Lenny (18:40):
Got it. And then, on that concept of delight, I always wanted to ask you this question. I've never had a chance. For B2B, do you find this is also something companies should really prioritize and do? Because not a lot of B2B products are delightful, and a lot of them are still really successful. How do you think about that kind of framework in B2B?

Gibson Biddle (18:55):
Okay, first, I think that most all of the frameworks I use work for both consumer and B2B. Personally, I've spent my whole career on consumer. The thing about consumer is, you're sort of trying to catch lightning in a bottle, right? Where enterprise, you can actually walk into it a little bit more thoughtfully. You can always find your first customers, et cetera.

Gibson Biddle (19:15):
Anyways, I was thinking about what's different. For instance, one of the hard to copy advantages of B2B is switching costs, right? I didn't bring that up in the context of Netflix. It's wicked hard to cancel. It's wicked easy to cancel Netflix and restart Disney+, whatever you want to do.

Gibson Biddle (19:29):
I was thinking about, I used to complain that the user interface for B2B software was horrible, and it's like, you've got to do better than this. And of course, at Netflix we proved that a simple, easy experience actually improves retention. So I would advocate, this is important, and they would explain to me all the basics. Hey, Gib. Actually, one of the basics surprised me. The people that are using our software are using it 10, 12, 14 hours a day. That's very different from a Netflix experience. And in fact, they want and need to engage in the complexity. There's stuff that they're trying to do that is really complex.

Gibson Biddle (20:07):
You can just think about our use of spreadsheets to build a cash flow statement. I'm highlighting some differences, but the model I think is still there. If you're starting a punk B2B SaaS company, I think at the end of the day, you're trying to find something that's 10X better than what's currently out there today, and then over time, your hard to copy advantage. It will be different from Netflix. It'll be different for every startup. But if you can delight your customers in these hard to copy ways, that also builds a business.

Gibson Biddle (20:36):
I mean, the reason you do that, you want to feel like you don't have to compete with peeps, really. You don't like it when you're always on guard about what your competitors should do. You sort of want to get to this place where you don't really care, and your sort of true North is okay, how can we best serve our customer? And that's what I really love about that particular model.

Gibson Biddle (20:53):
Lenny, I would be very careful about anything I say about enterprise and B2B, because I've spent zero hours in this, okay? Now, you said half of my audience is in B2B and enterprise, and you hear a lot about the consumerization of enterprise software, and I think that's good. I think that's helpful and important.

Lenny (21:13):
Awesome. That's a really helpful caveat for folks listening, that if you're building a B2B business, maybe don't follow all this advice to the letter. But I imagine there's still a lot you can pull out.

Gibson Biddle (21:21):
Well, honestly, it's so idiosyncratic. It's going to be different for each company, or each startup, or different stage. And that's why the tools, the models, the frameworks I use, they have to work generally, but then people have to apply their own good judgment.

Lenny (21:33):
Sweet. Okay. What I'd love to do is get a little more concrete using this model, and go through a few examples of how you may have thought through problems you were tackling at Netflix through this lens, to kind of see how it actually works in practice. Does that sound good?

Gibson Biddle (21:48):
That sounds like we're going to do some rapid fire mini cases.

Lenny (21:50):
That's exactly right.

Gibson Biddle (21:51):
And I'm going to put you in the hot seat, Lenny. You're the proxy for the listeners today.

Lenny (21:55):
All right. Just make sure they're easy questions.

Gibson Biddle (21:58):
No matter what you say, I'll make you look smart.

Lenny (22:01):
I like this. I just want that applied to all of life. Okay, so the first mini case study is something that I've seen a lot of people build, kind of hack together, is this idea of watching Netflix together with friends. I think one app is called Netflix Party. So the question there is, should Netflix launch a Netflix Party feature? Basically letting people watch Netflix together but in different places?

Gibson Biddle (22:22):
Yeah, yeah. It's kind of a real case. A bunch of engineers at Patreon, six or seven of them, they actually enabled, if you're using Netflix, they let you connect with your friends on Netflix, watch the same TV show or movie at the same time, and chat with each other while you're watching it, trash talk each other or use emojis, what have you. They called it Netflix party. The Netflix lawyers noticed it, and so they renamed it Teleparty. It exists. You can use it across multiple games, across Disney and Netflix, whatever you want.

Gibson Biddle (22:52):
Okay, so the hypothesis is, Netflix should launch this idea for real, not just download the silver light, download the...

Lenny (23:01):
Chrome extension?

Gibson Biddle (23:02):
Chrome extension. There you go.

Lenny (23:03):
Yeah, yeah, yeah. I think I've tried it, actually. It's pretty cool.

Gibson Biddle (23:06):
Yeah. It's complicated, right? I mean, you and I are both freaks, so we can figure it out. So the idea is that we'll delight customers, because this sounds like fun, especially during COVID. We can have this connected experience when we're also disconnected. Hard to copy advantage. We're kind of building a network effect. You and I will be connected and watching on Netflix. We don't want to quit because we don't want to leave each other behind. And then, the margin. For Netflix, it's largely about will it improve retention? Netflix today, 2% are canceling. Netflix has just ticked away at it point by point. It's just, it's these kinds of things that create a little bit more value, that improve retention.

Gibson Biddle (23:45):
The way I think about this is, the way that addition of this feature would actually improve retention is if some reasonable number of customers actually used it. And so, what I look out for is, I don't like two percenters. So if you find an idea that only works for 2% of your customers, now you're creating complexity, one more thing to choose. What happens when I hit this button?

Gibson Biddle (24:10):
And frankly, some complexity that everybody else building the product forgets, right? This happened to me a lot. We'd have, in the old days, there was a profiles feature. When we launched streaming, we forgot about the profiles feature for DVD. Like, oh, crap. So, as a rule, I never used rules as thumbs, but these two percenters, I would kill them. If I launched something and it was only 2% we'd, we called it scraping the barnacles, just get rid of it.

Gibson Biddle (24:34):
So, I think the key question here is, what percent of Netflix members would use Netflix Party if you launched to all? You want to guess at that, Lenny?

Lenny (24:44):
Let's say 5%.

Gibson Biddle (24:46):
5%. Okay. I think that's good guess. I'm going to give you some historical context. We actually did Xbox Party back in 2008, 2009. My guess with the Xbox team was it would be a two percenter. I think it barely squeaked to 5%. And then, because it was only at 5%, we killed it. So I think that's a great guess. If you had said 10 or 15%, then I would've been scratching my head. Could that actually have a shot at improving retention?

Gibson Biddle (25:14):
Anyways, Netflix hasn't launched this. They could, of course, test it, but I think the history, the failed hypothesis of social, kind of leans against it, and I just gave you two examples. The friends network getting, giving ideas of friends and Netflix, and the second, the Xbox Party. Those are two failed instances of social. Netflix will keep experimenting with this, but in this case they chose not to. So, not enough delight despite the fact that it could build hard to copy advantage. And if you don't have enough delight, enough usage, there's no shot at improving margin.

Gibson Biddle (25:45):
Okay. You were awesome, Lenny. I told you, you sounded exceedingly smart. Okay, what do you got? What's the next one?

Lenny (25:51):
Nailed it. Just real quick, I really like the reminder of just focusing on reach and making... As good as the idea might be, just always coming back to what is the reach of this thing? Even if conversion increases like 50%, if like 10 people see it, it doesn't really matter.

Gibson Biddle (26:05):
Yeah.

Lenny (26:05):
That's such a good reminder.

Gibson Biddle (26:06):
Cool.

Lenny (26:06):
Okay, next one is, something that you've shared is that during COVID, Netflix auto-canceled, apparently, something like half a percent of its members because they were inactive. And so, the question there would be, why do they do that, and how would Netflix have thought about that?

Gibson Biddle (26:20):
Yeah. Probably seen Netflix's stock history. But the beginning of COVID, they thought they were going to have 8 million new members, Q1 2020. They picked up 16 million. So, that was awesome. It was about that time that my perception as the product manager at Netflix was looking at the data focused on non-member experience, I think his name is Eddie Woo. And he was looking at the data, and he noticed half percent of the members weren't actually enjoying the service, like for a year. They clearly had entered their credit card, their email a year ago, and then just forgot that they had the service.

Gibson Biddle (26:51):
And so, when he thought about it, he said, you know, I feel like it's the right thing to actually auto cancel people who aren't using the service they're paying. Of course, he was doing it a time where there was great growth, okay? So, let's use the delight and hard to copy margin enhancing model. Is this a delightful thing to do?

Lenny (27:10):
Absolutely. I feel really good.

Gibson Biddle (27:11):
That's my question. Okay.

Lenny (27:11):
Yeah, if a company's like, hey, okay, here, take your money back. You're not using this thing.

Gibson Biddle (27:15):
Exactly. And what's the hard to copy advantage that you'd be building by engaging in this best practice?

Lenny (27:22):
I imagine there's kind of a brand halo, just you feel good about Netflix being really good to you.

Gibson Biddle (27:27):
Totally. So if I told you, and this is the case, Netflix chose to auto cancel these folks like, huh, that's a really cool thing to do. And then the margin, the bad news, you're going to lose a hundred million bucks. So, there is delight, there is hard to copy advantage, and you're going to lose a hundred million bucks. Does that delight and hard to copy advantage outweigh the negative of losing a hundred million?

Gibson Biddle (27:50):
I'm just going to ask you two more questions. Is this a high stakes decision or a low stakes decision? Eddie's decision to auto cancel these folks and lose a hundred million bucks. High stakes or low stakes? You're the product manager, Lenny.

Lenny (28:04):
It all depends on how much a hundred million is worth to the business. I imagine Netflix is such a large scale where it's not a huge deal, and it's a one off that's not recurring, and so you could give it a shot.

Gibson Biddle (28:13):
Okay, so you've skipped ahead. You're looking too smart. On magnitude, it's a hundred million against a company that's doing 30 billion in revenue. And then, the second thing you brought up is, it's reversible, which is, he could do it now, but he doesn't have to continue this practice forever. And so, my joke there, I got married 30 years ago. I was anxious about getting married. My friend said, "Gib, if it doesn't work out you can always get divorced." So they're saying it's reversible. Now I've been married 30 years, so it's worked out.

Gibson Biddle (28:39):
But my point here is, as product managers, we feel like every decision we make is high stakes. It's good occasionally to think about, hey, what's the magnitude? And then, is it reversible? Amazon calls those, this was a two-way door decision. It's reversible. The one way door, those are the bigger deal. And I think frankly, most people would argue that getting married is a one way door, but hey, half of folks don't.

Lenny (29:01):
Yeah, very hard to reverse. Reversible but expensive.

Gibson Biddle (29:04):
Okay, what else you got?

Lenny (29:05):
Okay, so you touched on Netflix's recent troubles with growth. And so, something that's always come up is this idea of why don't they offer a really cheap plan, or a free plan that's advertise supported. And so, I imagine you've thought about that a lot, and Netflix has thought about that a lot. How does that work with your framework?

Gibson Biddle (29:21):
Well, let's fast forward two years. Netflix earnings Q1 2022 were bad. For the first time in 10 years, they actually lost customers, and they'd like to get the growth going again. Okay, that's a different context, right? Today.

Lenny (29:37):
This episode is brought to you by PostHog. PostHog offers a suite of product analysis tools, including funnels, heat maps, session recording and experimentation, all in one easy to use platform. PostHog is open source, so you can host it on your own infrastructure, which means that you have control over who has access to your data and makes regulatory compliance a breeze, because you don't need to send user info to third parties.

Lenny (30:00):
Post Hog's app system works seamlessly with your data warehouse, both for importing and exporting data, which enables you to bring your data into one place and easily understand user behavior across a range of touchpoints. If you'd like to learn more, check them out at PostHog.com/Lenny.

Gibson Biddle (30:18):
So your question is, should Netflix have a lower-priced, advertising-supported plan?

Lenny (30:25):
Okay, great.

Gibson Biddle (30:25):
Okay, let's do it. We'll DHM it. Would an ad-supported plan that's lower price be delightful for customers, Lenny?

Lenny (30:33):
I don't know if delightful is the right word, but if I didn't have a lot of cash, it would feel really nice to be able to use Netflix.

Gibson Biddle (30:39):
Okay, so the possible delight is, it might only cost you five bucks, or who knows, it might be free, I don't know. But for a set of customers who are ad tolerant, that might be a reasonable trade off, right? You don't have to pay $10 or $15 or $20 bucks. You could pay maybe five, or two? I don't really know what the right price is.

Gibson Biddle (30:56):
Okay, so the next one is, would Netflix be building hard to copy advantage if they did this?

Lenny (31:00):
I guess the hards of copy pieces, if there's a network effect, they just accelerate that further, and that gives them some advantage. I don't know.

Gibson Biddle (31:06):
Maybe. So if they pick up a new set of people, a new set of profiles, it's a technical term, as you get big, is you build economies of scale. So if they are able to grow, Netflix, they'll spend about $18 billion on content this year, whereas poor Amazon will only spend $8 billion. I just love saying poor Amazon. Because Netflix can amortize it across 220 million members. So, more growth, more customers, and hopefully a different segment of customers that they haven't gotten yet, so it's not just cannibalistic, could build more hard copy advantage.

Gibson Biddle (31:39):
My argument, I'm just going to skip ahead, if you cross fingers, I mean, you are picking up a new customer profile, new customer type, so you're going to have incremental revenues, which is really what Netflix is looking for. For me, I just want to tell you why Netflix hasn't done advertising yet. We actually did do it, 5, 6, 7, 8... 2005 through 2008. We put big-ass ad banners on every page on the site, even for the members. We did a retention test, and it actually did not hurt retention. A big surprise. And that was the first year that we generated an operating income of $20 million bucks. It was like the first profitable year.

Gibson Biddle (32:14):
We also did this at our business. We were selling used discs, previously viewed discs. That's how we first made money, and Reed Hastings, the CEO, came to me in 2008 and said, "Gib, I need you to kill advertising and previously viewed, because I think we can deliver a profit in our core business." And he wanted to keep things simple, create this simple experience that's part of a subscription.

Gibson Biddle (32:34):
You have had this. We had a lot of pride and ownership. He didn't involve me in the decision, all of these things, right? He's just sort of sticking a gun to my head. He only asked me two questions. He said, "Gib, who's going to be the best in the world at advertising?" And I said, "Google." And then his second question is, "Who needs to be the best in the world of personalization?" I said, "We do." And his argument was to kill previously viewed and advertising to create a simple experience for the customers, and so that we could stay manically focused on personalization.

Gibson Biddle (33:02):
Now fast forward, so on the earnings call, for him, the debate is really between simplicity, which he's a huge fan of. But during the earnings call he said, "Actually, there's something I believe in even more, and that's customer choice." And he was saying, you know what? I think for this new set of customers, giving them the choice to have a $5 a month plan with advertising... He did not say the $5 bucks. I'm just plugging that in. In this case, customer choice may be more important than delight. And in this case, rather, customer choice may be more important than the complexity of advertising, or maybe the stinky experience.

Gibson Biddle (33:39):
Whew. There's something important. What he said is, today it's relatively straightforward to execute an advertising-based business doing this. There's a zillion partners who could do it, so we could continue to focus on the core of what we do, which is personalization. Which I thought was a really thoughtful response. So my guess is, they will do advertising, but he was very contrite. Stock had half of its value. He felt he had disappointed shareholders. So I think he was looking for ways to earn back that trust.

Lenny (34:05):
Yeah. The market sometimes forces you to do something you didn't expect. I really like the Socratic Method that Reed uses in the story you shared, where he kind of asks you these questions that help you get to the same conclusion he got to.

Gibson Biddle (34:16):
Honestly, I reflected on that for five years. Why didn't he engage me in the decision? And then I just realized... I mean, by the way, this being a CEO is a really hard job. But I realized I had so much pride and ownership, he just knew that I wouldn't want to kill it, that it would be hard for me to be objective. And he felt strongly that he believed he knew the right answer and said, hey, I just need you to do this. And he was right. So, it took me five years to process that, but there's a lot of things you do to support the CEO, because that job is really hard.

Lenny (34:47):
We're going to talk a bit about the role of a CPO and what you learned on that journey, but one final mini case study. Should Netflix charge for customers to share their accounts with other people, outside of their home, especially?

Gibson Biddle (34:59):
Yeah, this one's got a lot of history. Okay, so I sort of told you a bit of the story, which is Netflix's growth has been excellent until now, and the reason they had that challenging earnings call is, it was just really hard to forecast. They had the influx of customers at the beginning of COVID, I call them fence sitters, that just happened to join en masse. And then, are they going to leave when COVID lifts? Are they going to leave when the theaters open up again? They shut down, for 700,000 Russian members, they shut off the service. You can imagine that in Eastern and central Europe, churn was a little higher than expected. Just nasty.

Gibson Biddle (35:38):
One of the things that this cloud of COVID forecasting did, obscured how the large extent to which sharing happens. And so, what they said was, in the US and Canada, there's a hundred million customers total. They think there's about 30 million folks that are sharing their email password outside the home.

Gibson Biddle (35:57):
So, how did Netflix get here? Netflix generally, they've got three prices, $10, $15 and $20 bucks, and they're always trying to give people reason for choosing the $20 one. And so, if you looked at their, I call it the price and plan page, it looks like a gas pump. Do you want to the left one, the middle one, or the right hand one? One of the incentives that they provided for folks to choose the $20 a month was the number of multiple streams. They had gone all the way to four streams at the same time. So in my household, four people could be watching the same time.

Gibson Biddle (36:27):
And of course people shared outside the house, right? And by the way, I don't think Netflix was clear that you couldn't. So now, if you look at the price and plan page today, they're not sort of pitching for multiple streams as the reason you should go to $20 bucks. They're pitching other things. There's better resolution. That's the key one. Better sound quality. You're going to have HDR sound and video. And then, they did clarify in the fine print that you can use one, two, or four streams for members in your household.

Gibson Biddle (37:00):
And that was a new clarification, because it used to be kind of with a family. Kelsey and Brit are my daughters. They're in the house, of course they can use it. They go off to college, they're still my daughters, they're part of the family. Of course they can use it. Kelsey gets married. Okay, so this is the first time they clarified it.

Gibson Biddle (37:14):
So now, I come all the way back to your question. As a potential growth opportunity, they'd obviously like to clarify how this should work, and they started testing in three different countries. Peru is one, and I think in the Caribbean. These smaller countries, I'm sure they're focused with new members to figure this out first. And so, they have two different things. You could let a person outside your household, you could actually pay a little extra for them as the primary, as the sponsor, if you will. And the other is a function where a person who's sharing your account in a different household can bump up to their own membership.

Gibson Biddle (37:48):
So, this is just complicated. Can I make the DHM model work with this? Well it explains why they did it. They were giving multiple streams because it was a really delightful experience. And Netflix says it in the rules. They were very permissive. I don't really think they worried about this. Was it building hard to copy advantage? Absolutely. More taste profiles, right? And you wouldn't leave because you didn't want to cancel the service to your daughter's and using out on the east coast. And was it building margin? Actually, it was driving people up to the $20 price point, and it was improving churn. You're getting more value out of service, okay?

Gibson Biddle (38:21):
So now, what do they do? For me, this is just testing and math. Like, honestly, let's try it, Lenny. Well, think about those 30 million folks. If you get an email saying, hey, we've noticed you're enjoying the service on somebody else's nickel, would you like to upgrade to your own plan? What percent of those folks are going to say yes, right? I mean, do you have a guess on that? I don't have a guess and I don't have an answer. But this is the game, right?

Lenny (38:47):
I find with emails, open rates and all these things, it ends up always being really tiny. So I guess, again, probably 5%, maybe 3%.

Gibson Biddle (38:54):
Okay. I think that's a fine guess. I'll just give you a different perspective. This is kind of like a free trial, right? they've been using a free trial. And the free trial conversion at the end of a month was 90% at Netflix, right? 90% enjoyed their first month so much that they continued with the service.

Gibson Biddle (39:13):
So, I mean, I agree with you, it might be five or 10%. I was just giving you that 90% to get you to imagine, huh, maybe it could be 10%, right? Maybe it could be 20%. This is just speculation. I think they're experimenting in these smaller countries. As we do this, if it were 10%, they'd pick up an additional 3 million in a quarter. I think that's going to help them when their growth is at a standstill.

Gibson Biddle (39:36):
The other question would be, would the primary account quit when you tell them their daughters on the east coast can no longer use the service, right?

Lenny (39:45):
Right.

Gibson Biddle (39:46):
I think where I'm going on this is, I don't know if we can give any real insight. The team at Netflix, this is what they live for, and the team at Netflix is testing and experimenting. They've probably put in an assumption like yours, 5% will convert, and now they're seeing if they're right or wrong, and they're figuring it in on these smaller countries, and a year or two from now, they will have worked it all out and we'll see the answer in North America. But I think it's going to take them a year or two to figure this out, because it's really hard. But they're keenly motivated, because they're trying to get the growth going again.

Lenny (40:17):
I was trying to watch Super Pumped on Showtime recently, and Showtime wasn't working, and I have to call my dad, because I'm leaching off their cable login account. And turned out that they moved and they changed their cable plan, and I'm probably the reason they're keeping a lot of it.

Gibson Biddle (40:32):
Well, so, Lenny, I was thinking about it. I'm open. I don't know the answer on this one, but just you and me comparing notes, what do you think? This is the kind of behavior that I love all product leaders to engage in. I call it building your personal board of directors. You're on mine, because I've been learning a lot about newsletters from you, right? Super helpful.

Gibson Biddle (40:51):
But when I would have questions like these, I would reach out to my pals, like, okay, what's the right level of investment on a mobile app versus desktop? That was a moving target for years. And I would just text my pals, and they would just give me the data. That's amazing insight, just by having peers in the business that you talk to, which this is the behavior that I want everybody out there engaged in. I call it building your personal board of directors.

Lenny (41:14):
I'd love to hear a little bit more on that, actually. How do people do that? Is it pick a few people on a topic and have them as your standing board?

Gibson Biddle (41:21):
I didn't even know I was doing this. This concept began for me, I was probably 30-ish. 30, yep. I got promoted to VP and I asked my CEO, "How do I learn how to do the job well?" And he said, "I don't know. Reach out and build your community of peers." Like, oh, that was good advice. It really was.

Gibson Biddle (41:39):
So, at any moment in time... You actually had one of my board members on a podcast, Melissa Perri. She's on my board, right?

Lenny (41:46):
Amazing.

Gibson Biddle (41:46):
Yeah, you voted for her. So, short answer is, it's really easy to build your community of peers. Just keep up your former colleagues. Keep up on LinkedIn. The harder part is building the mentors. And the first rule of thumb is, don't ask a person to be your mentor. That's really awkward. First, identify them. Say, this is a person I think that could be helpful to me. And then, find ways to be helpful. Everybody needs help. Everybody, everybody, everybody.

Gibson Biddle (42:13):
So, to help you understand the kind of help I need, my greatest fear is aging ungracefully, right? So I'm trying to understand what's going on. Okay, I asked you earlier, should I be on Discord, right? Like, oh, crap, do I have to be on Discord? But in many cases, somebody can help me to understand Discord. That's super helpful to me. And that's how those sort of mentor relationships eventually end up, and between the peers and the mentors, the mentors can help you to see around corners.

Gibson Biddle (42:43):
Actually, my favorite story of somebody who did approach me, they were in data, they wanted to be in product. They kept asking me, "Hey, do you have any startups I can work with on the weekends?" That's a good idea. I didn't have any answers. I got sort of frustrated with them. I said, "Just build me a website, a baby website." He said, "I can't build a website." So I gave him my credit card and said, "Get on Squarespace." If you go to GibsonBiddle.com, that's my baby website that John Lou built for me. That was incredibly helpful to me. Someday I should get a real one, but I've decided it's not that important.

Lenny (43:13):
I also have a baby website on Squarespace.

Gibson Biddle (43:15):
Exactly.

Lenny (43:16):
We're in good company.

Gibson Biddle (43:17):
Anyways, that's the concept of a personal board of directors. It's really important and helpful career advice in the long term.

Lenny (43:23):
Awesome. I'm glad we chatted about that. That wasn't something we planned to chat About. Something else I wanted to dive into, beyond strategy, is prioritization. You have a really great model for our prioritization called the JAM model, that I share often with folks. I'd love to just kind of hear your overview of this model, and when it makes sense, and just roughly how to use it.

Gibson Biddle (43:39):
Yeah, well, it's a lot easier because it spells something, right? As opposed to saying... I'll just give you a good case. I joined Chegg 2010. We were inventing a concept of renting textbooks to students instead of buying them, saving them a lot of money. And my first week was challenging, because on one end of the hall, the CEO, Dan, was saying, "Grow, baby. Grow. The most important thing we can do as a startup is grow." And at the other end of the hall, I had my CFO partner, Greg, saying, "Slow, slow, slow. We actually don't know if we have a business model that works." And I could tell he was sort of, the company's got like 40 people, sort of driving folks crazy.

Gibson Biddle (44:15):
So, as the product leader, what the heck should I do? And the answer was, I got them in a room and I said, "Listen, I just need you to force rank these three factors for me: growth, engagement, and monetization. And I need the two of you to agree." So, you could say growth is most important. When we say growth, it's basically year over year customer growth. Do you want it to be 50% or 10%?

Gibson Biddle (44:40):
Whatever the answer is, engagement is how I think about product quality. A more engaging product is a better product. So if you think investing in building a better product is super important, then you go with engagement, and the proxy metric that I use for that at Netflix was retention. And then, the third is monetization. You have these customers, you have this product, and how much effort do you put into turning that into a business?

Gibson Biddle (45:04):
So, Dan said, "Well, that's easy. Growth, engagement, and monetization." And Greg said, "Yeah, that's easy. Monetization, engagement and growth." He did the flip, right? I'm like, "I'm going to come back in two hours. You guys got to fight this out." Which is sort of what happened.

Gibson Biddle (45:19):
So, they agreed on growth first, engagement second, monetization third. And then, a couple months later, it started to happen again. Greg started to say, "No, no, no." And so, it was that point that Greg actually left the company. Which was, these are the kinds of fundamental misalignments that can wreck startups. I'm not saying that one or the other was right or wrong, but as leaders in the organization, we've got to get some of the basic stories straight, including how do we fundamentally prioritize growth versus engagement versus monetization?

Gibson Biddle (45:56):
This is really the number one source of misalignment that I discover among startups. And startups, you're always flipping back and forth between growth and engagement. Grow faster, build a better product. Grow fact forth, and then later, you get a little later to monetization. But this model, I find it super helpful to get leaders across an organization fundamentally more aligned.

Lenny (46:17):
So, if you're a PM, or maybe a founder, thinking about using this model, would the first step be get your leaders above you to kind of align with you on, of these three things, here's how we stack rank it?

Gibson Biddle (46:27):
Personally, I'd start with a SWAG. I would take a shot, a stupid, wild-ass guess of what I think is right, so at least I started with a point of view before I shared it with my team. And frankly, the next most important thing that happens is, if you're trying to create a metric focused organization that appreciates data and learning through numbers, deciding, I mean, the hardest one is, what is your engagement metric? How do you measure product quality?

Gibson Biddle (46:52):
At Netflix, it's monthly retention, but that's a hard conversation. The growth story's pretty, like, it's usually some percentage year over year of customer growth. I mean, but it's always different, but the only variation on what you said was, have a point of view yourself, and then get everybody's feedback.

Gibson Biddle (47:07):
That's frankly, when I would join a new company, I would give myself two weeks to develop the product strategy for that company, which is a little outrageous, but I would just do it fast. I would develop the SWAG, but then I'd go to one person. "Hey, this is my best thinking, what do you think?" And of course, they had been there for four years. They were much smarter than I, and they would refine my thinking.

Gibson Biddle (47:25):
I'd do that one by one, and then maybe six weeks later, I could share a product strategy across the company. But this is the value of a SWAG, which is a stupid, wild-ass guess. And don't be afraid to start at that level.

Lenny (47:36):
I really like that strategy, versus going in a little hole, spending months just thinking about the perfect answer, and only then presenting. I find this works better.

Gibson Biddle (47:44):
We're hiring a consulting company to do it. Go shoot me, okay?

Lenny (47:47):
I like that you're hiding your mouth as you say that.

Gibson Biddle (47:50):
Yeah. Only Lenny can see. Yeah, but this is a podcast, Gib. Nobody can see you.

Lenny (47:54):
Yeah. I will reveal. Okay, so on that topic actually, I'd love to transition and talk about our last topic, which is around career, or product manager. So, you're the CPO at two very successful companies, or maybe you're called the VP of product, but roughly a head of product. You have these two muckety mucks, right? Chief Muckety Muck. And in theory, this is kind of the end state of a PM career if you stay along the path. A lot of PMs go on different paths, but in theory, this is kind of where your career is heading. What would you say it takes to become a CPO someday? What kind of skills do you think you need to build that are maybe not obvious to someone that's not in that role yet?

Gibson Biddle (48:28):
Yeah, let's take a little step by step. Individual contributor, and then to manager. When you're just starting, you're just trying to learn the job. And I'd say, at a high level, you're just trying to optimize for learning in your entire career. But for individuals, building products is hard, and there's a number of technical skills that are required. So yes, some technical, but a lot of creative skills. There's some consumer science, that's the A/B testing. There's the management. How do you get people working together to actually build stuff? These are technical design skills, right? These are the technical skills.

Gibson Biddle (48:59):
So, early in your career, you're just trying to learn the job. And by the way, the job is hard. And second, it's different from every company to company in different stage. So you, Lenny and I, we're just trying to be helpful in a leveraged way. But the key thing is, the job's a little different in everything. So, just try to become expert in your area, expert in whatever your one thing is that you're building.

Gibson Biddle (49:19):
And then, the next step to become a manager is, there's a lot of, communication is sort of the heart, and that's why I try to... Product strategy is a great way to communicate what's important and what's not, try to demystify it. If you're early in your career, ask if you could be on interview teams, even if you're not hiring, because then you're starting to practice something that's really important as you want to grow your career later, which is it's really hiring and recruiting people.

Gibson Biddle (49:45):
When I was in the thick of that, I spent one to two days a week hiring and recruiting. It's really the most important thing. And then, some amazing opportunity would come along at the company and they'd say, you know what? Maybe somebody on Gib's team should do it, right? Because they knew I could replace people. There's always somebody new to pop in. So, I really was expert in hiring and recruiting later in your career.

Gibson Biddle (50:07):
If you want to be a muckety muck, my theory is the skills of a leader are the same, whether you're head of product, or the chief financial officer, or head of data. When I'm interviewing any of those kinds of candidates, I am looking for leadership skills. Can they do inspired communication of a vision? I do look for product strategy skills. That helps you to frame what that vision is. I do look for management skills. Have they built and managed teams?

Gibson Biddle (50:38):
I look for people who are proactive, results oriented. For me, leaders lead. You can't be a follower. So, I look for really proactive, results oriented folks. And this is pretty nuanced, but later in career, I look for folks who understand how important culture is, because culture helps people to understand the skills and behaviors that are wanted of everyone within the building, and they let you provide leadership in a highly leveraged way, instead of using evil processes and meetings and rules. I look for people who appreciate culture as a tool to help lead organizations.

Gibson Biddle (51:18):
And then, of course, they had to grow up as a builder. They had to learn all those damn technical skills for product manager. If I abstract outside of all that, honestly, the thing that I probably did best, I think maybe I did three things best. To know me, I was an English major. I'm non-technical, and I didn't care. First I was in marketing, and then I went into product, which I just loved.

Gibson Biddle (51:37):
I think I did a good job with sort of optimizing for learning. Actually, one of my hacks was, I started doing talks. I used to call it Topic This and That, on Friday mornings, about something I had just learned. That was the easiest way for me to learn something. So, optimized for learning.

Gibson Biddle (51:50):
We talked about building a personal board of directors, and that has been incredibly helpful for me, and that probably gets to the third thing. I was a pretty good picker, and the reason I was a good picker of companies is, I would lean on my personal board of directors. Some of them were CFOs. I'm like, "Hey, Barry, I'm thinking about joining this startup, Chegg." Hey, as a CFO, as a VC, would you invest in it, right? It's the same question I have to ask, should I invest my time?

Gibson Biddle (52:16):
So, I had people like that who helped me to isolate, was Electronic Arts a good company to join in 1991? Yes. Was Netflix a good company join in 2005? Yes. Was Chegg a good company to join in 2010? Yes. So, I was fundamentally a good picker, and I would really give a lot of credit to that personal board of directors that I had for that.

Lenny (52:36):
What about just day to day as a PM, what have you found to be really good habits, and kind of like a routine that PMs follow, that you've seen to kind of contribute to the success of an ICPM, especially?

Gibson Biddle (52:49):
My short answer is, begin your day with intent, okay? What are the three to five things I'm hoping to do today? Second, minimize meetings, okay? Minimize meetings. That sucks the life out of everybody, including you.

Gibson Biddle (53:03):
Spend a lot of time with your customers. It could be focus groups, it could be usability, it could be looking at survey data, it could be digging the dirt to understand their behavior to the data, and it could be designing and executing A/B test results. Those are all ways of becoming the voice of your customer, and that's a big part of your job as a product leader.

Gibson Biddle (53:24):
Find a balance between doing and thinking. Most of us do, do, do. Occasionally stop and ask yourself, okay, what's important here? What should I really be doing right now, as opposed to the things that I enjoy doing? Self-managing yourself. The only reason people need managers is that we need someone to force us to do the things that are important that we don't enjoy doing. So, I'm always self-managing myself. Gib, you have to do an invoice. Crap, I've got to bill people. That's no fun, right?

Lenny (53:56):
That inside voice, inside Gib.

Gibson Biddle (53:57):
Yeah, that invoice voice. Yeah, our in-voice. Gib, you should write a damn book.

Lenny (54:02):
Or not.

Gibson Biddle (54:02):
We're ignoring that inside voice. Yeah, you and me both. And then, I don't know, for me, exercise is awesome for me. It keeps me happy. And don't watch too much TV, and I watch too much TV. So, there you go. And don't do what I do. Do what I say.

Lenny (54:17):
Right. Yeah. I also probably watch too much TV. Funny coming from someone that helped build Netflix, but I totally get it. So, too good. It's too good.

Gibson Biddle (54:25):
Well, my wife's trying to cure cancer. She's like, "Oh, congratulations, Gib. You helped invent binge watching, you idiot. What good are you doing for humanity?"

Lenny (54:34):
Oh, man. Brings us delight, and that's valuable.

Gibson Biddle (54:37):
Yeah, yeah. Thank you very much.

Lenny (54:39):
Final question. You've had this illustrious career. What's one piece of advice that you'd give a PM in the beginning stages of their career, and then maybe as a bonus, I want maybe mid stage. What comes to mind?

Gibson Biddle (54:50):
Yeah, I think I did the early stuff. Pick the right company. At some point, understand that you are responsible for your career, not your workplace. And that's one of the reasons I encourage people to start building that personal board of directors, so you can compare notes. The other thing I say is, don't listen to your parents, because they're a generation ahead. They really don't know what the future looks like. I mean, I know I would give bad advice to my daughter, and so don't listen to your parents.

Gibson Biddle (55:16):
And then later, ever since I stopped direct deposit, I think of myself as just purely career hacking. So in your career, it's just a lot like building a product. You have theories and hypotheses, you find ways to experiment with them, and then you were successful or you failed. So one of my hypothesis, whenever it was, six years ago, was I would enjoy teaching. I actually tried it. I taught at Stanford, entrepreneurship for graduate level engineers, and I really liked it, but I didn't love it, largely because I was required to be in Palo Alto every fall. I couldn't travel as much as I like to, right?

Gibson Biddle (55:52):
Okay, so on one hand, okay, don't teach in the classroom, and my next vector was, what if I teach outside the classroom? That's what I really love to do. I do talks, workshops, all around the world in the last two years, virtually. I just love doing that, and I have a ton of flexibility. So, that's just a little example of me treating my career like, what's my hypothesis? Finding where to experiment with, and then, based on the results, do the next thing. And I've really been doing that my entire career,

Gibson Biddle (56:16):
So, if you embrace this idea of experimentation, you're like a product, you need to have hypothesis, you need to try see what works. The next thing you need to do in building a product or building your career is be bold. So, don't wimp out. At some point, when I'm working with different companies, they all kind of get attracted to the small, incremental wins, and they sort of forgot what made them a successful startup in the beginning, which is taking on fundamental risk. And so, I just nicely encourage people to be bold, to go a little bit out of your comfort zone, because that's where you learn more, and that comes back to this idea of optimizing for learning.

Gibson Biddle (56:52):
Anyways, and how do you encourage people to be bold? How do you encourage them to try new things? And the simple thing is, just start. Try it tomorrow. For me, the baby step was when I, on talks, I would just ask my friends if I could drop by and do a talk. I just did it. I didn't overthink it. I didn't spend 97 years setting up my display and getting the right clicker. I just gave a really bad talk. But that's how I started, and then I sort of optimized from there.

Lenny (57:21):
What a perfect way to end our chat. Really inspiring and helpful advice that I'm going to try to re-listen to and use myself. Just to close, where can folks find you, reach out to you, and then also just, how can listeners be useful to you?

Gibson Biddle (57:33):
That's a great question. Thank you. The first, I would say that Lenny has been a mentor for me in "Ask Gib" Product Newsletter. So, I reached out to him via a Twitter and asked him lots of stupid early questions, so he was incredibly helpful. So, probably the most important thing is to know that I write a newsletter every two weeks. That's the cadence I'm on now. Lenny knew me at the beginning when I was doing dailies. He's like, "Dude, don't burn out." It's called Ask Gib. I've answered like 63 questions so far. I really have enjoyed it.

Gibson Biddle (58:04):
Second thing would be my baby website GibsonBiddle.com. I have the advantage of being the only Gibson Biddle on the internet. I'm sure you're the only Lenny, but nobody can spell your last name, right?

Gibson Biddle (58:15):
Yeah, and then the third, how can people be useful? I'm a feedback freak, so you'll notice at the end of every talk I do, every essay, whether you find me on Medium, or Ask Gib, wherever, there's a link to give me feedback. And it's always the same question: On a scale of zero to 10, where zero sucks, 10 is excellent, how likely would you be to recommend this to a friend?

Gibson Biddle (58:38):
That has been incredibly helpful to me, and that's how I've learned to slowly get better at everything I do. The insight I get each day from folks is amazing. And I'll ask one follow up: but what'd you like, and what could be better? And it's just been incredibly helpful. So, don't ignore that link at the end. Don't treat it like United Airlines asking how is your flight? This is important, damn it! And your feedback is incredibly helpful to me, so thank you.

Lenny (59:04):
I'm going to go answer some of your surveys now. Thank you so much for doing this. I learned a ton, and I really appreciate your time.

Gibson Biddle (59:10):
That was great fun, Lenny, and thanks a ton for your help with my Ask Gib newsletter, as well.

Lenny (59:15):
Forever and Ever.

Gibson Biddle (59:16):
Okay, cool. I'll hold you to that.

Lenny (59:19):
That was awesome. Thank you for listening. If you enjoyed the chat, don't forget to subscribe to the podcast. You could also learn more at LennysPodcast.com. I'll see you in the next episode.

---

## Dumbest idea Ive heard to $100M ARR: Inside the rise of Gamma | Grant Lee (co-founder)
**Guest:** Grant Lee  
**Published:** 2025-11-13  
**YouTube:** https://www.youtube.com/watch?v=3H0ngGU5pbM  
**Tags:** pmf, growth, retention, acquisition, onboarding, metrics, prioritization, user research, iteration, a/b testing  

# Dumbest idea Ive heard to $100M ARR: Inside the rise of Gamma | Grant Lee (co-founder)

## Transcript

Grant Lee (00:00:00):
I'm in my third pitch in, I get to the very end of the pitch, feeling pretty good about myself. The investor pauses a little bit, and then just says, "That has to be the worst pitch, worst idea I have ever heard. Not only are you trying to go against incumbents, you're going against incumbents that have massive distribution. You are never going to succeed."

Lenny Rachitsky (00:00:18):
You guys are at over 100 million ARR now, worth over $2 billion. One of the most interesting ways you guys grew early on was influencer marketing.

Grant Lee (00:00:25):
All the initial influencers, I onboarded manually myself. I would jump on a call with each one of them so that they understood what Gamma represented, how to use the product. You want to be able to have them tell you story but in their voice. I think a lot of people think influencer marketing and they'll think these big trendy creators, people that have a million followers. This is the wrong approach. You basically give them a script to read, immediately feels like an ad. That product is not connected really to them in any way. You're much better doing the hard thing, which is hard to scale, finding the thousands of micro influencers that have an audience where your product maybe is actually useful. People really trust what they say. That ends up becoming this wildfire that can spread really, really fast.

Lenny Rachitsky (00:01:04):
Something you talk about it, there is actually a lot of ways to think experimentally, even in the early stages.

Grant Lee (00:01:08):
We would have an idea in the morning, come up with some sort of functional prototype, recruit a bunch of people that are legitimately good prospective users, but have zero skin in the game, ship fast so people can start playing with it. In the afternoon, we're already running pretty full scale experiment. You start actually hearing other people describe their usage of the product. We can also watch them struggle. By the evening or by the next day. We can actually go through all of it together and say, okay, we're going back and we have to fix this. This is not usable and we've done that for everything.

Lenny Rachitsky (00:01:36):
Today my guest is Grant Lee, CEO and co-founder of Gamma. This is a really unique and inspiring, and very tactically useful conversation because Grant is building something that is essentially the dream for most founders. A massive AI startup that's profitable, and has been for a long time, that didn't raise a lot of money for a long time. And as a small team, it's just around 30 people, all who can fit in a small restaurant serving over 50 million users globally.

(00:02:02):
If you're not familiar with Gamma, they're an AI powered presentation and website design tool. They just hit 100 million ARR in just over two years. They're valued at over $2 billion. And unlike a lot of the fast growing AI startups that you hear about, they're growing profitably and sustainably, and in a category that most people did not believe had a huge business opportunity. As you'll hear in the conversation, one investor told Grant, this is the dumbest idea that he has ever heard.

(00:02:29):
In this conversation, Grant shares the very counter-intuitive lessons that he's learned, finding product market fit, how he knew they had product market fit, the specific tactics that helped them grow, including a deep dive into influencer marketing, which blew my mind. Also how they figured out their price, his thoughts on building a GPT wrapper company that is durable, a ton of hiring advice, and so much more. This could honestly have been another two hours of conversation. I suspect we'll do another follow-up conversation next year.

(00:02:56):
If you love this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. It helps tremendously. And if you become an annual subscriber of my newsletter, you get a year free of 16 incredible products, including Devin, Lovable, Replit, Bolt, n8n, Linear, Superhuman, Descript, Wispr Flow, Gamma, Perplexity, Warp, Granola, Magic Patterns, Raycast, ChatPRD, and Mobbin. Head on over to lennysnewsletter.com and click product pass. With that, I bring you Grant Lee after a short word from our sponsors.

(00:03:29):
My podcasts guest and I love talking about craft and taste and agency and product market fit. You know what we don't love talking? About SOC 2. That's where Vanta comes in. Vanta helps companies of all sizes get complying fast and stay that way with industry-leading AI automation and continuous monitoring. Whether you're a startup tackling your first SOC 2 or ISO 27001, or an enterprise managing vendor risk, Vanta's trust management platform makes it quicker, easier, and more scalable. Vanta also helps you complete security questionnaires up to five times faster so that you can win bigger deals sooner. The result, according to a recent IDC study, Vanta customers slashed over $500,000 a year and are three times more productive. Establishing trust isn't optional. Vanta makes it automatic. Get $1,000 off at vanta.com/lenny.

(00:04:24):
Did you know that I have a whole team that helps me with my podcast and with my newsletter. I want everyone on that team to be super happy and thrive in the roles. Justworks knows that your employees are more than just your employees. They're your people. My team is spread out across Colorado, Australia, Nepal, West Africa, and San Francisco. My life would be so incredibly complicated to hire people internationally, to pay people on time, and in their local currencies, and to answer their HR questions 24/7. But with Justworks, it's super easy. Whether you're setting up your own automated payroll, offering premium benefits, or hiring internationally. Justworks offer simple software and 24/7 human support from small business experts for you and your people. They do your human resources right so that you can do right by your people. Justworks, for your people. Grant, thank you so much for being here and welcome to the podcast.

Grant Lee (00:05:19):
Lenny, it's so great to be here. Thank you for having me.

Lenny Rachitsky (00:05:21):
I see your face all the time in my LinkedIn feed. I don't know if you know this is a thing. On these JPMorgan Chase ads. I'm so curious if other people see this or if it's just me. Did you know this was a thing?

Grant Lee (00:05:31):
I think it's maybe once a day now I get a text message and just no message. It's just a screenshot or an image of me doing something in San Francisco on one of these ads that we're seeing. And so yeah, kind of embarrassing, but also we're happy customers of JPMorgan Chase, so trying to represent.

Lenny Rachitsky (00:05:49):
Oh my God, I hope you love them. Because it's always you. There's no one else. It's like Grant.

Grant Lee (00:05:54):
I know. Can I talk to you [inaudible 00:05:56] swap somebody out. I mean that'd be great. I'm totally fine with that.

Lenny Rachitsky (00:05:59):
Okay, so to get serious, the reason I'm really excited to have you here is, unlike a lot of super fast growing AI startups, you are both growing like crazy, you are growing very profitably. We're going to talk about this. You did not raise a ton of money when you started. You waited a long time to raise a bunch of money. You also built a business in a category that I think most people never imagined there was this big of an opportunity. And you're basically, you've achieved the dream of a lot of founders these days, especially people building AI startups.

(00:06:31):
So my goal with this conversation is essentially do an anthropological study of a really successful AI startup. Talk about how you found product market fit, how you grew, all the lessons you've learned along the journey. And I'm going to break this conversation up kind of along the different milestones of the journey. Before we get into the first piece, is there anything that you think is important for people to hear broadly about the story of Gamma?

Grant Lee (00:06:57):
Yeah. Maybe I'll just start with a quick story if that's okay. And it's really just the founding story. So we started the company back in 2020. This is peak pandemic. And even fundraising was just so different. So all of the fundraising was done over Zoom. You were kind of sitting in these Zoom meetings trying to pitch. Many investors you never met in person. So just a different era. And so for us, we're first time founders. I was actually living in London at the time, and so different time zone. I had to do all of my pitches at night. And I have two little kids, so wait for them to go to bed. 8:00 PM. We had a pretty modest flat, so nothing big. I would basically find this little corner between the kitchenette and the laundry room to kind of set up shot, far enough from the kids so they wouldn't be woken up.

(00:07:45):
In between 8:00 PM and like 2:00 AM, I'm just pitching. Trying my best. I had the fake Zoom background so people didn't know where I was, and just pitching. And so really the first day, I'm in my third pitch in, trying to tell the story of Gamma, obviously just starting to get the hang of the pitch. And I get to the very end of the pitch feeling pretty good about myself. And the investor pauses a little bit, and then just says, "That has to be the worst pitch, worst idea I have ever heard. Not only are you trying to go against incumbents, you're going against incumbents that have massive distribution. You are never going to succeed."

(00:08:23):
And so in my head, I'm already kind of shell shocked and thinking what's my rebuttal? And before I could even respond, he hangs up. And so I'm there sitting there thinking about it. And before I could really get down on myself because I had to prepare for the next pitch, I just internalize this feeling that maybe he's right. Maybe something about what he's saying is actually correct. And so for me, I started thinking about, if we're going to succeed in this category, we're going to really have to think about growth from the very beginning. This category is going to be really, really hard to break into.

(00:08:58):
And so we really kind of made this sort of promise to ourselves, that as we continue to build, growth was going to be critically important. And so my thing to your audience is that I don't come from a growth background. So if I can learn growth, anybody can learn growth. And I think especially in this sort of market, hyper competitive, oftentimes very crowded, it's going to be essential.

Lenny Rachitsky (00:09:19):
That is such a fun story. Oh my god. How bad must this investor feel at this point. We won't name names. Just to share some stats, I know this is going to be by the time this launches, this will be out, but you guys are at over 100 million ARR now, worth over $2 billion. A business that, again, most people did not think was going to work in this category.

Grant Lee (00:09:41):
Yeah, thank you. Yeah, we feel super proud to have accomplished that. And again, yeah, I'm excited to share some of the growth tactics and things that worked for us because I think hopefully it'll help others kind of on their journey as well.

Lenny Rachitsky (00:09:53):
Okay. So let's dive into it. Let's talk about product market fit. Tell us the story of just how you found product market fit, and how you knew you found product market fit.

Grant Lee (00:10:02):
Yeah. I'll start by telling kind of the moment where we thought we maybe had product market fit. And I think a lot of founders ask themselves, do we have it or are we not? And I think there's often a sort of temptation to kind of almost fool yourself into thinking you have it. And so we sort of did our first public beta launch, this is back in August of 2022. We launched on Product Hunt, and felt really good. We had what we felt like was a great launch, ended up winning product of the day, product of the week, product of the month. And it was like, wow, I think we have something here.

(00:10:32):
And then we'd look at signups, and you'd get that initial spike in signups, and then they sort of flatten out. We were still getting new users every day, but it was clear we didn't have strong word of mouth. There wasn't strong organic virality. And so if we just kind of played things out, we knew that the product wasn't going to grow on its own. Something was missing there. We didn't have that strong word of mouth so that the product could just continue growing.

(00:10:55):
And so we really asked ourselves, okay, what do we need to change? And the answer is we need to fundamentally change everything. It for us almost became this sort of bet the company sort of moment. Because at that point we were running low on runway. We knew we needed to make progress and we didn't really know what could be done. And so we got everyone together. At this point, the team was just over 12 people. And we said, okay, it's going to be all hands on deck.

(00:11:22):
We are going to do everything we possibly can to make the first 30 seconds of the product feel magical. The moment you land into the product, it has to be great, and it has to be so great that someone that goes through that onboarding is going to tell all their friends. And if we can get that right, then maybe we have a chance at actually doing something in this space. And so we spent three, four months actually after the product launch, we felt great, but we knew we had to go back to the drawing board.

(00:11:48):
We spent the next three, four months actually revamping the entire onboarding experience. And of course, this is also where AI for us kind of played a big role. We actually rebuilt it so that AI was part of the actual onboarding. So every single new user would experience this sort of magic in the first 30 seconds. And so we relaunched, this is end of March 2023. And all of a sudden, we'd go from a few hundred signups a day to now first day it was like a couple thousand, and then the next day would be like 5,000 signups, and then 10,000 signups a day, and then 20,000 signups a day.

(00:12:21):
And then it just kept going up. And we weren't doing any sort of marketing, no advertising. It was all sort of organic word of mouth virality of the product, people using the product and sharing it with others, where we for the first time really felt this pull. We didn't have to do anything. Product was just growing. And it was just such a distinct difference between that feeling and coming out of the Product Hunt launch where we could have fooled ourselves into thinking we have product market fit. I think the temptation would've been, hey, let's just spend more on ads or spend more on marketing. Because we'll just fuel the top of the funnel and everything else will work itself out.

(00:12:53):
I think that would've been a trap. I think that would've led us down to this path of trying to brute force our way into product market fit. And it would just always be sort of a fleeting sort of destination. We would never actually arrive. And so I think we made the tough call, the right call. It was a sort of bet the company moment, and I think on the other side it just felt so different.

Lenny Rachitsky (00:13:11):
Grant, this is exactly what I wanted this conversation to be. I'm so excited. I have so many questions I have to follow up on the stuff you shared before we even get to the rest of the journey. So one is essentially what you're describing is product market fit to you was when organic growth started to really take off, and it was just growing through word of mouth. You weren't doing much because it was so awesome, people were telling their friends about it. Is there anything more there that might be helpful for people to share just to hear about just like, okay, here's what it actually looks like?

Grant Lee (00:13:38):
Yeah, I mean my one piece of advice is when you're early on, your mindset should almost be like you're trying to create a word of mouth machine. If you can get that part right, everything else becomes significantly easier. And if you have any, and I think this applies to both prosumer, B2C, as well as even B2B products, if you have a B2B product, even if you're not telling all of your friends, you should be telling colleagues where that product is relevant. You should probably be telling former coworkers where, hey, you've discovered something like, oh, I wish we had this in our prior lives, and that should even be magical.

(00:14:14):
And then you should see that in all the leads that are coming through or people coming through through your prospects and your existing customers. If you're not seeing a healthy chunk of those leads come through that way, I would go back. I'm like, why? Why is that not happening? Because again, that's the massive tailwind you need where every single thing you do on top of that, all the marketing, all the sales, all the advertising, you're just going to have it becomes way, way easier.

Lenny Rachitsky (00:14:36):
How much of this was, you described it as a word of mouth machine, how much of this was word of mouth loops and virality features versus just the product itself? One was awesome and two is kind of innately shareable because it's presentations people share with each other.

Grant Lee (00:14:50):
Yeah, totally. I think for us, we do benefit from being in a category where, by nature of it, if you like Gamma, you're sharing it, presenting it to others. So I think for us it's a combination of both. And ideally, you have other ways where word of mouth or organic virality can happen in your product. So by nature of usage, like it's being shared.

(00:15:09):
We basically had an internal mantra that, we go back to the first 30 seconds, we want it to be dead simple for someone to create content, we want to be dead simple for them to share it. And everything we did for that first 30 seconds, or call it the first few minutes, is remove friction so that they can do both of those things. Create and share. And I think other people, when you look at your own product, you think about, okay, what is it about my product and how it gets used? Can you remove friction such that it can actually spread, and even if it's locally within an organization or within a workspace, just be able to enable that as much as you possibly can.

Lenny Rachitsky (00:15:43):
The other really profound point you're making here is the story of you won product of the day on Product Hunt, which alone is so hard. So many people try to win and don't. Most people don't. I've tried to help companies win, and it's a really hard thing to achieve. And then you won product of the week and product of the month, and still you're like, no, this isn't working. Most people that achieve that are like, no, we got this, and they would not have to bet the company. There wouldn't be a feeling that we have to rethink everything. What is it there that you're just like, no, this isn't going to work, as much as exciting as this is, this isn't it?

Grant Lee (00:16:20):
Yeah, I mean part of being a founder is being as self-aware as you can and be your own worst critic. And so oftentimes you want to have these vanity metrics that feel good to celebrate, and you should celebrate. But you should know when it's a vanity metric versus is this core to our growth engine? If this number goes up, does it mean the product is working? And I think that's where we looked at, okay, it felt good to win those things. We kind of put ourselves at least on the map. But it wasn't good enough to actually have this sort of feeling that we had a core growth engine we could just invest in and get better and better. That wasn't there yet.

Lenny Rachitsky (00:16:53):
So essentially it kind of started to just plateau and slow. It wasn't like this rocket ship that took off from that point.

Grant Lee (00:17:00):
Yeah, it was still like we were still getting signups. They were coming through. But you could just tell there wasn't this building momentum. And I think that's where it's always hard to tell. You have to, me and my co-founders, we sat down, we're trying to be honest with ourselves. Okay, is this going to be enough? And it just really felt like it wasn't going to be good.

Lenny Rachitsky (00:17:17):
The other point here is the power of onboarding, which comes up a bunch on this podcast when you talk about driving retention. So you launched Product Hunt, did great and then started kind of petering out. How much did the product change after things started to work versus onboarding? Just like how important was onboarding? And then just tell us why the first 30 seconds, where'd you come up with that number?

Grant Lee (00:17:41):
Yeah. So for us, the onboarding and the product experience, for us that's intertwined. The analogy I always think about is if you go into a restaurant and maybe the food is good, but when you really think about the user experience, it's like the moment you walk into the door, you get seated, the waitress, waiter comes by, greets you, you can order. And of course the food has to taste good. And then you finally get the bill and you leave. Is that entire experience something that feels delightful? Is it good enough for you to tell your friends about? If someone just came by and dropped the food on your plate on the table, and just left and never came with a bill, I'm like, okay, maybe I'm not going to recommend this to somebody else.

(00:18:18):
And so for us, we thought about, okay, the first moment someone walks through our door, dropping into the product, what is something we can give them? Can we shorten that time to value as much as possible? A lot of this is inspired by Scott Belsky, he talks about that first mile, the first 15 minutes. And I think that's totally right. And I think one approach is you think about new users as you almost have a cynical view of them. You have to think about them being selfish, vain, and lazy, right? They're coming in, they have no desire to learn a new tool.

(00:18:48):
And so what can you give them in that first 30 seconds that earns you the next 30 seconds and then the next 30 seconds? And so for us, we knew that if we can't, people's attention span is even shorter to today than maybe 10 years ago, and so what is it in that first 30 seconds, can we actually show you something and earn the right to keep building that relationship with you? We really thought a lot about that, and certainly that's all we could really afford at the time. We only had 12 people building. It's like we couldn't make an entirely revamp the entire product. We knew that we had to least put all of our energy into one spot, and so we made that coming into the door, come through the door, make that moment feel magical so that we can do a little bit more over time.

Lenny Rachitsky (00:19:27):
I love your point about how you could think of it as like, okay, it's onboarding versus the product. The lens of how do we make this incredibly valuable and aha-ish for the first 30 seconds almost informs what the product should be.

Grant Lee (00:19:39):
Yeah. It really helps you pull forward what is the most magical thing about your product. Sometimes founders will think about the five, 10 features. Well, maybe there's only one thing that kind of differentiates you. I try to learn a lot from, we'll get into some of the marketing pieces of this, but even just having this sort of founder led marketing lens of what can I do to help a new user just understand. There's this thing from consumer advertising, which is you throw a consumer one egg, they can probably catch it. You throw them four or five eggs, they're probably going to drop all of them.

(00:20:12):
And oftentimes founders want to talk about the four or five features they have, maybe 10 features. And then the consumer is totally confused, like why do I need this thing? We try to just give them that one egg, that one first experience. We're like, okay, create a slide in seconds. That's the egg. I'm going to throw you this egg. Is that compelling to you? Some people are still going to opt out, but for the people that catch that, you're solving a real problem for them, and then you can continue building on that over time. You've given them enough so that they'll sit around and keep playing with your product.

Lenny Rachitsky (00:20:41):
That is a hilarious metaphor I've never heard for onboarding time to value, just focus on one egg at a time. Just going even further back, what was the original insight that you had that led to Gamma and what Gamma is today?

Grant Lee (00:20:55):
After the last startup I was at was acquired, I went back into kind of my roots, which is consulting. I was advising early stage startups. And the sort of medium I was using was Google Slides. So I just remember this late night trying to prepare for next day's meeting, trying to format and figure out the right layout, and spending hours just trying to get the sort of look and feel right, rather than the content itself. And for me, that just felt completely backwards. I should be spending 90% of the time on the content, 10% maybe on the design and formatting.

(00:21:25):
And so the question just was what if there's a better way? What if we could reimagine this format from the ground up? Slides have been around for almost 40 years as the default medium of choice for a lot of this. And so we thought about, okay, if we had different building blocks, different primitives, so you're not locked into the fixed 16 by nine slide, what could we offer to users? And so that was really the starting point of all this.

Lenny Rachitsky (00:21:48):
Hearing this, I could see why investors would be like, I guess so. But slides has been around, PowerPoint has been around 40 years. I get it. I get why people would be... And specifically AI, was that a part of the vision initially, or did AI start to come up, and then wow, great timing,

Grant Lee (00:22:04):
Great timing. It wasn't part of the original vision, although the spirit was there, which is we wanted to make it incredibly fast and effortless for people to create content. So it just so happened that AI was a magical gift that allowed us to do all those things along the same sort of ambition or vision that we had. And so we integrated it core to all the building blocks we were already building well before AI was part of the picture.

Lenny Rachitsky (00:22:27):
It's such a cool other example. There's just so many examples of ideas that were not possible before are now very possible with AI. And it's a great opportunity for people to come after as these places, categories, people think is an impossible place to build a big business. AI now allows it. Awesome.

(00:22:43):
Speaking of that, let's talk about the growth journey, and how you actually grew from nothing to 100 million ARR in just over two years. I'm thinking we break it up. I know these milestones aren't that clear, but kind of like zero to 100 million ARR, one to 10, 10 to 100, something like that. And let's just see how it goes. How did you get your first set of users? How'd you get your, say, first 100 users? How'd you get to 100 million ARR from zero?

Grant Lee (00:23:10):
Our first 100 looks very different, I'd say. So this was even pre this sort of AI launch we had. The first 100 users for a product like ours, you're trying to convince all your friends to use the product. Anybody that's ever made a slide deck, you're trying to talk to. And I think early on, your friends want to do you a favor, so they're going to try the product. They're also going to lie to you. They're going to tell you how great it is. And then you look at the usage and nobody's coming back.

(00:23:33):
And so I think our first 100 was sort of gradually hard-earned post the product launch, people learning like, okay, this is kind of becoming a little bit more useful. Usage was still pretty episodic, so they weren't coming back every week. And then I do think the moment post the AI launch is where all of a sudden we saw that sort of organic growth happening, people coming back to the product regularly. And so that's where, it wasn't even the first hundred, it was like probably the first 10,000 users all came within a pretty short time period after that initial launch.

Lenny Rachitsky (00:24:02):
Awesome. We're going to talk about monetization pricing later, which is obviously an important part of actual getting to million ARR and 10 million AAR. So what I'm hearing essentially is the Product Hunt launch was a big part of just the first 10,000-ish users. I know there was also a tweet when you relaunched that helped in a big way. Talk about that.

Grant Lee (00:24:24):
Yeah. So when we did our AI launch, we didn't do our AI launch on Product Hunt. We basically said, hey, let's just put it out on Twitter, see if we can get some virality. And honestly, we kind came up with kind of a clickbaity sort of tweet. It was like the most valuable skill in business is about to become obsolete. And so it was intentional in that we wanted to create a little bit of engagement. We knew that having sort of a more provocative in a tweet would allow people to engage with it.

(00:24:54):
And so after a couple of days, all of a sudden it started getting a little bit more viral and a lot more engagement. And we looked and it was basically because Paul Graham had commented and saying something like, "Surely, the thing that the slide deck is describing is more valuable than the slide itself." And obviously it was fun just to see that comment. I think once that comment came through, even more engagement on the post. And then that was really the whole intent of that post was just to be able to have that level of engagement so that people, it would have some level of reach.

(00:25:24):
And so for me, it was almost like my first learning moment, going back to what does founder led marketing even mean? It means how do you actually break through the noise? How do you get a chance to have people even engage with a post like that? Part of that is copywriting, part of that is storytelling. Part of that is just having even the right visuals to share. And so it was for me kind of a moment just understanding, hey, to kind of do this right, you kind of have to do things that maybe you're not super comfortable with, but it makes a difference.

Lenny Rachitsky (00:25:52):
Such a fun story. So you intentionally set that announcement up to be controversial is what I'm hearing?

Grant Lee (00:25:58):
Totally. Yeah. I'd say provocative. A little spicy.

Lenny Rachitsky (00:26:01):
That is so cool. So essentially you got to 10,000 users through Product Hunt, and then essentially one controversial tweet that ended up baiting Paul Graham to comment.

Grant Lee (00:26:11):
Totally.

Lenny Rachitsky (00:26:12):
Amazing. And it was just a comment. It wasn't even him retweeting it.

Grant Lee (00:26:16):
No, just a comment. And then others would pile on.

Lenny Rachitsky (00:26:19):
Yeah. It's interesting how much a comment can increase the distribution of a tweet versus them retweeting it or quote tweeting it.

Grant Lee (00:26:26):
Totally. And of course the algorithm change all the time. So part of it was just luck based on when it happened, how it happened, who posted.

Lenny Rachitsky (00:26:32):
And you use this term founder led marketing, which I love, and I'm already seeing it in action here. This is you thinking about, it's not delegating to someone in marketing, it's not hiring an agency, it's like how do I tell a story that I think will break through the noise based on you building this company, having the insight to build this product. And I guess is there anything more there you think is important for people to hear about the importance of the founder thinking through this stuff?

Grant Lee (00:26:56):
Yeah. I mean, I think most people today are probably familiar with founder-led sales, which is still very, very important. I think before you hire your first salesperson or AE, it's great for the founder to understand what it takes. And they're going to craft the right narrative, the right story. At my previous role, I was the COO at a startup where I was doing a lot of, I wasn't founder, but I was early. And so I was helping the founders go through this, and really helping go into meetings with a client or a prospect and saying, "Hey, this is why our product is interesting."

(00:27:26):
And I think today there's so many AI startups that are much more either B2C or prosumer. And so you're not necessarily talking to individual prospects, but the idea that you can be really in control of the narrative on the marketing side is really, really important. And I think I'll describe a few things where, over time, I think that skill set just really, really helps you.

(00:27:48):
One is you have a chance to be a creator yourself these days. I think a lot of founders are trying to be more active on social media. And I think if you can kind of overcome the initial cringe factor of seeing yourself and postings like, oh, this doesn't feel authentic, if you can overcome that initial feeling, you start investing into like, okay, how do I become a better copywriter? How do I articulate something that is clear, not just clever? I think there's that saying where obviously if you can have that clarity, that's super important. And most people will try to get super creative with their copywriting, but that's not usually the right way to break through and communicate something. So how do you improve your own copywriting?

(00:28:27):
And then that allows you to actually have a higher bar when you start working with other marketers, or in this case for us, working with influencers. If you're working with influencers and creators, and you can totally empathize with how they approach that work, and you know what a good hook looks like or you know how to structure a good post, you can only do that if you've gone through it a little bit yourself and you know how hard it is. And I think too many founders will then just say, they'll write something that just feels so much like an ad, and then they'll give it to a creator to help amplify. And then that just never works. And so I do think part of founder-led marketing is going through this yourself.

Grant Lee (00:29:00):
And so I do think part of founder-led marketing is going through this yourself, using your own platform. In the beginning it's probably going to be super small. But as you get bigger, you have a platform to ... You have a voice and people listen. And you're going to get better and better at your own storytelling. I think these are all skills you should invest in as early as possible, because you know you're going to have to get better and better. It's like practice, you got to practice over and over.

Lenny Rachitsky (00:29:21):
I definitely want to pull on this thread more because you tweeting the lessons you learned building Gamma is what led to this conversation. I was reading, I'm like, " Okay, he's sharing a bunch of stuff, but there's so much more I want to hear." And we're going to talk through this and go in a lot more depth than what you've shared on Twitter. But I love that that's example of that working, having this conversation.

(00:29:41):
So let me ask a couple of questions here. One is just how do you find time as a founder or CEO of a very fast growing crazy startup? We have so much to do. How do you just allocate the time to do this? And then any just key lessons you've learned about doing this well, beyond what you've already shared for people that want to try to start sharing things on LinkedIn and Twitter?

Grant Lee (00:30:00):
My advice is definitely just to try to start small. Don't let it become so intimidating that you just don't get started. For me, it was like just having a notepad or a Google Doc around in the beginning where I would just constantly jot down, okay, this is something I learned or something I observed or something that worked well, something that was unintuitive but worked, and just start creating a log of that. And then once I had enough of those, and I'd spend basically every week, I'd block off a few hours to go a little bit deeper. I'd take a lot of those bullet points and try to say, "Is there enough here to turn this into maybe a post or something that can be shared broadly?" And in the beginning I didn't have enough. It was all sort of scattered thoughts. But over time you start accumulating some interesting themes. And then I would start stress testing some of that.

(00:30:45):
So I would tell my teammates like, "Hey, this is something interesting. Do you find this interesting?" And if there were enough like, "Oh yeah, I would not have expected that", or, "That's not something I've ever heard before," then I'd actually start crafting the initial post. And then you actually just put it out there. I think what I've learned is, even for LinkedIn versus Twitter, the audiences want different things. And so you almost have to then have different tones of voices or even nuggets or sharing. For me, I invested much more in LinkedIn early on just because it felt a little bit more natural for me. And then over time I said, "Okay, well I'm going to start packaging certain content for Twitter that's actually different than what I would post on LinkedIn." Sometimes on Twitter you get even more tactical or even more into the weeds. And so I found that to be helpful.

(00:31:27):
But honestly, I'm still learning. And so every time you post, you go back, after a couple of weeks you go and say, "Okay, what things are actually being engaged with? Are things actually creating ..." Ideally you're creating enough value where people are either bookmarking it, sharing it, retweeting it, these things that are signals for there's something valuable there. And then you just go back and you start collecting your own sort of, these are my all-star posts, these are the ones that I've actually broken through. And then you go back and try to understand, okay, what about that post do I think was actually useful? Was it the actual content? Was it the structure of the content? Was it some sort of contrarian advice? And you start thematically bunching that together such that as you're brainstorming every week, you just have a good sort of body of work to work off.

Lenny Rachitsky (00:32:10):
This is so interesting and valuable. So let me mirror back a few of the lessons that I heard here that I think is easy for people to miss. So one is just what to share. What I heard here, and I completely agree with this, and this is what I try to do, is pay attention to things you've learned, things that you find interesting, things that are unintuitive to you. Just have a doc and just put these there. And every time you learn something, find something interesting, just add it to the doc. Or yeah, I haven't heard before is a good one too.

(00:32:39):
So it's essentially just like if you find it interesting, people on social media will also find it interesting. And one approach is just share it as it's happening, which is what I try to do. Just like, "Oh hey, just learned this thing with with clock code. Check it out." Or save it up for a big long post. The other interesting, I've never heard this before, of post different things to LinkedIn and Twitter. I just copy and paste the same thing. I love that you do something different for the two platforms.

Grant Lee (00:33:05):
I think we all kind of have intuition that there's just different audiences, right? And so if you know that kind of fundamentally, then the question is how do you package up the story the right way so that the audience is ready to receive it? And I think this can differ by the type of creator or the founder, whoever's posting it, and of course the actual content itself. And so for me, I'm still tweaking, but I do find that just copy and pasting from one to the other doesn't usually work. You almost need to be in the right mindset of, okay, what do I think will be more engaging on Twitter? And then what do I think will be more engaging on LinkedIn? And then test a bunch, see what actually works. Go back and iterate a little bit.

Lenny Rachitsky (00:33:49):
So if you had one bullet point tip for what works on Twitter versus LinkedIn, you shared maybe more tactical on Twitter, is there anything more there you can share?

Grant Lee (00:33:56):
Yeah, that's what I've found is tactical, oftentimes more contrarian on Twitter. And also I would say technical too. People really like to know, again, going back to getting into the weeds, is this something I feel like I could replicate? And I'm not going to give you ... There's no credibility if you just give a blanket statement or something that feels generic. I really need to know, if you could show me the metrics, even better. I feel like that ...

(00:34:22):
Versus LinkedIn, it's oftentimes more even just either more aspirational or aspirational or a topic or a theme that just feels relevant at that point in time. And you can just kind of make more of a broader statement. It doesn't need to be as tactical. It's more like inspirational, is like, "Oh, okay, now I need to go and learn a little bit more about pricing and packaging," for instance. And that could be the sort of spark that somebody needs. And you don't need to spell it completely out. Part of it's also that on LinkedIn you can't really do threads. And so doing a super long form post isn't as practical. Maybe that changes in the future, where maybe the tactical pieces, that element might actually change.

Lenny Rachitsky (00:35:01):
And last piece is you said you just block off time. Is there a specific time of the week you do this? How do you actually ... Because everyone's like, "Oh sure, I'll block off time. And then, I don't know, okay, but I actually got to do all this other stuff so I'm not going to use it this time or maybe next week."

Grant Lee (00:35:12):
For me, it's usually two times of the day, very first thing in the morning and last thing at night. And partly it's because of kids. It's almost like I need time where there's just zero distraction and there's no noise in the house, and so I can actually think. And then I think in the mornings it's about where are you finding inspiration, what are topics you're energized by? And then I think at night it's about reflection. What are the things you actually went through that day? You can almost pull up your calendar and be like, "Okay, I talked to X, Y and Z people. And was there anything from those conversations that might be relevant?" That's where I write some of those things. It's more of a recap of actually what happened.

Lenny Rachitsky (00:35:50):
And what helps me to not feel like this is some cringey self-promo egotistical stuff is just it's useful stuff that I've learned that ends up being helpful to people. And people in the comments are always just like, "Oh, that is really cool and useful. Thank you." It's not like self-promotion-

Grant Lee (00:35:51):
Totally.

Lenny Rachitsky (00:36:05):
... it's not just like, "Look how amazing I am. Check out my amazing products." Like, "Here's a thing I learned. You might find it useful."

Grant Lee (00:36:11):
That's exactly right. I think one way of thinking about it, with founder-led sales, it's always about exchange of value, right? You want to be able to give the customer this feeling that they're getting an amazing product. In exchange they're going to pay you money for it. I think with founder-led marketing, it's almost this mindset of you want to give people a ton of content, maybe it's a value in the content, so you're sharing something, maybe some secret tactic or you're giving them something where inherently there's value in it, and in exchange you sort of get goodwill back. You're not necessarily getting money back, you get goodwill. They're going to follow you, they're going to engage with your post, they're going to tell others about it. And then over time you can exchange maybe some of that goodwill for actually talking about my product and announcing it and they're going to help amplify the news. And I think that's magic, where you kind of bank the goodwill for a long period of time by providing just a ton of value with no expectation of anything immediately in return.

Lenny Rachitsky (00:37:06):
The book I always point people to when they're struggling with this sort of thing and like, "Okay, I did this and no one cared, didn't do any good," is there's a book by Scott Pressfield, I think is his name, called Nobody Wants to Read Your Shit, which is exactly what is right. Nobody wants to read it. The bar for people to care is very high. There's so much stuff to read and process. And so this book gives you a really good lens of just like, okay, the bar is very high and nobody wants to read your shit, so you have to try really hard to make it really good.

Grant Lee (00:37:38):
Great reminder.

Lenny Rachitsky (00:37:39):
We'll link to that in the show notes. Okay, let's come back to the growth of Gamma. So we've talked about how you got your first tens of thousands of users, essentially product hunts, rethinking, onboarding, making it really magical, and then this very controversial tweet that Paul Graham commented, created some buzz. Let's talk about the next phase and maybe, I don't know, tell us kind of the ARR at that point through 100 million. Just broadly, what should we know?

Grant Lee (00:38:07):
So when we got to about 10 million in ARR, I think there was this feeling for me, which was we knew we needed ways to help just continue to amplify and spread the word about Gamma. I think it was already working in terms of the organic virality was there, and so we did feel like it was time to start amplifying some of this. And I think the main blocker of my mind that I started feeling was that our initial brand was holding us back. And I think a lot of people will discount whether or not a rebrand is valuable. And I think sometimes it is, sometimes it isn't.

(00:38:39):
For us, there's a few different things we looked at. So one, our initial brand was almost more of a placeholder brand because we created it the moment we incorporated the company, which was again late 2020, beginning of 2021, where we needed something so that as we built, we could at least share it with people. We could put up a landing page and just feel like, okay, there's something here. But we didn't invest a whole lot into it. And so it was pretty limited in sort of what I call the DNA of the brand. There wasn't that many ... The art direction was very limited in scope. There wasn't much when it came to voice and tone.

(00:39:12):
And so it was something that we knew was good enough to start, but it wasn't scalable. And when I think about something that could be scalable, it's almost like you can take the ingredients of a brand and replicate it a ton, this DNA is something where you can imagine creating tons of content around and all feeling pretty cohesive. And I think that needs to be done by design. You're really being thoughtful about every single element. Like what is the art direction you want to go with? What is the voice and tone? Such that as you're creating thousands of pieces of copy, it all feels pretty cohesive.

(00:39:45):
And so we went back to the drawing board and we spent many months rethinking what would be the brand, what is this vision that we have longer term? Our creative director internally partner with Smith & Diction, an amazing agency that has helped folks like Perplexity also do their rebrand or their initial brand. And we [inaudible 00:40:05] many months just really trying to craft what we think is the core DNA of the brand, and doing so in a way that we could replicate it as much as possible.

(00:40:15):
Replication piece of it comes into play, because as you start scaling you're going to have to create a ton of content, your own content on social media, ads for performance marketing, assets for influencers to be able to use and showcase in their content. And so you're going from tiny pieces of content to all of a sudden every week we're testing thousands of pieces of creative. And you cannot do that if you don't feel confident that as you're replicating, you have that sort of cohesive feel. So for us that we realized it was going to be necessary and it's why we invested so much. It ended up being way more expensive, way more time consuming than I would've imagined. But I think coming on the other side of it being the right investment, feeling that that was the right time to do it.

Lenny Rachitsky (00:40:55):
I love how many things you did that feel like this will not work out. Building a startup within the presentation space, doing a whole rebrand in the middle of scaling, also just reworking the entire product after you launched and just rethinking the whole thing. All these things and everyone's always like, "No, this is not how we win." And interestingly, worked out for you guys.

(00:41:19):
I want to come back to the brand stuff, but one of the most interesting ways you guys grew early on was influencer marketing, which a lot of people hear about and talk about. I haven't heard much of how to actually do this and what actually works. Talk about that as a broad growth lever for you guys. And then I want to get into just what tools did you use, who actually was really helpful there, thing like that. So yeah, just give us the big picture.

Grant Lee (00:41:44):
Yeah. I think a lot of founders assume that with influencer marketing it's almost like turnkey. You set aside a budget, you find some creators, you figure out the right campaign or the right moment of time to do it and it's all done, you're ready to go. And I think the reality is, going back to this founder-led marketing mindset is like, well, you're going to set yourself up for success if you actually are super involved in that entire process. So for us, what this meant was all the initial influencers I onboarded manually myself. I would jump on a call with each one of them so that they understood what Gamma represented, how to use the product. You want to be able to have them tell your story but in their voice, right? And they can't do that if you're not willing to put in that investment.

(00:42:32):
And so we would spend a lot of time going through ... It wasn't my job to tell them how to pitch Gamma, but it was my job to make sure that they understood what Gamma was as a product. And so we'd spend a lot of time, like me just walking through the product, them asking questions, us just kind of brainstorming what could the hooks be, and me just giving them some initial feedback and saying, "Oh yeah, this one, I love that. I figure it's going to work great for your audience." But not trying to be super prescriptive. And working with a ton of micro influencers, people that don't have massive followings but are committed to ... Going back to giving value to your audience. They're committed to giving value to their audiences. They want to be able to showcase tools that actually they would use or they are using. And how do you do that in an authentic way? You can't really fake that. You really need to spend the time doing that.

(00:43:16):
And just like you would onboard a customer, you onboard an influencer the same way. You want them to be an extension of your team. And I think they can feel whether or not you're willing to put in the work. And if you're not, then they're just going to treat it like any other project, ship it and be done with it. If you invest in that relationship, guess what? They'll be back to actually post about you again. And you're all of a sudden having this sort of this relationship that actually you can build over time. I think that's really where the magic is. Too many people discount that initial piece.

Lenny Rachitsky (00:43:47):
This is awesome. To be clear, influencer marketing, essentially a person with a following on say TikTok, Instagram, Twitter, LinkedIn, whatever, gets paid in some way to promote your product. That's the simple way to understand influencer marketing, yeah?

Grant Lee (00:44:00):
Yes, that's definitely the simple way. And I'd say there's definitely different levels. I think a lot of people think influencer marketing and they'll think these big trendy creators, people that have a million followers for instance. And the idea is that, okay, we're going to carve out a really big budget, we're going to choose five or six that we feel like are really the tastemakers in the space and put all of our money into just having them talk about our product. And I think usually this is kind of the wrong approach. Because many of them, they do have massive audiences. And for you, you basically give them a script to read and it immediately feels like an ad. That product is not connected really to them in any way. It's just something that they're ... For this week they happen to be working with you and then they move on with their life. And it never feels organic or authentic and you wasted a ton of money doing so.

(00:44:55):
I think you're much better doing the hard thing, which is hard to scale, but it's finding the thousands of micro influencers that have an audience where your product maybe is actually useful. And for instance, for us early on it'd be educators, people that for them, part of their job is creating slides every day because they need to engage their students. And so for them, having a tool that actually saved them a ton of time was something they love talking about. And if you can find some of these pockets, we call them echo chambers, where if you find a pocket like educators, teachers love telling other teachers about products they love using. During summer break, they all come together and talk about, "Okay, what are the things that are going to actually improve my job next school season?" And obviously during this AI wave, a lot of those have been, "Okay, what are the AI tools that just save me a ton of time?"

(00:45:43):
And so if you can start actually tapping into these pockets of echo chambers, that's even better. It doesn't have to be this flashy, well-known influencer. It's actually just this person that has an audience where people really trust what they say. And that's amazing. That ends up becoming this sort of wildfire that can spread really, really fast.

Lenny Rachitsky (00:46:03):
And what's the dollar amount these folks get? It's like a few hundred bucks, a few thousand bucks, something like that?

Grant Lee (00:46:07):
Yeah, few hundred to low thousands, low single digit thousands.

Lenny Rachitsky (00:46:11):
How do you find these folks? Is there tools that you use? Is it just like a bunch of manual searching and looking?

Grant Lee (00:46:17):
Yeah, in the very beginning it was all manual, a lot of cold outreach. And then we ended up finding a couple of different things. One is a platform, a YC company called 1stCollab. That has been amazing. They basically do all of the automated outbound for you. Plus you can help them actually create profiles or personas of different creators, so for instance educators being one, and then they'll go out and actually, based on that profile, find all the right creators for you. So they've been amazing, really great to work with.

(00:46:46):
And then we've also found small agencies to also help kind of augment that. I look for agencies that are super young and hungry. These are people that they're native to social media and so they really understand it. And they can really be able to bring in creators that are great to work with. And I think part of it is if you find creators that are great to work with, everything else becomes easy. So we've had a few, one is AKG Media, actually out in the UK, and they've been fantastic to work with as well. So you kind of find a few different things, either agencies or platforms that can help you actually scale this thing up.

Lenny Rachitsky (00:47:22):
And when they post, they're generally transparent about this is a paid promotion, right?

Grant Lee (00:47:23):
Yes.

Lenny Rachitsky (00:47:27):
They're not just pretending, "I found this tool and I love it"? Cool.

Grant Lee (00:47:31):
Yeah, exactly right.

Lenny Rachitsky (00:47:32):
Okay. And so how much impact did this lever of influencer marketing have on your growth, say from 10 to 100? Is this the biggest lever of growth other than just word-of-mouth, people continue to share it?

Grant Lee (00:47:44):
Yeah, so word-of-mouth has definitely been the biggest. So we look at all new subscriber growth, over 50% of this is word-of-mouth. It's either people searching direct, coming direct, entering Gamma.op, or going through search and typing in Gamma, like a branded keyword search, where they're looking for Gamma, they've heard about Gamma. But I think for us, social media and influencers specifically has always been an amplifier. So every time we invest in influencer marketing, we actually see word-of-mouth increase even more. And it's always like you can just see it. Basically anytime you spend a little bit of money, you start seeing people come through influencer, the word-of-mouth factor actually will get another 1.5 additional users on top of that, which has been really interesting to see.

(00:48:29):
And I think part of this is just recognizing that ... And I think we kind of understand it, but with influencer marketing, why it's so effective, we all know Dunbar's number, which is have this number of 150 people that you call kind of your network. And your network you trust more than the average stranger down the street. If they tell you something, they recommend something, there is a sort of halo effect, you learn to trust them. A lot of these influencers, the reason why they share so much about their lives is because they want to be in your network. They want you to feel super close. And once you feel super close, you trust them to actually share things that are going to be useful.

(00:49:05):
And so when they recommend a tool, there is a sort of halo effect, where it doesn't feel like it's coming from a stranger, it feels like it's coming from a friend. And that's where every time we've spent money there you actually see this amplifications, like, "Okay, that's kind of interesting." You wouldn't necessarily expect that. But for us it's been this sort of amplifier from the very beginning.

Lenny Rachitsky (00:49:24):
This is so fun to hear about. I've not heard this level of detail on how influencer marketing works and how to make it work. A few more questions here. So you said there's maybe a few thousand people you ended up working with, roughly, influencers?

Grant Lee (00:49:35):
Over the course of a year. It wasn't all in the same time. Basically in the beginning you do ... In the very, very beginning we had a small budget. It was like 20 creators a month. And then you start increasing that to like 50, then 100. We're definitely not fully scaled at this point, but I could easily see a point where you're working with many, many creators every single month. And that gives you a chance to actually test a variety of, again, content hooks, ways to talk about the product, value props.

Lenny Rachitsky (00:50:03):
Amazing. And you said the key here is you spend time with every one of these creators, influencers early on to help make sure they understand what you're doing and get excited about it. It isn't just like a thing you outsource.

Grant Lee (00:50:16):
I think there's a lot of value there. It's again hard to quantify. And most founders probably feel like they're too busy to allocate that time. But I think it was a good investment. Because going back to you want them to feel like an extension of your team. They're not going to feel like an extension of your team if, one, they've never met you, and two, you've never even told them really how the product works. They're forced to go to your website to figure it all out. Those are going to be not a whole lot of love that they're feeling from the outset.

Lenny Rachitsky (00:50:47):
So what I'm hearing is quality over quantity, especially when you're getting started. And then there's this other piece of niche which I think is very counterintuitive. Instead of going to large influencers with a huge audience, it's good with folks that are small. What's like a audience size roughly that you think is ideal for this, or what niche just means?

Grant Lee (00:51:05):
Honestly, I don't think there's a minimum, because even with platforms like TikTok, they oftentimes are giving you credit for a brand new account. They want to help amplify that new account, because obviously if they're thinking from a creator perspective, if that new creator feels like, "Oh, coming to TikTok is a massive win for me," they're going to be more invested in it. And so there really isn't a minimum. A lot of these platforms are trying to shift to kind of the same thing, where they really reward new creators on the platform. And so you could have a small audience, it doesn't really matter. You could have 10,000 followers, that's also good. I think as long as the content feels, again, engaging, authentic to the people you're talking to I think it has a really good chance of actually taking off.

Lenny Rachitsky (00:51:46):
That's such a good point with TikTok, where it's not follower related, if it's useful and people find it clickable or whatever, likable, viewable, the algorithm will spread it to a lot of people. Such a good point.

Grant Lee (00:51:59):
Totally.

Lenny Rachitsky (00:52:00):
Okay, there's a couple more points you made in the tweet that I want to make sure we highlight. So one is you made this point that 90% of your reach in influencer marketing comes from less than 10% of people. Is there anything there that you think is important for people to hear?

Grant Lee (00:52:11):
Yeah, I mean this just goes back to it's hard to know where that 10% is going to come from. So you kind of just have to cast a super wide net. You can sort of, I think try to, again, trick yourself into thinking you're great at picking creators or you're great at telling them how to post about your stuff. But the reality is, even for me, I could never guess. I kind of had some idea, but I just had to make sure that I was meeting enough creators broadly such that when you meet enough, they're all posting, there's some pocket that end up just taking off. And I was not a good predictor of that. I was not smart enough to actually know which ones would take off. I just knew that we had to play the sort of numbers game to make it work.

Lenny Rachitsky (00:52:49):
So one of your tips here is people fail often in this because they start too small or their budget's a little too small. You recommend 10,000 to 20,000 a month over six months and just trying this. It sounds like you're doing like 20 to 30 creators a month. Is that the right framework for how to just start this thing and explore?

Grant Lee (00:53:07):
Yeah, totally. And I'd say it's not just that the budget's too small, it would be that they put all their eggs in one basket. So you can also easily blow that 20 K on just one bigger influencer and then be like, "Oh, that didn't work, so I'm going to try it again. That didn't work. Okay, I give up." And I think rather than doing that, you should be like, "Okay, that 20 K, I could actually probably work with 40 different influencers and see what actually works." And across the 40, I'm going to try to find a variety of personas, a variety of use cases, spend a lot of time with them, and then actually see what's working, what's not.

(00:53:39):
And then next month take those learnings and double down. If educators are working, go with educators. If consultants are working, go with consultants, find more consultants, there's going to be more there. I think that's where the putting all your eggs in one basket is just probably the surest way to fail, because you're going to miss a ton and it's going to take you way too long to learn and you're going to come to the conclusion that it's a waste of time.

Lenny Rachitsky (00:54:00):
I feel like this whole podcast conversation could be just about this one lever. So much I want to keep talking about, but there's more questions here because this is so useful and interesting. You had this line in your tweet about how reality is not an accident and that this approach is how you figure out what actually works. And then once you do that, then you start leading into that messaging. Talk about that.

Grant Lee (00:54:20):
This goes back to obviously if you're testing a bunch, you'll finally find that sort of post or set of posts that actually go viral. Going back to just the fundamentals, like make it easy for your influencers to be able to tell your story in their voice. One thing we did, we open sourced basically our entire brand. We have Brand.gamma.app, which is everything about our brand, our voice and tone, our art direction, what we use in mid-journey to create the sort of art direction that we have so that a creator can do the same, right? And they can actually just copy all of that so that they don't have to reinvent the wheel every time they're trying to post about Gamma. They have all of that.

(00:54:56):
And I think going back to this notion of just make it dead simple for them, remove friction. They already have enough on their plate to have to figure out. Don't make it any harder than it is. And if you remove friction, then it's like, oh, you get into this rhythm of adding creators is easy, having them post is easy, reviewing what's working, what's not is easy. And if you're able to do that relentlessly over many, many months, then all of a sudden hitting the sort of viral post is easy because you're going to have enough bats there where some are actually going to pop off. But you only can get there after you've done all the hard work before that to remove friction from the process. And feeling like it's almost like a well-oiled machine at that point.

Lenny Rachitsky (00:55:38):
Is there a platform you find most helpful for the stuff you guys are doing? Is it like TikTok, Instagram, LinkedIn, something else?

Grant Lee (00:55:45):
Yeah, I mean this is one where for us we cast a pretty wide net too. But it's very clear, LinkedIn, the conversion rates are just substantially higher. They're 4X, maybe 5X higher than other platforms. And I think a lot of people are probably still sleeping on LinkedIn, frankly. And so it's one where some of the influencers there or creators there can be a little bit more costly. But if you can eventually be more targeted knowing that, hey, this type of creator is pretty impactful for our product, then working with them, it's just like, "Oh, that's great." The conversion rates are just so strong and it really feels like we're just getting started there.

(00:56:22):
So if in the beginning you're not sure, it's always helpful to cast a pretty wide net. And then similar to just the influencer strategy, like test and iterate, you'll figure out ... Many of these things will follow a power law. So it's like one or two channels are going to be the most important for you. For instance, Twitter for us hasn't been that impactful. And I think for tools like Notion, they've been really, really impactful. You're not going to really know, and so just test and then double down on the ones that really move the needle for your product.

Lenny Rachitsky (00:56:48):
I think that many people listening now are like, "Wait, LinkedIn posts are sponsored sometimes? I didn't know that." How do you know if it's a sponsored post? Is it like a #sponsored or something like that? How do they communicate this?

Grant Lee (00:56:57):
Usually they'll say they're a partner or yeah, basically it is sponsored in some form, or they'll #ad or something along those lines. So that's probably the way you'll see it the most.

Lenny Rachitsky (00:57:12):
Cool. By the way, I don't do this sort of stuff. Have you ever seen me on LinkedIn? I'm not doing any paid stuff. It's just so people know. And I don't plan to do that.

(00:57:19):
This episode is brought to you by Miro. Every day, new headlines are scaring us about all the ways that AI is coming for our jobs, creating a lot of anxiety and fear. But a recent survey for Miro tells a different story. 76% of people believe that AI can benefit their role, but over 50% of people struggle to know when to use it. Enter Miro's Innovation Workspace, an intelligent platform that brings people and AI together in a shared space to get great work done. Miro has been empowering teams to transform bold ideas into the next big thing for over a decade. Today, they're at the forefront of bringing products to market even faster by unleashing the combined power of AI and human potential. Guests of this podcast often share Miro templates. I use it all the time to brainstorm ideas with my team-

Lenny Rachitsky (00:58:00):
... Often share Miro templates. I use it all the time to brainstorm ideas with my team. Teams especially can work with Miro AI to turn unstructured data, like sticky notes or screenshots, into usable diagrams, product briefs, data tables, and prototypes in minutes. You don't have to be an AI master or to toggle yet another tool. The work you're already doing in Miro's Canvas is the prompt. Help your teams get great work done with Miro. Check it out at miro.com/Lenny. That's M-I-R-O .com/Lenny. Let's come back to this brand point. So, one of your big lessons is invest in brand before you go heavy into hit paid ads and performance marketing. I imagine you do some ads at this point on Facebook and Google and things like that.

Grant Lee (00:58:42):
Yeah, we run ads performance marketing. I think there's this stigma that brand marketing and performance marketing are sort of at odds with each other. I very much follow the sort of thought that brand marketing is performance marketing. Everything is some form of performance marketing. It just might not be as attributable, so the ability to actually map back to every single dollar spent is a little bit harder, but it doesn't mean that it's not impactful.

(00:59:12):
And I think as a company scales, you have to invest in both, and ideally they work really, really well together. The more you invest in brand marketing, it strengthens your performance marketing. This goes back to having enough creative to even test. If you're too limited in scope and you don't have a brand, you feel like you can actually amplify your handicapping, your ability to actually have a good performance marketing program.

Lenny Rachitsky (00:59:32):
I love that heuristic of how do you know if you are under invested in brand is if you're limited in the number of ideas you can try in performance marketing.

Grant Lee (00:59:32):
Totally.

Lenny Rachitsky (00:59:43):
Is your design system just... Is everyone having to redesign things from scratch and come up with all these frameworks every time they run an ad?

Grant Lee (00:59:52):
Exactly. Yeah, yeah. Basically you kind of have a feeling for, "If I were to scale this up to a thousand pieces of creative, would it still feel cohesive or is it kind of all over the place?" And if it feels like it's all over the place, then you kind of have to go back to the drawing board.

Lenny Rachitsky (01:00:05):
You said when you talked about the rebrand, that it took a lot longer than you expected, that it was more expensive than you expected. That's the fear, I think, everyone has when they hear this like, "Oh, I don't have time for a rebrand." I also imagine, because your product is so visual, that it makes more sense to invest there and to spend the time and money.

(01:00:23):
For the typical founder, do you have any just, I don't know, thoughts of just like, "Here's when it makes sense. Here's a sign you really need to invest here heavily." Versus, "It'll probably be all right."

Grant Lee (01:00:32):
Yeah. I mean, I do think it's probably more geared toward anything that's a little bit more prosumer or consumer because so much of your product, you're trying to create this feeling for a user, what are they experiencing. And the experience happens way before they even drop into your product. It might be they see an ad or they see a billboard or they see something. It's like, "Okay, that piqued my interest a little bit."

(01:00:56):
And then you need some sort of symmetric messaging in that they see there's some symmetry in that, they see the ad, then they drop into the product or they land on your website, it feels cohesive and it feels like, "Okay, this is interesting. I'm going to go all the way through to sign up and then maybe actually start using the product."

(01:01:12):
That's a little bit different when it's a B2B product or where there isn't as much reliance on that initial moment. They might just hear about it through a colleague and then sign up for it and then go through a huge procurement process and then it's like, "Okay, maybe it matters, but probably not so much as for a product where the brand can have so many different touch points."

Lenny Rachitsky (01:01:33):
I want to talk about some broader things that have worked to help you grow, but before we do that, I just want to visualize the pie chart of how Gamma grows. Say, post-10 million ARR. If I have it correctly in my head, it's over 50% just word of mouth, organic, people are sharing it, doing presentations for each other, "Oh, it's Gamma. Just go check it out, sign up." Then it feels like the second-biggest bucket is influencer marketing, social stuff. And then is the third performance/paid marketing?

Grant Lee (01:02:03):
Yep, that's right. Yeah.

Lenny Rachitsky (01:02:04):
Cool. On that last piece, is there anything else there for people that are starting to explore performance marketing, essentially Facebook Ads, Google Ads, all these other platforms, is there anything else that you think might be helpful for people to hear or learn just to get started down this road?

Grant Lee (01:02:19):
I would just have two recommendations. One, going back to my initial piece of advice, which is don't invest until you have word of mouth. Don't fool yourself into thinking that you'll solve other problems by just starting to ramp up a performance marketing program. Just get the word of mouthpiece first, so that you're coming into this program with some tailwinds and then start ramping it up.

(01:02:40):
The second piece is: set some constraints. You don't want your product to be at a point where more than 50% of your acquisitions are coming through paid acquisition. I think if that is happening, your core growth engine is broken. And it feeds right back to point number one, which is if your core growth engine is broken, you just have this leaky bucket. You're trying to spend so much money building top of the funnel, people are not making it all the way through. Something else should be fixed before you really try to dial it up. And it doesn't mean you don't spend a little bit of money, but just don't dial it up until you feel like your core growth engine is actually working.

Lenny Rachitsky (01:03:17):
When you said the first point about wait until you have word of mouth before investing in performance marketing, is that essentially a large chunk of your growth should be coming from word of mouth, direct, organic?

Grant Lee (01:03:29):
Yeah, yeah. And for us, even at scale, again going back to more than 50% of new signups still come through word of mouth. That, for us, is a sign like, "Okay, if something is still working, people are using the product, telling other people, then you want that feeling before you really start dialing anything else up."

Lenny Rachitsky (01:03:45):
Is there a percentage that you think is helpful for people to think about just... Is it 25% or more something like that or just word of mouth for you to feel like, "Okay, we actually have organic growth as a major growth engine"?

Grant Lee (01:03:55):
Yeah, I think this comes back to maybe just how maybe aggressive you want to be. I think just rough heuristic is the more, the better. If it's over 50%, I think that's great. If it's approaching that, good. And just going back to, don't fool yourself into thinking just ads is going to be the way you grow. Because you can do that, but everything else becomes harder and harder. 

(01:04:16):
If you rely on paid acquisition to be the main growth engine, you should be prepared for things like CAC, like customer acquisition costs, to keep going up. The more you're trying to reach a new audience, it gets more and more expensive. So, don't assume it's going to be flat, and then all of a sudden you're running on this treadmill that's actually running faster and faster. And so that's where it's easy to get hooked on that early on when you're just investing a small amount of money, and then it's almost impossible to get off that treadmill when you're too far into it. So, anticipate that and give yourself a better chance at actually being able to sustain that growth long-term.

Lenny Rachitsky (01:04:50):
Important advice. Okay. There's a couple more elements you've shared that were key to Gamma's growth. One is sharing prototypes with users before you ship. What does that look like? What does that mean? Why is that so powerful?

Grant Lee (01:05:05):
Yeah. I mean, this for us was a huge unlock. Going back to early days, when you're just trying to get your product into anybody's hands, you're getting to your friends trying to use it, and again, they're going to lie to you, tell you how great it is, and then never come back to using the product. 

(01:05:19):
I think what you want to be able to do, the ideal situation is, you recruit a bunch of people that are legitimately good prospective users or customers of your product, but have zero skin in the game. They do not care at all whether or not your product succeeds. They're just in it to test it. And for us, it was people that have made slide decks or make slide decks regularly, let's drop them into Gamma, give them very little context. We just tell you, "Hey, this is an alternative to PowerPoint. Go ahead and try it."

(01:05:48):
And then as you're going through the onboarding flow and testing the product, just tell us everything that's going on in your head, describe what you're seeing, tell us what you're trying to do. We'll give you maybe a few different tasks like, "Oh, create a piece of content." And when you watch them do that and also hear what they're saying, you just immediately feel the pain. 

(01:06:10):
All the places they're struggling and all the places are so confused by what they're seeing and you sort of then can internalize that pain and say, "Okay, we're going back and we have to fix this. This is not usable." We, oftentimes, are dog-fooding everything. And so you can get to the point where you're so familiar with your own product, everything feels kind of easy and you know where things are, but when you start actually hearing other people describe their usage of the product, that's a gift.

(01:06:36):
You're all of a sudden you're like, "Okay, now I know where to actually spend the time." People aren't even getting to the third screen. They're stuck on the first screen because they can't even find the button that we think is so dead obvious, and so let's go back and actually re-engineer, re-architect that piece of it.

(01:06:50):
And we've done that for everything: landing pages, onboarding experience, new feature launches, export, sharing, every single piece of that such that we can actually see where things are working or not. And then every time, we'll learn something that's kind of painful, but obvious that we need to fix and we go back and fix it.

Lenny Rachitsky (01:07:08):
How do you scale this sort of thing? How do you run every new big idea, new feature change by people? Do you have a closed beta group, a decent platform? How do you actually do this?

Grant Lee (01:07:19):
There's a couple of great platforms. Voicepanel, which is also YC company, full disclosure, angel investor, and then there's also platforms like UserTesting, that really help you source and find these people that fit again, that persona or profile you're looking for. So, in our case, people that are in a specific job function or create decks regularly, and so you can use those platforms to really scale up these programs pretty fast.

(01:07:45):
And then once your team knows how to use those platforms... We would have an idea in the morning and in the afternoon, we're already running a pretty full scale experiment or a research study, and by the evening or by the next day, we can actually go through all of it together. So, it's pretty fast once you have it set up. It's more about how do you get the program onboarded the right way. 

(01:08:06):
I think the other sort of mechanism we did early on was once we had some repeat users, we created sort of a program for our power users. We called it the Gammaster Program, which is we put them into a separate Slack workspace, and that was a place for us to share very, very early prototypes like wireframes, sometimes they were functional prototypes, and get them to get some initial feedback as well. This definitely helps with more later stage or features or things that aren't going to be necessarily important as part of onboarding, but once you understand Gamma, like, "Oh, how do you share it?" 

(01:08:41):
For instance, this was a great way to start testing some of that because they already understand Gamma, but now you're adding that new functionality. And then we can also watch them struggle and hear how they're struggling with the product. And so that has been a great way just to have a separate Slack workspace. Anytime we're thinking about something, they're the first to hear about it. Give us some early indication if we're on the right track or not.

Lenny Rachitsky (01:09:00):
I love this workflow that you shared of you have an idea in the morning, you built a prototype. Do you built it with AI prototyping tools like Cursor, Lovable, something like that?

Grant Lee (01:09:11):
Yep. That or it could be... Yeah, I mean we're lucky a lot of our designers also know how to code, so even before the recent tools, come up with some sort of functional prototype and then be able to ship that so people can start playing with it.

Lenny Rachitsky (01:09:24):
Yeah. So, you have an idea in the morning, you build a prototype using various tools. By the end of the day, you are getting feedback from real people using one of these platforms, Voicepanel or UserTesting, and just that loop saves you, I imagine, potentially months of just building the thing nobody wants and shipping it, launching it, and then just failing. 

Grant Lee (01:09:45):
Totally. Yeah. I think this is even more probably helpful for certainly a lot of folks that are starting to do much with vibe-coded apps. Yeah, that's great. You've lowered the amount of time to get something out there. Now, prove that it's useful to some set of users, and this should be again, every day, every week, you should be able to go through a ton of these, and then build on the things that seem to be working. 

(01:10:08):
I feel like that's almost like a way to speed run a lot of that early... you're in the idea maze, you think you have something that could kind of work. How do you actually break through so that people are actually finding value in what you're building?

Lenny Rachitsky (01:10:21):
Yeah, I love it because so many people hear this idea of just run your stuff by users before you do the user research. It sounds so hard and heavy lift-y, and the way you're describing it is very automated, very quick to do. You don't have to go think about finding random people in a coffee shop. It's just like these platforms exist where you could go plug in your thing, get feedback by the end of the day.

Grant Lee (01:10:44):
Totally. Yeah, and that helps you just move way faster.

Lenny Rachitsky (01:10:48):
Is there a feature that you were super excited about that you built and ran through this and just like, "Okay, that was a huge failure"?

Grant Lee (01:10:54):
I don't think any of the ones where we... We always try to chunk it down. So, none of the things we're testing earlier on are these massive features. They're always an inception or a starting point of, "This could be something interesting."

(01:11:07):
And then we take that initial learning and actually then build the product around it. It's never like, "Oh, we spent four months working on this thing. Let's see if anybody actually wants it." It's almost like we always start super early. And then a bunch of ideas die right away, but they're still pretty small ideas. 

(01:11:20):
And then the ones that kind of pass the initial test, you start building towards something that could be, hopefully, more game-changing or much more value-add. And by the time you're actually shipping, you've gone through 10 different layers of actually testing and iteration before it actually sees the light of day.

Lenny Rachitsky (01:11:34):
What's really interesting about you and the way your company operates, you guys are ex-Optimizely people, so you're very versed in experimentation. A lot of people talk about A/B testing experimentation as something that doesn't make sense for a startup because the scale is so low. What I'm hearing here, and I know this is something you talk about, is just there is actually a lot of ways to think experimentally, even in the early stages. Is there something more there you think is important for people to hear?

Grant Lee (01:12:01):
Yeah. I really think it's more of... The mindset you go into to almost any problem or opportunity is the saying of, "Strong opinions weakly held." I think it's totally fine to have some of these assumptions or hypotheses going into a lot of these things, but you should always know that there's a way to start trying to validate some of this.

(01:12:20):
As a founder, you're always trying to build conviction, and so you build conviction by not having it all live in your head, but getting it out there and start testing this with users, prospect customers, and starting to see what are the things that actually feel right. And sometimes you have enough data to be statistically significant. Sometimes it's more of a, "Hey, we at least were able to gut check this a little bit and get some qualitative feedback." I think that's still valuable. It shouldn't be this sort of all or nothing like, "It has to be static for it to be useful." I don't think that's true. 

(01:12:49):
In fact, I'll just share the very early story of when we first started Gamma, we knew we wanted to help change the way people communicate, and we actually had two different ideas we were parallel pathing kind of at the same time. Of course we had presentations, reimagining how people were creating presentations, and we also actually had this separate idea, which we called The Lobby, which is a virtual office. This is a place where this is, again, peak pandemic, much more hybrid work, much more virtual work. And so this was a place where everybody on the team, whether you're in the same office or not, could gather, collaborate to feel pretty magical. 

(01:13:26):
And we worked on both for six months. We worked on both the virtual office and the presentation product for six months. We would dog-food both. So, oftentimes we'd be in the virtual office, presenting the presentation tool and kind of use both. And after six months, we came to this conclusion that we wanted to go all in on the presentation tool. And the reason was, when we looked at the virtual office tool, we were sort of always competing against what we thought was something we'd never be able to surpass, which is in real life experience, actually being able to work shoulder to shoulder with your colleagues and having this environment where you really feel like you're building together. 

(01:14:05):
Virtual office could get pretty good, but we would never beat that. And so we were almost limited in our own imagination about how good could this product be versus the presentation product. We ended up with a million more ideas we thought we could actually introduce that could be better than how you work in PowerPoint today. We were just so energized by it. 

(01:14:25):
And so for us, that was this sort of A/B test of testing these two things that we invested equal amount of time into, and coming out at the other end realizing that, one, was going to be the product we were pour all of our blood, sweat and tears into making it great because we saw the potential in it.

Lenny Rachitsky (01:14:43):
I didn't know that about you guys, that you explored that other idea. There's so many startups that did that during COVID times, and like, "Okay, this is the future. We're all going to be remote, and let's work remotely in virtual offices." There's a startup and I'm a tiny investor in, Lindy, that is now a big AI agent company, and they did the same thing. I imagine that was their whole first concept. It was just these little avatars. It was like a little game where you walk around, go to little virtual meeting rooms. 

Grant Lee (01:15:07):
Yeah, it was a fun product to work on, but yeah.

Lenny Rachitsky (01:15:12):
Yeah, it's interesting how we just reverted back to the mean of just like, "Yeah, people are in offices again. That was a fun experience." Although things have changed. Just to highlight this point you made that I think is really powerful, I haven't heard it described this way before, just the power of testing prototypes very, very, very early, using these platforms that make it super easy.

(01:15:34):
We always hear, "Okay, you have a mock, you have a prototype. Yeah, testing with users always feels like this heavy thing. You got to have a user research team, go do interviews, do one-on-ones." What you're describing is something... I don't know why everyone's not doing this. With AI tools, it's so easy now. Have an idea, build the prototype, test it with, I don't know, is it like dozens of people? How many people actually run through a prototype on average?

Grant Lee (01:15:58):
20.

Lenny Rachitsky (01:15:59):
20 people. So, 20 people look at this thing, give you a bunch of feedback, you realize this was very dumb, or, "Here's the nugget that we want to lean into." And instead of building a thing, instead of doing all these user research sessions, things like that. Super cool. 

(01:16:12):
Okay. Is there any other big lesson or lever that has helped you grow to today's 100 million ARR, and $2 billion company? We talked about influencer marketing, we talked about testing prototypes, investing in brand and a little bit of paid growth. Anything else?

Grant Lee (01:16:33):
Certainly for us, the ability to adapt and move fast in this environment. I attribute a lot of what we've been able to accomplish to a few things. One is we do have a small team and a lean team, one that's able to move really fast. I think that means, by default, we have to look for a lot of levers where a small team can do a lot of different things. 

(01:16:54):
So, we can talk, one, obviously about how do you construct a team like ours and what I think has worked. And then two, going back to experimentation being this sort of thing where for us it's been a huge unlock because it allows you to not only test things and iterate a ton, it allows you to build much more efficiently. And so we've been in a startup where we've had great unit economics from the very beginning. We run profitably, we have really strong margins. 

(01:17:22):
I don't think that would be possible if experimentation wasn't core infrastructure to us because the temptation would be you just throw the most expensive model at every job and assume that's going to work. And the reality is that never is the case. And so for us to be able to actually test across 20 different models in production today, always trying to align the kind of value we're delivering to our customers with our ability to actually scale this operation, that's been in the background. 

(01:17:48):
And not always things that are easily quantifiable or things that you're sharing broadly, but it is core to our DNA. And again, going back to a team that came from Optimizely, probably not surprising, but I do think that's been part of our ability to actually execute at this level.

Lenny Rachitsky (01:18:03):
I love that the product is so beautiful and such a good experience. It's such a good example of experimentation and being really obsessed with running experiments, A/B tests. Data can create really beautiful products and experiences that aren't just feeling like some kind of micro-optimized flow.

Grant Lee (01:18:19):
Totally. Yeah. And just going back to one part of the team, part of that plays a huge role, which is you want to build a product where people talk about taste and brand and all these things, what they emote. I'm not going to throw in whether or not, yes or no, but I do think it makes a difference. And for us, at some point, more than a quarter of a team or about a quarter of our team was product designers. I think that's an unintuitive level of investment, or at least that's not common. You don't see many startups at our stage or early stage where a quarter of the team's product designers. 

(01:18:55):
And I think that was an important investment for us because when you think about with AI companies, so many companies are trying to invent new surface areas or new user experiences, and that's not possible if you're not really getting the foundation right, really thinking deeply about user problems and how can you solve them in a novel way. And so for us, we made that investment in the very beginning, even if it was counter to what other startups would do, because we actually felt like it was the right thing.

Lenny Rachitsky (01:19:21):
Okay. I definitely want to spend more time on hiring. Before we get to that, you've touched on this kind of concept that you guys are, what many described, a GPT wrapper company. You essentially sit on top of other models, do some cool stuff, charge for that. There's historically, and there's been a big shift here, historically, there's this sense that, "Okay, you're just this thin layer on top of the model. How is there any sort of motor leverage or long-term business model here when it's just the model that is doing the thing and charging you guys to do all this AI work?"

(01:19:57):
It feels like people have started to realize maybe that is the only place money will be made because the models are just so hard to compete with, and that's not a place you can build a business anymore. Talk about just what you've learned about this concept of being a GPT wrapper, and what people may not be understanding about the business opportunity there.

Grant Lee (01:20:15):
When you think about maybe just literally only being a wrapper on one model or one provider, yeah, maybe there's only limited amount of utility or value add. But then when you start thinking about, "Okay, I'm going to go really deep into this one workflow, and it's not just one model." It's maybe 20 plus models powering all different parts of the product, and then you're thinking about the orchestration that's required and you're thinking about, obviously if you're experimenting constantly being able to test across the newest models versus models that have been around that are cheaper, you're doing a lot to really... Your job is to, again, align value, maximize the value you're delivering to the end user in a way that's sustainable for you as a business. And so there's a lot more to that. 

(01:21:00):
And so for us, we've always been passionate about being very close to our customers, our users. Who, for them, their job to be done is visual communication, visual storytelling. And the default tool today is going into a PowerPoint or Google Slides where the amount of effort to create something... We've all been there late at night trying to format a deck, trying to find the right layout, all this manual and tedious work. 

(01:21:24):
Well, what if you could abstract all that away and give them something that feels a little bit more delightful, a little bit easier, much more effortless? What would that earn you in terms of a customer that wants to come back to your product? And so that's everything that we focus on is you need to go deep into the workflow, be empathetic to the user and their job that you're trying to solve, and of course, apply the best technology possible so that you're delivering on that promise of a product experience that's way better than the status quo. 

(01:21:52):
And I think if you can be laser-focused on, it doesn't matter if you're a wrapper or not, what is the technology you're doing and applying, that makes a real difference? So, that's the ultimate goal.

Lenny Rachitsky (01:22:01):
This is a really cool framework for how to think about what it takes to build a successful wrapper company that is... I don't know, I'll keep using that term. I don't know if it's [inaudible 01:22:09], but just some ideas don't work. These model companies are launching their own products here and there.

(01:22:16):
So, what I love about what you're describing here is almost like a heuristic that'll tell you if there's an opportunity/how to be successful as a GPT "wrapper company." I'm putting in air quotes. It sounded like maybe there's three here. But talk about just if you think about the bullet points of what you need to do to build a successful business on top of existing models.

Grant Lee (01:22:37):
I mean, I think the most important thing is before we even talk about the technology, so we're skipping to the part where you're trying to apply the most interesting models or technology to solve some problem. Start with solving the problem you actually care about. 

(01:22:53):
I think it's very tempting right now to chase shiny objects, like a founder might be able to gain some initial traction by literally being that GPT wrapper and solving any sort of problem. And you start to see some traction and then you just go with that. But before you do that, you should think about, "Is this a problem I can invest five to 10 years into actually solving? Do I care deeply enough about it?"

(01:23:13):
Because if you can't, you're never going to go... actually think about overcoming the variety of different hurdles, whether it's other startups or other incumbent tools that are trying to start doing the same thing. 

(01:23:24):
And so for us, we go back to... We've started this company because we really care about helping change the way people communicate their ideas. We really feel like this idea of visual communication, visual storytelling matters. It helps elevate everybody and it gives people much more opportunity to do the things that in the past if you weren't great at making slides, your ideas might've died, and someone else that was able to actually articulate their ideas better ended up winning the deal or winning the favor of their manager or their boss. 

(01:23:53):
And so we felt like that was the wrong, that didn't feel right, and so could we help democratize visual storytelling, visual communication? That was sort of our north star. And then you go back into thinking, "Okay, every step of the way, what are the tools and technology I can apply to help solve that and actually move the average person closer to that long-term vision of ours?"

(01:24:14):
And of course, AI has been, again, this gift where yes, you can apply that to solving this job. You can also apply that AI to many different jobs. Figure out what is the problem you care deeply enough to go deep, because going back to this sort of idea, you need to own the sort of end-to-end workflow. A customer needs to have... You want your product to live in their brain somewhere where when they think about, "Hey, I have to create a presentation." They come to you as the default tool.

(01:24:40):
And the moment they start creating it to the moment they ship it and send it to their boss, that end-to-end experience needs to feel magical, needs to feel great. And I don't think you can really do that unless it's actually a workflow you either know deeply yourself or you care deeply to actually help solve for somebody else.

Lenny Rachitsky (01:24:57):
So, some of the elements I'm hearing here is, one, is just like actually really care about solving this problem, not come from, "Oh wow, this cool thing happened and it worked. Wow, maybe I could sell this thing to people." Because you may end up having to work on this thing for 10, 20 years.

Grant Lee (01:25:11):
Totally.

Lenny Rachitsky (01:25:12):
Two is: understand the problem really, really deeply and have real empathy for the people trying to solve this problem. You have this problem creating presentations at your previous job, so you understood it, and I imagine you understand even more deeply now that you worked on this. Essentially, care really deeply, go really deep on the problem, have real empathy for the people facing this problem, and then there's this actually be able to solve this problem using the technology out there.

(01:25:39):
And you made this point about how you guys use 20 different models to do what you do. Talk a little bit more about that just because people may think, "Oh, okay, I could just go to ChatGPT or Claude and it'll create an awesome presentation for me." Why does it take 20 different models? Why is that such a big part of the success here?

Grant Lee (01:25:55):
Yeah, so going back to the workflow, you're trying to go and break down every step of the creation process for a user. So, the moment of the initial idea to maybe creating an outline of what you want to present or articulate to creating the first draft. What do we show you there to editing the content? 

(01:26:14):
Like, "Okay, I have a first draft, but it's only 60% of the way there. How do I get to 100% of the way there?" Those are all things that might require different models. The initial outline might be better served by something that's purposed-built for actually creating the best outline, the best narrative, the best story arc, versus one where you're actually going back and saying... Gamma, our agent can actually go and review your entire deck and say, "Actually, if I were to add suggestions, I would say, 'You may want to change the visual layout on these set of cards, and you may want to actually change the imagery or the visuals for these cards to match everything else.'"

(01:26:50):
These are things that, again, every model might be better served for different things. And so knowing how that actually breaks down into the end user, sitting down, working on the product, working on their presentation, how do you help them? I think you can only do that by understanding-

Grant Lee (01:27:00):
Their presentation, how do you help them? I think you can only do that by understanding that workflow and then breaking that down into finding the right tool for the right job.

Lenny Rachitsky (01:27:08):
That is super interesting. Essentially there's like, here's the things that AI has to do for us. I don't know, imagining some kind of a storyboard and then it's figure out the model and level of model and prompt for that model to achieve each of these steps as best as possible.

Grant Lee (01:27:23):
Totally. Yeah, and it applies to even on the visual side, finding the right image. I think certain models are great at photorealistic output versus others want more of the artistic vibe or something that feels more abstract. And so again, you can choose the right model for the right job. It doesn't mean that you'll never use other models, it's just like as you're going through that workflow, the content might dictate what's the best use case. So in that particular use case and so you're always trying to map to that, what is the end user trying to accomplish in that certain moment?

Lenny Rachitsky (01:27:55):
Which models are you finding most useful in the work? I don't know, is there anything surprising about, "Oh wow, this model's actually really good at this and this is really bad at that."

Grant Lee (01:28:04):
Yeah, I think surprising or not surprising, the leaderboard is constantly changing and so this is where you almost, you have to have the mindset that you can be adaptable. We're just getting to the point where there's going to be more personalization too, is going back to a consultant's going to have different needs than an educator. Educator's trying to engage their students. They may want to have language or visuals are more animated and that makes sense. Consultant can't get away with that. They may need something that is much more structured or information dense. And so again, how do we actually be the same tool that can serve both of those needs? I think that's where it becomes interesting and it's almost like there isn't necessarily even a "best model". It's like what's the right model for that particular user? That's actually a much harder problem to solve and we're just starting to try to embrace some of that now.

Lenny Rachitsky (01:28:50):
Is there one that's just like, "Oh, that's actually really cool." For something that we didn't expect?

Grant Lee (01:28:54):
Early on, things like creating the outline, Perplexity was actually great. Not one that people talk about as often, but creating the outline and doing web search and actually integrating some of those elements together for us was pretty powerful.

Lenny Rachitsky (01:29:07):
Okay, there's two more things I want to talk about. One is pricing. How you guys figured out your approach to pricing. You guys started monetizing really early and that feels like such an important piece to AI startups because you're spending real money on an inference and other things. And then I want to talk about hiring. So in terms of pricing, when did you decide it was time to really start charging and then how did you pick your approach to pricing your actual price?

Grant Lee (01:29:32):
So we kind of stumbled into having to do pricing and packaging. I mentioned our big AI launch in March 2023. This was pre-revenue, so we wanted just to get, we focused all of our effort on the first 30 seconds, literally all hands on deck, just trying to get that right. And we spent zero time on actually monetization. So we had a credit system. All new users get 400 credits. Once they burn through those credits, there was actually nothing more you could do with AI. It kind of just got cut off. And so Intercom for us was just blowing up with people saying, "How do I purchase more credits? I want to keep using this thing." In a very fair question. So basically all of April we ended up having to do a quick sort of pricing and packaging exercise. We did a couple of different things.

(01:30:18):
We did run a form of Van Westendorp, which is just understanding-

Lenny Rachitsky (01:30:22):
Classic.

Grant Lee (01:30:23):
...what is the overall willingness to pay. And so we did use that. We did kind of integrate some forms of conjoint analysis, which is just trying to understand what are the features or things that people actually value in your product. And so we'd survey a lot of our early users and ended up coming to a price point that was, in the beginning we only had one plan type. It was roughly like 20 bucks a month. Part of this was also just realizing we almost didn't need to overthink it too much because this is when the initial wave of AI companies and startups were coming out and products are coming out and you almost end up becoming anchored by, what does ChatGPT charge? Because everyone becomes familiar with that price point. And so we ask ourselves how complicated do we want to make it?

(01:31:05):
We always default to remove friction, make it as easy as possible for a user to understand. And so we end up coming up with a similar price point and ship that as the V1, basically end of May 2023. And for us, we wanted to see a couple of things like, okay, we have the initial price point. Is it economical for us at that price point? Are we actually making money? And we'd monitor there for that for many, many months realizing that yes, actually at that price point we could still generate pretty good margins and that would allow us to reinvest that profit back into growing the business.

(01:31:37):
Continue to add obviously head count, but then also investing even more into inference costs, whatever we wanted to do to experiment broadly with AI. And so we've always had that pricing and packaging. Does it not only need to be easy to understand for a user, obviously you have to have strong conversion rates, but it should be something where you feel like you could build an enduring durable business off of. And if it's not right, then you can always go back and try to tweak things, but it's something you should be monitoring as early as possible.

Lenny Rachitsky (01:32:06):
What's interesting, we have the head of ChatGPT on the podcast and he shared the way they picked ChatGPT's prices is the Van Westendorp survey that they ran in Google Forms.

Grant Lee (01:32:14):
Totally. Yeah, I listened to that one. Yeah, it was a great one.

Lenny Rachitsky (01:32:17):
Oh, what a, that survey man, what a, and not only just that survey being the slick, I'm imagining that XKCD comic with the open source little, I don't know, block holding up the entire world, like this one little piece of code. That's like the survey, just behind everything. But it's interesting how that one decision just created this ripple effect on all AI startups, 20 bucks a month. Of course that's what everyone's doing.

Grant Lee (01:32:43):
Totally. Who knows what would happen if they chose a different number, but here we are.

Lenny Rachitsky (01:32:46):
Everyone would be so much more rich if it's just like 25 bucks. Someone. Imagine the GDP of growth-

Grant Lee (01:32:52):
Yeah.

Lenny Rachitsky (01:32:54):
...from that. Oh man. Okay. And then the way, so was Van Westendorp helped you pick a price point and then you said this conjoint analysis, we actually have a guest post that I think describes how to do this well and if not we'll find, appoint people to how to actually approach this. You started charging, so was post product [inaudible 01:33:11] launch, you launch with no paid features. People were just like, "I want to pay, I want to keep using this." You're like, "Okay, I guess we've got to start charging."

Grant Lee (01:33:18):
That's right. Yep.

Lenny Rachitsky (01:33:20):
Is there anything, looking back, I guess just you wish you'd known when you were approaching pricing for folks that are doing this now like, "Oh, we should have done this differently or should have thought about this."

Grant Lee (01:33:28):
Yeah, I mean that one's hard. I think you never want to obviously just throw something together without giving it much thought, but for us with limited resources, we focused on the only thing we thought mattered, which was getting some initial users and having that organic growth. And I think there's maybe two checkpoints of thinking about whether or not you feel like you have product market fit. I think one checkpoint is organic growth. The second is are people willing to pay for the product? And I think if you pass both those, you feel like you've, at least within some pocket of the market you have some PMF. So I think those are both important questions to ask depending on your resources. Ideally you can do kind of both and experiment a little bit along at the same time. And then by the time you actually have paying users, you sort of check some of those boxes for yourself.

Lenny Rachitsky (01:34:15):
By the way, I love that your launch pricing. You're like, "Okay, let's figure out if we're actually making money or not." It's not obvious with AI companies. [inaudible 01:34:24]

Grant Lee (01:34:24):
Well, we also didn't have a choice because at that point runway was also low. So if we weren't making money, well we would actually be in a tough spot.

Lenny Rachitsky (01:34:31):
That's such a good point that you did not have a huge amount of money sitting around to spend on the way a lot of companies in AI do, just, "We'll deal with it and we'll figure out how to make money later."

Grant Lee (01:34:40):
Totally. Within a couple of months we had hit a million in ARR and became profitable. And so those were both two exciting milestones for a company that months prior were heads down figuring out how we even survive.

Lenny Rachitsky (01:34:53):
What a story. I'm so excited to be telling this story. Okay, final topic I want to talk about is hiring. You have some really hot takes on hiring, clearly it's worked out for you guys. What are some things you've learned about hiring well, what is your approach to hiring?

Grant Lee (01:35:08):
So we had this mantra internally, I mean even before the sort of AI launch for us, which was "Hire painfully slowly." And I think the temptation is once things start working, you just start, [inaudible 01:35:23] scaling this thing and start adding more and more headcount. And for us that always, I don't know, that didn't feel right. We wanted to build the team very thoughtfully, be lean, but also be a team that every individual feels like they have high amount of impact that they have on a daily basis. And so for us that was from sort of the very beginning. And so even as we've scaled up, I think we've been super efficient by nature of just being a very lean team.

Lenny Rachitsky (01:35:47):
So I think a lot of people hear this advice of "Stay lean, be efficient." You have some even more concrete pieces of advice here of just what that looks like. You have a huge, I don't know, philosophy of just huge leverage per person. You focus a lot on revenue per employee. Talk about that.

Grant Lee (01:36:03):
So obviously we look at things like revenue per employee, but we never let that be the sort of North Star. It's not something that dictates our strategy per se. Same thing with profitability. I think by being efficient, that ends up becoming a side effect of yeah, we are profitable and growing. But I think for us more is like we care a ton about adding the right team members. So it's easy. You can almost sort of shoot yourself in the foot as a founder by just setting the wrong goals. If your goal is to double in headcount and add a hundred people to the company, then that becomes the goal. The goal is no longer to add the best people. It's no longer to maintain a high quality bar. The goal is to hit a hundred people and that's everything everyone's focused on. So then guess what?

(01:36:44):
If that's the goal, then the thing that ends up dropping is, okay, maybe we will settle for employees that are good enough and we're going to make sure we get to that hundred because a hundred is going to help us get to the next phase of growth. And then the next phase of growth. And I think we've tried to resist that temptation, which is we want everybody that comes through the door and joins our team to really be the type of person that represents Gamma. Our first 10 to 12 employees, we spent so much time really getting the DNA right. I think Brian Chesky talks about this. Your goal is you get that first 10 and you want to be able to then replicate the next 10 and then replicate the next 10, but that 10 needs to be all super cohesive. You need to have the same shared values, same principles, same ambition, same vision, and if you don't, then what are you even replicating?

(01:37:32):
Right? At that point you're just adding headcount and you can easily just be adding headcount because we're chasing the next shiny startup to join. And so for us, we really focused on that first 10. That allows us to really have this sort of community of teammates that basically want to stick around. A lot of founders think about not wanting to have a leaky bucket on the product side, but the same thing applies on the team side. If you have a leaky bucket, people are just constantly leaving, revolving door. That's a huge amount of cost. The continuity cost is massive and it's really hard to quantify.

(01:38:08):
And I mentioned our first 10 employees, all 10 of them are still here today, five years later. And so that sort of continuity, it means that you have this tribal knowledge that sticks with you. It means that people can continue building and having that sort of cohesive feeling. So I think that's one piece that's just like, it's hard to quantify, but I do think, new startups I would advise just to really be thoughtful about that, get that to a point where you really feel confident that as you're adding the next 10 and next hundred, you're actually replicating the same DNA and not actually just adding a bunch of random people to the company.

Lenny Rachitsky (01:38:39):
One of your very specific piece of advice is hire generalists versus someone that's just really deep in one thing, why is that so important? What does that look like?

Grant Lee (01:38:47):
This very much feels like the age of the generalist or the rise of the generalist right now. When we think about of a team that can be really flat, you still want people that can be very spiky in certain areas. So for instance, obviously a product designer that knows how to code, that's great. It allows you to actually span across many different domains. And again, an organization that's super flat, when you're wearing a lot of different hats, that means every individual, if you're a generalist, you can wear by default a lot of different hats. And that's helped us just maintain this idea that the work, the opportunity in front of us can easily expand. Each person plays a huge role. They don't need to wait and ask for permission. They can go after and pick up a piece of work because it's there and they can at least get it started even if they're not the one that always sees it through.

(01:39:34):
And so for us, I do think this rise of the generalist is going to be important. You can always augment that by working with contractors or agencies that are hyper-specialized in certain areas. And this is where, for instance, going back to influencer marketing, you might work with an agency rather than kind of scale up your own influencer marketing team. You work with a hyper-specialized team there. But my marketing team is all generalists. Our head of marketing more recently launched this cool drone show in San Francisco. We have 4,000 people in San Francisco. The mayor came by, she created that entire project and managed that entire project end to end herself while also managing the entire marketing team. And so it's like this idea that a generalist is able to play all these different roles, can still be super high impact. For us, it also goes hand in hand with, I mentioned sort of this other role, which is the player coach. Traditional management layer is like a manager manages a ton of people and that's kind of their core focus.

(01:40:33):
All of our people leaders are player coaches in that they still do the end work themselves and they can mentor and coach those around them. This analogy came from, or this mindset came from, it's something I borrowed from just the sports world in general because there's a lot of sports that just move incredibly fast. Like football for instance, it moves really, really fast. And so you might have a coach that's calling into play, but the quarterback can actually make a last-minute adjustment based on what he's seeing the defense do. And so you want a player that is on the field that can adapt as needed and that way the coach doesn't have to call every single thing in. He's just kind of giving you the general intent of what you want to run as the play and then the quarterback can still make the adjustments.

(01:41:13):
And so all of our people leaders, our management layer is all folks that actually can make those adjustments. If they're seeing something that doesn't feel right on a daily or weekly basis, they're adjusting priorities for that team and they're still doing the work themselves too. They're so close to it that they understand what is the relative prioritization at all times. So both of those I think have been, when I think about founders, they oftentimes think about innovation in the sense, we're going to innovate on products or innovate on technology. I think every founder today has a chance to innovate on org design, and that starts by just thinking about what is the type of company we want to build today? What does it mean? And when it comes to the management later, what type of sort of leaders do we hire? What does it mean when it comes to hiring specific roles and specific functions? All of that is a chance for you to be very thoughtful and build a company that you're excited to be at for hopefully many, many years to come.

Lenny Rachitsky (01:42:07):
So what I'm hearing here is manager, there's no pure managers at Gamma and your plan is to not have people that are just managing the ideas. Everyone, even a manager is doing their own IC work.

Grant Lee (01:42:18):
Yes.

Lenny Rachitsky (01:42:19):
And then the other piece of advice here is just generalists. People that can do a lot of stuff, and I hear this a lot on this podcast just like everyone is, there's no more just like you're a designer, that's all you're going to do. Designers need to build stuff, market stuff, write some PRDs probably.

Grant Lee (01:42:34):
Just one thing to add is that's where we are at today. I think being adaptable means that certain things may evolve and change and how the player coach model evolves and maybe in certain functions or as the team scales, that's not going to be practical everywhere. I think the reality is you just have to know and be willing to adopt different frameworks over time and being honest with yourself with what's working, what's not. I think we're constantly trying to learn and evolve ourselves. I think we're doing it in a way that we don't believe it really has been done before, and so we have to kind of pave our own path over time.

Lenny Rachitsky (01:43:10):
I love that. Giving yourself an out when the time comes when you need to just hire managers.

Grant Lee (01:43:14):
A year later when you invite me back, I'll say, "Yeah, this is what we learned."

Lenny Rachitsky (01:43:16):
Yeah, that makes sense. That's probably going to happen. It's like people are like, "We don't need product managers." [inaudible 01:43:22] "I see. Maybe we do." Yeah, that makes sense. One last piece I want to talk about is you have this really cool quote that you shared on Twitter. " When you find someone exceptional, bet big on them." This is a big part of your philosophy is just bet big on the people that are doing super well. Just talk about what that looks like and why that's so important.

Grant Lee (01:43:40):
Yeah, I mean this starts top of the funnel, which is you meet candidates, you decide who you actually hire. And so if you don't start with a high bar there, going back to what is the goal? The goal is to hit a hiring target versus maintaining a super high quality hiring bar. Those are different goals and I don't think we've ever kind of dropped our bar. And so then you bring somebody in that you think is exceptional, that brings something unique to the table, that can be a good teammate. When they're thriving, you just give them more and more resources. I think what you realize, another sports analogy is when you're on an A team for instance, or a team that you feel like is exceptional, A players want actually more playing time. You never see a star player that says "I actually want less playing time."

(01:44:26):
They want more time on the field, they want to actually go after the hardest problems. They want to be able to feel like they're making a huge impact. And so if you have fewer exceptional teammates where you can just throw almost anything at them and they'll figure it out, that feels for you as a team, just feels great because then they get what they find rewarding, which is the ability to go after hard hairy problems and to be able to come out through the other end feeling like they've accomplished something. And I think that for us has always been something that goes beyond just almost everything else. We give people a chance to really thrive in this environment and we try to nurture that as much as humanly possible every step of the way.

Lenny Rachitsky (01:45:04):
Is there anything else around hiring that you think is really important or a big lesson you've learned or lesson you share that we haven't talked about yet?

Grant Lee (01:45:12):
I mean, there's some of these intangibles, which is for the founding team, does this feel like this could be your life's work? When you're pitching a potential candidate, does this feel like something where you're actually committed? The unfortunate side of a lot of what's happening in the AI world broadly is I think you're coming to learn which founders are sort of missionaries versus mercenaries. And many that were just chasing maybe just a big outcome, or something shiny, or something to feel good about themselves, they'll go off and then the company, I guess doesn't live on or maybe has to find a different way, a different path.

(01:45:47):
And so something I admire is you look at some of the founders, obviously before this sort of AI era, folks like Dylan or Melanie, Figma, Canva, Ivan at Notion, they've been doing this for over a decade now. They had many chances to just leave and sunset off into doing whatever they wanted to do, but they care so much about the mission, they've stuck it through. And I think when you're talking to candidates, candidates can kind of tell, is this something the founders even care about? And I think you're going to have a better chance of attracting true missionaries, people that want to build with you for the long haul, if it's authentic and it's something you actually care about.

Lenny Rachitsky (01:46:24):
Oh man, I keep saying this. I feel like we could have at least five more hours of stuff to talk about. That'll be good content for when you come back and you're making a billion dollars a year. Before we get to our very exciting lightning round, Grant, is there anything else that you think is important for people to hear? Any last, I don't know, lesson you want to double down on? Anything you want to leave listeners with?

Grant Lee (01:46:48):
Yeah, I mean, just going back to the original story of that was probably the ultimate low point. Having an investor that spent 20 minutes listening to my pitch, telling me that it was the worst thing, worst idea in the world. I think throughout the journey there's going to be those low moments. And when I think about being a founder and working a startup, you're honestly just trying to increase your luck surface area as much as possible. And for me, luck surface area has two dimensions. The first dimension is people. Who are you surrounding yourself with that share your same ambition, share the same values, same principles, and find those people and then give yourself enough time to prove that you guys can accomplish great things. I'm lucky to have two amazing co-founders. We've been working on this thing for five years. There's 0% chance we'd be where we are if I didn't have them. And we've had to overcome a lot. But I guess for us it's like creating that own luck over a long time horizon has been the only way that it's been possible.

Lenny Rachitsky (01:47:48):
Well, it's clearly showing in the success you guys are having. Grant, with that, we've reached our very exciting lightning round. Are you ready?

Grant Lee (01:47:56):
Yep. Yes.

Lenny Rachitsky (01:47:57):
All right. I've got five questions for you. First question, what are two or three books that you find yourself recommending most to other people?

Grant Lee (01:48:07):
Yeah, so I'll give one that's for pre-product market fit folks and the one post-product market fits.

Lenny Rachitsky (01:48:07):
Perfect.

Grant Lee (01:48:12):
Pre-product market fit I would say is Shoe Dog, which is written by Phil Knight, founder of Nike. And he talks about two things. One, you should chase your sort of crazy ideas, but these should be ideas you're passionate about. He was an athlete, and so not surprisingly, he focused a lot about creating tools or shoes in this case for other athletes and was passionate about that. And the second thing he taught me was going back to the team thing, he surrounded himself with other people that were super passionate about athletics and shoes as well. And so the folks that he had as his initial startup crew were all that.

(01:48:49):
And I think that gives you a chance of overcoming a ton, where you're focused on problems you actually care about solving, and you're dealing with a team that shares the same ambition as you. Post-product market fit, there's a book called 7 Powers by Hamilton Helmer, where I think when you think about how to build a durable business, there's so much in there. I think there's a lot that you can kind of read and reread as you kind of evolve and hit new milestones yourself. And so much of that can be both tactical but also zooming out and thinking about what are the big picture strategic questions you as a founding team you need to be thinking about. So both are great.

Lenny Rachitsky (01:49:21):
Hamilton was on the podcast, we'll link to that episode. I also love that book. Many people mention it. Next question, do you have a favorite recent movie or TV show you've really enjoyed?

Grant Lee (01:49:31):
Yeah, The Lazarus Project is one, I'm a huge sucker for time travel and sci-fi, so this is one I just started watching. And for me, it has all the right ingredients for a fun show.

Lenny Rachitsky (01:49:44):
Is there a product you recently discovered that you really love?

Grant Lee (01:49:47):
Yeah, I mentioned this already, Voicepanel. So again, a full disclosure angel investor, but we've been using it and going back to kind of being a cheat code for folks that are starting to experiment a ton with different ideas, vibe coding, maybe some of these might get this into the hands of users, hear what they think about it. I think, and honestly can help speed up a lot of things and save you time from wasting time on the wrong ideas or ideas where there's no market.

Lenny Rachitsky (01:50:13):
Is there a life motto that you often find yourself coming back to in work or in life?

Grant Lee (01:50:18):
Yeah, so there's this Chinese idiom that my mom used to say, it's a [foreign language 01:50:24] which the translation is "A frog at the bottom of a well". And the story is like there's a frog at the bottom of the well. He looks up every night and he sees the world and he imagines he knows everything about the world. And then one day a bird comes along and describes all the things that he sees, the ocean, the mountains, and the frog realizes that what he sees is just such a limited part of the world and the bird asks, "Do you want to come join me?" And kind of see the rest of it. And so frog goes along.

(01:50:54):
And so for me, I came from a pretty modest childhood. My parents, we didn't have a whole lot and I think it would've been very easy to kind of have a very narrow lens on the world and be like, "Oh, this is what it is." But my mom never allowed me to do that. She always pulled me to dream much bigger to say, "Hey, the world is vast. It's your opportunity to seize it. You have to go out there, don't have a narrow view of what's possible. Always dream bigger." And so for me, that's always carried through and every time I feel like I'm thinking too little or too small, I try to zoom out and remind myself that there's much more out there to go after.

Lenny Rachitsky (01:51:30):
That is so good and so important and so valuable in today's world where so much more is possible. Just like, most of what limits people it feels like now is just, I don't know what idea I have. I don't know what to do. Now you could get things done so much quicker and so much more is possible. So that's such valuable thinking. Okay, final question. You help people present better. Your tools basically help people become better presenters. What's one tip you've learned or one tip you teach people to become better presenters that might be helpful to listeners?

Grant Lee (01:52:00):
Yeah, I mean, I'll go back to the consumer advertising concept, which is one idea at a time, this notion of you give them one egg, someone can catch it, give them too many eggs, they're going to drop it. So don't try to throw too many concepts all at once. Keep it simple. People will appreciate it. And so with every sort of presentation, break it down into the core concepts, try to make sure you're covering one at a time. And I think once you sort of see a through line there, then it becomes easy for it to package up into something that feels more cohesive.

Lenny Rachitsky (01:52:32):
Less is more, as they say.

Grant Lee (01:52:35):
Totally.

Lenny Rachitsky (01:52:36):
Grant, two final questions. Where can folks find you online? Where can they find Gamma? What should they know? Just plug anything you want and then how can listeners be useful to you?

Grant Lee (01:52:44):
Yeah, so you can find me on both Twitter and LinkedIn, DM's open. I honestly hear just knowing how hard the journey is in general, whether just thinking about a startup idea or you're deep into startup land, I want to be hopefully helpful. I'm going to be hopefully your biggest cheerleader, so let me know how I can help. And then for us, we're always looking for feedback. So if you're trying Gamma, it's falling short of your expectations, let us know. We'd love to help in terms of just trying to make it better. And yeah, really appreciate all the feedback and support along the way.

Lenny Rachitsky (01:53:16):
Grant, this was awesome. I really appreciate you making time. I know you're trying to build a crazy fast-growing startup with a lot going on, so I really appreciate you making time for this.

Grant Lee (01:53:24):
Thanks, Lenny. It's been a blast.

Lenny Rachitsky (01:53:24):
It's been a blast for me too. Bye everyone.

(01:53:29):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Lessons from working with 600+ YC startups | Gustaf Alstrmer (Y Combinator, Airbnb)
**Guest:** Gustaf Alstromer  
**Published:** 2023-03-02  
**YouTube:** https://www.youtube.com/watch?v=ZoKLofsp8u0  
**Tags:** growth, retention, activation, metrics, roadmap, iteration, a/b testing, experimentation, analytics, subscription  

# Lessons from working with 600+ YC startups | Gustaf Alstrmer (Y Combinator, Airbnb)

## Transcript

Gustaf Alstrmer (00:00:00):
If I drill down what makes companies fail, it's quite simple. It's just like they don't talk to users, which means they don't find product market fit. And if they don't find product market fit, nothing else really matters. What mistakes do people make is like it is all about that. It's all about talking to customers and learning that you're building something that's actually useful. YC Slack headline is make things people want, and it's still true and it's always going to be true.

Lenny (00:00:30):
Welcome to Lenny's Podcast where I interview world-class product leaders and growth experts to learn from their hard one experiences building and growing today's most successful products. Today my guest is Gustaf Alstromer. Gustaf is a group partner at Y Combinator where he's been for almost six years. Prior to that, Gustaf was at Airbnb for over four years where he started the original Airbnb growth team and where I was very lucky to get to work alongside him for a number of years. Gustaf is also at the heart of YC's increased focus on climate tech, and in my opinion is one of a handful of people who've had an incredible impact on the increasing amount of investment and people flowing into climate tech.

(00:01:10):
We chat in depth about what's happening in climate tech, why things have shifted so much recently, what's new and exciting, and how to think about the space if you're hoping to make the jump. We also get deep into Gustaf's experience working with over 600 startups over his time at YC. We talk about what are the most common mistakes that early stage startups and founders make, what advice YC partners give founders most often, the most common attributes of successful founders, the importance of having a technical co-founder and why that's the case, so much more. I guarantee you will leave this episode smarter and more inspired and I can't wait for you to hear it. With that, I bring you Gustaf Alstromer after a short word from our wonderful sponsors.

(00:01:53):
This episode is brought to you by Linear. Let's be honest, the issue tracker that you're using today isn't very helpful. Why is it that always seems to be working against you instead of working for you? What does it feel like such a chore to use? Well, Linear is different. It's incredibly fast, beautifully designed, and it comes with powerful workflows that streamline your entire product development process from issue tracking all the way to managing product roadmaps. Linear is designed for the way modern software teams work. What users love about Linear are the powerful keyboard shortcuts, efficient GitHub integrations, cycles that actually create progress, and built-in project updates that keep everyone in sync. In short, it just works. Linear is the default tool of choice among startups and it powers a wide range of large established companies such as Vercel, Retool and Cash App. See for yourself why product teams describe using Linear as magical visit linear.app/lenny to try Linear for free with your team and get 25% off when you upgrade. That's linear.app/lenny.

(00:03:02):
This episode is brought to you by Eppo. Eppo is a next generation A/B testing platform built by Airbnb alums for modern growth teams. Companies like Netlify, Contentful, and Cameo rely on Eppo to power their experiments. Wherever you work, running experiments is increasingly essential, but there are no commercial tools that integrate with a modern grow team stack. This leads to wasted time building internal tools while trying to run your experiments through a clunky marketing tool. When I was at Airbnb, one of the things that I loved about our experimentation platform was being able to easily slice results by device, by country, and by user stage. Eppo does all that and more, delivering results quickly, avoiding annoying prolonged analytics cycles, and helping you easily get to the root cause of any issue you discover. Eppo lets you go beyond basic clickthrough metrics and instead you turn north star metrics like activation, retention, subscriptions, and payments. Eppo supports test on the front end, the back end, email marketing and even machine learning clients. Check out Eppo at getepo.com. Get, E-P-P-O.com, and 10X your experiment velocity.

(00:04:15):
Gustaf, welcome to the podcast.

Gustaf Alstrmer (00:04:17):
Thank you, Lenny. Honestly, it's so great to see you. I'm excited to be talking to you.

Lenny (00:04:22):
I've been looking forward to this conversation for a while ever since we booked this. We worked together at Airbnb for many years. I was really lucky to get to work with you before you moved on to bigger and better things at YC. Speaking of Airbnb, you once tweeted about how special an experience that was for you, and I think even more interestingly, how many of the people that have left Airbnb can't find another place that's as special that just like that bar has been set too high. And so my first question is just like, what do you think it was that made Airbnb so special? Why was it such an important experience for you and other people? And even more importantly, just what is it that you take from that experience that you bring to startups that you work with now?

Gustaf Alstrmer (00:05:02):
Yeah, it's funny. I think this year in a couple of months it'll be 10 years ago since you and me started Airbnb.

Lenny (00:05:07):
Wow.

Gustaf Alstrmer (00:05:08):
It was 2012. The reason I treated that was I asked everyone that I'd met after Airbnb, because I had this experience of like, this was the highlight of my career up until then, at least being in the team like that and I asked everyone, "Have you found anything better?" Besides maybe one or two people, I haven't heard anybody say that they found something better. And they all missed that dearly. I thought a lot about why that was the case, but I would say Airbnb did not feel like a normal job. It felt like more like a group of friends trying to just do something together and we were friends. At least in the beginning it did not feel like this was a job. It was sort of like an ongoing project and an assembly of amazing people. I think in the end we managed to build two things, like a really successful company, thanks to Joe and Nate and Brian just for starting this. Without them there would be nothing to build.

(00:06:04):
I think people don't like to use the word family, but I feel like that way because when I go and meet with Airbnb alumnis from that team. We have a very special bond that reminds me of close social connections more than anything else. It does not remind me of coworkers. I asked myself why this was the case. The best answer I have is probably we brought in a special type of people. We had very diverse backgrounds. A lot of us was former founders. Not many of us were career people from the technology industry of the early days, not many of us.

(00:06:37):
I think that bar that we set, the first, I believe when I joined there was probably five or seven PMs and there was 30 engineers or something and you joined a little bit before me, those people set the bar or set the standard of what we were looking for afterwards. I think it took a long time to change that narrative. I mean, eventually you have to hire people that only had big corporation careers, but I don't remember we did that for a long time. When I actually read my goodbye note recently, my words there still means a lot to me and it means sort of like you're trying to reflect on exactly these things on like, building a great company that became successful and being part of this sort of family of really close friends.

Lenny (00:07:21):
So it sounds like if you had to boil down what Airbnb did, it sounds like hiring was the main piece that impacted the way it turned out just like the founders being very specific about the type of people they were hiring.

Gustaf Alstrmer (00:07:32):
Absolutely.

Lenny (00:07:32):
Is there anything that's like, I don't know, a take away there of just what you recommend to founders, like hiring. People know, be very careful who you hire. The first, I don't know, 10 people will impact the culture long term. But I don't know. Is there anything just abstracting away there of just what to look for in that first batch of hires?

Gustaf Alstrmer (00:07:50):
It's a tricky one because I would like to say that all the things that we did were the cost of the outcome of this, but that's not really how the world works. Some of the things we did work, some of the things that we did did not work. It's hard for us to actually disentangle what those things are, but I think we can talk about the things that we did. First of all, we made sure we hired people that were really excited to be there, right? They wanted to build Airbnb and they were really excited to work on Airbnb. That was the most important thing. Of course people had other offers, but I think you can figure out from those offers are you excited to be here or not. So that was probably the first thing.

(00:08:30):
The second thing I think is trying to understand the true motivations of the people that were there, like lower, "Why are you here?" We did something we call culture interviews that I think the founders have written about or there's probably content online about this. We did a lot of culture interviews early on to try to figure out we got the people that were there that mapped our core values and were really excited to work on Airbnb. I think finally, I don't know how this happened, we did pick people from diverse backgrounds. Most startups don't have most of the PMs being former founders, but I believe that was the case for the first 10 or 12 or 15 PMs at Airbnb. A lot of us were former founders. I think that that made a big difference for how you make decisions and how you get started on things.

(00:09:21):
I think I actually see this a lot in the Airbnb founders. They really care about the time at YC and they tried to recreate YC inside Airbnb a couple of times with demo day and with so new products completely isolated from the rest, starting with doing things that don't scale and talking to customers. So I think that that experience had made a big impact on them, but it's hard to say just these two things go and apply these things. It's actually kind of hard to say, "Well that will work at it as Airbnb." I think that's a really tricky question to answer.

(00:09:51):
The last thing I would say is Airbnb had an incredible business model, an incredible business from early on and it was hard to fail. What I mean by that is it's hard to fail with a company. You can fail with individual things inside the company, but a company was still going to succeed. I think we all felt that. A lot of companies don't have the ability to take risks like Airbnb did early on because they don't have something that's so obviously great.

Lenny (00:10:18):
That's a really interesting point on the last piece that you may have the most amazing culture and hire incredibly well, but if the company doesn't work out, it's not going to be looked back as like, "Wow, that was an amazing experience, but we failed."

Gustaf Alstrmer (00:10:18):
Yeah.

Lenny (00:10:30):
Yeah, that's interesting. So you mentioned YC and this kind of is a good segue to where I want to focus most of our time. You mentioned that you've worked with over 600 companies at this point, which is absurd. It feels like it's you get some statistical significance on takeaways at this point of what works and doesn't work. So I have just a bunch of questions about your experience working at YC and with all these companies. The first is I think about this quote that Elad Gill tweeted once and he wrote, I think, a post about it. Elad Gill is a legendary angel investor. He said that starting a company is an act of desperation. You're either desperate to change the trajectory of your career or you're desperate to make a bunch of money, you're desperate to achieve some kind of mission or build a specific product that you're just like, "I need this to exist." I'm curious if you agree with that sentiment and then I have a follow-up question around that.

Gustaf Alstrmer (00:11:20):
Yeah, actually I haven't heard it before, but you know me, I'm an optimistic person. I think it probably reflects on my view of this question, but I would say desperation sounds like a negative place that you're starting at. I actually think that most people to start companies start from a positive place. But the motivations, I agree with what he said, can be very diverse for successful founders, right?

(00:11:41):
So we actually asked this in one of the early Group Office Hours sessions. We asked them, "Why are you doing this?" And we don't want to hear an answer like, "I found this niche of the market.' That's not the why. The why is like, "Why will you come in and work late after four years when you have no money left and everything's going to shit?", right? Then the niche market is not the answer. There's something deeper than that. We've learned that it varies a lot for people's motivations to start companies. Some of them just want to solve some technical problem that they feel are passionate about solving. Some of them want to prove themselves in front of others or prove themselves towards themselves. Some have grand really important motivations to change the world and they will say things like, "I want to give everyone water or I want to solve climate change or I want to democratize publishing." You can imagine any number of large ideas. Some people just want to start a big company and just want to be successful.

(00:12:44):
It doesn't matter, in my experience, what your motivation is. I don't think either of these motivations. It sounds like some of them will be better than others. In my experience, it's not the case. The motivation will change over time to just running this thing, right? Like once something becomes big, it's hard to think every day about exactly why you got started because the motivation is just like it can be fun and work on boring things because it's fun to build something big. Everything doesn't have to be shiny and big and grandiose because there are many ideas that are "boring," but just the idea of running the company becomes the motivation eventually.

Lenny (00:13:17):
That is really interesting that one of the main things you look for, it sounds like when you're interviewing, is how strong and durable is that drive to build this company. Is that what you're saying?

Gustaf Alstrmer (00:13:26):
It's actually kind of hard for screen for motivation, I would say, in interviews because the purpose of this kind of Office Hour question is to highlight why someone is there and highlight the diversity of reasons people are there and sometimes even highlight from one founder to another co-founder why they are doing this. They might have never talked about this. Actually, surprisingly, often founders have not talked about why they're doing this. And just knowing why someone is here really helps with conflict resolution for example, really helps with understanding why someone is there on a certain day or something like that. So it's not something we screen for as much as I think we try to help founders discover this among themself and really know this about themself. I've just accepted that the motivations to start companies is widely diverse.

Lenny (00:14:13):
Do you ever discourage founders from starting a company when you see that maybe it won't be a durable kind of lasting motivation or whatever other reasons just knowing how hard starting a company ends up being?

Gustaf Alstrmer (00:14:23):
It's a good question. I would say sometimes if someone doesn't have a motivation or don't know why they're doing this, they're doing this because they read that it would be a natural career step. So a good reason to not start a company is if you think of starting a company as a career step. Well, it is not. Because if it's successful, it'll be your entire career. It'll be 10 years most likely. And if it's not successful, then it's not something that people generally aspire to start. So non-successful startups. So I think people will start companies because this is sort of something they want to put on their resume. They have not understood what startups are or why you should do them.

(00:14:58):
Sometimes you can screen and kind of figure this out, but sometimes people don't even know why they're starting a company when they get started and it kind of gets figured out along the way. And that's okay. I don't want to discourage people who don't know exactly why they're starting this company just to start a company. They might figure out along the way and find the true motivation after doing this for a little bit or finding that it's really fun.

(00:15:21):
I think I discourage people to start startups if they have so many other things that are important than their life that are more important than the startup. So if there are financial constraints or family constraints or relationship constraints and they are going to trump this, then yeah, you should think a second time perhaps because startups are hard. They're much harder than a normal job. Equally hard if they're successful or failure, right? There's no middle way, we're like, "Oh, my company is doing great so I can chill." That doesn't work that way either. So I don't really discourage or encourage people, I just want them to have all the information.

Lenny (00:16:03):
You mentioned YC Office Hours and I had a question around this. I'm working on this piece where I'm interviewing a bunch of B2B founders of companies that are doing super well and I asked them a few questions like, "How'd you come up with the idea? How'd you find your first few customers?" it's shocking how many of them bring up a conversation in YC Office Hours as the most pivotal point that set them on the trajectory that they're on now. I'm curious what happens in these Office Hours? What are the most common pieces of advice that you give or maybe most surprising pieces of advice that you give in these Office Hours so that people can get maybe a glimpse into these conversations you have?

Gustaf Alstrmer (00:16:43):
So at YC we have two type of Office Hours, two of the common ones. We have regular Office Hours, which is usually a one-on-one or basically the founders talking to me, or me plus another partner. They happen every week or every other week throughout the entire program. And they happen years after the program on the regular basis. Then we have Group Office Hours, which is you and six or seven other startups talking to us. They have [inaudible 00:17:07] a little bit different purpose. So the goal of the regular Office Hour, I always ask the question, "What's holding you back from moving faster? We don't want to hear updates, we don't want to hear strategy questions. We want to understand what's slowing you down or what's holding you back from moving even faster. You generally have a specific goal."

(00:17:27):
And I think that question of what's slowing you down or were holding you back crystallizes the priorities. There are only so many things you can do as a startup and there are only so many things that matters at that stage. And by asking that question, we can start digging into, "Okay, what's the goal? What are the things that drives towards that goal? What are the things that's slowing you down towards that goal?" Usually, the founders don't know what's slowing it down, so the conversation and us probing questions actually leads to us or them discovering what it is just slowing them down.

(00:17:59):
In the Group Office Hour, it's a little bit different. The Group Office Hour holds a couple of different purposes. One of them is if I think back on Paul and Jessica's motivation to start YC, this is a surprise to them, but starting a company is incredibly lonely. You can't really lean on your employees and say, "Hey, I'm feeling really shitty as a founder today. Everything is going to shit." Employees isn't going to take that well. So you lean on perhaps your investors, but they're not really available. But what you can lean on is other founders because they're all in the same situation. It's sort of like when you ask a founder the question, "How are things going?", it's so emotional for them to answer that question because it's never going well, right? It's never like, "Oh, everything is going fantastic." They might say that, but everybody knows all founders, when they look each other's eyes, then no, that's not the answer.

(00:18:48):
So founders have infinite number of problems that they're thinking about all the time, which is why they're allergic to the question, "How are things going?" But when YC started, we put all the founders in a group together in a room and they started learning that all founders, all companies are broken in some way, right? They're all having these massive problems and they're all feeling that anxiety when they hear the question, "How are things going?" And just hearing other founders explain their problems, perhaps solving their problems, is a really good way for yourself to both feel motivated to do it yourself and see how problems get solved when other companies are having similar problems. Nowadays because of the scale at YC, we group companies together that have the same problems or the same area that they're operating in.

(00:19:30):
The second thing that Group Office Hours do well is accountability, right? We ask you, "What were your goals? What were your goals for the last two weeks? Did you hit them?" And then that gives founders accountability because founders are competitive. They don't want to look bad. They don't want to come back after two weeks and say "Nothing worked," or at least like, "We didn't learn anything." They want to learn something and make progress whether it's positive or negative.

(00:19:54):
Group Office Hours to me is the most magical moment because it really creates this very intense three or four month period. Founders often come back to us afterwards and say, "Hey, we want to do that again. We don't have this really intense, really productive period. We don't have a program exactly. We have other programs, but we don't have anything exactly that mimics that experience." But we do encourage founders to continue with Group Office Hours after YC. Many of them do and many of them, ad hoc, continue to meet for years in this group setting where they ask the same kind of questions to each other, to hold themselves accountable, to learn from each other, and to just have someone else to lean on. I think this was unknown and somehow the world didn't know before that starting company is super lonely and you have all these anxiety. By just talking to other people who have the same problems, it's just one of the best thing you can do.

Lenny (00:20:45):
There's so many things that come up when you talk about this. One is I had a startup at one point and we worked in the coworking space. We joined the coworking space because we're like, "Oh, we'll meet other founders. It'll be social, we won't be alone." But it turns out everyone's just heads down, headphones on, "I don't have time for anything. I just need to work." It's like a microcosm of that experience that even if you're surrounded by founders, no one has time to do anything. They're just working.

Gustaf Alstrmer (00:21:09):
You got to schedule it and force it and put the laptops on the floor and the phones on the floor and you just sit there with pen and paper. That's how you have to do it. We tried to mimic that as much as we could over Zoom. But honestly the best experience of this was in person, in a ring, in mountain view with no computers and everyone just paying attention to everyone. That was the best experience. Yeah, that's what I remember is one of the most meaningful parts of YC. I didn't have it myself when I did YC, but now everyone has it.

Lenny (00:21:36):
The other thing that's made me think about is someone tweeted once, "Don't ever ask a founder how they're doing or how it's going. It just creates all this anxiety because nothing's ever going great."

Gustaf Alstrmer (00:21:44):
Don't do it. Everybody looks at each other's eyes and they know that they're allergic to that question.

Lenny (00:21:50):
That's hilarious. So just to summarize the questions you said you asked, the one is in the individual Office Hours, is what's holding you back. And then in the group setting, what was the question again that you asked?

Gustaf Alstrmer (00:22:01):
What are your goals for next two weeks and what were your goals for the last two weeks and did you hit the goals? And if you didn't hit them, what came in the way of hitting the goals? It's very simple. That can uncover lots of problems that other founders are having exactly in the same way. Just by talking about the things that held you back or the things that allowed you to hit your goals, uncover something material for the other seven companies doing that in the ring.

Lenny (00:22:26):
If you kind of zoomed out a little bit and thought about the startups you've worked with, what would you say are the most common mistakes that early stage startups make broadly?

Gustaf Alstrmer (00:22:36):
There's so many. I mean, this is how I initially learned about startups, by searching for that on Google and landing on Paul Graham's articles because he kept-

Lenny (00:22:45):
Wow.

Gustaf Alstrmer (00:22:45):
I think I've written many articles about this topic because it is so common. So this topic can go on forever. But if I take the most recent experience I've had in YC, I would say startups fail, one, because they don't talk to customers. And if you don't talk to customers or users, you don't actually know what's important. If you don't know what's important, it doesn't matter what you build, it doesn't matter kind of what ideas you have in your head if you don't actually know what it is that you need to build and you don't validate with customers. That's where a lot of the failure stems from. A lot of early YC for us or early part of the program is us pushing and probing founders to be like, "Tell us about the conversations you've had with the customers. What did you learn? Can you show us the organizations?" Or like all these questions, like, "What are the software they're using? What are they paying for? What problems do they have? How are they describing the intensity of that problem?" So that's what we spent a lot of time early at YC.

(00:23:43):
After that, I would say one of the commons mistakes in... I'm not talking about generally startups here, I'm talking inside YC. The second most common thing I see in YC is people are just afraid to talk to customers. They're just not trying hard enough to get in front of customers. I think this comes from, technical people tend to think that software is just sort of solution to everything. But really what you should need to do is to talk to someone over Zoom or over phone or in person, even better. People are just afraid of doing that and they're afraid of being rejected. These are common, people that want to build good products are just really afraid of people saying no.

(00:24:25):
The problem is, which anyone who hasn't done sales before that joined YC, they realize this, is that if you take the average customer group in the world, 90% are not early adopters. It doesn't matter if you have something new and cool, they're just not interested. They are not incentivized to take risks in their job to try something new. They're just incentivized to not take risks and just continue what they're doing. Those 10 percents are the early adopters. They're The ones that you actually want to reach. But that means you have to reach 10 to find one. And then you convince that one person to get on the phone or a video call with you. And that takes work and it takes a lot of work. I think people don't really think of this. This is common knowledge, basic stuff for salespeople, but founders should never done sales before just get surprised by the percentages and the sort of what it means to do this.

(00:25:12):
If I think of more generally outside of YC, so these are two kind of things I experience within YC, but I think generally outside of YC, I would say the two most common problems the same one is not talking to customers, the other one is not being technical and not knowing what it takes to build successful technology company. It means having technical founders and it means being able to build the first prototype. This is something we screen for when we interview people in YC and we aren't accepting a whole lot of team that don't know how to build or get their first prototype built themselves because we know it is a super common value pattern.

(00:25:50):
I can go on and on and on and on for this one, but honestly if I drill down what makes companies fail, it's quite simple. It's just like they don't talk to users, which means they don't find product market fit. And if they don't find product market fit, nothing else really matters. What mistakes do people make is it is all about that. It's all about talking to customers and learning that you're building something that's actually useful. YC Slack headline is make things people want, and it's still true and it's always going to be true.

Lenny (00:26:23):
This is really interesting and good advice. It's interesting that... Like, "Talk to customers," people hear that all the time. They're like, "Of course we're going to talk to customers. We're going to do that of course." And your experience is they know this but they just don't do it probably because they're afraid. Maybe also because they think they already know what they need to build and it's like, "Yeah, we're good."

Gustaf Alstrmer (00:26:41):
And you have all these validators, right? So the people are validating that even if you don't talk to customers, why has he accepted you? This investor invested in you. This investor said you were great, like blah blah blah. All these different validations that you confuse with product market fit, right? We have to remind everyone on the first day in YC, "None of you have product market fit because you probably don't," right? Almost nobody has. Because people confuse this external validation with the thing that matters the most, which is talking to customers and learning what matters. It's just like a thing that just keeps coming back. Some get really good at it. And that is the source of successful startups, is when you really get good at this.

Lenny (00:27:21):
It reminds me coming back to Airbnb, one of the most important moments in Airbnb history was Paul Graham telling the founders of Airbnb, "Where are your customers?" And they're like, "Oh, they're in New York" and he's like, "Why are you talking to me and not in New York right now talking to them?" And they talk about that all the time.

Gustaf Alstrmer (00:27:35):
Yeah, it's absolutely true. I think he wrote the article Do Things That Don't Scale as a learning.... The learning there was the Airbnb founders doing the trips to New York and learning about how to build Airbnb, which is a very counterintuitive idea, which is when you have to spend the most amount of time with your customers. I think Airbnb is sort of one of the best stories inside YC of doing this well.

Lenny (00:27:57):
This also reminds me, I've been talking to a bunch of founders recently. I asked them, "How many customers have you talked to help figure out this idea?" So just the other day it was 150 financial CROs that they talked to before they actually started raising this round. Another company, actually two Airbnb guys that started, they actually ran ads I think on LinkedIn to find specific people to talk to and that specific role. And they talked to probably at least 100, maybe 200. So there's a strong correlation there.

Gustaf Alstrmer (00:28:26):
Yeah, I think that's the volumes that people don't expect. They think they might have to talk to five, but I think you have to talk to 25 to 50. That means you have to reach out to a lot more to be able to get to people that are potentially early adopters. Those ones you talk to are also the ones that become your customers. So you are already doing most of the sales by just doing this work anyway.

Lenny (00:28:45):
Do you have maybe one tactical tip you could share of just either getting over your fear of talking to customers or just holding yourself accountable to actually doing it?

Gustaf Alstrmer (00:28:55):
Yeah, I tell this story, I actually told this story yesterday. So remember when you sign up first service that's a cool service and you hear about in TechCrunch or something like that and then you realize you already signed up a year ago, right? And then from the founder's perspective, you sign up to something you never used it. So the founders who build those services, their inclination to think is that "Everybody hates me because they sign up and they never use me." They never use the service. The fear of that is that basically the fear of rejection. So if I put my thing out there and most people won't use it and they will tell all their friends how shitty this thing is, you should never even sign up for it, that's the fear people have, but the truth is that people sign up for it and be like, "Oh, I'm busy. I got something else to do." And they actually don't remember or care.

(00:29:43):
So whenever you sign for something that you signed up a year ago, think of yourself that that is the common customer experience, which is that you just sign up for a lot of stuff you don't even remember you. You never have this, "I hate this thing' reaction. You always have this like, "I'm indifferent to this thing. I don't actually care to even complete the sign up flow or try it out," right? I think that's the thing that people need to remember, is that the worst thing that can happen to startup is not that people hate what you're doing, it's that they're completely indifferent to what you're doing. It's not the worst thing, but the most common thing that happens is people just is indifferent. But it doesn't give you a second chance. Let's say, it always gives you a second chance and you really need to internalize that people have busy lives and if people don't actually use what you're building, that's fine. You can reach out to them a year from now or six months from now or two weeks from now and they probably will if you make some improvements.

(00:30:37):
I think people just have this fear that, "If I get a lot of rejection, that means everything is bad." But the rejection should be put in context to the early adopter idea and that most people who don't care are not early adopters, who don't want to dig into new things. And that the more narrow of a solution you have to a specific problem, the fewer people actually want to dig in. But that's where you have to start because you cannot build the whole thing right up front and make everybody loves you. That doesn't really work that way.

(00:31:07):
Even Airbnb was like air mattresses or staying in someone's homes when they're home. That was not the complete solution of Airbnb. But there were early adopters who dug in and be like, "Yep, I like that. I like those two things. I want to have people stay in my living room in my mattress." But that's not what Airbnb is about today, and a lot of those things were unknown at the time. But I think people are just afraid of rejection and you just need to overcome that fear and just learn that there's nothing that's really that bad that can happen when people don't use the service or sign up and don't care. It's not really that bad.

Lenny (00:31:42):
It reminds me of a quote that I always love for Mark Andreessen, that everyone's time is already allocated. They don't have space for your product right now. They already have plans for their day.

Gustaf Alstrmer (00:31:42):
Totally.

Lenny (00:31:51):
And it takes a lot to convince someone to pay attention to anything. I guess that just comes back to why it's so important that your product is solving a real pain and not just a nice little toy that is better than what's out there, but not so much better that you're like, "I need this right now." So maybe just along those lines, do you have any thoughts on just the importance of that pain and just how critical that is?

Gustaf Alstrmer (00:32:15):
I actually recorded... I'm happy of these videos, but I've recorded two videos on YouTube as part of YC Startup School last fall. You can go watch them on YouTube right now. One of them is how to talk to users and the other one is how you sell or how you use sales. The one about talking to users, I think there's a difference in asking someone, "Do you have a problem with X, Y, Z? Is this podcasting setup working for you?" And people say, "Yeah, it's kind of working." But if you are a podcasting setup experts and you watch people use some other thing that's really shitty, they might also think that it's pretty good. But you have to watch them do it. And the best way for you to figure out what is the intensity of the problem is not to ask them but to watch them or to watch them solve the thing that they do.

(00:33:06):
You know how a lot of non-technical people don't know how to automate things? So they will do the same thing in Excel like a million times by just tapping because that's the only thing that they know and they're not technical enough to write some kind of script to do it, and you just have to watch those people to just feel the pain. You can't actually ask them how difficult is it to do X, y, z because they won't even know that it's that difficult to them. So the best thing I've learned about how to discover the pain is to watch people, have them screen share, have them walk you through their daily workflow about the area where you're doing some discovery. That is the best thing.

(00:33:43):
I'll give you another example. So there's a bunch of waste companies that are doing EV charging for electric cars and they're like, "What are the problems in EV charging?" And I was like, "Just rent an EV and go and charge at all the non Tesla chargers and see what they say, see what you experience." And the truth is that it's just like garbage. A lot of EV charting systems are just so shitty and the apps are terrible. You just have to just use them yourself to know how bad it is.

Lenny (00:34:13):
It's cool how often it just comes back to, "Just go do the thing. Do things that don't scale." Classic YC advice. I want to come back to something you mentioned that I want to pull a thread on as the technical co-founder, being technical early on, just to cover that. So I know YC looks to... Having a technical founder is an important variable in you're deciding to accept a company. Say someone doesn't have a technical co-founder, do you have any advice for what they could do, like what often can work?

Gustaf Alstrmer (00:34:41):
Yeah, I think the first thing is to understand the value of technical co-founder. So some people who are in this situation where they have an idea of something they want to build and they don't have anyone to help build them in building it, I had a friend Paul who gave this incredible quote, he said, "I have an idea for a song, I just need a musician to help me make it," right? That's kind of similar to how it is with engineering. If you view output of engineering as like, "I just have an idea for a song, I just need someone to actually make it for me" and then you're not valuing software engineering or mechanical engineering or any engineering skill set deep enough, right?

(00:35:17):
The truth is that the engineering part is the really hard part. The first thing I would say is you need to learn how to value the engineering piece. Let me give you an example of how you don't do that. You applied to YC and you have 90% for yourself and 10% for the engineer. You're basically saying that like, "Oh, the engineering part of this company is only worth 1/10th of me. I'm the non-technical person." So that to me is a signal that you're not really valuing engineering.

(00:35:44):
Okay, so how do you go out about and find someone? Well, the truth is that there are a lot of technical co-founders. The technical people, they also want to find business co-founders. They don't want to do other part. They don't want to do sales and they actually don't really care that much about fundraising. They just want to solve the problem. And that's fine. We built something called co-founder matching where those funders can meet, but if you don't participate in that, you can just start by asking the best technical people that you know. "Are you interested in starting a company with me?" Same thing with rejection. Many of them will just say, "No, I have a great job, I'm really happy." But some of them will have thought about starting a company for a while and was hoping that someone would come and ask them to do that. So you have to remove your fears and go and ask the best people.

(00:36:29):
The reason you want to have a technical co-founder and not a hired engineer or not a hired contracting team is because so many of the decisions you're going to make are technical and so many of the iterations you're going to make relies on engineering. And if you don't understand that, you won't actually make the right decisions anyway. It's not like service. You have an idea for a product, you build a product and you're done. There's infinite number of iterations in that process.

(00:36:54):
And then finally, I would say a lot of people learn how to code themselves, right? So there are a lot of places online that you can learn the skillset that takes to build a prototype. You might not be the best engineers. So there are many successful startup founders who are not the best engineers because they stop coding when they hire three or four engineers, that's fine. But you need to be sufficiently good that you understand the value of engineering and that you understand that the best way to solve most of the problem is with software. There are a lot of founders who just, for whatever reason, study something else that doesn't have to be a conscious or very precise reason that you had when you were 18 or 19 and then you're 25, you're like, "Oh, I wish I know how to code" and then just learn to code and they learn how to code. It's not that more difficult than that.

Lenny (00:37:42):
Have you ever seen a startup work out if they had a contracting firm, like engineering firm build a product? Does that ever work or were you just like, "No, do not ever do this"?

Gustaf Alstrmer (00:37:53):
Basically, I can't recall any specific ones where people have a contracting firm but I've recalled founders where let's say you had two non-technical founders, but they valued engineering and they had an ability to build a team of great people that were not co-founders and they gave them equity and they become successful. There are many examples of that I would say, but I don't remember any specific examples where you had a contracting team building the whole thing. I think the reason for that is it takes more than just sort of riding a spec to build a product. You can't actually spec yourself to a great product. You have to just be part of the iterations yourself. That's why I think someone being the engineer, having the idea of what iteration looks like and just doing it is how you do things.

(00:38:38):
I think that the cases where I've seen non-technical founders make this work is that they have really good engineering teams who feel like they're founding team. It might not be co-founders per YC-7 definition of having 10%, but they feel like they're the bonding team.

Lenny (00:38:52):
This reminds me of a story of just the recent podcast interview I did with the CPO of Calendly. She talked about how when Calendly started, they actually had a Ukrainian dev team built the first product. Not only did they help them build the first product, they actually ended up driving all the growth initially because they saw Calendly and started using it within their firm.

Gustaf Alstrmer (00:39:14):
Wow.

Lenny (00:39:14):
And then everyone that they knew started using it and spread within Ukraine and they actually continue to work with that firm. They're still the [inaudible 00:39:20] team for Calendly or some part of it.

Gustaf Alstrmer (00:39:22):
Wow.

Lenny (00:39:24):
Yeah

Gustaf Alstrmer (00:39:24):
Wow, that's cool.

Lenny (00:39:24):
There's a success story.

Gustaf Alstrmer (00:39:26):
I mean, I would say it's certainly the case that in some countries people have other jobs while they start the startups, so like the engineers. In Ukraine for example or in Eastern Europe, it's very common that if they start their own startup, they actually have a full-time job as a contractor while they're starting the startup because that's how you pay the bill because often you can't raise money. And that's fine too.

Lenny (00:39:46):
Amazing. That's some hustle.

(00:39:49):
This episode is brought to you by Pando, the always on employee performance platform. How much do you love the performance review process? Yeah, it's time-consuming, subjective, biased, and there's rarely any transparency. With the rapid shift to distributed work, it's a struggle to create the structure and transparency that you want to help your employees have the highest impact and growth in their careers. Pando is disrupting the old paradigm of performance management, including a continuous employee-centric approach so employees stay engaged, see their progression in real time, and know exactly when and how they can level up. With Pando, managers can leverage competency-based frameworks to effectively coach and develop their teams and align on consistent growth standards resulting in higher quality feedback and higher performing teams. Visit pando.com/lenny for more info and get a special discount when you sign up and reference this podcast. That's pando.com/lenny.

(00:40:47):
I want to zoom out a little bit and ask another big question and see what answer you have for this. If you just think about the most successful startups in YC or even just the companies you worked with, if you had to pick just one or two attributes of what's most common across successful companies, what would that be?

Gustaf Alstrmer (00:41:04):
I would say the most common reason that I've seen founders succeed or companies succeed, it comes down to the founders and characteristics of those individuals. The most important characteristics of those individuals are they're really determined to win and they don't give up when things are hard and they have an internal motivation that's just really infectious to people around them, which is how they end up building really good teams around them. People are actually going to want to go and work for them. I have numerous examples of people like this where the CEO or one of the founders are just really inspirational people.

(00:41:42):
The second thing I would say is they are technical. So that's kind of like they're technical enough. If I would grade companies on a scale of technical to less technical, more technical founders are more likely to succeed, I would say. And then I would say they figure out how to talk to users and move fast early on so they don't wait for permission from their investors or from YC or from someone else to make progress. They're like, every day or every week there's continuous progress. They're not doing this for someone else, they're doing this for the customers. They're not doing this for the investors, that's for sure. The investors are sort of in the way more or less. And they're just naturally focusing on the customers.

(00:42:29):
Finally, what I would say is the skill that's really attributed to great founders is excellent communication skills. So the ability to communicate really complicated ideas clearly, to enjoy the communication part, right? Enjoying communication is often kind of correlated with enjoying doing fundraising, which is an important part of some companies' success. Not all of them, but for some of them. I would say communication or storytelling is part of the same arc, right? And those are part of the same thing that actually motivates people around you. If you can communicate why you're building, what you're building and why it's important to the world, tell a story about that, that can motivate people around you to just want to follow you. I think it's rare that I've seen founders succeed where the founder isn't in some way an inspirational person or someone that is a good communicator. Most of the time, you at least have respect or you somewhere know that they're going to succeed, right? And that is what inspires you to be around them or be on their team.

Lenny (00:43:33):
That is a really cool list. So just to summarize, one, they have the strong will to win, and with that they're inspirational. They kind of pull people along and get people really excited. Two is they're more likely to succeed if they're technical and can build a thing. Three, they figure out how to talk to customers, don't wait, just start doing it. And they're just obsessed with that versus what investors want them to do and they don't want to talk to the investors to make time for the customers. And then excellent communication skills, which comes back to the first. They're able to story tell and get people excited. Is that right?

Gustaf Alstrmer (00:44:06):
Yeah, I would say those are the attributes of successful things. To be a super successful company, there's something else that have to happen. Those things are not things you can put on a list because they are the outliers, right? If you look at startups on a typical YC batch, there'd be a couple billion companies. Those are the outliers. They'll almost certainly have all the things that we've talked about. Many other companies in the batch will have that too, but then what makes someone a true outlier is something that is unknown. That's why so many investors said no to Airbnb when they were not trying to raise money because that was an outlier idea. It was an idea that was not logical and did not make sense to most people. Those kind of ideas, the ones that end up succeeding often don't make sense to people. There's some reason that no one has done this before because they're just not natural next step of the world.

Lenny (00:44:57):
That's a great segue to a question I've been meaning to ask, which is, how good are you at predicting in a batch which startups are going to be the monster hits? So maybe like you and then just generally YC, how good are you all at knowing what's going to work out, is going to be the next Airbnb or Dropbox?

Gustaf Alstrmer (00:45:14):
I think the truth is that we're not very good at knowing what's going to succeed. Certainly we cannot figure out who's going to be the really successful company in the batch. That's not possible. What we're good at is knowing what failure looks like. What we sometimes like to tell founders at the beginning of the batch is like, "If you fail, please do it in some new exciting way. Not one that we've seen 100 times." Because we have seen people fail for a large number of reasons. The best way for us to sort of not predict, but the best way for us to make more companies succeed is to tell them how they might fail, right? Be very direct and honest with them and say, "You doing these three things, these things are likely going to lead that you won't succeed." And if we do our job well, most people get that feedback and they're on the track for succeeding.

(00:46:06):
Now, which of those companies end up becoming the best? There are so many things that are uncorrelated to being the best, and it's the things that people don't like. I'm in a hot industry, I was writing up on TechCrunch like, this investor started talking to me. You'd be surprised how many of the things I just mentioned are uncorrelated to outlier success, right? That's why it's so hard to actually do this. I think people really want these questions to be answered. People really want to believe that you can pick really great companies at the seed stage, but everything I've learned from the plus 600 companies that I've worked with is that it's just not that easy and it's maybe not even possible and certainly not possible when you talk about finding the outlier companies. I don't think it's that easy. And if it was easy, then we would accept a lot fewer companies. We just accept those ones, but it's just not that easy.

Lenny (00:46:59):
Do you have a sense of which ones are likely to work out better than others? Or is it just like, "We have 150 really unclear, but one of these, hopefully."

Gustaf Alstrmer (00:47:09):
One good indicator is if each new Office Hour there is really exciting new stuff, right? We're not talking about the same thing we talked about two weeks ago or four weeks ago. They've already done that stuff, right? Like, "Oh, I was trying to sell to these three customers. Well, they already bought it. I'm not actually talking to seven others." And now we are talking about a different price and different product because they're like, they want more of what we're doing. If I'm experiencing that, and that's like a consistent trend, then when people draw this revenue graph of this 10% weekly growth rate kind of situation, those are the companies that we attribute that to. It's like if you're able to make that progress on that short amount of timescale, you are on track to do something well.

(00:47:51):
Now, a lot of other things have to go well for you to ultimately be able to succeed, but progress on this weekly or biweekly timescale is a really good indicator of someone who'll succeed. To me, much better indicator than I am in this market or I'm talking to this investor or something like that. But those are much worse indicators of someone succeeding than I'm making progress and it's pretty fast clip.

Lenny (00:48:17):
Interesting. And so what I'm hearing is at the beginning of a batch, we're just in a bet on a bunch of companies that have a lot of potential founders, technical maybe, they have the strong will to win and all these things. Through the batch, you're looking at the companies that are exceeding your expectations week to week in terms of progress that they're making.

Gustaf Alstrmer (00:48:34):
I mean, sometimes it could be different reasons that people are not making progress. But if you are making continuous progress, and I think Paul and Jessica said this, this was true early days in YC, if you are hitting your goals and you're making progress continuously, if that continues, that's a really strong correlation to some success. But again, going back to the question, can we predict who's going to be the best ones? No. And that's why we really focus on trying to meet people not to fail. Especially good teams can't fail. If you have a really talented team who's really technical in how to build a product but they make some other basic mistakes, like not talking to customers or something like that or trying to build everything all at once, I feel like it's our responsibility to make sure they don't make the basics mistakes that we've seen many times. We need to help them at least make some spectacular mistake that we haven't seen before. Then that's a high potential team. If someone's on a good track for a decent idea but they're still early, that's a really good potential.

Lenny (00:49:30):
I have kind of a fun question that I wanted to try, which is kind of connected to this idea around attributes of successful founders and companies. So I had this founder friend named Flow, and he was asking me recently, "If you had to think about the most successful founders, which attributes do they have?" And he kind of gave me this list and it's kind of like two ends of a spectrum. So I thought it'd be fun to just go through this list and see, in your experience, which end of the spectrum, if any, are associated and correlated with the most successful founders. Does that sound good?

Gustaf Alstrmer (00:50:01):
Sure. Sure. Let's do it.

Lenny (00:50:03):
Okay. So the first is speed versus quality. Is there end of the spectrum where you find that most successful founders are either speed-focused or quality-focused?

Gustaf Alstrmer (00:50:10):
Sometimes founders ask us this question, "What should I focus on? Growth or retention?" And the answer is, they're asking us for permission to not do one or the other. The truth is, to succeed, you have to do both. I would argue that speed versus quality, there's different level of speed and different level of quality at different stage of the company. But the truth is that you always have to move fast and you have to understand what the meaning of quality is, right?

(00:50:35):
So I think I actually don't see that as a spectrum, but I would say if you move fast with talking to customers, you'll build something that have potential having quality because you know a lot about the problem. I think when people think about quality, they often think about, "What is my personal definition of quality?" I have a bar of quality, but quality to me of a good product idea, a good startup idea, has more to do with the customer think is valuable. And if you move fast by talking to customers and having customer learnings and know the problems, then you will actually come up with something that's high quality. So they're not at a spectrum to me.

Lenny (00:51:11):
All right. Let's try another one. Confidence versus humility as a founder?

Gustaf Alstrmer (00:51:16):
I don't think that they're on a spectrum. I think that learning to predict confidence as a founder is critical going back to this communication piece of motivating people around you, right? I wouldn't want to join a company where the founder's completely not confident in their own idea, right? Because that is going to shine through. An investor isn't going to want to invest in someone who's completely not confident in that idea. So learning to first build your own confidence for what you're working on and then predicting that confidence to the people around you I think is critical. A lot of people will have doubt around you. And if you're not predicting that confidence, it's not clear that anybody else will if you're the founder. You're the one who's have to do it.

(00:51:58):
I think that you can predict that confidence while having a strong sense of humility towards the people around you. But I think when it comes to startups, learning to have that confidence is an important piece of the early days, right? And especially if you're building something that's very difficult, that takes a lot of work and a lot of money, protecting the confidence that you will succeed is critical for everybody that's doubting you. And those doubting you is a lot of people around you, right? And you just need to have an unnatural amount of confidence to prove them wrong. I think, again, this is not on the spectrum with humility. In fact, the most successful founders are often the most... You cannot inspire people around you if you don't have a strong sense of humility. People don't actually want to spend time with you, which means they don't want to work for you or invest in you. Again, you need both, but they serve different purposes when you get started.

Lenny (00:52:48):
Tough gig this founder life. You got to got to be everything. Let's see if there's a big difference in this next one. Execution and tactics versus focusing on strategy and kind of higher level stuff. How deep do founders go that you find that are most successful?

Gustaf Alstrmer (00:53:02):
So this one actually I have a strong opinion about. I think that the reason that we talk about strategy a lot is because it goes back to business school. The origin of business school was to teach people to join the corporate world. And in the corporate world, strategy matters, right? So when you join a big company, you're employee number 2,010 or something, then you probably might have a business school job where thinking about corporate strategy is an important thing. When you are a small startup, strategy does not matter because there's not that much a strategy as about. Maybe later on you might be fruitful to think about strategy, but strategy kind of assumes that you can do multiple things at the same time, which small startups cannot. They can just do one thing at the same time. So execution is the thing that matters for companies.

(00:53:51):
Whenever someone wants to have a strategy conversation, it assumes that they don't understand their priorities. The priorities is always a list from top to bottom where there's one thing that's more important than the others. You can't really have a strategy session about the other things because there's only one thing to work on. So to me, a clear answer here is the good founders are execution-oriented and they just continually have one priority of what they're trying to go for. And then they're just hitting that priority all the time and then new priorities will come up and you don't really have time to have a discussion about company strategy. Company strategy also assumes that you have product market fit because you already have something that's working. If you don't have that, then getting to people wanting your product, that is your strategy. You don't have any other strategy.

Lenny (00:54:36):
Awesome. Okay. We found one that's quite different one on the spectrum or the other. How about autocratic and kind of like, I don't know, I think of Steve Jobs-like versus kind of consensus, collaborative driven, if this is a spectrum at all. And then where do you find founders might fit that are most successful?

Gustaf Alstrmer (00:54:53):
I don't know if I have an answer to that question because I think when you work at early stage, you might look different than when you work at late stage. I don't spend a lot of time with founders that have thousands of employees and hearing how they are in the... When I talk to those founders, I talk to them one-one-one and I only hear from their perspective. So I don't actually know how they're peering in a large corporate setting. But when you're a small company, you're three people or five people or 10 people, you cannot be an autocratic decision maker. The founding team have a founding team decision making dynamic that could look different. Sometimes it's like everybody decides together on everything and sometimes you say, "I have my area of expertise and you have yours. We split it up, the decision making." Either of those things are fine. I think you just have to have a process so you don't rehash every decision after you made them a million times.

(00:55:42):
I would say the thing that matters the most at that point is to be willing to adhere to the process that you and your founding team have come up with. Your individual nature could be different in a different role in a different company. But for a startup to work out, you have to have a specific process on how you make decisions. Those are on a very short sprints, like weekly or biweekly. And everyone needs to feel good about decisions after the fact. At least they feel good about the process. I don't think that you can just decide... You can't also be fully collaborative, everyone gets decided about everything. So small startups agree on how they decide together. So after that, everyone just follow the process. That's usually how things work out.

Lenny (00:56:27):
Okay, I got one more. Cares more about the product or cares more about the distribution and growth strategy?

Gustaf Alstrmer (00:56:33):
Well, there's a lot of assumptions built into that, I would say, because caring about the product to me is caring about the customers. Sometimes if I would say something like, "Oh, great founders care about the product," a lot of founders misinterpret that as in my personal perception of the product or my ideas of what the product is. And that's wrong. The right perception there is the expectations or the use of the product from the customers. So if you are meaning focus on the product or cares about the product in that sense that your customers care about, then absolutely, I think that's a really, really critical, important thing to have early on, like talking to users, doing things you don't scale. Once you get big, if you don't figure out a scalable distribution strategy, you won't succeed. And those are different for different companies, but they're not doing anything that don't scale.

(00:57:27):
Doing things that don't scale is not a scalable strategy. Eventually, something specific will be the things that work for you. If you're lucky, people will talk about your product and you'll have organic growth. But in many cases, that sales, that is some kind of consumer distribution strategy. You can't start with that. I've seen a lot, and this is when I had to reset my thinking coming from a growth team joining YC, is you can't start a startup ethic with a growth team mindset because that is just scalable things all the time. And really what you need to go back to is doing things that don't scale and unscale your way of thinking about customers. But it's really useful to have the growth mindset once something is working, right? Once you have thousands of people signing up everything every day, well how do you get to 2,000? Well, that's probably something that looks more like this thing that the growth team would do or distribution team would do.

(00:58:21):
I would say everyone has different experiences of this based on their prior experience, right? So if you work for a company that was infinitely successful, then you won't care so much about this. If you work for Google, you'll never even think about this because distribution is just the website. But if you work for a really small shitty product, then you think a lot about distribution because that's natural to you on how you succeed. So I think at the end of the day, talking to customers matters the most. That is what it means to care about a product to me. And then distribution is something that you will definitely invest a lot in once something is working.

Lenny (00:58:53):
Awesome. All right. I have probably a hundred other questions I want to ask along these lines, but I want to make sure we get to another topic which I know is near and dear to your heart, which is climate tech. So my understanding is you're instrumental in pushing YC to focus on climate tech as a focus area. I believe you led the charge on their initial request for startups I think is the term where you all put out like, "Here's who we want to fund." I think you've mentioned you funded a couple dozen climate tech companies and the last few batches, is that all generally correct?

Gustaf Alstrmer (00:59:24):
First, request for startup was actually Sam Altman and a few other folks that was kind of that one who drove that. The second one that we wrote into our actual request for startup, I wrote that one, was carbon removal specifically focused on. And then naturally the people that apply with climate tech ideas get in my reading queue of applications and I read them and I interview them. Not all of them, but many of them. I think today we funded over 130 plus companies that are focused on climate tech in some way or another.

Lenny (00:59:53):
Wow.

Gustaf Alstrmer (00:59:54):
The trend line is that really ambitious people who want to start companies in this area. Some of them want to start the companies because the climate tech is the number one problem, but they don't view this as a nonprofit. Now I want to really make this as a distinction. People somehow think that starting a climate tech company is doing good for the world, but it probably doesn't have a lot more than that. The truth is that the world have decided. Because climate is one of the biggest problems that we're facing, if not the biggest, we've decided that we are going to stop doing the things that we're doing and we're going to change our entire energy system and change all the things that we do that emits carbon. And we have just decided, governments have decided this. The question is how it's going to happen, but this decision has been made.

(01:00:42):
In that transition, we're talking about trillions of dollars of money moving from things that cause climate change to things that don't. The scale of this transition is not something we've seen recently. Like software is not that big in comparison. It actually is much smaller than this transition. So I think if you look at something like Tesla, which now has, I don't know, $600, $700 billion market cap, that's just one company that currently provides a couple percent of all the cars in the United States, new cars sold. And that is already one of the biggest companies in the world and has now the biggest, richest person in the world. We've only seen the beginning of this. The economical motivation be behind the decisions that people are making are just as strong as I want to fix climate change because this is just a really good business. This change have attracted a large set of software founders that you and me know that listen to this podcast that said, "My skills is relevant here. There are a lot of things that I can do. And if not, I can learn those things."

(01:01:43):
But most importantly, the skills of working for startups is really, really critical to join this transition. A lot of them have started companies or joining companies. I still get an email every week from some accomplished software engineer who asked me "Which software companies should I work for to fix climate change?" And I've gotten those emails for two or three years now. This thing just attracts really, really ambitious people. It's not stopping. It's accelerating. I feel lucky to work with so many of these great founders because they are uniquely interesting people.

Lenny (01:02:16):
I've noticed exactly the same thing of just how many smart, driven, amazing people are like, "I just want to move to a climate tech company. That's all I'm looking for now." Just to give you credit, I feel like you are ahead of the curve on the shift that's started to happen and pushed YC to focus on this really early. I always think like, "Man, I know Gustaf and I feel like Gustaf has made such a massive impact on the investment and focus in startups on climate." And so I just want to give you huge props for doing that and being so at the forefront of a lot of this.

Gustaf Alstrmer (01:02:50):
Thank you. I mean, sometimes I'd say that it matters to someone who has the credibility of YC to start accepting these companies. It does matter. I remember when I spoke to Diego from Pachama in 2018 when he was starting Pachama, we were whiteboarding in YC. He was a YC alumni starting a different company. The word climate tech did not exist. People were unsure if investors would fund companies like these. Pachama's raised $60 million to have, I don't know, lots of big customers, lots of employees and it's clearly doing really well. But I think at the time of 2018 it was kind of unknown. One of the reasons it was unknown is we had this previous bubble, clean tech bubble, in 2008, 2009, 2010 that didn't work out because of a number of specific reasons and investors were just afraid of funding things because they had some scar tissue or scars from this previous thing that happened.

(01:03:46):
Now that turned out upside down. The number of new investors that are investing in climate tech is as big of a trend as any other trend we've seen in the last decade or two decades. There's just an enormous focus on the investing side. Most recently, me and another guy, David Rusenko, wrote this request for startup, a new updated, very detailed list of... I hope we can post it in the show notes, a very detailed list of ideas or areas where we think it might be worth looking If you want to start a company.

(01:04:18):
Now, we don't know what good ideas look like. We don't know. But we can tell you where all the areas of opportunity exist. We should go and look for good ideas. We wrote this because in response to all these people that come to us and say, "I want to work on climate tech. I don't have a good idea because I don't have any specific experience in this stuff." And then we're just like, "Don't work on these three things but go and work on any of these 25 directions." It already has generate a good response. I think it'll generate more response. But I think it's important for YC to tell the world that we look and fund these things. And that's always been the reasons we had requests for startups, is to let people know that these are things that we actually want to fund.

Lenny (01:04:58):
I actually moderated a panel a couple weeks ago. This organization called the Climate Draft put together PMs that are in climate tech. A lot of the questions were just like, "What kind of background do I need to move into climate tech startup to start a climate tech company?" It's interesting, every single one again and again just said like, "Your actual regular PM skills is all we need." There's a lot of people already at the company that are experts in the science and that's okay if you have no experience. They just need the business experience, how to operate, how to execute, standard stuff that PMs learn. And so would you agree with that that you don't need to have this deep background in science and climate to move into the space?

Gustaf Alstrmer (01:05:41):
Yeah, I would say if you were working on a software company and even some of the hardware companies, that's probably generally true. Absolutely. It's much more valuable to have that background than to have this specific domain expertise background. Those are complimentary. But as a PM, having the solid PM background is the more valuable piece I would say. Being a competitive PM, coming from a really good culture of product management, knowing what good looks like, that's invaluable to some of these companies because in the past they weren't able to hire these people. So I agree with that 100%.

(01:06:14):
In terms of founders, I've seen everything, right? I've seen people having some domain expertise starting a company and really succeeding. I've seen people who had no domain expertise and learned everything they need to know. Maybe they partnered up with someone who had a domain expertise and then succeeded. I've seen all of it and I actually think that you can succeed in either of these categories. You don't need the deep expertise. It depends really on all the area you're in. But someone like Pachama, Diego and Tomas did not have expertise in forests besides the personal experience. They just had a willingness to solve the problem and it really worked out for them.

Lenny (01:06:51):
You mentioned you have this list of areas you're excited about. I know we'll share in the show notes, but is there any you want to highlight, just like here's areas you're most excited about and want to fund and/or are there companies you want to mention that are super interesting and super cool in the space that people should know about?

Gustaf Alstrmer (01:07:04):
We wrote the list and we are highlighting companies in each of the categories. I don't know if I want to highlight any specific categories, but I can talk about some of the things that we've funded in the past that has real legs. So here's how I generally think about climate tech. So we have to decarbonize all the things we do that emits emissions. That means we have to change a bunch of things in the world, change transportation, change energy, change homes, all of these things, or change how we heat homes for example.

(01:07:35):
And then there is carbon removal. Carbon removal is sort of like, well even if we do all of this stuff really well, it's probably not going to be enough. And because there's an opportunity and there's some evidence to suggests that we can actually remove carbon from atmosphere in some way or another, a lot of companies are also working on this at the same time. I would say we need to do both and they're not in conflict. We probably are going to need to do both. Well, we certainly need to do the first one.

(01:08:02):
On the decarbonization side, there's infinite number of categories of our society where we met a lot of carbon, right? So I'll give you an example. Shipping is a really big deal. A lot of carbon emissions come from freight ships around the world. That's not obvious solution how you would solve that because the kind of oil that they run on is really cheap and it's a very low margin business and they don't have a whole lot of incentives to change besides what is coming down regulatory. So it's not a national solution where someone to be a cool, someone will build a test off ships and it just work out. But the two companies to be funded in that area, one of them is Seabound who is building carbon capture and removal for ships.

(01:08:41):
The other one is Fleetzero who build electrical ships. Electrification is on and again and again and again and again and whenever it's being applied, turn out to be a more efficient way of doing whatever thing that you were previous doing with the combustion industry. It is almost no maintenance. It's cheaper to build. The batteries are more expensive, it's cleaner and it fits the carbon coal you have. There's just a bunch of benefits there, but there has limitations. Usually the limitations on electrification has to do with batteries. It's like how far can you go? Now that category is what I call the... Which is a very important kind of critical one, which is the carbon accounting and sort of the recommendation systems that help big company account for the carbon that they have and they are giving some recommendations of what you do.

(01:09:25):
So I'll give you three examples. We funded Unravel Carbon, which is carbon counting software in Singapore, focusing on Asia, probably the leading one there. There's company called Carbon Chain, which is focused specifically on supply chain and shipping and raw materials, stuff like that out of UK. And then there's ANAI here in the Bay area. Who knows how this market is going to play out, but this market has carbon accounting customer demand right now, right? So all the large companies of the world have other either promised the government, promised their shareholders or promised the public, or maybe even the employees, they go into decarbonize. They don't always have an idea how to do it. These software platforms is like the plug and play "This is how you do it."

(01:10:07):
And then I'll give you two examples of things you can go into if you don't have any specific domain expertise and just a good software engineer. There's a company called Enode. They are basically building Plaid for EV chargers and Plaid for home energy system. So if we imagine that the future of all homes or future of all charging of EVs is going to be a bunch of energy appliances that are run by small computers, they're all wifi connected, you can connect to them and do things, tell them to turn on, turn off, turn on when it's cheap, turn off when it's whatever, all these different things that are valuable for the energy grid. Then you need a software platform to connect with all of them. And that's what Enode has been building.

(01:10:48):
Another related company is called Static. Static is the Airbnb for EV charging in India. The reason that you need something like that is you don't have Tesla charging. You don't really have public charting in general. People don't have outlets in their garage and they don't have garages. So you need to build a new bottom up EV charging system or platform, and that's what Static has been doing. They're actually building out public charging infrastructure as well, but they have their own app. So if you use a Static app, they'll direct you to all the Static chargers. I believe that they're the biggest or the fastest growing EV charging network in India, which is the second-biggest country, if not the biggest country in the world right now.

(01:11:25):
So the potential of these ideas, even that they're doing well now is just infinite, such an enormous market. If you succeed in one of these things, I don't think we are going to have as many gas stations as we have today and different networks. We're not going to have the same in EV charging. It's going to be a lot more consolidated around the use experience of the end user and the app they open to do this stuff. So I'm pretty convinced that there's real big opportunities for software entrepreneurs to figure this out. There's some companies in the current batch that are focused on this too.

(01:11:59):
The final one I would mention is Heart Aerospace. We have a Heart Aerospace and the Right Electric and a few others focused on aviation. Aviation is another big difficult to decarbonize. Heart and Right are focusing on battery electric planes. So they're basically making commercial airplanes that fly on batteries and flying electric motors and it's incredible to see.

Lenny (01:12:22):
What a killer list. We're definitely going to include links to all these companies in the show notes. Something I was thinking about is, so one narrative violation you mentioned is that there's actually money to be made in climate tech. It's not impact-oriented market anymore. It might be worth chatting about why that happened, but the question I want to get to is also things are going well. A lot of progress is being made. People see climate change and it's like we're dead, it's game over. But it feels like battery prices are coming down, solar's coming down, wind powers ramping up, all these startups are investing. So it'd be fun to just hear what's going well and maybe what is there to be optimistic about, but then also, "Okay, yeah, things are going well, but there's still things that are not going so great and where we need to double down."

Gustaf Alstrmer (01:13:10):
Two specific things that went well in the last say 12 or 24 months. First one was politics. So in the United States we got the IRA, which is like it's called the Inflation Reduction Act. It makes sense because shift into greener energy is going to actually reduce inflation because it reduces energy costs. But it's really a climate bill, right? It really is a bill that is focusing on onshoring, a lot of supply chain for the green economy and incentivizing a lot of this change that we just talked about. Whether it's carbon removal or home energy or home heating, whatever it might be, this bill addresses all of it and is massive. So that's one really good news. Politics didn't have a lot of good news in the US for a long time on this. Maybe not ever actually.

(01:13:52):
The second good news, and it's such a good news that Europe is now trying to conquer. They're not trying to counter the IRA with their bill because they're seeing some of the battery companies saying, "Well, I'll actually going to build the next factor in US, not Europe anymore. I changed my mind."

Lenny (01:14:05):
Oh, wow.

Gustaf Alstrmer (01:14:05):
So Europe now has to counter with their incentives as well. The second good news is corporations are now customers. So maybe three or four years ago you went to a Fortune 100 company and you're like, "Hey, do you want to buy my XYZ decarbonation solution?" What it's like? The software platform or EVs or whatever it might be. They're like, "Well, talk to this person on this floor. Maybe they can help you." And this person was not really empowered to make decisions. That has changed. Now they're like, "Actually, we promised our shareholders to reduce emissions by 2% every year and we also promised the government and we promised whatever publicly to do that. So we got to do that." They're like, "Where do we start? What's the first 2% that we got to decarbonize? Maybe that starts with energy. Oh, we'll change our energy providers." But they are now showing up as customers, not just with LOIs but paying actual for contracts, right? Doing investments in these companies because they've all see the future and they don't want to be behind.

(01:15:02):
There's financials motivations for this. They want to get access to capital that has some strings attached to some of these things, but they don't want to fall behind. And then they don't want to be the Toyota to Tesla, where Toyota said, "We are not going to do battery electric." It's just like they're still saying that sometimes and everybody else is like, "Tesla is the one we got to copy because that's the one that's winning." All these corporations are really afraid of being the Toyota. They're really afraid of being the last one who's not changing and then the world will move past them and then they're going to die. So I think the motivation here is intrinsically survival and it's really about sort of adopting this because this is where the world is going.

(01:15:39):
I think these are the two best news. The thing that I think what... We also wrote about this in the request for startups. This is not a thing where you can convince everybody to just agree with you. And even if you did, people wouldn't know what to do. So you have to view this as an economical opportunity and say... We can't convince everybody that this is going to be the thing that's going to happen. It doesn't actually matter if you convince everybody. What matters is that sufficient amount of corporations are convinced that they change their habits. And then you can sell the things you're building to them.

(01:16:09):
As sort of founder, just focus on your customers and focus on B2B. That's what most people I recommend to do here because that's where most of the change is going to happen. That's why I'm really optimistic about these startups and these founders. What they're doing is, in my opinion, more impactful than someone running a campaign trying to convince some other people that this is a big problem. Even when people know that climate change is problem, they don't know exactly what to do about it. But the startup founders, they know.

Lenny (01:16:37):
You touched on this, but it feels like one of the biggest shifts is capitalism is kicked in and is now leaning into climate tech startups and that's-

Gustaf Alstrmer (01:16:46):
Yes. Absolutely. Absolutely.

Lenny (01:16:48):
... making a big dent. Well, with that, we've reached the final part of our chat, which is the very exciting lightning round. I've got six questions for you. Are you ready?

Gustaf Alstrmer (01:16:58):
Yeah.

Lenny (01:16:59):
What are two or three books that you recommend most to other people?

Gustaf Alstrmer (01:17:04):
The first one I recommend, I think I have it here. Yeah, this one. It's called The 100% Solution. It's written by Solomon Goldstein-Rose. It's for people who think climate change is a problem but don't know what to do about it, or they're just kind of in despair or think they're like, "Ah, everyone are going to die," right? There are some books written where the outcome of the book is like, "We're all going to die," but the truth is that we're not all going to die. This book is trying to cover the 100% of all the solutions in detail, kind of much more detailed version of the request of Sharp that we wrote. It gets you freely optimistic. And I give that to anybody who's cared about climate change because it really lays out this from a very optimistic way of looking at the world. And that's why I recommend that book more than almost anything else. That's probably my number one book.

Lenny (01:18:00):
Amazing. I love that if just a one book, here's the book you got to read. I like that approach. What's a favorite recent movie or TV show that you've really enjoyed?

Gustaf Alstrmer (01:18:10):
Oh, I watched so much. I don't know. I love Emily in Paris on Netflix. I think I have TV serves different purpose for me these days. It's just like entertainment.

Lenny (01:18:22):
Yeah, I get that.

Gustaf Alstrmer (01:18:24):
But what else movie do I watch? We watch the Everything All at Once. I thought that was a really good movie. That was-

Lenny (01:18:30):
Yeah, it might win Best Picture.

Gustaf Alstrmer (01:18:32):
Yeah.

Lenny (01:18:32):
We have a drinking game here. People say White Lotus, we drink. And so you did not, that's probably for the best. Favorite interview question that you like to ask YC founders when you're interviewing them?

Gustaf Alstrmer (01:18:43):
What have you done since you applied to YC on your product? What are specific things that you've accomplished since you applied? Because that usually is a month or two month months ago.

Lenny (01:18:51):
That's awesome. It connects so much with what you said earlier.

Gustaf Alstrmer (01:18:55):
I hope the answer is like, "Here are all the things that we did."

Lenny (01:18:59):
Versus we just prepared for this interview.

Gustaf Alstrmer (01:19:01):
Exactly. Exactly.

Lenny (01:19:02):
Most out there wild startup you have funded?

Gustaf Alstrmer (01:19:07):
I think I would say when I stepped onto the hangar floor of Heart Aerospace. I can send you a photo. Literally, I am looking at an airplane that's being made and I'm like there's no SaaS company's office you can walk into and you just open your mouth and you're like, "What the hell is this?" There are a few of those companies that are space companies or airspace companies or something like that where it's just a different feeling that you fund them and you can touch it. I have a lot of appreciation for things like that now because they're much harder to do, but when you succeed, they're much more tangible and you can be like, "I have a tiny little piece in this space rocket or this airplane that we funded or this satellite above us." I really think that that's in some way a strong legacy compared to some other things that exist and just replace other softwares. And all these are better businesses, but there are strong legacies.

Lenny (01:20:06):
What's a pro tip for applying to YC?

Gustaf Alstrmer (01:20:09):
Pro tip. Number one thing is go to YouTube and type in like... I think there's a video that we've recorded which is about how you succeed with your application [inaudible 01:20:18]. It's an hour long video that gives you all the pro tips on how to do it. We told people in advance, "Once you've watched that video, then see if you know anybody who've done YC and then reach out to them and maybe ask them if YC is right for you, but also ask them what's important for you to, as you kind of approaching applying to YC, writing the application, during the interview, what were the things that matter?" Those are probably the two things I would do.

Lenny (01:20:46):
Final question, what's one pro tip for visiting Sweden?

Gustaf Alstrmer (01:20:49):
First of all, you should visit in the summer. It's a really good time to be there. It's a very different country in the winter. Try to go outside the cities into the nature and then prepare yourself for Swedes not all being Americans. They're a little bit more colder and have a little bit more distance to you and they don't randomly talk to you like I've learned to do here in America. I think you just have to go along with a little bit different of a vibe than you have here in the US. Most people actually love it. Most people who have just been, they love it, but most of them go in the summer.

Lenny (01:21:23):
This reminds me, I wanted to close it, but there's a tweet once about how in Sweden when you go to someone's house, they don't feed you. It's not expected that you will have food. You have to bring your own food. Is that true? And what's that about?

Gustaf Alstrmer (01:21:35):
It's absolutely true. I actually gave an unconference talk about this topic. The unconference talk was all of the strange things to Swedish people do and why. If i would summarize it, yes, we do that. I actually experienced that. I went to a friend's house and they had dinner and I waited in my friend's room while they had dinner. That was just normal. And why did that happen? I think there's a strong sense of individual responsibility in Sweden, which kind of reaches over to unfriendliness, [inaudible 01:22:10] from an American or foreign lens because this is so crazy. But in Sweden it's just like, "Well, you take care of your kids. I'll take care of my kids." And it's not really a question.

(01:22:18):
I think that a lot of the motivations of why Swedes are strange, one of them is we don't want to be indebted to someone else. So we never want to feel like... Which is why you wouldn't... For example, if you go to a bar in Sweden, you don't buy a round, you buy your own beer because maybe you have to figure out the money at the end of the day, things like that. I think it's just actually quite individualistic society, but it's individualistic with heart I would say. There's a warmth to it, but it will definitely be appeared strange to people who don't really understand this. They think people are cold and they're just like they don't understand that there's actually a heart behind this stuff.

Lenny (01:23:00):
That sounds really smart, to be honest, the system. I would be into it, but I can see how people are very confused. Gustaf, I can't thank you enough for doing this. This was incredible. I know that people listening to this are going to leave informed, inspired, motivated, hopefully motivated to move faster and make more progress. Two final questions. Where can folks find you online if they want to learn more or ask you may be follow up questions? And two, how can listeners be useful to you?

Gustaf Alstrmer (01:23:27):
I tweet sometimes on twitter.com/gustaf. The most useful things that I put out is probably on the YC's YouTube channel. So I record a couple videos on growth, on sales, on how to talk to customers. I actually send them to people all day long because the Start School videos that we made are a lot of preparation went into it and it answers most of the questions that people have. So watch those first, I would say. But yeah, sometimes I tweet other stuff that people can follow. That's fine. How can people be useful to me? I love hearing feedback from founders, what they're working on. I want to hear kind of questions they have about their companies. But I want to also really emphasize that to apply to YC, you don't need to know any of us. You don't need to reach out to us. It doesn't make any specific difference.

(01:24:15):
The principles in YC is that you should be able to become an insider in YC in Silicon Valley without knowing anybody. That's kind of what the application process is about. So feel free to reach out to us if you have questions, but don't feel like that's required to be a good YC applicant. It's actually the opposite in that we read and treat all the applications equally. Thank you so much for listening to this podcast. I mean, it made me happy you made all the way to the end.

Lenny (01:24:44):
Yeah, extra credit for listening to the end. I also just want to say while you're saying that, it feels like YC is such a good force for the world. It just enables so much innovation and progress. And if technology is what drives the world forward, IC is so at the center of a lot of that. So just huge props to what YC is doing and what you're doing, Gustaf.

Gustaf Alstrmer (01:25:02):
We feel a lot of responsibility towards that. That's for sure.

Lenny (01:25:05):
All right, I'll let you go. Again, Gustaf, thank you for doing this.

Gustaf Alstrmer (01:25:09):
Thank you so much.

Lenny (01:25:12):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## The science of product, big bets, and how AI is impacting the future of music | Gustav Sderstrm
**Guest:** Gustav Sderstrm  
**Published:** 2023-05-21  
**YouTube:** https://www.youtube.com/watch?v=QtJoYFyrdPI  
**Tags:** growth, retention, acquisition, activation, onboarding, metrics, user research, mvp, a/b testing, experimentation  

# The science of product, big bets, and how AI is impacting the future of music | Gustav Sderstrm

## Transcript

Gustav Sderstrm (00:00:00):
The internet started with curation, often user curation. So you took something, some good like people or books or music, and you digitize it and you put it online and then you ask users to curate it. And that was your Facebook, Spotify, and so forth. And then after a while, the world switched from curation to recommendation, where instead of people doing that work, you had algorithms. And that was a big change that required us and others to actually rethink the entire user experience and sometimes the business model as well. And I think what we're entering now is we're going from your curation to recommendation to generation. And I suspect it will be as big of a shift that you will eventually have to rethink your products. We have to rethink the user interface and the experience for recommendation first era. And so what does that mean in the generative era? No one really knows yet.

Lenny (00:00:47):
Welcome to Lenny's Podcast where I interview world-class product leaders and growth experts to learn from their hard one experiences building and growing today's most successful products. Today, my guest is Gustav Sderstrm. Gustav is a product legend and he's now the co-president, chief product and chief technology officer at Spotify, where he's responsible for Spotify's global product and technology strategy and oversees the product design data and engineering teams at the company. I've had Gustav on my wish list of dream guests to have on this podcast since the day I launched the podcast and I'm so happy we made it happen.

Lenny (00:01:19):
In our conversation, we dig into what Gustav has learned about taking big bets and what to do when they don't work out, how Spotify moved away from squads and how they structure their teams now, how AI is already impacting their product, and also the future of music generated by AI. Also, why all great products need to pull some magic trick, how accurately succession represents Swedish business culture, and his hilarious analogy of peeing in your pants. Enjoy this episode with Gustav Sderstrm after a short word from our sponsors.

Lenny (00:01:51):
This episode is brought to you by Microsoft Clarity, a free easy to use tool that captures how real people are actually using your site. You can watch live session replays to discover where users are breezing through your flow and where they struggle. You can view instant heat maps to see what parts of your page users are engaging with and what content they're ignoring. You can also pinpoint what's bothering your users with really cool frustration metrics like rage clicks and dead clicks and much more. If you listen to this podcast, you know how often we talk about the importance of knowing your users, and by seeing how users truly experience your product, you can identify product opportunities, conversion wins, and find big gaps between how you imagine people using your product and how they actually use it.

Lenny (00:02:33):
Microsoft Clarity makes it all possible with a simple yet incredibly powerful set of features. You'll be blown away by how easy Clarity is to use and it's completely free forever. You'll never run into traffic limits or be forced to upgrade to a paid version. It also works across both apps and websites. Stop guessing, get Clarity. Check out Clarity at clarity.microsoft.com.

Lenny (00:02:59):
This episode is brought to you by Eppo. Eppo is a next generation AB testing platform built by Airbnb alums for modern growth teams. Companies like DraftKings, Zapier, ClickUp, Twitch, and Cameo rely on Eppo to power their experiments. Wherever you work, running experiments is increasingly essential, but there are no commercial tools that integrate with a modern grow team stack. This leads to waste of time building internal tools or trying to run your own experiments through a clunky marketing tool. When I was at Airbnb, one of the things that I loved most about working there was our experimentation platform, where I was able to slice and dice data by device types, country, user stage. Eppo does all that and more delivering results quickly, avoiding knowing prolonged analytic cycles, and helping you easily get to the root cause of any issue you discover.

Lenny (00:03:44):
Eppo lets you go beyond basic click-through metrics and instead use your north star metrics like activation, retention, subscription, and payments. Eppo supports test on front end, on the backend, email marketing, even machine learning claims. Check out Eppo at getE-P-P-O.com. That's geteppo.com. And 10X, your experiment velocity.

Lenny (00:04:08):
Gustav, welcome to the podcast.

Gustav Sderstrm (00:04:11):
Thanks for having me, Lenny. Pleasure to be here.

Lenny (00:04:13):
It's my pleasure to have you on. So at this point, you've been at Spotify for over 14 years, which is a rare feat in the tech world, and you've held a lot of different roles while you've been at Spotify. Can you just start off by giving us a sense of what these various roles and what you've done over the years at Spotify and then just what are you up to these days? What are you responsible for now?

Gustav Sderstrm (00:04:33):
So I came into Spotify in early 2009, late 2008. And my job then, I had been an entrepreneur, started some of my own companies in the, back then, very, very early feature phone, smartphone space. So I had a bunch of knowledge there. I had sold the company to Yahoo in the mobile space. I worked there for a while. I came back to Sweden and then I met through a mutual friend, Daniel Ek, the CEO and co-founder of Spotify. And they had built the desktop product already, the free streaming desktop product, and it was amazing and I could try it, but they needed someone to figure out what to do with mobile. And because I had been an entrepreneur in that space, I got that job.

Gustav Sderstrm (00:05:20):
So my job was to head up mobile for Spotify and figure out what the mobile offering would be, which was a challenge because, obviously, Spotify desktop was a free on-demand streaming application and back then, specifically with edge networks, you couldn't really stream at all in real time. The performance wasn't there and also you couldn't fund that with an ads model. So it was a product and business model innovation that was a lot of fun. So that's how I started. Then after a few years, I took on all of product development for Spotify. And then a few years later, I actually took on the technology responsibility, the CTO role for Spotify as well. And recently, my official title is co-president of Spotify together with Alex Nordstrom. So we run half of the company each. I run the product and technology side and he runs for the business and content side. So that's the super fast version.

Gustav Sderstrm (00:06:20):
Aside from getting more responsibilities taking on the technology department, it has been the same job by title. I've always reported to Daniel, but because Spotify's grown so much every six to 12 months, it's been starting at a new company. First, it was sort of a Swedish Nordic challenge and then it was a European challenge and then it was getting into the US and then we became a public company. So it's as if I had jumped around between a lot of jobs actually, even though it was largely the same title and role.

Lenny (00:06:55):
Your story makes me think of the classic be careful what you're good at because you end up taking on more and more. And clearly, you've been given more and more responsibility over the years and so clearly things are going well and you're doing well.

Lenny (00:07:08):
Shifting a little bit. So you're on my podcast currently. You actually have your own podcast, which was this limited series on the product story of Spotify, which I listened to and loved, and it's surreal to listen to your voice in real time because I've been listening to that recently in preparation for this conversation. Two questions, just what made you decide to launch your own podcast knowing you had a full-time job and a lot going on and the production value for your podcast was very high for what I could tell? And then two, just what did you learn from that experience in terms of the product you ended up a building and just empathizing with the podcast creator side of?

Gustav Sderstrm (00:07:41):
There were a bunch of different reasons why I did that. One is, and not a small one, I think, like you, I love writing and I have this secret creator dream in me. I used to write blog posts a long time ago and I write internally a lot. You can't write that much externally when you work at a company like this.

Lenny (00:08:01):
Yeah.

Gustav Sderstrm (00:08:02):
But I love writing and talking and presenting. So there was certainly that. And then no small part was, from a product point of view, to empathize with one of our main constituents, the podcast creator. I'm, unfortunately, not a great musician. I try to play instruments and so forth, but I don't have any records. I don't sing very well. But I decided to make a podcast and that taught me a huge amount about what it's like to be a creator, creating different styles of podcast.

Gustav Sderstrm (00:08:33):
For example, we wanted to do a higher production cost podcast with music and then right away you run into a bunch of problems as Spotify is actually pretty well positioned to solve, but still, it's really hard to have music in a podcast from a rights perspective. So you understand all these problems that podcasters have and you can be better at solving them. But the biggest benefit and the real reason for doing the public podcast was that I have actually done an internal podcast through a hack where we could gate the podcast-only employees. And I tried to figure out internally how to build more culture around Spotify and help define for new employees and existing employees, who we are, the mistakes we did, the successes we had, and how we think about strategy specifically in product strategy because we were quite well known externally for technology and the squads and all of these things, not so much for product strategy.

Gustav Sderstrm (00:09:36):
And because I love storytelling more than Google Docs, I decided to do an internal podcast and I went around and I interviewed actually Daniel's direct reports. So the CMO, the CHRO and CFO. And just ask them about a bunch of stuff. And the idea was to make them more approachable for employees because I felt listening to podcasts, even these people that have no idea who I am because I've never met them, I feel like I know them, I feel like I know how they think and I just like them much more. So the secret idea was, what if you could get to know your leaders much better than you do through occasional meetings or some town hall? So I did that internally, and because I'm a product person, we ended up talking a lot about product and product strategy. And people internally really like that.

Gustav Sderstrm (00:10:26):
So next time, the question was, what if people that don't even work at Spotify yet could feel as if they knew people at Spotify? That'd be great because most leaders in most companies are very opaque and appear as some otherworldly creatures that aren't really real, I think, when you see them in business papers or something. So what if you have heard them talk for an hour or so? So that was general idea. So a combination of recruitment tool, sharing more about how we think about product strategy and just because I think it was a lot of fun. I got to interview a bunch of smart and interesting people both externally and internally.

Lenny (00:11:09):
Did it have the effect that you were hoping after looking back?

Gustav Sderstrm (00:11:12):
I think it did. The podcast did well and, no, we did not give it our own promotion. I had to compete as everyone else, which also gives you a lot of empathy for the problem of like, okay, now you have a product, what about user acquisition? How do you actually get people to listen to it? So it did achieve what I wanted in the sense that we have this thing called intradays where especially in the past few years when we've hired a lot, we actually fly people to Stockholm for an onboarding session to learn about Spotify. And the leadership is on stage, talking about what they do and the departments and strategy and so forth. And it's very common that people come and tell me that, "Oh, I listened to this podcast or this and the episode and it's at least one of the key reasons why I joined or sometimes the reason why I joined." So it's anecdotal, but it may be in the many tens of people, at least, who have said it. So that seems to work.

Lenny (00:12:12):
That's really interesting. Just again, and this comes up a few times on the podcast, is just the power of content in all these different ways for hiring for culture building. And it sounds like the original goal was just internally build this clinic culture and strategy.

Gustav Sderstrm (00:12:24):
That was the original goal, make senior leadership more approachable and reduce the distance and then also share more of the thinking in an entertaining way rather than just through docs that people end up not reading.

Lenny (00:12:38):
I love that. So I was listening to it, as I said, and what was really interesting is I think episode four was actually all about AI, and I think your first attempts at leveraging machine learning in AI within Spotify. And I think that's what led to Discover Weekly and a few other tools. And that was years ago. And it's interesting listening to it now where AI is, again, a huge deal. And so I'm curious very tactically on the product team what you advise product managers and product teams on how to think about AI in their product thinking and also just in their day-to-day work.

Gustav Sderstrm (00:13:12):
I can give a few examples there and I don't know that we're more sophisticated than anyone else, but we'll be doing at least the traditional machine learning for quite a long time. And I think in the podcast, I think I talked about the journey of the internet in stages. And one way to think about it is that the internet started with curation of the user curation. So you took something, some good, like people or books or music and you digitize it and you put it online, and then you ask users to curate it. And that was your Facebook, Spotify and so forth. And then after a while, the world switched from curation to recommendation, where instead of people doing that work, you had algorithms. And that was a big change that required us and others to actually rethink the entire user experience and sometimes the business model as well.

Gustav Sderstrm (00:14:04):
And I think what we're entering now is we're going from your curation to recommendation to generation. And I suspect it will be as big of a shift that you will eventually have to rethink your products. So that's one lens. So I tend to talk to my teams about, even though it's all machine learning, I ask them to think of this as something completely different. The recommendation error was one type of machine learning. The generation error is a different type, so don't think of it as just more of the same, think of it as something actually completely new instead. And what we learned in ... Well, a few things. So if you look at this new era of large language models and the fusion models and so forth, there are two types of applications. As I said for the recommendation error, we had to rethink the user interface and the experience for recommendation first error.

Gustav Sderstrm (00:14:57):
And so what does that mean in the generative area? No one really knows yet. As usual, there are a bunch of iterative improvements. So we use these large language models to improve our recommendations. You can have bigger vectors that can have more cultural knowledge. You can use it for safety classification on podcasts that no one has listened to yet and so forth. So there's lots of obvious improvements and we're doing those. But so far, we've only really done one real generative product in the hard definition, which is a product that couldn't have existed without generative AI, and that is the AI DJ. So that's a concept that we've been thinking about for a very long time. And the AI DJ is you press a button, a digitized person, there's a real person named X, digitized X. So he's now an AI, comes on and talks to you about music that you like and suggests music, and you can listen to it. And if you don't like it, you can just call him back and he says, "Okay, now, let's listen to something maybe from a few summers ago," or "Here's some new stuff that were trending yesterday in The Last of Us episode or something like that."

Gustav Sderstrm (00:16:10):
So that product couldn't have existed without generative AI, both generating the voice and generating the content of what the voice says. So you can have individualized, personalized voice at the scale of half a billion people. And so we had the use case we have seen for many, many years. Sometimes people call it the radio use case. We called it the zero intent use case internally when you actually don't know what you want to listen to at all.

Gustav Sderstrm (00:16:40):
Spotify wasn't that good. Spotify was good when, at least roughly, you knew the use case of what you want to do, if it was a workout or dinner. We had lots of options for all of those. But if you really didn't know at all, it was hard to open Spotify and stare at it. And people used to say longingly that this was the one thing that radio was good at. Radio was quite bad, to be honest. I mean, it's not personalized to you at all. It's not on demand. You come in in the middle of things, it's actually terrible in many ways. But people still often say that there was something good about it. And I think that's something was the fact that you had a knob and you could just switch between contexts. It's like no, boring, boring, boring, boring, okay, this is good.

Gustav Sderstrm (00:17:23):
And Spotify never had that mode of, I don't know what I want, but I want to cycle through things until I find something that I like. And I think with the AI DJ, that's actually the use case we managed to solve. So X comes on and says, "I'm going to suggest something to you that you can listen to." And if you like it, you can keep listening, but if you don't like it, you bring him back again and you change channel. And for one reason or another, we tried to solve that for many times for a long time, but just starting to play a random song without any context as to why you would hear this, it just never worked. So that was our first foray into a product that couldn't exist before. And I think to your question of principles around that, there are a few pretty distinct principles that we've learned.

Gustav Sderstrm (00:18:09):
One that I really like that is not my principle at all, I think it is straight from Chris Dixon, is the principle of fault-tolerant user interfaces. So I can't say how many times during the early machine learning era when we said we're moving from curation to recommendation. I saw a design sketch that was a single big play button because clearly that is the simplest user interface you can do, but if you don't understand the performance of your machine learning, you can't design for it. The quality of your machine learning, if you're going to have a single play button, needs to be literally 100% or zero prediction error, and that's never the case. So let's say that you have a one in five hits, four out of five things are done, then you need a UI that probably at least shows five things at the same time on screen. So you have a one in five of something being relevant on screen.

Gustav Sderstrm (00:19:03):
So you need to understand the performance of your machine learning to design for it. It needs to be fault tolerant and often you need an escape hatch for the user. So you make a prediction. But if you were wrong, it needs to be super easy for the user say, "No, you're wrong, I want to go to my library or to this or to that." So we have that principle of having fault-tolerant user interface and a user interface that corresponds to the current performance of your algorithms. And I think that is going to be true for generative machine learning as well. I think a very clear example actually is Mid Journey. If you think about the early Mid Journey user interface inside the Discord channel, actually generating an image was very, very slow.

Gustav Sderstrm (00:19:48):
It took a long time to generate high-quality image and they could have built the silver button thing where you put in a prompt, you wait for minutes, you get an image, and I think one out of four times, it's going to be bad. So you would've been disappointed three out of four times and it's a minute each, so like four minutes later, you'd be, "This is a shitty product." What they did was they generated four simultaneous low-res images very quickly and you could say, "So apparently, their performance was probably one in four, that's why they showed four and not six." And so one in four was usually pretty good. You click that one and either continue to iterate or scale it up. So that's also an example of, I think, people understanding where the performance of generative AI was when they built the UI. So that's something that I would be inspired by.

Gustav Sderstrm (00:20:37):
And for the AI DJ specifically, another principle is to try to avoid this urge of just wanting to show off the technology and then have this voice that talk and talk and talk and talk. You have to remember that people came there for the music. So the principle for the AI DJ coming from the team, by the way, this was a bottoms-up product actually, it required a lot of support. We actually acquired big companies and so forth to be able to build it. But the idea had been built by teams bottom up. So the principle there was literally to do as little as possible and get out of the way. And I think that was really helpful. It's not telling you what the weather is and what happened in the news and going on and on and on about this band. It is trying to get you to the music and I think that's why it's working because it is working very well for us.

Lenny (00:21:24):
I love this distinction between recommendation and generation. And this begs the question of, there's this trend that I imagine you're seeing of people autogenerating music using artists catalog. There's this Drake and The Weeknd thing that came out a week or two ago. Where do you think this ends up going and how do you think artists adjust to this world where music can just be autogenerated? This play button is all of it is generated versus just like the DJ in between the songs.

Gustav Sderstrm (00:21:53):
First, big caveat, this is just super early. No one knows anything about how this is going to play out or the legal landscape and so forth, but I think it's going to have a lot of impact. And I think if we talk about two things, one is what it could do for music, the other is the right situation, and if rights-holders are getting compensated and so forth. So we talk about the first thing in isolation. I think an interesting example is right about when I grew up, Avicii came along. And it's interesting to think about because Avicii was not really considered by the existing music industry as a real artist because he couldn't really play an instrument and he couldn't sing, and he was just sitting with this computer in this DAW, digital audio workstation. And so it wasn't really considered real music. And I think now all of us consider it very real music and that he had tremendous real musical talent.

Gustav Sderstrm (00:22:51):
So I think right now, we're probably in the face where people say this isn't real music and it's somehow fake. I think the way to think about these diffusion models if and when they get good enough at generating music is probably the same like an instrument. It's just a much more powerful instrument and we'll probably see a new type of creator that wasn't proficient at any instrument and they couldn't assemble a full orchestra and do the thing that they had in their head and they can now generate very new things. I also think, by the way, that there is this distinction between AI music and real music that doesn't exist. For sure, very talented real musicians are using AI to get better and to help create new ideas. So that distinction doesn't really exist. It's all going to be AI. The question is what percentage, which makes the problem harder because you can't talk about if it should exist or not.

Gustav Sderstrm (00:23:50):
You have to talk about what percentage should exist and who gets to use it or not. But I think the way to think about it is probably as an instrument and that could help create a huge amount of art. And I think this is not news to you who probably use these things a lot, but I think if you don't use these generative models, there is the perception that you tell it to create a hit and you will get that. That's not how it works. Actually, what these models do is because they've been listening to a lot of music, they are very good at doing something that sounds very similar to what already exists. Actually being original is very hard. And from one point of view, as it now gets easier to create more generic music, it will actually be more difficult than ever to be truly unique.

Gustav Sderstrm (00:24:39):
So I still think there would be tremendous skill in creating something truly unique. And my hope would be that what happened with the DAW and that technology jump was you got a whole new genre like EDM that you couldn't really produce it with an orchestra or live. And maybe we'll see completely new music styles with these technologies. I think that would be very exciting. So that's on the positive side, but then you have the rights issue, which I have a lot of empathy for. And Spotify specifically has seen this before. So we had a different technology shift like this, which was the technology shift to online downloads of music and piracy and peer to peer. So first, it was a big technology shift in peer to peer and it was exciting for consumers. More consumers started listening to more music than ever. And I think that's where we are now with generative AI.

Gustav Sderstrm (00:25:31):
There's a new technology, but it also required a new business model before creators and industry could actually participate and benefit from this. And that's, obviously, self-serving to say because we were a big part of innovating that business model. But I still think that's what's necessary and I hope that that's what I and we could be part of. So I think we've seen the first part, the technology shift, and there will probably be a lot of discussion and chaos here which have a lot of empathy for, but I think we haven't seen the second part yet. What is a model where this could be a benefit? What actually happened after piracy is that the music industry got bigger than ever, not just as big but bigger than ever. And I think that could happen with this technology as well. But we're right in the beginning.

Lenny (00:26:20):
So along the same lines, something else you teach is this idea of all truly great products have to pull some magic trick. This comes up in your podcast a lot and I think you mentioned this other places, and thinking about all the stuff you're talking about here, it feels like, in a sense, everything's going to feel like magic because AI's baked into it.

Gustav Sderstrm (00:26:38):
I think when we did the AI DJ, we did a small version of that. When people first listened to it, we could see that reaction in use of testing when they've wondered ... So the magic trick there was that how could they record this person saying so many different things because it's talking about my music. So the magic trick was, obviously, didn't record a person saying, it's generated, and that magic trick wears off. You hear it all the time now and so forth, but it was one of those magic tricks. So I still think that concept is important and it seems to correlate with products going viral and taking off.

Gustav Sderstrm (00:27:15):
And I think it was the same using something like Dall-E or Stable Diffusion or Mid Journey the first time. It completely seemed like a magic trick. And, obviously, there is no magic, it's just data and statistics. But I think getting to that point and iterating a product to the point where it feels like magic the first time is very helpful. And it's often a question of just getting the performance to a certain level, scoping down, removing things. There's a lot of fine-tuning, I think, that makes you cross that line from it's cool and impressive but not magic to it feels like magic. I don't understand how this could be done.

Lenny (00:28:00):
Yeah, it reminds me of the launch of GBT which ended up being the biggest, most fastest growing product in history, and it's like the epitome of a magic trick. It feels like actual magic.

Gustav Sderstrm (00:28:09):
Absolutely, absolutely. And to most people, it is still very ... Actually to a lot of ascent, even to researchers, it's a little bit magical. No one really understands fully. So I guess there's maybe some magic left in the world.

Lenny (00:28:23):
Absolutely. And I think a lot of people are worried about not understanding what's going on there. Shifting to the way you all build product at Spotify. So Spotify is famous for popularizing this idea of squads and tribes. And correct me if I'm wrong, but you guys have moved away from that approach.

Gustav Sderstrm (00:28:39):
Yeah, that's right.

Lenny (00:28:41):
Okay. So I'd love to understand just why you shifted and what you learned from that approach to building product, and then just like how do you organize the teams now? What do you do now?

Gustav Sderstrm (00:28:51):
This was something that we focused a lot on early and it turned out to be smart of us to name these things into squads and chapters and so forth. It wasn't really ... Well, maybe it was deliberately branding, but it wasn't for purposes of branding that we made it up. We made it up because we thought it was a good structure to use and we needed names for things and this was the early internet eras you were allowed to make things up. And so it was very good for where we were at the time and it certainly helped us in recruiting. It's become a little bit of a cost to us because people still think that we organize that way and it's not a very efficient way of being organized at this scale or maybe even if you started over right now because we've learned more.

Gustav Sderstrm (00:29:35):
But I think the big difference is the idea with the squad specifically was twofold. They were supposed to be small and full stack. So squad should be about seven people and it should have front and backend, mobile, QA, agile coaches and so forth, and it should be very autonomous was the idea. And that's really what we shifted. So, first of all, as you grow the company, scaling in increments of seven engineers just creates a ton of overhead. So, obviously, our teams now tend to be much bigger, maybe two, three times that at least per manager to maybe have 14 or something instead of seven and just less overhead roles. So that's one. It looks more traditional as you learn more and is reasonable as you scale. The second big thing I think we struggle with was back then when I joined, the average age at Spotify was ... I mean, I was the oldest and this was 14 years ago. So I think the average age was probably under 30 or something and it wasn't most tech companies.

Gustav Sderstrm (00:30:46):
And so we had coming from Sweden, which is a different culture than the US, and I love a lot of things about Swedish culture and I think we managed to keep the best parts, but Sweden is a very bottoms-up autonomous culture. There's this famous drawing on how you make decisions in Sweden. In the US, I think it's just a hierarchy. In Sweden, it's a circle. It's in a circle, no one is in the middle, there is no leader and so forth.

Lenny (00:31:13):
Interesting.

Gustav Sderstrm (00:31:14):
So I think by culture, we're very inspired by this super autonomous thing. And I think the idea with autonomy is very reasonable and the right one, which is we work and we are hiring the smartest people we can find and we pay high salaries for that. So if you're hiring smart people, one way to think about it is you're renting brain power.

Gustav Sderstrm (00:31:39):
So if you're renting all of this expensive brain power and then you give them no room to think for themselves, that doesn't sound smart, then you should actually hire less smart people and keep your costs down or something. So I think you have to give a bunch of autonomy to actually maximize the value of the investment you're making. So that's very reasonable that you would give a lot of space for people to use as much of their talent and capacity as possible. But the problem with that is if you put autonomy very far towards the leaves of the organization, and also if you combine that with having a very junior organization, which we did back then, there's a fair chance that you're just going to produce heat. You're going to have a hundred squads with a hundred strategies running in a hundred directions. And Spotify has been there in that camp.

Gustav Sderstrm (00:32:29):
I mean, we managed to get somewhere, for sure, in spite of this, but I'd struggle to say we were efficient in doing that. So we've done a few things. The team structure is more traditional, larger teams, less overhead. And we've been specifically working with where in the org do we put the autonomy because the extremes are at the leaves and we were there. The other extreme may be at the top, let's say maybe some Twitter, there's one person. Both have problems. If you have it at the leaves, you're going to produce a lot of heat. If you have it at the top, you need someone with a lot of capacity and Elon has a lot of capacity, but you are, by definition, going to bottleneck. All decisions have to go through there. And Daniel, it's not his personality that he even wants to make all the decisions.

Gustav Sderstrm (00:33:19):
He wants to maximize throughput rather than to bottleneck the throughput. So the question is, if it's not at the top and not at the very bottom, where do you put it? And what we've found, which I don't think is very contrarian at all, I think this is the case in most companies, is around the VP level. So if you have Daniel, then you have the C level, myself and others, then you have the VP level, that is a good mix of instead of having one person in the company think, so only Daniel then and the rest just do, you have on the VP level in the company this many tens to maybe hundreds of people that have a lot of autonomy to think. So you get a good amount of freedom of thought and people thinking in different directions, but it's not like 8,000 people. And these people on the VP level are both quite a lot of them, but they're also usually quite senior. They have a lot of pattern recognition.

Gustav Sderstrm (00:34:16):
So I think that solves for, it's a good ... If you think of it as an optimization problem, it's a good optimization space. So the autonomy level in Spotify now tends to be quite high at the VP level and then lower around those levels.

Lenny (00:34:33):
And when you say autonomy, what does that actually mean? Is it the VP of, say, the podcasting product has a lot of say over what happens and there's not a ton of ... I don't know how involved are people above? And I know Maya's the VP of product, I believe, for the podcast product.

Gustav Sderstrm (00:34:48):
Exactly.

Lenny (00:34:49):
Who I think is going to come on the podcast someday. What does that mean in terms of Tommy for her, what practically?

Gustav Sderstrm (00:34:54):
So it means that I would ask Maya to define a strategy for what we do in podcasting, how are we going to be different, why would a podcaster want to be here? Whereas another company, I will make that strategy or another company, Daniel would make that strategy. Same with ... The AI DJ, for example, came from our personalization team. And so that was a bet that they made. So they have autonomy to make those kinds of bets and define strategies. Same with the user interface, we have an experienced team, can talk about the org structure later, but I put a lot of autonomy on the VP of experience to define and suggest what it is that we want to do. And in other companies, I would define all of that myself, for example.

Lenny (00:35:45):
Just going even a little bit further here, I know you have just strong opinions on the way to organize teams and how the organization helps you optimize for specific things. What are your just thoughts along those lines and what have you learned about how the impact of organization and what you're optimizing for?

Gustav Sderstrm (00:36:03):
Yeah. So I talk about an idealized spectrum or maybe not idealized but exaggerated spectrum. Nothing is really true, but you create extremes to make a point. So on one spectrum, you have something like Amazon, which is known for two-pizza teams, no dependencies. You try to minimize dependencies so you can run in parallel. Teams compete with each other even on the same project and so forth. But they have direct access to the user.

Gustav Sderstrm (00:36:37):
And so the benefit here is if you have an idea, the time to get the user is very low and it has worked for them. It's produced Kindle, it produced Alexa, it's produced a lot of very novel things. There are a few interesting downsides here. One downside that I'm extremely impressed with Jeff Bezos' foreseeing is if you have teams that compete with each other, the incentives are to hide your results, hide your code. And that should make for an organization that gets no platform leverage because no one's corporating. And I think either he had that insight or because he saw this, he had to do this, but he's well known for pushing extremely hard on hard APIs. If you don't create hard APIs to your technology, you're out. And if you think about it, it has to be that way because otherwise no one would do it.

Lenny (00:37:32):
And a hard API is essentially everyone knows how to use this API and connect to this team to interface with.

Gustav Sderstrm (00:37:38):
Exactly. You have to expose your technology to others. You have to maintain those APIs and they have to be very structured because otherwise the whole thing would collapse as everyone's supposed to compete because there are no incentives. You have to centrally force that. And interestingly, even though theoretically then they're the worst position to have a structured platform, I think, because they forced it so hard, they were the ones who did Amazon Web Services because they had such hard defined APIs because of this rule that it was easier for them to turn it inside out and expose it the rest of the world. Whereas if you look at someone like Google, I think they struggled more with externalizing their APIs maybe because it is so friendly and soft. So they didn't need as hard APIs on the inside because there was no competition. People could just go into each other's code.

Gustav Sderstrm (00:38:18):
So it's interesting anecdote around it, but the main point is you're faster there, but it's going to be hard to corporate. And so you will see something like maybe exaggerating a bit. Sometimes you'll see multiple search boxes on the same page from different teams. And this has been true in Spotify, by the way, as well. You've seen multiple toasters on the Now Playing view coming up from different teams because they're working. When we were in the autonomous mode, everyone running. And then ... So you get the benefit of speed, but you get the drawback of shipping your org chart and shipping complexity to the end user. But clearly, that's been the right choice for Amazon because they're a trillion-dollar company. But then on the other spectrum, you have something like Apple who's also a trillion-dollar company. So clearly, both models work, where you would never see two search boxes from the same team popping up on an iPhone. That is centrally organized by something that is close to single individual.

Gustav Sderstrm (00:39:20):
So they are instead in what is probably the world's biggest largest functional org, they're doing as much. If you think about what goes into the Apple, I mean, they certainly do everything we do. They have music service, podcast service, audiobooks, and they have a billion other services. So it's not like they have an easier problem. And yet they build something that feels more like it was built by a single developer for a single user. So they centralize and they have this bottlenecking function that everything has to go through and be decided how it fits with everything else. And so that has the benefit of the user experience being simpler and not shipping the org chart and increasing complexity. But it also has the drawback of speed without having facts on it. I've heard people working at Apple have said, "Yeah, it took seven years to get that thing to market," because you just had to wait in the pipeline.

Gustav Sderstrm (00:40:17):
So you have these extremes. And I think the most interesting example, I think, to think about is when you double click the power button on an iPhone, the Apple Pay comes up. That decision, how did that happen? You can imagine that all the services team would like to pop up when you double click that button. And so someone had to decide, should music come up, should payments come up, should something else come up? And so they have a different structure there. And on that spectrum of centralized versus decentralized, because of our strategy, which is we're a single application, trying to add or not trying to, we have added multiple types of content with actually very different business models on the backend, rev shares and royalties and book deals and so forth into single user experience. That is our strategy. We think the user experience in keeping that simple is the most important thing.

Gustav Sderstrm (00:41:12):
So we've chosen more of the centralized model, where these different vertical businesses, if you think about it, the music business, podcast, audiobooks business, they have it to go through a single recommendation organization because that's another problem. Which one do you recommend to which user? Should be a book or podcast or music? And how do you weigh them against each other? And also the user interface could easily get incredibly complicated if everyone built their own UI. The music team built their UI and then someone added features on top. So that's how we chose to optimize. But it is based on our strategy and I think both models work.

Lenny (00:41:50):
This episode is brought to you by Eco. Last month, Eco users earned an average of $84 in cashback rewards. How? With Eco, the future of personal finance. Eco is the update to a misaligned financial system. Providing an app that works just like your bank but removes almost all of the middleman, helping even the best money optimizers optimize in less time automatically. What if you earn rewards for paying your rent or got rewarded for ordering food and shopping online or even earn rewards for saving each month? And then imagine if you got rewarded again just for getting rewarded. With Eco, you can spend at some of your favorite merchants and automatically get 5% cashback, plus Eco's APY rewards look more like $80, not 80 cents. And then there are Eco points, the world's first open reward system. You earn them whenever you do almost anything in the Eco app.

Lenny (00:42:40):
Eco is working to make these points the most rewarding points ever. So it pays to be early. Sound too good to be true? Go to eco.com/lenny, sign up for an onboarding and find out why it isn't. Lenny's Podcast listeners who attend an Eco welcome session will get an exclusive 4% APY on deposits over $1,000. Learn more at eco.com/lenny, that's E-C-O.com/lenny.

Lenny (00:43:05):
It's interesting these two examples you gave, Apple and Amazon, they're two of the biggest companies in the world and they're like at the extremes of these two into the spectrum. And it's interesting, most companies are somewhere in the middle. I wonder if there's just a benefit to being in an extreme and that ends up being really important.

Gustav Sderstrm (00:43:21):
I think so. In almost all industries, you have this smiling curve concept, where you want to be at the extremes on the smiling curve, and that's where big business opportunities are but not in the middle. So it's probably true in terms of organizational models as well.

Lenny (00:43:34):
Speaking of extremes, I want to talk a bit about taking big bets. So you guys had this big launch event recently where you basically redesigned the whole primary feed of Spotify to make it feel more like where apps are going, like TikTok reels feel of just stream, and you start hearing videos and music starts playing and some people loved it, some people did not. And I'm curious as a product leader, how you think about thinking long term and dealing with people that are just like, "What the hell's ... I hate change, stop changing things." How do you think about that? Who do you listen to? Who do you ignore? How do you know to stay the course? How do you approach that?

Gustav Sderstrm (00:44:10):
Yeah, you're being very kind. There was a lot of negative feedback on Twitter on some of that. So let me actually dig into some detail because I think for product people listening to this, this is an interesting lesson that I think few companies talk about because you want talk about everything that went exactly as you thought they would and you don't want to talk about the things that didn't go exactly as you thought they would.

Gustav Sderstrm (00:44:39):
So I'll go through what we are trying to achieve and what we learned. So Spotify is mainly a background application, and for a long time, we've been considered very good at background music and podcast recommendation. When the phone is in your pocket and you're listening to an EDM playlist or pop playlist or something, we're really good at inserting another EDM track there or another pop track there or something like that in the background.

Gustav Sderstrm (00:45:09):
What we hear from users again and again, though, is that they say that they get trapped in a taste bubble. So I love my Spotify, I love this, but I'm a little bit bored with EDM now and Spotify's not suggesting something completely new. And if you think about that problem, it may sound similar to the recommendation problem, it's just another recommendation problem, but it's actually fundamentally different because when you're recommending another EDM track inside the EDM playlist, you have a lot of signal from that user that they like EDM. But if you're going to recommend a completely new genre, by definition, you have no idea. Because if you had an idea, it wasn't new to them. So you can't know anything. So back to hit rate, your hit rate is going to be incredibly low when you suggest something completely new to the user.

Gustav Sderstrm (00:46:03):
So this problem of helping people get out of the taste bubble isn't that easy as it sounds. And we can't really take some genre that maybe isn't typical. So I'm a big fan of Reggaeton, for example. It's not typically ... It's not that common in Sweden. And if you would look the rest of my profile, it's EDM heaviness, you probably wouldn't have guessed it. And Spotify wouldn't have guessed it. So if I'm listening to my favorite EDM playlist in the background or maybe my metal playlist, metal is very big in Sweden, it's really hard for us to just insert a Reggaeton track in the middle of that. Most people are going to think Spotify's broken.

Lenny (00:46:41):
Yeah.

Gustav Sderstrm (00:46:41):
What the hell are they thinking? So that doesn't really work. So in order to help people break out of their taste bubbles, you need something different. You need something where your hit ratio can be very low and you need people to expect it to be very low.

Gustav Sderstrm (00:47:00):
So when we recommend things in the background, our hit ratio needs to be at least nine out of 10, maybe one dud is okay, but if you get five duds, you're going to think we broke your playlist and your session. We need something where one out of 10 is a success. If you find one gem out of 10 tries, you're very happy. So you need a completely different paradigm. And you also need to be able to go through many candidates quickly because the hit rate is so low. You can't take three minutes per item. It's like, "Okay, I didn't like this," and it's still like two minutes left before the next one comes on. You need to quickly say, "No, no, no." So the obvious candidates for this are these feed-type experience, where you can go through lots of content, you're expecting the hit ratio to be much lower. And if you don't like it, the cost is very low, you just swipe.

Gustav Sderstrm (00:47:50):
And then this is the reason why people have been ... When they want to break out of their taste bubbles or when they come into Spotify and listen to something completely new, it is usually because they found it on one of these services, like a TikTok or YouTube or something, where they get exposed to lots of new content. So people were asking us for these tools and so that's what we wanted to solve for. And so we built a bunch of features, feed-like structures, where you can go through either a new genre with many tracks or a podcast channel with genre with many episodes or even full playlists. And we implemented those and we put them in something called subfeeds. So in the current experience, and this is roll out worldwide, if you click the podcast subfeed, you get a feed of podcast episodes. Click the music subfeeds, you get a feed of playlists where you can go through many playlists. And if you don't understand the name, you can quickly hear what they sound like and check out a few tracks and understand if this is for you. And if you go through the search and browse page, you can find completely new genres that you can quickly go through.

Gustav Sderstrm (00:48:59):
And so those are working as we intended. People go to them when they want to find new music. They browse through them and they save new songs. So they're working as we intended. The thing that didn't work as we intended was when users asked us for this again and again, we took the sum of these things and we put it on Home because people ask so much about discovery and we can see clearly how correlated discoveries with retention on Spotify and so forth. But what we misjudged or failed or rather learned about our own homepage is that the way it works right now, and this is what you can see in the Twitter comment, if you remove the angry voices and try to see what they're saying, they're saying the following, which is actually quite clear in the quantitative data as well, that if you look at what people do on Spotify's homepage, the current one, it is almost 90% what we call recall.

Gustav Sderstrm (00:49:59):
So it is either getting to a session that you're already in or a specific playlist that you know you want to get to or at least a specific use case. So you come in with a high intent, you actually knew what you wanted, and maybe only 10% of the time as a true discovery, like I don't know what I want. So if you think about, that is 90% recall and 10% discovery. When we tested the design ... So the subfeeds were working and not working, but when we tested some of them on Home, we switched it from 90/10 to 10/90. So 10% recall, 90% discovery. And while people want discovery, they probably don't want 90% discovery, instead of 90% recall. So if you then look at the comments on Twitter, what they're saying is like, "Hey, I can't find my playlists anymore. Where are these things?"

Gustav Sderstrm (00:50:47):
They're not really complaining about the discovery, they're complaining about the things they don't get anymore. And we can see this in the quant data as well. And you can see traffic shifting from home into search and into library, which is a clear sign people are trying to find the things they can't find anymore. And you can even see people then trying to use these discovery tools which are optimized for quickly understanding new things to do the recall. Where's that workout playlist I know I want? And it's actually very bad UI for recall, it's like a slot machine, right? Very unpredictable if you ever get to that workout playlist. It was optimized for finding new things, not for recall of existing things. When you do recall, you want the dense UI with many items on screen because you know what it is you're looking for. So you don't need a lot of real estate when you're doing discovery of new things. You want a lot of pixels and you probably want sound because you don't know what it is.

Gustav Sderstrm (00:51:40):
So what we learn about our UI, and I think there's maybe a little bit of product jealousy here, you always look at other experiences. And if you look around, it could be forgiven for thinking that most other products, if you look at something like YouTube, for example, their homepage is exactly that. It's a huge single-item discovery feed with only new items. And people don't seem to tweet angrily about how angry they are at you to say they love YouTube and it's a big product. And I think what we discovered was that we actually did something really well on our homepage, which was supporting you being inside a multiple sessions at the same time. So you could be in the middle of two podcasts and an audiobook and also them actually I just want to get to that workout playlist. I don't remember the name of it, but I know it's workout.

Gustav Sderstrm (00:52:31):
We actually did that part really well. I would venture just say much better than the other experiences where you literally have to go to some tab and into library and start browsing to get back to where you were. And so maybe it's path dependent. Because we have done recall pretty well, people got, I think, reasonably upset when they couldn't do the recall anymore. And we didn't want lose that because it was one of the things we did well and underestimated. And my takeaway is actually we do it better than other experiences. So we certainly want to keep that. So what we did was now we're just updating their hypothesis to achieve the same goal, which is these things are working and when people want to discover, they use them and they seem to work, they can also get better.

Gustav Sderstrm (00:53:20):
You're on this hill-climbing journey from a machine learning point of view, but the question is, how do you make sure that whenever people feel that they are in that I'm trapped in my taste bubble, they understand that these things are there and they're easy to use? So now we have a version of Home that we are also testing, obviously, where these things are very available but voluntary and you can still do all of the recall. And so from my point of view, this is the reason we A/B test because you want to be scientific about it and you want to learn as much as possible about your own product and your users. And now I'm sharing a lot of the learnings. Maybe we should keep them to ourselves, but my hunch is that it's going to make it a much better product.

Gustav Sderstrm (00:54:09):
But what I told my teams when we went into this, because I've done this a few times, agree to signing, I think there are two fundamentally different types of product development. One is designing a new feature. It is hard, but it's voluntary for people to use. So you do the AI DJ. Some people love it, that's fine. If you don't like it, it didn't make it worse for you. But when you redesign, it is much more tricky because it's not voluntary to participate in the redesign. So there's a cost even for people who don't like it. Then you have a very tricky problem here, which is there are going to be two types of feedback. One is you did something and it was right, but people are upset because you changed stuff. The other is you did something and it wasn't right, and people are also upset but for good reasons.

Gustav Sderstrm (00:55:08):
And so how do you separate these two? Because I think I explained this to ... When we talk through this with my teams, I think the analogy to think about is you have your desktop, your physical desktop, you have your computer in one place, you have your pencil over here, you have your notebook over there, and I come in and I just rearrange all of it. And you have spent, in our case, maybe 12 years with that setup. It doesn't matter if I have a lot of quantitative data that my new setup is better, you're going to get upset because you are effective in this old setup. And it's hard to tell those apart. The most classic use case is the Facebook newsfeed, which people are very upset about when it became a single newsfeed. But it turned out to solve a lot of user problems that you didn't have to run around all of Facebook collecting events yourself.

Gustav Sderstrm (00:55:58):
So there are some ways of understanding if you made it better, but people's habits are broken or if it's not better. And one thing is, for example, to look at new user cohorts that don't have that behavior versus all user cohorts and so forth. So we went through all of this with the teams. Before we did it, I said, "This is going to be painful." There's probably going to be a lot of tweets because chances that we get it exactly right are very low. So for that reason, it hasn't been very hard on the team. It is hard ... You want to respond to people, but the right way to do it is to listen, understand, try new hypothesis to really figure out what's going on. So I think I've done it maybe three or four times now. Three maybe. One unsuccessful, two successfully. So kind of knew what I was getting into.

Gustav Sderstrm (00:56:45):
So it's almost like you punish yourself, very painful, but also the most exciting things. And I think any product person knows that the easiest, the most straightforward thing to do is to iterate around where you are. There's no risk. You're not going to get fired, no user is going to get angry. But everyone also knows that eventually if you don't adapt new technologies, new paradigms, et cetera, you're going to get replaced. You have to find this balance of trying new things. And when you work in software, you have this tool of A/B testing and being scientific about it. When you build hardware, it's worse. If you're wrong, you're wrong. You can't update.

Lenny (00:57:26):
I love this story. I so appreciate you sharing it. I imagine also with a big launch like this, you can't actually A/B test it ahead of time because of the press season. They're like, "Oh my God, look what Spotify's doing." And so you're limited there. Imagine, right? You couldn't really test this ahead of time.

Gustav Sderstrm (00:57:40):
The hardest thing about this is if you're trying something completely new, the MVP needs to be very big so you can build a new IU, but if you didn't do algorithms for single item feed, you can't tell if it was the right idea but poor machine learning, right? UI poor machine learning. Or you have to build a lot and that gets quite expensive. That's actually ... The biggest why it's painful is not really the feedback from the outside. It is the cost you have to take on the inside. You incur a lot of costs as you're really hoping you're right.

Gustav Sderstrm (00:58:15):
And in our cases, the changes on the homepage aren't that hard for us to do. The important thing is that the underlying hypothesis of, can we help you break out of your taste bubble actually works and then you update the acquisition funnels into that experience. But I think the problem is that you need to get so many things in place to be able to say, "You might get a false negative," just because you didn't do it well or not. That's the biggest challenge, I think, with these big rewrites where everyone has to update everything before you can know if you're right or wrong.

Lenny (00:58:52):
What was that process like of helping you understand what is not working and what is working and what you wanted to change? I imagine there's a bunch of data you're looking at, some tweets, things like that. What was the tactical, "Oh, shoot, something's not going the way we expected, here's what we should do?"

Gustav Sderstrm (00:59:08):
Well, the feeds, we tested, but the home feed, we rolled out and tested afterwards. And we tested out on users, a few different variants of it. And then we got the data back and we looked more at the quantitative data. And we do a lot of user research where people sit and use the feeds to understand and build our own theorem mind of what is working and what is not working. And then, obviously, you look at user feedback, of course, and some users are very good at expressing what is of it that isn't working, others are not as good as expressing what isn't working. So it can be hard to parse that, but certainly, that's a factor as well.

Gustav Sderstrm (00:59:49):
And so then once you do that, then you have quantitative data to look at. And then you sit in recent through, what do you think is right and wrong? What are the different hypotheses? What is working, what is not working? And then just update and test again and again until you prove or disprove your hypothesis. Trying to be as scientific as possible about it. And also I think the biggest risk also when you've invested so much time in something is getting precious about things. You have to just be brutal. You have to believe in things 100% until the data says no and then you believe in something else 100%. That sounds easy. It's very hard to do, to the extent that people get upset when you do it because, for some reason, people don't like when people change their minds. It is what we should want from everyone. I would love a politician who said, "I'd looked at the data and I realized actually this is right and now I believe this." But we hate politicians that do that. They feel untrustworthy and we ridicule them.

Gustav Sderstrm (01:00:56):
So I think that's the biggest risk with anyone. You just have to be unemotional and just look at the proof and the data. And then if you do that, you just move on and then you get to where you want to be, and you solve the same problem but you adapt.

Lenny (01:01:14):
I really like that philosophy. Essentially, it's the idea of strong opinions loosely held. Is that-

Gustav Sderstrm (01:01:19):
Exactly. Exactly what it is. And it sounds so easy, but it's hard.

Lenny (01:01:23):
Right? Because to your point, people don't respect someone changing their mind. They're like, "Oh, I see, they were wrong the whole time and they were so confident about being wrong."

Gustav Sderstrm (01:01:31):
Yeah, exactly. And it's unclear why it is what we should want, but I think it has something to do with human psychology. We actually tend to love profits and people who hold very strong opinions with very little data. Those are the people we like. People will look at a lot of data and actually that, we don't like. Not sure why.

Lenny (01:01:57):
We're flawed creatures.

Gustav Sderstrm (01:01:59):
For sure.

Lenny (01:02:00):
Is there something that you've recently changed your mind about along these same lines that maybe comes to mind of like, "Oh, yeah?"

Gustav Sderstrm (01:02:06):
No, I think these learnings about the science system and homepage does really well, maybe better than others, that we don't want to wash out with a bath water or whatever the [inaudible 01:02:20] expression is. I think that's the biggest current learning I'm actually very happy about.

Lenny (01:02:26):
Yeah, I love learning that we're doing some really well that we didn't really realize necessarily and maybe we should lead into that more.

Gustav Sderstrm (01:02:34):
Exactly.

Lenny (01:02:35):
Going in a somewhat different direction. Shishir Mehrotra suggested to ask you something. He's on your board, I believe.

Gustav Sderstrm (01:02:41):
Yes.

Lenny (01:02:41):
And he suggested to ask you about your 10% planning time. What is that about?

Gustav Sderstrm (01:02:46):
This is a concept that I think Shishir has used for a long time ever since he worked at YouTube. And the idea is that, roughly, you shouldn't be spending more than 10% of your time planning versus executing or building, which means that if you're working quarterly 10 weeks, you should spend one week planning as we work in six-month increment. So we try to spend two weeks planning and roughly successful. And this is ... Actually, when we talk about org models, give a shout-out to Brian Chesky at Airbnb, who is actually one of the first, I think, to have these more contrarian old models. He's much more applesque than most of Silicon Valley. He also works in six-month increments. He has a lot of experience in that as well. So that's what the 10% planning time is. And I think if you find yourself planning much more than that, you're either planning too much or your execution period is just too short for that amount of planning. It's a rule of thumb, but I find that it works.

Lenny (01:03:53):
I asked a few PMs what I should ask you, PMs that work at Spotify actually, that I haven't told you. And someone pointed out that you always bring a lot of energy and clarity to a room. That's something they see you as really strong at. What have you learned about just the importance of that or just how to do that well as a leader?

Gustav Sderstrm (01:04:11):
Well, that's great to hear. I didn't know that so I'm trying to figure out what to answer. I think that the energy, I don't know. I guess I'm just excited about what I do. I've always been excited about technology. I love seeing new things. My core drive is still this notion of you see something which I think you'll empathize with that doesn't exist yet. And you're like, "Wow, I wonder if that could exist. That would be so cool." And then in order to get people to do it, you try to share that excitement. So I don't think I can bring a lot of energy for something I'm not excited about. So I have to work on things I actually believe in and that I'm excited about. And so maybe then the energy comes more naturally. Unfortunately, for me, so far, Spotify has been in this phase where a lot of innovation is allowed and I'm even asked to try to do new cool things.

Gustav Sderstrm (01:05:09):
Maybe I would have less energy for a pure optimization phase. On the clarity, I've always liked trying to explain things. It's a well-known fact that the best way to understand something is to try to explain to someone else. So I go around explaining things to people who didn't ask for it and not to sound smart, but to see if I actually understood it. And so maybe it's that practice. And on that note, I actually do ask my leaders that work for me and I ask them to ask their leaders to always explain themselves. And I think when ... We talked a little bit about autonomy and so forth, we don't promise everyone that they have to agree, but I think the promise we should make to all employees is that even if they don't agree, they should be entitled to understand why you're making the decision.

Gustav Sderstrm (01:06:06):
What I don't think is acceptable is to say, "No, we're going to do it this way because I'm more senior. I've seen this a bunch of times. You are not smart enough." All of those things. I think you have to explain yourself so you owe an explanation. And I find that valuable back to the only way to understand something is to explain it because it usually turns out that if you can't explain it yourself, you probably don't really even understand it yourself. Sometimes I think it's possible that you can have product instincts that are good but you can't express them. But most of them, when people say there's something there but they can't explain it, they actually don't understand it themselves. And many times, there actually isn't anything there. And also if you can explain it as a product person, that knowledge is now shared. So it just becomes much more effective for the organization. So sometimes I try to provoke people a little bit and say ... When people ask how much is art versus science, I say, "It's 0% art, 0% magic, and 100% science." And that's because I want to force people to try to explain it. I think we use the word art and magic. We have historically used the word art and magic for anything that we couldn't yet explain.

Gustav Sderstrm (01:07:33):
Genetics was magic and art until it was science. And quantum physics was magic until it was science. And most recently, actually, intelligence and creativity was art and magic until it was statistics in an LLM. So I think I try to push people to say, "Are you sure you can explain this?" because that forces people to think through. So maybe I like it and I try to force it on people. So maybe that's why people think I sometimes bring clarity.

Lenny (01:08:07):
I love that. Question along those lines, is there a system or an approach to explaining that you recommend? Is it just write it out in a document? Is it explaining in a certain style or is it just however is natural to the person?

Gustav Sderstrm (01:08:20):
I used to write everything and then write and rewrite and make it more and more condensed. So that worked for me. I don't write as much anymore. Now, I tend to walk and talk in my head myself. What I actually do is I ... And I found this different for different people and a lot of people want to bounce something with someone else, that's how they think. You repeat the same thing again and again and you get some feedback on it. And so I used to write a lot. I sometimes do when it's an idea I want to understand better. And at some point in my life, I would love to write something real like a book or something. But what I do increasingly now is I do my one-on-ones with peers or people who report to me or something, and I just put on AirPods and do a distributed walk and talk.

Gustav Sderstrm (01:09:12):
Both people are walking but in different locations and you spend an hour discussing something. That has actually turned out to be very, very fruitful. So then you get the power of you're not alone so you get more brain power than your own. And I don't think there is strong evolutionary proof for this, but there's certainly indications that you're thinking better when you're walking, whether it's because you're oxygenating your brain or because it's evolutionary for some other reason, I'm not sure. But I found that walking, talking, and thinking actually even if you're not in person, just over AirPods, it's super effective. It was the pandemic that forced us. I thought we would get less creative and strategizing will suffer during the pandemic and I found the opposite. We had more of this than ever and I started thinking about why, and I think it's all of these walk and talks that we did.

Lenny (01:10:07):
You threw out there that you want to write a book someday. What do you think your book would be about?

Gustav Sderstrm (01:10:11):
I have no idea. I have no idea. Statistically, it's probably going to be about something that I did a lot, so it has to be about something with technology or product or something. But I would love to write something fictional. That'd be a lot of fun.

Lenny (01:10:26):
Oh, boy. I'll pre-order as soon as that's up. Another concept I wanted to touch on that another PM suggested, which is he called it the P in the pants analogy. Does that ring a bell? And is that interesting to talk about?

Gustav Sderstrm (01:10:40):
I don't know exactly which occasion this person is referring to, but I know I've used that analogy a few times.

Lenny (01:10:49):
Okay. Promising.

Gustav Sderstrm (01:10:50):
I don't know if it's like a Swedish analogy because I thought it was more widely known. But the idea is that you do something ... So the saying is that's like peeing in your pants in cold weather. It feels really warm and nice to begin with. And then after a while, you start to regret it. It's about being short term, basically. So now I just say that's like peeing in the pants inside because people know what I mean. It's a short-term thing.

Lenny (01:11:21):
That's a hilarious way of communicating that idea. Must be a Swedish thing.

Gustav Sderstrm (01:11:25):
Yes, I think Swedish people do it for some reason, apparently others don't.

Lenny (01:11:30):
Maybe because it's cold a lot of times of the year.

Gustav Sderstrm (01:11:33):
Yes. That's probably it. This is a saying in cold climate. In the warm, it doesn't help. No one understands what you mean.

Lenny (01:11:39):
Speaking of Sweden, do you watch Succession?

Gustav Sderstrm (01:11:42):
Yes, I do.

Lenny (01:11:43):
Okay. So Sweden's become a big part of the show, specifically the company trying to ... I guess I don't want to spoil, but there's a character that's really important. Yes, exactly. That is Swedish. And so I'm curious just what do you think of the way they portray the Swedish culture and Swedish business dealings?

Gustav Sderstrm (01:11:59):
It's super fun to see this as a Sweden. And I guess, first and foremost, like anyone or any person or any country that gets represented by super tall, well-built, great looking Alexander Skarsgrd should probably be pretty happy. So that's good. Then I think there's this episode where they are in Norway, without giving away too much.

Lenny (01:12:25):
Yep.

Gustav Sderstrm (01:12:26):
There are elements that are authentic. There's a lot of, I think, paid brand positioning from a Swedish brand named Fjllrven, which I think means arctic fox, which is actually a very popular outdoor brand in Sweden. So that's authentic. The sauna things and so forth are authentic. So it's real, but it's exaggerated. Actually, the thing that isn't very authentic is his negotiation style. Swedish people tend to be serious, cautious, and this guy's more of a player. So he's not the typical Swedish businessman from a negotiation tactic point of view, I think.

Lenny (01:13:11):
Yeah, it doesn't make me think of the way you described it where in Sweden, people sit in a circle and no one's in the center.

Gustav Sderstrm (01:13:15):
No, exactly. He's very much in the center.

Lenny (01:13:19):
And then when people go saunas, there are just like a chant, sauna, sauna [inaudible 01:13:23].

Gustav Sderstrm (01:13:23):
Exactly.

Lenny (01:13:24):
The last episode.

Gustav Sderstrm (01:13:25):
It's a great show. I love it.

Lenny (01:13:26):
I love it. This season is insane. I'm so curious where it all goes. Maybe just the last question before very exciting lightning round. Spotify is, at this point, the biggest podcasting platform for me specifically and I think globally, and I love using it. It works great. I'm curious just what's next for Spotify and specifically Spotify podcasting.

Gustav Sderstrm (01:13:48):
There are two sides to it. It's for Spotify creators and for Spotify listeners. For Spotify creators, there are two things. One is, and this is what we talked about at Stream On, we talked about it also for music discovery, but it's the same problem and even harder for podcast. So we're still focused very heavily on helping podcast creators find more audience. This is ... Like I said, it's even a bigger problem to break out of your habits and your bubbles in podcasting. Such a big investment to find a new podcast. And so that is something, I think, we could and should do really well. So we keep investing a lot there. And as I said, you'll see more as we roll up more features now.

Gustav Sderstrm (01:14:37):
The other big need for creators is monetization and you can monetize today in many ways with DEI and Spotify SEI and so forth. But we're working hard to expand that and make it better because the industry is starting to mature and I think this is one of the biggest needs and the biggest things we could do for creators to help them monetize better, actually both free and paid. We also have paid podcast. So that's on the creator side.

Gustav Sderstrm (01:15:07):
On the consumer side, I don't want to share too much. We've shown that we're investing a lot in discovery. I want to keep some secrets for when they roll out, but we are investing a lot in the user expense itself. I think it's far from optimal yet what it could be. One thing that I can share that we're investing a lot in is just the ubiquity and playback across different devices and in cars and all these things that we've done well for music. But I think the listening experience can get a lot more seamless. I think search can get better. The data about podcasts and ... Well, I don't want to say too much, but looking at AI and generative technology, there is a lot that can be done.

Lenny (01:15:52):
All right. Well, I'll take what I can get. With that, we've reached our very exciting lightning round. I've got six questions for you, Gustav. Are you ready?

Gustav Sderstrm (01:16:01):
I think I am. Let's do it.

Lenny (01:16:03):
Okay, we'll find out. What are two or three books that you've recommended most to other people?

Gustav Sderstrm (01:16:08):
Okay. This is why I try to squeeze in seven into two and three. So if we start on product, I think it's well known, but one that I would recommend product people to read is 7 Powers by Hamilton Helmer, and Netflix has used a lot. We use a lot. It's just if you're starting out, it's great to have a strategy framework. No strategy framework is right, but having one is better than none.

Gustav Sderstrm (01:16:31):
Another in the space of mental models and frameworks, I think, is The Complete Investor by Charlie Munger. So, yes, it's about investment, but really it's a bunch of mental models that he uses. And I think the key takeaway is you have a problem, you should always apply three different models to it because what models do is they simplify and reduce dimensionality. The world has probably infinite dimensions and they reduces to maybe three or four. And the risk with that is you happen to get rid of a really important dimension, maybe pandemic diseases or something. But if you use three models that have different dimensions and was reduced in different ways, statistically, and it comes to the same conclusion, even the second model you apply vastly increases your chances that you're right. So that was a good book to read.

Gustav Sderstrm (01:17:24):
Then I think if we go outside of product, I'm very interested in just science and mathematics. So a few quick ones. The Mystery of the Aleph, an amazing book. Something Deeply Hidden by Sean Carroll on the interpretation of quantum mechanics. Helgoland by Carlo Rovelli on the relational interpretation of quantum mechanics. The Beginning of Infinity and The Fabric of Reality by David Deutch. The Case Against Reality by Donald Hoffman on the evolution versus truth and that evolution doesn't optimize for seeing the truth, just for fitness. Gdel's Proof, I think, is an amazing book on his incompleteness theorem, that in any axiomatic systems, there will be true statements that can never be proven, which is a weird thing to think about. And then maybe one of my favorites is The Demon in the Machine by Paul Davies that, I think, is lesser known on how information is really just entropy and this concept of information engines, that you can power something by just information and exhaust is also information. That was not a quick list.

Lenny (01:18:39):
No, I was just going to say you've set the record for the most number of books, but it also shows how you've become so insightful and wise just reading books like these. And so I think if people are looking to get to a place that you're at now, I think there's the lesson.

Gustav Sderstrm (01:18:55):
I'll keep the artist much shorter, I promise.

Lenny (01:18:57):
It's all good. We got time. Okay, next question. What's a favorite recent movie or TV show?

Gustav Sderstrm (01:19:03):
So we talked about Succession and it is a recent favorite. So I'll just frivolously take something that isn't recent but is an absolute favorite, which is Halt and Catch Fire, which I think is on FX. Amazing show. If you ever worked in technology, kind of starts out in the Silicon Prairie in the '80s and follows up to present day. Amazing show.

Lenny (01:19:24):
Halt and Catch Fire. Yeah, I watched some of it. I actually fell off of it, but it's a good reminder to go check it out.

Gustav Sderstrm (01:19:29):
Got to go back.

Lenny (01:19:30):
I'm going to go back. What's a favorite recent interview question you like to ask?

Gustav Sderstrm (01:19:34):
I don't ask it, but my favorite question is Lex Fridman's small ending question that is usually something like, so what's the meaning of it all? I like that. It's a tough question to get.

Lenny (01:19:46):
I'm so tempted to ask you, but-

Gustav Sderstrm (01:19:48):
No, don't.

Lenny (01:19:50):
Okay. Let's move on. That'll be another ... That'll be our second take at this.

Gustav Sderstrm (01:19:53):
Yes.

Lenny (01:19:55):
What are some favorite products you've recently discovered that you love?

Gustav Sderstrm (01:19:58):
The obvious one is ChatGPT GPT-4 and just playing around with that, trying to create bots for yourself that do different things for you and so forth. But I don't think that's probably true for everyone. The other really favorite is something you've written about and talked about, which is Duolingo, which I think is both very impressive from a product point of view, the execution and what they've done. It is also insanely used in my family. We have a family account and everyone is using it and competing every day. So I'm both impressed by the product and I also use the product quite a lot.

Lenny (01:20:35):
What languages are folks learning within your family?

Gustav Sderstrm (01:20:38):
In my family, it's Spanish right now.

Lenny (01:20:41):
How's it going?

Gustav Sderstrm (01:20:41):
Bien.

Lenny (01:20:44):
You get a gold star.

Gustav Sderstrm (01:20:47):
I only have a few thousand XP. I'm not that good yet.

Lenny (01:20:51):
No, I don't know if that's good. That sounds pretty good. Next question, what's something relatively minor you've changed in your product development process that's had a tremendous impact on your team's ability to execute?

Gustav Sderstrm (01:21:01):
I'm not sure I've done anything minor that had a tremendous impact. Usually, it takes something bigger to get a big impact. I think maybe one thing that I've tried to do back to clarity and so forth is this thing I mentioned about I'm trying to push a lot for what I call Socratic debate, where the idea is obviously that the best idea wins, not the most senior idea and so forth. And trying to push for this notion of having people explain themselves, not saying I think there's something there or have a feeling or something like that. And apparently, as you said, that has had some impact because people apparently say that about me. So that's probably the biggest thing.

Lenny (01:21:53):
Final question, what is one fun ritual of the Spotify product team, and is it saunas?

Gustav Sderstrm (01:21:59):
So Spotify is so big now that it's quite local actually, different parts of Spotify, different product rituals. I accidentally created one ritual many years ago, maybe 12 years ago, when we talked about which phase a product is in. And it was ... We needed some definition. So I think off the cuff, I said, "Well, it's four phases." It's think it, build it, ship it, tweak it." And then the think it phase, it should be cheap, not a lot of money spent. In the build it phase, you're going to start spending a lot of money. So then you must have reduced the risk in the think it phase that you're right. And then you have the ship it phase and then you go over and tweak it. And it was something that wasn't that thought through, but it's funny because I still hear it sometimes even from other companies like, "Oh, we're in the think it phase," or "We're in the tweak it phase." So it stuck. I don't know if it's very good, but it's stuck.

Lenny (01:22:57):
It is catchy. I think anything getting stuck in people's head is a success. Gustav, thank you so much for being here. We are two for two for Swedish people. Gustaf, with an F, Alstrmer was on the podcast.

Gustav Sderstrm (01:23:10):
Who is also an amazing person.

Lenny (01:23:12):
Also an amazing person. I feel very jealous of people that get to work with you and for you. Thank you again for being here. Two final questions, where can folks find you online if they want to learn more, maybe reach out, ask some questions.

Gustav Sderstrm (01:23:23):
[inaudible 01:23:23] @GustavS.

Lenny (01:23:24):
Okay. Say it again

Gustav Sderstrm (01:23:28):
@GustavS.

Lenny (01:23:29):
Awesome. And then final question is just how can listeners be useful to you?

Gustav Sderstrm (01:23:33):
Just reach out. I do read feedback and I try to remove the angry comments and understand what they're actually thinking and why they're upset or what's not working.

Lenny (01:23:44):
And then the reaching out, would you recommend an angry tweet at you or more of a email to that email address you shared?

Gustav Sderstrm (01:23:50):
Well, the @GustavS is the Twitter handle, so just tweet at me.

Lenny (01:23:54):
Okay.

Gustav Sderstrm (01:23:56):
You can be nice as well.

Lenny (01:23:57):
Okay.

Gustav Sderstrm (01:23:57):
It's okay.

Lenny (01:23:58):
Amazing. Gustav, thank you so much for being here.

Gustav Sderstrm (01:24:01):
Thank you for having me, Lenny. It's been a pleasure.

Lenny (01:24:03):
Bye, everyone.

Lenny (01:24:05):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcast, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Why AI evals are the hottest new skill for product builders | Hamel Husain & Shreya Shankar
**Guest:** Hamel Husain & Shreya Shankar  
**Published:** 2025-09-25  
**YouTube:** https://www.youtube.com/watch?v=BsWxPI9UM4c  
**Tags:** acquisition, metrics, analytics, management, vision, market, persona, design, ux, ui  

# Why AI evals are the hottest new skill for product builders | Hamel Husain & Shreya Shankar

## Transcript

Lenny Rachitsky (00:00:00):
To build great AI products, you need to be really good at building evals. It's the highest ROI activity you can engage in.

Hamel Husain (00:00:05):
This process is a lot of fun. Everyone that does this immediately gets addicted to it. When you're building an AI application, you just learn a lot.

Lenny Rachitsky (00:00:12):
What's cool about this is you don't need to do this many, many times. For most products, you do this process once and then you build on it.

Shreya Shankar (00:00:18):
The goal is not to do evals perfectly, it's to actionably improve your product.

Lenny Rachitsky (00:00:23):
I did not realize how much controversy and drama there is around evals. There's a lot of people with very strong opinions.

Shreya Shankar (00:00:28):
People have been burned by evals in the past. People have done evals badly, so then they didn't trust it anymore, and then they're like, "Oh, I'm anti evals."

Lenny Rachitsky (00:00:36):
What are a couple of the most common misconceptions people have with evals?

Hamel Husain (00:00:39):
The top one is, "We live in the age of AI. Can't the AI just eval it?" But it doesn't work.

Lenny Rachitsky (00:00:45):
A term that you used in your posts that I love is this idea of a benevolent dictator.

Hamel Husain (00:00:49):
When you're doing this open coding, a lot of teams get bogged down in having a committee do this. For a lot of situations, that's wholly unnecessary. You don't want to make this process so expensive that you can't do it. You can appoint one person whose taste that you trust. It should be the person with domain expertise. Oftentimes, it is the product manager.

Lenny Rachitsky (00:01:09):
Today, my guests are Hamel Husain and Shreya Shankar. One of the most trending topics on this podcast over the past year has been the rise of evals. Both the chief product officers of Anthropic and OpenAI shared that evals are becoming the most important new skill for product builders. And since then, this has been a recurring theme across many of the top AI builders I've had on. Two years ago, I had never heard the term evals. Now it's coming up constantly. When was the last time that a new skill emerged that product builders had to get good at to be successful?

(00:01:41):
Hamel and Shreya have played a major role in shifting evals from being an obscure, mysterious subject to one of the most necessary skills for AI product builders. They teach the definitive online course on evals, which happens to be the number one course on Maven. They've now taught over 2,000 PMs and engineers across 500 companies, including large swaths of the OpenAI and Anthropic teams along with every other major AI lab.

(00:02:07):
In this conversation, we do a lot of show versus tell. We walk through the process of developing an effective eval, explain what the heck evals are and what they look like, address many of the major misconceptions with evals, give you the first few steps you can take to start building evals for your product, and also share just a ton of best practices that Hamel and Shreya have developed over the past few years. This episode is the deepest yet most understandable primer you'll find on the world of evals. And honestly, it got me excited to write evals, even though I have nothing to write evals for. I think you'll feel the same way as you watch this.

(00:02:41):
If this conversation gets you excited, definitely check out Hamel and Shreya's course on Maven. We'll link to it in the show notes. If you use the code LENNYSLIST when you purchase the course, you'll get 35% off the price of the course. With that, I bring you Hamel Husain and Shreya Shankar.

(00:02:58):
This episode is brought to you by Fin, the number one AI agent for customer service. If your customer support tickets are piling up, then you need Fin. Fin is the highest-performing AI agent on the market with a 65% average resolution rate. Fin resolves even the most complex customer queries. No other AI agent performs better. In head-head bake-offs with competitors, Fin wins every time. Yes, switching to a new tool can be scary, but Fin works on any help desk with no migration needed, which means you don't have to overhaul your current system or deal with delays in service for your customers.

(00:03:31):
And Fin is trusted by over 5,000 customer service leaders and top AI companies like Anthropic and Synthesia. And because Fin is powered by the Fin AI engine, which is a continuously improving system that allows you to analyze, train, test, and deploy with ease, Fin can continuously improve your results too. So if you're ready to transform your customer service and scale your support, give Fin a try for only 99 cents per resolution. Plus, Fin comes with a 90-day money-back guarantee. Find out how Fin can work for your team at fin.ai/lenny. That's fin.ai/lenny.

(00:04:05):
This episode is brought to you by Dscout. Design teams today are expected to move fast, but also to get it right. That's where Dscout comes in. Dscout is the all-in-one research platform built for modern product and design teams. Whether you're running usability tests, interviews, surveys, or in-the-wild fieldwork, Dscout makes it easy to connect with real users and get real insights fast. You can even test your Figma prototypes directly inside the platform. No juggling tools, no chasing ghost participants. And with the industry's most trusted panel plus AI-powered analysis, your team gets clarity and confidence to build better without slowing down. So if you're ready to streamline your research, speed up decisions, and design with impact, head to dscout.com to learn more. That's dscout.com. The answers you need to move confidently. Hamel and Shreya, thank you so much for being here, and welcome to the podcast.

Hamel Husain (00:05:04):
Thank you for having us.

Shreya Shankar (00:05:05):
Yeah, super excited.

Lenny Rachitsky (00:05:07):
I'm even more excited. Okay, so a couple years ago, I had never heard the term evals. Now it's one of the most trending topics on my podcast, essentially, that to build great AI products, you need to be really good at building evals. Also, it turns out some of the fastest-growing companies in the world are basically building and selling and creating evals for AI labs. I just had the CEO of Mercor on the podcast. So there's something really big happening here. I want to use this conversation to basically help people understand this space deeply, but let's start with the basics. Just what the heck are evals? For folks that have no idea what we're talking about, give us just a quick understanding of what an eval is, and let's start with Hamel.

Hamel Husain (00:05:49):
Sure. Evals is a way to systematically measure and improve an AI application, and it really doesn't have to be scary or unapproachable at all. It really is, at its core, data analytics on your LLM application and a systematic way of looking at that data, and where necessary, creating metrics around things so you can measure what's happening, and then so you can iterate and do experiments and improve.

Lenny Rachitsky (00:06:22):
So that's a really good broad way of thinking about it. If you go one level deeper just to give people a very, even more concrete way of imagining and visualizing what we're talking about, even if you have a example to show would be even better, what's an even deeper way of understanding what an eval is?

Hamel Husain (00:06:36):
Let's say you have a real estate assistant application and it's not working the way you want. It's not writing emails to customers the way you want, or it's not calling the right tools, or any number of errors. And before evals, you would be left with guessing. You would maybe fix a prompt and hope that you're not breaking anything else with that prompt, and you might rely on vibe checks, which is totally fine.

(00:07:11):
And vibe checks are good and you should do vibe checks initially, but it can become very unmanageable very fast because as your application grows, it's really hard to rely on vibe checks. You just feel lost. And so evals help you create metrics that you can use to measure how your application is doing and kind of give you a way to improve your application with confidence. That you have a feedback signal in which to iterate against.

Lenny Rachitsky (00:07:44):
So just to make very real, so imagining this real estate agent, maybe they're helping you book a listing or go see an open house. The idea here is you have this agent talking to people, it's answering questions, pointing them to things. As a builder of that agent, how do you know if it's giving them good advice, good answers? Is it telling them things that are completely wrong?

(00:08:04):
So the idea of evals, essentially, is to build a set of tests that tell you, how often is this agent doing something wrong that you don't want it to do? And there's a bunch of ways you could define wrong. It could be just making up stuff. It could be just answering in a really strange way. The way I think about evals, and tell me if this is wrong, just simply is like unit tests for code. You're smiling. You're like, "No, you idiot."

Shreya Shankar (00:08:29):
No, that's not what I was thinking.

Lenny Rachitsky (00:08:31):
Okay. Okay, okay, tell me. Tell me, how does that feel as a metaphor?

Shreya Shankar (00:08:35):
Okay. I like what you said first, which is we had a very broad definition. Evals is a big spectrum of ways to measure application quality. Now, unit tests are one way of doing this. Maybe there are some non-negotiable functionalities that you want your AI assistant to have, and unit tests are going to be able to check that. Now, maybe you also, because these AI assistants are doing such open-ended tasks, you kind of also want to measure how good are they at very vague or ambiguous things like responding to new types of user requests or figuring out if there's new distributions of data like new users are coming and using your real estate agent that you didn't even know would use your product. And then all of a sudden, you think, "Oh, there's a different way you want to kind of accommodate this new group of people."

(00:09:24):
So evals could also be a way of looking at your data regularly to find these new cohorts of people. Evals could also be like metrics that you just want to track over time, like you want to track people saying, "Yes. Thumbs up. I liked your message." You want very, very basic things that are not necessarily AI-related but can go back into this flywheel of improving your product. So I would say, overall, unit tests are a very small part of that very big puzzle.

Lenny Rachitsky (00:09:56):
Awesome. You guys actually brought an example of an eval just to show us exactly what the hell we're talking about. We're talking in these big ideas. So how about let's pull one up and show people, "Here's what an eval is."

Hamel Husain (00:10:06):
Yeah, let me just set the stage for it a little bit. So to echo what Shreya said, it's really important that we don't think of evals as just tests. There's a common trap that a lot of people fall into because they jump straight to the test like, "Let me write some tests," and usually that's not what you want to do. You should start with some kind of data analysis to ground what you should even test, and that's a little bit different than software engineering where you have a lot more expectations of how the system is going to work. With LLMs, it's a lot more surface area. It's very stochastic, so you kind of have a different flavor here.

(00:10:47):
And so the example I'm going to show you today, it's actually a real estate example. It's a different kind of real estate example. It's from a company called Nurture Boss. I can share my screen to show you their website just to help you understand this use case a little bit, so let me share my screen. So this is a company that I worked with. It's called Nurture Boss, and it is a AI assistant for property managers who are managing apartments, and it helps with various tasks such as inbound leads, customer service, booking appointments, so on and so forth. It's like all the different sort of operations you might be doing as a property manager, it helps you with that. And so you can see kind of what they do. It's a very good example because it has a lot of the complexities of a modern AI application.

(00:11:40):
So there's lots of different channels that you can interact through the AI with like chat, text, voice, but also, there's tool calls, lots of tool calls for booking appointments, getting information about availability, so on and so forth. There's also RAG retrieval, getting information about customers and properties and things like that. So it's pretty fully fleshed in terms of an AI application. And so they have been really generous with me in allowing me to use their data as a teaching example. And so we have anonymized it, but what I'm going to walk through today is, okay, let's do the first part of how we would start to build evals for Nurture Boss. Why would we even want to do that?

(00:12:36):
So let's go through the very beginning stage, what we call error analysis, which is, let's look at the data of their application and first start with what's going wrong. So I'm going to jump to that next, and I'm going to open an observability tool. And you can use whatever you want here. I just happen to have this data loaded in a tool called Braintrust, but you can load it in anything. We don't have a favorite tool or anything in the blog post that we wrote with you. We had the same example but in Phoenix Arize, and I think Aman, on your blog post, used Phoenix Arize as well. And there's also LangSmith. So these are kind of like different tools that you can use.

(00:13:29):
So what you see here on the screen, this is logs from the application, and let me just show you how it looks. So what you see here is, and let me make it full screen, this is one particular interaction that a customer had with the Nurture Boss application, and what it is is a detailed log of everything that happened. So it's called a trace, and it's just the engineering term for logs of a sequence of events. The concept of a trace has been around for a really long time, but it's especially really important when it comes to AI applications.

(00:14:12):
And so we have all the different components and pieces and information that the AI needs to do its job, and we are logged all of it and we're looking at a view of that. And so you see here a system prompt. The system prompt says, "You are an AI assistant working as a leasing team member at Retreat at Acme Apartments." Remember, I said this is anonymized, so that's why the name is Acme Apartments. "Your primary role is to respond to text messages from both current residents and prospective residents. Your goal is to provide accurate, helpful information," yada, yada, yada. And then there's a lot of detail around guidelines of how we want this thing to behave.

Lenny Rachitsky (00:14:56):
Is this their actual system prompt, by the way, for this company?

Hamel Husain (00:14:58):
It is. Yes, it is.

Lenny Rachitsky (00:14:58):
Amazing. That's so cool.

Hamel Husain (00:14:59):
It's a real system prompt.

Lenny Rachitsky (00:15:01):
That's amazing because it's rare you see a actual company product's system prompt. That's like their crown jewels a lot of times, so this is actually very cool on its own.

Hamel Husain (00:15:08):
Yeah. Yeah, it's really cool. And you see all of these different sort of features that are different use cases, so things about tour scheduling, handling applications, guidance on how to talk to different personas, so on and so forth. And you can see the user just kind of jumps in here and asks, "Okay, do you have a one-bedroom with study available? I saw it on virtual tours." And then you can see that the LLM calls some tools. It calls this get individual's information tool, and it pulls back that person's information. And then it gets the community's availability. So it's querying a database with the availability for that apartment complex.

(00:16:01):
And then finally, the AI responds, "Hey, we have several one-bedroom apartments available, but none specifically listed with a study. Here are a few options."

(00:16:12):
And then it says, "Can you let me know when one with a study is available?"

(00:16:16):
And then it says, "I currently don't have specific information on the availability of a one-bedroom apartment."

(00:16:23):
User says, "Thank you."

(00:16:25):
And the AI says, "You're welcome. If you have any more questions, feel free to reach out." Now, this is an example of a trace, and we're looking at one specific data point. And so one thing that's really important to do when you're doing data analysis of your LLM application is to look at data. Now, you might wonder, "There's a lot of these logs. It's kind of messy. There's a lot of things going on here. How in the hell are you supposed to look at this data? Do you want to just drown in this data? How do you even analyze this data?"

(00:17:07):
So it turns out there is a way to do it that is completely manageable, and it's not something that we invented. It's been around in machine learning and data science for a really long time, and it's called error analysis. And what you do is, the first step in conquering data like this is just to write notes. Okay? So you got to put your product hat on, which is why we're talking to you, because product people have to be in the room and they have to be involved in sort of doing this. Usually a developer is not suited to do this, especially if it's not a coding application.

Lenny Rachitsky (00:17:47):
And just to mirror back, why I think you're saying that is because this is the user experience of your product. People talking to this agent is the entire product essentially, and so it makes sense for the product person to be super involved in this.

Hamel Husain (00:17:59):
Yeah. So let's reflect on this conversation. Okay, a user asked about availability. The AI said, "Oh, we don't really have that. Have a nice day." Now, for a product that is helping you with lead management, is that good? Do you feel like this is the way we want it to go?

Lenny Rachitsky (00:18:30):
Not ideal.

Hamel Husain (00:18:32):
Yes, not ideal, and I'm glad you said that. A lot of people would say, "Oh, it's great. The AI did the right thing. It looked, it said, 'We didn't have available,' and it's not available." But with your product hat on, you know that's not correct. And so what you would do is you would just write a quick note here. You would say, "Okay." You might pop in here, and you can write a note. So every observability application has ability to write notes, and you wouldn't try to figure out if something is wrong. In this case, it's kind of not doing the right thing, but you just write a quick note, "Should have handed off to a human."

Lenny Rachitsky (00:19:19):
And as we watch this happening, it's like you mention this and you'll explain more. You're doing this, this feels very manual and unscalable, but as you said, this is just one step of the process and there's a system to this. That was just the first one.

Hamel Husain (00:19:30):
Yeah, and you don't have to do it for all of your data. You sample your data and just take a look, and it's surprising how much you learn when you do this. Everyone that does this immediately gets addicted to it and they say, "This is the greatest thing that you can do when you're building an AI application." You just learn a lot and you're like, "Hmm, this is not how I want it to work. Okay." And so that's just an example.

(00:19:58):
So you write this note, and then we can go on to the next trace. So this is the next trace. I just pushed a hot key on my keyboard. Let me go back to looking at it.

Lenny Rachitsky (00:20:09):
And these tools make it easy to go through a bunch and add these notes quickly.

Hamel Husain (00:20:13):
Yes. And so this is another one. Similar system prompt. We don't need to go through all of it again. We'll just jump right into the user question. "Okay, I've been texting you all day." Isn't that funny? And the user says, "Please." Okay, yeah, this one is just like an error in the application where this is a text message application, sorry, the channel through which the customer is communicating is through text message, and you're just getting really garbled. And you can see here that it kind of doesn't make sense. The words are being cut off like, "In the meantime," and then the system doesn't know how to respond, because you know how people text message, they write short phrases. They split their sentence across four or five different turns. So in this case-

Lenny Rachitsky (00:21:16):
Yeah, so what do you do with something like that?

Hamel Husain (00:21:18):
Yeah, so this is a different kind of error.

Lenny Rachitsky (00:21:19):
Mm.

Hamel Husain (00:21:19):
This is more of, "Hey, we're not handling this interaction correctly. This is more of a technical problem," rather than, "Hey, the AI is not doing exactly what we want." So we would write that down too.

Lenny Rachitsky (00:21:20):
Which is still really cool.

Hamel Husain (00:21:20):
Yeah.

Lenny Rachitsky (00:21:31):
It's amazing you're catching that, too, here. Otherwise, you'd have no idea this was happening.

Hamel Husain (00:21:35):
Yeah, you might not know this is happening, right? And so you would just say, "Okay." You would write a note like, "Oh, conversation flow is janky because of text message."

Lenny Rachitsky (00:21:51):
And I like that, I like that you're using the word janky. It shows you just how informal this can be at this stage.

Hamel Husain (00:21:56):
Yeah, it's supposed to be chill. Just don't overthink it. And there's a way to do this. So the question always comes up, how do you do this? Do you try to find all the different problems in this trace? What do you write a note about? And the answer is, just write down the first thing that you see that's wrong, the most upstream error. Don't worry about all the errors, just capture the first thing that you see that's wrong, and stop, and move on. And you can get really good at this. The first two or three can be very painful, but you can do a bunch of them really fast.

(00:22:38):
So here's another one, and let's skip the system prompt again. And the user asks, "Hey, I'm looking for a two- to three-bedroom with either one or two baths. Do you provide virtual tours?"

(00:22:51):
And a bunch of tools are called and it says, "Hi Sarah. Currently, we have three-bedroom, two-and-a-half-bathroom apartment available for $2,175. Unfortunately, we don't have any two-bedroom options at the moment. We do offer virtual tours. You can schedule a tour," blah, blah. It just so happens that there is no virtual tour, right?

Lenny Rachitsky (00:23:16):
Mm-hmm. Nice.

Hamel Husain (00:23:16):
So it is hallucinating something that doesn't exist. Then you kind of have to bring your context as an engineer, or even product content, and say, "Hey, this is kind of weird. We shouldn't be telling a person about virtual tour when it's not offered."

(00:23:32):
So you would say, "Okay, offered virtual tour," and you just write the note. So you can see there's a diversity of different kinds of errors that we're seeing, and we're actually learning a lot about your application in a very short amount of time.

Shreya Shankar (00:23:55):
One common question that we get from people at this stage is, "Okay, I understand what's going on. Can I ask an LLM to do this process for me?"

Lenny Rachitsky (00:24:04):
Mm, great question.

Shreya Shankar (00:24:04):
And I loved Hamel's most recent example because what we usually find when we try to ask an LLM to do this error analysis is it just says the trace looks good because it doesn't have the context needed to understand whether something might be bad product smell or not. For example, the hallucination about scheduling the tour, right? I can guarantee you, I would bet money on this, if I put that into chat GPT and asked, "Is there an error?" it would say, "No, did a great job."

(00:24:34):
But Hamel had the context of knowing, "Oh, we don't actually have this virtual tour functionality," right? So I think, in these cases, it's so important to make sure you are manually doing this yourself. And we can talk a little bit more about when to use LLMs in the process later, but number one pitfall right here is people are like, "Let me automate this with an LLM."

Lenny Rachitsky (00:24:55):
Do you think we'll get to a place where an agent can do this, where it has that context?

Shreya Shankar (00:24:58):
Oh, no. No, no, no. Sorry. There are parts of error analysis that an LLM is suited for, which we could talk about later in this podcast. But right now, in this stage of free form, note-taking is not the place for an LLM.

Lenny Rachitsky (00:25:13):
Got it. And this is something you call open coding, this step?

Shreya Shankar (00:25:14):
Yes, absolutely.

Lenny Rachitsky (00:25:17):
Cool. Another term that you used in your posts that I love and that fits into this step is this idea of a benevolent dictator. Maybe just talk about what that is, and maybe, Shreya, cover that.

Shreya Shankar (00:25:27):
Yeah, so Hamel actually came up with this term.

Lenny Rachitsky (00:25:29):
Okay, maybe Hamel cover that, actually.

Hamel Husain (00:25:33):
No problem. And we'll actually show the LLM automation in this example, because we're going to take this example, we're going to go all the way through.

Lenny Rachitsky (00:25:40):
Amazing.

Hamel Husain (00:25:41):
And so benevolent dictator is just a catchy term for the fact that when you're doing this open coding, a lot of teams get bogged down in having a committee do this. And for a lot of situations, that's wholly unnecessary. People get really uncomfortable with, "Okay, we want everybody on board. We want everybody involved," so on and so forth. You need to cut through the noise. And a lot of organizations, if you look really deeply, especially small, medium-sized companies, you can appoint one person whose tastes that you trust. And you can do this with a small number of people and often one person, and it's really important to make this tractable. You don't want to make this process so expensive that you can't do it. You're going to lose out.

(00:26:36):
So that's the idea behind benevolent dictator, is, "Hey, you need to simplify this across as many dimensions as you can." Another thing that we'll talk about later is when it goes to building an LLM as a judge, you need a binary score. You don't want to think about, "Is this like a 1, 2, 3, 4, 5?" Like, assign a score to it. You can't. That's going to slow it down.

Lenny Rachitsky (00:26:59):
Just to make sure this benevolent dictator point is really clear, basically, this is the person that-

Lenny Rachitsky (00:27:00):
Make sure this benevolent dictator point is really clear. Basically, this is the person that does this note-taking, and ideally they're the expert on the stuff. So if it's law stuff, maybe there's a legal person that owns this, it could be a product manager. Give us advice on who this person should be?

Hamel Husain (00:27:16):
Yeah. It should be the person with domain expertise. So in this case, it would be the person who understands the business of leasing, apartment leasing, and has context to understand if this makes sense. It's always a domain expert, like you said. Okay. For legal, it would be a law person. For mental health, it would be the mental health expert, whether that's a psychiatrist or someone else.

Lenny Rachitsky (00:27:41):
Cool.

Hamel Husain (00:27:42):
Though oftentimes, it is the product manager.

Lenny Rachitsky (00:27:44):
Cool. So the advice here is pick that person. It may not feel so super fair that they're the one in charge and they're the dictator, but they're benevolent. It's going to be okay.

Hamel Husain (00:27:52):
Yeah. It's going to be okay. It's not perfection. You're just trying to make progress and get signal quickly so you have an idea of what to work on because it can become infinitely expensive if you're not careful.

Lenny Rachitsky (00:28:07):
Yeah. Okay, cool. Let's go back to your examples.

Hamel Husain (00:28:09):
Yeah, no problem. So this is another example where we have someone saying, "Okay. Do you have any specials?" And the assistant or the AI responds, "Hey, we have a 5% military discount." User responds, and it switches the subject, "Can you tell me how many floors there are? Do you have any one-bedrooms available or one-bedrooms on the first floor?" And the AI responds, "Yeah, okay. We have several one-bedroom apartments available." And then the user wants to confirm, "Any of those on the first floor and how much are the one-bedrooms?" And then also, it's a current resident, so they're also asking, "I need a maintenance request."

(00:28:56):
You could see the messiness of the real world in here, and the assistant just calls a tool that says transfer call, but it doesn't say anything. It just abruptly does transfer call, so it's pretty jank, I would say. It's just not-

Lenny Rachitsky (00:29:13):
Another jank.

Hamel Husain (00:29:14):
Another kind of jank, a different kind of jank. So when you write the open note, you don't want to say jank, because what we want to do is we want to understand, and when we look at the notes later on, we want to understand what happened.

(00:29:24):
So you just want to say, "Did not confirm call transfer with user." And it doesn't have to be perfect. You just have to have a general idea of what's going on.

Lenny Rachitsky (00:29:39):
Cool.

Hamel Husain (00:29:39):
So, okay. So let's say we do, and Shreya and I, we recommend doing at least 100 of these. The question is always, "How many of this do you do?" And so there's not a magic number. We say 100 just because we know that as soon as you start doing this, once you do 20 of these, you will automatically find it so useful that you will continue doing it.

(00:30:07):
So we just say 100 to mentally unblock you, so it's not intimidating. It's like, "Don't worry, you're only going to do 100." And there is a term for that, so the right answer is, "Keep looking at traces until you feel like you're not learning anything new." Maybe Shreya should talk about-

Shreya Shankar (00:30:30):
Yeah. So there's actually a term-

Hamel Husain (00:30:31):
... that.

Shreya Shankar (00:30:31):
... in data analysis and qualitative analysis called theoretical saturation. So what this means is when you do all of these processes of looking at your data, when do you stop? It's when you are theoretically saturating or you're not uncovering any new types of notes, new types of concepts, or nothing that will materially change the next part of your process.

(00:30:57):
And this kind of takes a little bit of intuition to develop, so typically, people don't really know when they've reached theoretical saturation yet. That's totally fine. When you do two or three examples or rounds of this, you will develop the intuition. A lot of people realize, "Oh, okay. I only need to do 40, I only need to do 60. Actually, I only need to do 15." I don't know. Depends on the application and depends on how savvy you are with error analysis for sure.

Lenny Rachitsky (00:31:25):
And your point about you're going to want to do a bunch. I imagine it's because you're just like, "Oh, I'm discovering all these problems. I got to see what else is going on here."

Shreya Shankar (00:31:33):
Exactly.

Lenny Rachitsky (00:31:34):
Is that right?

Shreya Shankar (00:31:34):
And promise, at some point, you're not going to discover new types of problems.

Lenny Rachitsky (00:31:39):
Yeah. Awesome. So let's say you did 100 of these, what's the next step?

Hamel Husain (00:31:42):
Yeah. Okay. So you did 100 of these. Now you have all these notes. So this is where you can start using AI to help you. So the part where you looked at this data is important, like we discussed. You don't want to automate this part too much.

Lenny Rachitsky (00:31:59):
Humans will still have jobs. This is the takeaway here. That's great.

Hamel Husain (00:32:02):
Yes.

Lenny Rachitsky (00:32:02):
Just reviewing traces. At least there's one job left for now. Great.

Hamel Husain (00:32:06):
So, yeah. Exactly. And so, okay. You have all these notes. Now, to turn this into something useful, you can do basic counting. So basic counting is the most powerful analytical technique in data science because it's so simple and it's kind of undervalued in many cases, and so it's very approachable for people.

(00:32:33):
And so the first thing you want to do is take these notes, and you can categorize them with an LLM, and so there's a lot of different ways to do that. Right before this podcast, I took three different coding agents or AI tools in how to categorize these notes. So one is, "Okay, I uploaded into a cloud project, I uploaded a CSV of these notes, and I just exported them directly from this interface." There's a lot of different ways to do this, but I'm showing you the simple, stupid way, the most basic way of doing things.

(00:33:13):
And so I dumped the CSV in here and I said, "Please analyze the following CSV file." And I told it there's a metadata field that has a note in it, but what I said is I used the word open codes, and I said, "Hey, I have different open codes," and that's a term of art. LLMs know what open codes are and they know what axial codes are because it is a concept that's been around for a really long time, so those words help me shortcut what I'm trying to do.

Lenny Rachitsky (00:33:46):
That's awesome. And the end of the prompt is telling it to create axial codes?

Hamel Husain (00:33:50):
Yes. Creating axial codes, so what it does is-

Shreya Shankar (00:33:54):
So maybe it's worth talking about what are axial codes or what's the point here? You have a mess of open codes, and you don't have 100 distinct problems. Actually, many of them are repeats, but because you phrased them differently, and that you shouldn't have tried to create your taxonomy of failures as you're open coding. You just want to get down what's wrong and then organize, "Okay, what's the most common failure mode?"

(00:34:19):
So the purpose, axial code basically is just a failure mode. It's the label or category. And what our goal is, is to get to this clusters of failure modes and figure out what is the most prevalent, so then you can go and run and attack that problem.

Lenny Rachitsky (00:34:36):
That is really helpful. Basically, just synthesizing all these-

Shreya Shankar (00:34:36):
Absolutely.

Lenny Rachitsky (00:34:39):
... into categories and themes. Super cool. And we'll include this prompt in our show notes for folks so they don't have to sit there and screenshot it and try to type it up themselves.

Hamel Husain (00:34:49):
Yeah. Great idea. And so Claude went ahead and analyzed the CSV file and decided how to parse it, blah, blah, blah. We don't need to worry about all that stuff, but it came up with a bunch of axial codes. Basically, axial codes are categories, like Shreya said. So one is, okay, capability limitations, misrepresentation, process and protocol violations, human handoff issues, communication, quality. It created these categories.

(00:35:18):
Now, do I like all the categories? Not really. I like some of them. It's a good first stab at it. I would probably rename it a little bit because some of them are a bit too generic. Like what is capability limitation? That's a little bit too broad. It's not actionable. I want to get a little bit more actionable with it so that if I do decide it's a problem, I know what to do with it, but we'll discuss that in a little bit. So you can do this with anything, and this is the dumbest way to do it, but dumb sometimes is a good way to get started, so-

Lenny Rachitsky (00:35:49):
And this is what LLMS are really good at, taking a bunch of information and synthesizing it.

Shreya Shankar (00:35:53):
Absolutely. Synthesizing for us to make sense of, right? Note that it's not automatically proposing fixes or anything, that's our job, but now, we can wade through this mess of open codes a lot easier.

(00:36:05):
Another thing that's interesting here in this prompt to generate the axial codes is you can be very detailed if you want, right? You can say, "I want each axial code to actually be some actionable failure mode," and maybe the LLM will understand that and propose it, or, "I want you to group these open codes by what stage of the user story that it's in." So this is where you can be creative or do what's best for you as a product manager or engineer working on this, and that will help you do the improvement later.

Lenny Rachitsky (00:36:40):
So there's no definitive prompt of, "Here's the one way to do it"?

Shreya Shankar (00:36:42):
Absolutely.

Lenny Rachitsky (00:36:43):
You're saying you can iterate, see what works for you?

Shreya Shankar (00:36:46):
Absolutely.

Lenny Rachitsky (00:36:46):
It's interesting the tools don't do this, or do they try and they just don't do a great job?

Shreya Shankar (00:36:50):
No, I don't think they do it. We've been screaming from the rooftops, "Please, please-"

Lenny Rachitsky (00:36:54):
Oh, wow.

Shreya Shankar (00:36:55):
"... do this." I do think it's a little bit hard, right? Part of this whole experience with the eval scores Hamel and I are teaching are a lot of people don't actually know this, so maybe it's that people don't know this and they don't know how to build tools for it. And hopefully, we can demystify some of this magic.

Lenny Rachitsky (00:37:13):
And just to double-click on this point, this is not a thing everyone does or knows. This is something you two developed based on your experience doing data analysis and data science at other companies?

Shreya Shankar (00:37:23):
Well, I want to caveat that we didn't invent error analysis. We don't actually want to invent things. That's bad signal. If somebody is coming to you with a way to do something that's entirely new and not grounded in hundreds of years of theory and literature, then you should, I don't know, be a little bit wary of that.

(00:37:42):
But what we tried to do was distill, "Okay, what are the new tools and techniques that you need to make sense of the LLM error-out analysis?" And then we created a curriculum or structured way of doing this. So this is all very tailored to LLMs, but the terms open coding, axial coding, are grounded in social science.

Lenny Rachitsky (00:38:04):
Amazing. Okay. What's funny about you guys doing this is I just want to go do this somewhere. I don't have any AI product to do this on, but it's just like, "Oh, this would be so fun." Just sit there and find all the problems I'm running into and categorize them and then try to fix them.

Shreya Shankar (00:38:18):
I love that.

Lenny Rachitsky (00:38:19):
Hamel pulled up a video. What do you got going on here?

Hamel Husain (00:38:22):
Yeah. So I pulled up a video just to drive home Shreya's point. We are not inventing anything, so what you see on the screen here is Andrew Ng, one of the famous machine learning researchers in the world who have taught a lot of people, frankly, machine learning. And you can see this is an eight-year-old video, and he's talking about error analysis.

(00:38:45):
And so this is a technique that's been used to analyze stochastic systems for ages, and it's something that it was just using the same machine learning ideas and principles, just bringing them into here, because again, these are stochastic systems.

Lenny Rachitsky (00:39:01):
Awesome. Well, one thing, we're working on getting Andrew on the podcast, we're chatting, so that will-

Shreya Shankar (00:39:01):
Nice.

Lenny Rachitsky (00:39:05):
... be really fun. Two, I love that my podcast episode just came out today is in your feed there, and it's standing out really well in that feed, so I'm really happy about that [inaudible 00:39:13].

Hamel Husain (00:39:13):
Very nice. Yeah. The recommendation algorithm is quite good.

Lenny Rachitsky (00:39:15):
Yes. Here we go. Hope you click on that. Don't screw my algorithm. Okay, cool. So we've done some synthesis. I know we're not going to go through the entire step. This is you have a whole course that takes many days to learn this whole process. What else do you want to share about how to go about this process?

Hamel Husain (00:39:31):
Okay. So you can do this through anything, and the same thing works just fine in ChatGPT, the same exact prompt. You can see it made axial codes. I really like using Julius AI. It's one of my favorite tools.

(00:39:45):
Julius is kind of this third-party tool that uses notebooks. I personally like Jupiter notebooks a lot, and so it's more of a data science thing, but a lot of product managers that are kind of learning notebooks nowadays, and it's kind of cool. It's like a fun playground where you can write code and look at data. But we don't have to go deeply into that. Just wanted to mention, you can use a lot. AI is really good at this.

(00:40:10):
So let's go to the fun part. Here we go. So now we have these axial codes. So the first thing I like to do, I have these open codes, and I have the axial codes, let's say, that we assigned from the cloud project or the ChatGPT. And so what I do is I collect them first and I take a look, like, "Does these axial codes make sense?" And I look at the correspondence between the different axial codes and the open codes, and I go through an exercise and I say, "Hmm. Do I like these codes? Can I make them better? Can I refine them? Can I make them more specific?" Instead of being generic, I make them very specific and actionable.

(00:40:59):
So you see the ones that I came up with here are tour scheduling, rescheduling issues, human handoff or transfer issue, formatting error with an output, conversational flow. We saw the conversational flow issue with the text messages. Making follow-up promises not kept.

(00:41:18):
And so basically, what I can do, what you can do now is you have these axial codes, and so I just collect them into a list, so this is an Excel formula. Just collect these codes into a list, and now we have a comma-separated list of these codes. And then what you can simply do is you could take your notes that you have, those open codes, and you can tell an AI, and this is using Gemini and AI just for simplicity, this is, again, we're trying to keep it simple, categorize the following note into one of the following categories as always.

Lenny Rachitsky (00:41:56):
For folks watching, I like all these different prompts and formulas you're sharing. This is the Google Sheets AI prompt.

Shreya Shankar (00:42:04):
Huge fan.

Hamel Husain (00:42:07):
And so basically, what you could do is you can categorize your traces into one of the buckets, and that's what we have here. We have categorized all those problems that we encountered into one of these things.

Shreya Shankar (00:42:22):
And this is automatic, which is very exciting. I mean, the AI is doing it. So this also drives home the point that your open codes have to be detailed, right? You can't just say janky because if the AI is reading janky, it's not going to be able to categorize it. Even a human wouldn't, right? It would have to go and remember why you said janky, so it's important to be somewhat detailed in your open code.

Lenny Rachitsky (00:42:45):
Okay. So avoid the word janky. It's a good rule of thumb.

Shreya Shankar (00:42:48):
Yeah. Or have it with 10 other words.

Lenny Rachitsky (00:42:48):
Oh, okay. What is-

Hamel Husain (00:42:48):
Yeah. I was being funny.

Lenny Rachitsky (00:42:52):
Yeah, okay. What are some of those other words that people often use that you think are not good?

Shreya Shankar (00:42:57):
I don't think it's specific words. I think it's just people are not detailed enough in the open code, so it's hard to do the categorization.

Lenny Rachitsky (00:43:04):
Great. And by the way, the reason you have to map them back is because, say, Claude or ChatGPT gave you suggestions and you change them and iterated on them, so you can't just go back and say, "Cool, whatever," in each bucket?

Hamel Husain (00:43:16):
Yeah, yeah.

Lenny Rachitsky (00:43:17):
Great.

Hamel Husain (00:43:17):
That's a really good question, actually. It's good to iterate and think about it a little bit like, "Do I like these open codes? Do these actually make sense to me?" Just like anything that AI does, it's really good to kind of put yourself in the middle just a little bit.

Lenny Rachitsky (00:43:32):
It's in the loop. Still space for us. Great.

Shreya Shankar (00:43:34):
One of the things that I like to do with this step if I'm trying to use AI to do this labeling, is also have a new category called none of the above. So an AI can actually say, "None of the above," in the axial code, and that informs me, "Okay, my axial codes are not complete. Let's go look at those open codes, let's figure out what some new categories are or figure out how to reword my other axial codes."

Lenny Rachitsky (00:44:00):
Awesome. And what's cool about this is you don't need to do this many, many times.

Shreya Shankar (00:44:03):
No.

Lenny Rachitsky (00:44:04):
For most products, you do this process once, and then you build on it, I imagine, and you just tweak it over time?

Shreya Shankar (00:44:09):
Absolutely. And it gets so fast. People do this once a week, and you can do all of this in 30 minutes, and suddenly your product is so much better than if you were never aware of any of these problems.

Lenny Rachitsky (00:44:23):
Yeah. It's absurd to feel like you wouldn't know this is happening. Watching this happening, I'm like, "How could you not do this to your product?"

Shreya Shankar (00:44:31):
A lot of people have no idea.

Lenny Rachitsky (00:44:31):
Most people. Yeah. We'll talk about that. There's a whole debate around this stuff that we want to talk about. Okay, cool. So you have the sheet. What comes next?

Hamel Husain (00:44:40):
Okay. So here's sort of the big unveil. This is the magic moment right now. So we have all these codes that we applied, the ones that we like on our traces. Now, you can do the ta-da, you can count them.

(00:44:56):
So here's a pivot table, and we just can do pivot table on those, and we can count how many times those different things occurred. So what do we find? Find on these traces that we categorized? We found 17 conversational flow issues. And I really like pivot tables because you can do cool things. You can double-click on these. You can say, "Oh, okay. Let me take a look at those," but that's going into an aside about pivot tables, how cool they are.

(00:45:25):
But now, we have just a nice, rough cut of what are our problems? And now, we have gone from chaos to some kind of thinking around, "Oh, you know what? These are my biggest problems. I need to fix conversational issues, maybe these human handoff issues." It's not necessarily the count is the most important thing. It might be something that's just really bad and you want to fix that, but okay. Now, you have some way of looking at your problem, and now you can think about whether you need evals for some of these.

(00:46:07):
So there might be some of these things that might be just dumb engineering errors that you don't need to write an eval for because it's very obvious on how to fix them. Maybe the formatting error with output, maybe you just forgot to tell the LLM how you want it to be formatted, and you didn't even say that in the prompt. So just go ahead and fix the prompt maybe, and we can decide, "Okay, do you want to write an eval for that?" You might still want to write an eval for that because you might be able to test that with just code. You could just test the string, does it have the right formatting potentially? Without running an LLM.

(00:46:53):
So there's a cost-benefit trade-off to evals. You don't want to get carried away with it, but you want to usually ground yourself in your actual errors. You don't want to skip this step. And so the reason I'm kind of spending so much time on this is this is where people get lost. They go straight into evals like, "Let me just write some tests," and that is where things go off the rails.

(00:47:24):
Okay. So let's say we want to tackle one of these things. So for example, let's say we want to tackle this human handoff issue, and we're like, "Hmm, I'm not really sure how to fix this. That's a kind of subjective sort of judgment call on should we be handing off to a human? And I don't know immediately how to fix it. It's not super obvious per se. Yeah. I can change my prompt, but I'm not sure. I'm not 100% sure."

(00:47:56):
Well, that might be sort of an interesting thing for an LLM as a judge, for example. So there's different kinds of evals. One is code-based, which you should try to do if you can because they're cheaper. LLM as a judge is something, it's like a meta eval. You have to eval that eval to make sure the LLM that's judging is doing the right thing, which we'll talk about in a second.

(00:48:25):
So, okay. LLM as a judge, that's one thing. Okay. How do you build an LLM as a judge?

Lenny Rachitsky (00:48:31):
Before we get into that actually, just to make sure people know exactly what you're describing there, these two types of evals. One is you said it's code-based and one is LLM as judge. Maybe Shreya, just help us understand what code-based eval even is? It's essentially a unit test? Is that a simple way to think about it?

Shreya Shankar (00:48:46):
Yeah. Maybe eval is not the right term here, but think automated evaluator. So when we find these failure modes, one of the things we want is, "Okay. Can we now go check the prevalence of that failure mode in an automated way without me manually labeling and doing all the coding and the grouping, and I want to run it on thousands and thousands of traces, I want to run it every week." That is, okay. You should probably build an automated evaluator to check for that failure mode.

(00:49:12):
Now, when we're saying code-based versus LLM-based, we're saying, "Okay. So maybe I could write a Python function or a piece of code to check whether that failure mode is present in a trace or not." And that's possible to do for certain things like checking the output is JSON, or checking that it's markdown, or checking that it's short. These are all things you can capture in code or you could approximately capture in code.

(00:49:38):
When we're talking about LLM judge here, we're saying that this is a complex failure mode and we don't know how to evaluate in an automated way. So maybe we will try to use an LLM to evaluate this very, very narrow, specific failure mode of handoffs.

Lenny Rachitsky (00:49:56):
So just to try to mirror back what you're describing, you want to test what your, say, agent or AI product is doing. You ask it a question, it gets back with something.

(00:50:05):
One way to test if it's giving you the right answer is if it's consistently doing the same thing, that you could write a code to tell you this is true or false. For example, will it ever say there's a virtual tour? So you could ask it.

Shreya Shankar (00:50:18):
Yes.

Lenny Rachitsky (00:50:18):
"Do you provide virtual tours?" It says yes or no, and then you could write code to tell you if it's correct based on that specific answer.

(00:50:27):
But if you're asking about something more complicated and it's not binary, in one world, you need a human to tell you this is correct. The solution to avoid humans having to review all this every time automatically is LLMs replacing human judgment, and you'd call it an LLM as judge. The LLM as being the judge if this is correct or not.

Shreya Shankar (00:50:47):
Absolutely. You nailed it.

Lenny Rachitsky (00:50:48):
Great.

Shreya Shankar (00:50:49):
So people always think, "Oh, this is at least as hard as my problem of creating the original agent." And it's not, because you're asking the judge to do one thing, evaluate one failure mode, so the scope of the problem is very small and the output of this LLM judge is pass or fail. So it is a very, very tightly scoped thing that LLM judges are very capable of doing very reliably.

Lenny Rachitsky (00:51:18):
And the goal here is just to have a suite of tests that run before you ship to production that tell you things are going the way you want them to? The way your agent is interacting is correct?

Shreya Shankar (00:51:28):
The beautiful thing about LLM judges, you can use them in unit tests or CI, sure, but you could also use it online for monitoring, right? I can sample 1000 traces every day, run my LLM judge, real production traces, and see what the failure rate is there. This is not a unit test, but still now we get an extremely specific measure of application quality.

Lenny Rachitsky (00:51:53):
Cool. That's a really great point because a lot of people just see evals for being this not-real-life thing. It's a thing that you test before it's actually in the real world. And what's actually happening in the real world, you're saying you should actually do exactly that?

Shreya Shankar (00:52:04):
Yeah.

Lenny Rachitsky (00:52:04):
Test your real thing running in production? And it's a daily, hourly sort of thing you could be running?

Shreya Shankar (00:52:09):
Totally.

Lenny Rachitsky (00:52:10):
Awesome. Okay. Hamel's got an example of an actual LLM as a judge eval here, so let's take a look.

Hamel Husain (00:52:16):
I love how Shreya really teed it up for me, so thank you so much. So what we have is a LLM as a judge prompt for this one specific failure. Like Shreya said, you would want to do one specific failure and you want to make it binary because we want to simplify things. We don't want, "Hey, score this on a rating of one to five. How good is it?" That's just in most cases, that's a weasel way of not making a decision. Like, "No, you need to make a decision. Is this good enough or not? Yes or no?"

(00:52:50):
It can be painful to think about what that is, but you should absolutely do it. Otherwise, this thing becomes very untractable, and then when you report these metrics, no one knows what 3.2 versus 3.7 means, so.

Shreya Shankar (00:53:03):
Yeah. We see this all the time also, and even with expert-curated content on the internet where it's like, "Oh, here's your LLM judge evaluator prompt. Here's a one-to-seven scale."

(00:53:15):
And I always text Hamel like, "Oh, no. Now, we have to fight the misinformation again because we know somebody is going to try it out and then come back to us and say, 'Oh, I have 4.2 average,'" and we're going to be like, "Okay."

Lenny Rachitsky (00:53:31):
It's wild how much drama there is in the evals space. We're going to get to that. Oh, man.

(00:53:37):
This episode is brought to you by Mercury. I've been banking with Mercury for years, and honestly, I can't imagine banking any other way at this point. I switched from Chase, and holy moly, what a difference. Sending wires, tracking spend, giving people on my team access to move money around, so freaking easy. Where most traditional banking websites and apps are clunky and hard to use, Mercury is meticulously designed to be an intuitive and simple experience.

Lenny Rachitsky (00:54:00):
Meticulously designed to be an intuitive and simple experience, and Mercury brings all the ways that you use money into a single product, including credit cards, invoicing, bill pay, reimbursements for your teammates and capital. Whether you're a funded tech startup looking for ways to pay contractors and earn yield on your idle cash, or an agency that needs to invoice customers and keep them current, or an e-commerce brand that needs to stay on top of cash flow and access capital, Mercury can be tailored to help your business perform at its highest level. See what over 200,000 entrepreneurs love about Mercury. Visit mercury.com to apply online in 10 minutes. Mercury is a fintech, not a bank. Banking services provided through Mercury's FDIC insured partner banks. For more details, check out the show notes.

Hamel Husain (00:54:45):
Okay, so this is your judge prompt. There's no one way to do it. It's okay to use an LLM to help you create it, but again, put yourself in the loop. Don't just blindly accept what the LLM does, and in all of these cases, that's what we did. With the axial codes, we iterated on this. You can use an LLM to help you create this prompt, but make sure you read it, make sure you edit it, whatever. This is not necessarily the perfect prompt. This is just the stupid, keeping it very simple just to show you the idea. It's like, "Okay, for this handoff failure," I said, "Okay, I want you to output true or false," it's a binary judge. That's what we recommend. Then I just go through and say, "Okay, when should you be doing a handoff?" And I just list them out.

(00:55:33):
Okay, explicit human requests ignored or looped, some policy-mandated transfer, sensitive resident issues, tool data, unavailability, same day walk-in or tour requests. You need to talk to a human for that, so on and so forth. The idea is, now that I know that this is a failure from my data, I'm interested in iterating on it, because I know this is actually happening all the time. Like Shreya said, it would be nice to have a way not only to evaluate this on the data I have, but also on production data, just to get a sense of, what scales is this happening? Let me find more traces, let me have a way to iterate on this. We can take this prompt and I'm going to use the spreadsheet again. The first step is, okay, when I'm doing this judge... I wrote the prompt.

(00:56:28):
Now, a lot of people stop there and they say, "Okay, I have my judge prompt. We're done. Good, let's just ship it," and the prompt says... If the judge says it's wrong, it's wrong. They just accept it as the gospel, be like, "Okay, the LLM says it's wrong, it must be wrong. Don't do that, because that's the fastest way that you can have evals that don't match what's going on, and when people lose trust in your evals, they lose trust in you. It's really important that you don't do that, so before you release your LLM as a judge, you want to make sure it's aligned to the human. How do you do that? You have those axial codes and you want to measure your judge against the axial code, and say like, "Hey, does it agree with me? My own judge, does it agree with me?" Just measure it.

(00:57:18):
What we have here is, okay, I say, "Assess this LLM trace." Again, I'm using just spreadsheets here, "Assess this LM trace according to these rules," and the rules are just the prompt that I just showed you. I ask it, "Okay, is there a handoff error, true or false?" Then this column, let me just zoom in a bit. Column H, I have, "Okay, did this error occur?" Column G is whether I thought the error occurred or not. You can see-

Lenny Rachitsky (00:57:53):
You're going through manually, you do that.

Hamel Husain (00:57:55):
Yeah, yeah, which we already did. We already went through it manually. It's not like we have to do it again, because we have that cheat code from the axial coding, we already did it. You might have to go through it again if you need more data, and there's a lot of details to this on how to do this correctly. You want to split your data and do all these things, so that you're not cheating, but I just want to show you the concept. Basically, what you can do is measure the agreement. Now, one thing you should know, as a product manager, is a lot of people go straight to this agreement. They say, "Okay, my judge agrees with the human some percentage of the time."

(00:58:41):
Now that sounds appealing, but it's a very dangerous metric to use, because a lot of times, errors, they only happen on the long tail and they don't happen as frequently, so if you only have the error 10% of the time, then you can easily have 90% agreement by just having a judge say it passes all the time. Does that make sense? 90% agreement look good on paper, but it might be misleading.

Lenny Rachitsky (00:59:15):
It's rare, it's a rare error. Yeah.

Hamel Husain (00:59:18):
As a product manager or someone, even if you're not doing this calculation yourself, if someone ever reports to you agreement, you should immediately ask, "Okay, tell me more." You need to look into it. They give you more intuition, here is like a matrix of this specific judge in the Google sheet, and this is, again, a pivot table, just keeping it dumb and simple. "Okay, on the rows I have, what did the human think? What did I think? Did it have an error, true or false? Then did my judge have an error, true or false?"

Shreya Shankar (00:59:56):
The intuition here is exactly what Hamel said, where you need to look at each type of error. When the human said false, but the judge said true, or vice versa, so those non-green diagonals here, and if they're too large, then go iterate on your prompt, make it more clear to the LLM judge, so that you can reduce that misalignment. You want to get to a point where most... You're going to have some misalignment, that's okay. We talk about in our course, also how to code correct that misalignment, but in this stage, if you're a product manager and the person who's building the LLM judge eval has not done this, they're saying like, "It agrees 75% of the time, we're good." They don't have this matrix and they haven't iterated to make sure that these two types of errors have gone down to zero, then it's a bad smell. Go and ask them to go fix that.

Lenny Rachitsky (01:00:52):
Awesome. That's a really good tip, what to look for when someone's doing this wrong.

Shreya Shankar (01:00:56):
Yeah.

Lenny Rachitsky (01:00:56):
Actually, can you take us back to the LLM as judge prompt? I just want to highlight something really interesting here. I've had some guests on the podcast recently who've been saying, "Evals are the new PRDs," and if you look at this, this is exactly what this is. Product managers, product teams, here's what the product should be, here's all the requirements, here's the how it should work. They built a thing and then they test it. Manually, often. What's cool about this is this is exactly that same thing, and it's running constantly. It's telling you, "Here's how this agent should respond," and it's very specific ways. "If it's this, this, this, do that. If it's this, this, that, do that." It's exactly what I've been hearing again and again, you could see right here. This is the purest sense of what a product requirements document should be, is this eval judge that's telling you exactly what it should be, and it's automatic and running constantly.

Shreya Shankar (01:01:45):
Yeah, absolutely. It's derived from our own data, so of course, it's a product manager's expectations. What I find that a lot of people miss is they just put in what their expectations are before looking at their data, but as we look at our data, we uncover more expectations that we couldn't have dreamed up in the first place, and that ends up going into this prompt.

Lenny Rachitsky (01:02:05):
That is interesting. Your advice is not skip straight to evals and LLM as judge prompts before you build the product, still write traditional one-pagers PRDs to tell your team what we're doing, why we're doing it, what success looks like. But then at the end, you could probably pull from that and even improve that original PRD if you're evolving the product using this process.

Shreya Shankar (01:02:28):
I would go even further to say you're going to improve... It's going to change. You're never going to know what the failure modes are going to be upfront, and you're always going to uncover new vibes that you think that your product should have. You don't really know what you want until you see it with these LLMs, so you got to be flexible, have to look at your data, have to... PRDs are a great abstraction for thinking about this. It's not the end all, be all. It's going to change.

Lenny Rachitsky (01:02:58):
I love that, and Hamel's pulling up some cool research report. What's this about?

Hamel Husain (01:03:04):
This is one of the coolest research reports you can possibly read if you want to know about evals. It was authored by someone named Shreya Shankar.

Shreya Shankar (01:03:13):
Oh, my God.

Hamel Husain (01:03:15):
And her collaborators. It's called "Who Validates the Validated?"

Lenny Rachitsky (01:03:20):
That's the best name for a researcher.

Shreya Shankar (01:03:21):
Thank you, thank you.

Hamel Husain (01:03:24):
I should let Shreya talk about this. I think one of the most important things to pay attention in this paper are the criteria drift, and what she found.

Shreya Shankar (01:03:35):
We did this super fun study when we were doing user studies with people who were trying to write LLM judges or just validate their own LLM outputs. I think this was before evals was extremely popular, I feel like, on the internet. We did this project late 2023 was when we started it. But then the thing that really was burning in my mind as a researcher is like, "Why is this problem so hard? We've been having machine learning and AI for so long, it's not new, but suddenly, this time around, everything is really difficult." We just did this user study with a bunch of developers and we realized, "Okay, what's new here is that you can't figure out your rubrics upfront. People's opinions of good and bad change as they review more outputs, they think of failure modes only after seeing 10 outputs they would never have dreamed of in the first place," and these are experts. These are people who have built many LLM pipelines and now agents before, and you can't ever dream up everything in the first place. I think that's so key in today's world of AI development.

Lenny Rachitsky (01:04:50):
That is a really good point. That's very much reinforcing what we were just talking about and that's why I'll pull this up, is just... Okay-

Shreya Shankar (01:04:56):
The research behind it.

Lenny Rachitsky (01:04:58):
Yeah, okay, great. You still got to do product the same way, but now you have this really powerful tool that helps you make sure what you've built is correct. It's not going to replace the PRD process. Cool. How many, say, I don't know, LLM as judge prompts, do you end up with usually say... I don't know. I know, obviously, depends complexity to the product, but what's a number in your experience?

Shreya Shankar (01:05:19):
For me, between four and seven.

Lenny Rachitsky (01:05:22):
That's it.

Shreya Shankar (01:05:23):
It's not that many, because a lot of the failure modes, as Hamel said earlier, can be fixed by just fixing your prompt. You just didn't think to put it in your prompts, so now you put it in your... You shouldn't do an eval like this for everything, just the pesky ones that you've described your ideal behavior in your agent prompt, but it's still failing.

Lenny Rachitsky (01:05:43):
Got it. Say you found a problem, you fixed it. In traditional software development, you'd write a unit test to make sure it doesn't happen again. Is your insight here is, "Don't even bother writing an eval around that if it's just gone"?

Shreya Shankar (01:05:54):
I think you can if you want to, but the whole game here is about prioritizing. You have finite resources and finite time, you can't write an eval for everything, so prioritize the ones that are the more pesky areas.

Lenny Rachitsky (01:06:07):
Probably the ones that are most risky to your business if they say something like Mecha Hitler, Grok.

Shreya Shankar (01:06:07):
Yikes.

Lenny Rachitsky (01:06:15):
Cool. Okay, so that's very relieving, because this prompt was a lot of work to really think through all these details.

Shreya Shankar (01:06:21):
But it's a lot of one-time cost. Right now, forever, you can run this on your application.

Hamel Husain (01:06:30):
Okay, data analysis is super powerful, is going to drive lots of improvements very quickly to your application. We showed the most basic kind of data analysis, which is counting, which is accessible to everyone. You can get more sophisticated with the data analysis. There's lots of different ways to sample, look at data. We made it look easy in a sense, but there's a lot of skills here to do to it well. Building an intuition and a nose for how to sort through this data. For example, let's say I find conversational issues, this conversational flow issues. Maybe if I was trying to chase down this problem further, I would think about ways to find other conversational flow issues that I didn't code. I would maybe dig through the data in several ways, and there's different ways to go about this. It's very similar, if not almost exactly similar as traditional analytics techniques that you would do on any product.

Lenny Rachitsky (01:07:41):
Give us just a quick sense of what comes next and then let's talk about the debate around evals and a couple more things.

Shreya Shankar (01:07:48):
What comes next after you've built your LLM judge? Well, we find that people just try to use that everywhere they can, so they'll put the LLM judge in unit tests and they will build, "Here are some example traces where we saw that failure, because we labeled it. Now we're going to make those part of unit tests and make sure that, every time we push a change to our code, these tests are going to pass." They also use it for online monitoring. People are making dashboards on this, and I think that's incredible. I think the products that are doing this, they have a very sharp sense of how well their application is performing, and people don't talk about it, because this is their moat. People are not going to go and share all of these things, because it makes sense. If you are an email-writing assistant, and you're doing this and you're doing it well, you don't want somebody else to go and build an email-writing assistant and then get you out of business.

(01:08:41):
I really want to stress the point that it's try to use these artifacts that you're building wherever possible online, repeatedly use them to drive improvements to your product. Oftentimes, Hamel and I will tell people how to do this up to this very point, and it clicks for people and then they never come back again. Either they have, I don't know, quit their jobs, they're not doing AI development anymore, or they know what to do from here on out. I think it's the latter, but I think it's very powerful.

Lenny Rachitsky (01:09:15):
Just watching you do this really opened my eyes to what this is and how systematic the process is. I always imagine you just sit on a computer, "Okay, what are the things I need to make sure work correctly?" What you're showing us here is it's a very simple step-by-step based on real things that are happening in your product, how to catch them, identify them, prioritize them, and then catch them if they happen again and fix them.

Shreya Shankar (01:09:38):
Yeah, it's not magic. Anyone can do this, you're going to have to practice the skill, like any new skill, you have to practice, but you can do it. I think what's very empowering now is that product managers are doing this and can do this, and can really build very, very profitable products with this skill set.

Lenny Rachitsky (01:09:57):
Okay, great segue to a debate that we got pulled into that was happening on X the other day. I did not realize how much controversy and drama there is around evals. There's a lot of people with very strong opinions. How about Shreya? Give us just a sense of the two sides of the debate around the importance and value of evals, and then give us your perspective.

Shreya Shankar (01:10:19):
Yeah. All right, I'll be a little bit placating and I say I think everyone is on the same side. I think the misconception is that people have very rigid definitions of what evals is. For example, they might think that evals is just unit tests or they might think that evals is just the data analysis part and no online monitoring or no monitoring of product-specific metrics, like actually number of chats engaged in or whatnot. I think everyone has a different mindset of evals going in, and the other thing I will say is that people have been burned by evals in the past. I think people have done evals badly. One concrete example of this is they've tried to do an LLM judge, but it has not aligned with their expectations. They only uncovered this later on and then they didn't trust it anymore, and then they're like, "I'm anti evals."

(01:11:14):
I 100% empathize with that, because you should be anti Likert scale LLM judge. I absolutely agree with you, we are anti that as well. A lot of the misconception stems from two things, like people having a narrow definition of evals and then people not doing it well and then getting burned and then wanting to avoid other people making that mistake. Then, unfortunately, X or Twitter is a medium where people are misinterpreting what everybody is saying all the time, and you just get all these strong opinions of, "Don't do evals, it's bad. We tried it, it doesn't work. We're Claude Code," or whatever other famous product, "And we don't do evals." There's just so much nuance behind all of it, because a lot of these applications are standing on the shoulders of evals. Coding agents is a great example of that, Claude Code. They're standing on the shoulders of Claude base model... Not base, but the fine-tuned Claude models have been evaluated on many coding benchmarks. Can't argue against that.

Lenny Rachitsky (01:12:24):
Just to make clear exactly what you're talking about there, one of the heads, I think maybe the head engineer of Claude Code, went on a podcast and he's like, "We don't do evals, we just vibe. We just look at vibes," and vibes meaning they just use it and feel if it's right or wrong.

Shreya Shankar (01:12:37):
I think that works. There's two things to that, right? One is they're standing on the shoulders of the evals that their colleagues are doing for coding.

Lenny Rachitsky (01:12:45):
Of the Claude foundational model.

Shreya Shankar (01:12:47):
Absolutely, right? We know that they report those numbers, because we see the benchmarks, we know who's doing well on those. The other thing is they are actually probably very systematic about the error analysis to some extent. I bet you that they're monitoring who is using Claude, how many people are using Claude, how many traps are being created, how long these chats are. They're also probably monitoring in their internal team, they're dogfooding. Anytime something is off, they maybe have a cue or they send it to the person developing Claude Code, and this person is implicitly doing some form of hair error analysis that Hamel talked about. All of this is evals, right? There's no world in which they're just being like, "I made Claude Code, I'm never looking at anything," and unfortunately, when you don't think about that or talk about that, I think that the community...

(01:13:39):
Most of the community is beginners or people who don't know about evals and want to learn about it, and it sends the wrong message there. Now, I don't know what Claude Code is doing, obviously, but I would be willing to bet money that they're doing something in the form of evals.

Hamel Husain (01:13:53):
We'll also say that coding agents are fundamentally very different than other AI products, because the developer is the domain expert, so you can short circuit a lot of things, and also, the developer is using it all day long, so there's a type of dogfooding and type of domain expertise that is... You can collapse the activities, you don't need as much data, you don't need as much feedback or exploration, because you know, so your eval process should look different.

Lenny Rachitsky (01:14:31):
Because you're seeing the code, you see the code it's generating. You can tell, "This is great, this is terrible."

Hamel Husain (01:14:35):
Yeah, yeah. I think a lot of people had generalized coding agents, because coding agents are the first AI product released into the wild, and I think it's a mistake to try to generalize that at large.

Shreya Shankar (01:14:51):
The other thing is, yeah, engineers have a dogfooding personality. There are plenty of applications where people are trying to build AI in certain domains and they don't have dogfooding for doctors, for example, or not out there trying to get all the most incorrect advice from AI and be tolerant and receptive to that. It's very important to keep, I think these nuanced things in mind.

Lenny Rachitsky (01:15:16):
What I'm hearing from you, Shreya, interestingly, is that if humans on the team are doing very close data analysis, error analysis, dogfooding like crazy, and essentially, they're the human evals and you're describing that as that's within the umbrella of evals. You could do it that way if you have time and motivation to do that, or you could set these things up to be automatic.

Shreya Shankar (01:15:40):
Absolutely, it's also about the skills. People who work at Anthropic are very, very highly skilled. They've been trained in data analysis or software engineering or AI, and whatnot. You can get there, anyone can get there, of course, by learning the concepts, but most people don't have that skill right now.

Hamel Husain (01:16:02):
Dogfooding is a dangerous one, only because a lot of people will say they're dogfooding. They're like, "Yeah, we dogfooded," but are they, really? A lot of people aren't really dogfooding it at that visceral level that you would need to close that feedback loop. That's the only caveat I would add.

Lenny Rachitsky (01:16:24):
There's also this, feels like, straw man argument of evals versus A-B tests. Talk about your thoughts there, because that feels like a big part of this debate. People are having like, "Do you need evals if you have A-B tests that are testing production level metrics?"

Shreya Shankar (01:16:38):
A-B tests are, again, another form of evals ,I imagine, right? When you're doing an A-B test, you have two different experimental conditions and then you have a metric that quantifies the success of something, and you're comparing the metric. Again, an eval in our mind is systematic measurement of quality, some metric. You can't really do an A-B test without the eval to compare, so maybe we just have a different weird take on it.

Lenny Rachitsky (01:17:06):
Yeah, okay. What I'm hearing is you consider A-B tests as part of the suite of evals that you do. I think when people think A-B tests, it's like we're changing something in the product, we're going to see if this improves some metric we care about. Is that enough? Why do we need to test every little feature? If it's impacting a metric we care about as a business, we have a bunch of A-B tests that are just constantly running.

Shreya Shankar (01:17:27):
This is now a great point. I think a lot of people prematurely do A-B tests, because they've never done any error analysis in the first place. They just have hypothetically come up with their product requirements and they believe that, "We should test these things," but it turns out, when you get into the data, as Hamel showed, that the errors that you're seeing are not what you thought what the errors might be. They were these weird handoff issues or, I don't know, the text message thing was strange. I would say that, if you're going to do A-B tests and they're powered by actual error analysis as we've shown today, then that's great, go do it. But if you're just going to do them, which we find that people try to do, just want to do them based on what you hypothetically think is what is important, then I would encourage people to go and rethink that and ground your hypotheses.

Lenny Rachitsky (01:18:23):
Do you have thoughts on what Statsig is going to do at OpenAI? Is there anything there that's interesting? That was a big deal, a huge acquisition. A- B test company people are like, "A-B test, the future." Thoughts?

Hamel Husain (01:18:34):
Just to add to the previous question a little bit, why is there this debate, A-B testing versus evals? I think, fundamentally, evals is... People are trying to wrap their head around how to improve their applications and fundamentally need to do... Data science is useful in products. Looking at data, doing data analytics. There's many different suite of tools, and you don't need to invent anything new. Sure, you don't need necessarily the whole breadth of data science, and it looks slightly different, just slightly, with LLMs. Your tactics might be different, so really what it is is using analytic tools to understand your product. Now, people say the word "Evals," trying to carve out this new thing, and saying evals and then A-B testing, but if you zoom out, it's the same data science as before, and I think that's what's causing the confusion is, "Hey, we need data science thinking," and AI product is helpful to have that thinking in AI products like it is in any product is my take on that.

Lenny Rachitsky (01:19:50):
That's a really good take, I think just the word "Evals" triggers people now.

Shreya Shankar (01:19:53):
Yeah.

Lenny Rachitsky (01:19:53):
If you just call it, "We're just doing error analysis, doing data science to understand where our product breaks and just setting up tests to make sure we know-"

Shreya Shankar (01:20:00):
That's boring, sounds boring. No, no, no. We need a mysterious term, like "Evals," to really get the momentum going. Your question about Statsig, I think it's very exciting. To be honest, I don't know much about it, because I just imagine that they're this company that... There's a tool that many people use, and maybe it just so happened that OpenAI acquired them. I'm sure they've been using them in the past, I'm sure OpenAI's competitors are using Statsig as well, so maybe there is something strategic in that acquisition. I have no idea, I don't know anything there, but I think those are really the bigger questions for me than, "Is this fundamentally changing A-B testing or making evals more of a priority?" I think they've always been a priority, I think OpenAI has always been doing some form of them, and OpenAI has gone so far, historically speaking, as to go and look at all the Twitter sentiment and try to do some retrospective on that, and then tie that back to their products. Certainly, they're doing-

Shreya Shankar (01:21:00):
Then, tie that back to their products. Certainly, they're doing some amount of evals before they ship their new foundation models, but they're going so much beyond and being like, "Okay, let's find all the tweets that are complaining about it, all the Reddit threads that are complaining about it, and go try to figure out what's going on." It goes to show that evals are very, very important. No one has really figured it out yet. People are using all the available sources signal that they can to improve their products.

Hamel Husain (01:21:26):
What I'll say is I'm really hopeful that it might shift or create a focus within OpenAI, hopefully. Up until now, a lot of the big labs understandably focused on general benchmarks like MMLU score, human eval, things like that, which are very important for foundation models. Those not very related to product specific evals, like the ones we talked about today, but handoff and stuff like that, they tend not to correlate.

Shreya Shankar (01:22:01):
Yeah, they don't correlate with math problem-solving, sorry to say.

Hamel Husain (01:22:06):
Exactly. If you look at the eval products, let's say the ones up until recently that some of the big labs have, they don't have error analysis. They have a suite of generic tools, cosine similarity, hallucination score, whatever, and that doesn't work. It's a good first stab at it. It's okay. At least you're doing something, getting people, maybe it's like getting people look at data. But eventually, what we hope to see is, okay, a bit more data science thinking in this eval process. That's hopefully the tools we'll get to.

Shreya Shankar (01:22:44):
Yeah, Pamela and I should not be the only two people on the planet that are promoting a structured way of thinking about application specific evals. It's mind-boggling to me. Why are we the only two people doing this the whole world? What's wrong? I hope that we're not the only people and that more people catch on.

Lenny Rachitsky (01:23:04):
The fact that your course on Maven is the number one highest grossing course in Maven, clearly there's demand and interest, and there's more people I think on your side. Interestingly, just as an example you've been sharing on Twitter that I think is informative, everyone's been saying how cloud code doesn't care about evals. They're all about vibes, and everyone's like, and they're the best coding agent out there, so clearly, this is right. More recently, there's all this talk about Codex, OpenAI Codex being better and everyone's switching and they're so pro evals.

Shreya Shankar (01:23:33):
I know.

Lenny Rachitsky (01:23:34):
Yeah.

Shreya Shankar (01:23:38):
It gets me every time. The Internet's so inconsistent. My favorite thing was yesterday, I believe, a couple of lab mates and I were out getting dessert or something, and somebody said like, "Oh, do you like Codex or Claude better or whatever?" The other person said, "Oh, I like Claude." Then, someone else said, "But the new version of Codex is better." Then, the first person said, "Oh, but the last I checked was two days ago, so maybe my thoughts, maybe I'm not up-to-date." I was like, "Oh, my God."

Lenny Rachitsky (01:24:14):
So true, so true. This is the world we live in. Oh, my God. Okay. I want to ask about just top misconceptions people have with evals and top tips and tricks for being successful. Maybe just share one or two each of each. Let me just start with misconceptions, and maybe I'll go to the Hamel first. Just what are a couple of the most common misconceptions people have with eval still?

Hamel Husain (01:24:31):
The top one is, "Hey, I can just buy a tool, plug it in, and it'll do the eval for you. Why do I have to worry about this? We live in the age of AI. Can't the AI just eval it?" That's the most common misconception, and people want that so much that people do sell it, but it doesn't work. That's the first one.

Lenny Rachitsky (01:24:55):
Shoot, many humans are still great. I think that's great news.

Hamel Husain (01:25:00):
The second one that I see a lot is, "Hey, just not looking at the data." In my consulting, people come to me with problems all the time, and the first thing I'll say is, "Let's go look at your traces." You can see their eyes pop open and be like, "What do you mean?" I'm like, "Yeah, let's look at it right now." They're surprised that I am going to go look at individual traces, and it always 100% of the time learn a lot and figure out what the problem is. I think people just don't know how powerful looking at the data is like we showed on this podcast.

Shreya Shankar (01:25:48):
I would agree with that.

Lenny Rachitsky (01:25:50):
Those are the top two? Okay.

Shreya Shankar (01:25:51):
Yes.

Lenny Rachitsky (01:25:51):
Is there anything else or those are the ones solve those problems.

Shreya Shankar (01:25:55):
Oh, those are definitely... Then, I guess the third one I would add is, there's no one correct way to do evals. There are many incorrect ways of doing evals, but there are also many correct ways of doing it. You got to think about where you are at with your product, how much resources you have, and figure out the plan that works best for you. It'll always involve some form of error analysis as we showed today, but how you operationalize those metrics is going to change based on where you're at.

Lenny Rachitsky (01:26:28):
Amazing. Okay. What are a couple of just tips and tricks you want to leave people with as they start on their eval journey or just try to get better at something they're already doing?

Shreya Shankar (01:26:37):
Tip number one is just don't be alarmed or don't be scared of looking at your data. The process, we try to make it as structured as possible. There are inevitably questions that are going to come up. That's totally fine. You might feel like you're not doing it perfectly. That's also fine. The goal is not to do evals perfectly, it's to actionably improve your product. We guarantee you, no matter what you do, if you're doing parts of these process, you're going to find ways of actionable improvement, and then you're going to iterate on your own process from there.

(01:27:14):
The other tip that I would say is, we are very pro-AI. Use LLMs to help you organize any thoughts that you have throughout this entire process. This could be everything ranging from initial product requirements. Figure out how to organize them for yourself. Figure out how to improve on that product requirements doc based on the open codes that you've created. Don't be afraid to use AI in ways that present information better for you.

Lenny Rachitsky (01:27:44):
Sweet, so don't be scared. Use LLMs as much as you can throughout the process.

Shreya Shankar (01:27:48):
But not to replace yourself.

Lenny Rachitsky (01:27:51):
Right. Okay, great. There's still jobs. It's great. Hamel.

Hamel Husain (01:27:55):
Yeah. Let me actually share my screen, because I want to show something. To piggyback of what Shreya said is, if you heard any phrase in this podcast, you've probably heard look at your data more than anything else. It's so important that we teach that you should create your own tools to make it as easy as possible. I showed you some tools when we're going through the live example of how to annotate data. Most of the people I work with, they realize how important this is and they vibe code their own tools, or we shouldn't say vibe code. They make their own tools, and it's cheaper than ever before because you have AI that can help you.

(01:28:40):
AI is really good at creating simple web applications that can show you data, that can write to a database. It's very simple. For the Nurture Boss use case, we wanted to remove all the friction of looking at data. What you see here is just some screenshots of what the application that they created looks like. It's just, "Okay, they have the different channels, voice, email, text. They have the different threads, they hid the system prompt by default." Little quality of life improvements. Then, they actually have this axial coding part here where you can see in red the count of different errors. They automated that part in a nice way and they created this within a few hours. It's really hard to have a one size fits all thing for looking at your data. You don't have to go here immediately, but something to think about is make it as easy as possible because, again, it's the most powerful activity that you can engage in. It's the highest ROI activity you can engage in. With AI, yeah, just remove all the friction.

Lenny Rachitsky (01:29:56):
That's amazing. Again, I think that ROI piece is so important. We haven't even touched on this enough. The goal here is to make your product better, which will make your business more successful. This isn't just a little exercise to catch bugs and things like that. This is the way to make AI products better because the experience is how users interact with your AI.

Hamel Husain (01:30:16):
Absolutely. If any, we teach our students, "Hey, when you're doing these evals, if you see something that's wrong, just go fix it." The whole point is not to have evals, a beautiful eval suite, where you can point at it, edit it and say, Oh, look at my evals." No, just fix your application, make it better. If it's obvious, do it. Totally agree with you.

Lenny Rachitsky (01:30:38):
Amazing. A question I didn't ask, but this is I think something people are thinking about. How long do you spend on this? How long does it usually take to do? The first time

Shreya Shankar (01:30:45):
I can answer for myself for applications that I work with. Usually, I'll spend three to four days really working with whoever to do initial rounds of error analysis. A lot of labeling, feel like we're in a good place to create the spreadsheet that Hamel had and everyone's on-board and convinced, and even a few LLM judge evaluators. But this is one-time cost. Once I figured out how to integrate that in unit tests, or I have a script that automatically runs it on samples and I'll create a Cron Job to just do this every week. I would say it's like, I don't know, I find myself probably spending more time looking at data because I'm just data hungry like that. I'm so curious.

(01:31:23):
I'm like, I've gained so much from this process and it's put me above and beyond in any of my collaborations with folks, so I want to keep doing it, but I don't have to. I would say maybe 30 minutes a week after that.

Lenny Rachitsky (01:31:41):
It's a week essentially, a week essentially upfront, and then 30 minutes to keep improving on adding to your suite?

Shreya Shankar (01:31:47):
Yeah, it's really not that much time. I think people just get overwhelmed by how much time they spend up front and then thinking that they have to keep doing this all the time.

Lenny Rachitsky (01:31:56):
Amazing. Is there anything else that you wanted to share or leave listeners with? Anything else you wanted to double down as a point before we get to a very exciting lightning round?

Hamel Husain (01:32:06):
I would say this process is a lot of fun, actually. It's like, okay, you're looking at data. Oh, it sounds like you're annotating things. Okay. Actually, I was just looking at a client's data yesterday, the same exact process. It's a application that sends emails, recruiting emails to try to get candidates to apply for a job. We decided to start looking at traces. We jumped right into it. "Hey, let's look at your traces." We looked at a trace, the first thing I saw was this email that is worded, "Given your background, blah, blah, blah, blah, blah." I asked the person right away, and this is where putting your product hat on and just being critical, and this is where the fun part is.

(01:32:55):
I said, "You know what? I hate this email. Do you like the email, given your background?" When I receive a message given your background, comma, I just delete that. I'm like, "What is this, given your background with machine learning and blah blah?" I'm like, "This is a generic thing." I asked the person like, "Hey, can we do better than this? This sounds like generic recruiting." They're like, "Oh, yeah, maybe." Because they were proud of it, they're like, "The AI is doing the right thing, it's sending this email with the right information, with the right link, with the right name, everything." That's where the fun part is, is put your product hat on and get into, is this really good?

Lenny Rachitsky (01:33:38):
Something I want to make sure we cover before we get to a very exciting lightning round is, this is just scratching the surface of all the things you need to know to do this well. I think this is the best primer I've ever seen on how to do this well.

Shreya Shankar (01:33:51):
Nice.

Lenny Rachitsky (01:33:51):
But I think we did it. But you guys teach a course that goes much, much deeper for people that really want to get good at this and take this really seriously. Share what else you teach in the course that we didn't cover, and what else you get as a student being part of the course you teach at Maven.

Shreya Shankar (01:34:07):
Yeah, I can talk about the syllabus a little bit, and then Hamel can talk about all the perks. We go through a lifecycle of error analysis, then automated evaluators, then how to improve your application, how do you create that flywheel for yourself? We also have a few special topics that we find pretty much no one has ever heard of or taught before, which is exciting. One is, how do you build your own interfaces for error analysis? We go through actual interfaces that we've built and we also live code them on the spot for new data. We show how we use Claude code cursor, whatever we're feeling in the moment that day to build these interfaces.

(01:34:49):
We also talk about broadly cost-optimization as well. A couple of people that I've worked with, they get to a point where their evals are very good, their product is very good, but it's all very expensive because they're using state-of-the-art models. How can we replace certain uses of the most expensive GPT-5, with 5-nano, 4-mini whatnot and save a lot of money, but still maintain the same quality? We also give some tips for that. Hamel, you're on. We also have many perks.

Lenny Rachitsky (01:35:23):
Yeah. Talk about the perks.

Hamel Husain (01:35:24):
Okay, the perks. My favorite perk is there's 160 page book that's meticulously written, that we've created, that walks through the entire process in detail of how to do evals that supplement the course. You don't have to sit there and take all these notes. We've done all the hard work for you and we have documented it in detail and organize things. That is really useful. Another really interesting thing, and something that I got the idea from you, Lenny, is, okay, this is an AI course. Education shouldn't be this thing where you are only watching lectures and doing homework assignments. Students should have access to an AI that also helps them. What we have done is we've, just like there's the LennyBot that you have.

Lenny Rachitsky (01:36:19):
Dot com.

Hamel Husain (01:36:20):
Yeah, lennybot.com, we have made the same thing with the same software that you're using, and we have put everything we've ever said about evals into that. Every single lesson, every office hours, every Discord chat, any blogs, papers, anything that we've ever said publicly and within our course, we've put it in there. We've tested it with a bunch of students and they've said it's helpful. We're giving all students 10 months free unlimited access to that alongside the course.

Lenny Rachitsky (01:36:56):
Amazing. Then, you'll charge for that later down the road?

Hamel Husain (01:37:01):
I have no idea. I just take one month at a time. I don't know where we're going with that.

Lenny Rachitsky (01:37:04):
Eight months and then we'll have to figure it out. I was thinking this whole interview should have just been our bots talking to each other.

Shreya Shankar (01:37:09):
That's amazing. I would watch that, only for 10 minutes then I don't know what they're talking about.

Lenny Rachitsky (01:37:14):
Yeah, maybe 30 seconds. Do you guys train it on the voice mode, by the way? That's my favorite feature of Delphi's product. If not, you should do that.

Hamel Husain (01:37:22):
Oh, I think, I can't remember, I should look at it.

Lenny Rachitsky (01:37:26):
You definitely should. Now that we have this podcast episode, you could use this content to train it. It's 11Labs powered. It's so good. Okay, so how do they get to... I guess that's okay. They get to that once they become, enter your course.

Shreya Shankar (01:37:38):
Yeah, sign up for the course and then you'll get a bunch of emails. Everything will be clear, hopefully.

Lenny Rachitsky (01:37:43):
Amazing. Okay.

Shreya Shankar (01:37:44):
We also have a Discord of all the students who have ever taken the class. That Discord is so active. I can't go on vacation without getting notified on the plane.

Lenny Rachitsky (01:37:55):
Bittersweet, bittersweet. Incredible. Okay. With that, we've reached our very exciting lightning round. I've got five questions for you. Are you ready?

Shreya Shankar (01:38:04):
Yes. Let's go.

Lenny Rachitsky (01:38:05):
Let's do it. Okay. I'm going to bounce between you two. Share something if you want. You can pass if you want. First question, Shreya, what are two or three books that you find yourself recommending most to other people?

Shreya Shankar (01:38:17):
I like to recommend a fiction book because life is about more than evals. Recently, I read Pachinko by Min Jin Lee. A really great book. Then, I also am currently reading Apple in China, which the name of the author is slipping my mind, but this is more of an exposition, written by a journalist on how Apple did a lot of manufacturing processes in Asia over the last couple, several decades. Very eye-opening.

Lenny Rachitsky (01:38:49):
Amazing. Hamel.

Hamel Husain (01:38:52):
Yeah, I have them right here. I'm a nerd. Okay, so I'm not as cool as Shreya is. I actually have textbooks, which are my favorite. This one is a very classic one, Machine Learning by Mitchell. Now, it's theoretical, but the thing I like about it is it really drives home the fact that Occam's razor is prevalent not only in science, but also in machine learning and AI. A lot of times the simplest, and also engineering, so a lot of times the simpler approach generalizes better. That's the thing I internalize deeply from that book. I also really like this one. Another textbook. I told you I'm a nerd. This is also a very old one, and this is Norvig algorithms. I really like it because it's just human ingenuity and it's lots of clever useful things in computing.

Shreya Shankar (01:39:49):
They're down the street, him and Berkeley.

Lenny Rachitsky (01:39:54):
The people that did that research?

Shreya Shankar (01:39:57):
Yeah, textbook authors.

Lenny Rachitsky (01:39:58):
Super cool. Oh, man, nerds, I love it. Okay, next question. Favorite recent movie or TV show? I'll jump to Hamel first.

Hamel Husain (01:40:06):
Okay, so I'm a dad of two parents. I have two parents. Sorry, two kids. Yeah, I'm a dad of two kids, and I don't really get the time to watch any TV or movies, so I watch whatever my kids are watching. I've watched Frozen three times in the last week.

Lenny Rachitsky (01:40:25):
Only three? Oh, okay. In the last week. Okay.

Hamel Husain (01:40:30):
That's my life.

Lenny Rachitsky (01:40:30):
Great, Hamel. Frozen. I love it. Okay, Shreya.

Shreya Shankar (01:40:32):
Yeah, I don't have kids, so I can give all these amazing answers. Actually, so my husband and I have been watching The Wire recently. We never actually saw it growing up, so we started watching it and it's great.

Lenny Rachitsky (01:40:46):
I feel like everyone goes through that. Eventually in their life they decide, I will watch The Wire.

Shreya Shankar (01:40:51):
I know, so we are in that right now.

Lenny Rachitsky (01:40:51):
It's like a year of your life. It's great. It's such a great show. Oh, man. But it's so many episodes and everyone's an hour long.

Shreya Shankar (01:40:58):
I know. I know.

Lenny Rachitsky (01:40:58):
It's such a commitment.

Shreya Shankar (01:40:59):
We get through two or three a week, so we're very slow.

Lenny Rachitsky (01:41:03):
Worth it. Okay, next question. Do you have a favorite product you've recently discovered that you really love? We'll start with Shreya.

Shreya Shankar (01:41:10):
Yeah. I really like using Cursor, honestly. Now, Claude Code. I'll say why. I'm a researcher more so than anything else. I write papers, I write code, I build systems, everything, and I find that a tool... I'm so bullish on AI assisted coding because I have to wear a lot of hats all the time. Now, I can be more ambitious with the things that I build and write papers about, so I'm super excited about those. Cursor was my entry point into this, but I'm starting to find myself always trying to keep up with all these AI assisted coding tools.

Lenny Rachitsky (01:41:48):
Hamel?

Hamel Husain (01:41:49):
Yeah, I really like Claude Code and I like it because I feel like the UX is outstanding. There's a lot of love that went into that. It's just really impressive as a terminal application that is that nice.

Lenny Rachitsky (01:42:04):
Ironic that you two both love Claude Code when it's just built on vibes.

Shreya Shankar (01:42:09):
I think it's false. It's not just built on vibes.

Lenny Rachitsky (01:42:13):
There we go. Okay, two more questions. Hamel, do you have a favorite life motto that you find yourself using in coming back to in work or in life?

Hamel Husain (01:42:21):
Keep learning in. Think like a beginner.

Lenny Rachitsky (01:42:26):
Beautiful. Shreya?

Shreya Shankar (01:42:27):
I like that. For me, it's to always try to think about the other side's argument. I find myself sometimes just encountering arguments on the internet, like this race to eval debates and really think, "Okay, put myself in their shoes. There's probably a generous take, generous interpretation." I think we're all much stronger together than if we start picking fights. My vision for evals is not that Hamel and I become billionaires. It is that everyone can build AI products, and we're all on the same page

Lenny Rachitsky (01:42:59):
Slash everyone becomes billionaires.

Shreya Shankar (01:43:02):
Yes.

Lenny Rachitsky (01:43:04):
Amazing. Final question. When I have two guests on, I always like to ask this question and I'll start with Hamel. What's something about Shreya that you like most? What do you like most about Shreya? I'm going to ask her the same question in reverse.

Hamel Husain (01:43:18):
Yeah. Shreya is one of the wisest people that I know, especially for being so young relative to me. I feel like she's much wiser than I am, honestly, seriously. She's very grounded and has a very even perspective on things. I'm just really impressed by that all the time.

Lenny Rachitsky (01:43:18):
Shreya?

Shreya Shankar (01:43:43):
Yeah. My favorite thing about Hamel is his energy. I don't know anybody who consistently maintains momentum and energy like Hamel does. I often think that I would start carrying much less about evals, if not for Hamel. Everyone needs a Hamel in their life, for sure.

Lenny Rachitsky (01:44:06):
Well, we all have a Hamel in our life now. This was incredible. This was everything I'd hoped it'd be. I feel like this is the most interesting in-depth consumable primer on evals that I've ever seen. I'm really thankful you two made time for this. Two final questions. Where can folks find you? Where can they find the course and how can listeners be useful to you? I'll start with Shreya.

Shreya Shankar (01:44:29):
Yeah, you can reach me via email. It's on my website. If you Google my name, that is the easiest way to get to my website. You can find the course if you Google AI Evals for engineers and product managers, or just AI Evals course, you'll find it. We'll send some links hopefully after this, so it's easy. How to be helpful? Two things always for me. One is ask me questions when you have them. I'll try to get to the respond as soon as I can. The other one is tell us your successes. One of the things that keeps us going is somebody tells us what they implemented or what they did, a real case study. Hamel and I gets so excited from these and it really keeps us going, so please share.

Hamel Husain (01:45:16):
Yeah, it's pretty easy to find me. My website is Hamel.dev. I'll give you the link. You can find me on social media, LinkedIn, Twitter. The thing that's most helpful is to echo what Shreya said, we would be delighted if we are not the only people teaching evals. We would love other people teach evals. Any kind of blog posts, writing, especially that as you go through this and learn this that you want to share, we would be delighted to help re-share that or amplify that.

Lenny Rachitsky (01:45:54):
Amazing. Very generous. Thank you two, so much for being here. I really appreciate it, and you guys have a lot going on, so thank you.

Shreya Shankar (01:46:01):
Thanks, Lenny, for having us and for all the compliments.

Lenny Rachitsky (01:46:05):
My pleasure. Bye everyone. Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at Lennyspodcast.com. See you in the next episode.

---

## LinkedIns product evolution and the art of building complex systems | Hari Srinivasan (LinkedIn)
**Guest:** Hari Srinivasan  
**Published:** 2023-07-16  
**YouTube:** https://www.youtube.com/watch?v=ZUwkTs_QWqg  
**Tags:** growth, retention, acquisition, activation, metrics, user research, experimentation, analytics, subscription, hiring  

# LinkedIns product evolution and the art of building complex systems | Hari Srinivasan (LinkedIn)

## Transcript

Hari Srinivasan (00:00:00):
It was March 2020 and we were just watching COVID hit. It was just this heartbreaking moment where in the feed you were seeing all these people, by no fault of their own, starting to post that they've lost their job. We started seeing in our data is you had some areas like maybe hospitality was really getting hit, but some areas like customer service that just couldn't hire enough. You'd think the marketplace would balance pretty quickly. You'd think, okay, maybe these people will start moving to other jobs, but it wasn't happening.

(00:00:24):
A large reason behind this, people are used to looking for certain particular titles, and they didn't start realizing other people could do this job. We made a pretty big push in something we call skills-first hiring. This was the idea that we could translate people's experiences into a set of skills, and by that we could help them really start balancing the marketplace with a much different system. I think that the job market is rebalancing, but it's being done, the pathways are being done in a very different way that seems to be maybe a change that holds through these ups and downs. That'll be very interesting to see.

Lenny (00:00:57):
Welcome to Lenny's Podcast, where I interview world-class product leaders and growth experts, to learn from their hard-won experiences building and growing today's most successful products. Today, my guest is Hari Srinivasan. This episode has a hilarious story.

(00:01:11):
On Twitter, an account called The Curious PM tagged me with a request to have someone from LinkedIn come on the podcast and talk about how they operate and what they've learned about building products that serve so many different types of customers. I replied asking for any suggestions for who he thought I should specifically talk to, and he suggested Hari Srinivasan, by doing some research on LinkedIn. I reached out to Hari, told him about this tweet and he agreed. Here's the episode.

(00:01:39):
Hari's been at LinkedIn for eight-and-a-half years and he leads the Talent Solutions Product Team as VP of product, which is also LinkedIn's biggest business, and includes all of the hiring and learning products, which you'll hear about in this episode. In our chat, Hari shares what he's seeing change in the hiring market, what you can do to improve your odds of finding a job through LinkedIn, what he's learned about building and maintaining really complex systems like LinkedIn, tips for getting into product management, and some lessons from his own course on product management. Plus, we also talk about how LinkedIn has been able to become a real source of valuable content and a lot less cringe over the past couple years, which I've definitely noticed and I share in our chat.

(00:02:20):
What a fun series of events that led to this episode. Big thank you to Jatin, hopefully, I'm pronouncing your name correctly, the guy behind the Curious PM account, for making this all happen. With that, I bring you Hari Srinivasan after a short word from our sponsors.

(00:02:35):
Today's episode is brought to you by Miro, an online collaborative whiteboard that's designed specifically for teams like yours. The best way to see what Miro is all about and how it can help your team collaborate better is not to listen to me talk about it, but to go check it out for yourself. Go to miro.com/lenny. With the help of the Miro team, I created a super cool Miro board with two of my own favorite templates, my one-pager template and my managing-up template, that you can plug and play and start using immediately with your team.

(00:03:05):
I've also embedded a handful of my favorite templates that other people have published in the Miroverse. When you get to the board, you can also leave suggestions for the podcast, answer a question that I have for you, and generally just play around to get a sense of how it all works. Miro is a killer tool for brainstorming with your team, laying out your strategy, sharing user research findings, capturing ideas, giving feedback on wire frames, and generally just collaborating with your colleagues. I actually used Miro to collaborate with the Miro team on creating my own board, and it was super fun and super easy. Go check it out at miro.com/lenny. That's miro.com/lenny.

(00:03:45):
Today's episode is brought to you by Brave Search and their newest product, the Brave Search API, an independent global search index you can use to power your search or AI apps. If your work involves AI, then you know how important new data is to train your LLMs and to power your AI applications. You might be building an incredible AI product, but if you are using the same datasets as your competitors to train your models, you don't have much of an advantage.

(00:04:11):
Brave Search is the fastest-growing search engine since Bing, and it's 100% independent from the big tech companies. Its index features billions of pages of high-quality data from real humans, and it's constantly updated thanks to being the default search engine in the Brave Browser. If you're building products with search capabilities, you're probably experiencing soaring API costs or lack of viable global alternatives to Bing or Google. It's only going to become harder to afford these challenges.

(00:04:38):
The Brave Search API gives you access to its novel web-scale data with competitive features, intuitive structuring, and affordable costs. AI devs will particularly benefit from data containing thorough coverage of recent events. Lenny's Podcast listeners can get started testing the API for free at brave.com/lenny. That's brave.com/lenny.

(00:05:04):
How are you? Welcome to the podcast.

Hari Srinivasan (00:05:06):
Thanks for having me. Been a big fan for a long time.

Lenny (00:05:09):
I really appreciate that. What a fun story behind this conversation. Let me just ask you, how did you feel when I cold-DMed on LinkedIn, asking you to be on this podcast because of a random tweet?

Hari Srinivasan (00:05:20):
I felt very honored. Again, I really have followed your work for a while. It's been really amazing to see what you've built, and I'm a huge fan of different builders. Also, it was a little bit of an honor that someone ... I know we're going to get into the story in a little bit. When you work on something, oftentimes jobs and learning, it's rare I think that it's in the influencer conversation. It's not necessarily something you or other people are properly experiencing on day-to-day. Sometimes, I don't know if we get to tell some of these stories, and I really appreciate you reaching out for that.

Lenny (00:05:50):
Yeah. Absolutely. I guess let me just give a big thank you to Jatin Rajvanshi, also known as The Curious PM, who tweeted about this concept and then is like, "Hey, talk to Hari about LinkedIn." Thank you, Jatin, for making this happen. It was all thanks to you. Usually, when this happens, someone tweets a recommendation of someone, they know each other. I'm like, "Eh, I don't know. This is some promotion of some other person." But you guys don't know each other, right?

Hari Srinivasan (00:06:15):
We don't, no. I'm looking forward to meeting you. Thank you, again, for putting in the word.

Lenny (00:06:20):
Absolutely. Also, thank you to Jatin for recommending a bunch of questions that I'm going to ask you.

Hari Srinivasan (00:06:26):
That I didn't know. Maybe I should've known. That I didn't know. Thanks, again, Jatin. It's very kind of you.

Lenny (00:06:32):
Yeah. Okay. Let's roll into some stuff. I actually want to start with LinkedIn as a platform broadly. I know you don't work on all parts of LinkedIn and don't necessarily know everything that's going on there, but something I've noticed that's pretty major is, it feels like LinkedIn's really made this move from being a very cringey place to post and spend time to, it's actually now interesting.

(00:06:55):
The feed that I see on LinkedIn is interesting. Oftentimes even more interesting than Twitter, which is crazy to say. Also, it's become the biggest source of traffic for my newsletter, more so than Twitter, which I never expected. My question is, as far as you know, what is it that y'all did right in the past couple years that has allowed for this shift to happen? Because this is very rare.

Hari Srinivasan (00:07:18):
Well, first, I'm glad you're having a good experience with it. That's really, really kind to here. First of all, it's very interesting you hit on it. Everything at LinkedIn is a very connected ecosystem. One of the things that we always think about is how the whole system fits together. I'm sure we'll get into it more and more about how we build at LinkedIn, but how you make decisions based on the very complicated ecosystem is actually not very difficult because we're all here to help people connect to economic opportunity. Every time there's a discussion, something I'm really, really proud about working here is, everyone knows how that decision is going to be made. It's all about how we're connecting people to economic opportunity.

(00:07:55):
Now, it's funny. Just the other day, I was driving. I was in an Uber with the person who runs a feed. He's this guy, Kamesh, who's just phenomenal. We were just talking about this and one of the things he mentioned to me was, "If you think about what a feed is when it connects someone to opportunity, it's got to do a couple of things really, really well." We've done a ton of member surveys on this, a ton of thought behind it. The first is, as you make relationship connections across the way, that is a real way by which people get opportunity. They keep in touch with those people. They learn they might follow someone, and hopes in getting knowing them and getting that knowledge. We got to make sure that that content is getting to them.

(00:08:29):
Then, when you think outside the network, we have to make sure that the things that people really want, which they keep saying are knowledge and advice and ability to get the real perspectives they need to get there, those are the things out of network they want. We've really, really been focused on driving those two systems. How does someone connect to opportunity both through the people and through the content that they actually want? As you know, when you do a feed, there's so many decisions that go into that complex system, so many decisions. But we've been really, really trying to make sure that we don't lose sight of that and start tuning all those knobs into that direction.

Lenny (00:09:04):
If we're trying to get even more specific with what has changed, clearly there's been a focus internally. Is that true? There's just like, "Hey, let's make this feed a lot more interesting"? Or is this just a never ending and then it's actually started to work investment as far as?

Hari Srinivasan (00:09:19):
Well, there's always been a focus on connecting people to opportunity. There's always been a focus on that. I think what's happened over time is we've gotten more and more clear with what our members really want, which is this ability to feel close to those relationships and the ability to really get that knowledge that they need. As we've gotten better and clear in that understanding and we've been able to dial the knobs in the right way, I hope it's landing in the right place. I don't think it's any place near declaring victory in any part of this product.

(00:09:46):
I think one of the beauty of working with that vision of connecting people to opportunity, there is always some piece of friction. There is always something we could be doing better. I'm always hesitant to say we've ever hit that bar, and I know there's probably people who listen to you who probably maybe have not had that experience. I always encourage you to reach out and let us know ways we can do better. But I'm glad you're having an experience with it. And then to your point, I always feel that as long as we stay focused on that and each of our decisions start moving in that direction, hopefully the product will continue to deliver.

Lenny (00:10:14):
Do you know if there's any product changes that have most contributed to that feed becoming much more interesting?

Hari Srinivasan (00:10:21):
Well, there's a couple of things that I think are very special that we're working on and it's hard to say which is most, because a lot of these things obviously accumulate and compound over time. But certainly, there's a lot of machine learning and algorithms that go behind these systems. Many of them, as we start understanding that these are things that people get value by, it's about how do we make sure that we're giving people that interesting knowledge? As we've gotten crisper on what that means, I think we've been better able to build towards it.

(00:10:50):
The other one, which is new, but I'm just particularly excited about, we're starting to do a lot of things which are gen AI-assisted. You basically can come in and get some prompts and people can bury their perspective on that. I think that combination, it's very early, but it's very exciting on how we might be able to help people unlock knowledge. There's almost a billion people now on the platform, knowledge of those billion people in a way that people can find and see.

Lenny (00:11:12):
Awesome. Again, I know this isn't the area you spend all your time on, but maybe one more question along these lines.

Hari Srinivasan (00:11:18):
Yeah, please.

Lenny (00:11:19):
Yeah. Do you have any sense of the kind of content that works best on LinkedIn in terms of the algorithm you talk about? The algorithm is probably one of the bigger impact things that have changed.

Hari Srinivasan (00:11:29):
If there's anything with knowledge or advice, I think that's what a lot of people are looking for. Every time we run these surveys, every time we talk to people on what they want, those are the things that really when you connect opportunity that people seek after in our system. You're a great example of that. You're able to give knowledge and advice in an area with a lot of depth. I think that maybe that's why you're having some of the success you're seeing on the platform, which is wonderful to see.

Lenny (00:11:53):
I think I'm actually not getting as much success as I could because I don't put in the time. I usually just post a simple thing with a link and I think I could be, if I really ... I just don't have time to do this of just like, post a lot more stuff within the actual post. I think that would do better.

Hari Srinivasan (00:12:09):
That actually makes me happy. My guess is what you want to be doing is learning and creating and not spending a lot of time managing. Maybe that's actually a good thing. It's actually another wonderful thing to hear.

Lenny (00:12:20):
Yeah, absolutely. Okay. Let's move to your sweet spot, which is the talent solution product? Is that what it's called?

Hari Srinivasan (00:12:29):
Yeah. It's basically any product on LinkedIn that helps you get a job or learn a skill. We have products for recruiters and hires, jobs. We have products for job seekers. We have LinkedIn Learning and then certainly, we run a pretty large creator ecosystem for instructors who post content into LinkedIn Learning.

Lenny (00:12:47):
Is it true that this is the biggest business within LinkedIn?

Hari Srinivasan (00:12:50):
It is a very big business between LinkedIn. It's certainly hopefully something that, again, if you go back to that vision of connecting people to opportunity, it's certainly something that I like to think is very, very core to that, how people get jobs and learn skills.

Lenny (00:13:04):
The feed gets all the glory and you guys are making all the money?

Hari Srinivasan (00:13:07):
I would not say that, but again, we joke about those things. It's so hard at LinkedIn to separate one product from the other. It's really the way we run. It's the way we think about the product. It's really the way we build. Let me just give you a super concrete example of that. Certainly, if you have someone coming in and looking at the feed, one thing we might do is suggest a job recommendation based on what they're looking for in that feed. Part of what we have to do is think about how someone who's looking at something in their interest might be driving their job-seeking experience as well.

(00:13:38):
And then when they're looking for a job, it's very important that they know how they can actually get connected in that job. The relationship, the network you build are very much part of that flywheel that go into it. And then even as we start looking at this, you might be looking at a subject and then you want to go deeper on, and there's a course that comes into it as well. All of this to me is a very, very connected ecosystem on how those items work together in order to give people opportunity. We might think of it from the outset as very different things, but inside, even the way we operate and the way we think about it, it's a very, very connected ecosystem.

Lenny (00:14:15):
What are the components again of this part of the org?

Hari Srinivasan (00:14:18):
We think about it as two different marketplaces. There's a hiring marketplace, which is, how do we connect job seekers and recruiters and hiring managers? And then there's a learning marketplace, which is, how do you connect learners to instructors?

Lenny (00:14:29):
Got it. And then within hiring, are there subcomponents?

Hari Srinivasan (00:14:33):
Yeah. Again, we really think about it as a marketplace. We're generally organized around seekers and hires. There's a team that's working on a Recruiter, which is probably one of the more flagship products that LinkedIn has always been around, a team working on jobs, which is, if you ever post a job on LinkedIn, and then a team working to always help job seekers make sure they connect. And then on the other side for learners, instructors, the team working on LinkedIn Learning, which is one of the bigger enterprise learning products in the world. And then a team working to help instructors.

(00:15:02):
Many people don't know this. We actually have two large film studios. We bring in instructors. We film a lot of content. One's in Europe and one's in Santa Barbara. It was all started with the Lynda acquisition. We have a large team of content creators and teams, everyone from makeup artists to script writers, that we get to use over there.

Lenny (00:15:22):
Wow. It's just marketplaces all the way down as you talk about this. Hiring marketplace, learning marketplace, the feed itself. Probably more I'm not thinking about.

Hari Srinivasan (00:15:31):
Yeah. It's very much the one model that we sometimes use internally as well is, how do we operate as marketplaces inside an ecosystem? I think it speaks to the complexity again of the product and hopefully somehow of how we might operate it.

Lenny (00:15:46):
I think with your vantage point at being at the center of hiring, a lot is changing within the hiring marketplace in the past, I don't know, year at this point, where it used to be very candidate-oriented, where they had all the power and they salaries were crazy. Everyone's bidding and trying to get people to join their company. Now, it's completely opposite. So many people looking, companies have all the power. I'm curious what you've seen, if that's roughly it, or what you're seeing basically in the hiring market these days.

Hari Srinivasan (00:16:15):
Yeah. Well, first of all, the balance that you're talking about, it is shifting in the sense that there are more seekers in the marketplace now and there are fewer open jobs in the marketplace. Of course, that changes how many applications you get for the job and how you have to look through. I think there's a model where people think it's drifting dramatically to exactly the way it was. I actually think some of the changes that occurred during the last couple of years are actually sticking around. Let me give you a couple examples of where things I think are really changing.

(00:16:44):
The first thing that happened was, and maybe in my opinion, one of the big changes to the world that no one's really talking about it to my degree is the impact of it, but there's been a real move to skills-based hiring. For the longest time, and I'll give you actually a really concrete example, it was March 2020 and we were just watching COVID hit. It was just this heartbreaking moment where in the feed you were seeing all these people, by no fault of their own, starting to post that they've lost their job.

(00:17:09):
We started seeing in our data is you had some areas like maybe hospitality was really getting hit, but some areas like customer service that just couldn't hire enough. You'd think the marketplace would balance pretty quickly. You'd think, okay, maybe these people will start moving to other jobs, but it wasn't happening. A large reason behind this, people are used to looking for certain particular titles, and they didn't start realizing other people could do this job.

(00:17:31):
We made a pretty big push in something we call skills-first hiring. This was the idea that we could translate people's experiences into a set of skills, and by that we could help them really start balancing the marketplace with a much different system. But instead of saying, "I need to have this talent," you can say, "I need someone who can do negotiation, and I need someone who can really help me understand how to deescalate a customer situation."

(00:17:54):
You find a lot of people in hospitality have about 70% of the skills you need for customer service and of course, you could train off the rest. We started seeing the skills-first hiring really start taking off. At this point, roughly 47% of our recruiters will come in, explicitly use skills when they start looking for candidates. That's a pretty big change that we're actually seeing hold. I know it's early in some of these changes, but it's a change where I think people are still continuing to start looking at skills.

(00:18:20):
Another one was this concept of, there's a lot more people who are starting to look for jobs by values. They were saying, "Look, most job sites work by you come in and you look for a job and a title, and that's how you navigate the world." We started realizing a lot of people wanted to come in and instead of look at it like that, they may say, "Look, I really want a job. This aligned with my purpose." Or even by an interest, I may want something in AI. We started launching collections in the way to filter in these things. We're still seeing some of that usage today.

(00:18:47):
I think that the job market is rebalancing, but it's being done, the pathways are being done in a very different way that seems to be maybe a change that holds through these ups and downs. That'll be very interesting to see.

Lenny (00:18:58):
What's interesting is it's not like this would change on its own. You're the biggest jobs marketplace in the world, right?

Hari Srinivasan (00:19:08):
We have a lot of professional jobs on our platform and a lot of professional seekers.

Lenny (00:19:11):
Hopefully, mysterious. I imagine it is. I don't know. I guess Indeed might be a competitor, but okay, let's say it's one of the bigger job markets. You influenced the way jobs are sought and posted and how people find jobs; so in a sense, designing. Sounds like basically, there was an internal decision. Let's focus on the skills approach. What's cool about that is that changes the way hiring happens in the world.

Hari Srinivasan (00:19:33):
It's one of the things that I think is so interesting about building products today is, it has to clearly be something people want. If we had just said we're going to go like this, and every hire was like, "I don't want to do this," or every job seeker said, "I don't care about it," I don't think anything would click. We also have to be receptive enough to amplify that signal and allow it to work through a system so that it could actually be easy to use.

(00:19:56):
I don't think we said that, "Hey, we got to go and do this value-based thing." I think we started feeling it and hearing it from members and then as we adapted, these things start amplifying as they come through. I do think that's hopefully something that I think about a lot is, let's just make sure that we keep a pulse on what people want and we make sure that we can get that through a system at a pretty fast pace. Because then, we will hopefully continue to be a place where people want to go look for jobs and make hires.

Lenny (00:20:25):
What I was thinking about as you were just chatting is this open to work feature that LinkedIn has. I remember days before that existed and people used to just like jury-rig, "Hey, I'm hiring," or, "I'm looking for a job." There's always this sense that if you're open to work, you're not as good. Because why would you be amazing and open to work and not hired? I'm curious if you were even part of this experience. Just, what was it like to come up with that approach to how to communicate that you're open to work?

Hari Srinivasan (00:20:51):
It's been through phases and I think those phases really reflect on the perception of how it's changed. In the beginning it was, you could say you're open to work, but it was a secret signal to recruiters if you will. That certainly still exists, but now we said you could more publicly say it and maybe it'd be a feed post. And then we started launching it. Actually it was around COVID when a lot of the stigmas of unemployment changed dramatically, because everyone started understanding you're in this different situation. We started putting it the frame and that's the more iconic way I think people associate with now.

(00:21:22):
It's funny. Just this week, we tried something new and I feel like it's almost the same journey. There are many customers as you can imagine, that have LinkedIn Learning and LinkedIn Learning is typically an enterprise product. It works across your employee base. We're trying to do Open to Internal Work where you can say, "I'm actually at the point where I may want the next play internally in my role," and an internal recruiter can see you. As you can imagine, I would actually even maybe argue more stigma about being concerned about upsetting your manager. Certainly, there's different cultures and companies about this.

(00:21:52):
I have a feeling in sometimes we like to think five, 10 years out, I think it's going to go on the same journey. That's one hunch I have, that there'll also be an employment-driven way internally for people to find their next play. It'll be interesting to see how it plays out, but already you can feel a little bit of that tension right when we launched it and knowing. Let's see how this goes.

Lenny (00:22:13):
You were talking about how hiring is changing. I'm curious how PM hiring specifically is changing. A lot of people listening to this podcast are product managers. Is there anything unique you're noticing there?

Hari Srinivasan (00:22:22):
Maybe a couple stats that could be very helpful. If you're having a hard time finding a PM role, let's start with this, you're probably not alone. We publish it. You can go to Economic Graph data. This is all public. We publish this. But if you look at tech, it's down about 50% year-over-year. We look at hires over total population on LinkedIn. You can go to Economic Graphs and you can see how it compares trends industry. We don't look at the functional data as much, but the PM data seems to be trending just slightly even maybe below software engineers and data as well, which is maybe a comp for this. I know not everything is perfect industry to function cuts.

(00:22:56):
It is a difficult place, but I'll give you a couple tips because I imagine that may be helpful for a couple of the listeners. It's certainly one of the larger inbounds of things I get. The first is, in those markets, you do want to make sure that the more you can do to form relationships and say that this is what you can do, which is always helpful. Now, I know that not everyone has relationships, but you can always try to develop those at different places and across LinkedIn as well. But that's one thing I would really, really start to look for.

(00:23:24):
The second thing I would really do is we have launched the way now to come in and signal obviously that you are interested in a role. We have those open to work capabilities, but then each job has a set of skills that they're looking for under it, like we talked about in skills-first hiring. Against each skill, you can actually add different kinds of credentials. I would really encourage people to add work products if that's something that they're actually building. You can add different kinds of recommendations or other things they can associate with that skill. Those credentials against it I think are becoming much more interesting for people to say, "Oh, this is someone I'm actually looking for."

(00:23:55):
And then the third thing I would really encourage PMs to start looking through is, this is probably more personal than anything in data, but every PM job is different. If you have experience in that industry and you're able to show that you have experience in that industry or some kind of understanding of it, I think that's a way to separate. I'd really start zoning in on roles where you might see if you don't have the functional experience, the industry experience. I think that would go a long way as how to help you differentiate from yes, what's probably more candidates, or more applications going into each role.

Lenny (00:24:30):
When you say industry experience, what's an example of that?

Hari Srinivasan (00:24:32):
Imagine that you are applying for a PM role, but that particular software is in, I don't know, automotive tech. If you happen to have worked in automotive before, have a knowledge about cars, that's a very helpful way to get in. I think if you're able to show that you can show an industry knowledge and an understanding of it, I think it's a real nice way to think about how to position yourself against some of the other candidates.

Lenny (00:24:55):
What else can that person looking for a job do to improve their chances of a recruiter basically finding them? I feel like that's probably the best tactical thing they can do because a lot of LinkedIn is recruiters reaching out and finding you.

Hari Srinivasan (00:25:08):
There's two things that anyone who's hiring is always going to look for. They're going to look for your skills and capabilities and they're going to look for your intent and interest in the role. A lot of our products and the pathways we try to do are making those things simpler. Maybe we'll just start with interest and we'll move back to skills in a minute. A couple of things we've launched recently, and I think they are symbolic of other ways you can connect. If you go to a company page and you're looking at the company, and I think they have to opt into this in some degree, look, you can say you're interested in that company even though they don't have roles. When the next role comes up, they'll have a signal that this person is actually very interested in this role.

(00:25:42):
That's an easy way to signify from an early stage that you have interest in them. That way, when they open up a role, as you can imagine, they start looking through, they'll have a spotlight on recruiter and they can click out on it and come through. Certainly, you can go into open work and say that this is something that I'm open to work right now, and you can signify to the whole population that this is an area that you want to go for as well. I would encourage both of those in some ways. If you're looking for a role, be open about it and tell the companies that you're looking for it. Those are really high signals of intent.

(00:26:09):
The other thing you can do on LinkedIn is you can actually go through when you say open to work and you can specify particular kinds of jobs and things you're looking for. I think that more detailed intent helps make sure you're showing it to the right place.

(00:26:21):
On the skill side, we talked about it a little bit, but I do think there's a big change. When you were just looking at title, I think you only had one way to really prove that you had the skills. You had to have that title, which is very hard to break in. In a world where you're looking at skills, you can go through and say, "Look, I can do these things and you could put evidence behind it." I'd really encourage people to do that. If you just go to any job post, you can see the skills, you can say add and you can see all the evidence and how you can add it. I would really encourage people to do that because when people are in recruiter and they're looking for skills, profiles pop up and you can scroll over a skill and you can actually see all those evidences.

(00:26:56):
Basically, a recruiter could say, "Oh, this is why I'd recommend you to this hiring manager." I think you will find that that's hopefully a very useful way of doing it.

Lenny (00:27:05):
I'm going to lob this question like a fishing line, to see if it catches anything. And if not, we'll move on. Are there any stats that you've seen of just like if you do X, Y, Z, your chances of getting hired or getting people reaching out just go significantly higher?

Hari Srinivasan (00:27:20):
Open to work certainly has a high signal to noise. As you can imagine, when someone's looking to fill a role, that's one they want. We are early in company commitments, but we are seeing some signal there that we got to move through it. Skills has a pretty high signal as well, when you're able to come through and show and demonstrate your skills. We're seeing some correlation to basically people getting a role.

(00:27:41):
And then the final one that is harder for us to look through, but it's certainly important. I do think we show the hiring manager on a lot of the roles. We show these people through. It's harder for us to trace that because of the way the outcomes work, but I would really encourage people to look through that and see if you can get in front of those people.

Lenny (00:27:58):
Is there a max seniority that you find works effectively on LinkedIn to find a job? I imagine CPOs aren't finding jobs on LinkedIn. If I'm looking for a job, do you have a rule of thumb of, if you're at this level, maybe you're not going to have a lot of luck? If you're below the-

Hari Srinivasan (00:28:15):
We certainly have CPO jobs that are posted, but the difference often is job posts versus recruiting. More and more senior roles are often recruited. We find that people will use LinkedIn in order to connect to a CPO and many people who are senior will say, "Oh, I got a message on LinkedIn and that led to this," or they made a long-term recruiting contact. But it may not happen through you finding a job and hitting the application button.

Lenny (00:28:38):
Let's talk about LinkedIn as a company to work in, the culture maybe for a bit. You told me that you have a story about your first product review when you joined LinkedIn and how that was wild. Can you just tell that story? I haven't heard this yet.

Hari Srinivasan (00:28:51):
Yeah. I came through a small acquisition that they made of our company, and I thought it was such a telling moment in this first product review. I went in and as you can imagine when you join a company, there's a lot of advice on how you should make that product work. I didn't know anything. I'd never been a PM. I remember taking a lot of that advice and putting together a presentation and just getting destroyed during that review. I think Jeff was the head of product and CEO at that point. In a very kind way, it was basically like, "Wait, this doesn't make any sense."

(00:29:23):
I just remember driving home and calling my wife and like, "I think I might be fired." I'm not sure if I was fired, but he was very kind about it. He's like, "Just come back and exit." I think five, four weeks. I remembered at that point I was like, if you're going to go in and you know you only have one shot, just do something you believe in and make sure it works. We started from that point and we worked backwards from there in this concept of, "Hey, I do believe that the most important thing is connecting to opportunity and we should really understand how to do that. Let's just start from there." It went very well.

(00:29:50):
To me, it was another way of you're in these large systems, you're in these large companies, you're in these large ... I think LinkedIn is very special because no matter what it is, it's got a very good North Star. It was a moment for me to really hammer that home, that as long as you get that North Star ahead of you, you're going to be just fine. I never worked at a place like that before, and I think a lot of times people wonder. You can imagine. The way we're talking about, we certainly have an engagement ecosystem. We have the hiring business and we have a marketing solutions business. We have a big premium business.

(00:30:24):
You can imagine when you're trying to make decisions across that, it could get very, very complicated. I think when people ask me to describe LinkedIn, I often start with that story because I feel like it helps cut through how decisions are made and what is seen as success here.

Lenny (00:30:39):
Just to clarify, so that North star is that phrase that you used of just connecting people to economic opportunity?

Hari Srinivasan (00:30:45):
That's it. That's it. I know it sounds bigger than it seems, but I can probably ... Time example again. You can understand when someone's driving on it. Having been here for a little bit now, you can understand when someone knows that and when someone doesn't. It's a hard thing to lose track of.

Lenny (00:31:00):
Yeah. It does sound vague and a nice, fuzzy, warm thing that people can say. What you're saying is that it's actually brought up in meetings constantly and product reviews. You're saying in this product review, everything changed when you came at it from that one perspective?

Hari Srinivasan (00:31:16):
Yeah. My first product here was the profile. You can make a profile that does a lot of different things, as you can imagine. You could think about how identity could be used in many different phases and what you should prioritize and not. But if you can explain why this is the thing that you should do that would help someone really do what they want to do, maybe it's have an incredible podcast and send that out there, maybe it's helping someone connect to a job. But if you can understand intent and how this is unblocked and why you want to prioritize that item, all of a sudden the world gets a lot simpler.

Lenny (00:31:51):
How does that actually get operationalized at a company? Is it just the leaders remind people of that? It's painted on the walls? How is that a thing that people come back to over and over?

Hari Srinivasan (00:32:01):
I do think it's a lot of repeat, repeat, repeat. I do think that's it. I do think the culture has a pretty high immune system now in the sense that when you aren't operating by that, people can see it and they operate against it. I think when Jeff was CEO, and Ryan, they are just exceptional at continuously repeating that. It's been so consistent for so long that I think it's just the DNA now. I do think it's exceptional. I think it's exceptional leadership, and I've learned so much from watching it and how it gets operated.

Lenny (00:32:34):
Is there a metric associated with that when people use it in a way of like, no, that's not actually what we mean? Is there some way of making it even more concrete in goals, metrics, ways to understand if people are actually achieving that?

Hari Srinivasan (00:32:46):
Yeah. Totally. I think at the next level of operation, what we think about is, when we run these marketplaces throughout this ecosystem that connect people to opportunity, what are the outputs that they measure? I'll just give you mine for example. We think a lot about number of hires, converting hires. How many people did we match? Which is a real tangible way of looking at opportunity.

(00:33:04):
And then number of people who learned a skill, which is usually in this world measured more by time than anything if you learn. Spend time for X amount of minutes. We do that skill because oftentimes skills don't have a direct outcome as you can measure to go through. We basically look at those things more than any other to say how successful that we are operating that marketplace.

Lenny (00:33:22):
Got it. Those make total sense to me.

Hari Srinivasan (00:33:24):
Yeah.

Lenny (00:33:24):
Are there other core values of LinkedIn that are public that you can share?

Hari Srinivasan (00:33:28):
You can Google them too and so they're very, very public, but probably the one that I think is most important to talk about in this world is, there's this concept of members first. I think anytime you run an ecosystem as complex as we do and you think about it, even if you're trying to connect people to opportunity, there's two people, how are you going to decide right now who needs it?

(00:33:49):
I think having clarity on which piece of the ecosystem is going to be where the focus is, it helps us make sure we establish a relationship of trust first, make sure to understand who's getting access to data, make sure we understand how decisions are being made. I always love that as a principle that we've stuck by.

Lenny (00:34:05):
Yeah, I see it on the page here. We put members first.

Hari Srinivasan (00:34:10):
Story checks out is what you're telling me.

Lenny (00:34:11):
Checks out. Checks out. What's interesting is the connecting people to opportunity, economic opportunity is not one of these values. It seems like it's even broader. They should at the company basically.

Hari Srinivasan (00:34:21):
The company, yeah.

Lenny (00:34:23):
Got it. Okay. I love that. This episode is brought to you by Eppo. Eppo is a next generation AB testing platform built by Airbnb alums for modern growth teams. Companies like DraftKings, Zapier, ClickUp, Twitch, and Cameo rely on Eppo to power their experiments. Wherever you work, running experiments is increasingly essential, but there are no commercial tools that integrate with a modern growth team stack. This leads to waste of time building internal tools or trying to run your own experiments through a clunky marketing tool.

(00:34:52):
When I was at Airbnb, one of the things that I loved most about working there was our experimentation platform, where I was able to slice and dice data by device types, country, user stage. Eppo does all that and more, delivering results quickly, avoiding knowing prolonged analytics cycles, and helping you easily get to the root cause of any issue you discover. Eppo lets you go beyond basic clickthrough metrics and instead, use your North Star metrics, like activation, retention, subscription, and payments. Eppo supports test on the front end, on the back end, email marketing, even machine learning claims. Check out Eppo geteppo.com. That's geteppo.com and 10X your experiment velocity.

(00:35:32):
You've touched on this idea of a complex system and I want to spend a little bit more time there. LinkedIn is, as you said, very, very complicated. There's all these marketplaces within marketplaces. There's so many customers you got to make happy. They all have to work together. I'm just curious what you've learned about building and maintaining a complex ecosystem like that.

Hari Srinivasan (00:35:55):
It's a fantastic question. I just openly think first of all, just career-wise, I've always been drawn to that. We talk about product as a whole. We always talk about it as a whole, but there's many different things you can build, many different types of things. And then we go, maybe there's hardware and software consumer goods. I actually try to think about products by their complexity curve a lot.

(00:36:17):
I think that the skills you need to manage a complicated ecosystem versus maybe the skills you need to design something that's less interconnected are quite different. I will get to the details maybe of what I mean in a minute, but I do think LinkedIn's a particularly complicated place. And I do think that the skillsets that you think through and you try to manage in a complicated ecosystem are quite different. Maybe some tactics that can help if it's something along those lines.

Lenny (00:36:42):
Yeah, let's do it.

Hari Srinivasan (00:36:43):
One of the things that I often think about is this concept of cause and effect. If you have non-interconnected things, it's actually quite easy not to have to think about that. You made something people love. I wrote a children's book not too long ago and it was fun. It was awesome to write. Once it was done, it was done, and it was out there and it was able to go. That's a little bit different than here. If you make a change, like open to work, all of a sudden you're thinking through the perception of someone on the other side. What is that going to do? Are they going to use the platform less or more? You're thinking about customers. What are they going to do with that data? Are they going to, to your point, perceive someone in a different way or not?

(00:37:21):
You have to think through second and third and maybe even fourth effects and manage that as you go through. I think that is something we really pride ourselves on is, how do we start thinking through these different things, and how do we start measuring them as we go? That is one.

(00:37:35):
The second thing I actually think is it does lead to your point a lot. You need a different kind of decision-making mechanism because there's a lot more ties in the ecosystem, a lot of people who just need a way to break it. We've put in things like we have something called RAPID, which is a really easy way to know who the decision-maker is. Just, you line up who's a recommender, who has to agree, who's a decision-maker. We have something called a five-day escalation rule, which makes sure that those items are in. I think you lead a lot more of those fuse, I don't know what they're called, fuse limits, or just systems in place in order to manage that complexity so that things get done. I think that those processes are actually really, really important to make sure that the ecosystem can run.

Lenny (00:38:10):
Let's talk about these two processes. RAPID, and what was the other one? Five-day-

Hari Srinivasan (00:38:14):
Yeah, five-day alignment. They've both been around LinkedIn for a little bit, but they're great. The RAPID is just a question of oftentimes to your point, if you're running two, three marketplaces, several different business model here, there's a question of who has the decision? Who can make the decision in this situation? Making sure that you have a single person's name with the decision and that person is ... That is really, really important because it gets the clarity real fast.

(00:38:36):
It's more of a personal rule, but one thing I love to say is, if you had three back and forths in an email, you got to pick up the phone. And if you've been on the phone for 20 minutes, it's time to just write that decision-maker and go. That way, you can make sure the concept of an hour, you should be able to get a decision. It doesn't always operate like that. I'm sure there's many PMs on LinkedIn who are operating here maybe, who may have some feedback from me on that, but that's the intent behind it.

(00:38:58):
And then a five-day alignment is, you should hold your managers accountable. That in five days if someone has something that they haven't been able to escalate and solve, that's probably then on the next level of person. But as you run that ecosystem and there's so much complexity around it, I think you need some of those processes in place in order to start answering some of those tiebreakers, if you will.

Lenny (00:39:17):
Ooh, I like that five-day rule. Basically puts the clock on a manager to get to unblock, basically?

Hari Srinivasan (00:39:23):
Yeah. Yeah.

Lenny (00:39:25):
With RAPID, I don't know if I totally understand. Is that an acronym for something? Or is it just-

Hari Srinivasan (00:39:29):
It is.

Lenny (00:39:29):
... make decisions rapidly?

Hari Srinivasan (00:39:31):
No, that's a great question. The D stands for decisions, but the R is for who's recommending it. The A, who has to agree. The I is for other people who may be able to be putting in an input. It's basically a list of people who need to be in the decision chain.

Lenny (00:39:44):
Got it.

Hari Srinivasan (00:39:45):
I would argue the most important thing is to have a single name on that decision line, because that usually makes sure that you can get a decision very quickly.

Lenny (00:39:51):
Are there any other really common frameworks or processes along these lines at LinkedIn that you find really helpful?

Hari Srinivasan (00:39:56):
The third thing is just in how we think about talent, especially in the product organization. I often really do try to suss out during interviews or in how we promote people, just their ability to see systems. Because again, I do think it's a different skillset and a different capability of how we map those things out on a complexity curve. Oftentimes, I think those talent systems will ... those who are able to see the whole, make decisions at the whole, that's rare actually.

(00:40:24):
I think most talent systems are, "Hey, how did your division grow or your product grow, your era grow?" We've tried our best to understand that it's not just about that. You want accountability in the ecosystem of course, but how well does this person work across? I think as we've created telemetry around that or organizational understanding of that, how we've understood ourselves, just, "Hey, this is the skillset that's really important here," I think that's quite rare in driving that kind of complexity system as well.

Lenny (00:40:52):
One more question along these lines.

Hari Srinivasan (00:40:53):
Yeah.

Lenny (00:40:54):
You've been at LinkedIn for a long time. It feels like historically, LinkedIn as a product team, the external impression was it's very optimizey-oriented and everyone there is just micro-optimizing all the little features of LinkedIn. Everyone I've worked with from LinkedIn, they're just really good at just optimizing things.

(00:41:16):
It feels like a lot of new stuff is happening with LinkedIn these days and I'm curious if that's been a real intentional shift of let's not focus so much on making emails work better and all the click-through rates of everything and more just, let's innovate more, let's do some bigger bets.

Hari Srinivasan (00:41:34):
I do think there's two things to acknowledge. First, there's an incredible growth team, and I think a lot of people that go on from LinkedIn in incredible roles are growth. I think there's an influencer change that a lot of people you meet might be growth-oriented. The second thing is, especially when LinkedIn started, and like you said, I've been here a little bit of time, but growing the network is probably a very, very important thing to get the scale out. I think a lot of things people interacted with at first were maybe more growth mechanisms than other systems.

(00:42:02):
I do think there's always been, at least for the last several years, an underlining line that value is what's going to carry this ecosystem, and value is ultimately what makes the day. To your point, I like to think that they may not be the most, I don't know, the glittery items, but I'm really proud of what we've done with skills. I think that's one of those invisible systems that no one really knows. Like, oh my gosh, that's a huge disruption if people can now get ... That's a huge language that people have created. That's a huge way that people have changed.

(00:42:32):
We're really proud of what we've done with values. Even open to work and commitments, these are major social systems that we've wired through. I'm really proud of what we've done with LinkedIn Learning. I would argue it's one of the bigger creator systems in the world. It's these incredible instructors and the ability to take someone who teaches, maybe is not great on camera, and move them to the studio and give them that capability and take their voice out there.

(00:42:55):
I think there's a lot of different things we've done that maybe because they're more invisible, if you will, or they're hidden in a marketplace that necessarily maybe a lot of the influencer voices may not actually need an access every day, I don't know if they get as much visibility. But I like to think that's been part of the DNA for a while and we've been really thinking through it.

Lenny (00:43:17):
Let's actually talk about LinkedIn Learning. I know this is a big passion of yours. You have your own course within this that I want to talk about. But broadly, just what is LinkedIn Learning, just so people understand? Because I don't know if a lot of people know this exists within LinkedIn.

Hari Srinivasan (00:43:29):
Great question. LinkedIn Learning is basically a way to learn professional skills. We entered the business in 2015 and the thesis was, we think about it as a marketplace again. You have seekers and job and oftentimes, seekers may not have all the skills in order to get the job. We're moving now towards the skills model, but without question, this other second-order impact. I don't think any of us wanted to, if you will, uberize the world. I don't think any of us wanted to make everyone there. We wanted to make sure everyone had the skills in order to learn the skills, in order to get there. Getting the learning business was really, really important for the vision and the mission. Basically, the idea was that we'd have ways to teach people skills that was very much tailored to professionals.

(00:44:12):
Now, that was the vision. The way the mechanism works is, we go and get the best instructors in the world. We will bring them into a film studio. We will do it at home or in a way that makes the content extremely ... We help write the scripts, we obviously have incredible graphic, in a way that makes a teacher and someone who's an expert who may not always have the capability or the time to go and make their own online course and get them in the studio and go from there. And then the vast majority of people will probably have access to it through their company. The vast majority of the usage and the business runs through enterprise and is a large enterprise learning product.

Lenny (00:44:47):
Awesome. Yeah. I'm just as a, I don't know, armchair quarterback strategy person, I could see where this came from of we're trying to help people connect to economic opportunity, find jobs. How do we help them? Oh, they don't have the skill? Let's help them build the skills. Makes a lot of sense. Okay. Within this, you have your own course on product management.

Hari Srinivasan (00:45:05):
Well, it's funny. I'd been thinking about a course for a while, but largely it was this concept of, I wanted to make sure I tried our own product and I understood the instructor pain point. But it's a very scary experience. It's like first, I don't know if I had anything to teach. My own concerns about that. But about four or five years ago, one of the things we started at PM internally was product university. We had our own internal university, which was basically we got some survey, we sent it out. I think everyone told us, well, it's literally the most negative one was people said, "I don't have the skills to do my job."

(00:45:40):
I remember looking around and I'm like, "Well, it's pretty obvious. We hired a bunch of people, there's no PM degree, and we've done nothing." What we started doing is internally creating a product university. It was a bootcamp coming in. We tried to get from different models and one of the things we really learned was, you can't teach this just through frameworks. You needed to have a series of case studies. You need to have a real series examples. But luckily, we had a bunch of things we'd done at LinkedIn, so we started putting a curriculum against that. And then just recently, a few of us got together and we filmed the actual course for it. It's basically taking our product university bootcamp and opening it up to the world.

Lenny (00:46:14):
You opened up some of your internal use cases as a part of this course?

Hari Srinivasan (00:46:17):
We do. Yeah.

Lenny (00:46:18):
That's awesome. I always say that one of the things you don't realize you have as an advantage working at a bigger company is access to tons of strategy documents and vision documents and stories of this. Because once you're out, no one's going to be able to share those with you because they're so private. I don't have access to any of these anymore. That's a really cool perk if you're working at a company like LinkedIn.

Hari Srinivasan (00:46:39):
Thanks. Yeah.

Lenny (00:46:40):
Question about your course. What are some of your biggest lessons that you teach? Can you just give a preview of some of the tidbits that you might learn in this course of yours?

Hari Srinivasan (00:46:48):
Well, again, a lot of it is case studies and use cases in the same way we teach it here, but a couple of things that we do talk through. When we started doing our own product university, we realized a couple big pain points that people hit. The first was, it's actually really hard to know how to validate and what the bar is for a new idea in any organization. I think it's really hard to say that. We provide a lot of framework. Simple things from, "Hey, you got to prove to the world why there's duct tape in here." There's someone actually physically going out and trying to do it.

(00:47:19):
How you can prioritize a list of ideas against a pain point, like how to make a simple expression, and how to look through what's an acute pain point and what's a wide range of people use, how we'd expect data in order to be used in order to validate this. Tools you could use to say if this is a good idea or a bad idea. More importantly tools to make sure you've went through the process and how you can communicate it. That's one framework set that we talked through.

(00:47:42):
The other is a lot about Damian, who leads our growth team. He comes in and he starts talking a lot about thinking in loops. How do you make sure that when you're building something you can have the fuel in order to cascade and grow? I think just the framework of doing that, how you measure that, how you monitor that, is also something that at least when I was starting and doing my startup, it was quite something I wish I had had access to. Those are maybe two good examples of frameworks and tools that we come through.

(00:48:09):
And then of course, trying to overlay that with real cases. Not always successful ones, of course, too. We talk about a lot of the failures we've had and where we probably went wrong if we had to diagnose them in postmortem.

Lenny (00:48:19):
A lot of the people listening to this are people that want to get into product management and aren't PMs yet. I imagine you get asked this a lot, how do I get into product management? What is your advice that you often give?

Hari Srinivasan (00:48:29):
Yeah. Well, let's start with how we look at the world, which is this idea of skills. We have a diagram that I think about, which is skills are on a triangle. You might have heard this one before. I don't know if you have. Skills are on a triangle, and I think you need three different skills to be a great PM. You need to be a Steven Spielberg type creator. Something around data science and the ability to really look at data and see patterns and then see the future. And then especially get more senior. I think it's a lot of general management. You have to basically be able to shine and innovate across the team, understand the budget, understand how companies differently work.

(00:49:01):
I've actually never seen a great PM who's in the center of it. I find the great PMs live on the edges. There's always someone who's this exceptional data scientist and the ability to maybe be a great GM and lead and inspire, or maybe someone who's so creative, who can lead a team in a different way. I think that one thing I would really, really encourage people to do is understand where they fit on that graph and gravitate towards those kinds of roles. Because a lot of times, I think what people do is they think they have to make up for the other pieces of that graph, and it leads them to a path where maybe they're not playing to their strengths. That's one thing I always encourage people.

(00:49:38):
The other thing I would say, and I know it's a little bit of luck in how this works, but I think about my journey, one thing I've really found was really helpful is, I was on the first team that did a hybrid SUV in the US. At the time, it was the Hybrid Escape at Ford. I came from the Midwest and it was one of those products where people would really drive out for hundreds of miles and see, and really a community gravitated around because it was a very special product. Being able to work on something that people loved, really loved early on, and see what that felt like and look like and that success was, it created a bar for what I would hope my products could do. It would.

(00:50:17):
If you're able to get into something that people really love and feel that and experience that, and really understand what that looks like and what it takes to get there, I think that's actually been a really valuable lesson throughout my career because you can understand the whole path on the way up. I look back at that as really something that I would hope other people if they can do it. I know you're making world decisions on many different criteria, but try to find something people love and really experience what that feels like.

Lenny (00:50:40):
To build on that, with PMs that work for you and work with you, when they're looking to get better and build their skills, other than go take some courses on LinkedIn Learning, what do you often recommend they do to help become stronger and better at their job?

Hari Srinivasan (00:50:56):
First, it is that feeling of, you got to own your product and you got to speak up and say this is where I want to drive it. Because a lot of times I think people are scared to do that, or worried about doing that, or don't feel that's their actual role. One, it's extreme clarity on hey this is your role. It's to own this and take this to the next level. When you start molding the clay, people want to come and help. When you start building something cool, people are like, "Oh." They're gravitated to it. But until you can start doing that, that's really tough. One, it's letting people know that's what's expected of them.

(00:51:26):
And then two, I would tell people to just build. As crazy as it sounds, I spend a lot of my time on the side, just trying to build different things. Try different clay, think through different ideas. I think that is a really important skill to have, to just being able to say, "Okay, I'm going to start with a blank sheet and make some art," or whatever it is you want to do. I encourage people to do that because it's a muscle, like anything else. It can atrophy. I really do think no matter what the heart of PM, in is that ability to be a builder, and you do got to make sure you can keep doing it.

Lenny (00:51:57):
Yeah. That's actually a great segue to where I was going to go next, which is, you say you build and you like to build stuff, but you're legitimately building a lot of stuff. You have the site, mindofhari.com, where you share all these side projects. Can you just talk about what's going on there and some of the stuff that you've built?

Hari Srinivasan (00:52:12):
Yeah. Arguably, the only thing I've ever been good at in my life is just building things and creating things. I get a lot of energy from it. Yeah, I have a site. It's called Mind of Hari because it is really whatever's top of mind. I try to do my best to completely separate it from business. I know there's always a draw as a good PM to say, is there a business here? But I try to keep it as art. It's completely art and it's what I want to build. I take on new subjects. I have two little kids and it's fun to ... One of them was a book me and my oldest wrote, and it was a set of bedtime stories we did. And then one day I was like, "Hey, we should just make this a notebook." And we did it. I think it's got about half-a-million readers now. It's been fun to see it take some life and go through.

(00:52:57):
We made a board game recently that I know Stanford Design School or some professors there have been using, and it was called Parallel Universe. It's, how do you have a card and then be able to see maybe the card says there's no windows in this world anymore, and then what would happen in that world? You got to list 10 different things that would happen. That ability to think ahead, the fun sci-fi stuff. I make healthy gummy bears. I just try to take something completely new and have that. I don't know, it's probably one of the more fun moments in this world where you can sit there and just create something and have some new clay. Yeah, that is what that website is about.

Lenny (00:53:34):
Wait, so you made actual gummy bears?

Hari Srinivasan (00:53:36):
Yeah, we are doing something with gummy bears. Lenny, I know you're expecting a new addition. Congratulations, again. But one of the things I found when I had kids is, no matter what I was trying to do, there was candy and sugar everywhere like any Halloween, any birthday party, et cetera. You can't get rid of it because it was just hard to do. So we were like, hey, we're going to sit down and make our own gummy bear. What I found is, this is just a fun tidbit for your readers, if you open a Twizzler or one of those, about 80% of what's in there is sugar because they're optimizing for shelf life. They're optimizing for what's in the store.

(00:54:07):
What we were able to do is basically create a gummy bear. About 40% of it is sugar. It's just got five ingredients. Honey is the sweetener because I don't want to give my kids some alternative sweeteners. But we have a small commercial kitchen and we produce some gummy bears. If you ever want to try them, to any of your followers, I'm happy to send some gummy bears and hopefully you can check them out.

Lenny (00:54:27):
Wait, is there a way to buy them somewhere?

Hari Srinivasan (00:54:29):
Well, you can go to Mind of Hari. We stock them seasonally. One of the things that we found out is there is different laws on how they can be shipped, and obviously we're not optimizing for long storage. But they'll be on Mind of Hari. You can always reach out to me and I'll find you and tell you which farmer's market we're at or whatever and you can come swing by.

Lenny (00:54:48):
Well, I don't see it on Mind of Hari, so maybe by the time this comes out, put it on here. Or if you're trying to-

Hari Srinivasan (00:54:53):
Put it on there?

Lenny (00:54:54):
Yeah.

Hari Srinivasan (00:54:54):
Yeah, it's on the homepage. And then when they're stock, we put them in the shop.

Lenny (00:54:57):
Okay. That means they're out of stock? All right, we're going to sell you out. Let's get all your gummy bears. With that, we've reached our very exciting lightning round. Are you ready?

Hari Srinivasan (00:55:06):
Yeah, let's do it.

Lenny (00:55:07):
What are two or three books you've recommended most to other people?

Hari Srinivasan (00:55:11):
The first one is called Thinking in Systems. It's the one I give the team every now and then. It's just a really good book about how I think sometimes people see systems. Can we talk about it? It could be abstract. I think it goes into real detail on how people can intervene at various parts and how to take actions at different systems. I really enjoy that book.

(00:55:31):
Not directly maybe a book I recommend, but a book that I just read that I thought was phenomenal, just to give it to readers if they want something good, it's called Tomorrow, and Tomorrow, and Tomorrow. It was recommending by a friend. Have you read it? You read it?

Lenny (00:55:41):
Yeah. I honestly didn't love it, but I liked it a lot.

Hari Srinivasan (00:55:45):
For some reason, I've been-

Lenny (00:55:47):
It was sweet.

Hari Srinivasan (00:55:47):
I thought it was very well done and there's a couple chapters I reflected on. I just finished it. I thought it was well done. That's one that I'll throw out there.

Lenny (00:55:54):
Yeah, it was very sweet. I feel like it got hyped too much for me. I'm like, okay.

Hari Srinivasan (00:55:54):
Oh, I didn't actually know it got-

Lenny (00:55:54):
I think that's the key.

Hari Srinivasan (00:56:01):
... much publicity. Okay, that's it. The third one that I just downloaded because I finished it, I'm actually going to open up my audiobook and tell you because I'm about, I don't know, an hour into and I'm really enjoying it, it is An Immense World. I don't know if you've read that one yet. It is about animals and how animals have different senses out there. It goes through a set of different animals and how they see the world.

(00:56:24):
Just one of those reminders that we're so limited sometimes in our own perception and how dogs, for instance, they can breathe in and take in sense even when they're breathing out. It's like vision almost, and it's just phenomenal to me just to think about all the things they're probably sensing as my dog and I are going on our walk.

Lenny (00:56:42):
I've learned dogs shoot air out of their nose first before they smell, to clear things out.

Hari Srinivasan (00:56:48):
Isn't that wild? They can probably see so much more of what happened in the history of a little walk than we're able to just because of that.

Lenny (00:56:57):
Incredible. Next question. What is a favorite recent movie or TV show?

Hari Srinivasan (00:57:03):
One thing we try to do is watch TV as a family. It brings us together a little bit. We are doing Star Wars with the kids, which is for the first time, which has been a really enjoyable experience, just being able to witness it through them. And then we've been going a little bit back in time. We watched ET. It's fun. It jogs your memory. These are phenomenal movies that we go through. I think your question is on recent TV shows that probably came out more recently.

Lenny (00:57:27):
Those work just as well.

Hari Srinivasan (00:57:28):
Yeah. The other one I did like, it's not a TV show but I ... God, what was it called? It was that podcast that came out. Case 63 I think it was called? Anyways, I hope that's the right name of it. But it was a sci-fi podcast. It was like 10-minute shorts. The premise of it is someone comes from the future and there's a little bit of speculative fiction and is at a psychologist. It's just a phenomenal piece. I'll have to get you the real name. Maybe I can get it for you after for the show notes or whatever.

Lenny (00:57:56):
Yeah, we'll edit your words and add that-

Hari Srinivasan (00:57:59):
Yeah, exactly.

Lenny (00:57:59):
... whatever's in the show notes, that's the one you meant. What is a favorite interview question you like to ask?

Hari Srinivasan (00:58:06):
I do like to ask people what the most complex thing they ever built was. I just love to understand mostly, what do they gravitate to? Is there something you gravitate to? And two, are they able to simplify it? I think those are two really important skills.

Lenny (00:58:19):
What is it that you look for in their answer that tells you it was a good answer?

Hari Srinivasan (00:58:23):
Both of those things. First, did they take on something that was super complex, really, really hard? Because I think there's only a particular group of people who gravitate to those kinds of problems. I do think more and more openly. I think that's a lot of, in my opinion, the ways the world is going to get better by the things that are really, really hard to solve. Intimacy doesn't scale. When you think about how people are going to feel more connected, it's going to be a lot more difficult to solve. When you think about healthcare, it's going to be very, very difficult to solve. Education is a very difficult interconnected space. I think people who gravitate to that, know those problems are hard, have a very special gift. It's hard to replicate that passion. So one, did you do that?

(00:59:06):
And then two, I think people who really understand systems are able to, somehow this is truly, especially people probably way smarter than me, they're able to simplify it. They're able to explain it and say, "This is how I looked at it, but here's how I modeled it. Here's the lovers and how I went after it." Even if it's nonlinear, they're able to say, "This is how the cause and effects works." I'm really looking for once you did it, did you really understand and were you able to crack it? Or at least, did you understand why you weren't able to crack it? I usually find this to be also the most rewarding conversations.

Lenny (00:59:35):
Awesome. Thanks for sharing all that.

Hari Srinivasan (00:59:36):
Yeah.

Lenny (00:59:37):
Next question. What is a favorite recent product that you've discovered that you love?

Hari Srinivasan (00:59:42):
I'll give you one more dad one. My youngest just hates brushing his teeth. Just was like, it was always a thing. I should actually find the name of the toothbrush, but you can just Google or Amazon this and you'll figure it out. Basically, it's like it was this Baby Shark toothbrush, but it's a game. You play that game for two minutes and you can try to pick up different prizes, you brush your teeth.

(01:00:02):
What I loved about it, because I think it's what all great products do, it turns a moment of annoyance to a moment of joy. It went not even just like you solved a pain point. It was an unreasonable experience of like now he loves it. It was just so well done. It's like 10 bucks, and it was 10 bucks extremely well spent. So much delight. Whoever made that toothbrush, thank you.

Lenny (01:00:23):
Damn. Is it playing Baby Shark? I hope not.

Hari Srinivasan (01:00:26):
Well, it can. It has that feature. It has that capability, but it is a small price to pay for me to get out to enjoy.

Lenny (01:00:35):
Good times. What's something relatively minor that you've changed in your product development process that has had a big impact on your team's ability to execute?

Hari Srinivasan (01:00:44):
I do like to change things relatively. Every quarter or six months, sit down and say, what can we get better at? The two areas I find myself innovating, if you will, innovating or tweaking the most, one is around planning. I think every company struggles with this. You get bigger, it probably becomes a more different ... especially when we talked about the complexity of the ecosystem. We started this thing where just basically we call it orange and red priorities. Which is, then a lot of times what people do is, teams will plan bottom-up.

(01:01:12):
They'll come into a manager or a leader and then the leader may shift things around or say, this is what ... I think we've really started shifting it in a different way. We said, these are the big rocks we got to get done. We're going to get those things done first. We're going to be upfront and honest with you, and these are the things and these are price. And then you can plan from there. I think it's relieved a lot of the progress. I think there's an honesty that comes within and that's been a big change.

(01:01:34):
The others just are the way we review products. That's always been a thing. My read is, when we keep our product review process live too long, it gets a little institutionalized and people start making long documents and stuff. You always have to change that every quarter. Basically, I think it always comes down to the same thing, which is, how do you get their problem statement quickly? And then how do you design from there? But the lever that we basically put in place for that was to really shorten the time.

(01:02:00):
I'm trying this thing, I don't know if it's going to work. But could we get to 15-minute reviews basically instead of an hour and see if that alleviates some of this? I'll let you know how it goes when we chat up next, but I'm very curious to see if this is going to be a different kind of system where we might be able to get to clarity quicker, or realize we're not at clarity and then break and come back.

Lenny (01:02:21):
Reminds me of a tweet I think I just saw. Maybe it was an Instagram post of teams that do stand-ups while doing a plank, to keep the meeting really short.

Hari Srinivasan (01:02:29):
That's interesting.

Lenny (01:02:30):
Could be the next one.

Hari Srinivasan (01:02:30):
I haven't tried that one yet, but it might be something we try next.

Lenny (01:02:34):
Last question. You've been at LinkedIn for a long time. I imagine you use LinkedIn a lot. Is there just a pro tip that you can share of how to be more successful with LinkedIn, find more value in LinkedIn, enjoy it more?

Hari Srinivasan (01:02:47):
The first is, I do think certainly there's ways, and the majority of ways that skills work is we infer skills. But I think that there is a skills section on the profile. I think a lot of people ignore it because they don't realize that there's value in it. That's changing, but I'm not sure if it's changing for everybody. I would pay more attention to skills as we get more into the skills-first stuff.

(01:03:05):
The second thing I would probably do, I don't know if it's that hidden, but I would check out LinkedIn Learning. I do think LinkedIn Learning is a gem. I think because it's sold largely through enterprises, a lot of people miss it. I would hope you check it out. But more importantly, tell me areas that we could get better on there as well. I hope that people will find value there.

Lenny (01:03:22):
What's the best way to find out about LinkedIn Learning? They just Google LinkedIn Learning and they'll find the-

Hari Srinivasan (01:03:26):
Yeah. Or go to LinkedIn/learning. Yeah.

Lenny (01:03:30):
Linkedin.com/learning? Okay. Great. Hari, I feel like we've opened the Mind of Hari up on this podcast. I appreciate you being here. Two final questions. Where can folks find you online if they want to reach out, and how can listeners be useful to you?

Hari Srinivasan (01:03:42):
Well, you can find me on LinkedIn. That's an easy one. I do really, really, really appreciate product feedback. I promise you I take it well, for those listening. And two, going back to the heart of this conversation around complexity, it is really hard to know sometimes what everyone's experience is because you're living in a very abstracted ecosystem. The more you could just say, hey, this is working or not, and the intentions are coming from a good place, and if you have a moment and you're not having a great experience, or you are having a great experience, you could write it. I really would appreciate to hear your perspective.

Lenny (01:04:15):
Amazing. Hari, thank you so much for being here.

Hari Srinivasan (01:04:18):
Thanks, Lenny. It's great meeting you.

Lenny (01:04:20):
You, too. Bye, everyone.

(01:04:23):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review, as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## The ultimate guide to adding a PLG motion | Hila Qu (Reforge, GitLab)
**Guest:** Hila Qu  
**Published:** 2023-04-02  
**YouTube:** https://www.youtube.com/watch?v=7l1fIxk7SnA  
**Tags:** growth, retention, acquisition, activation, onboarding, metrics, kpis, roadmap, user research, mvp  

# The ultimate guide to adding a PLG motion | Hila Qu (Reforge, GitLab)

## Transcript

Hila Qu (00:00:01):
... [inaudible 00:00:01]. Always say is actually fundamentally DLG, data led growth. So when you give away your free product, what you want to get in exchange are two things. One is a broader reach because free product spread itself is lower barrier to entry. Two, you want to understand you usage behavior of those free users, which features do they use and which features kind of correlates with a higher conversion rate, retention rate, all of that. If you don't have a foundation of data and understanding of how to analyze those data, you are giving a way of free product for nothing.

Lenny (00:00:44):
Welcome to Lenny's podcast where I interview world-class product leaders and growth experts to learn from their hard one experiences building and growing today's most successful products. Today my guest is Hila Qu. I've heard some listeners have been doing listening parties with this podcast where their team listens to an episode all at the same time over Zoom and shares their insights and lessons in a shared chat. And I would say that this episode is a great candidate for that. It's incredibly packed with advice on how to start and optimize your product led growth motion. We talk through common pitfalls that you probably run into or to get started, feel us favorite tools, what you recommends for an initial PLG oriented team, how to audit your existing funnel, plus tangents on how to improve your activation and retention and some foundational overviews of product like growth and some of the core concepts associated with it.

(00:01:34):
Like I say at the end of the episode, this episode delivers tens of thousands of dollars in value. Something you won't find for free anywhere else. I am really excited to bring it to you. With that, I bring you Hila Qu after a short word from our sponsors.

(00:01:49):
This episode is brought to you by Amplitude. If you're setting up your analytics stack but not using Amplitude, what are you doing? Anyone can sell you analytics while Amplitude unlocks the power of your product and guide you every step of the way. Get the right data, ask the right questions, get the right answers, and make growth happen. To get started with Amplitude for free, visit amplitude.com. Amplitude, power to your products.

(00:02:16):
Today's episode is brought to you by Miro and online collaborative whiteboard that's designed specifically for teens like yours. I have a quick request, head on over to my Miro board at miro.com/Lenny and let me know which guests you'd want me to have on this year. I've already gotten a bunch of great suggestions, which you'll see when you go there, so just keep it coming. And while you're on the Miro board, I encourage you to play around with the tool. It's a great shared space to capture ideas, get feedback, and collaborate with your colleagues on anything that you're working on.

(00:02:48):
For example, with Miro, you can plan out next quarter's entire product strategy. You can start by brainstorming, using sticky notes, live reactions, a voting tool, even an estimation app to scope out your team's sprints. Then your whole distributed team can come together around wire frames, dry ideas with a pen tool, and then put full mocks right into the Miro board and with one of Miro's ready-made templates, you can go from discovery and research to product roadmaps to customer journey flows to final mocks, all the aim Miro. Head on over to miro.com/Lenny to leave your suggestions. That's M-I-R-O.com/Lenny.

(00:03:26):
Hila, welcome to the podcast.

Hila Qu (00:03:29):
Thank you Lenny for having me. I'm so excited.

Lenny (00:03:32):
I'm excited as well. I don't know if you know this, but you have the very unique distinction of having two posts in my top 25 most read post of all time in my newsletter, which are the two parts of your series on how to add a product led growth motion. And so I'm really excited to dig into product led growth and help more people be successful product led growth.

Hila Qu (00:03:52):
Awesome. I should have made it three posts, three part.

Lenny (00:03:57):
I like that ambition. There's always more. Yeah. Well I think the next milestone is get into the top 10, get two into the top 10.

Hila Qu (00:04:06):
Yes.

Lenny (00:04:06):
Okay. Maybe this podcast will... Oh, okay. This podcast will be in the feed of the newsletter, so maybe we'll get there. No pressure. No pressure. One question I wanted to ask you is anything come out of writing those guest posts? Has anything good happened as a result?

Hila Qu (00:04:21):
I always take a very long-term view for writing. I enjoy writing myself. Spend actually four months on that one. After it's published, I see a lot of shares kind of and people writing very long summary of it. That's always very encouraging and also many people I didn't expect reading it reach out to me, let me know, "Hey, I read that." For example. I think Ravi, he is also on your podcast. I didn't know him personally, one day he's like, "Hila, I read that. That's awesome." And a bunch of friends in VC and they kind of read that. They told me it's great. I even have a advisory client kind of landed because of that as well. So it's awesome.

Lenny (00:05:10):
Amazing. It makes me really happy to hear all that. I was also curious, has anything, and we're going to get into the details of all the stuff you wrote about and even beyond what you wrote about, but is there anything you're thinking has shifted on having after having written that series in terms of PLG?

Hila Qu (00:05:25):
I wouldn't say it's shifted completely because I always believe you don't need to be a PLG purist. Meaning there are kind of people who are like, "PLG is the future. It's only thing, you don't need sales." Right? I was never like that, but recently by working with a few of my clients, I witnessed in reality many startups actually are having both. They have a PLG motion, they have a sales team as well. PLG motion is perfect for lowering the barrier for more people to try, broader the reach. It's a kind of volume kind of game. And then the sales motion, you can have very targeted list of big customers you go after, you close them and it's a big order. Usually revenue, a very strong foundation for a company. And I've seen actually a lot of my clients that are doing, they have both. They're doing that. They try to get the benefit of both from their early stage and it's super cool.

Lenny (00:06:29):
Is the simple way to think about this trend that eventually every one will need to do both. It's not one or the other, it's just both. And it's just a matter of when you add the other.

Hila Qu (00:06:40):
I would think so because let's say if you are in the sales motion dominated kind of traditional B2B software industry, your competitors will be adding PLG, as soon as they add it they will have a benefit of attracting more end users and end users become case to the employer, to the clients. And you lose that. And if you are only in PLG somewhere else may go after the big customers. It takes time for PLG to go to the big customer and close them. So you lose a little bit of time there as well. I think eventually you need both.

Lenny (00:07:19):
Cool. That's kind of the way I've been seeing it. I did a few series on traditional product led growth companies, [inaudible 00:07:28]. All those guys, and they all add sales teams eventually last famous for being product led only. And so everyone ends up adding sales team. I think more recent trend is sales led enterprise E products are all just realizing they need a product led growth component. So that's kind of what I've been seeing too.

Hila Qu (00:07:43):
Yeah, exactly. But I would say it is easier if you have PLG from early on. If you are pure sales led, you try to add PLG, that's the harder thing to change basically.

Lenny (00:07:56):
Interesting to set a little foundation. Before we get into a lot of this stuff, it'd actually be helpful just to explain what is product like growth, just simply, because people hear this term a lot and it'd be helpful just to understand it broadly. And then also just like why is it so popular? Why does everyone want a product growth component to their business?

Hila Qu (00:08:15):
Just use a simple example in B2C product. When you think about Facebook, when you think about a lot of the products you use every day as an end consumer, it's always by default product led growth because there's no sales team [inaudible 00:08:32]. The LTV of the product doesn't support that. I think PLG the term become popular because traditionally in B2B, word sales is the main motion. You need a sales team to close the deal After the contract is signed, the end users can now finally use it.

(00:08:51):
But nowadays, it's not necessarily a case. You can have your B2B SaaS product developed in a way to allow end users to try before you buy. So that's the reason I think this has become being more popular. And the fundamental driver behind this is the user of B2B softwares are also human. It's the same human using B2C softwares and we're already trained to use product, try, and before we make any decision. And we demand that in B2B as well. So it needs to happen. And more and more companies are capturing that trend basically, and they're trying to utilizing that as a entry point to either disrupt existing B2B players or build something really awesome for end users. So that's why it's becoming more and more popular.

Lenny (00:09:42):
To pull on that thread a little bit more even to help people visualize a product led growth product, what makes it product led? There's a self-serve component, what are attributes or just kind of common elements of something that's product led versus sales led? Let's say.

Hila Qu (00:09:59):
Yeah, definitely. I think maybe we can use a product as a example, right? Think about Zoom how me or you, maybe everyday users, how we get to know Zoom is not necessary through a sales team call me code or email me code and introducing me this, showing a demo of Zoom, and I get to know Zoom, right? It's because maybe Lenny, you hosted a webinar I joined and I get to just use this software already without even knowing it's Zoom. And then afterwards I may one day think about I want to do this myself and I just do that in a sign-up and I already create a host a webinar and I can pay if I need a paid plan or I can use a lot of more advanced features when I, let's say hit the 40 minutes limit, I can already click that and pay and become a paid customer already.

(00:10:53):
So I think the key properties also of PLG products, think about it should have a very low barrier to entry. Usually it has a free version, free trial. You don't need get approval from your boss to use it. You can use it today and then it has some sort of a self-service checkout flow. If you need a better version, you can buy yourself as well. And this product, basically the free product will spread on its own in some way or another.

Lenny (00:11:24):
Okay, perfect. I think that was really helpful. I think we dive into some of the meat of the discussion that we have planned and where I thought it'd be fun to start is the common pitfalls that people fall into when they're trying to add a product led growth motion. And so what are the most common ways people fail when they're trying to figure out product led growth?

Hila Qu (00:11:45):
The first of all, as I mentioned, you need to have some sort of vehicle. A lot of the companies, if you go to their website, especially B2B companies, you'll see the biggest CTA is called book demo. They don't have anything else. The first step for you to do is submit a form and kind of basically explain yourself to this company, I'm from who and who company and I want to use the tool, can you come back to me and allow me to see a demo of your product? That means the entry point to PLG is cut off. Instead, the first step is you need to either have a free product, free trial, some sort of a low barrier entry for anyone who stumble upon this product to give it a try. A lot of companies don't have that. That's the first I would say hurdle or peaceful.

(00:12:38):
And especially if you are a sales lead and you already have all those things figured out, you try to go to add PLG, it's not as easy as just say, add a kind of free trial CTA on your website. You need to build this free experience. You also need to convince your sales team, your existing product team, your marketing team, "Hey, let's try this out." Because before this process is super clean. Everyone only get only selected future leads and sales work on those. But now you need to allow more people in and there need to be more understanding of their behavior data, the process need to change. So it's actually a whole process. So I would say that's first one. And along with that is some companies didn't think it thoroughly and they are just kind of saying, "Oh, PLG is cool, let's do PLG."

(00:13:34):
And then they maybe spend three months build kind of some sort of a very basic free trial and then they think that's it. They think the leads will come, conversion will come, self-service revenue will come. It's not that easy. It's not that simple. It is definitely a entire motion. So I would say you need to commit to it. Maybe you can do some thinking, collecting some data, build your conviction, but to a certain point you need to commit to at least a year or even two years kind of roadmap to build this entire thing out and change the process internally sometimes as well to support that. The last one, I would say a lot of times the company's committed, they want to do this, but they don't know the right way or they don't have the foundation, they don't have the expertise of PLG.

(00:14:27):
Their internal team, they're really good at sales or maybe really good at as the traditional motion, but they don't have this part of expertise and foundation. A common thing I see is that company want to do PLG and they have no usage data at all and they're like, "I will just doing PLG. But PLG I always say is actually fundamentally DLG, data led growth. So when you give away your free product, what you want to get in exchange are two things. One is the broader reach because free product spread itself is lower barrier to entry. Two, you want to understand the usage behavior of those free users, which features do they use and which features kind of correlates with a higher conversion rate, retention rate, all of that.

(00:15:20):
If you don't have a foundation of data and understanding of how to analyze those data, you are giving a way of free product for nothing. Like you are really not being able to utilize all of that to build your PLG motion. So I think data foundation and expertise in terms of how do I design that user journey, that journey is very different from the sales user journey. Those are sometimes missing in company when they just begin to doing this. And in those cases I think it's super helpful to maybe either find someone who have done this as an advisor or hire someone like you need to have that expertise or through advisor to support your PLG motion.

Lenny (00:16:06):
This is great. We're going to talk about the data piece more in depth later, but on the commitment piece, I thought that was really interesting. I imagine many times founders or leaders think they have commitment and then they realize maybe not so much. Are there any kind of flags that tell you that, "Oh, you're not actually committed to working on this for a year or two years, whatever it takes."

Hila Qu (00:16:27):
The red flags I've seen basically sometimes, first of all, they think about PLG equals launch of free version or launch of free trial. They made this assumption in their head, "Oh, I already have a product. I already have a software that's working, customers are using. Now if I add a free version, if I open a free trial, that's it." Like that's basically PLG, and I will have conversions. I will have people becoming a product qualified leads just because I have it. "Hey, I open this for you, just come and use it and [inaudible 00:17:07]." And I think that's one red flag. Basically they are not thinking about the entire thing through understanding the implication, not only the free product, it's really just a start. You need to think about how to activate, how to design the upgrade path, how those teams, those new growth teams work with other sales and marketing teams, all of that.

(00:17:29):
So that's one. The other one is they don't have a dedicated team. They just basically assign one person to the thing. They are imagine, "Hey, you already have this. It's not that big of deal. You can just figure this out by borrowing resources from everywhere and try to coordinate all the stakeholders from sales, marketing, product." That person need to be a magician in order to be successful in that basically. And I think the third thing is basically they are really doing this because it's trendy. They didn't think about the deeper strategic reason why this is a good fit for their business. Do you have a product that's relatively low complexity, doesn't require a lot of customization for the customer to see value.

(00:18:19):
Time to value need to be relatively short or you can figure out a way to make it short. And then do you have a lot of potentially end user S&B business? They are interested in the solution. They want to try that out. If you do not have both, if you for example, develop a software for the [inaudible 00:18:42]. Companies like [inaudible 00:18:44]. Or defense companies, only three target customer exist in the entire world, you don't probably want to do PLG, right? So think deeper about the fit and then commit. And I would say those are the red flags.

Lenny (00:18:59):
Okay. So on that last point, I thought that was a really interesting, we talked about how every company probably should add a product led growth piece, but I think what you're also saying is actually not every company, there are some companies like defense contractors that are probably going to be sale led.

Hila Qu (00:19:15):
I think it's a spectrum. I would say the defense company, defense software company is a pretty extreme example. And of course in those case, I don't think it makes sense, but I think majority of B2B software, I've seen, you've seen, we've used even some more complicated ones. Like Salesforce used to be this example of sales motion. They're the pioneer of SaaS and they do this so well, but they begin to add look into sales service portal and all of that. And even a lot of the bigger players are looking into that. So I think majority of the B2B software, probably they are in the middle of the spectrum rather than the defense company.

Lenny (00:20:05):
You kind of shared some of the attributes of what allows you to be product led, like quick time to value. If you have this in your head, what are some of those bullet points of what you need to figure out for it to be successful potentially as product led?

Hila Qu (00:20:18):
The first thing is that have a... And you mentioned you are able to have a vehicle, have a free version, have a free trial. Sometimes it's a open source product. A lot of developer products start as a open source product. It has its constraints, but it is also a great kind of vehicle for PLG or if none of those are option, you can build a really realistic kind of experience. For example, I remember Amplitude, they are pursuing PLG now, but they used to have a lot of barrier. As an end user, it's hard for me to put that code into my product and see my data, but they build a really realistic interactive demo that's getting closer to PLG. So it's not PLG, but it's getting closer and you can already see the value and play with it yourself. So that's the first step. Have a vehicle.

(00:21:18):
The second step step is time to value. Basically, just because you have this vehicle doesn't mean people will come and use it and see the value. So you need to figure out how do you give your users a warm start and help them get started. I was talking with a kind of company today, they just realized we have this tool and when people come in into the free trial, they are asked to do some action, but nobody know how to do that. They may not have everything ready to take that action. So we're like, "What about we gave them some sample video or sample action they can try." Right? It's not the same as they do it themselves, but it's better. It's getting closer. And after that you can ask them to try the thing on their own and they need to do more work.

(00:22:07):
So kind of think about all the ways you can reduce time to value. It doesn't need to be this big aha moment in the first five minutes, but at least give them some mini aha moments, right? So that's the second thing, third thing is think about from there. If they get aha moment, if they want to buy, you need to have this self-checkout flow ready, self-service flow. It's the foundation, if you have it, it doesn't mean they won't buy immediately, but at least it gave them this option to do that themselves. And the fourth thing I would say, between this kind of activation usage, aha moment to this conversion moment, actually there's a big gap. And what is the gap? How you can understand the gap, how you can guide people around that journey is basically you need to have a very good grasp of data.

(00:23:03):
You need to have the foundation to understand their usage, their behavior, and then you can design a user journey in the product, in email, in all those tools to guide user to the next step. So have a very strong data foundation there. I would say. I think those are the main thing. And there are other things like your pricing need to be relatively simple. If your pricing is super complicated, they need to... Whenever they pick, for example, they try the product, they love it, they have a self-checkout flow, but in order to decide how much they need to pay, they need to send your sales some information, you need to do a quote, then that's broken, right? Or they're already confused about this process. So that is another kind of important thing as well.

Lenny (00:23:54):
Cool. So just to summarize, I took notes on this kind of the things that you got to get. If you want to add a product led growth component, there needs to be something free and kind of self-serve that you can-

Lenny (00:24:00):
... growth component. There needs to be something free and kind of self-serve that you can just start using on your own. There needs to be a quick time to value, there needs to be a self-serve checkout experience. You need a data foundation. I really love the way you phrased it where one of the benefits of product growth is the data component that'll help you understand what to build on, how to monetize these folks. And then the last piece is pricing that's simple, that people understand.

Hila Qu (00:24:23):
Yeah, yeah, yeah. Just imagine you are building, selling something on e-commerce side. You need all of this, right. Just in order for the B2B buyer to buy your software in PLG motion, you need to make all those available to him. It doesn't mean if you view this, it'll happen, again, right. That's the data experimentation. A lot of that need to be there to support a lot of iteration and make this work.

Lenny (00:24:52):
Awesome. Okay, so we've been going in a lot of directions. We started with pitfalls and things you probably will... You'll run into that may set you off track. But let's zoom out again and let's get into, just say you're convinced we need to invest in adding a product-led growth motion to our product. What's the first step that you recommend for people to go down?

Hila Qu (00:25:12):
I think the first step actually, I would recommend founders and leaders to just understand what's PLG funnel, what's sales-led funnel with SLG funnel. Because I remember when I begin to work on PLG at GitLab, it was not that clear to me. There's a lot of things you can read, but they're not all super clear. What is PLG? How is that different? And through working on that myself, I begin to develop this conviction and kind of this clear picture. The biggest difference from SLG and PLG is that the sales funnel traditionally work like something... You have marketing team working on the top of funnel, bring visitor and then they need to have a process to turn the visitors into lead. And leads is something, it is basically very popular and vitally used in the B2B business. And you go through some qualification process and leads need to be from your target kind of customer, target industry.

(00:26:23):
The company need to meet certain size, but they also need to show interest. And how marketing team historically gauge interest is how much they interact with your marketing campaigns. Do they open an email? Do they read three white papers? Do they go to this webinar? That's how they gauge interest. And for each positive action you did as a buyer, they add some points to you. And once you reach certain points, you become this marketing qualified leads. Basically those are the better ones we featured through that process and we gave that to the sales team. And sales team has more process, but then they choose some of them, work on them, and they close some of them. So that's kind of traditionally B2B sales-led motion works. And then product-led funnel is different. It's much more similar to B2C. Basically you can still have people visit your website and they sign up for free version or free account or free trial.

(00:27:21):
The most important thing, the biggest difference, is now you want them to use the product. You can still send all the marketing emails, all of that, but those are supplemental. Those are kind of trying to get them to the product to use, to try, and the usage, product usage, is almost like the leading indicator for success for PLG, versus in the sales funnel, it's almost like how many do you get and do they interact with the marketing campaigns, which in the old days it's what you have because nobody can access your product unless the contract is signed. But nowadays that's almost like an artificial barrier. It's not there. You can totally build a product in a free version to allow people to use. So usage becomes so important. And that's the biggest difference from the usage that you have two potential conversion paths.

(00:28:18):
One is that if this product is not that expensive, the price point fits in most companies' budget. Some companies may just use their credit card and they buy online. That's also, you then don't even need sales team to be involved. And it's very similar to the B2C product, e-commerce product, buying process. And it's awesome because it's automated, you don't need to have more sales team involved. It's low cost, it's efficient, it can happen on its own every day. It will just add up to your revenue. And then the other potential conversion pass is where the product usage is high, but also this customer, this potential prospect, fits into your ideal customer profile. It's from a Fortune 500 company or it's from a target industry that you know they need your solution. Then this customer worth more of your time and you should actually not, even if they may want to buy on their own, you may want to still have your sales team or have your customer success team to reach out to them to understand a little bit more of the situation and give them some white glove service. Hopefully you can even close a bigger deal than if they would have buy on their own. So that's another pass. I call that PQL, PQA, like sales pass.

Lenny (00:29:47):
And that stands for product qualified lead, right?

Hila Qu (00:29:48):
Product qualified leads, product qualified account. So the first step is for you to understand those two funnels and then think about if you want to add PLG, right? What is this journey? What are the steps along that funnel you need to establish for your product in order for your user to be able to convert in that funnel?

Lenny (00:30:12):
So you talked about these two funnels. One question is, are they basically the same for almost every product or should you try to figure out what's really unique about my funnel? And then second, is there an example of product that you think about like, here's the sales led funnel for them and then here's the product-led version of that, just to make it a little more real even?

Hila Qu (00:30:30):
Maybe I can give an example first and then we can talk about the other question. So I can use GitLab as an example since that's where I'm most familiar. GitLab actually have a enterprise sales team, very strong sales team, from the very beginning. But the company also we started from open source product.

Lenny (00:30:50):
Maybe describe what GitLab is for folks that aren't super familiar with it.

Hila Qu (00:30:53):
Yeah, so GitLab, we are a developer platform, DevOps platform, basically engineer teams, developer teams. They use this product to manage their entire DevOps process, from storing their code, kind of managing the version control, releasing CSAD, like security scan, all of that. It's an all in one platform for that team. So for the sales-led motion, like I mentioned, the teams, our marketing team, were working bringing a lot of visitors to our website and they sign up for free trial, for free accounts. And then we have this lead nurturing and lead scoring process to surface which are the good ones for our sales team. In our sales team, we have SNB, we have the mid-market, we have enterprise, and they each kind of took their buckets of leads and work on them and close them. They become revenue.

(00:31:52):
And then how the product led funnel work for us is someone, maybe as a developer, I heard about GitLab, I go to website, I see, "Oh, I can actually sign up for a free account." I may use it for my personal project. My company may be using another solution, but I have some side project I'm doing as a developer. I want to use GitLab to host that. And I did that. And so you begin to see this, individual users having some usage but nothing to do with his company. And then one day maybe this person's employer, "We want to look into some other solutions. We have way too many point solutions for each step of DevOps. Now we want to potentially consolidate them. So what are the options?" And this engineer raise his hand, "Hey, I have been using GitLab for a very long time and I really like it. I think we should check them out." And then this team, maybe this engineer manager or CTO depending on the size of company, they're like, "Okay."

(00:32:55):
He went to their website and he kind of signed up for a free trial because that allow him to test some more advanced features. It's 30 days, but he already has... This person knows how to use it. This person already set up the foundation with the free version and they started the free trial. They use their 30 day to do a proof of concept, the entire company already using it for part of their process. And they're like, "Oh, awesome. I tried this feature, that feature, that feature. It's a great tool. It can support our workflow and I'm pretty sure we should be able to get ROI from this product." And then in this case they are like, "I only need five seats. It's cheap. I will just go to the pricing page and check out the pricing and buy from there." Or in some cases, this is a big company and we see this big company is using our product, our sales team get that data signal, they may send an email and reach out and say, "Hey, I saw you were checking it out. How can I help?" And that may start a sales conversation, eventually become a contract from there.

Lenny (00:34:07):
Great. Thank you for sharing that example. Maybe a last question on this first step of mapping out the funnel. Do you recommend people just get in front of a whiteboard and just sit together and like, "Here's what it would be potentially if we added a product-led growth motion?"

Hila Qu (00:34:20):
Yes. Yes. And I think it's not that... The devil is in the details. Just mapping out the big steps is not that hard. You think about, " I have a marketing site already. I can build a free version." And then they use the free version and I build a checkout flow and that's it. That's the story. But that's the first step. If you don't even have those components, mapping out the funnel will allow you to see a missing checkout flow, a missing free version, you already identified that. But the devil is in the detail one layer down. How do you design an experience for each of the step? What do you say on your marketing side to drive free signup? In the free signup, how do you guide them to use the three most important features? And in the checkout flow, which payment option do you offer so that customers from everywhere can buy very smoothly? So that's the next layers kind of detail that actually has so many opportunities for optimization, maximization and all of that.

Lenny (00:35:29):
That's actually a really good segue to the next question, which is just, okay, you've mapped out the funnel, what do you do next?

Hila Qu (00:35:35):
If you don't have the foundational components, you need to build all of that. But if you have something, if you already have this funnel exist, right, it's just not working perfectly at least, but it's working, it's there. I think the next step is you need to pick a starting point. Where do you want to focus first to drive the maximum impact? Personally, I'm a big fan of finding leverage. I think doing growth is always about finding leverage. If you can always find the area that with relatively small investment can give you the biggest results, that can be such a kind of momentum, can empower you through future experiments and more work. And just finding leverage is a beautiful thing in my mind. So I always want to do that. So when I think about pick a starting point, one thing I actually do with a lot of my advisory clients as a first step is, we do a full funnel audit, full PLG funnel audit.

(00:36:38):
Think about, we go through me as a kind of end user, go through the entire journey, pretend I am interested, semi interested, and I want to buy from the website. Does that kind of attract me? Is it super clear the value proposition? And then from there, going through the sign up of the free account or free trial, is that smooth? And when I begin to use the product, do I get to my aha moment fast or I am very confused and frustrated, abandoned at that moment? And from there, if I'm like, think this is good, right, I hit my aha moment, I want to buy. Can I even buy? You will never believe, like when I do this audit,, there are so many low hanging fruits usually in this process. For example, one client, when I go to the checkout flow, the kind of checkout form is so confusing.

(00:37:38):
They ask a bunch of questions that only let's say UK customer need. Every other places they don't need to answer, but they ask the question anyway. And I as a US based person is very confused and I drop off at that point. And then there are other things, for example, the aha moments like I talk about. I don't know what to do when I land inside a product for the first time, I'm super excited and ready, but I don't know what to do. I'm so lost and confused. That's usually a pretty big focus area and opportunity area. Just getting your users to aha moments. They are already over so many hurdles here, but don't just turn down them and they leave because it's so confusing.

Lenny (00:38:25):
It might be helpful just to explain an aha moment. I know people hear this term a lot. What's a simple way to think about what is an aha moment?

Hila Qu (00:38:32):
I think it as a moment, as a first time a user experienced value of your product. So it gets popular because Facebook has this example from the early growth days. I think you added 10 friends in seven days, you hit your aha moment. But there are many layers under that. The reason why Facebook used that to define its aha moment is because in early days, if you add these friends, you begin to form some connection. You can see an interesting feed, you can interact with your friends, and that social interaction, it's the core value of Facebook, and Facebook leaves by looking at a lot of data. If you meet that data metric criteria it's kind of very likely you will hit that aha moment. But I think for a lot of, especially we're talking about many SaaS product, B2B software, the value of such product is usually either you see a workflow can be supported by this, it can save your time, it can save your money, it can help you make more money, or it just solve this pain point that you never get to solve on your own without a software product.

(00:39:57):
So at GitLab we actually did a bunch of analysis. We're trying to understand what is the aha moment for our new users. We ended up have something along the line of two users, two features used in the first 14 days. So it's very similar to Facebook's kind of format. But deep down, because we are a platform, we are a team product, two users is talking about the team components. Whatever the first user is trying and using that is so valuable, he or she is confident to invite another coworker to come in. That itself is very, very valuable action and indicates this first user is seeing value. And if together they use two or more features, that means we are seeing the collaboration, the platform components of the product. And within the first 14 days, because it has to be reasonably quick but not unrealistic, because we are a complicated product, we're not Facebook, we're not Zynga or a game app, it's hard for you to figure it out in the first day. So yeah, I think it's a very important concept for any PLG company to figure out because that's often the biggest opportunity area I see.

Lenny (00:41:24):
Aha moment and activation is often interchangeable, right?

Hila Qu (00:41:27):
Yeah.

Lenny (00:41:27):
So those are kind of two things you'll hear. And just to reframe, re-say what you say, so GitLab's activation slash aha moment milestone was two users using two features in 14 days.

Hila Qu (00:41:38):
Mm-hmm.

Lenny (00:41:40):
And I imagine the way you got to that was you looked at what point does retention improve if they got to a certain milestone, right? Is that roughly how you [inaudible 00:41:48]?

Hila Qu (00:41:47):
Yeah, exactly. So there are how you can get to that, right? First of all, the internal team, our growth team, actually we did some brainstorming. We think about what are the potential action or behavior that indicate they're getting value. We ideally want to do something like they maybe successfully merge their first PR or they successfully run their first pipeline. All of that. There are some potential high value actions we can think of. We just list all of them. And then the next step is, we did a correlation analysis to understand, hey, those are the 10 high value actions we believe we want to look at. If a new user did this action, what's the maybe 30 day conversion rate and... Not 30 day, 90 day conversion rate. What's the 30 day retention rate? Because we look at both. Sometimes you only look at retention or you only look at conversion, it doesn't give you the full picture.

(00:42:52):
So we look at if you did this action, let's say if, Lenny, you are trying our product, you are able to successfully merge the PR in your first 30 days. Does that improve your likelihood to convert? Does that improve your likelihood to retain? And we compare across those 10 high value actions, compare with the average. And we begin to see, oh, some actions actually if you do that, it lift your conversion, lift your retention much bigger. And those are the candidates for potential aha moments. And from there, the reason why we ended up not picking one single action... For some products, actually you can pick a single action. If one action really stands out, I don't know, for Airbnb [inaudible 00:43:39] is probably, you book a hotel, you go to there, you are so happy, you leave a high star review. That's the key action for this platform.

(00:43:49):
For GitLab, we have so many different workflow components. Teams are here for different reasons. Some are here for security, some are here for like CSAD. So that's why we ended up combining like two action. It can be any of the two high value features. The next step is actually you need to launch some experiments to try to get more people to do those high value action. And you then see, do I see higher conversion? Do I see higher retention? Because in data you are only isolating correlation. You are not proving causation. You just saw people who are doing this are more likely to convert. But it doesn't mean if you get people to do that, they will convert. So experimentation is the step. You will finally kind of validate that.

Lenny (00:44:37):
Hila, this is amazing. This is like a mini podcast on activation. We should do another one just on this. And then in the show notes, I'll link to a couple posts that I've written with a bunch of advice on setting activation milestones and improving them. I forget if you've contributed to that post or not, but if not, we should add some of these stories. But let's get back to our core. We have enough to talk about on just product led growth. So just to summarize the audit that you do, I wrote some notes as you were talking, and maybe we can keep going from that point. What you look for when you're auditing a product to see where they may pick a starting point, what I wrote down is, one, are you just excited to try it? Is the landing page pulling you in? Two, can you actually use it on your own and just try it? Three, do you get to the aha moment where you're like, okay, I get it, [inaudible 00:45:25] it, and then can I actually buy this on my own? Is that roughly the audit? Is there anything more to that?

Hila Qu (00:45:30):
Exactly. And I also look at their initial first few emails they send to me, because sometimes the email magically can help a lot. If I'm frustrated the first time... The other day I'm trying a product, I'm frustrated, I'm like, I will give up. And then in the night I saw an email, I'm like, oh, maybe I just click the CTA and give it one more try. And that time actually I figured out I get to the aha moment.

(00:45:57):
So I also look at the email, the first initial emails, and then when I map this out, I ask the company to give me the data at very high level for each of the step. How many people are on your website? How many people go through signup? How many people hit this aha moment? We need to define that. We need to... Usually a lot of discussion, like how many people get to the aha moment, how many people started self-checkout and being successful. And then like that between my experience from a user perspective and the data, we usually immediately begin to see, oh, this is the biggest opportunity. Usually activation and conversion are two of the common starting places.

Lenny (00:46:42):
This episode is brought to you by Ahrefs. You probably know Ahrefs as one of the leading all-in-one SEO tools, used by companies like Facebook, Uber, Shopify, LinkedIn, Pinterest, and thousands more. But Ahrefs is not just for big companies. With their new Ahrefs webmaster tools, you can optimize your personal website like a professional for free. You can scan your website for over a hundred common SEO issues that might be hurting your performance in search engines, plus get advice on how to fix those errors. You can have it automatically browse your website's internal and external links, and get actionable insights from your backlink profiles, and you can learn what keywords your website ranks for and see how you stack up against your competitors. Visit ahrefs.com/awt and start improving your website's visibility. That's ahrefs. com/awt.

(00:47:31):
Okay, so let's get into that then. So you've done this audit, what other advice do you have for folks to figure out where they should start and invest in that part of the product to help launch product-led growth?

Hila Qu (00:47:42):
You can do a audit like this yourself, right. Just imagine if you are a B2C user trying to buy a product, you want it to be easy. Ideally, PLG for B2B can be that easy as well. So go through that process and identify, where is confusing, where do you get stuck? If you find-

Hila Qu (00:48:00):
... where is confusing. Where do you get stuck if you find that you have a problem with activation, meaning if you enter into the product you are like what do I do, I don't know what should I do, and maybe I just left. And then, if that's the biggest opportunity, activation, then you need to think about find the right aha moment metric as the first step, as we just talked about, because that's the success, that's the goalpost. And then, design a product experience to help more people together. And I usually think about do is better than show is better than tell, meaning you want to remove all the frictions and somehow give them a warm start, give them some sample template, give them some sample thing they can play with initially in that very moment already, and you can supplement that with your email to bring them to the product if they don't do that. So that's activation. If activation is okay, but your conversion, your self-check checkout flow, usually there are also room for improvement. Many company I work with, when I try to buy, I cannot even find where to buy. It's very hard to find where do I click to start this checkout process, or they may have some frictions in the checkout flow where it's not localized. One company, when I look at their data, they find that India has very low success rate, which is expected, but we begin to say it's because the payment solution they choose actually doesn't support that market well. And they added another payment solution, immediately they are seeing much better success rate. And if they're already in the checkout, you don't want to lose any of them, right? Just do a hundred experiments to get to as much higher kind of commercial possible, because you don't want to lose any of them. So activation, conversion, usually are two great place to start.

(00:50:08):
And then from there, I would say think about your PQL/PQA, motion, which is the other conversion pass, which is if you also want to have sales blended into this, right, product-led sales motion, how do you set up the structure, the foundation so that you can know what are some data signal to tell you those are better leads? And what are some customer criteria, in terms of size segment, you should set up, how do you get those data, and then how do you hand this to your sales team, how they can close using those data, use this knowledge? That's another very big opportunity area. That's a bigger effort, compared to those two low-hanging fruits.

(00:50:53):
And the last thing I would say, product-led acquisition is a great place to start. If your product is a collaboration software, think about Airtable and it's Figma, right? As part of my workflow, I invite my team to join, I spread this out. If you have that use case, you can build that into a product that's awesome, that's very powerful.

Lenny (00:51:18):
So there's a lot there. So let me try to summarize what you just shared and how it connects. So you have a self-serve product, you've gotten to a point where you can sign up and try something for free?

Hila Qu (00:51:28):
Mm-hmm.

Lenny (00:51:29):
And then you do this audit of where along this journey do we think the biggest opportunities lie and the most leverage lives? And you have these, I think, four buckets of opportunity?

Hila Qu (00:51:40):
Mm-hmm.

Lenny (00:51:40):
Acquisition, which is top of funnel, do you want to double down and invest there first, or activation, which is help people see the value more quickly?

Hila Qu (00:51:48):
Mm-hmm.

Lenny (00:51:49):
Bucket three would be, you called it conversion, which essentially help them buy it more efficiently?

Hila Qu (00:51:56):
Mm-hmm.

Lenny (00:51:56):
And then there's a bucket of retention, of just keeping them around longer, which I don't know if you mentioned this, but I know that's probably not where you want to start, so it's even not worth chatting about too much.

Hila Qu (00:52:04):
Yeah.

Lenny (00:52:05):
Cool. And so the question, basically, a founder or product team has to decide is which of these three buckets do they go in on when they're trying to add product growth, acquisition, activation or conversion?

Hila Qu (00:52:16):
Mm-hmm. Mm-hmm.

Lenny (00:52:17):
It'd be cool, maybe just one example of each of these three buckets, like what's a product that did a good job here? And then you also talked about how to know which one to start with. Maybe just again, just a quick summary of you should probably start activation if this, if you have something like that?

Hila Qu (00:52:32):
You should probably start with activation. Activation is actually a common good starting place for most B2B software.

Lenny (00:52:32):
Awesome.

Hila Qu (00:52:40):
Because usually B2B softwares are not designed to really get you to use quickly, historically. A good example, there are, I think, all the best PLG companies, they do a awesome job. That's almost like my criteria to say whether this is a great PLG product or not. Think about Miro, as an example. If you go through their activation experience and sign up to usage, they ask very limited questions, very targeted. They drop you, kind of, they ask you about your use case, what are you here for? Are here to do a brainstorm session? Are you here to develop a roadmap? And they quickly gave you templates to get started. Just like in maybe five minutes, you finish the entire journey from go to the website and sign up, answer a few questions, and you are already using the template they provided to do the thing you want to do. That's time to value. That's a success. I think that's a really great standard for all the PLG, like a B2B product, try to follow. So that's activation is usually a good place. If you don't know where to start, do that.

(00:53:54):
And then conversion, I would say, is a place, again, worth investing, but there are two layers. One is the self-check-hub flow, just do some experiments there. You can actually go to any E-commerce website, like, I don't know, go to Lululemon, go to Amazon, make your conversion process as easy as theirs. That should be your goal. The consumers shouldn't be confused about complicated pricing, where to find all of that, so that's a place always worth investing, testing more, because that's revenue so close to be added into your book.

(00:54:39):
And then the PQL/PQA part, the other more-complicated path, I would say that's something you want to figure out activation and self-checkout a little bit, and you want to have some reasonable user number and then invest there, otherwise it can be a little bit jumping too fast and jumping too ahead. And the acquisition, a product-led acquisition is a great place to invest, if you have a collaboration workflow, you have some inherent, internal viral components in your products. Think about Figma, think about Calendarly even, right? It can spread. This product is so easy. You can build something to allow it to spread on its own.

Lenny (00:55:24):
Okay. I'm hoping that was really helpful, because I think a lot of people are like where do I start, what do I do to help start moving down this road of product growth? And what I'm hearing generally is just activation is probably where you want to focus, which is essentially getting people to your value quicker. And what's cool about that, and we had a podcast with Lauryn Isford from formerly Airtable, now at Notion, talking about all the ways to do that. And interestingly, one of the biggest levers for retention, and moving retention, is often onboarding and improving activation, so win-win.

Hila Qu (00:56:00):
Yeah, definitely. And I could talk a little bit about retention expansion, if you think that's helpful as well?

Lenny (00:56:00):
Sure, let's do that here.

Hila Qu (00:56:08):
Yeah, I know that I didn't talk about that in the post, and there are people asking, hey, do you plan to write another post on this specific topic? So the reason why I didn't cover too much retention expansion is, as you mentioned, it's not usually a first place to start. I call retention the messy middle. It's actually a messy part of the entire funnel. A quick activation, conversion, those are fast. Those are almost sometimes shorter time span, right? You have a lot of never, and you can test very quickly, and that acquisition is a very big leverage. You need to get more users, always.

(00:56:48):
Retention is super important, but it's a little bit messy. It's over a very long period of time, and your customers can be, at any given moment, they can be retained or not, like if they just cancel or they just decided not to use anymore, you already lost them, so it's a very messy part. But how I think about retention, there are two steps. One is how to build a habit in their usage pattern, so that they are using this maybe every week, every day. The key to do that is, first of all, your product need to have a high enough frequency. If you are using this once per month, it's not likely you can build this into a habit.

(00:57:39):
Before GitLab, I worked at Acorns. We started as an investment app, and the whole thing is passive investment, passive investing. You bought some ETFs, and then you basically don't even need to check, and you just keep adding money and it will grow, and after 10 years is awesome. It's actually the right investment philosophy, but when I worked as a head of growth, it made a big challenge for me, because think about set and forget it. They don't even need to go back to a product to be successful. And that make it very hard, as a head of growth, to drive engagement, drive retention. I don't even know whether they're retained or not, if they are not coming back, right? I can only gauge from other indicators. So I think one thing I would say about building habit is think about how to build those habit feature or collaboration feature into your workflow already, into the product already. That is the reason they can retain, fundamentally, if it's high frequency, if it involves collaboration with other people, if it's part of their workflow. So that's the first step. You can obviously use a lot of the looks to reinforce that. You can send them an email if they take certain action, and get them back, and to repeat that action, but fundamentally you need to build that into your product.

(00:59:09):
And then the next part around retention is I actually think extension is part of retention. Basically you already have a steady usage flow. You are using this habitually every week, every day. What are the right moment to prompt you to think about maybe buying more? And there are three buckets of product-led extension. The first one is up upgrade to a higher tier. The second one is buying more seeds, buying more license. The third one is if you have some sort of a consumption add-on component, just consuming more, right? Like for GitLab, you can go from bronze tier to a silver tier, you can go to a higher tier, and then you can buy more seeds, and you can also buy more CSCD minutes to consume. Those are all the different moments. How you can do that is really understand data, understand usage, and trigger a lot of the right conversation at the right moment to the right person.

(01:00:17):
And you can, again, a lot of similar tactics you use in activation conversion actually can be beautifully applied in expansion, because it's almost a combination of getting people to the aha of that feature, use that feature, try that feature, getting them to convert.

Lenny (01:00:34):
You're leaving all these gold bricks that I have to resist not following and getting off track with, because there's so much, and like retention is its own conversation. We could have maybe just one question along those lines. What's something that you've launched that had a tremendous impact on retention? Is there an example of just like, wow, that really had a big impact, you talk about frequency maybe, but what comes to mind?

Hila Qu (01:00:56):
I can share some of my example at a course my-

Lenny (01:00:59):
Yeah.

Hila Qu (01:01:00):
I think there are two things. One thing is actually very similar to what you just said. When I was asked to work on retention, I did a bunch of analysis. The biggest leverage for me is actually activation. So I ended up doing tons of experiments in activation. I identified what are the features for users to take experience value quickly so that they are more likely to retain. For us, it's a feature called recurring investment, which makes sense in hindsight, but at that time nobody's caring about that. We have some other very cool investment features called roundup investment, so nobody is really paying a lot of a attention on this, but when I look at data, I saw recurring investment has a high correlation with retention. So I did a lot of work trying to get more people to set this up, and which has been a great success, actually, in a very short period of time.

(01:01:58):
And then from there, I would say we begin to add more use cases that has a higher frequency, like I mentioned, right? If you only come here once per month to check our investment, it's very hard to retain you. We don't have any lever to engagement with you as well, if you are not in the product. So we ended up adding IRA account, retirement account. We ended up adding spending account, like a debit card, like more high-frequency use cases. Those use cases come with higher frequency and better retention by nature, so now you change the problem from how do I improve retention to how do I drive adoption of higher-frequency use cases? So I did, again, a bunch of experiments how to drive more adoption of retirement account. Once you have a retirement account, an IRA, there's tax consequences, all of that. There it's very hard for you to leave. So you flip the question into, again, adoption/activation problem in that case as well.

Lenny (01:03:04):
Amazing. Thank you for sharing those. Oh man, there's so many other things we could talk about retention, but we have enough to talk about on product-led growth. So there's two other areas that I want to touch on. One is data and infrastructure, and what people should know about how to set that up for success, and the other is hiring your team, and how to build out your product-led growth team. So starting with the data piece, maybe just as a big picture, just like what are the buckets of data and infrastructure people should be thinking about that they're going to have to invest in or should start thinking about early?

Hila Qu (01:03:36):
I think there are two big buckets. The first bucket is product usage data. As I mentioned, a lot of B2B software, they're really lacking in that, because when you sell via sales team, you don't need to know so many details, so granular usage data, all of that. The second bucket is I call this customer 360 database, because product usage data is one component, is the most essential. In order for your product-led gross motion to be successful, you also need to connect that with your marketing teams, marketing campaigns, your CRM, your sales force, who are the customers, prospects, what their stage. So those ideally need to be connected so that you have a 360 picture of your customer. If I have an Airbnb as a potential, like a target account, do I know there are users from Airbnb that are using my product, which features are they using, and do I send any marketing campaigns to each of them, do they respond, all of that. All of those ideally need to be connected, but in reality is all over the place. It's all in its own tools in most of the B2B companies.

Lenny (01:04:57):
What are just some tools that you think people should check out, start with maybe? What's Hila's recommendations on an initial stack or areas to explore, in terms of tooling?

Hila Qu (01:05:08):
I say there are two piece. One is infra, the other piece are some tools that are kind of secondary. So from infrastructure perspective, on data tool, my first tool usually, one is some sort of data hub segment, right? This next one is some sort of a product analytics tool. Think about Amplitude. I know PostHog is actually a pretty popular one. It's an open-source product analytics tool. There are Mixpanel, Pandle, all of that. So have some sort of data hub, data collection tool, and have some sort of product analytics tool. That's the data infrastructure.

(01:05:49):
And then you need to have an experimentation tool because, like I said, you cannot just imagine you build everything and everything works perfectly. So you need either like Optimizely, I know Amplitude has some experimentation components. Eppo is a new and upcoming one. You need some tool to allow you to do experimentation.

(01:06:12):
The third piece I think that's pretty essential, I counted in the infra, is some sort of a lifecycle marketing tool. I know many B2B companies, they use HubSpot or they use something for their email marketing, but those are usually least nurturing. And it's very different from lifecycle marketing tool, meaning you need to connect with Segment, Amplitude. You know what customers are doing your product, your design, your email, your in-app, your push notification, based on their behavior, at the right moment, to the right person. And you measure success by do they take the right action in a product, versus the lead nurture email marketing tool is do I get them to read the article, open the email, I add 10 points to their lead score, and they are a next step further in their list funnel? So, data tool, experimentation tool, lifecycle marketing tool, those are the infra.

(01:07:10):
And then from there, there are a lot of PLD tools you can add on top to make your day-to-day much easier. Just to start, as so like that are most essential for acquisition, you need to have some sort of a like a data enrichment tool. Think about ZoomInfo, Clearbit, because the biggest difference between B2B and B2C is that you still need to know about their company. You want to know this person, but you also want to know this person's company, right? That's a very important thing, and you can get a lot out of those data enrichment tool, and then you can design your journey differently based on that.

(01:07:52):
For activation, a lot of my clients are finding a lot of value in those tools like Appcues, User-Led, basically the tools that allow you to build onboarding flow quickly in a product without engineer kind of resource. So you need to do some initial integration, but as soon as you did that a marketing manager, a PM or someone, can just build some customized onboarding step-by-step flows himself. I think that's quite neat, because you need to test the tongue in that area.

(01:08:27):
And in terms of conversion, I would say there are many product-led growth, product-led sales tools. I think those are great. If you want to build out your PQL/PQA conversion pass, think about Endgame, Pocus, Tableau and Pace. There are a couple of them.

Lenny (01:08:47):
Wow. Amazing. That was an awesome list and really well-structured. Is there anything else along the data or infrastructure piece that you want to touch on before we move on to hiring and the team?

Hila Qu (01:08:59):
I just want to go back to the point, as I mentioned, product-led growth is data-led growth deep down. So in most of the situation when I see a company want to get started, where they are really missing or they need to invest more, is data. So if you identify you have a gap in this area, don't feel bad as well. A lot of pretty big companies are in the same shoes, and if you can't invest the time, money, the team, the tool, to figure this out, the benefit of this, right, the data collection, understanding usage data, can not only power your PLG motion, it can really power your entire product team, even your customer success team. Now you gave them the ingredients they need to develop the next feature, based on not only what your top customer asked for, but also what everybody's using, right?

(01:09:59):
Your customer success team can take a much deeper view in understanding what the clients are using, rather than just talk with the executives from the client and get a rough gauge of the situation. So I think it is a area worth investing, and every B2B company should be investing in.

Lenny (01:10:21):
I'm trying to channel what listeners might be thinking right now, and I imagine some people might be like what if I pick the wrong tool? I'm kind of stressed, I have to do all this research. I'm kind of worried about starting, because it'll set me up for failure later. Which of these buckets do you think is most important to get right, right from the beginning, and any advice on how to just avoid messing that up?

Hila Qu (01:10:41):
To get started, I would say probably a product analytics tool is the first step, and maybe the data hub, such as Segment. So if you have Segment and particle tools like that, it allows you to plug into so many different tools. You can basically try all the different tools, and if it doesn't work, you just flip a switch, you can try another tool. So there is a benefit there, but it is expensive, so I know companies may just go right into the product analytics tool. I would say it's hard to get it wrong completely, right?

(01:11:19):
In order for a product analytics tool to be meaningful, the first step is you need to collect the data, you need to do some instrumentation, you need to have the foundation. And then, because it's garbage in, garbage out, if you send a bunch of garbage data into your product analytics tool, your analyst will be just even more confusing, right? It's like he doesn't know whether to trust the data, what to use. So a lot of company I work with, the first step is maybe not looking into tool, but do an audit of your data instrumentation situation, to understand how many of the key actions are intact, is the format correct, is the data, what are the gaps? And you may need to do some re-instrumenta ...

Hila Qu (01:12:00):
Right, what are the gaps? And you may need to do some reinstrumentation, reformatting and things like that before you even plug into a product analytics to make it useful.

Lenny (01:12:10):
For someone that may want to do that audit, is there a thing you would point them to, or, I don't know, a blog, a course, something to help them understand if they're doing it right? Or is it like, "Bring Hila on," and you need someone like you to kind of help them through it?

Hila Qu (01:12:24):
No, you can bring me, but you don't have to bring me. I think there are, if you search on Google just the data dictionary, or data product usage, data audit, a lot of companies published template and spreadsheet you can use. I can even send you a few afterwards.

Lenny (01:12:43):
That'd be amazing.

Hila Qu (01:12:44):
And then you can just scroll through. Basically the key idea is go through your product experience, identify the key actions, and go through your data instrumentation and see, "Do they match?"

(01:12:57):
And the success of this is you identify the gaps and eventually you want to establish something called the data dictionary. I basically do that for a lot of my clients. And the data dictionary will include, here are all the key actions, what's the event name for each of those, and what are the property and things like that.

(01:13:17):
But you now know, "Hey, I have this action track, this is the name. If I have a new product manager or analyst, we can all refer to this." And everyone know the same definition rather than people are interpreting differently. So that's a very important part to success even before the tooling.

Lenny (01:13:39):
Awesome. It also reminds me a previous guest, Crystal Widjaja, has a awesome post on why most analytics efforts fail. And she talks a lot about this, of how to set your events up for success. So we'll link to that as well.

Hila Qu (01:13:50):
Mm-hm.

Lenny (01:13:51):
Maybe one last thing here, I'm trying to think about what would screw people up most, and it's probably not having a data warehouse and ETL sorts of tooling in place, because that feeds a lot of this.

Hila Qu (01:13:51):
Yep.

Lenny (01:14:01):
Is there anything you want to add there about just the importance of a data warehouse and how to set that up?

Hila Qu (01:14:06):
Some of the early stage companies I work with, when they just get started in the very beginning, they don't have data warehouse. They just basically have their product and they have some sort of a Google Analytics or Amplitude, and that's it. It's pretty wild, but it's working and they can get to someplace from there.

(01:14:25):
But as soon as you begin to have data user, it's time to get serious to establish a data warehouse, have some ETL solution. I think there are the most common best practice ones, like AWS and things like that. There are also some startups that are doing this and you can utilize as well.

(01:14:49):
But again, as soon as you become a serious business, you should invest in that. Otherwise, it's pretty wild and it's pretty fragile as well.

Lenny (01:14:59):
And when you say AWS, you mean at Redshift, I imagine?

Hila Qu (01:15:01):
Yeah.

Lenny (01:15:02):
Cool. Awesome. Okay, final area that we have time for, which is awesome, which is around building your team. So maybe just two questions here. What is your advice for starting the initial team investing in PLG? How does that usually look and what do you think people should do? And then later, how does that evolve over time?

Hila Qu (01:15:21):
How I see most companies started is the founder or the leadership team realize that they need to do PLG. And they build a conviction. Maybe initially there isn't even a dedicated team, but they did something here and there, they decided to invest in this.

(01:15:40):
And the common place to start is to hire a head of growth, or it can be a lead growth PM, but someone who has a little bit of experience in this area. And then they begin to build this core growth squad as the first growth team. And I think that's a very common place to start.

(01:16:01):
The other place to start that's less common, but I also think it happening in reality, is maybe they will start a cross-functional, almost like a tiger team. Because if the initial focus area is, let's say, they want to do a product qualified lead, or basically add that funnel. That involves not only product team, that will involve data team because you want to know what are the usage pattern that indicate these is better leads. You also need to bring sales team in because they need to work on those leads to close them.

(01:16:39):
So if that's the initial starting area, a cross-functional tiger team is also possible option. But the most common way is hire a head of growth, usually a growth PM, and then start a team with engineering, design, data to support that core growth squad.

Lenny (01:17:00):
And the main difference between these two. One is dedicated, "We are going to dedicate full-time people to helping us grow." Like I say we talked about earlier, let's say they're going to focus on activation and that's their whole job. Versus tiger team is basically they're borrowing resources from other teams and this is kind of a side project for them.

Hila Qu (01:17:18):
Yeah. A little bit, for a period of time. So it's temporary. It's kind of they almost to want to get into... I would say usually the cross-functional team, the tiger team, is a little bit prior to a full commitment. They're pretty much committed, but they still want to try this out and get a final conviction, and then they begin to dedicate resources.

(01:17:43):
And you ask about how do they evolve from there.

Lenny (01:17:46):
Before we actually get there, maybe one more quick question. Which would you recommend? I imagine you'd recommend a dedicated team, if you can do that.

Hila Qu (01:17:54):
Mm-hm.

Lenny (01:17:55):
When would it make sense to go the tiger team route? In what cases?

Hila Qu (01:17:59):
One situation I would recommend is that if the initial focus area is, like I said, product qualified leads, the sales conversion path. Because if you think about you have a head of growth or a core growth PM, that person usually has a growth PM background and is in the product organization. And they're awesome if the initial focus areas are activation, conversion, those kind of involve a lot of experimentation. But activation and conversion are relatively confined, it's something the growth PM and engineer design data, they can work on.

(01:18:39):
If your initial focus area you felt like, "My biggest bit is actually do this PQL thing," it is a little bit harder for the growth PM to socialize all those cross-functional resources, because he need to get pretty deep into data. He need to have a counterpart in sales, even in marketing. So in that case, I think it's possible that maybe you start a tiger team.

(01:19:03):
You can combine both. You can have a growth PM dedicated, but have some tiger team to be working with him or her on this PQL project as well.

Lenny (01:19:14):
Got it. And I like this term tiger team, by the way. I haven't heard that before. It sounds like a lot of fun. Very dynamic. Okay, cool. And then yeah, what happens next after you have this initial team?

Hila Qu (01:19:24):
Once you have this initial team, it's important to give them the resources they need, and give them an initial focus area, give them support and a little bit time, allow them to try things out and get some early wins. And early win is the biggest thing I would say for, and whenever you start a new growth team, try to look for some opportunity, try to get some early wins in whichever focus area you choose.

(01:19:53):
And from there, if you get some of the wins, the team has some momentum, there are more confidence from the organization in PLG, right? It's time to potentially extend and formalize. So fundamentally I think you should not only think about the PLG team, you should think about the PLG org. Because PLG is a motion, it's cross-functional by nature, it's not just a product team or growth team.

(01:20:24):
Eventually you need to get to the place basically there is a head of growth product, that's the center of the PLG org. But there's also need to be a head of growth marketing, that's his or her counterpart in marketing organization. And then a head of product led sales, that's the counterpart in the sales organization.

(01:20:47):
Exactly where they sit, how they sit, it's different company by company. The most common one is head of growth product report to product org, head of growth marketing report to marketing, head of product led sales report to sales. But they have some sort of a very strong collaboration, because they are working in the same motion and same funnel. But I think that's next step, think about this org.

(01:21:11):
Once you have those counterparts in product, in sales, in marketing, the next step is think about what are the metrics they own to make sure you can manage this funnel, this motion, in the data-driven way. Because the PLG metrics are very different from SLG. The top of funnel is more about high quality signups. You don't want a lot of traffic, you want free signup, free trials. But it need to meet certain quality bar, it's not just anyone.

(01:21:46):
And then the head of growth product, he or her top KPI is about usage, activation. Activated teams is a very common metric. And then maybe number of PQLs, that's another. You want to get those teams to certain usage threshold basically.

(01:22:07):
And then the head of product led sales, he will be focused on converting those PQLs into revenue. So he will focus a lot on conversion rate, efficiency and maybe revenue, things like that.

Lenny (01:22:23):
Got it. And you're sharing a lot of org design verbally in the post, which we'll share obviously in the show notes. You can actually see a diagram of what these look like, to help kind of make it super clear.

(01:22:36):
I have maybe just one more question. Going back to the initial team, what are the functions you recommend they have on this like MVP PLG team?

Hila Qu (01:22:45):
The most important one is have a growth PM to be the lead, right? Head of growth, director of growth, lead growth PM. And then the growth PM, as you know probably very well, growth PM, he is a PM but has a much stronger skill set in analytics, experimentation, very data-driven. Think about metrics.

(01:23:06):
The growth PM's way of working is similar to other product manager, but his KPIs is actually more similar to the sales and marketing work. He's very focused on the conversion rate, the journey, the funnel versus the feature specifically itself.

(01:23:23):
And then the other functions you need to have for sure, I would often say actually a data analyst needs to be the very first hire. Sometimes even try to find a growth PM who can do analysis if you're really small, you can find that type of unicorn person.

(01:23:43):
Or even before hiring growth PM, hiring analyst, I would actually go as far as that. Because without insight, without a lot of foundation, your experimentation, your effort is really directionless in a sense.

(01:23:58):
So growth PM, analyst. And from there definitely you need some dedicated engineer, you need a designer. Designer can be somewhat not dedicated in early days, but engineer needs to be. Some sort of user research support as well, it doesn't need to be dedicated. But those are the core growth squad.

Lenny (01:24:18):
Okay. Real actual last question here for the growth PM. In your experience, are they most often coming from within the company already and they kind of shift to this role? Or do you recommend they find someone externally?

Hila Qu (01:24:30):
That's an excellent question. I have seen both. I actually recommend if you can find someone internally, maybe he's a PM, he want to do growth. Or he is an analyst who want to become more like a product role.

(01:24:48):
I even have a one client, the head of growth I work with used to be a investor relationship, like head of investor relationship. And he reports to the CEO and founder. He's very analytical. He hasn't been a PM before, but he can socialize the resource within the company to launch experiments in product, in marketing, in all of that. And I, as an advisor, will come in, guide him in the area he's not familiar with. And we actually drive pretty good results together.

(01:25:20):
So I think prefer hiring internally if possible. If not, if you really don't have anyone internally with that knowledge or with that interest, you can look outside. I would say map the initial growth PM hire to your starting point. If we already decided activation is the biggest focus area, try to find some growth PM with that experience. And if the conversion is a focus area, acquisition is the focus area, try to find someone with that experience.

Lenny (01:25:54):
I love that advice. We've reached our very exciting lightning round. I've got actually seven questions for you, the most ever we've had for a lightning round. Are you ready?

Hila Qu (01:26:04):
I'm ready.

Lenny (01:26:06):
Okay. What are two or three books that you've recommended most to other people?

Hila Qu (01:26:10):
This first one is called The Almanack Of Naval. Yeah, I don't know whether we read that one. I really love that one. That's kind of a life-changing book for me. I have it-

Lenny (01:26:22):
Do you have a favorite Naval-ism that comes to mind?

Hila Qu (01:26:26):
I learned finding leverage from him. He talked about there are four type of leverage. It can be your writing, it can be code, it can be capital, it can be team. So the reason why I invest a lot in writing is I felt like that's my leverage. And I love that.

(01:26:44):
The second book is called How Women Rise. I really love this one. I gifted this to a lot of my female team member and I really learned a lot from them.

(01:26:56):
And the third one is my book, it's called [Chinese 01:27:01]. It's only in Chinese, if you don't read Chinese you cannot read it. But I heard, my friends told me, if you are launching an email campaign, if you're doing experiments, have this book by the side, it will help with conversion rate just by its appearance.

Lenny (01:27:18):
That's amazing. Is there an English translation or is it only in Chinese right now?

Hila Qu (01:27:22):
It's only in Chinese, so you have to learn.

Lenny (01:27:25):
All right, I see. All right. There's an advantage there, if you can speak Chinese your email conversion will go up.

Hila Qu (01:27:29):
Yes.

Lenny (01:27:30):
And then just to the first book, it was called The Almanack Of Naval, right?

Hila Qu (01:27:34):
Okay.

Lenny (01:27:35):
Is that right?

Hila Qu (01:27:35):
Yes, yes.

Lenny (01:27:36):
Okay, cool. Sweet. And we'll link to all these. Okay, favorite recent movie or TV show?

Hila Qu (01:27:41):
I watched a movie, it's a sci-fi movie from China, it's called The Wandering Earth 2. It's by the famous author, Cixin Liu. He's the author of Three Bodies. I don't know whether you heard of it?

Lenny (01:27:53):
Mm-hm. Oh my God, love that.

Hila Qu (01:27:54):
That movie is awesome. It's kind of really cool. I really highly recommend it.

Lenny (01:28:00):
I have to go check that out. Oh my God. I heard they're bringing Three Body Problem to Apple TV or Netflix. There's like a show coming.

Hila Qu (01:28:06):
Yes, yes. I look forward to that as well. I watched many versions already kind of film, none of them are good. So-

Lenny (01:28:17):
That's the problem it's so hard to do well. Oh man, I'm not optimistic, but I'm excited anyway.

Hila Qu (01:28:21):
Yeah, yeah.

Lenny (01:28:22):
Favorite interview question that you like to ask.

Hila Qu (01:28:24):
When I interview a growth PM or analyst, I will always ask, "What is a experiment you launched that has a very unexpected result? And what did you do after that?"

Lenny (01:28:37):
What do you look for in an answer there that makes you feel like they are strong?

Hila Qu (01:28:41):
So first of all, they have to be launching a lot of experiments to get very unexpected answer. So if you are only... Many people remember their success for the interview, they prepare that very well. I don't want to ask, "What's your successful experiment?"

(01:28:58):
Secondly, I want to know just why it's unexpected. That reveals the deep, deep level of their thinking, how deep they are thinking. If they should expect that based on what they described, then they are not thinking deep enough, they are not understanding customer enough.

(01:29:15):
And what they do afterwards is also awesome. Like, "How do you face a failure or unexpected result? What are the clues you can pursue? What are the actions you can take? How do you learn something out of it?"

Lenny (01:29:28):
I love it. What's a favorite recent product you've recently discovered that you love?

Hila Qu (01:29:33):
I would say, similar to everyone, ChatGPT. But also Lululemon yoga pants.

Lenny (01:29:43):
Amazing. Great. What's something relatively minor you've changed in your product development process that has had a tremendous impact on a team's ability to execute?

Hila Qu (01:29:51):
Yeah. At first I added basically a section in the dock, in the ticket stack. Ask the PMs to write the success metric ahead of time. As well as adding which of the growth lever this is helping. Is this contributing to acquisition, activation, retention, monetization? And it forced them to sometimes think through deeply, "Why are we even doing this?" Sometimes they ended up not doing that by just writing it down.

Lenny (01:30:23):
I love that. Next question. I know you're big on children's books, do you have a favorite children's book?

Hila Qu (01:30:29):
My favorite children's book is called Someday, and I recommend everyone to check it out. And basically it's talking about how our children used to be our baby, become our kids, and when they are taller and more stronger than us and they will remember us.

Lenny (01:30:51):
I'm going to need to check that out now. And final question. I know you're big on growth concepts, you have all these frameworks and concepts. And so what is your favorite growth concept?

Hila Qu (01:31:02):
I would say north star metric, because I find it's not only valuable to growth, it's valuable to just everything.

(01:31:10):
When I think about what do I want to do with my career, does that fit my own personal north star metric? When I think about how I want to raise my kids, I think about what's the north star metric for successful education for my kid?

(01:31:27):
Because it forced me to think long term. It forced me to think about what's valuable to me, to them, not only by the society standards, ARR revenue, like salary. And also what's my vision for myself and for my kids.

Lenny (01:31:43):
I love that. It reminds me of a recent guest where she always asks, "What are you optimizing for?" Whether she's talking with her kids or her husband or her team, and it's a similar concept.

(01:31:54):
Hila, this was incredible. I think we've shared tens of thousands of dollars of value, and it will probably lead to millions of dollars of revenue for a lot of companies. And it's everything I hoped it would be. Thank you so much for being here and for sharing so much wisdom.

(01:32:08):
Two final questions. Where can folks find you online if they want to reach out and learn more? And how can listeners be useful to you?

Hila Qu (01:32:15):
Yeah, they can find me on LinkedIn. Just search Hila Qu, H-I-L-A Q-U. You can find me. I have a personal website that's under development, but I contracted it to my kid, to my 12-year-old. So he need to wait until summer and hopefully this summer he can finish it.

(01:32:32):
Yeah, if you are a founder, you are looking for a growth advisor, feel free to hit me up. I'm always happy to just have a call with founders and leaders, get to know more people. And I'm a growth nerd, so I always want to nerd about growth anyway.

Lenny (01:32:51):
Amazing. Hila, again, thank you so much for being here.

Hila Qu (01:32:54):
Thank you.

Lenny (01:32:55):
Bye, everyone.

Hila Qu (01:32:56):
Bye.

Lenny (01:32:59):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcast, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review, as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## How we restructured Airtable's entire org for AI | Howie Liu (co-founder and CEO)
**Guest:** Howie Liu  
**Published:** 2025-08-31  
**YouTube:** https://www.youtube.com/watch?v=GT0jtVjRy2E  
**Tags:** growth, acquisition, onboarding, roadmap, user research, iteration, experimentation, analytics, funnel, conversion  

# How we restructured Airtable's entire org for AI | Howie Liu (co-founder and CEO)

## Transcript

Howie Liu (00:00:00):
If you were literally founding a new company from scratch with the same mission, how would you execute on that mission using a fully AI native approach? If you can't, then you should find a buyer and then if you really care about this mission, go and start the next carnation of it.

Lenny Rachitsky (00:00:12):
Or people that work for you, how have you adjusted what you expect of them to help them be successful?

Howie Liu (00:00:18):
If you want to cancel all your meetings for like a day or for an entire week and just go play around with every AI product you think could be relevant to Airtable, go do it.

Lenny Rachitsky (00:00:27):
Of the different functions on our product team PM, engineering design, who has had the most success being more productive with these tools?

Howie Liu (00:00:33):
It really does become more about individual attitude. There's a strong advantage to any of those three roles who can kind of cross over into the other two. As a PM, you need to start looking more like a hybrid PM prototyper, who has some good design sensibilities?

Lenny Rachitsky (00:00:49):
Do you see one of these roles being more in trouble than others? Today, my guest is Howie Liu. Howie is the co-founder and CEO of Airtable. I'm having a bunch of conversations on this podcast with founders who are reinventing their decade plus old business in this AI era, to help you navigate this existential transition that every company and product is going through right now. Howie and Airtable's journey is an incredible example of this, and there's so much to learn from what Howie shares in this conversation.

(00:01:20):
We talk about a very interesting trend that I've noticed that Howie is very much an example of, of CEOs almost becoming individual contributors again, getting into the code, building things, leading initiatives themselves. That's something that we call the IC CEO. We also talk about the very specific skills that he believes product managers and product leaders, also engineers and designers need to build to do well in this new world that we're in. Also, how he restructured his company into two groups, a fast thinking group, and a slow thinking group, which allowed their AI investments to significantly accelerate.

(00:01:52):
If you're struggling to figure out how to be successful in this new AI era, this episode is for you. If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. Also, if you become an annual subscriber of my newsletter, you get a year free of 15 incredible products, including Lovable, Replit, Bolt and Adyen, Linear, Superhuman, Descript, Wispr Flow, Gamma, Perplexity, Warp, Granola, Magic Patterns, Raycast, ChatPRD and Mobit. Check it out at lennysnewsletter.com and click product pass. With that, I bring you Howie Liu.

(00:02:23):
This episode is brought to you by Lucidlink, the storage collaboration platform. You've built a great product, but how you show it through video design and storytelling is what brings it to life. If your team works with large media files, videos, design assets, layered project files, you know how painful it can be to stay organized across locations. Files live in different places. You're constantly asking, is this the latest version? Creative work slows down while people wait for files to transfer.

(00:02:49):
Lucidlink fixes this. It gives your team a shared space in the cloud that works like a local drive. Files are instantly accessible from anywhere. No downloading, no syncing, and always up to date. That means producers, editors, designers, and marketers can open massive files in their native apps, work directly from the cloud, and stay aligned wherever they are. Teams at Adobe, Shopify and top creative agencies use LucidLink to keep their content engine running fast and smooth. Try it for free at lucidlink.com/lenny. That's L-U-C-I-D-L-I-N-K dot com slash Lenny.

(00:03:24):
Today's episode is brought to you by DX, the developer intelligence platform designed by leading researchers. To thrive in the AI era. Organizations need to adapt quickly, but many organization leaders struggle to answer pressing questions like, which tools are working, how are they being used, what's actually driving value? DX provides the data and insights that leaders need to navigate this shift. With DX, companies like Dropbox, Booking.com, Adyen, and Intercom. Get a deep understanding of how AI is providing value to their developers and what impact AI is having on engineering productivity.

(00:03:58):
To learn more, visit DX's website at getdx.com/lenny. That's getdx.com/lenny. Howie, thank you so much for being here and welcome to the podcast.

Howie Liu (00:04:14):
I'm so excited. Thank you, Lenny. I've been a listener from afar for a while now.

Lenny Rachitsky (00:04:19):
I'm really flattered to hear that. I'm also very excited. You've been on quite a journey over the last, is it 13 years, is it longer?

Howie Liu (00:04:27):
Yeah, right about 13.

Lenny Rachitsky (00:04:28):
13 years. I imagine there've been a lot of ups and a lot of downs. I want to talk about all those things. I want to talk about a lot of the lessons that you've learned along the way. I want to start with what I imagine was a very surprising down moment in the history of Airtable. This is something that, unfortunately, something I think about when I think of Airtable. I feel other people may feel this way, is there's this tweet that went super viral, maybe a couple of years ago at this point where someone just shared all this data and they're like, Airtable is dead.

(00:04:57):
They've raised way more money than they're worth. They're not making enough to get from underwater. Yeah, Airtable RIP. What happened there? How much of that was true? How did that go?

Howie Liu (00:05:06):
Yeah, so basically none of it was true. I mean, the surprising thing to me was how viral this tweet went when ... Frankly, I actually look back at this person's other tweets. I think they worked at CB Insights, and the irony is the whole point of that business is to have good data, good data quality around private company data. And they just literally had incorrect numbers by a strong multiple on what our revenue scale was, what our growth rate was. And if it gave me some consolation, I look back and this person had also tweeted about other companies, like Flexport was the last take-down tweet.

(00:05:45):
They have like, "Oh, Flexport's dead" and their evaluation is too high, and blah, blah, blah. And so, I think that the more surprising thing was just like this person has been tweeting a bunch of spicy takes that are not substantiated by real data or correct data, and yet this particular tweet went super viral and that was the perplexing part to me. And then, actually, I think what really gave it legs was on the All In podcast, which is obviously super popular. And I listened to it. They covered it. They were like, "Oh, latest on this week's news, this tweet about Airtable. What do we think about this?"

(00:06:22):
And it almost, I think became a way to talk about a broader theme of what happens to this last generation of highly valued companies, maybe decacorn companies in this new ... And at that point, it was the recent moment for both public and private markets. They did also issue a correction though. All In, did a follow-up episode, a few, I think weeks later saying, "Hey, we got the numbers wrong. We are revising our case and a view on Airtable."

Lenny Rachitsky (00:06:53):
What's that line about how a lie gets around the world some number of times before truth has even this time to get out of bed?

Howie Liu (00:07:02):
Yeah. Well, I think I learned about memes and morality very quickly in that experience. Not a very good social media person, but I think I learned a little more.

Lenny Rachitsky (00:07:10):
Yeah, it's tough. Twitter is such ... The incentives are so misaligned. It's just I tweet something people want to share, not truth.

Howie Liu (00:07:17):
Well, especially ... I mean, there's a lot to like ... I would say, I like the post Elon Twitter more than the pre Elon Twitter because it is just bolder, and I guess I really admire bold product execution where you're not just stuck to the current laurels and they've made so many changes, but I do feel like I get injected into my feed very sensational content all the time, and I mean, it works on me. I can't help but to click on it and engage with it, but it does ... I think it does result in this kind of content, really spreading.

Lenny Rachitsky (00:07:52):
Yeah. Now, Nikita running the show, I don't know if you saw this, there's a new ... We don't need to keep talking about Twitter, but there's a new feature where you take a screenshot of a tweet and it has a huge X.com logo watermark on the top, right? Yeah, just to ... People are sharing these tweets all the time. Yeah.

Howie Liu (00:08:06):
Yeah.

Lenny Rachitsky (00:08:06):
Man. Never a dull moment over there.

Howie Liu (00:08:07):
For sure.

Lenny Rachitsky (00:08:08):
Okay. I want to go in a completely different direction, something that I'm really excited to talk to you about, which is this very emerging trend that I've noticed that I feel like you're at the forefront of CEOs becoming ICs again. It's kind of this move of, IC CEOs. CEOs getting their hands dirty again, building again, getting in the weeds, coating again. I feel like you're again at the forefront of this. Talk about just why you've done this, why you think this is important, and just what that looks like day to day to you versus what your life was like a few years ago.

Howie Liu (00:08:39):
The underlying reason for this shift, at least for me, is that, as we started the company, I was very much in this mode. I was literally writing code both on the backend, thinking about the real time data architecture of our platform, also the front end, the UX. And I would argue that in that founding moment, the initial product market fit finding, and especially for a product that is pure software, we weren't building an operationally heavy business like a dog walking marketplace where the tech is only an afterthought.

(00:09:11):
The tech was the product, right? And in a very Meta sense, Airtable is the platform for other people to build their own apps. So it's all about the attack, like the very intimate design decisions, again, both architecturally and on the front end and the product UX choices. That is the product's value prop. You can't separate those two. You can't say, "Okay, I researched the jobs to be done. Here's the workflow, here's the process, and then, okay, some engineer can just build it as an afterthought."

(00:09:40):
It's those little decisions and really be able to be at the bleeding edge of what's possible both in the browser and with the real-time data architecture. That made the product what it was. I think the same is true for Figma, which actually had a very parallel timeline to us. We both were founded around the same time, both spent two and a half years building the product, hands-on that early team before launching. And when I think now to both the era in between that founding moment and then now as well as now the new gen AI moment, I think there was a maturing era of both SaaS overall and Airtable specifically.

(00:10:19):
Where, as you scale up and you learn how to build teams and organizations and you have to scale up stuff that's not actually those intimate details, but process and people and so on, you kind of get by default further and further away from those details, right? And maybe for some businesses that's fine because no longer is it about finding the details that make for a magical new product market fit. And it is really just about scaling up an existing thing that works and using what I would call more blunt instruments to scale it up, like a more blunt roadmap, a more blunt go-to market execution strategy.

(00:10:56):
Regardless, I think that now, we're entering this moment where ... Certainly every software product in my opinion, has to be refounded because AI is such a paradigm shift, it's not even just like the shift from desktop to mobile or on-prem to cloud where that was more like a very one time and somewhat predictable change in form factor. I think AI is so rapidly evolving that with every evolution, every new model release and every new type of capability that's released, it actually implies novel form factors and novel UX patterns to be invented to fully capitalize on those capabilities.

(00:11:36):
And so to be continuously relevant and to refine product market fit in this era, I think you have to be of the details. There is no looking at it from 10,000 foot view and saying, "Oh, we're just going to throw a bunch of people at this problem." It's actually understanding what is the right product experience and the right business model that backs it up and the right ... everything else to support that engine to take advantage of the capabilities in our product domain.

Lenny Rachitsky (00:12:07):
You have this phrase somewhere where you talk about being the chief taste maker.

Howie Liu (00:12:11):
Yeah.

Lenny Rachitsky (00:12:11):
And to do that, you have to do exactly what you're describing.

Howie Liu (00:12:14):
That's right. I mean, I think that, and I would also say it's actually now also hard to taste the soup without participating in at least some part of creating the soup. Meaning With AI, you can kind of look at the final product and say, "Okay, this feels right or not, or it feels like we're being bold enough and we're properly productizing these new capabilities." But I think to really understand the solution space of what's possible, you have to be in the details.

(00:12:46):
I mean, literally, you can't just look at screenshots or a pre-recorded video of a new product feature. AI is something you have to play with, and ideally you're playing with both the packaged up app or solution that you've built with it, but you're also playing around directly with the underlying primitives who are using the models either via API or via a chat interface. You're really pushing them to the boundaries. Because that's the only way that you really understand what these new ingredients. It's like as a chef, you just gained access to amazing new ingredients, but you have to actually get comfortable with them to put them into a new dish.

Lenny Rachitsky (00:13:23):
And we had Dan Shipper on the podcast, he runs this newsletter and podcast to product a company called Every. And they work with companies to help them become more AI successful and adopt AI and all that stuff. And I asked him, what's the signal that a company will have success adopting AI and seeing huge productivity gains? And he said, does the CEO use ChatGPT or Claude daily?

Howie Liu (00:13:48):
Yeah.

Lenny Rachitsky (00:13:49):
And I feel like you're describing exactly, hourly,

Howie Liu (00:13:51):
Literally hourly, or you could even have a measure of inference costs, right? Like the equivalent underlying inference compute cycles, right?

Lenny Rachitsky (00:14:02):
How many tokens you use?

Howie Liu (00:14:03):
Yeah, I mean, I'm proud to say I am pretty sure I'm still the ... I just checked this recently, but I take pride in being the number one most expensive in inference cost user of Airtable AI, not just within our own company, but I think for a long time I was globally across all our customers vault. I mean, I'm extremely intentionally wasteful. Wasteful in the sense of I'll do something that costs maybe hundreds of dollars of actual inference costs. For instance, doing a lot of LLM calls against long transcripts of let's say, sales calls to extract different types of insights like here's the product apps, identify or here's summaries, et cetera.

(00:14:49):
And we also have now a capability that's basically like an LLM map reduce. So effectively, even if you can't fit the entire corpus of content into one LLM call, because the context window limitations, we'll map through all of this content and break it up into chunks and then perform an LLM call on each one and then perform an aggregation LLM call on those chunks. Very expensive, because you're basically running a highly expensive model against a lot of data and then running it again on the aggregates of that. But for me, hundreds of dollars spent on this exercise is trivial compared to the potential strategic value of having better insights.

(00:15:29):
It's as if a really, really smart chief of staff has gone through and read every single sales call transcript that we've had in the past year and giving me very astute product insights, marketing insights, kind of positioning insights and segmentation insights. That's invaluable. You could pay a consulting firm literally millions of dollars to get that quality of work. So to me, I still think the value versus the actual cost of AI when applied greedily but smartly, it's a crazy ratio. And more people should be aggressively throwing compute cycles at these very high value problems.

Lenny Rachitsky (00:16:11):
Until somebody tweets how you're costing the company so much on AI compute and you guys are going to be underwater.

Howie Liu (00:16:19):
I'm just kidding. It's like how we have personally taken down the cashflow profile of the business.

Lenny Rachitsky (00:16:27):
So CEO's, founders hearing this, they're probably like, okay, I should probably start doing this. What does this actually look like? I imagine you still have a lot of other stuff you got going on once, you got all these ... How do you change your day to day to do this?

Howie Liu (00:16:41):
Yeah, so I actually cut my one-on-one roster by default, and the idea is not that I don't want to spend time one-on-one with people, but rather that I found that the ... Just having more standing one-on-ones actually precludes me from engaging in more timely topics. I like to think of the best types of meetings as very urgency driven. And there's some timely topic, you've discovered some insight. Maybe I talked to some new startup and I learned something from their product or their approach.

(00:17:20):
And I want to bring that into how we're thinking about a new feature at Airtable or even just plant the seed with some different EPD people within Airtable, I want to make most meetings very timely and very informed by real alpha. There's got to be some kind of value and insight to seed that with. Now, in addition to that, I'll supplement with, when I'm in person with someone, I want to carve out time for a proper catch up and less structured, less timely, and just more of building a relationship with a human.

(00:17:53):
But I actually find that having that common .. It's almost a barbell approach where it's like if you're going to spend time with somebody in a freeform way, actually do it in a high quality, not forced weekly ritual way. Go for a longer lunch or coffee walk or whatever in person when you can. Maybe that's a once every month or two kind of thing. And then the in-betweens are either topical, so we do have standing meetings for ... Now, we have a weekly basically sprint check-in on all of our AI execution stuff, which now is half the company or half the EPD org is working on AI capabilities.

(00:18:29):
We're trying to ship very quickly, like I basically want to always ask the question, how would an AI native company, like a cursor or windsurf, et cetera, how would they execute? And are we executing as fast as them and taking advantage of all the new stuff as well as them? So bringing that level of intensity and urgency to how I spend my time within, that's been the biggest shift for me.

Lenny Rachitsky (00:18:55):
What's a change you've made to help the company move faster and match that sort of pace?

Howie Liu (00:19:01):
Yeah. I mean, we did do a reorg of the EPD org. So before we had ... we've gone through a few different reorgs over the past, call it, four years. The original state as we just proliferated, I think by default or incrementally, was that we had a bunch of groups that were each responsible for a feature or a surface area. So there was a group responsible for search within our table, and there was a group responsible for mobile experience and so on and so forth. And that has its benefits. Obviously, that team can go and get really ramped up on that part of the code base, that part of the product.

(00:19:36):
But it has the disadvantage of yeah, you tend to think incrementally when everyone's remit is actually a feature that they incrementally improve by definition as opposed to thinking about a mission or a outcome goal that might need to coordinate dramatic changes across a wider set of surface areas instead of just each one incrementally improving. And so, we reorged initially to basically different business units effectively. So I know Airbnb has done the functional to GM back, et cetera. This was more like saying, "Look, we have an enterprise business" and them MO there is more about scalability.

(00:20:19):
Can we support the larger scale data sets and use cases? Do you have the core capabilities needed to be able to push out an app to maybe 10,000 seats or 20,000 seats for product operations? A lot of architecture, a lot of scale, that kind of work. We would have, what we call the teams filler, which is more about self-serve, kind of the product UX, how easy it is to adopt the product on board, share, do all the kind of basic functionality. An AI pillar, solutions pillar, and basically infra. And what we found though with that approach is that there was still ... there was more kind of holistic bets being made.

(00:20:58):
So the team's pillar could think not just about one feature, but the overall onboarding experience where really about Nuxt in a way that touched multiple parts of the product, but it still felt like it wasn't ... Especially as we started to execute more on AI stuff, it wasn't allowing us to aggressively and quickly move as a AI native company would. I mean, when you look at the cursors of the world, they're shipping major new stuff every week. And it's not like, "Oh, well we have this separate roadmap for enterprise, we have this roadmap for this group."

(00:21:33):
And it just feels like one cohesive product that's shipping at a breakneck pace. So we did this recent reorg where now we have what I call the fast thinking group, which officially is called AI platform, but it really means we want to just ship a bunch of new capabilities on a near weekly basis. And each of them should be truly awesome value. You should drop your jaw, how awesome it is to use this new capability in Airtable. And then separately, we have the slow thinking group, and that's not meant to be better or worse. It's literally like you need fast and slow thinking in the common sense to operate as a human.

Lenny Rachitsky (00:22:12):
I have that book behind me.

Howie Liu (00:22:14):
Yeah, I love that book. But slow thinking it's like, it's just a different mode of planning and executing, right? It's like more deliberate that require more premeditation. We can't just ship a new piece of infrastructure that has a lot of data complexity like our data store HyperDB that now can handle multi-hundred million record data sets. That's not something you ship in a week in a hacky prototype. So we now have these two separate parts of the company, and I actually think what's really cool is they actually compliment each other very well, right?

(00:22:46):
Because the fast execution, the AI stuff, that creates the top of funnel excitement that also inspires new use cases and new users to come to Airtable, including in large enterprise, right? Enterprises can use this stuff too. It's not just like a SMB thing, but the slow thinking basically allows those initial seeds of adoption to Sprout and grow into much larger deployments. Whereas I think a lot of the challenge for many of the AI native companies I've seen is that they could have a very wide top of funnel, like get all of this AI, tourist traffic.

(00:23:19):
A lot of interest, a lot of early usage, but then sometimes the challenge is how do you turn that into more durable growth and get each of those adoption seeds to retain and expand over time.

Lenny Rachitsky (00:23:33):
That is super cool. I've never heard of this way of structuring teams, the fast thinking, thinking fast, thinking slow, the Kahneman. It's so interesting for the fast thinking team, do you find there's specific archetypes of people that are successful there? Is it a lot of bringing in new people that are not just used to the way of working at our table? What do you find?

Howie Liu (00:23:52):
We have a mix. So we brought in ... I mean, we're always hiring, right? There was never a point in the company's life where we stopped hiring. And candidly, even when we had to do two rifts, that's significantly reduced our head count. We had just way too quickly grown and overscaled the business at a certain point. But even when we did our rifts, we were still actively recruiting and hiring in ... I mean every major department, but especially in EPD, because it's always been my belief that it would be arrogant to say that we have all the people we ever need already in the roster today, right?

(00:24:29):
We're always going to need to find new, fresh perspectives, new skillsets, et cetera. And so, we've continued to hire ... I think we've learned as we've gone along of what is the ideal type of hire, and we've done some actual hires and learned from that as well. But I think the fast thinking part, it really just requires a lot of ... Somebody who's able to operate with a lot of autonomy, who's entrepreneurial in nature. Now, it doesn't mean they have to literally be a former founder. I know some companies are, like Rippling for instance, does a lot of actual acquisitions and gets actual founders into the company.

(00:25:04):
We found that that's great and we've done some of that as well. But also there are some really, really capable people who we didn't literally have to acquire in, and yet, they're just able to think full stack about the problem and the user experience. Problem, not just meaning the technical layers of the problem, but also, what is the wow factor we're trying to create. So tangibly we're doing this new thing that's about to ship, where not only can you describe the app you want to build and then iterate on it with our conversational agent Omni.

(00:25:41):
And it builds it with the existing air table platform capabilities, but we're also giving it the ability to actually do code gen, to extend those apps with really final mile very bespoke functionality or visuals. So you could say, "Hey, generate me a very, very specific type of map view with this kind of heat mapping and this kind of icons and ..."

Howie Liu (00:26:00):
It's kind of like heat mapping and this kind of icons. And when you click it, do this. And that's a capability that there's so much ambiguity in some of the design decisions around it. And you have to blend that design thinking with some of the technical constraints of what can the AI models actually one shot effectively?

(00:26:21):
And if not, how do you add in the right human workflow for approval and review, and the reprompting and so on? So just so many different design decisions, and you need somebody who can really think full-stack about that kind of product and is not overwhelmed by that kind of open-endedness, but relishes in it.

Lenny Rachitsky (00:26:38):
I was actually playing with it before we started chatting. I made a really cute startup CRM.

Howie Liu (00:26:43):
Oh, that's awesome.

Lenny Rachitsky (00:26:43):
Yeah, started talking Omni over here. It's like the colors are beautiful-

Howie Liu (00:26:47):
[inaudible 00:26:47].

Lenny Rachitsky (00:26:47):
... so that's what's standing out to me right now.

Howie Liu (00:26:49):
[inaudible 00:26:49] there is...

Lenny Rachitsky (00:26:50):
Yeah.

Howie Liu (00:26:50):
I will say just as a note, I consider myself at my core a product UX person. That's my passion. And everything else I've had to learn to run this company is almost like what was a necessary part of the journey. But my real passion is thinking about product UX. And I think of UX in a deeper sense than just the cosmetic design. What you could put into a framer kind of prototype. I think of it as literally what should this product do and how should it represent that and behave for the user? That is the product, in my opinion, right. And of course, then you have to figure out technically what's possible and how to implement it.

(00:27:36):
But I think to me what's under executed today in the world of AI products is there's so many awesome capabilities of AI, and most of them are really under merchandise, and there's very poor, actually, visual or otherwise metaphors or affordances given to users to help represent or understand what those underlying capabilities are. I mean, ChatGPT obviously extremely successful product, so not knocking it at all, but you come in and you just get this completely blank chat box by default, and now they have suggestions underneath and so on.

(00:28:13):
But the product UX part of me is just craving more visual metaphors or colors or some kind of use the canvas of a web interface and all the richness interaction you create there to better represent or show all the different things that you can do with the underlying model, right. And so that's something we've tried to do with Airtable, is show all of the different states and use colors even to play those up.

Lenny Rachitsky (00:28:44):
It's interesting how much of this connects with I just had Nick Turley on the podcast. He's head of ChatGPT at OpenAI, and he had these two really interesting insights that resonate directly with what you're describing. One is he has this concept of whenever something is being worked on, he's always asking, " Is this maximally accelerated? How do we move faster? If this is important, what would allow us to move faster?"

Howie Liu (00:29:06):
Yeah.

Lenny Rachitsky (00:29:06):
And I love that that's one of the themes that's coming up as you talk, is just this creating this very clear sense of speed. And you even call it the fast-thinking team, like, "You are going to move fast." And then the other one is just this insight that with AI, you often don't know what it can do and what people want to do with it until it's out. So there's this need to get it out, and that'll tell you what it should be.

Howie Liu (00:29:29):
I couldn't agree more with both of those, and particularly on the second point, I think it's interesting. Clearly, there have been companies that have both been successful in PLG and more sales-led distribution for AI products. The most notable ones I can think of are Palantir with their AIP deployments. That's obviously very sales-led. You're not PLG into a Palantir deployment. But even companies like Harvey and so on, they're doing very well. And it's primarily, from what I understand, sales-led.

(00:29:59):
You're not self- serving into a Harvey instance at a law firm. And yet, to me, the best way to get AI value out there is experientially, right. And so you can kind of get that in a sales motion. You can show a demo. Maybe you can do a POC, but it's so much more powerful when you just open up the doors and say, "Anyone who wants to come and sign up and trial this product can." And I think to me, it's a real proof point that ChatGPT is arguably the most successful kind of PLG product of all time, just in terms of sheer scale of users. Like they announced 700 million... Is it MAUs or week... I think it's actually-

Lenny Rachitsky (00:30:41):
Weekly active users.

Howie Liu (00:30:41):
Weekly.

Lenny Rachitsky (00:30:42):
10% of humans on earth use it-

Howie Liu (00:30:43):
That's insane.

Lenny Rachitsky (00:30:44):
... weekly.

Howie Liu (00:30:45):
That's insane. In how many years? A few years.

Lenny Rachitsky (00:30:48):
Three years. Under three years.

Howie Liu (00:30:49):
Yeah. So I mean, literally, that is just the most insane ramp curve. And I don't think they would've gotten there if you couldn't just come in and literally try the product out. And as a little bit of a rebuttal of the point I made earlier where I think ChatGPT doesn't do a ton right now, and even earlier they did even less to expose all the different ways you could use it, but they just made it so frictionless to just try it for yourself that you as a user could come in and just literally ask it anything and see how it did. And of course, people in the early days tried to stump it and showed, "Oh look, see, it's not that smart. It doesn't answer this hard question really well."

(00:31:26):
But clearly, the magical nature of it still appealed to you enough. Everybody used it. And so I think I do have a view. We've gone through that whole arc of we started PLG. I'd like to think Airtable was one of the PLG darlings of our era. And anyway, I started moving up market and doing more sales execution, although that was still always on top of usually PLG within an enterprise, but we started doing more and more sales execution. We still have that. That's still really important for our business. But I also think, me personally, one of my goals is to shift my attention back into that kind of builder-led adoption and literally showing in the product experientially, not telling in a deck, the value that you can get from AI and Airtable.

(00:32:20):
I think that's so key, and it's [inaudible 00:32:23], but it's also more than that. It's not just literally how do you onboard somebody into the product. It's literally thinking about the entire product experience itself, right. And in our case, we just made the entire product experience AI-centric. It used to be that we had kind of this secondary thing that you could ask questions to the assistant sidebar. We now made our agent the default way of doing everything in Airtable, and it's now the Airtable app, as you know, it is almost like an artifact that's manipulated by and can be tool used by the agent.

Lenny Rachitsky (00:32:58):
Let me follow that thread. So if you go to Airtable.com today, it looks like basically all the other AI app building sites. Now it's just tell me what you want to build. Thoughts on that, as just a thing everyone's starting to do is there... what do you think comes next? Is this... Is it working well?

Howie Liu (00:33:15):
There's clearly an incredible magic to vibe coding and app building with AI. And this is actually a prime illustration in my view of that concept we talked about a second ago, which is as capabilities of these underlying models evolve, the form factor in the product UX also needs to evolve with it. And so the earliest models, like the kind of original ChatGPT, like GPT-3.5 kind of era models were not nearly as smart as the current models. And so you couldn't really ask it to one shot a more complicated chunk of code, or certainly not like a full stack app, and expect it to work.

(00:33:56):
And so the right form factor for leveraging those models in a software creation context was GitHub Copilot, right. It's like auto-complete a few lines of code at a time. But you couldn't chat to it and tell it, "Build me this entire app from scratch." And I think that as the models got better and better, you saw that the new form factors emerge. I think Cursor did a great job of being an early pioneer of this more age agentic way of leveraging the models to do more complex things and generate more larger chunks of code.

(00:34:27):
And now with Composer, you can literally just go into Cursor and build an app from scratch, build me a 3D shooter game from scratch, and just watch it go and create all the files and fill out each file, and then the thing actually runs some of the time. And so to me, this is where the world is going. The models are clearly getting smarter. And if you think about the original vision of Airtable, it was always about democratizing software creation. We just strongly believed that the number of people who use apps far outweighs the number of people who can actually build their own or manipulate apps and harness custom software to their advantage.

Lenny Rachitsky (00:35:08):
That sounds very familiar, very familiar these days.

Howie Liu (00:35:10):
Yeah, exactly. And so I think this is, it's a different means to the same end. And so it's almost like we have to lean into this because if we started Airtable today, this is what we would be all in on. Now I think that the advantage that we have, and I do think you have to be realistic to yourself, especially as a company that predates GenAI and now has to find your new footing in the AI landscape. You can't fool yourself and just say like, "Okay, I'm going to throw in some AI stuff on the landing... on the marketing site, put in a couple AI features, and call it a day."

(00:35:43):
I think you actually have to take a clean slate approach to saying, "How would our mission best be expressed? If you were literally founding a new company from scratch with the same mission, how would you execute on that mission using a fully AI native approach?" And then, by the way, do you have useful building blocks that you can leverage from your existing product and your existing business, or are you literally worse off having this legacy asset versus starting something from scratch? And I don't think the answer is always yes or no. I think it just depends on the product.

(00:36:19):
And if you can't really introspect and say, "Look, I think I'm better off doing this with the pieces that I have for my existing business and product," then I think you should sell. You should find a buyer for that company and then go. And if you really care about this mission, go and start the next carnation of it. In my case, I really thought about this and really feel strongly that the building blocks that we have, these no code components, actually do allow us to execute better on this vision than if I had to start from scratch.

(00:36:50):
Meaning the problem with vibe coding, especially if we're building business apps... So I should clarify that we want to democratize software creation, but specifically, we are focused on business apps. We're not trying to be the platform where you create a cool viral consumer game. This is for like your CRM, right. Or if you want to build an inventory management system as a small restaurant or a lawyer trying to build a case management system, that's what we've always been focused on. And I think in this AI-native world, clearly, you should be able to generate those apps agentically.

(00:37:24):
And yet if you have an agent that has to generate every single bit of that app from scratch, from code, it's going to be very unreliable. There's going to be bugs. There's going to be data and security issues. And then you're also going to have a context collapse, as it just cannot manage all of the code that it's written, basically, as the app gets more and more complex. And what we actually have are basically these primitives that the agent can manipulate and use without having to literally write the code from scratch to represent, "Here's a beautiful crud interface on top of the data layer.

(00:37:57):
Ours is real-time and collaborative, and really rich, and has collaboration on it. And by the way, here's all these other view types and a layout engine for a custom interface, a layout, or automations and business logic." And so it's almost like in programming terms, the Airtable pieces in our Lego kit today can be used by this agent as almost like a more expressive DSL, like a domain-specific language to build business apps instead of literally having to write everything down to the SQL and HTML and JavaScript to build every part of that app from scratch.

(00:38:31):
And so if we can combine the best of both worlds, we have these very reliable, high-quality Lego pieces. Now, an agent can go and assemble them for you instead of you just using the GUI to do that. And by the way, if you do want to fall back to the GUI, there's a really great kind of way for the non-technical user to still understand and participate in what's going on. Whereas if you're not technical, you can't inspect the code underneath a v0 or Lovable or Revolut app, right.

(00:38:58):
It's just kind of opaque to you. And if you can't re- prop it to get what you want, you're kind of stuck. This is much more akin to a developer using Cursor can generate lots of code, but then can still drop back to the IDE to edit and manipulate it to the final production-ready state. So that's kind of the play that we're making. And if I didn't fully and truly believe we have a better shot at doing it with our existing product, I wouldn't be running this company in its form today.

Lenny Rachitsky (00:39:25):
I'm talking to a lot of founders that are going through the journey are going on, which is, "We've had a business for a decade, AI emerged, and wow, we got to figure out something that works... that could work even better." And so I'm trying to pull out the threads that are consistently working across these journeys because I think a lot of companies are trying to figure this out. So one that you just touched on is just if you were to start today, what will you do?

(00:39:48):
What would that business be? Plus, how can... do we have an unfair advantage with the thing we've done in the past? That feels like an important ingredient. And then the other... circling back to stuff you've shared already, there's just creating a sense of urgency and pace and getting people to understand this is how things move in AI, and we need to create this fast-thinking team. I love that metaphor in framing.

(00:40:11):
And then there's the point you made about just talking to AI regularly as the founder feels like an important element, just like to truly be this ICCO talking to AI, working with AI regularly. Just on that note a little bit more, just to give people a sense of what this looks like day to day. So you're talking to Omni all day trying to and undertook... flex the power of what you can do and iterate on it. Is there anything else you're doing day to day that helps you figure out what to do for the business?

Howie Liu (00:40:38):
One, I try to use as many different AI products, including not Airtable, as I can, and both literally for the novelty factor and just some new cool demo comes out. Like Runway release their immersive world engine, and so I'm going to go try it out. When Sesame AI put out their cool interactive voice chat demo, I tried that out because even though we don't have a direct and near-term need for really realistic and interruptible voice mode where it's not as core to our capabilities, I just want to understand and get a feel for everything that's out there.

(00:41:23):
And I try to invent little, almost like side projects of my own, to have a real reason to use these products. Like, "Oh, cool. What if I were to take... What if I were to try to create a funny little short... a funny video short using a combination of HeyGen avatars with a script, like a comical script generated by AI? And maybe it'll be on an interesting topic. So I'll do deep research on the topic with ChatGPT and pull together the results, have it compose kind of a little dialogue.

Lenny Rachitsky (00:41:58):
Did you actually do this? Is there something you made?

Howie Liu (00:42:00):
Yeah. That's literally an example of something, just a fun weekend project. And to be honest, these things only take you an hour if you become kind of pretty proficient with using the products. They're all so easy to use. You can literally do the deep research thing, kick off query, make a coffee, come back in 20 minutes. Okay, let me prompt it to generate me some dialogue. It's a little bit like what NotebookLM does for you out of the box, but sometimes I like to just do it myself. And then, okay, let me take the script and cut it up and turn it into a HeyGen avatar and then download the video and play it.

(00:42:32):
And just for fun. I'm not trying to make that into an actual YouTube video business. But I think coming up with these different fun weekend projects is a really useful construct to force myself to actually try these products in a more than just a Twitch click way. And what it gives me is, A, it's not just understanding the models, which is also very, very important, right. GPT-5 came out yesterday, and playing around with it a bunch just on a variety of different personal use cases, but there's a difference between just understanding the model but then also understanding the product form factors in which they can be placed, right.

(00:43:15):
Meaning when you apply the model in a more structured way, when you apply the model with different tool calling than maybe what ChatGPT has in its out-of-the-box form, when you apply it with a more agentic workflow, again, that might be different from what ChatGPT gives you out-of-the-box, that's when you kind of learn you really get to inspire yourself on what are the product's form factors that these new models can take. And plus, by the way, I find it to be really fun. There is to me a delight and entertainment value to just using AI, period, because A, it's not perfectly predictable.

(00:43:57):
So I think the element of you're not quite sure what you're going to get. It's like a box of chocolates. And B, it always blows my mind just to think about, "Wow, five years ago we didn't have any of this stuff." AI was like, okay, it's like we can do predictive analytics. There's some basically very advanced kind of regressions that we could run with AI, but it looked nothing like this in its current form, and it's just actually super fun, in my opinion, to get to play around with all the different types of products that come out.

(00:44:33):
I think that is a big part of it because on the point about the pace of the world moving so much faster in AI than any other landscape in SaaS, in the mature SaaS era, it was important to study your competition. If you were building a SaaS company, you'd be crazy not to follow Salesforce every year and see what the major releases they're putting out are, or ServiceNow, or so on.

(00:45:03):
This is the equivalent of that, but there's major new releases and products and so on every week, not every year. And so I just think you have to say abreast of all... of it all and combining this with our point earlier of a lot of this has to be experienced, not just read. You can't just read the write-up on TechCrunch or even a tweet about a new capability. You kind of have to try it to really get a sense of what it is.

Lenny Rachitsky (00:45:33):
Today's episode is brought to you by Anthropic, the team behind Claude. I use Claude at least 10 times a day. I use it for researching my podcast guests, for brainstorming title ideas for both my podcast and my newsletter, for getting feedback on my writing, and all kinds of stuff.

(00:45:49):
Just last week, I was preparing for an interview with a very fancy guest, and I had Claude tell me what are all the questions that other podcast hosts have asked this guest so that I don't ask them these questions. How much time do you spend every week trying to synthesize all of your user research insights, support tickets, sales calls, experiment results, and competitive intel? Claude can handle incredibly complex multistep work.

(00:46:13):
You can throw a hundred-page strategy document at it and ask it for insights, or you can dump all your user research and ask it to find patterns. With Claude 4 and the new integrations, including Claude 4 Opus, the world's best coding model, you get voice conversations, advanced research capabilities, direct Google Workspace integration, and now MCP connections to your custom tools and data sources.

(00:46:34):
Claude just becomes part of your workflow. If you want to try it out, get started at Claude.ai/Lenny. And using this link, you get an incredible 50% off your first three months of the pro plan. That's Claude.ai/Lenny. For people that work for you across Airtable, say the product team, PMs, maybe engineers, designers, how have you adjusted what you expect of them to help them be successful in this new world?

Howie Liu (00:47:02):
One is really, really, really stressing this idea of go play with this stuff. And I mean, when I say play, I really mean play in the psychological sense of there's a difference when you go in and you're kind of just trying to check the box and get a job done. There's a difference when you come in with a curiosity and you're kind of exploring, right. And it's both more fun and energizing, but also, I think you learn more through that. And so I've really tried to stress the value of play with these AI products.

(00:47:36):
And I kind of try to lead by example, by literally going and sharing out links or screenshots of the things that I'm doing in these various products. So, as an example, I will go into one of the prototyping tools and show, "Hey, I built a marketing landing page for this new capability we're launching." I created a landing page for it in Replit, let's say, and now I'm sharing that link. Instead of what typically we would've done in the past is like, okay, we're going to write a doc about it and then share the doc, I'm just going to show you an actual landing page with visuals and everything in there.

(00:48:20):
Or I'll share the actual link to my deep research reports. Or instead of me writing a perfect memo on a topic, I'll actually just prompt my way into getting a chat thread or a chat output that basically covers all the content that I care about and maybe even ask it to, "Okay, summarize this all into a final memo output," and then intentionally share that rather than expose the fact that I'm using AI in this way and here's literally how I'm prompting it so you can follow along as well.

(00:48:49):
But really trying to encourage everyone to go and just play with these products. And I've even said, "Look, if anyone wants to just literally block out a day or frankly even a week and have the ultimate excuse, you could use... you could say that I told you to do it, right. If you want to cancel all your meetings for a day or for an entire week and just go play around with every product, AI product that you can find that you think could be relevant to Airtable, go do it. Period. So I think that's the most important thing is this play, this experimentation.

(00:49:25):
I think there's also a lot of other kind of shifts in how we execute prototypes over decks. I want to see actual interactive demos because, again, it's hard to... In a deck or in a PRD, you could say, "Okay. Well, we're going to make Omni really good at handling this kind of app building." Okay, those are just words. The real proof is in the pudding of like, "Okay, let me try it out on a few realistic prompts that I can imagine."

(00:49:49):
And in a demo, in a real prototype, you can instantly try it out on unrealistic rather than golden pathy scenarios and see how it feels too. Does it feel too slow? Do we need to expose more of the reasoning or steps that are happening behind the scenes? Create a progress bar or something like that. But it's really hard to get that feel of the product with anything but a functional prototype that really does, in an open-end way, use the AI to do whatever you put in.

(00:50:24):
So I think it's more like a experimentation playground it feels like how we need to execute, versus I think, in the past, it sometimes felt like a more deterministic resourcing and kind of timelines view of execution. We're going to put this many people on this problem, and this is the eight-week timeline to this milestone, and then we're going to ship in a quarter from now. And I think now the whole thing is just a lot more experimentation and iteration-driven.

Lenny Rachitsky (00:50:56):
Of the different functions on a product team, PM, engineering design, who has had the most success being more productive with these tools, and how do you think this will impact each of these three functions over time?

Howie Liu (00:51:07):
What I found is that it really does become more about individual attitude and maybe some polymathism. There's a strong advantage to any of those three roles who can kind of cross over into the other two, like the hybrid unicorn types.

(00:51:26):
So if you're a designer who can be just technical enough to kind of be dangerous and understand a little bit of how these models work and how does tool calling work and all of this stuff, then you can actually design a concept or even prototype a concept, including in these prototyping tools that's much more interesting and maybe realistic than if you're just stuck in the flat like let me put something in a static design concept because I think designs have to be more interactive. The whole... The value of the product and the [inaudible 00:52:04]-

Howie Liu (00:52:01):
... the value of the product and the product functionality is in the interaction of it, right? Think about the design of Chachi Petite. Again, it's the most basic design you could possibly imagine. The real design actually is happening underneath the hood in how it responds to different queries and what happens after you fire off a prompt, right? So I think I found that there are people within each of these functions, there are engineers who are very good at thinking about product and experience and can go and prototype out the whole thing. They're designers who can do the same. Even if they can't literally code, they can prototype something out literally using a prototyping tool.

(00:52:42):
I think that's where AI tooling is also giving more advantage to people who can think in this way by equipping them with an alternative to actually having to go through the long hoops of learning CS, right? Then PMs as well. I think there are some PMs who are really getting into the technical details and studying up on how does this stuff work and actually getting hands-on, rather than seeing the role as writing documents, writing PRDs.

Lenny Rachitsky (00:53:08):
Do you see one of these roles, I don't know, being more in trouble than others, just like you need fewer of these people in the future potentially?

Howie Liu (00:53:16):
I think overall you can get more done with fewer people, and that's not to say we want to go and make the team smaller, but rather ... the really cool thing for us and I think a lot of other companies is it's not like you have a finite set of things you need to do and execute on from a product standpoint, and okay, now I can do that with a 10th of people. I mean, you could do that in a lot of cases, but for us, maybe it's also because we're a very meta product, right? We are the app platform with which you can build now any AI app with AI, right? The apps themselves leverage AI capabilities at runtime, whether it's to generate imagery for a creative production workflow or leveraging deep research, or AI-based crawling of the web to search for companies that match a certain criteria for your Dealflow app or something like that.

(00:54:10):
We can effectively leverage all of these other AI capabilities in this app platform, because by definition we're enabling our customers to build apps that have this wide range of AI capabilities. But because of that, it's like we have a almost infinite set of possible AI capabilities that we could execute on, right? I'm always telling the team like, "Look, the great news is it's like we have all these fruit trees and there's so many crazy low-hanging fruit, and you've got literally massive watermelons literally sitting on the ground and all you have to do is walk over 20 feet and pick it up instead of having to climb the really tall coconut tree to grab a hard coconut from 50 feet up. So there's so many watermelons on the ground, just go out and start finding the biggest ones and attacking those, right?"

(00:55:03):
What that means is that if we can build this culture, and I do think it's a learnable way of operating, I really like to believe in the growth potential of any human and any individual. I think if you really have a growth mindset, and that's why one of our most important core values is growth mindset, right? If you really have that growth mindset, I think especially if you're willing to put in the nights and weekends hours, or in my case I'm literally telling people like, take a full day off, take a full week off and learn this stuff, you can become more fluent in this way. I think then what we get is a team that can just go and work on more things in a much more leveraged and fast way, right?

(00:55:48):
So, I like to think people who are willing to jump on the train are just going to become more and more effective. It's not like, oh, as a PM my role is becoming entirely irrelevant, right? No, it means that as a PM you need to start looking more like a hybrid PM prototyper who has some good design sensibilities. By the way, I think some of the best eng PM and design cultures respectively over the past even few decades have always been multidisciplinary in nature, right? The original PM spec at Google required the PMs to actually be somewhat technical so they could understand the engineering limitations of the product designs they wanted to make, and they had to be kind of designy, right?

(00:56:33):
I remember my co-founder, Andrew, when he was in the APM program was always reading books about design, even down to visual design and color theory and that kind of thing, right? So I think it's just a reminder that designers as well, some of the best designers through designer to Apple, including hardware designer, you have to understand some of the technical capabilities of how this stuff works, right? If you're an engineer, I think some of the best engineers and maybe Stripe always had a very good engineering culture of engineers who could think about the product and business requirements. In fact, on any given product group, at Stripe my understanding is that the DRI isn't always the PM as is traditionally the case in that triangle. Sometimes it's actually the engineer who's taking the product lead and saying, this is what we need to build.

Lenny Rachitsky (00:57:24):
So, what I'm hearing is essentially the trend across product engineering design is each of those functions needs to get good at one of the other functions at least.

Howie Liu (00:57:35):
Yeah.

Lenny Rachitsky (00:57:35):
Ideally you can do them all, but if you can just do one additional, so a PM becomes better at design, an engineer becomes better at product management.

Howie Liu (00:57:43):
Well, I would actually go further and say I think you need to get decently good at all three. There's just a minimum baseline of if you're any one of those roles, you need to be minimally good at the other two, and then you can go deeper into your own specialty, right? You could be a designer who's really good at thinking about UX and interaction design, and then just good enough to be dangerous on thinking about what's technically possible and what is the product story around this feature.

Lenny Rachitsky (00:58:17):
I love that. To do that, one piece of advice that comes up again and again in what you've been describing is use the tools constantly to see what's possible, and that will teach you a lot of these things.

Howie Liu (00:58:28):
I think, well, use the tools gives you exposure to what's possible, right? It's kind of like if you wanted to be a great industrial designer, and let's say, I mean, the chair is the ultimate hello world of industrial design, it's the canonical design object, you wouldn't just sit there in a vacuum with no familiarity with the materials that you can use, plywood, steel, whatever, or existing form factors of chairs trying to invent the world's best chair in a vacuum, right? You should go and first do a study of all of the best chairs out there today. Go look at an Eames chair, sit in it and try to examine it to reverse engineer how it was made, and just look at the prior art for that type of product. That's how I see the go out and play with these products, and also, I think actually going and designing or implementing or executing is the best practice.

(00:59:21):
So you can't just only go and look at other people's chairs, eventually you have to go and actually try building your own and then try building another one and another one and another one. So, I think that's where ... when I think about how I hone my own product UX sensibilities, I never ... and at that time that I was in school and then learning about this stuff, there wasn't really any good curriculum for UX, right? It's not like there were great college classes to learn product UX. I mean, even CS was very academic in nature at that time, it wasn't applied software engineering, like build an app or whatever. Maybe now at some of the schools like Stanford, MIT, they have actually UXy type courses, but it's still a rarity for most people to have access to that.

(01:00:03):
So, the way I learned all of my product sensibilities was just trial and error and also using and studying other products, and then going and trying to build my own weekend project ideas, right? Oh, I want to build a Yelp style app with a map view and then also a list view, and I want it so that when you pan around in the map for it to automatically update the list view. Maybe there's some UX improvements I can make on top of that, but I can also test my technical skills to figure out which parts of this are hard to implement and how do you make it work, and what are some of the design changes or affordances that you can use to map to the technical possibilities.

Lenny Rachitsky (01:00:43):
To do that, I loved your piece of advice, which I forgot to double down on, which I also find really powerful. The best tip there is find something to actually build that is useful to you and fun. Pick a project that's like, okay, this would be fun to do. Have a problem you're solving that forces you to actually do this thing.

Howie Liu (01:01:00):
For sure. Look, I think that can be night and weekend projects, it can also be the daytime job projects, right? I mean, I am basically telling our teams on the AI platform group especially, "Look, in that low hanging fruit metaphor, it's like I'm not being prescriptive with you on which watermelons you should pick, but you should go ..." We do have different pods within that group, but one of them for instance is what we call the field agents team and they're responsible for the agents that work within your app. So this is not the agent that builds your app, but these agents that run on a customer's behalf to do web research on your customers, or they can go and analyze a document and in the future maybe do things like actually generate a prototype of a feature from a PRD or from a feature idea.

(01:01:52):
I'm telling them, "Look, there's a almost infinite number of superpowers you can give these field agents. I'm not going to tell you which specifically to do. Now you can ask me to weigh in for sure, but you should go and just experiment and prototype a few different directions we could go." What if you prototype what it would look like to have a deep research implementation in field agents, so that for any given row of data, let's say in your case it's podcast guests, you can just click a button or click a button en masse across every speaker you have lined up to do deep research powered by ChatGPT's own deep research on each of the speakers and have them all laid out side by side in this table, right? Go prototype that and see how it feels and looks like. So I think some of this stuff can also be in your daytime job, especially if that daytime job is literally to go and build AI functionality.

Lenny Rachitsky (01:02:46):
I actually tried to do exactly that. The problem I ran into, I wonder if it's changed, is there's no API for ChatGPT deep research yet as far as I know.

Howie Liu (01:02:55):
There is now, there is now.

Lenny Rachitsky (01:02:56):
There is, there we go.

Howie Liu (01:02:58):
Sometimes it ends up being ... and I think they only recently exposed it. It ends up being something on the order of a dollar plus per research call, which-

Lenny Rachitsky (01:03:05):
What a deal.

Howie Liu (01:03:05):
... I mean, again, exactly. I mean, some people would say, oh my god, that's so expensive, and you rack up 50 of those, you've cost $50 a month. I think it's like, well, it just saved you hours of research by a human.

Lenny Rachitsky (01:03:16):
Not only that, I actually have a researcher that I pay to give me background on guests that was four or 500 bucks and the dollar sounds great. I've been doing this-

Howie Liu (01:03:28):
[inaudible 01:03:28]

Lenny Rachitsky (01:03:28):
... I've been doing this manually.

Howie Liu (01:03:29):
If he was being smart he would be using deep research and they just collected [inaudible 01:03:33]

Lenny Rachitsky (01:03:33):
They might be. They might just be. Oh, man. Okay, there's one more skill I wanted to talk about real quick. This comes up a lot in these conversations is evals.

Howie Liu (01:03:43):
Okay.

Lenny Rachitsky (01:03:43):
The power of getting good at evals, I know that's something you value highly. Talk about just why you think this is something people need to get good at.

Howie Liu (01:03:50):
Yeah, and I listened to your episodes with [inaudible 01:03:54] and Mike who talked about this. I think it's interesting that both heads of OpenAI and Anthropic have converged on this point. I mean, look, I think I would add a slightly different or additive take though, which is I think for a completely novel product experience or form factor, you should actually not start with evals and you should start with vibes, right? Meaning you need to go and just test in a much more open-ended way, like, does this even work in kind of a broad sense?

(01:04:28):
So as an example, for our custom code generation capability, instead of defining evals that get repeatably tested as you vary the prompt or the model or the agentic workflow used to generate these outputs, and you have to define what does good look like by definition for the eval, I would first start with a much more open-ended and ad hoc style of just throw stuff against the wall, try different prompts and see how well it does.

(01:05:01):
To me, evals are more useful, A, once you've converged on the basic scaffold of the form factor and you kind of know what are the use cases you want it to work well for and what you want to test against it. Whereas in the early days, especially if your product market fit finding either for an entirely new company or for a pretty dramatically new or bold new capability that doesn't really have ... it's not an incremental improvement on something that exists in Airtable today, I think you have to just be a little bit more creative initially and throwing stuff at it, seeing what works to understand, okay, let's use an example, we're implementing this new capability that can use basically a long-running AI crawler agent that goes and researches the web for a specific type of object or entity, right?

(01:05:55):
So it's similar to deep research, but what it actually does is instead of outputting a report, it's actually going and compiling a list of things. The things could be companies or people or anything else, right? Find me every Marvel movie ever made, find me every DC Comics spin-off series, literally anything. You have to go in and first just try out a bunch of random ... use your own brain to think of what's the range of use cases I can test this against, right? Then you get back some results and you're like, okay, well, it's clear that where it does really well are these types of searches, people and companies with this kind of parameter.

(01:06:42):
I think to me, evals are useful once you have a sense of what is that cluster of useful use cases, you can start then more programmatically measuring the changes that you're making to improve the output for that, right? But by that point, you've probably already scoped the product and maybe the way we would merchandise it in Airtable is not a completely open-ended capability, but hey, here's a specific capability that can research one of these X number of entity types including people and companies, and here's even the filter conditions or criteria that are more explicit that you can define to give it the prompting to search for that thing, right?

(01:07:25):
But I kind of think it's more useful as a way to iterate your way to improvement, and you can start really testing stuff empirically, right? You can A/B test, especially if you have the scale of a really large product like Anthropic or OpenAI, you can just test everything and see like, oh, this model actually performs better than this one, this prompt performs better than this one, but I think early on you don't have that luxury and you're in a much more open-ended discovery process.

Lenny Rachitsky (01:07:51):
That is very wise, evals could constrain you too early. I think about just the Double Diamond, I don't know, IDO framework of be divergent first, and then converge and then maybe-

Howie Liu (01:08:01):
Yeah. Yeah, exactly. I hadn't heard that before, but that completely resonates.

Lenny Rachitsky (01:08:06):
Okay, let me try to reflect back some of the advice I've been hearing about how to shift a company to be successful in this new world, and let me see if I'm missing anything that you think is really important. So, one is there's this sense of just reset the expectations on pace and urgency and help people understand in AI things move incredibly fast, this is how we need to operate. Then there's also a piece of get stuff out so that you can learn how people use it and what it's capable of versus polishing it endlessly. Forcing people almost ... I don't know if forcing's the right word, but encouraging people to play with the latest stuff and giving them a chance to take days off or block out calendars, cancel meetings, just stay on top of this stuff to play as you talked about it. Then sharing things they've learned, get the vibes of what's possible.

Howie Liu (01:08:54):
Yeah.

Lenny Rachitsky (01:08:55):
There's also this idea of just rethink, okay, if we were just start today in this world, what would we do to achieve the same mission we are trying to achieve? Ideally it leverages this unfair advantage we have with things we've been working on for a long time. Then there's just talk to AI constantly every hour as you described.

Howie Liu (01:09:16):
For sure. Yeah, multiple times an hour, if possible.

Lenny Rachitsky (01:09:16):
Multiple times an hour, it keeps going up. Is there anything else that I missed there that you're like, you need to do this too to have a chance?

Howie Liu (01:09:25):
I think just to really, really try to break down role silos, and I think that's true certainly for EPND in the typical EPD triangle, but I also think it's probably true even for non-product roles, right? I think it's true in marketing, right? Something I'm really pushing for in marketing and I think our marketing team is really leaning into actually is if you can just do all of the thing yourself ... traditionally how a marketing team might operate is like, okay, you have one person who's responsible for executing the performance marketing part of a campaign. They literally go into the Google AdWords interface and they're tweaking the parameters of targeting and budget and conversion tracking, et cetera, and then somebody else is actually responsible for coming up with the specific ad copy, and somebody else yet was responsible for coming up with the seed content or positioning guide written by a PMM that feeds into the ad creative, and so on and so forth, right? Maybe they're promoting some new demo asset that somebody else yet created.

(01:10:35):
I just think that in the same way that you can collapse the roles in EPD, and the ideal person, maybe they're very specialized and deep in one dimension like engineering, but they're well-rounded enough to be dangerous on the other two, I think that's kind of true in almost every other function, right? Sales as well, I think you should start to be able to play more of an SE role. Traditionally salespeople didn't necessarily know the product that well and relied on the SE to come in and be the product experts. I think it's really hard to sell any kind of AI product now without actually being fluent in the product and be able to demo the product, so AEs need to be SE fluent as well.

(01:11:21):
So I just think that that concept of collapsing roles, everybody needs to become more full stack to do the ... being more outcome-oriented, right? Your outcome as an AE is to convince customers of the value of your product and close deals, right? Okay, well, in order to do that, you used to have dependencies on having assets created by marketing and an SE to help you demo. Can you collapse more of those dependencies so that if you had to, you could do it all yourself, right? I just think it's a new operating mentality overall for every AI native company or company that wants to compete in this new arena.

Lenny Rachitsky (01:12:06):
That is a great addition. It almost feels like you go back to startup times when everyone's doing a bunch of stuff. There's no here's the head of product, here's the head of engineering, we're just doing stuff-

Howie Liu (01:12:06):
Totally.

Lenny Rachitsky (01:12:16):
... that needs to be done.

Howie Liu (01:12:17):
Totally.

Lenny Rachitsky (01:12:18):
Yeah, I'm kind of seeing it as this upside down T where there's the thing you're really strong at and then as you described, the minimum of being good at engineering design or ... and SE, by the way, sales engineering imagine is what that stands for. Adjacent roles, you need to start having a baseline. The baseline is increasing of how much you need to understand that, everyone's Venn diagrams are kind of converging.

Howie Liu (01:12:40):
Exactly.

Lenny Rachitsky (01:12:42):
Amazing. Okay, let me take a step back and zoom out and think about the broader journey you've been on over the past decade plus. Let me just ask you this, what's the most counterintuitive lesson you've learned about Airtable building and company building teams that maybe goes against common startup wisdom?

Howie Liu (01:13:02):
I heard your interview with Brian Chesky and then later you talked about founder mode in that YC retreat, and the points there really, really resonated with me. I feel like maybe less eloquently I deduced some of the same principles just in my own experience, which is I think when you're scaling up, and this relates also to what we talked about before around the early days of building a company, you're in the details, you're finding product market fit, you kind of have to be pretty versatile, right? All these decisions from a technical standpoint to design, to even commercial, and what's the freemium model going to be like? And how are we going to market this product? What does the website look like? They're all very intertwined, right? You can't compartmentalize and then almost factory produce each of these things separately. They're all intertwined and you have a very small tight-knit team that's thinking full stack about all of this combined.

(01:14:04):
Obviously that's the only way, in my opinion, to create that magical product market fit in the first place. Then I think as you scale up, the default guidance that you often get from operational experts and larger scale company investors is like, okay, you got to industrialize the process of all of this stuff, right? It's kind of like going from a bespoke artisanal, one person made an entire item of clothing to we got to factory produce this thing, right?

(01:14:38):
What that means in an organizational context is you then create these different fiefdoms, you hire all these execs and each exec just manages their own swim lane, and there's relatively looser coupling between all of those different groups, right? So then you've got sales executing on its own thing, marketing's executing on its own thing, product's executing on its own thing. Even within product there's different product groups and surface areas that are each executing on their own thing.

(01:15:05):
Using the factory metaphor of there's an argument that that's actually kind of an efficient way to scale up production for each of these different swim lanes, right? Each one can operate in a more autonomous and purely scale up focus, wait, how do we produce more of this thing? If the thing happens to be within one product group improving search, that's our main focus. We're just going to go and ship, ship, ship more stuff to improve search. So it's not completely crazy why people give this advice, but I think what you lose is the magical integrative value of holistic thinking and making the bigger picture bets, right?

(01:15:48):
I think Brian talked a lot about this on his episode with you, which is like, look, in a company that is really serious about product, first of all, I really liked his point about the CEO has to play a CPO role, you have to care about the product. Ultimately the product is the thing and you can't just coast on scaling up go-to-market around the product forever, you got to keep innovating on the product. By the way, the best way to innovate on the product is not incrementally split over all these different little surface areas, but actually to have a bigger, more step function vision of how this product needs to make a leap, or what's the next big either act of the product or new capability of the product or reinvention of the product, right?

(01:16:35):
So I think if you really care about doing that from a product execution standpoint and almost refinding new product market fit on a regular basis, I think it necessitates a completely different operating and leadership model throughout the organization. All of the stuff we just talked about in terms of how to operate in the AI native era I think is actually exactly the same as how you need to operate in this constant product market refinding of fit state.

(01:17:02):
So I could not agree more with that concept of you got to think ambitiously and move the organization holistically towards these bigger outcomes, but also ship and learn and experiment a lot more in this era. Then maybe the meta learning I had from all of the above is that the specific advice obviously was like, okay, go scale up in this way or go hire these types of people, experienced operators, et cetera. Now, obviously there's some truth to that, right? The people giving this advice are not incompetent. They had some reason for giving it and in certain contexts that is the right thing to do, but I think my meta learning is it's not enough to just trust the recommendation, like, here's the action you should take from a lot of people, 'cause everybody has different priors and it's almost like we're all our own LLMs, and we all have different training from a different corpus of data informed by our own experiences. Maybe you're trained on the service-

Howie Liu (01:18:00):
... experiences, and maybe you're trained on like the kind of ServiceNow or the Oracle training corpus, and this person's trained on the Facebook corpus, and I'm trained on the Airtable one. I think what I've tried to do more and more is not to just ignore advice from smart people. Obviously, that's not the right answer, but to kind of take their... It's almost like in an LLM you can now with a reasoning model actually inspect the chain of thought and see how it's thinking. Why did it come up with this answer? To me, that chain of thought like "Why did you recommend this?", is actually more informative than the actual, "Just do this recommendation."

(01:18:44):
The answer might be like, "Hey, at So-and-So company, this is how we eliminated the PM role entirely." For Brian at Airbnb, it made sense. We're no longer having PMs in their traditional form. Now, we have program managers and product marketers, but more than the actual decision because I don't think it's a one-size-fits-all, everybody should do the same, why did you do that? The why actually was very informative, and then be able to take that and say like, "Okay, how would I apply that?" Maybe it yields a different outcome, but the reasoning actually is very informative.

Lenny Rachitsky (01:19:19):
It's interesting how this idea founder mode is not so different from this ICCO trend that you're following and it's-

Howie Liu (01:19:26):
For sure.

Lenny Rachitsky (01:19:26):
... yeah, yeah, it's like being in the weeds, being in the details, trying things yourself, not delegating to execs.

Howie Liu (01:19:32):
Yeah, and I think anything taken to an extreme can be problematic. There is a world where you are so in the details and in every detail that you're basically just micromanaging and you're kind of creating like a euphemism for that. That's not really what founder mode is about. That's not like the Brian conception of founder mode is to like micromanage everything and not trust anyone, but I think it's more about finding that right balance of being unabashed about caring about the details that do matter and where the tying together of details across different groups or departments actually is the only way to yield a non-incremental outcome. Otherwise, each person is just optimizing within their own domain, but you'll never get to the global maxima or the global breakthrough. 

(01:20:23):
I think the really cool thing about CEOs as I seize it, frankly any leader playing more of an IC-like role and being in the details is I think for the right type of person, it's actually more fun that way. I mean, to be honest, for me, the times where I felt most disintermediated from what I felt was the substance of this company was when I thought that I was almost like forcing myself to step away from the details. I thought that's what a at-scale CEO was supposed to do. I mean, there's some famous CEOs who have talked about, "The less decision I could make the better. The less details I'm exposed to the better. I just want to inspect at the topmost layer how this business is running, and if everything underneath it is going smoothly, then I'm able to do that and everything looks good."

(01:21:19):
I just think that's maybe, again, it works in a certain type of very mature type of business. Even then, though, I can't imagine that at a CPG company like a Procter & Gamble. You wouldn't want to have a CEO who still actually goes and tastes the soup and tries the products and sees literally the details of what the new product innovation pipeline looks like, as well as like how it's being experienced on the shelves and so on. I don't know. I guess I'm just more and more skeptical that that hands-off pure delegation and process management role ever works as a CEO. Maybe you go through a long enough period of where the business is coasting that nobody notices, but I got to say, for me it's just much more invigorating to get to play that role. I think for the types of operators and leaders that I most admire, that's what makes the job interesting. They don't want to have a automated away kind of role as a leader.

Lenny Rachitsky (01:22:22):
If you could go back in time and whisper something in a decade-ago Howie's ear that would have saved you a lot of pain and suffering over the last decade, what would that be?

Howie Liu (01:22:33):
Don't step away from the details that both you love. I mean, first of all, if your passion is building product and product design, even if it feels like at times the company needs to do all this other stuff like scale up, go to market, and operations and just have like a large people organization, that itself creates a lot of need to do things and manage. There becomes a new job invented just to manage a larger group of people, and obviously you're going to have to do some of that. You can't just completely eschew all your responsibility as an at-scale CEO, but don't lose the essence of the thing that you love doing and that really made this product happen and gives this company as many companies that were founded on a magical product market fit finding insight. Don't step too far away from that, and always make sure that is still your number one, even if other stuff has to also add to your plate.

Lenny Rachitsky (01:23:45):
I think people don't talk enough about this how if someone starts a company that's an idea they have they're excited about, it takes off and then you're stuck on that for a long time, and then even if things are pushed in a direction you're not as excited about. This point about just remembering what you actually love about it and coming back to that is so important because that's the only way to keep doing this for a long time.

Howie Liu (01:24:05):
I think that's so true, and to me that's why there's always been a difference between entrepreneurs who love the act of building a product or the business, too, versus those who saw a just purely business or financial opportunity that they felt like they couldn't pass up exploiting or going after. Look, no knock on people who are more the latter, and there's entire industries where it's all just about alpha generation. You can go into the private equity business and so on, and it's just purely it's rationally about how do I find the alpha? I think that some of the best companies, product central companies, at least in my opinion, are run by those people who actually just love the product. I think you get a feel for that from some of the AI companies like Sam, I think genuinely just loves working on AI.

(01:25:03):
If he could spend a hundred percent of his time on just being close to the AI and the research, I mean, he would and he's even said as much. Ranging to like Brian's with Airbnb, it's pretty clear that people like this are not motivated like... Airbnb was not founded because like, "Oh my God, we want to make a lot of money off this arbitrage opportunity against hotels."

Lenny Rachitsky (01:25:24):
They just needed to pay their rent.

Howie Liu (01:25:26):
Yeah. Well, that and I think they loved the product and I think they also loved the way in which they built the product, the design-centric nature of that product and company and culture. That's what gives you the continued joy of working on what could be the same company for a very long time.

Lenny Rachitsky (01:25:45):
Howie, is there anything else that you wanted to touch on or leave listeners with before we get to our very exciting lightning round?

Howie Liu (01:25:51):
I just want to reiterate, especially for listeners here who are in an EP or D role and especially in the P role, I really do believe that this is not like you either have or you don't like in terms of the skill set needed to be relevant and AI needed, but I do think it's a call to action to go and bolster your skill sets where they may be less refined right now. I think even programming, I really believe everyone could learn how to be a software engineer if they wanted to. Now, obviously, some people just as with like great writers are never going to be a published author or the Hemingway, but everyone can gain a good enough proficiency of software engineering if they really wanted to. 

(01:26:39):
You could take that boot camp. You could do like some coding exercises on the side, et cetera. The point there is that sometimes I think we treat these disciplines like hard, hard skills that if you're already halfway into your career and you're not already an engineer, if you're not already a designer, okay, well, you can never be one. I just think our brains are malleable and there's a lot of great curriculum out there to learn. Lot of it, like I said, just comes down to also like trial and error and building projects, maybe nights and weekends projects even to learn this stuff. Everyone can learn how to be a versatile kind of unicorn product engineer/designer hybrid in the AI-native era. The only thing stopping you is just going out and doing it.

Lenny Rachitsky (01:27:30):
That is a really empowering way to end it, and just to double down on that, it's never been easier to learn these things. There are super intelligences that you can talk to that do a lot as they're building can help you learn.

Howie Liu (01:27:43):
Yeah. I mean, literally, I go into ChatGPT sometimes and I ask it just like, "Hey, how would you build this app?" I'm just curious. I'm like, "How would you build Manus, the open-ended agent?" Literally, how would you build it? You can ask the questions and it's like having an amazing, brilliant software architect, software engineer, product manager, designer expert tutor that you can literally like there's no dumb question. They have infinite patience. They're literally on and awake 24/7. It is the most incredible time to learn this stuff, to your point. Then, of course, the interactive tools to go and actually build stuff. Anyone can download Cursor and just start asking Composer to generate some code for you, and then looking at the code and trying to figure out what it does. To your point, when I think back to the earliest era that I experienced of building apps, first I learned C++, then I learned PHP and JavaScript and even building kind of JavaScript single-page apps in the early days like '08 through 2010. It was a dark, dark art. I mean, there were some like... You just had to go and like learn some of these things. There wasn't great tutorials for it. You had to reverse engineer certain things. There were just weird things like if you wanted rounded corners in your UI, you literally took Photoshop, opened it up, created like a rounded corner in pixels, and then cut that pixel up into an image that you dropped onto the page at exactly the right position to be at the edge of a box.

(01:29:15):
It's like crazy stuff. I mean, everything was so much more arcane at the time, and now it feels so much more fluid and accessible, and the gap between the arcane tech that you have to wade through to build something has just been minimized so much. It's like the effort and abstraction between you and the magical, delightful actual building of the thing that you want has been so minimized. It's never been a more exciting time to be a builder.

Lenny Rachitsky (01:29:47):
You remember spacer.gif?

Howie Liu (01:29:49):
Oh yeah, yeah.

Lenny Rachitsky (01:29:50):
It's like to create. It's that line stuff you just kind of have-

Howie Liu (01:29:52):
Yeah, I remember it. Yeah.

Lenny Rachitsky (01:29:54):
... the invisible one-pixel thing that you just stick in places.

Howie Liu (01:29:57):
Yeah. Yeah, yeah. No.

Lenny Rachitsky (01:29:57):
Oh my God, what a time to be alive. Howie, with that, we've reached our very exciting lightning round. I've got five questions for you. Are you ready?

Howie Liu (01:30:05):
Yes.

Lenny Rachitsky (01:30:05):
Here we go. What are two or three books you find yourself recommending most to other people?

Howie Liu (01:30:09):
You know, I've been trying to read fiction more, partly because I think it's just a really nice mental reset. I will say like Three-Body Problem for anyone who hasn't read it, it's a mind-expanding book. I like sci-fi and fiction that kind of opens your brain, so maybe this is my cheat card, but it's a three-book series. Those are three great books.

Lenny Rachitsky (01:30:30):
I love that series, and my tip there is it gets good one and a half books in is my tip, so just keep reading. That's where it's like, "Okay, now I'm in."

Howie Liu (01:30:40):
I liked even the first one, but I felt like it was inception where every subsequent book was like you dropped into another, like you incepted into another layer, right?

Lenny Rachitsky (01:30:53):
Awesome. Okay. What's a favorite recent movie or TV show you've really enjoyed?

Howie Liu (01:30:57):
TV show, I just started watching The Studio. It's like the Seth Rogen, Rogen.

Lenny Rachitsky (01:31:05):
Yeah, it's so stressful.

Howie Liu (01:31:05):
Yep. Yeah, it is pretty stressful, and I mean, Silicon Valley was too close to home when it came out, so I watched it, but it was just cringy. The Studio is kind of fund to watch because it's a little bit about like inside baseball of Hollywood, and yet I'm not in Hollywood, so it's entertaining to watch. It's I thought smart and a funny show because I split time between L.A. and S.F. I also feel like it's very real to me. I see a lot of the literal characters out there in the world that it's characterizing.

Lenny Rachitsky (01:31:43):
Do you have a favorite product you recently discovered that you really love? Could be an app, could be gadget, could be clothing.

Howie Liu (01:31:48):
Okay, so I'll give two because I feel like I have to say some kind of software product. I mean, I'm a really big fan of Runway, the product and the company. I just think every new model they come out with, they just came out with a new one just I think like two days ago that gives even more controls and refinement on creating exactly the video scene that you want. I think just the photorealism in what you can generate now, and they also built this cool demo thing that's an immersive world generator I mentioned before. I think it's just cool to see. I also like the underdog story. I'm clearly like Google's gunning in the space, has VO3 and so on and has its OpenAI, but I love the underdog story of this sub-hundred-person company still punching above their weight and building really awesome video experiences. That's the software one.

(01:32:45):
Then, a very, very kind of nerdy real-world answer on product is I kind of just recently got into this whole cottage industry of artisanally produced basically clothing by small-scale Japanese manufacturers that use literally like hundred-year-old looms to make clothes the old-fashioned way or the old-fashioned industrial way. They have these loop wheeler machines and they spin the cloth in a very slow pace, so it's completely impractical from a production-scale standpoint, but I've gotten some of these t-shirts and I just love the... I guess in a world where it feels like everything is becoming so much faster moving and even tech from five years ago is obsolete, I love a little bit of the throwback to like old things sometimes can be even more cherishable in this new era. Maybe that makes me a hipster, but I love the vintage, the retro increasingly these days.  

Lenny Rachitsky (01:33:56):
I feel like anything that starts with artisanal small batch Japanese is going to be really good stuff. Is there a brand you want to share that is that? Or is this like you want to keep it-

Howie Liu (01:33:56):
Yeah. No, I mean-

Lenny Rachitsky (01:34:06):
... under the radar.

Howie Liu (01:34:07):
... actually, so Self Edge, which actually has a storefront, the main storefront is on Valencia Street in S.F. They carry a lot of these items. That's kind of their whole MO and they have like jeans and t-shirts. I've gotten a lot. I mean, they basically curate a really good selection of different actual makers. One of them is called Studio D'Artisan, another one's called... Actually, it's cool. There's this company called... I think the umbrella company is actually just Toyo, T-O-Y-O, Manufacturing, which sounds like it's a big kind of like large-scale conglomerate, but it's anything but. It's like a really small-scale Japanese vintage manufacturer of clothing, but they have a few sub-brands.

(01:34:51):
They actually bought the rights to this American post-war brand that was kind of like Hanes, one of the like big four or five menswear, kind of undershirts and athletic wear brands called Whitesville. I don't know where the name came from, but basically it's a bunch of like basic clothing, like t-shirts, et cetera, and this Japanese indie company, they bought the defunct basically name and now is reproducing clothes almost made to the exact shape and stack, and even with the exact recreation of the graphic packaging on these tees, but like today. I just think there's something really funny and ironic about they've taken an American post-war aesthetic and literal brand, but it's actually a indie small-scale Japanese manufacturing approach to making those clothes.

Lenny Rachitsky (01:35:51):
I feel like we just tapped into what could be a whole other podcast conversation about clothing and-

Howie Liu (01:35:56):
Yeah-

Lenny Rachitsky (01:35:56):
... craftsmanship-

Howie Liu (01:35:57):
... [inaudible 01:35:57].

Lenny Rachitsky (01:35:58):
... but I'm going to pull us out of that.

Howie Liu (01:35:59):
The next podcast franchise.

Lenny Rachitsky (01:36:02):
Or just Howie and Lenny talking about clothing.

Howie Liu (01:36:04):
That's great.

Lenny Rachitsky (01:36:05):
Okay, two more questions.

Howie Liu (01:36:06):
Yeah.

Lenny Rachitsky (01:36:06):
Do you have a life motto that you often find useful in working or you like to share with friends or family?

Howie Liu (01:36:12):
I stumbled on this guy Paul Conti, who I think he's an MD, but also a psychologist, and he has a book, but also he did this long-form podcast with Andrew Huberman, and he actually ends up talking a lot about just how to think about your life outlook and kind of your framework for thinking about life, but grounded in a kind of like scientific and neurological and cognitive science basis. I found one particular point really, really powerful it took with me, which is if you live your life in a way that's foundationally built around humility and gratitude. Look, everybody has different circumstances.

(01:37:06):
I think I fully own that even though I didn't come from money, my family was very, very financially modest growing up. I still had incredible resources and opportunities afforded to me even just by virtue of growing up in the U.S., being born in and growing up in the U.S., but also having access to a computer and the internet and even all the free resources I could then access and learn about from there. I still feel like whatever you have or don't have to start with, if you kind of approach the world and kind of the future with a spirit of humility and gratitude rather than, I guess, the opposite of that, I think I've felt like it kind of becomes a self-fulfilling prophecy. You're open-minded, you're kind of grateful, and then more opportunities actually come your way, and maybe it's because the energy you're putting out into the world and other people.

(01:38:07):
You're kind of attracting good opportunities and good people and good things, but I think there's a lot of other parts of his framework, but the one that is easiest to remember is like, how do I approach each day? Even if I'm going through a tough moment and I had to fire somebody today, or maybe I get disappointed because we lost a customer deal or something broke or whatever, but to still try to look at the entire situation from overall a feeling of humility and gratitude I think just really does shift your like... It spills over into everything else for that day and maybe even for the whole lifetime. 

Lenny Rachitsky (01:38:52):
That super resonates. That is really powerful advice that's hard to internalize, but important.

Howie Liu (01:38:57):
Yeah, it's easily said, hard to practice.

Lenny Rachitsky (01:38:59):
Yeah. Where can folks find you? What should they know about Airtable and how can listeners be useful to you?

Howie Liu (01:39:05):
Okay, so I am on Twitter, howietl. I don't post that much, but I'm a lurker, so I listen and watch, and you can always DM me there. You can also email me directly, howie@airtable.com, anytime you have ideas, feedback, et cetera. On Airtable, just go try it. The whole point is we want to make this an experiential product. That's why we're really leaning into the PLG roots. We talked about the homepage literally says like, "Just start building right now. What do you want to build? Go." 

(01:39:36):
It starts building, and so use the product, give me feedback, and if you have ideas of your own and you want to rip on them, I love because my passion is thinking about product and product UX, especially in the AI era if you're working on or thinking about something interesting in that space. Even if it's just purely to riff on a concept, that's something I enjoy doing, and maybe I get to learn and sharpen my own skill set from. Feel free to reach out and, yeah, I mean, tell your friends and family to try Airtable as well. That's the main thing.

Lenny Rachitsky (01:40:08):
Sounds like you're looking for people to nerd snipe you and-

Howie Liu (01:40:10):
Yes. Yeah.

Lenny Rachitsky (01:40:12):
... Howie, thank you so much for being here.

Howie Liu (01:40:14):
Awesome. Thank you, Lenny. 

Lenny Rachitsky (01:40:15):
Bye, everyone. Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Ive run 75+ businesses. Heres why youre probably chasing the wrong idea. | Andrew Wilkinson
**Guest:** Interview Q Compilation  
**Published:** 2025-07-03  
**YouTube:** https://www.youtube.com/watch?v=VxAwUb86MUE  
**Tags:** growth, retention, experimentation, conversion, monetization, management, strategy, market, persona, design  

# Ive run 75+ businesses. Heres why youre probably chasing the wrong idea. | Andrew Wilkinson

## Transcript

Lenny (00:03):
Welcome to a very special episode of the podcast. Ever since I started this podcast, one of people's favorite segments continues to be the lightning round, and in particular, a question I ask guests around their favorite interview question that they like to ask candidates and what they look for in a good answer. What we've done is we've picked my favorite interview questions that guests have shared. Out of over a hundred guests on the podcast, we've got 17 of my favorite interview questions all combined in this one episode. You can use this episode anytime you are preparing to interview candidates, if you want to improve your existing interview questions, or if you're about to get interviewed and you want to prepare for the kinds of questions that you might get in the interview process.

(00:47):
Before we dive in, let me tell you about our product called Sendbird. The all-in-one communications API platform designed for both web and mobile apps. In a world saturated with multi-channel communication, product teams are discovering the effectiveness of in-app communication. With Sendbird, businesses can elevate their in-app experience with decluttered and branded communication featuring AI powered chatbots, one-way messages, chat, video calls and livestream capabilities, all tailored for commerce, marketing and top-tier support. Forward-thinking companies such as Hinge, Patreon, Yahoo, Accolade, and more use Sendbird to build in-app communication experiences that drive engagement, conversion and retention. In-app communication has the highest conversion, highest engagement and highest satisfaction of any communication channel. And when it comes to investing in this channel, trust Sendbird to take your in-app communication experience to the next level. Start today with Sendbird's free plan, and as a listener of Lenny's Podcast, you'll get an additional two months of unlimited usage and access to all premium features, including creating your very own generative AI chatbot. Visit sendbird.com/lenny to begin your free journey. That's sendbird.com/lenny.

(02:04):
This episode is brought to you by ePO. ePO is a next generation AB testing and feature management platform built by alums of Airbnb and Snowflake for modern growth teams. Companies like Twitch, Miro, ClickUp and DraftKings rely on ePO to power their experiments. Experimentation is increasingly essential for driving growth and for understanding the performance of new features, and ePO helps you increase experimentation velocity while unlocking rigorous deep analysis in a way that no other commercial tool does. When I was at Airbnb, one of the things that I loved most was our experimentation platform where I could set up experiments easily, troubleshoot issues and analyze performance all on my own. ePO does all that and more with advanced statistical methods that can help you shave weeks off experiment time, an accessible UI for diving deeper into performance, and out-of-the-box reporting that helps you avoid annoying, prolonged analytic cycles. ePO also makes it easy for you to share experiment insights with your team, sparking new ideas for the AB testing flywheel. ePO powers experimentation across every use case, including product, growth, machine learning, monetization and email marketing. Check out ePO at getepo.com/lenny and 10 x your experiment velocity. That's getepo.com/lenny.

(03:22):
First up, we've got Eeke De Miliano. Eeke was head of product at Retool. She was also a PM at Stripe. Currently, she's actually starting her own company. Here's Eeke sharing her favorite interview question.

Eeke De Miliano (03:36):
"To what do you attribute your success?" And you can't say "luck". Because I think humble people will always say "luck" in some way, and I always kind of want to know, how self-aware are you, basically, and how curious are you? I think people have really sort of gone back and reflected on why are they where they are today really says a lot about how they think about the world.

Lenny (03:58):
Next up, we've got Geoff Charles, Head of Product at Ramp, and also just happens to be one of the most popular episodes of the podcast.

Geoff Charles (04:06):
I ask, "What's the hardest thing you've ever done?" I ask that because working at Ramp is hard, and I want to understand what hard means for them. I want to understand why it was hard. I want to understand how they overcame that difficulty, how they worked with other people to overcome that difficulty, and how much agency they had in overcoming that. So it's a really good sign around what is difficulty to them and how much work they put into overcoming that.

Lenny (04:31):
Next up we've got Shishir Mehrotra CEO, and Co-founder of Coda. Funny enough, we posted this exact clip to TikTok and Instagram Reels, and it blew up. It's one of the most popular clips we've ever put on our channels. By the way, did you know I have a TikTok and an Instagram channel? Just look up Lenny's Podcast on TikTok or Instagram. Anyway, with that, here's Shishir Mehrotra sharing his favorite interview question.

Shishir Mehrotra (04:56):
It's a very simple question, and it's a coded Eigenquestion test. The question is, "A group of scientists have invented a teleportation device. They've hired you, Lenny, to be their business counterpart, bring this to market, product [inaudible 00:05:14]." This question will actually work well for any role. But say, "You could be a product manager for this thing, bring it to market. What do you do?" That's the whole question.

(05:23):
Usually people will start asking a bunch of questions and say, "Well, tell me more about this device. What does it do? How does it work? Is it big? Is it small? Is it vast? Does it disintegrate things or not? Does it need a receiver and a sender? Is it safe?" All these different questions come out.

(05:39):
I'll just let those questions come out, and at some point I'll say, "Okay, nice job generating all the questions. Turns out these scientists, they hate talking to people and they're kind of annoyed by all your questions. And so they've decided that they will answer only two of your questions, and after that they expect a plan. What two questions do you ask?"

(05:59):
Interestingly, all of a sudden the sharp product managers, engineers, basically every role, they very quickly find what are the one or two Eigenquestions on this topic. There's no right answer, but I'll tell you one of my favorite ones, because the product manager said, "Okay, if I had to ask two questions, the two questions I would ask, one, is it safe enough for humans or not?" That was a very crisp way to get to just safety. How reliable is it? They didn't ask how reliable it is, how many bits in the middle of this. "Just tell me, is it safe enough for humans or not?"

(06:31):
The second one is, "Is it more expensive CapEx or OpEx? Is it more expensive to buy them or to run them?"

(06:37):
And then he took those two questions, and he said, "Just with those two questions, I can form these quadrants." You can say, "Oh, it's safe enough for humans and they're very cheap to buy, but expensive to run." Then you probably run them like human fax machines. You put them everywhere you can and you say, "Hey, look, it's expensive to use, but you all have the ability to teleport anywhere you want and this is how we're going to run it."

(06:59):
On the other hand, they're very expensive to buy, but cheap to run, you'd probably have to place them very strategically, in which case what you'd probably do is replace airports. Because airports are pretty strategically placed in places where people are trying to get around places.

(07:12):
If it's not safe enough for humans, then you've got a whole different class of use cases where you go value what goods are transported in very costly ways? And people come up with, "Do you do the most expensive things? Is teleporting people's replacement [inaudible 00:07:29], is that a really demanding thing?"

(07:32):
But these two questions kind of get to the heart of it. The question is totally made up. No teleportation device exists, at least not yet. I find that people's ability to learn the method is significantly higher if it's low stakes.

(07:45):
That question, by the way, if you ask a kid that question, the new teleportation device, you get to ask two questions, almost every kid will quickly get to two pretty good Eigenquestions. Again, kids are incredibly good at simplifying these things down. It's actually a skill we remove from ourselves. A lot of your candidates tell me things like, "I guess I would ask them what size it is." I'm like, "Why would you ask them? What decision is that going to allow you to make, to know what size it is?" Sometimes they can explain it, but sometimes not. They don't get hired.

(08:16):
But then, actually, the thing I'd say about it is, there are Eigenquestion kind of everywhere. You could take any product out there. I'll do it with my kids a lot. I was just riding with with my younger daughter, and she said, "How come there's three gas stations in the same corner? Why do people do that?" That's a really insightful observation. What's the Eigenquestion? How do you place a gas station? You can almost take anything and say, "What is the question that really drives this answer?"

Lenny (08:45):
This next interview question comes from Yuhki Yamashita, Chief Product Officer at Figma, also a former Head of Design at Uber.

Yuhki Yamashita (08:53):
"Describe to me a time when you were part of a controversial product decision. What did you do?" All those things. I think it's really revealing, because if they can set up this conflict and understand why this problem was really important and represent both sides and such that you can understand why that conflict existed in the first place, and they can do it in this kind of even-keeled way where you realize that they can take on these different perspectives, you start to learn a lot about that person, I think.

(09:25):
Or sometimes I just ask them for basic things like, "Okay, talk about a big problem that you worked on." The thought experiment for me is always, coming out of that, do I feel compelled to work on that problem? Right? No matter how boring it sounds on the surface, I think a really great product manager kind of casts something. It's like, "Well, this is why it's so existential and this is why it's so interesting, and really rallied the troops up. That's kind of one big thing of storytelling and communication, because at the end of the day, so much of our job is around that.

Lenny (09:57):
Next you'll hear from Katie Dill, Head of Design at Stripe; Karri Saarine, CEO of Linear; and Camille Hearst, Product Leader at Spotify, former Product Leader at Patreon; who all share the same favorite interview question.

Katie Dill (10:12):
"Tell me what work you are most proud of?" The reason I ask that is because, well, it helps me understand their taste and their judgment, what motivates them, what work they view as good and as a good outcome. It also helps me understand a little bit about what they like to do and where their gravity pulls them.

Karri Saarinen (10:36):
I think usually I like to ask what is the candidate most proud of and why on their professional life or otherwise. What they're most proud of and why? But I think it's gives you a little bit of indication of what the person values and how they think about things. Also, I think it's always nice that people can share something they think they did really well, and we can spend time on it, versus just asking something more negative things.

Camille Hearst (11:04):
I like to ask people to tell me about something they're really proud of that they accomplished, take me through the process, and talk to me about why they're proud of it. I find you can learn so much about a person's motivations, about their work ethic, about what they care about, what good looks like to them, and I think those are all really important things to understand about a person if you're going to work closely with them.

Lenny (11:29):
Next is JZ, Head of Product at Webflow, former Airbnb colleague, sharing her favorite interview question.

Jiaona Zhang (11:35):
I do like to do behavioral questions. Just really understanding, when they've been in challenging situations, when they've been in ambiguous situations, how do they navigate?

(11:44):
Ambiguity is a big one for me, because at the end of the day, the PM job is really ambiguous. It's really hard to describe on a piece of paper all the things that you're going to encounter. Good answers are people who put structure and a way forward through the ambiguity. That's what you look for. You want your PM to not just be like, "Oh no, we're swimming in ambiguity," but actually put a path forward.

(12:05):
I think, also, looking for people who are seeking help, seeking those inputs, as opposed to being like, "Yep, this is the way. This is very clear." Because, again, the chances of whatever path you chart out for any product, for anything that you're doing, is the right path from the first time that you do it, so rare. And so I want to see someone be able to get those inputs, be able to say, "This is the path. This is how I learned why I put this path together." And then going back to a lot of the stuff I think we touched upon in this podcast is like, what are the little milestones that make you say, "Hey, is this working? Is this not working?" And then make you either make a different decision. Seeing people do that really well is a big thing I look for.

Lenny (12:44):
Next up is Noah Weiss, Chief Product Officer at Slack.

Noah Weiss (12:49):
"What unfair secrets have you learned to improve the velocity and energy level of a product team?" When I say "unfair" or "secret", I usually mean not something that you probably read on a media [inaudible 00:13:02]. "What did you learn? How did you learn it? How does it work, and how do you apply it?" You also just get amazing, interesting bits of inspiration from asking that.

Lenny (13:11):
This next question comes from the very sultry voice of Ben Williams, former VP of Product at Snyk and now an advisor to product-led growth startups.

Ben Williams (13:22):
"Fast forward three years, what's different about you then?" A lot of people will default to telling you where they aspire to be in terms of role or title, but what I'm really looking for is signals of humility, of self-awareness, around areas of personal and professional growth. People who can be open about where they think they need to work on to grow themselves as people. I love that.

(13:49):
Also, just generally throughout interviews, I'm looking for curiosity. Day-to-day, good PMs will be asking "why" as much as my six-year-old son does, which is a lot, so I'll try and discern that through the course of the conversation. It's not really a question, but something I'm looking for.

(14:08):
And then maybe I want to flip it, because building on something that Adam Fishman was saying, his theme of evaluating the people dimension of folks you are potentially going to work with when you're interviewing with a company. This was a question I got asked myself recently by a candidate, which I just thought was brilliant, and that was, "Tell me about the diversity, equity, inclusion and belonging initiatives that you've recently personally been involved with?" It just felt like a really great way for them to be able to test alignment of their personal values with those of someone they'd be working with really closely, so I love that.

Lenny (14:42):
Next up is Meltem Kuran Berkowitz, Head of Growth and a very early employee at Deel.

Meltem Kuran Berkowitz (14:48):
"What would your siblings say about you?" It's very telling. If they have siblings; if they don't, I will say, "What will your parents say about you?" But it's very telling what you think other people think of you.

Lenny (15:00):
What do you look for in their answer that gives you a sign that they're a good candidate or not?

Meltem Kuran Berkowitz (15:05):
I look for sincerity and self-awareness. Your siblings are never ... I mean, I love my sister, but she'll call me. She'll talk to me a lot. Being aware of that is very important. If someone was like, "My siblings will say I'm very organized and that I'm the one that brings our family together," that's probably a bullshit answer. But if they're like, "Oh, yeah, they'll say these weird things about me," that shows a little bit of self-awareness and humbleness that I want to see in a person.

Lenny (15:30):
Next is Paige Costello, Co-Head of Product Management, and also Head of AI at Asana.

Paige Costello (15:36):
I like to ask, "Tell me about a time something went wrong. What was it? What did you do about it?" Yada, yada. Effectively, the question gets at, when the product failed, when something about the team didn't work, just things that go wrong because that's what happens when you're doing this work. Evaluating people's mindset, the way they talk about it, and the way they relate to evaluating the situation, I think it's a great question. It really tells you a lot about how people think and how they perceive themselves when things are not working well.

Lenny (16:15):
We are in the final stretch now. There's only five more interview questions to go. Next up is Nikhyl Singhal, VP of Product at Facebook, also one of the most popular episodes of the podcast.

Nikhyl Singhal (16:25):
"What's something that everyone takes for granted that you think is essentially hogwash or inaccurate?" Sometimes I'll ask a manager, "Look, you've managed hundreds of people in your career. What's conventional wisdom that you bet against, that you have found is actually inaccurate?" And you could do that for, "What do people think about AI that's inaccurate, that everyone believes?" You could do that for domains. You can do all kinds of things.

(16:53):
I'm always looking for people to break this sort of interview mindset. Everyone always prepares for interviews, and then their entire conversation is predicting what you think you want me to say. As a result, you can have high-quality people that you dismiss, because they weren't genuine.

(17:19):
There's no way to answer that question without being genuinely opinionated. Because it starts with, 'What is the thing that you think ...? I want to sit here and then tell me why it's inaccurate." When I break that wall, I'm testing, is this person authentic? Because sometimes I'm dismissing them because they told me nothing new. But I don't want the interview process to penalize them, and this was my save question.

Lenny (17:52):
This next question comes from Ayo Omojola, Chief Product Officer at Carbon Health, former Product Lead at Square, and also a former founder.

Ayo Omojola (18:01):
"Tell me something you did that worked out, but not for the reason that you thought it would work," or, "Tell me something you did that was a good decision that didn't work." A lot of my process is just teasing out introspection. It's just like, "Are you a person who is reflective about the decisions you've made, and why they worked and why they did not, and incorporating that into your model so you make different decisions next time?"

Lenny (18:21):
Next up is Scott Belsky, Chief Strategy Officer at Adobe, former Chief Product Officer of Adobe, also former Founder of Behance.

Scott Belsky (18:31):
I like asking about something people have learned about themselves that reveal the limitation in how they work. It's a way to test introspection, and once this person hits their limits or struggles, can they be open and introspective, or are they going to blame and point fingers? So I do ask that.

(18:49):
I also like the question, "Do you consider yourself lucky?" I think it's a fascinating question, because some people who are super-insecure about where they are and how they got there and might decline admitting luck. Those who are comfortable should admit that they were lucky. I mean, I think the truth is, we're all very lucky and certainly privileged, and I just think that that's always an interesting conversation.

Lenny (19:18):
Our penultimate interview question comes from Lauryn Isford, Head of Growth at Notion, former Head of Growth at Airtable.

Lauryn Isford (19:26):
"Tell me about a time that you delivered something that was impactful." I'm looking for someone to help me understand how they define impact and what it means to them. I think a good answer for a growth practitioner is intrinsic motivation about having an impact on the business.

Lenny (19:46):
Our final interview question is actually advice for doing reference calls, which comes after finding someone great through your interview process. This comes from Paul Adams, Chief Product Officer at Intercom, with a killer Irish accent.

Paul Adams (20:00):
I have to do referral calls. You're interviewing someone, you want to give them the job, and they've got referees. Of course, the referees they have are the best people that they ever worked with and their favorite managers. This question is, "What feedback will I be giving this person in their first performance review?" It's an amazing question, because the person can't dodge it. There's an answer, and it's incredibly enlightening.

Lenny (20:23):
And it's a wrap. Thank you so much for listening. I hope you found this valuable. Leave a comment either on the newsletter post, or in the YouTube comments, or even on Twitter. Let me know what you think. If there's a great response, we'll continue to do this. If not, we'll never do this again. All right, thank you. Enjoy.

---

## Becoming evidence-guided | Itamar Gilad (Gmail, YouTube, Microsoft)
**Guest:** Itamar Gilad  
**Published:** 2023-09-21  
**YouTube:** https://www.youtube.com/watch?v=aJWSn-tz3jQ  
**Tags:** growth, activation, onboarding, churn, metrics, okrs, roadmap, prioritization, user research, mvp  

# Becoming evidence-guided | Itamar Gilad (Gmail, YouTube, Microsoft)

## Transcript

Itamar Gilad (00:00:00):
You fake it, you do a fake door test, you do a smoke test, Wizard of Oz tests. We used a lot of those in the tabbed inbox by the way, one of the first early versions was actually we showed the tabbed inbox working to people. But it wasn't really Gmail, it was just a facade of HTML and behind the scenes and according to the permissions that the users gave us some of us moved just the subject and the sender into the right place. So initially the interviewer kind of distracted them and then showed them their inbox and then the top 50 messages were sorted to the right place more or less if we got it right. And people were like, "Wow, this is actually very cool." But it gave us some evidence to go and say, "Hey, we should try and build this thing."

Lenny (00:00:43):
Welcome to Lenny's Podcast where I interview world-class product leaders and growth experts to learn from their hard won experiences, building and growing today's most successful products. Today my guest is Itamar Gilad. Itamar, is a product coach, author, speaker and former longtime product manager at Google where you worked on Gmail, identity and YouTube. He also just published an awesome new book called Evidence-Guided: Creating High-Impact Products in the Face of Uncertainty. Itamar, has an important perspective on why and also how you can push your team and organization from an opinion-based decision-making process to a more evidence guided approach. In our conversation, Itamar, shares a number of very practical and handy frameworks that do just that including the confidence meter, metrics trees, GIST and the GIST board, plus his take on how people often misuse ICE for prioritizing ideas. Also, how you could make your OKRs more effective and so much more. Enjoy this episode with Itamar Gilad, after a short word from our sponsors. This episode is brought to you by Ezra, the leading full body cancer screening company.

(00:01:49):
I actually used Ezra, earlier this year unrelated to this podcast completely on my own dime because my wife did one and loved it and I was super curious to see if there's anything that I should be paying attention to in my body as I get older. The way it works is you book an appointment, you come in, you put on some very cool silky pajamas that they give you that you get to keep afterwards. You go into an MRI machine for 30 to 45 minutes and then about a week later you get this detailed report sharing what they found in your body. Luckily, I had what they called an unremarkable screening which means they didn't find anything cancerous. But they did find some issues in my back which I'm getting checked out at a physical next month probably because I spend so much time sitting in front of a computer. Half of all men will have cancer at some point in their lives, as will one third of women. Half of all of them will detect it late.

(00:02:40):
According to the American Cancer Society, early cancer detection has an 80% survival rate compared to less than 20% for late stage cancer. The Ezra, team has helped 13% of their customers identify potential cancer early and 50% of them identify other clinically significant issues such as aneurysms, disc herniations, which may be is what I have or fatty liver disease. Ezra, scans for cancer and 500 other conditions in 13 organs using a full body MRI powered by AI and just launched the world's only 30-minute full body scan which is also their most affordable. Their scans are non-invasive and radiation free and Ezra, is offering listeners $150 off their first scan with code Lenny150. Book your scan at ezra.com/lenny. That's E-Z-R-A.com/lenny. This episode is brought to you by Vanta, helping you streamline your security compliance to accelerate your growth. Thousands of fast-growing companies like Gusto, Quorum, Quora and Modern Treasury, trust Vanta to help build, scale, manage and demonstrate their security and compliance programs and get ready for audits in weeks not months. By offering the most in-demand security and privacy frameworks such as SOC 2, ISO 27001, GDPR, HIPAA, and many more.

(00:04:02):
Vanta, helps companies obtain the reports they need to accelerate growth, build efficient compliance processes, mitigate risks to their businesses and build trust with external stakeholders. Over 5,000 fast-growing companies use Vanta to automate up to 90% of the work involved with SOC 2 and these other frameworks. For a limited time Lenny's Podcast listeners get $1,000 off Vanta. Go to vanta.com/lenny, that's V-A-N-T-A.com/lenny to learn more and to claim your discounts get started today. Itamar, thank you so much for being here. Welcome to the podcast.

Itamar Gilad (00:04:40):
It's a pleasure being here, thank you for inviting me.

Lenny (00:04:42):
It's my pleasure. I thought we'd start with the story of your work on Google+ and Gmail and how those experiences formed your perspective on how to build a successful product. Can you share that story?

Itamar Gilad (00:04:57):
Google+ was my first experience at Gmail, I joined Gmail in August 2011 and the first thing they asked me is, "Let's connect Gmail with Google+." If you're hazy about the story, back then Facebook was massive. It's still massive but then it was growing like mushrooms, people were spending hours. That really freaked out Google and the obvious solution was to launch a social network of Google called Google+ and we all believe in this thing, it really caught on very well initially we all used it, we all believed in it. So our mission was to build this thing and Google really cut no costs. It created a whole new division within Google and it created a whole strategy around Google+ and we had to connect Gmail and YouTube and search to Google+ to make them more personalized in a sense and more social. So that was the idea and we went on and we launched a series of features in Gmail for a couple of years, honestly and Google+ itself became this massive project, very feature rich and with a lot of redesigns and iterations and none of it worked.

(00:06:09):
It turned out people actually didn't need another social network, people didn't love it, people didn't use it. Eventually in Gmail we rolled back all the Google+ integration a few years later and Google+ itself was shut down in 2019. So putting aside all the tremendous waste that went into this, all the millions of person hours and personal weeks. In hindsight, not only did Google bet on the wrong thing it missed much easier opportunities. So just not far from Google's headquarters there was WhatsApp, not very famous in the US but they actually created massive impact. Hundreds of millions of people were using their stuff and they became a threat to Facebook much more than Google was. So Google missed the opportunity of social mobile apps like WhatsApp, like Snapchat, etc and for me this story kind of was the epitome of what I call today, opinion-based development. We come up with an idea, we believe in it, all the indications show it's good.

(00:07:13):
Maybe the early tests show it's good, then we just go all in and we try to implement it and I made this very mistake many times as the product manager, I was the guy pushing for the ideas. So for me, this was kind of a turning point I felt we need to adopt a different system.

Lenny (00:07:32):
And just before you move on to the next story, how big was the team? Roughly how many years was spent on this area? Just to give people a sense of the waste as you said.

Itamar Gilad (00:07:41):
So there was a tremendous earthquake inside Google to create the Google+ team, teams and the entire divisions were kind of thrown apart and reformatted and I think at its peak it was about 1000 people inside-

Lenny (00:07:55):
Wow, [inaudible 00:07:56].

Itamar Gilad (00:07:56):
It was a division the size of Android and Docs and a really sizable thing, they're under their own buildings. It's taken from the playbook of Steve Jobs, create this whole secretive project inside and just run like hell.

Lenny (00:08:13):
Yeah. I remember though Facebook was really scared, I remember they shut everything down. It as like a code DEFCON one situation too, so it really scared Facebook at the same time.

Itamar Gilad (00:08:22):
Yeah, it's true. But at the end of the day, neither Google's advertising revenue was affected, neither was Facebook affected. So it turned out this idea was not that necessary after all.

Lenny (00:08:35):
Yeah, okay. So that's an example of something that didn't work because it was opinion based software, I think the phrase you used and then there's a different experience with tabs I think with Gmail.

Itamar Gilad (00:08:47):
That's right. So Google, is a very successful company. It's not for me to criticize it or to in hindsight kind of say you guys need to be better and some of the people that were behind Google+ was some of the smartest leaders and I still think they are despite this story. If you look back at the history of Google, how things started in the first decade or so. Google, was what I call an evidence guided company. So essentially it put a high premium on focusing on customers, coming up with a lot of ideas on looking at the data, looking at how these ideas actually worked out. They weren't shy about launching betas and things that were very rough and incomplete and learning from that and then they expected people to take action based on the results. So fail fast is a very famous paradigm and so you had to kill your project or pivot it seriously if it didn't work out and I think had we kept fail fast it would've really have helped Google+, if we had this mentality.

(00:09:56):
But for some reason with Google+, Google put this playbook aside and used a different playbook which I call plan and execute essentially. But I think inside Google the DNA still existed. So inside Gmail, the next project after Google+ was the tabbed inbox. So it was kind of the reverse of Google+, it started as a very small idea that no one believed in and we started looking what's behind the city? What's the goal? What's the problem actually we're trying to solve? It turned out that a lot of people were receiving social notifications and promotions, etc, and most of them were very passive. They weren't clearing their inbox, they were just living in this world of clutter and I came up with an idea how to fix this. I was sure it was great, I wanted to push it, plan and execute, but my colleagues were like, "Hold on, we actually tried this. We have a bunch of ideas to help people organize their inbox, they're not using it. Why is your idea good?"

(00:10:57):
So that sent us, kind of me and my team into researching these users into establishing a goal that was much more user-centric and then thinking of other ideas. And then we started testing them much more rigorously and basically we started testing on our own inboxes and then we recruited other dog footers, other Googlers to test the same inbox, then we put it outside for external testers. We did usability studies, we did data, we built a whole data mining team and a whole machine learning team to build the right categorization and we ended up with a solution that turned out to be very successful for a lot of these passive users. This was a surprise to a lot of people because most of my colleagues and most of the people I talk with actually know how to manage their inbox. So for them that solution makes complete nonsense, like splitting promotions and social to the side sounds like the stupidest idea. But there's about 85% of the population, 85 to 88% that absolutely love it and today Gmail has about 1.8 billion active users according to Gmail.

(00:12:14):
Most of these users are using this feature, so it was a pretty high impact feature as well.

Lenny (00:12:20):
And the feature specifically, just in case people aren't totally getting it is the promotions folder and the social I think and then the regular.

Itamar Gilad (00:12:27):
Yeah, there are a couple more that you can enable in settings if you like.

Lenny (00:12:30):
Yeah, I use it, I love it. Except it puts my newsletter in people's promotions folder, who do I talk to about that?

Itamar Gilad (00:12:36):
Yeah. Newsletters are a very complicated scenario for the categorization engine.

Lenny (00:12:41):
Yeah. We just need an exception for my newsletter and then we're good. Okay, but go on.

Itamar Gilad (00:12:45):
So in hindsight I was asking and saying, "Why was this project so different?" And I think the reason is that we didn't have that much confidence in our opinions. We had opinions, we had ideas but we didn't just go all in and just let's build it. We actually used an evidence guided system and I think that's not unique just to Google. I think every successful product company out there that you look at Amazon, Airbnb, anyone you will check, at least in their best periods they found a way to balance human judgment with evidence. They didn't try to obliterate human judgment and opinion just to supercharge them with evidence and they came up with very different models. Apple, is another example but the principle still holds in all of these companies.

Lenny (00:13:33):
Awesome. So you took that experience and all the experience you've had from coaching product leaders working with companies and you wrote this book called Evidence-Guided, which people on YouTube could see sitting there behind you. So I want to talk through some of these stories and then some of these other lessons and frameworks that emerged. But maybe just to start, what's the elevator pitch for this book?

Itamar Gilad (00:13:55):
So this is a book for people like us, product people who want to bring evidence guided thinking or modern product management if you like into their organizations. There's a lot of challenges, it's not simple, we all read the books, we all know the theory, we all know some parts of the system. It tries to give you a system how to do that, it's a meta framework that kind of helps you lift your organization in the direction of evidence guidance if that's what you want to do.

Lenny (00:14:23):
So going back to the story briefly before we get into the frameworks and lessons of the book. In the first example of Google+, basically it came top down, "Hey, we need to build a social network, go build it." Obviously that happens at a lot of companies, I don't know if there's an easy answer to this. But are there cases where it does make sense to approach it that way? Obviously Apple is a classic example of Steve Jobs, is like we need to build an iPhone. I don't know if that's exactly how it went. But are there instances where it is worth just approaching new product ideas that way based on the experience and creativity and insights of the founder? Or is your thinking it should always come from this evidence-based approach?

Itamar Gilad (00:15:01):
I think the founders are very important, especially in the startup and scale-ups phase. They come up with many of the most important ideas and it's super important that they have the space to express and to push the organization to look at those. However, it's not about shutting them down it's about looking at them critically. You need to create the environment in the organization where the leader comes and says, "You know what? I talked to these three customers, I figured it out. Here's what we need to do in the next five years." And you need to ask, "Where's your evidence?" And by the way, the example you give that's a classic example. Steve Jobs, he just brainstorm in his kitchen the iPhone and then just told the team to build it. That's the story Steve Jobs, told but it's not the real story at all. Now we know what actually happened and the iPhone has actually a story of discovery, of trial and error, multiple projects to do it, multitouch with phones, most of them failed.

(00:16:02):
Steve Jobs, was the architect. He kind of managed to connect the dots and eventually come up with this perfect device but he wasn't actually the creator, it wasn't his brainchild. He was actually against it for a while but over time as he saw the evidence, as he saw what this thing can do, as he saw the demos he was able to piece together something that was very useful.

Lenny (00:16:26):
That's really important insight. People that are hearing this might feel like I like this idea of pushing back and encouraging the founders to make it more evidence guided. In the case of say Google+, was it even possible? Could you have come to Larry and Sergey and be like, "Here's all this data I've gathered that tells us this is not going to work?" Do you have any advice for how to push back and encourage the founders and execs to really take the counterpoint seriously or really kind of vet their idea?

Itamar Gilad (00:16:58):
So another nice thing about Google is that it's a very open culture and people are not shy to tell even Sergey and Larry that they are wrong and they do this all the time. In certain forms, right? You need to know the right channels. But there was a very big discussion about Google+ and whether it's the right thing to create a clone of Facebook, there was a very public internal discussion. I think what I would change is not have this discussion based on opinions, because when you have the discussion you come with your own opinions usually the most senior person's opinions will win. That's just the way it is. If we had come with hard data and we said, "Listen, things are not actually panning out the way you guys are expecting. What can we do? Should we continue? Should we pivot this?" I think the discussion would've done better. Now I'm doing a huge disservice, I was not in all the discussions. I know probably in Google+, there were very serious discussions happening along these lines.

(00:18:02):
But it's just as a general trend, I find that evidence is very empowering for us smaller people in the organization or mid-level managers to be empowered to challenge the opinions.

Lenny (00:18:15):
Is there anything tactically you found to be useful and effective in giving people, say they don't work at Google. They work at companies where founders and bosses and execs are not as open to challenge. [inaudible 00:18:26] any tactically found about how to present a counter proposal or like, "Hey, I have this data that we should really pay attention to?"

Itamar Gilad (00:18:33):
I think if you come with data, if you run a secret experiment and you come back and you show them you usually get one of two results. Either they get extremely mad at you and they tell you to get back to work and to do what you were told and in that case, probably you need to start polishing your resume and look for another place either inside the organization or outside it because that person is not being reasonable to be honest. But the more common case is they're pleasantly surprised and that's what happened with Steve Jobs, as well. He was against phones but then people showed him all sorts of evidence that Apple can make a phone. He was against multitouch initially but then he changed his mind, there was a lot of back and forth. So even, Steve Jobs, given evidence was willing to flip and I say this in many organizations. So evidence is so powerful, that's why this is the principle I based the book on.

Lenny (00:19:28):
You have this concept of being evidence guided. People listening may feel like, "Hey, we're evidence guided, we're in experiments, we make decisions using data." Oftentimes they aren't actually and so what are signs that maybe you're not actually that evidence guided or as evidence guided as you think you are?

Itamar Gilad (00:19:45):
I think there's a few telltale signs that I look for, first the goals are very unclear. Either there are many or they're very kind of obscure and vague or they are about output, there's misalignment. So the goals part is not there, usually this goes hand in hand with metrics. Missing metrics or just using revenue and business metric but there's no user facing metrics. So that's another telltale sign, then there's a lot of time and effort spent on planning especially on road mapping. Creating the perfect roadmap which really can consume a lot of time of the top management and PMs, etc. Then as you go down you see there's not a lot of experimentation and if there is experimentation there's not a lot of learning and finally another telltale sign is that the team is disengaged. So the engineers are kind of getting the signal that what they need to do is deliver, they're focused on output, that's what they're measured on. So they're kind of disengaged, they're disengaged from the users, from the business, they don't care that much.

(00:20:57):
It's usually something that you can fix by adopting a more evidence guided system.

Lenny (00:21:05):
Okay. So let's dive into your approach to becoming more evidence guided. In the book, you share this model that you call the GIST model which is kind of this overarching approach to building a product that almost forces you to be more evidence guided. So let's just start with what's the simplest way to understand this GIST model?

Itamar Gilad (00:21:26):
With your permission, I can show a few slides.

Lenny (00:21:28):
Oh, let's do it.

Itamar Gilad (00:21:29):
And maybe that will help.

Lenny (00:21:32):
Here we go, and then yeah, a good excuse to go check this out on YouTube.

Itamar Gilad (00:21:36):
All right, you're seeing this? So this is the GIST model, goals, ideas, steps and tasks, and essentially it's tries to break the change which is a really big change for a lot of companies into four slightly more manageable parts. They're still big but each one you can tackle on its own and that's kind of the reason I kind of split it, and goals are about defining what we're trying to achieve, ideas are hypothetical ways to achieve the goals, steps are ways to implement the idea and validate it at the same time. So essentially build, measure learn loops and tasks are the things we manage in Kanban and Jira and all these good tools. These are the things that your development team is usually very focused on and just listening to this, a lot of this will sound familiar to you because GIST is not a brand new invention. It's a meta framework that puts in place a lot of existing methodologies. It's based on lean startup, on design thinking, product discovery, growth, There's a lot of all of these things here. It just tries to put them all into one framework or one model.

Lenny (00:22:43):
So what's the simplest way to think about what this model is meant for? Is this how you think about your roadmap? Is this how you plan? What is this trying to tell people to do differently in the way they build product broadly?

Itamar Gilad (00:22:56):
I would say these are four areas that you need to look at and ask, are we doing the right thing in each? In each you may need to change or even transform and as I go and explain each one of those I'll give you basically three things. In each chapter in the book I try to touch on three things. The principles behind them, the frameworks or models that implement the principles and then process and the process honestly is the most brittle part and the one that you would need to change and adapt to your company. Because not two companies are exactly the same, and it's very tempting when you write a book not to give any process but that's the part that people actually want the most. So it's included as well, but just be aware that you will have to change this process.

Lenny (00:23:44):
Awesome. Okay, so we're going to talk about each of these four layers. Before we do that, where do vision and strategy fit into this? Do they bucket into one of these four layers and how do you think about strategy and vision?

Itamar Gilad (00:23:55):
That's a great question, so there's this whole strategic context that is outside of GIST. GIST, is not trying to tackle that, it assumes it's in place, there's another huge blob which is research. GIST, is not about research it's more about discovery and delivery. But strategy is extremely important and you can use some of the tools we will talk about to develop your strategy as well. In many companies the strategy is just a roadmap on steroids, it's small plan and execute just on a grand scale and Google+ again, was a strategic choice actually if you think about it. So in the book there is a chapter where I touch on strategy and I explain how the same evidence guided methods are being used by companies to develop their strategy as well.

Lenny (00:24:43):
Awesome, maybe one last context question. So people might be seeing this and thinking okay cool, I have goals, I have ideas steps, I have tasks, I'm already doing this. What is this kind of a counter or reaction to? What are people probably missing when they're seeing this and they're like, "Oh, I see. This is like what we're not doing and this is the most important, this is something we should probably change." And we'll go through these in detail too.

Itamar Gilad (00:25:03):
I think talking about each one will help.

Lenny (00:25:06):
Okay, let's do it.

Itamar Gilad (00:25:09):
But we can talk about in each level what's actually being done. So when people say I have goals, usually they take the goals layer and use it as a planning session. They talk about what shall we build by when, what are the resources? And that's actually not goals at all, that's planning work.

Lenny (00:25:26):
Cool, let's talk about goals and I know part of this is OKRs related too, so I'm excited to hear your take on OKRs.

Itamar Gilad (00:25:33):
Oh, that's a whole different discussion. You had, Christina, the real expert over there so I doubt I can add more to that. But it's true OKR is all part of it, but let's start with goals. What's our goals supposed to be? Goals are supposed to paint the end state to define where we want to end up and the evidence will not guide you unless you know where you want to go, and in many companies what you have is goals at the top for revenue, market share, whatever it is, and then a bunch of siloed goals for each department. There's engineering goals, there's design goals, there's marketing goals, etc, and that actually pushes people into different vectors and it's really hard to decide. I would argue that in evidence guided companies, and you've worked for a few so probably you've seen this. They use models in order to construct overarching goals for the entire organization. One of the models I show in the chapter about goals is the value exchange loop.

(00:26:34):
 Where basically the organization is trying to deliver as much value as it can to the market and to capture as much value back, and by creating a feedback loop between these two you are actually able to grow very fast. Now, I would argue that you want to measure both of these and to put a metric on each and the metric we usually use to measure value delivered is called the North Star metric. I know you wrote an article, a very good article about it.

Lenny (00:27:01):
Thank you.

Itamar Gilad (00:27:02):
And in it you listed dozens and dozens of companies, like leading companies and what they considered the North Star metric is super interesting. I would argue that what they told you is what is the most important metrics we measure? What is the number one metric for us? But it's not what I call the North Star metric, the North Star metric measures how much value we create for the market. For example, let's take WhatsApp. WhatsApp for a very long time measured messages sent because every message sent is a little incremental of value for the sender, the receiver, it's free, it's rich media, you can send it for anywhere in the world, compared to SMS that's huge value. So if in year one we have a billion messages being sent in year two, two billion probably we doubled the amount of value. In Airbnb, I think one of your key metrics or the real North Star metric was nights booked. I don't know if it was still the case while you were there?

Lenny (00:27:55):
Yeah, absolutely.

Itamar Gilad (00:27:56):
And there are examples like this in Amplitude for example, they measure active learning users or weekly active learning users. Which are users that found in the tool some insight that was so important that they shared it with at least two other users and they consume it. So it's a very powerful thing to point at this metric and say, "This is the most important metric combined with the value metric that we want to capture, revenue, market share, whatever it is." Once you have these two, you can further break them down into what I call metrics trees. So there's a metric three for the North Star metric and there's the metric three for the top KPI, the top business metric which you see here on the left side in blue and usually they overlap. So you might find in the middle some metrics that are super, super important because moving them actually moves the needle on everything else.

Lenny (00:28:57):
Can you clarify again the difference between what you call this top KPI versus North Star metric?

Itamar Gilad (00:29:02):
So the North Star metric is measuring how much value we're creating for the user, the core value that they're getting. In this case this is some productivity suite, so this is number of documents created per month for example. Because we think that every document created maybe it's a small document, I don't know. AI is in fashion now, is a little incremental value, so that's the number we're trying to grow. The top KPI is what we expect to get, it should be revenue or profit.

Lenny (00:29:31):
I see, this is the value exchange. I see, one is what users are getting, one is what you're getting back from them.

Itamar Gilad (00:29:36):
Exactly.

Lenny (00:29:37):
Basically how the business is benefiting. Awesome. I think this is a really important concept, the metric tree. I think a lot of people think they have something like this in mind where they're just like, "Cool, here's our North Star Metric, here's the levers and things that we can work on to move that." But I think actually mapping it out the way you have it here where it kind of goes layers and layers deep to all of the different variables that impact this metric. Not only is it a way to think about impact and goals and things like that, but also helps you estimate the impact of the experiment you're potentially thinking about running. So if you're going to work on something at the bottom here like activation rate, say you move that 10%. How much is that going to impact this global metric? It's probably a very small amount.

Itamar Gilad (00:30:19):
This is a very important one and we'll talk about impact assessment shortly, this helps with it. It also helps with alignment because the entire organization is trying to move these two metrics, it's the two sides of our mission essentially. We have the mission that's the top objective of the company and these are the two top most key results if you like, the top most things. So when you go and work with another team and you say, "Hey, why don't you work on my project?" They might say, "This idea actually might move the North Star metric model in your idea." And that helps you guys align and I've seen cases where team B put aside their own ideas to jump on the ideas of team A, because of this model. It also creates an opportunity to give some sub metrics to teams to own on an ongoing basis, so it creates a little sense of ownership as well and mission within the tree.

Lenny (00:31:10):
It also helps you figure out what teams you should have, which teams have the biggest potential to impact the metric.

Itamar Gilad (00:31:18):
Another thing that happens in a lot of organizations, the team topology reflects the structure of the software or some hierarchical model where we want to organize the organization in a particular way. But if you start with a metrics tree, you can try to arrange the topology around goals and sometimes you need to readjust. It's not a constant reorg but from time to time you will realize the goals have changed and we need to reorganize, so the tree helps visualize that as well.

Lenny (00:31:49):
I think for people that are listening to this and thinking about this, I think the simplest way to even think about this is basically there's a math formula that equals your North Star metric or your revenue or whatever you're trying to do and if you don't have some ideally really clear sense of what that math formula is you should work on that. Because that will inform so much of how you think about where to invest, what teams to have, where to invest more resources, less resources.

Itamar Gilad (00:32:13):
Right.

Lenny (00:32:15):
Imagine a place where you can find all your potential customers and get your message in front of them in a cost-efficient way. If you're a B2B business, that place exists and it's called LinkedIn. LinkedIn Ads allows you to build the right relationships, drive results, and reach your customers in a respectful environment. Two of my portfolio companies Webflow and Census are LinkedIn success stories. Census had a 10x increase in pipeline with the LinkedIn startup team, for Webflow after ramping up on LinkedIn in Q4 they had the highest marketing source revenue quarter to date. With LinkedIn Ads, you'll have direct access to and can build relationships with decision makers including 950 million members, 180 million senior execs and over 10 million C-level executives. You'll be able to drive results with targeting and measurement tools built specifically for B2B. In tech LinkedIn, generated two to five X higher return on ad spend than any other social media platforms. Audiences on LinkedIn, have two times the buying power of the average web audience and you'll work with a partner who respects the B2B world you operate in.

(00:33:20):
Make B2B marketing everything it can be and get $100 credit on your next campaign, just go to linkedin.com/podlenny to claim your credit. That's linkedin.com/podlenny, terms and conditions apply. Okay. So metrics trees, what comes next?

Itamar Gilad (00:33:39):
All right. So next we need to go to the ideas layer and the ideas layer is there to help us sort through the many ideas we might encounter and they may come from as you said the founders, the managers, the stakeholders, from the team, from research, from competitors. We're flooded with ideas, and what usually happens inside organization is some sort of battle of opinions or some sort of politics sometimes or highest paid person's opinion. You had, Ronny Kohavi, who invented this term in your show. What doesn't happen is very rational, logical decisions these are the best ideas, because it's really, really hard to predict honestly. There is so much uncertainty in the needs of the users, in the changes in the market, in our technology, in our product, in our own organization. It's almost impossible to say this idea is going to be the best, but we do say this because we have cognitive biases that kind of convince us that this idea is far superior to anything else and it's definitely the right choice.

(00:34:48):
In order to avoid this, what we want to do is to evaluate the ideas in a much more objective and consistent and transparent way. In the book I suggest using ICE, impact, confidence and ease. I think I have a slide coming on this. So impact, confidence and ease which is basically a way to assign three values to each idea. The impact tries to assess how much impact it'll have on the goals and that's why it's so important that we have very clear goals and not many. How we are measuring the ideas on the North Star metric, on the top business KPI, on a local metric of the team. Whatever it is, let's be clear about it and then let's evaluate the ideas against this thing. Ease, is basically the opposite of effort. How easy or hard it's going to be, but both of those are guesstimates, both of those are things we need to estimate. I would argue that just by breaking the question to these two questions we usually have a slightly better discussion than just my idea is better than yours.

(00:35:52):
But then there's the third element which is confidence, which tries to assess how sure are we or should we be about our first guesstimates about the impact and the ease.

Lenny (00:36:03):
It's interesting you use the word ease, because I think it's usually effort. You kind of make it positive, is that an intentional tweak you made?

Itamar Gilad (00:36:12):
I'm using the definitions of, Sean Ellis. Sean, invented ICE. You know Sean, I don't know if you've had him yet? But he's-

Lenny (00:36:21):
I haven't had him on yet.

Itamar Gilad (00:36:23):
Yeah. For the people who don't know him, Sean, is amazing. He's like one of the fathers of the growth movement, he coined the term growth hacking and he popularized the concept of product market fit.

Lenny (00:36:36):
Yeah.

Itamar Gilad (00:36:36):
He created ICE, he created a bunch of things that we use in product that we don't even know.

Lenny (00:36:40):
Wow, I didn't know he came up with ICE. Okay, cool. So the original version of ICE is ease instead of effort.

Itamar Gilad (00:36:45):
Exactly, yeah.

Lenny (00:36:45):
Fun fact.

Itamar Gilad (00:36:47):
A lot of your viewers are wondering where's the R because there's another variant of this culture. RICE, where there's rich as well. I prefer ICE because I prefer to fold the rich into the I for various reasons but both are valid, both are equivalent in a sense.

Lenny (00:37:04):
I'm in your boat, that's exactly how I think about it. I think people over complicate this stuff and try to get so many math formulas involved with estimating impact, and I feel like these are just simple heuristics to kind of bubble the best ideas to the top. It doesn't have to be a perfect estimate of impact and confidence and all those things, so I think the simpler is better and it always ends up being a spreadsheet. People always have these tools to estimate these things but it's like a spreadsheet, Google Sheets. Great.

Itamar Gilad (00:37:28):
So yeah, you're actually leading me to my next point. So when you come to estimate impact you will realize it's the hardest part. So sometimes it's just a gut feeling and it's a guess and sometimes it's based on some spreadsheet or some analysis and the back of envelope calculation you've done and I think that's legitimate. Sometimes these things do show you some things you didn't think of and sometimes the best case it's based on tests. You actually tested it, you interviewed 12 customers, you show them the thing and out of those only one actually liked it. You should reduce your impact based on that usually, or you do other types of tests. We'll talk about testing in a second. What happens is that people tend to just go with gut instinct and then give themselves a high confidence. They say it's an eight and I'm pretty convinced, so it's eight for confidence and I found this a bit disturbing because it kind of subverts the whole system.

(00:38:22):
So I wanted to help people realize when they have strong evidence in support of their guesses and when it's weak evidence, how to calculate confidence in a sense. For that I created a tool called the confidence meter, which you can see here this colorful thing and should I go and explain it?

Lenny (00:38:41):
Yeah, let's do it. And then again, if you're just listening to this you can check this out on YouTube and you can see the actual slide.

Itamar Gilad (00:38:47):
All right, awesome. So basically I constructed it a bit like a thermo meter. It goes from very low confidence which is the blue area or the upper right, all the way to high confidence which is the red area and you can see the numbers going from zero to 10. Where zero is very low confidence, we don't know basically anything we're just guessing in the dark and 10 is full confidence. You know for sure this thing is a success, no doubt about it and across the circle I put various classes of evidence you might find along the way. So for example, starting at the top right, all of these blue areas about opinions. It could be your own self-confidence in the idea, your self conviction, you feel it's a great idea. Guess what? Behind every terrible idea that was ever someone thought it was great, that gives you 0.01 out of 10. Maybe you created a shiny pitch deck or a six-page document that explains in detail why this is a great idea. Slightly harder to do but still very low confidence, maybe you connected it to some theme, it's about the blockchain...

(00:39:59):
Well sorry, the blockchain is out of fashion. What's hot right now?

Lenny (00:39:59):
AI.

Itamar Gilad (00:40:04):
Exactly, AI. It's about AI, that makes it a good idea? Absolutely not. Or the strategy of the company, that's another thematic support. Thousands and thousands of terrible ideas are being implemented right now as we speak based on these themes. So all these things combined can give you a maximum 0.1 out of 10 according to the tool, if you follow it then we move into slightly harder tests. One is reviewing it with your colleagues, your managers, your stakeholders the idea. They don't know it either, they don't have a crystal ball, they're usually not the users, they cannot predict. But they can evaluate it in a slightly more objective way and maybe find flaws in your idea. On the other hand groups tend to have biases too, politics group thing. So groups can actually arrive sometimes with worse decisions than individuals, there's some research to that. Next, our estimates and plans. So you may do some sort of back of the envelope calculation or your colleagues might go out and try to evaluate the ease a little bit better.

(00:41:07):
That gives you a little bit more confidence, but still we're at the level of guesswork at this point. Next we're moving to data and data could be anecdotal. So you find a few data points dotted across your data or you talk to a handful of customers or maybe one competitor has that same idea. In many companies I meet, if the leading competitor has this feature and we think it's a good idea validation is done. Let's launch it, that's it. It's a great idea, we need to do it. It never works honestly, you should not assume that your competitor actually knows what they're doing anymore than you do. Data could be also what I call market data. That comes from surveys, from assessing a lot of your data by doing a deep competitive analysis and there are other methods where you create a larger dataset and you contrast your idea against it. Finally, to gain medium and high confidence you really need to build your idea and test it and that's where the red area is.

(00:42:11):
So there's various forms of tests, we'll talk about them if we have time and they give you various levels of confidence.

Lenny (00:42:19):
Awesome, this is a very cool visual. We'll link to a image of this in the show notes too if people want to check it out. I think what's awesome about this is you could just use this as a little tool on your team of just like where are we along the spectrum? We think the impact of this is very high. But we're probably in this blue area of confidence and so let's just make sure we understand that and it's really clear language to help people understand. I see if we had this, it'd be a lot more confident.

Itamar Gilad (00:42:45):
So you can also tie your investment into the idea based on the level of confidence you had found essentially, so early on you want to do the cheap stuff just to gain more confidence and then you can go and invest more. If it's a really cheap idea, you can jump to a high confidence idea, you can test, you can do an AB experiment. Early adopter program, whatever it is and then launch it. Some ideas you don't need to test, sometimes the expert opinion is enough. If you're just changing the order of the settings, no one sees this or no one will be impacted. The risk is low, you can launch it without testing. So part of the trick is also knowing when to stop, not just trying to force your way all the way up when you don't have to.

Lenny (00:43:31):
That's a really important point. The other important point here is just a big part of a PM's job is to say no and to stop stupid shit from happening and this is an awesome tool to help you do that. To be like, okay, here's this idea you have, just like let's just be real, how confident are we in this? And, okay, it's going to take us three months to do this. Maybe we should think about something different, maybe we should work up the confidence meter before we actually commit to this.

Itamar Gilad (00:43:56):
Yeah. This is a real world usage that I hear about a lot, some people use this to kind of do... An objective way to say no and gently. Or to say we'll think about it but look at these other ideas we have and how their impacting is and confidence stack up.

Lenny (00:44:12):
Classic PM move, just like that was a great idea but what about this better idea? Coming back to something that we talked a bit about at the beginning, say you have a founder who's actually very smart and experienced. Say even at a startup where you don't really have the time to build tons of evidence for ideas. Do you have a different perspective on how much time to spend building confidence in ideas versus just like cool, they actually have really good ideas let's just see what happens?

Itamar Gilad (00:44:41):
So there's always like a trade-off between speed of delivery and speed of discovery, and that actually leads to the next layer of how do we combine the two? Because people tend to think it's an either/or. Either we are building very fast or we are learning and then we're building very slow, but I think we're using the wrong metric. The metric is not how fast can we get the bits into production, when there's a lot of uncertainty and we all face uncertainty and startup especially. It's not about getting the bits to production, it's about getting the right bits to production. It's about creating the outcomes that you need, the impact, and so it's about time to outcomes and I would argue that the evidence guided method is far more impactful. It's far faster, it's far more resource efficient than the opinion-based method. Because opinion-based methods tend to waste a lot more of your resources, building the wrong things or discovering, learning too late. Well, evidence guided helps you learn earlier.

(00:45:50):
Plus it is a fallacy that if you learn you don't build, good teams know how to do both at the same time and that's actually what the steps layer is meant to teach you or to help you do.

Lenny (00:46:03):
Awesome. So maybe just to close off that loop, say someone listening is at a bigger company, say Netflix versus a series A, series B or startup. Is there something you'd recommend about them approaching this differently? Any kind of guidance there of just how to take what you're sharing differently if you're a different source of companies like that?

Itamar Gilad (00:46:23):
Absolutely. I think the concept we talked about of the North Star metric, the value created versus the value captured is very important in every company. Building your entire metrics trees, maybe overkill, doing heavy weighted OKRs may be overkill for early stage. Early stage companies even don't know how they create value, so they need to iterate and their goals is really to find product market fit. Beyond that, what happens is that you need to start building your business model. So that's your goal and you iterate towards that and you need to put metrics on that and then when you move into scale, you need to try to create order because when you scale up... And all of this is covered in the book, there's a special chapter just about these questions. When you scale up, you get a lot of people and a lot of money and everything is happening at the same time. So there you need a order of evaluating ideas in a very systematic way. In a company like Netflix, by the way I don't know if they need this specific method. They're very-

Lenny (00:47:27):
Yeah, maybe that was a bad example. They're probably doing things pretty well.

Itamar Gilad (00:47:30):
One thing I discovered by the way, there's two types of companies that really benefit from this technique. One is those companies that are kind of emerging into modern product development. They have product teams, they have product managers, they have OKRs, they're starting to do Agile. But they're starting to do experimentation, but they're struggling to put it all together. Every CPO is building their own little framework and the other type is those companies that used to be evidence guided and they regressed and that happens way too often. Change of management, change of culture, and then all of a sudden they need to rediscover, to rekindle that spirit that was lost along Google+. So some of the people that actually respond to the strongest are actually surprisingly in these companies.

Lenny (00:48:19):
What I love about your frameworks and kind of all these things we're talking about is these are just a... You can almost think of them as a grab bag set of tools to make you more evidence guided as a company. You could start with thinking about the confidence meter, you could start using ICE more. You could start using the metrics tree and all these things just push you closer and closer to being more evidence guided, you don't have to adopt this whole thing all at once.

Itamar Gilad (00:48:41):
Absolutely. I would recommend that you don't try because if the transformation is way too big, you will get fatigued and you will just create a lot of process for a lot of people and you would not see the results and after a quarter you'll give up. So exactly what you suggested is the right approach.

Lenny (00:48:57):
What would be the first thing you'd suggest if people were trying to move closer to being less opinion oriented and more evidence-based? Which of these frameworks or models would you recommend first?

Itamar Gilad (00:49:06):
I recommend that they discuss internally where is the biggest problem that they're facing. If the goals are unclear, there's misalignment, we keep chasing the wrong things, start at the goals layer. Try to establish your North Star metric, your top business metric, your metrics trees, start assigning teams with their own area of responsibility. If you're spending a lot of time in debates and you're constantly fighting and changing your mind. Start with the ideas there and establish impact is confidence or whatever prioritization model you like, but involve evidence in it. I think the confidence meter is a good tool to use irrespective. If you're building too much and you're not learning enough, start adopting the steps layer which we haven't seen yet and if your team is very disengaged. You have one of these teams where the developers are very into Agile, very into quality, very into launching things, start working on the tasks there.

Lenny (00:50:10):
Awesome. Okay, let's keep going.

Itamar Gilad (00:50:13):
All right, so steps. Steps are about kind of helping us learn and build at the same time as we said and one of the patterns I see is that organizations don't know that they can actually learn at a much lower cost. They believe they need to build this elaborate MVP which is not minimal in any way and then launch it and then they will discover it and basically it's what we used to call beta 20 years ago but just with a different name. What I'm trying to do here in the steps layer is to help companies realize there's a gamut of ways to validate your ideas or more specifically to validate the assumptions in your idea and I created a little model for this, it's called after assessment fact finding, tests, experiments and release results. But again, it's just putting together things that much smarter people invented. So in assessment you have very easy things, things that don't require a lot of work. You check if it aligns with the goals, this idea that you have in your hand.

(00:51:14):
You do maybe some business modeling, you do ICE analysis, you do Assumption Mapping which is great tool by, David J. Blend, or you talk to your stakeholders one-on-one just to see if there are any risks, etc. These are usually not expensive things and they can teach you an awful lot about the impact and the ease of your idea. The next step is to dig data and usually that goes hand in hand with this. So you can find data in your data analysis through surveys, through competitive analysis, through user interviews and through field research, observing your users. Obviously these last two are pretty expensive, so it's often good not to wait until you have the idea and then start doing your research. It's best to keep doing your research ongoing and then you have some sort of data to lie on and to compare your idea against. But until now we didn't build anything, now you're ready to start testing, building versions of the product and putting them in front of users and measuring the results. But initially you don't build anything, you fake it.

(00:52:18):
You do a fake door test, you do a smoke test, Wizard of Oz test, a concierge test, usability test. We used a lot of those in the tabbed inbox by the way, one of the first early versions was actually we showed the tabbed inbox working to people. But it wasn't really Gmail, it was just a facade of HTML and behind the scenes and according to the permissions that the users gave us. Some of us moved just the subject and the sender into the right place. So initially the interviewer distracted them and then showed them their inbox and in it the top 50 messages were sorted to the right place, more or less if we got it right and people were like, "Wow, this is actually very cool." And that gave us a lot of evidence.

Lenny (00:53:02):
That's an awesome story. So that was in the user research, it wasn't rolled out to people? It was a manual individual?

Itamar Gilad (00:53:08):
There wasn't a single line of code written, this was just cooked up by the researchers and our designers. But it gave us some evidence to go and say, we should try and build this thing.

Lenny (00:53:19):
Love that.

Itamar Gilad (00:53:21):
So initially you fake it, mid-level tests are about building a rough version of it, it's not complete, it's not polished, it's not scalable, but it's good enough to give to users to start using. So those are early adopter programs, alphas, longitudinal user studies and fish food. Fish food is testing on your own team.

Lenny (00:53:40):
Fish food? I haven't heard that term before. So it's dog fooding, but more local to your team.

Itamar Gilad (00:53:46):
I think it's a Googly thing, but some people told me that they use fish food as well in their company the name. So I'm using it, I don't know if there's a better name for it.

Lenny (00:53:54):
I wonder why it's called fish food, because it's like little? It's like little gentle little clicks?

Itamar Gilad (00:53:58):
It could be. Yeah, I don't know.

Lenny (00:54:00):
Wow. Okay, super cool. I'm learning a lot here.

Itamar Gilad (00:54:03):
So the next stage is to actually build a kind of more complete version of this and then you can dog food it, then you can give this to your users internally. When I joined Microsoft many years ago, the first thing I noticed was that Outlook was very buggy and I asked people what's going on? And they told me we are all dog fooding the next version of Outlook that hasn't come out yet and that's a very common practice in Silicon Valley. You can do previews, you can do betas, you can do labs, so those are tests. Now, there's a special class of tests which are experiments because they have a control element. So AB tests, multivariate tests, those are all experiments. I'm using the word experiment the way data scientists use it, although people tend to call experiments to everything that you see here and finally, even the release you can do stage release, you can do percent launches, you can do hold backs. All of these things help you further validate your assumptions. Sometimes you need to roll back and change things, but it's another opportunity to learn.

(00:55:06):
So the key point is you don't have to start at the right-hand side, which is expensive. You can start early on and that leads to poking a lot of ideas very quickly. You realize they're not as good as you thought, and then you can invest more effort into the good ideas. If they generate positive evidence, you can go further and further until that point where you feel you're ready for delivery.

Lenny (00:55:29):
Okay. So we've talked about goals, we've talked about ideas, we're talking about steps here. Is there anything else along steps? And then next I know comes tasks.

Itamar Gilad (00:55:37):
No, this is it for steps. There's a lot more with this, we will not go into all of it.

Lenny (00:55:42):
Okay, that sounds good. Let's talk about tasks and what you mean there.

Itamar Gilad (00:55:46):
All right, awesome. So in many organizations there's these two worlds. There's the planning world where basically you have the managers, the stakeholders, some of the PMs really sit and think about what we need to launch and that's where we create the strategies and the roadmaps and the projects. But guess who is not invited to the party? The people who are actually doing the work. They live in Agile world, they're very focused on moving tickets to the done state, on completing burning story points, pushing stuff into production and there's a big gap between these two worlds. They don't understand each other, they don't see eye to eye, there's a lot of mistrust being built sometimes against the plans or the managers feels that the teams are just not being very effective. We've seen all of this and the solution, the stop gap is to put a PM in the middle. The PM is supposed to make all of this work, deliver on the roadmap like a project manager, feed the Agile machine with perfectly prioritized product backlogs and stories and it just doesn't work honestly.

(00:56:50):
And the PMs I meet are very tired and they have to spend so much time in planifications and roadmap discussions and they're very busy, they don't have time to do research or to test ideas. So I suggest changing this and bringing the developers a little bit out of their Agile cage if you like and no disrespect to Agile, it's a great thing but let's let them do more than just develop. Let's let them discover as well and one of the tools I suggest and again this is a process is what I call the GIST board. So it's basically the top three layers of GIST. The goals are on the right, these are just the key results usually per team I suggest not more than four. So you create a GIST board per team, then the ideas we're working on right now sometimes with our ICE scores and then the next few steps that we might want to pursue in order to validate these ideas and this is a very dynamic thing.

(00:57:48):
It changes all the time, the team leads need to update it and the team needs to meet around it at least once every other week to think to talk about what's going on. Are we still following the right ideas? How are we doing on the goals? What are the next steps? What's blocking us from completing the most important steps? And this is a discussion that is not happening today, because most of the discussion happens at the roadmap level and then there's a lot of discussion at the task level. But this middle layer of what actually are we trying to achieve and how well are we doing on it doesn't exist. If you do have this, you create a lot more context in the minds of your team and then they need to ask you fewer questions. You need to tell them less what to do. They know what's success and they are able to actually do a lot more on their own.

Lenny (00:58:37):
Is the way to think about the GIST board as the way you should be road roadmapping or is this more of a strategy framework to think about why you should be prioritizing broadly?

Itamar Gilad (00:58:48):
The way I say this is at the beginning of the quarter, the team defines its goals. The leads of the team define the goals, but they review it with the team, they review it with the managers, of course with the stakeholders. Everyone's in agreement, these are the maximum four key results and the one or two objectives you guys need to work on, teams cannot deliver on more than that. You copy these key results into the GIST board, then you start looking at your idea bank or you start generating ideas and say, how can we achieve these key results?

Lenny (00:59:18):
And to clarify the thing you copy is the key result as the goal?

Itamar Gilad (00:59:22):
Yes, exactly. You can write the objectives alongside that to remind people what are we trying to achieve, but the key results are the thing we show here. Then you pick some ideas, the ones that look most promising and as unintuitive as it sounds or counterintuitive as this sounds I would recommend that you let the team pick these ideas. The manager of the stakeholders can propose the ideas, everyone can propose, but the team should use the ICE process to kind of... And especially the product manager is very important here to choose which ideas to test first. Then the team together needs to develop which steps should we run, how can we validate this? Some of the steps will be done by the PM, some by the data analyst, some by the user researcher. But some will involve the team, there'll be some coding, there'll be some running of experiments and so there's some ownership around the steps. A sub team owns each one of these steps and we will change the board very actively.

(01:00:24):
So if an idea turns out to be bad we will take it off the board and put another idea in this place or maybe we achieve the goal, we don't need to work on this anymore, we can focus something else. So it's a project management tool in a sense.

Lenny (01:00:36):
Awesome. So I'm looking at it and I think maybe the most important piece of this is that steps aren't just like a project, like launch a better onboarding or add the step to onboarding. It's you want to emphasize the steps that you're going to take to get to more and more confidence essentially, and more and more evidence guided thinking versus just, "Well, let's figure out how to launch this feature idea."

Itamar Gilad (01:01:03):
Exactly. It's not a engineering milestone or a design milestone, it's a learning milestone. So we build something and along the way we actually grow the scope of what we build. We are building the product in the process and we learn, so the two have to come hand in hand.

Lenny (01:01:20):
And for folks that aren't watching this on YouTube, just to walk through an example, we'll do it real quick. So one of your goals here is average onboarding time, you want your goal to be the average onboarding time less than two days, currently five and a half days. An idea there is an onboarding wizard, and then the steps are a usability test with mockups and then a usability test as a prototype and then an AB test?

Itamar Gilad (01:01:42):
Yeah, basically, and you can alter this as you go along. Sometimes you can run multiple steps in parallel it's not always sequential. But that's basically the process, yeah.

Lenny (01:01:53):
Awesome. So again, what you're trying to emphasize here as a team is just we're not just going to launch this onboarding wizard and we're not going to figure it out later. It's like let's be upfront about the steps we're going to take to build more and more confidence. This is something we should keep investing more and more in, which is really interesting.

Itamar Gilad (01:02:09):
Yeah, and another interesting thing that happens every time you run a step if it's successful you have evidence and you can go back to the managers and tell them and share and say, "With this idea we thought it was great, but we got this result. What do you think that means?" And sometimes that manager that propose it would say, "I think the test failed, let's rerun it." Or sometimes they will say, "Maybe it's not as strong as I thought. The discussion just becomes that much more nuanced and objective if you like.

Lenny (01:02:42):
Maybe just to close out this framework. How does this relate to a roadmap that they may have in a spreadsheet or in Jira or in Asana or something like that. Does this sit on top of that? Is this replacing a roadmap somewhere else?

Itamar Gilad (01:02:54):
I would say that release roadmaps where you are just saying by Q3 we want to launch this or by October we have to launch that, they're kind of competing with this. If you're doing that and people know that the goal is to launch that thing by October, forget about learning, forget about evidence guided, I recommend using outcome roadmaps saying by October we want to achieve this outcome. By Q4 we want to launch in another three countries, or we want to grow our usage in India by that much, by this time we need to tackle the problem of churn and how we achieve this. Sometimes we know we have a concrete idea that is high confidence that we already tested, we switch into delivery, then we can put it on the roadmap and say, "Yeah, we're going to build this thing and we'll aim for October." But otherwise you want to keep it open and the roadmaps can kind of suffocate this process if you decide upfront with low confidence that this particular idea must be launched.

Lenny (01:04:04):
Okay. So you're proposing people switch the roadmapping practice to this, which is very ambitious. I love it.

Itamar Gilad (01:04:10):
Well, this is not a roadmap. This is just a tool for the team to manage the project, but I have a proposal for outcome roadmaps inside the book.

Lenny (01:04:20):
Okay, awesome. Okay. So I was going to ask if people wanted to try this approach, the book is the best way to fully understand the framework and how implement it.

Itamar Gilad (01:04:30):
That's one way. I have articles, I have resources on my site, but I try to condense much of what we just discussed in a lot more nuance in the book. So if you are interested in that, I would give it a go.

Lenny (01:04:45):
Awesome. Maybe just on the topic of OKRs real quick. How do OKRs connect to all this? It sounds like broadly you kind of assume people will keep working on here's our metric or key results or objectives and then that plugs into this kind of GIST framework.

Itamar Gilad (01:05:01):
So the metrics trees, plus your mission, plus the individual missions of the teams give you most of what you need to populate your OKRs. There's of course a process of alignment, top down, bottom up, side to side, which I talk a little bit about as well. OKRs is a very rich topic, but those things are usually the core. There's usually some other OKRs that's about the health of the company, the health of the product, etc. Those are called supplementary OKRs, I talk about those as well. So yeah, I think OKRs are a helpful tool if you like them.

Lenny (01:05:37):
And just zooming out again. Basically you don't need to take all of these ideas and lump them all together and change the way you work as a business. You can start with picking some of these ideas and starting to become more and more evidence guided. It sounds like this GIST board isn't where you probably want to start, but maybe it's once you have more and more experience using some of these tools or you tell me. Do you sometimes go straight to this way of thinking about the roadmap and the plan?

Itamar Gilad (01:06:04):
So it might not be the full board because you're missing some of the pieces, maybe your goals are not as good or your idea prioritization isn't as good. But if your team is very, very delivery focused and sometimes it's also the opposite. The managers are telling them how to build and you want to break this kind of dynamic, you want to create a step backlog. So instead of a product backlog, let's create a backlog of steps which are just validation steps, betas and previews, etc, and that changes the dynamic pretty strongly.

Lenny (01:06:39):
So by the time this podcast comes out, the book will be out. What is the best place to find the book?

Itamar Gilad (01:06:44):
Hopefully on Amazon, you can search for it. You can go to my site, itamargilad.com and it'll be presented prominently there and there's also the book landings page where you'll find everything you need to know about the book, evidenceguided.com.

Lenny (01:06:59):
Well, with that we've reached our very exciting lightning round. Are you ready?

Itamar Gilad (01:07:03):
Yes, let's go.

Lenny (01:07:04):
What are two or three books you've recommended most to other people?

Itamar Gilad (01:07:07):
So I'm going to cheat, I'm going to recommend a series of books so two series. One is the-

Lenny (01:07:12):
Cheating is allowed.

Itamar Gilad (01:07:13):
All right, cool. One, and those are obvious one. One is the series published by SVPG, Silicon Valley Product Group. So INSPIRED, EMPOWERED, now I think TRANSFORMED has come out, I haven't read it yet but I'm sure it's amazing. So this is Marty Cagan and his colleagues, they write some tremendous books and every product manager should read them. The other series, a bit older, this is the Lean series, The Lean Startup, Lean Enterprise, Lean Analytics, there's gold in all these books, Lean UX, really, really important books and I think they're not as appreciated as they should. Running Lean, that's another example.

Lenny (01:07:54):
What is a favorite recent movie or TV show?

Itamar Gilad (01:07:57):
I'm not really a big TV or movie buff, I just put on whatever comes up. I'm discovering that YouTube is actually becoming one of my sources of information entertainment. I'm learning a lot of Spanish recently, so I discovered this channel called Dreaming Spanish which is if you're learning Spanish it's incredible. So that's my recommendation.

Lenny (01:08:19):
That's a unique choice, I love it. Favorite interview question you like to ask candidates.

Itamar Gilad (01:08:24):
I like to ask them to design something for a niche audience. So a navigation system for elderly people or some sort of laptop for people with vision impairment, etc. So those are good questions to see their customer empathy, their creativity, their ability to evaluate multiple ideas, their ability to find flaws in their own ideas. So there's a lot of room to dig in there and kind of see how this person is thinking as a product person.

Lenny (01:08:57):
What is a favorite product you recently discovered that you love?

Itamar Gilad (01:09:00):
It's a cliche, but it's AI. There's a company called ElevenLabs, that do voices and the best voices, synthetic voices you heard, but they can also replicate your own voice so you can create a voice signature. If you're American you can use their kind of default free version or cheap version to replicate your own voice and that could be pretty useful if you need to narrate an audiobook or do some online course. So I'm finding this service very interesting.

Lenny (01:09:36):
This is all part of my big retirement plan, find all of these components together that can replace me eventually. You got AI generating content, we'll have this voice thing. I love it, it's all happening.

Itamar Gilad (01:09:45):
There's an AI version of you, right? I can ask you questions now with-

Lenny (01:09:48):
Oh, there is lennybot.com.

Itamar Gilad (01:09:50):
Right.

Lenny (01:09:51):
It's all part of the plan. Okay. What is a favorite life motto that you repeat most to yourself that you share with others?

Itamar Gilad (01:09:59):
That's a big one. Albert Einstein I think said, "Strive not to be a success, but to be of value." And I think that's a great motto for people and for companies. It's something that kind of guides me and this whole concept of the value exchange, etc, is kind of loosely connected to that.

Lenny (01:10:19):
I love that, that's such a important point for people putting out content online. So many people are just like, I just want to be successful, get followers, here's all these things I'm tweeting and showing and the thing that actually works is deliver value, create valuable stuff that people really value and want. I find the signal for that is, do you find it interesting and valuable? If you're like, "Oh wow, that's really interesting." Oftentimes other people are going to find it interesting. So I love that, great choice, I'm going to look at that one up. Two more questions. What's the most valuable lesson you learned from your mom or your dad?

Itamar Gilad (01:10:53):
I think both of them in their own way, they had relatively modest jobs, teaching or doing other things, but they always strived again to be the best they can and to deliver the most value they can. So it's very connected somehow, maybe I'm seeing the world through this lens. But they kind of taught me to strive to be the best I can at what I do.

Lenny (01:11:19):
The final question, you're Israeli for folks that can't tell. What is your favorite Israeli food that people should definitely check out or I try to get whenever they can?

Itamar Gilad (01:11:29):
When I arrive in Israel I usually go for shawarma, which is like dner kebab if you know it, it's just better. So if you're in Israel, if you go visit Haifa, which is the city where I grew up definitely check out the shawarma.

Lenny (01:11:44):
Awesome. Itamar, I hope people got the gist of your book from our conversation. What's the best way to find it? What's the best way to learn about you and reach out if they want to ask any questions? And then also, how can listeners be useful to you?

Itamar Gilad (01:11:56):
To find it you can go to itamargilad.com or to evidenceguided.com, and you'll find a book and you'll find me. Best value to me, try it out, just take some of these ideas, bring them back to your office, talk with your colleagues, say what do you think we should do about this? Just give it a go and reach back to me, tell me I'm easy to find in my website. Tell me what happened I'm really interested.

Lenny (01:12:22):
Amazing. Itamar, thank you again so much for being here.

Itamar Gilad (01:12:25):
Thank you.

Lenny (01:12:26):
Bye everyone. Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Notion's lost years, near collapse during COVID, staying small to move fast, building horizontal
**Guest:** Ivan Zhao  
**Published:** 2025-03-06  
**YouTube:** https://www.youtube.com/watch?v=IIPKMixTMfE  
**Tags:** growth, roadmap, experimentation, funnel, monetization, revenue, hiring, culture, leadership, management  

# Notion's lost years, near collapse during COVID, staying small to move fast, building horizontal

## Transcript

Lenny Rachitsky (00:00:00):
The way you described the early years of Notion, you described the first three to four years as the lost years.

Ivan Zhao (00:00:05):
We try many different versions. The first version, okay, everybody can make and create their software, so let's just build a developer tool that's so easy that more people can do that. We tried that a couple of years and learned that actually most people just don't care. Our realization is actually let's hide our vision, which is everybody can create their software in the form factor that people do care. So what kind of tool do people use every day? Productivity software. It took us two years to realize we need to build a productivity tool. We called it sugar-coated broccoli. People don't want to eat the broccoli but people like sugar, so it gave them the sugar then hide your broccoli inside of it.

Lenny Rachitsky (00:00:40):
What other elements do you think are key to you finding something that actually ended up working?

Ivan Zhao (00:00:44):
What is the building a product or business. You want user. You want revenue. That's the product business. And building for something you want the world to have is building for your value. You have some taste. You have some aesthetic. There are different energy. You need to create a balance. Too much of yourself. Then there's no users. Then you're just doing our project. And too much for business, you're building a commodity.

Lenny Rachitsky (00:01:03):
The way you think about Notion, it's almost like a philosophy of how to work and be versus just a productivity tool. And so I'm just curious how you think about the relationship between tools and human potential.

Ivan Zhao (00:01:15):
Tools are extensions of us. And once they extend us, once we shape them, once we bring them to world, they can come back to shape us.

Lenny Rachitsky (00:01:28):
Today, my guest is Ivan Zhao. Ivan is the co-founder and CEO of Notion. Ivan is a really unique and also a deeply philosophical founder who doesn't do a lot of podcasts, so I'm really excited to share a glimpse into how he built one of the most beloved and most popular products in the world.

(00:01:45):
We talk about the first three to four years of Notion that he describes as the lost years, how he was able to get into a great school in China by winning a programming contest, the joy and suffering of building a successful horizontal product, plus his approach to staying lean and craft and making trade-offs and also leadership. Also, a wild story about how Notion almost died during COVID because the one database that everything lived in almost ran out of space.

(00:02:10):
If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. Also, if you become a paid annual subscriber of my newsletter, you now get a year free of Notion Pro and Perplexity Pro and Superhuman and Linear and Granola. Check it out at lennysnewsletter.com. With that, I bring you Ivan Zhao.

(00:02:32):
This episode is brought to you by Eppo. Eppo is a next generation A-B testing and feature management platform built by alums of Airbnb and Snowflake for modern growth teams, companies like Twitch, Miro, ClickUp, and DraftKings rely on Eppo to power their experiments. Experimentation is increasingly essential for driving growth and for understanding the performance of new features, and Eppo helps you increase experimentation velocity while unlocking rigorous deep analysis in a way that no other commercial tool does.

(00:03:02):
When I was at Airbnb, one of the things that I loved most was our experimentation platform where I could set up experiments easily, troubleshoot issues, and analyze performance all on my own. Eppo does all that and more With advanced statistical methods that can help you shave weeks off experiment time, and accessible UI for diving deeper into performance, and out-of-the-box reporting that helps you avoid annoying prolonged analytic cycles. Eppo also makes it easy for you to share experiment insights with your team, sparking new ideas for the A-B testing flywheel. Eppo powers experimentation across every use case, including product, growth, machine learning, monetization and email marketing. Check out Eppo at geteppo.com/lenny and 10X your experiment velocity. That's geteppo.com/lenny.

(00:03:50):
This episode is brought to you by Airtable ProductCentral, the unified system that brings your entire product org together in one place. No more scattered tools. No more misaligned teams. If you're like most product leaders, you're tired of constant context switching between tools. That's why Airtable built ProductCentral after decades of working with world-class product companies. Think of it as mission control for your entire product organization. Unlike rigid point solutions, ProductCentral powers everything, from resourcing to voice of customer, to roadmapping, to launch execution. And because it's built on Airtable's no-code platform, you can customize every workflow to match exactly how your team works. No limitations, no compromises. Ready to see it in action? Head to airtable.com/lenny to book a demo. That's airtable.com/lenny.

(00:04:44):
Ivan, thank you so much for being here, and welcome to the podcast.

Ivan Zhao (00:04:47):
Thank you for having me.

Lenny Rachitsky (00:04:48):
I know you don't do a lot of podcasts, and so I'm very honored that you're here. I want to start with the story of Ivan. Your background is quite unique for a founder of a $10 billion plus tech company, and I don't think a lot of people know it. For example, you grew up in a small town in China. And the way you got out of there, the way you got into tech is pretty interesting. Can you just walk us through that early years of Ivan and how you got out there?

Ivan Zhao (00:05:16):
Yeah. I think a small town in China, the definition, it's actually 4 million people. It is called Urumqi. It's in the northwest desert part of China. So I grew up there and then I moved into... My mom took me to Beijing, the capital of China. And that's actually how I got into programming, coding, because I'm from somewhere else and in order to go into good school in the capital, you need to win some kind of competition. And there's different paths. You can get at math or you can get at programming like Information Olympiad. I was really into computer games at the time so of course I picked the programming one so I can play computers all day long. And I win some competition and got me to a good school. So that's how I got into programming.

(00:06:05):
Later then, I moved to Canada. When I moved to Canada, got into college, did not study computer science since I already knew how to code, but a lot of video games. Did a lot of art actually, art and science. By the time I graduated college, I realized most of my friends are artists. They need to make their websites, get web portfolio made. And I'm the only nerd in my art friend circle so I made three or four websites and realized, "Oh, actually people don't know how to create with the software media, computing media." So that got me into want to create a product like Notion today which it allow more people to create tools, create software for their daily work and life.

Lenny Rachitsky (00:06:49):
Okay. So going back to get into a great school and to leave the small town, not so small, you had to enter a programming contest. And you placed first or second or how well did you actually do in this one?

Ivan Zhao (00:07:05):
Second in Beijing.

Lenny Rachitsky (00:07:07):
In Beijing, okay.

Ivan Zhao (00:07:08):
Pretty big. Beijing is a big city.

Lenny Rachitsky (00:07:11):
Okay. Incredible. Another stat or a story I heard is that you learned English by watching SpongeBob SquarePants. Is that real?

Ivan Zhao (00:07:18):
Yeah, it's real. I moved to Canada pretty late, 16 years old, and what I learned is in China you can learn English but it's typically just grammar and doing exams. What you're missing is the context, the culture. So you have to watch SpongeBob or Simpsons to get a sense of humor essentially. You can understand jokes. Watching cartoons, it's probably the easiest way to do that.

Lenny Rachitsky (00:07:45):
That's amazing. And there's another seminal moment in your path. I don't know if it was this point or later, but the Douglas Engelbart paper ended up being a very meaningful moment for you.

Ivan Zhao (00:07:57):
So while I was in Canada in last year of school working on trying to building website from our friends and building a creative tool for them, and then you just look into the history of a creative tool for software, for computing. Eventually arrived at 1960 and '70s. So you realize the first generation of computing pioneers, which is around San Francisco, Stanford areas, South Bay, they actually had the best ideas. For them, people like Douglas Engelbart, Alan Kay, Ted Nelson, those first generation pioneers, for them computing, there shouldn't be a separation between builders and users. It's the same medium. Engelbart's original paper called Augmenting Human Intellect, when I read that paper, it's like holy shit. If you are making software, if you know how to code or design, this is the highest leverage thing you can do for other people. So giving them the ability to use computing to augment their problem-solving ability or their intellect, that just got me obsessed with this problem and I want to start a company like Notion.

Lenny Rachitsky (00:09:05):
It makes me think of Steve Jobs's famous line of how the computer is a bicycle for the mind.

Ivan Zhao (00:09:10):
You know what? Steve Jobs is actually at fault of this in some strange ways. So the story is... Actually, the fact. It's not a story. Xerox PARC has working on the first-generation personal computers called Xerox Alto. Alan Kay was one of the main persons behind it. Alto runs down the system called Smalltalk, which is there's no separation between users and users' app. There's no thing called application. Everything is malleable. You can change the tools. So when Steve Jobs, the famous story is when he went to Xerox PARC to in demo with Alto, he does not... It's the first time he see graphic user interface, one of the first time, and it's also they present them with this Alto system that everything could change. But he did not see the power of it. Even when people would demonstrate like, "Hey," Steve Jobs say, "I don't like this direction of scroll bar direction. When you scroll up and down, it shouldn't scroll the opposite reverse direction." Then people just instantly change the scroll bar direction for him.

(00:10:16):
That's the power of the original Smalltalk Alto system. He only saw the graphic user interface. He did not see the underlying object or the environment power. As the generation of Steve Jobs and Bill Gates made PC, personal computing, popular and they stuck with this an application framework rather than the Smalltalk object framework. Then that has all the apps we have today and has the SaaS route we have today.

Lenny Rachitsky (00:10:43):
That vision of how products should be sounds very familiar and we'll talk about that later of how you think about Notion, but let's assume to the beginning of Notion, when we were chatting earlier, the way you described the early years of Notion, you started Notion in 2013 and some over 10 years ago at this point, you described the first three to four years is the lost years of Notion. And I think this is actually a really big deal for founders to hear about because there's all these companies these days, you hear these stats, they had 100 million ARR in two years, in under two years now. And you don't hear a lot of stories of companies of your scale and success that took three to four years to find product market fit essentially. What went on during these lost years as you described them and just how did you stick with it? That's a long time to stick with something that isn't working.

Ivan Zhao (00:11:32):
Because the goal is always building a computing tool. It's like what product is this? It's really hard to shape the product. The vision is, the dream is there, but the product is very... There's so many paths. We'll try many different versions. The first version to take, okay, everybody can make and create their software. So let's just build a developer tool that's so easy that more people can do that. We tried that a couple of years and learned that actually most people just don't care. The majority of people, they wake up, they have report due, they need to get their job done, they don't care creating software to optimize whatever they're doing. They don't care. So we give to our friends, give to investors. It did not resonate with people.

(00:12:22):
But we really want to build that tool so we just keep going and our realization is actually, let's hide our vision, which is everybody can create their software, in the form factor that people do care. So what kind of tool do people use every day? Productivity software. So that's why it came to Notion today. If you use Notion, Notion are more understood as the productivity suite, but our intent, and if you use Notion, more you discover intent, which is that it has a no-code developer power into it and you can create almost any kind of productivity software using Notion itself. That took us two plus year to realize. So actually the world is not like you. The world are not developer, designer mind. That the world is they only care what's in front of them and they're so noisy.

Lenny Rachitsky (00:13:16):
There's a quote that this makes me think about where you said, "The first version of Notion was more about what I wanted than what people wanted."

Ivan Zhao (00:13:23):
It's very much so because sense of maturation is you don't see the world just from your perspective but from outside your perspective. At tech, we were young. Took us multiple years. It hit your head straight into the wall to realize that. People just don't care.

Lenny Rachitsky (00:13:40):
I love the way you phrased that, that you have to hide your vision behind something that people understand and know how to use and...

Ivan Zhao (00:13:47):
We call it sugar-coated broccoli. People don't want to eat the broccoli but people like sugar, so give them the sugar then hide the broccoli inside of it.

Lenny Rachitsky (00:13:55):
Wow. The other thing I've heard is that you threw away your code every time, so you rebuilt it many times. You threw away the code each time.

Ivan Zhao (00:14:03):
That's true. Actually, it took us four year to get somewhere. First two year is that you build too much like developer product. Nobody cares. It took us two year to realize we need to build a productivity tool. Then it took another year to realize to build this out, but in the middle of that I realized we built on the wrong technical foundation. So eight, 10 years ago, there's computing before. Right now, all the web app runs on React. Before React wins, there's a competing technology called Web Component from Google. And it makes sense. Web Component feels like a Lego-like, the building block-like, and we're betting on that technology. And then we realize because it's so new, it's just so unstable. It don't know where the bug come from. It's from your source code or from the underlying libraries? Then we have to restart the company, rebuild the whole thing. Otherwise, we're going to run out of time. So we set a code base. We set a company so we can build on our own more orthodox technology foundation.

Lenny Rachitsky (00:15:10):
How did you actually stay solvent all this time? A lot of people want to keep working at an idea. Oftentimes they need to pay the bills. How practically were you able to keep working for three to four years? I know there's a story of your mom loaning you some money during that time.

Ivan Zhao (00:15:25):
Well, Chinese mom always can help, and I'm a single child. Yeah, actually my mom helped me kickstart the company because I'm Canadian. In order to move to US, you need to register a company. So my mom helped me with the initial and raised the money. I returned the money to her. Then we run out of the money so, "Hey mom, can I borrow that just to bridge us?" Which she did. I'm really grateful for that. How we bridged? How do you last here so long? Because the thing you want to create does not exist, which what is called Notions. It's a Lego for software. It doesn't quite exist. There's a Lego for Lego. You can see that in furniture exist, but Lego for software at the usable mass market adoption level doesn't quite exist. And you just want that thing to exist. And I grew up with Legos. It's the only toy I ever wanted, and I want the same feeling of creativity and playfulness to the toy that people can use every day. And my co-founder, Simon, feels the same way. Lego is the only thing he wanted for every Christmas.

Lenny Rachitsky (00:16:36):
Have you guys seen Magna-Tiles though? I have a one-and-a-half-year-old and Magna-Tiles are quite delightful. I think it's like a pre-Lego. The children can play them.

Ivan Zhao (00:16:45):
Magna-Tile?

Lenny Rachitsky (00:16:46):
Yeah. It's like they're little magnetic plastic planes and then you can build much bigger things really quickly. It's more for babies, but I'm having a blast.

Ivan Zhao (00:17:01):
Oh, I see it. It's like... Uh-huh.

Lenny Rachitsky (00:17:02):
It's a different version of Legos. I like that you're in real-time looking it up. You're like, "Okay, our new vision Magna-Tiles for software."

Ivan Zhao (00:17:08):
Now, most people know, "Oh, Magna-Tile." Idea is the same. Modular, right?

Lenny Rachitsky (00:17:13):
Yeah, creativity. Okay, back to your story. So there's also a moment where you moved to Japan. Just what was that about? Is that just escape and disconnect?

Ivan Zhao (00:17:20):
Yeah, that was during one of the rebuild phases. During the... We know what the product should look like. It should be a productivity software with a Lego power hiding inside of it. We build on the wrong technical foundation. And if we continue to build on the wrong ones, we're going to run out of money. Company won't exist. So we decided to lay off everybody. At that time, the Notion was five people. The layout I brought back to me and Simon, two people. And morale obviously there was really low. You have to say goodbye to your teammates. And so we have the idea, "Let's just go somewhere that we've never been to change the scenery a little bit." And Japan is always top on our list.

(00:18:00):
So the funny thing is if we... And we subleased our apartment and office. We're actually making money living in Japan and then San Francisco. So we did that for a while. We actually travel around the world for a while just to change it up, me and Sam just coding every day and design every day. That's some of the happiest moments. Birthday every day.

Lenny Rachitsky (00:18:27):
I saw a stat you're coding 18 hours a day. Here's the quote I heard, :We just code, code, code. Then hey, let's go for food. Then we go eat, go back to work, and do it again."

Ivan Zhao (00:18:35):
Because me and him working so well now. Even back then, it's like you know what each other other people are thinking and you can just cross through the problem space really quickly. The technical product space, design space, and just non-stop of shaping stuff.

Lenny Rachitsky (00:18:55):
So maybe just to close out this thread, for people, for founders that are either struggling and just can't find a thing that's working, "I've been working on something for a long time," I'm curious what advice you'd share for sticking with it. And I'll share things I've heard you say so far and I'm curious if there's something you'd add. One is you just believe this needs to exist in the world and you need to really feel this, "I need this to be a thing." I think there's an element of staying lean, like you've let everyone go and it's just you and Simon again. There's also this element of disconnecting almost and just going to a different location and just like, "Let's just reset." What other elements do you think are key to you finding something that actually ended up working?

Ivan Zhao (00:19:36):
I'm lucky and Simon lucky that high is never too high, low is never too low for us, so somehow it wasn't feeling too down. Whenever I feel down, I just go to sleep and next day I'm just reset. So that's lucky for me. Definitely don't be afraid to reset. I think courage is quite important because oftentimes you're working on things don't matter, but momentum just took you there. Your first point of building something you want the world to have. What is the building a product or business? You want user. You want revenue. That's a product business. It's almost like a sports. The market is the arena. Then you'd want to optimize the scorecard where it's building for winning. And I grew up playing sports. I like to compete so I like that.

(00:20:34):
And building for something you want the world to have is building for your value. You have some taste. You have some aesthetic. You have some values. You want the world to have more of that. They are different energy. I realize actually fairly recently, they're really different. Depends on which day I wake up, I might be in different mood for things, but building for value it's more lasting and more fulfilling. Looking in the thing we're building today and looking back, I find most proud of thing I create something authentic to myself and happen to be also useful for others, and that just keeps you going. And that feels like a more durable energy source for all those dark years, loss years during Notion, and still every day for me.

Lenny Rachitsky (00:21:24):
It's interesting you say that because also there's this aspect of it wasn't working initially because you're building it for yourself and not for people, but what I'm hearing is it's still important to build a thing that you are still excited about but also have you go back and forth. Here's what the business needs and here's the thing I'm excited about.

Ivan Zhao (00:21:42):
Yeah, really a cue. Almost like a therapist, right? It's true. You're building too much for your own self and value without realizing at the end of the day, if you're building a product and tool has to be used by others, you need to create a balance. Too much of yourself, then there's no users. Then you're just doing our project. You're just doing a research project. And too much for a business, you're building a commodity. So where's the spectrum? Yeah, it's never ending spectrum. It's interesting.

Lenny Rachitsky (00:22:17):
Yeah, okay. So I'll summarize some of those things you shared of just how to stick with it and stay with an idea and not give up. So I love that you said just get sleep, very Brian Johnson of you, just like, "Get some sleep when it's a real down day. There'll be another day tomorrow." Really simple but...

Ivan Zhao (00:22:32):
It's like a daily personal physical reset. You can reset your code base. You can reset your mental model.

Lenny Rachitsky (00:22:39):
Okay. And then there's also, I love these points. Don't be afraid to reset, as you just said. Tobi Lutke was on the podcast. He said the same thing. "Just be comfortable with some cost. I have done all this already and I will throw it away and start again and that's okay."

Ivan Zhao (00:22:53):
Yeah. I think it's not just a self-help way to say don't be afraid to reset. That's like, that's okay, that's fine. I think the more interesting point here, it's like you can create progress through better abstractions. And that thing compounds faster, can catch up to all the things you build much quicker than you ever thought. Or humans are not thinking, not good at thinking in terms of abstraction or exponentials. We're thinking in terms of linearly. If you just reset it and you find a better way to do it, you can get all the thing you have to some cost recovered really quickly.

(00:23:29):
So actually going back to the computing pioneers part, small talk, one of the first system and a huge influence for Notion was really tiny code base and inspired by Lisp, which is another programming languages and probably a hundred lines of code or something. The kernel of things could be really small, but just like math. It can compound. It can have complex behavior that unlocks so much value and things for you. But if you just find those right, you can catch up to all the things you did. You are free to lose really quickly. So I think that's the kernel of why reset is so powerful.

Lenny Rachitsky (00:24:10):
And we're seeing exactly what you're describing in LLM advancements these days. All these companies have been working on this for so long and then they've cracked an abstraction of how to think about scaling these systems. And now just people launch them and are immediately where the companies that have been working this for decades are today because they are building off these abstractions as you described in these.

Ivan Zhao (00:24:34):
Trying to caught up the US really quickly.

Lenny Rachitsky (00:24:36):
With DeepSeek, yeah. The point you also made about momentum, be weary of momentum taking you in direction and moving in a different... not being stuck to that direction is exactly the way I think the chain of thought models network actually where generally LLMs are like, next word, next word, next word, next word. And if they ever make a wrong turn, they're stuck. They keep going from that path. And these chain of thought models are now good at just like, wait, let me rethink. Is this actually the right path or should I start again? So I feel like AI has almost figured out exactly what you're describing.

Ivan Zhao (00:25:06):
Interesting.

Lenny Rachitsky (00:25:07):
Oh, man. Okay, last question about the early years. Everyone's always wondering what does product market fit feel like? You worked on it for three to four years. What was the moment? What would it look like? What was different when you're like, "Okay, this is going to work"?

Ivan Zhao (00:25:20):
I think going back to me and Simon, high is never that high, low is never that low, it never hit us as a binary state. Just like, "Oh, good. We have people who care about this thing we make now. Oh, good. People reach out to us who are paying us." And it's a very gradual ramp. Maybe that's why early days when it's really the lost eras, it doesn't feel too low because it just... Even for Notion today, it feels like it's so small in terms of where it could be. It just they keep going, right? It's a less of a milestone way to thinking about things. It's more just like, "Can we do the same that's in our head and better than we did last week?" way of thinking about things. So there's a such movement that product market, boom, milestone achieved. Didn't feel that way.

Lenny Rachitsky (00:26:13):
I've heard that from a lot of founders actually. Was there a moment in that point of just like, "Oh, this is different," or, "Maybe it's going to work this time"?

Ivan Zhao (00:26:23):
I think for a while, okay, once we start revenue, product grows faster now. Investors start knocking on the door was like, I remember one day it's like there's a dog food, dog treats sent to our entire office. So first of all, office wasn't public, the address. And the dog treats, why do people want this so much? So that was a moment I paused a little bit and I guess there's enough attraction for investors.

Lenny Rachitsky (00:26:55):
And the dog treats were trying to... It was like a gift to be like, "Hey, you should talk to us. We're sending this fun gift."

Ivan Zhao (00:26:59):
Yeah, because of the way how we just hire someone in the office as a dog. Then I think we post on Twitter or something. And I said, "Why did this show up to our office?" Someone really hustled into where we are in our office address and follow us on Twitter.

Lenny Rachitsky (00:27:17):
Did you end up taking their money?

Ivan Zhao (00:27:19):
Not the first time, yeah.

Lenny Rachitsky (00:27:20):
Okay, later. Okay, it's long game.

Ivan Zhao (00:27:24):
No.

Lenny Rachitsky (00:27:25):
Awesome. So I've never heard that before. Sign product market fit as VCs are starting to... You start getting a lot more messaging and cold outreach from VCs.

Ivan Zhao (00:27:33):
Actually, I had one of our investor, it's really helpful because all those years you just like there's no feedback loop. You just go for it. Then the feedback loop gradually show up. Then for a while it's, oh, VCs start knocking on doors. So I should talk to those people. The people like what we're doing. I did some meetings, quite a few of meetings. Maybe it doesn't... I realize and one of the members is saying, "Ivan, what are you doing? You clearly don't need money. You're just trying to feel good to do external validation about this." And I said, "Oh, that's so true." It doesn't help us make a better product and the truth is with what customer tell us. Then we just went back to building. I went back to hardcore building, no meeting modes. That's where the dog food story came about and realized, "Oh." It's interesting.

Lenny Rachitsky (00:28:30):
You mentioned this investor, they said it was really helpful. Is you want to give them some credit or do you want to keep-

Ivan Zhao (00:28:35):
Oh, Shana Fisher. She's in New York.

Lenny Rachitsky (00:28:38):
Okay, cool.

Ivan Zhao (00:28:39):
Yeah, she's like another therapist, right?

Lenny Rachitsky (00:28:43):
This episode is brought to you by Sinch, the customer communications cloud. Here's the thing about digital customer communications. Whether you're sending marketing campaigns, verification codes or account alerts, you need them to reach users reliably. That's where Sinch comes in. Over 150,000 businesses, including eight of the top 10 largest tech companies globally, use Sinch's API to build messaging, email, and calling into their products.

(00:29:09):
And there's something big happening in messaging that product teams need to know about, Rich Communication Services or RCS. Think of RCS as SMS 2.0. Instead of getting texts from a random number, your users will see your verified company name and logo without needing to download anything new. It's a more secure and branded experience, plus you get features like interactive carousels and suggested replies. And here's why this matters. US carriers are starting to adopt RCS. Sinch is already helping major brands send RCS around the world, and they're helping Lenny's podcast listeners get registered first before the rush hits the US market. Learn more and get started at sinch.com/lenny. That's S-I-N-C-H.com/lenny.

(00:29:57):
I want to shift to talking about Notion today and the way you've approached it and a good segue is what you've been talking about right now is how lean and efficient you've been and how that's been a big priority for you. So a few stats I've seen. One is that you guys are profitable. You've been profitable for a couple of years now. I don't know if you've spent even the money you've raised. I think most of it is still in the...

Ivan Zhao (00:30:20):
Yeah.

Lenny Rachitsky (00:30:20):
It's still in the bank. You're nodding, if you're on YouTube. You didn't have a salesperson until you hit over 10 million ARR. You hired your first PM at 50 people. You've always kept the team generally really small. Why is that been important to you? It's very cool now. Everyone's like, "Of course, that's how it should be." But for the past decade, that has not been the case. You've always been that way. Why has that been so important?

Ivan Zhao (00:30:44):
I think going back to the abstraction system way of problem solving, I think we're lucky that me and Simon and Akshay, we have the skillset you probably can run a whole company, which is a couple of us, I can design, I can do marketing, storytelling, close sales deals. So you realize you don't need a lot. But when you can do a lot at the same time or hire people who can do that, naturally keep the company small. And you all know you're doing product management. The overhead is actually more from internal communication. It's really hard to get people's mind to be aligned on things, to see the world in the same way. And the part that you do need people, maybe you can solve better through systems, through better tools.

(00:31:39):
Notion itself is a meta tool to build other tools. So we pretty much run everything on Notion. We use the same mindset to build our company. And accidentally, that keep our headcount low, keep our company profitable, which then puts you on a positive treadmill of you don't have to go for the next 18, 24 months to find money. You can just focus on building.

(00:32:03):
And also because your team's small, we have this internal Notion called talent density. We don't try to track number of people but we try to track how talent-dense, revenue per employee we are. And people want to work with either more talented people. So it's a positive company group.

Lenny Rachitsky (00:32:27):
I wonder how much of this is actually from being around for so many years without success of, "We just have to stay very lean and save our cash because otherwise, we'll die." Do you think that was a formative experience to inform how you want to operate or is that always something?

Ivan Zhao (00:32:42):
No, I wouldn't say we're, Notion, is a cost saving-first company. I like fancy chairs. I like furniture. But we're not wasting money. I think it's more just from a taste or approach to problem solving. I just believe better system is much better than brute force through people.

Lenny Rachitsky (00:33:05):
When people hear this idea of staying lean and staying small, it sounds great or we're going to be super efficient and lean and smart with our money and down dense. It's very hard to do and it's very hard not to hire more engineers, more designers. What advice do you have for folks that want to operate this way? What has allowed you to actually be successful while staying lean and not having as many engineers as competitors, many designers as competitors?

Ivan Zhao (00:33:29):
I think just understand abstraction or system is a better curve than pecan curve, right? Linear. We internally help other people and understand this. Internally we use the metaphor that Notion's a small bus. The bus, the smaller the bus, it's easier to turn corners, easier to accelerate, easier to maneuver. The bigger the bus it is, bigger the boat or bigger the bus, slow down. And as a leader in the company, you decide who sit around you on the bus seats. That dictates how fast our overall bus moves, dictate your work and life experience at this company because you pick your roommate, you pick your seat mates. That metaphor clicks with people inside a company and overall help us optimize to make the bus link.

Lenny Rachitsky (00:34:18):
I've never heard of that metaphor before.

Ivan Zhao (00:34:22):
It probably came up somewhere but... Or it does not.

Lenny Rachitsky (00:34:25):
Small bus. So along these lines actually, so I visited the office recently and I noticed that it's just a very cozy vibe. And I learned that you had a rule of no shoes in the office for a long time until the last office, that you all ate around one table for a long time, that you try 30 different shades of warm white on the walls before you chose. Why is that important to you? Why is it so important to be so thoughtful about the office experience?

Ivan Zhao (00:34:53):
Maybe there are two dimension part of it. One is the pragmatic part. You just want office to be a pleasant experience to be at. Therefore, most office, the top light feels like hospital. You're just like, "Oh, man." And the white is so pale and the floor is so dark. Why use some kind of cream, make floors more friendly colors? And don't use top light. Top light is evil. So just the office feels cozy so people spend more time. You feel more creative, more at ease in the office space.So the vision work we have is should feels like artist studio or should feel like your home. And that's why most our office furniture are home furnitures. It just feels cozy. That's more so people spend more time, feels more creative, juices flow better.

(00:35:42):
The other world just like at least personally for me, it hurts the eyes if you just see ugly things. It's more from a value aesthetic front. It's like we talk about ergonomic chairs. Does it hurt your back when you sit on bad chairs? But you have more visual improve from, at least for me from the eyes. If the chair looks ugly, the wall looks ugly, it hurts. So it's better to not have thing that hurts.

Lenny Rachitsky (00:36:05):
You also have a really interesting naming convention for your conference rooms.

Ivan Zhao (00:36:08):
Yeah, that's true. Yeah. We name our conference room after timeless tools in history. So there, I'll give you an example. iPhone's obvious one, original Macintosh, various different form of chairs, Lamy's 2000 pens, Toshiba rice cookers, and other ones because they're inspirations. They're just like at the end of the day, we're creating a tool. We're creating a meta tool. A lot of people to create tools, software tools. And Toshiba rice cooker changed how people eat rice in Asia for a hundred million, tens of a hundred million people. The Sony transistor radio is the first one to shrink something small and useful for people. And those things change people's life and last for decades. What it's like to create a software product like that? I want to inspire my team to think that way. Because software, and especially tech, it's every six months, every 12 months cycle. We don't think enough about creating something that lasts. I care creating something that at least the form factor lasts longer than 18 month.

Lenny Rachitsky (00:37:21):
There's a quote that you tweeted once that I think of as you talk about this from Steve Jobs. "The problem is that there's just a tremendous amount of craftsmanship between a great idea and a great product." I don't know if you remember tweeting that, but just what do you think of when you hear that?

Ivan Zhao (00:37:36):
Yeah, I think the key word here is craft. Internally, our company philosophy called crafts and values. Craft is your skill set, your taste. Value is your personal value and how do you see the world. Craft is interesting word. It's like about apply your value to some technical know-how and to make more clever trade-offs to create something new and useful and just keep doing that.

(00:38:09):
My wife often refer me as a wood cabinet builder. That's how at least my mindset training towards building Notion is like, "Oh, can I make this wood cabinet more beautiful and more useful and feels nicer on your hand?" And that's like you have aesthetic direction towards it and you have your technical know-how to actually make things happen. Then you need to do permutation and trade-off in your head where on paper and to get there. That to me, that's craft. And building product, to me at least, to me feels that way. Building business feels that way. Building company feels that way.

Lenny Rachitsky (00:38:44):
It's interesting that so much of this conversation is this and the way you think about building this company is this balance between practical, useful things people need and business and practical stuff, and then the value of building something you're proud of and craft. And there's always this trade-off almost of speed and quality, and I know that's an important element for you. Just thinking about trade-offs between decisions, so talk about just trade-offs, just how you think about making a trade-off.

Ivan Zhao (00:39:13):
Yeah, I think this is quite relevant especially for product makers and business makers is there's no free lunch. You don't get something for free. You have to give up something. Then what do you give up? It's essentially you give up the right thing that market or your user wants at that given space and time. It's just the craft of building a business or building a product. And that the market is so dynamic, especially now with AI. The optimized function for the market changes so then you need to make new trade-off and new technology emerges. I always feels like AI language model feels like a new type of wood. It feels like aluminum. It's a new type of material. So you can make... Mass air travel wasn't available until aluminum become cheap enough that people can make airplanes that support this at cost. And it's like computer wasn't there until semiconductor becomes... It's like require new technology to unlock new way to making trade-offs, and then you need to balance the technology trade-off with human behavior trade-off.

(00:40:35):
As a human, ever since we got out of Africa, we're set, right? That's a constraint. It's invariable. And every generation pick up some new things but after you're 16 years old you don't want to learn new things. So those are there are the people trade-off, technology trade-off. There's some macro. There's a different dimension of things just cooking together that come together as a product more as a business than what is that? And I think a product maker, business maker's job is to find that sweet spot of all the multiple dimensions, then create something has a right to exist. At least it's more durable to exist.

Lenny Rachitsky (00:41:16):
And I'm hearing there's this thread of just like with new technologies, what is now possible. And I know you guys are doing some cool stuff with AI that I'm going to get to that is unlocking some cool new ideas. But before I get there, I want to talk about just you as a leader. At this point, you've been at this for 12 years, something like that.

Ivan Zhao (00:41:31):
Like that, yeah.

Lenny Rachitsky (00:41:32):
And if you don't mind me saying, you're a soft-spoken leader, which is you're not like the archetype of what people imagine is like the CEO of a 10 billion... And I'm sure you guys are valued much more now. I don't even know. That was probably an old valuation. I think it's great for people to see leaders like you that are not necessarily the classic archetype of CO, and I imagine there are things you've had to work on and build and lean into that aren't natural to you to step into this role of this increasingly growing, high-scale business. What are some of the areas you've had to most build and learn to do that didn't come naturally to you?

Ivan Zhao (00:42:10):
I guess you've never been in a business meeting or brainstorm session with me. You're not there.

Lenny Rachitsky (00:42:15):
Haven't seen that side of Ivan Zhao.

Ivan Zhao (00:42:18):
Yeah, I wouldn't say I'm the most soft interaction person at work. It's actually the reverse is true because I grew up in China. People way more direct. People just say what they want, say what they think. And you move to California, you move to US, you move to the West, you felt wow, everybody says everything's wonderful, everything's nice, but that's not true. I would say Notion's ethos probably more like a East Coast rather than West Coast, so somewhere in between. It's more direct.

(00:42:51):
What do you want to learn? A bunch of things. I think the early days is we talk about that the world's not like you. The world don't care about you so you have to shave off the idealistic part of you to go something that's like the world actually cares, the sugar coat of broccoli. You have to hide the broccoli within something, the sugar pills. So that's one. That's more self. That's more myself.

(00:43:20):
As company grows, you realize... I'm pretty good at storytelling. So that's a one-to-one influence. But as a company grows, you realize you need to be one-to-many storytellers. That's a skill. The one reason I try not to do podcasts and all those things, oh, it's actually it drains energy in a different ways. I prefer just building product and brainstorm sessions. Then you realize it's a necessary craft for me to pick up in order to change the shape of the company, the business I'm building. I treat it like a craft. There's some things skill that's in the video game. You need to pick up something to unlock something else and to make new demand, you trade off with yourself and the business. That's fun though. Every 12, 18 month, Notion's like a new company or at least they require different skill set coming from me. So I need to pick up new things. And it's an infinite game and infinite games are more fun.

Lenny Rachitsky (00:44:19):
I love this idea. I love that you keep coming back to this idea of there's the ideals and the values and the vision and what you're trying to do, and then you have to find the way to frame it and package it so that people actually understand and want it. And that's how you get in.

Ivan Zhao (00:44:35):
Yeah. It's like human minds are resistant to change, and how do you land in people's head? Through my best word marketing and positioning are for. So you need to find the sweet spot to get in. And you also be truthful. It's not just deceiving. So deceiving is not truthful. You can fool other people once or twice, then there's no future. It has to be actually tied back to something genuinely the value creating or the exchange with the other person. So yeah, it's a craft. Storytelling is the vast dimension of making trade-offs.

Lenny Rachitsky (00:45:15):
I love this word, trade-offs. Comes up again and again too. It's so interesting that there's these threads that have come up again and again in our chat. Along that journey of becoming this leader that you've become, what would you say has maybe the biggest surprise or most unexpected part of the journey of something you've had to learn to do or something that didn't turn out the way you expected? Just as a personal growth story.

Ivan Zhao (00:45:36):
If you use the product in the past three years, you realize Notion product, you realize, "Hey, we actually ship bunch of things not so great." Two years ago. Actually last year, 2024, is the year that I can say we ship good stuff at good velocity and good quality and align with our values. We get lost there for a year, a year and a half shipping something not according to our value, not according to my value. Notion, we call Notion is Lego for software. We ship non-Lego pieces into our product. We're still there. We're still cleaning up part of it. That's a realization. It's like going back to the value part, it's like if you create this thing called a product or business, you attract people are value aligned to it. Then if you're trying to optimize too much on this competition revenue side of things, forced to introducing something anti-your-value, then the system, it's like there's organ rejection with your employees, with your customers.

(00:46:42):
I'll give you a concrete example. For a while and still is, project management is one of the most important use cases for Notion. And you can get a better project management tool just by hard coding things like sprints, milestones, all those things into your product, or you can do it in the way the Notion are being, through Lego pieces. What are the sprint? Sprints are clusters of a task that group together. So it's a new Lego. So introducing Lego is much harder, slower. You can instead we hard-code a sprint concept into the product. And this doesn't quite fit. And took me at least a year, a year and a half to realize that's not the way we should continue building Notion. We should go back the original Lego way of building the product. So we changed quite a bit internally. Now, it feels good now. Building according to your values is the meta point, at least for me.

Lenny Rachitsky (00:47:43):
Okay, I got to follow this thread. What is it that you changed that allowed you to come back to your first principles? Was it like you step... Is it founder mode was the answer? Is it people, personnel shift? What allowed you to change the way things were going?

Ivan Zhao (00:47:58):
I would say all of that above, but especially just release the sprint product through our community and customers. Then it's like what is this? It's like underpowered compared to other competitor products to doing product management and it doesn't work well with the rest of Notion like I said. And if you talk with engineers, they'll say, "Okay, there's this part of Notion you have to touch the code base. That's just weird. That's your hardcore too much into it. From all the dimension technical front, calling a customer. And when you use the thing it just doesn't feel right." So there's another saying that if you build in a Lego way inside Notion in the code base or product, the system work for you. If you're building non-Lego way, the system work against you. So in some sense, we're creating a tool that has emergent behavior, inter-channeling that emergent behavior to unlock more values.

Lenny Rachitsky (00:48:52):
So I'm hearing as you launched it, it just didn't go well. Everyone's just like, "What is this? This isn't feeling good." And there's a moment of realization of I see. Here's what we did wrong here and we should come back to this original abstraction vision of what we're trying to build.

Ivan Zhao (00:49:04):
That took nine months, a year to realize sometime.

Lenny Rachitsky (00:49:11):
Along those lines actually, people come on this podcast and they share all these stories of things are going awesome all the time. And this was a great example of it didn't. I'm curious if there's another story of let's say a crisis that you all went through when things were looking pretty bleak for Notion along the journey of building Notion.

Ivan Zhao (00:49:31):
Yeah, one of the bleakest one, it's when we... During COVID, we just couldn't scale up our infrastructure. For the longest time, Simon's really good at don't do premature optimization, so for the longest time, we Notion runs on one instance of Postgres database. And then we find the beefiest machine. We keep scrolling, find a beefier future machine to scale our user base, but then we're running off even the largest instance there is for Postgres. So there's a doomsday clock that when we're going to truly run out of this space to store everything in Notion and Notion got a complete shutdown. So we stopped building any new features, all hands on deck, almost every engineer in the company trying to solve that problem. Eventually we did, but it was a close call.

Lenny Rachitsky (00:50:21):
How close are we talking about?

Ivan Zhao (00:50:23):
If I recall correctly, probably in weeks running out of the time. And then as you approach the limit of what Postgres can do, behavior becomes sporadic. You really don't know which day going to hit you. But we just need to go as fast as you can to become sharding problem.

Lenny Rachitsky (00:50:39):
Yeah, I was going to ask, so the solution is sharding the database?

Ivan Zhao (00:50:39):
Yeah, sharding.

Lenny Rachitsky (00:50:40):
Okay, cool.

Ivan Zhao (00:50:43):
Don't do as late. Yes. Don't do premature optimization but plan ahead a little bit. Don't go late.

Lenny Rachitsky (00:50:49):
How long did you have from when you launched this doomsday clock to time running out? Was that a few months?

Ivan Zhao (00:50:54):
Maybe a bit longer. Yeah, in the month, less than six but more than three, something like that.

Lenny Rachitsky (00:50:59):
The bittersweetness of COVID just ramping up certain businesses.

Ivan Zhao (00:51:03):
People just run like they have to use online productivity software, collaboration tools.

Lenny Rachitsky (00:51:08):
Yeah, blessing and a curse. Speaking of a blessing and curse, this is a great segue to where I wanted to go in the final area I want to spend time on which is building horizontal software and building software that bundles together a bunch of different stuff. Notoriously hard to build a horizontal platform that does a lot of things when there are often point solutions that are very, very good at that one thing. And it's interesting. If you look at the timelines of companies that have built horizontal products, they all take a long time to build and finally find product market fits. It's actually a really common pattern. And when we were talking about what would be fun to talk about, the way you described it is the joy and pain of building horizontal products. So let me just ask broadly just what have you learned about what it takes to successfully build a horizontal platform type of product?

Ivan Zhao (00:51:56):
First of all, no regret. And second, I wouldn't want to build anything else because going back to the value, Lego for software doesn't exist and Lego is a horizontal thing. So that's the thing we want to build. We always want to do that. So we did not start to optimize for business but we're optimized for that vision.

(00:52:19):
Learning-wise, I think segmentation is quite important because people can use a Lego for different things. Only hardcore Lego fans care about Lego bricks. Most people care about Lego boxes. And they actually want the Lego box to be ready-made. When you unpack the box, the set is there for you, right? That's what we're learning a lot, especially move up market. There's this term that took me a while to learn. It's called solutions. You need to be a solution for enterprise customer, you need to sit somewhere on a P&L to optimize for their business where due third risk. That's Lego box. It's not a Lego brick. Segmentation related to that. So you need to shift your mindset as you more towards B2B, more towards move out market. I wish we have done earlier. For the longest time, I've stalled too much in the Lego brick mindset, now in the solution Lego box mindset.

Lenny Rachitsky (00:53:14):
That's such a good metaphor. I feel like even if you're not building Legos for business, just this idea of what is the box that you are selling to people, how's it being positioned? How do you picture it? What are the value? Props such a good metaphor.

Ivan Zhao (00:53:29):
If you're building vertical software and naturally your vertical is the box, right? So you know you have 1 or 2% of your selling to. Pretty straightforward that your market constrains you and no judgment. People like you, you can go that way, but then you just hit the wall off the market. The advantage of building horizontal, there's no wall, at least for in our space. We, Notion, go after entire software market, but then you need to create a wall yourself. So to make your go-to-market distribution, to create the spot in people's mind, your customer's mind more clearly for them and for your go-to-market teams. That's why where solutions is one of my favorite word internally to rally the sales team or the product team. You think that way, but then you need to hold in your head, make sure you're still building bricks behind the scene. Otherwise, you pigeonhole yourself into the best spot, like what we did with project management sprints features.

Lenny Rachitsky (00:54:25):
So speaking of that, so I don't know if you know this. I ran a survey recently where I asked my readers what tools they use most, what tools they love most. And it went out to my entire subscriber base. We've got 6,500 people filling out the survey. And Notion more than any other company placed very highly in many categories. For example, I have the notes here, it was the second most popular project management tool after Jira. It was the fourth most popular docs. Which is interesting because you think Notion would... Notion is known for docs and it's interesting, that was the lowest one actually. And then it was third in CRM, just behind Salesforce and HubSpot.

Ivan Zhao (00:55:02):
Yeah, we did not intend to build CRM, but what is a CRM is relational database. That's why we give people that brick. That's a relational database and they can build CRM themselves. I think the good advantage is if a customer use Notion, they can address those three, four use cases in one place. Especially for our startup mid-market companies, their need for each of the vertical use case is not as complex so they can have all the information in one place, good for their teams, good for AI actually. That's a huge market change that's like we did not expect until recently. And save their costs, which is more and more people care about the bundling purchase nowadays. And our approach for that is, yes, we're number two in project management, number what? Number four in CRM, but we're interested in more bricks to make us number... Move up the categories in ranking. So it just takes time, but that's our approach.

Lenny Rachitsky (00:56:05):
Yeah. Well, it's working whatever you're doing there. So say someone is trying to build a horizontal tool like yours. There's a lot of founders that are trying to build something that can do a lot of things really well. Do you have any advice for that first use case? Just figuring out something that initially works like you're talking about segmentation, is there something there of like, "Do this if you want to find any success with a horizontal tool"?

Ivan Zhao (00:56:28):
First, I wouldn't recommend it.

Lenny Rachitsky (00:56:30):
But you wouldn't do it differently?

Ivan Zhao (00:56:32):
I wouldn't do it differently myself, but I wouldn't recommend it. It's a problem. The problem space too large to have best practice, but I can share something that's relevant for us. Notion, we always want to build a meta tool, a tool to build the lack of our software. We somehow stand up upon document notes as one use case. And that just gave us a large top of the funnel that there's a 1 billion plus people use this use case every day. So that fuels our growth. We call our internal strategy called B2C2B. All those consumers, personal user use Notion for the most simple way you can use a computer or your phone, which is note-taking or document-sharing. And then they realize, "Oh, Notion can do more of that." There's relational database power, you can do tasks, you can manage track other things. Then they bring Notion to work.

(00:57:24):
Half our B2B customers coming from prior personal users, and most of them are using Notion for notes and talk in the first place. So pick. Well, at least we stumble upon a use case, a horizontal use case to give us a large top of funnel that help us grow our more verticalized enterprise use cases, and that's the reason where we ship a calendar product last year because which other category of software has 1 billion plus users? There's document notes, there's calendar, there's email, right? That's why we're also working on the email product right now.

Lenny Rachitsky (00:58:01):
Yeah, man. Watch out, everyone. And then you mentioned AI and it's such a good point that AI is best when it has data. And the fact that you have all of this stuff already in there gives you a lot of really interesting opportunities to leverage AI.

Ivan Zhao (00:58:17):
We definitely did not expect language model. It's such a gift for everybody building tools, right? Complete change the material you can work with. One realization, it's you have a surface area that people spend daily work with, especially during writing and managing your tasks and project. It's really easy to slice the language model writing AI capability into it. So that's the first part we built. That realization is AI is so good at reasoning and understanding and searching things, and we can do a much better job of finding and searching things if all the information are together. That's what we realized. AI is really good with bundled offerings. AI is really good with horizontal tools. So that's the second phase, we call it. The first product was our AI writer product. Second product is AI Q&A or connectors. Please look at all the information in Notion and give your answer.

(00:59:18):
And then we also need to work with the external connector because there's things that are living in Jira, living in Zendesk that other customers still rely on. So we need to build AI connectors. But more and more information coming back to the Notion core. I would say the third one, which is even more fascinating, it's for the longest time and it's still is one of the biggest weaknesses of building for Legos, it's hard to piece together. It's not everybody can put together a Lego set from scratch. There's always the builders and user with the Legos. But guess who is really good at piecing things together, assemble things? Especially things like since Sona 3.5. AI is so bad at writing code. Coding is just assembling things together. So now we're looking at holy shit, we spent the last five, six year building all those Lego blocks for knowledge work. If we're just putting AI coding agent on top of it, you can create any kind of knowledge, customer software, customer agent for whatever your vertical use cases you need. So that's the most fascinating approach for me, and we did not expect this at all.

Lenny Rachitsky (01:00:33):
Thank you, AI. Is there anything else along the lines of building horizontal products and bundling that you think is interesting to share or important? Otherwise, I have one last question I want to ask you.

Ivan Zhao (01:00:43):
I think market is like waves. There's... Who said this? There's two-way to build business, bundling and bundling, right? There's too much of a zig and the zag. Actually, my favorite version of this is there's a classic Chinese literature called Romance of Three Kingdoms. It's great novel. It talked about the three kingdom era of China and the opening sentence of this novel, it's, "Empires long united must divide, long divided must unite." That has always been bundling, unbundling. It's one of my favorite book to read when I was a kid, but business works same way. When there's too much, you can see this.

(01:01:29):
It's like before computers, everything works on paper. Our knowledge work are done through papers is fully democratized medium. Then PC happens during the '80s. The first era is a piece there actually are so many applications. There's early database software, dBASE, it's quite famous. It started dBASE 2 because it gives them credibility. Oh, they have been stick around for some time. So that's the first unbundling phase of software computing. Then Microsoft bundled everything back into one suite in the '90s. Then the SaaS unbundled it. Now, we're at the tail end of SaaS. There's so many verticalized SaaS average company to use almost a hundred tools. It's madness. So there's more the market shifting towards more a bundling approach. And with AI and with the macro, so there's more value to be created through bundling, at least for now. The market could shift again. So understand this trend, I think, helpful to see should you build a vertical solution or should you build horizontal solution because it does different things.

Lenny Rachitsky (01:02:40):
I love that story. Okay, so last question. Something that one of your early investors, Finn Barnes, suggested to ask you. I'm curious where this goes. There's this, and you've touched on this a number of times, just the way you think about Notion, it's almost like a philosophy of how to work and be versus just a productivity tool. And so I'm just curious how you think about the relationship between tools and human potential and humans and how we live in the world.

Ivan Zhao (01:03:08):
The tools are extensions of us. That's why our office room named as timeless tools. They extend us a little bit. And once they extend us, once we shape them, once we bring them to world, they can come back to shape us.

(01:03:29):
One of my favorite quotes like the Marshall MacLean quotes, "We shape our tools. Then after, our tools shape us." I think that's probably too philosophical for building product or business, but there is a sense thinking what are you bringing to the world that will come back to bite you or shape you? And are you extending the part, the so-called good part of human nature, or are you extending the part that might be more zero-sum, might be more negative, right?

(01:04:05):
For me, what is Legos? Lego is creativity. Lego is beauty. Software to me feels like lacking both. It's definitely lacking a lot of creativity. It's so rigid. So I believe both are human nature that worth amplifying. You can build another business that amplifies a different part of human nature. There was Sequoia famously invests in seven sins or seven human natures of human because they're so powerful if you just latch onto them, you can create a business, you can create a product. But at least I prefer to amplify creativity and beauty in the domain of software. To me, that's aligned with my values and I think can at least shape the market, shape our user of our product towards the better part of themself.

Lenny Rachitsky (01:04:58):
It must feel so good to have a product that is so aligned with the way you want to see the world and actually working and growing at this rate and scaling and becoming this, I don't know, part of the ether of the world.

Ivan Zhao (01:05:11):
It feels good. Yeah, it feels good that some of the most heartwarming thing is still it never gets old when you walk by coffee shop and see people using Notion. Oh, it feels good. And it feels good that we see people in our community can create a living selling Notion template, Notion apps, that they're not a software engineer. And going back to the original mission of when people create software, I think that's one of the most fulfilling thing, at least as a maker of tools can experience.

Lenny Rachitsky (01:05:39):
That last point, I think people don't realize, so people are making millions of dollars selling Notion templates on the internet like at Etsy and other places.

Ivan Zhao (01:05:48):
Consulting templates, yeah, and they're not programmers. I think I would say that's the heart of that because their domain expertise, they're YouTubers or creators. They have lifestyle brand. They know certain things but they're not makers of software. Then they can use Notion, package their workflows and expertise into Notion and templates and make limit with it. It's awesome, all that.

Lenny Rachitsky (01:06:13):
Yeah, millions of dollars is it's crazy. Ivan, before we get to an abridged lightning round, I'm curious if there's anything else that you wanted to touch on think might be useful for folks to hear before we get to a very exciting lightning round.

Ivan Zhao (01:06:27):
I think people in tech, I wish more people look beyond tech to steal good ideas. It's like Tech Hacker News Twitter are so focused on the now and what's in front of it, what happened six months ago, versus humanity. If you just read books in other industry, you can look sideways. If you go back to history, there's a massive amount of patterns and shapes and trade-offs you can steal from and you can make what's in front of you much more interesting. You could give you... People figure out clever patterns in whatever domain in the past. You can just take in front of you. And I wish more people do that. I think it would be a very interesting way for product makers, business maker to solve the problem in front of them by stealing outside of from the domain of tech and business. So at least it's very inspiring, very useful for me personally.

Lenny Rachitsky (01:07:26):
It makes me think of the quote, "Good artist copy. Great artists steal."

Ivan Zhao (01:07:30):
Great artists steal, yeah. Well, Steve Jobs stole that from Picasso or something who stole from former artist probably.

Lenny Rachitsky (01:07:37):
Well, this is actually an amazing segue to our very abridged lightning round. And the first question is... And by the way, welcome to the lightning round.

Ivan Zhao (01:07:43):
Oh, okay.

Lenny Rachitsky (01:07:45):
The first question is just what are a couple of books that you find yourself recommending most to other people? Could be along the lines of what you just described or could just be generally.

Ivan Zhao (01:07:53):
I think the domain that are interesting the most is the complex system domain. You can look up the term. I think more and more people talk about this, but thinking a system, complex system when all the different things merge together, it creates emergent properties. Talking about ants, talk about beads, talk about life itself. It's just so fascinating how do with few primitives, few Lego bricks, you can create a thing called life. That thing just, it's sugar for me. So I love reading in that domain. And this is really helpful for create product, at least a horizontal product because you're trying to channel the energy, smaller parts to create something that the sum is much larger than its parts.

Lenny Rachitsky (01:08:43):
Is there a specific book that comes to mind or is it just generally that's a cool area?

Ivan Zhao (01:08:48):
That's a cool area to your attention to.

Lenny Rachitsky (01:08:50):
Next question. Do you have a favorite recent movie or TV show you've really enjoyed?

Ivan Zhao (01:08:55):
I like to watch old documentaries. Maybe this is another area or category too. There's quite a few on YouTube. People make really good documentary in the '80s, in the '70s. That's like all the old BBC ones, they're just excellent and they have a strong opinion in them. It's no longer just general education thing. They have a direction. They have a taste. Go look it up. Oh, yeah. One is a really good one to get started called Connections. I think it's called but the gentleman's name is Burke. It's about how different things from different domains inspire other domains, and usually he used 30 minutes or 60 minutes to chain together a bunch of connection of stories. It's really good for technologists to watch. Highly recommend.

Lenny Rachitsky (01:09:49):
I feel a very consistent pattern throughout all of these answers and your entire conversation of just emerging properties, connections, Legos, building abstractions.

Ivan Zhao (01:10:00):
Yeah, I think I did Enneagram. My Enneagram, it's 7 and 7. 7 is, it is actually perfect with what we just talking about. 7 is creative, finding connection, see the forest and tree. 8 is they call Challenger. It's like competitive AR optimizing. So true energy accessing me.

Lenny Rachitsky (01:10:23):
Oh, wow. It's all makes sense. I got to take this Enneagram. This comes up a bunch on this podcast.

Ivan Zhao (01:10:27):
Right, yeah.

Lenny Rachitsky (01:10:29):
Final question. Do you have a life motto that you often think back to, that you often repeat in your head of just like when times are hard or just to keep going with something you're working on that you find useful?

Ivan Zhao (01:10:41):
I like to think things as a craft. You just make it better. Make for yourself. If it's unique enough for yourself and useful for others, things will follow.

Lenny Rachitsky (01:10:51):
Ivan, thank you so much for being here. Two final questions, working folks find you online if they want to follow-up on anything, and then how can listeners be useful to you?

Ivan Zhao (01:11:00):
Probably find on me on Twitter, Ivan Z-H-A-O. It's helpful give us feedback about Notion, about our product. That's the best help.

Lenny Rachitsky (01:11:12):
What's the best way to do that? Is it like DM, Ivan, or is it-

Ivan Zhao (01:11:14):
Yeah, just DM me.

Lenny Rachitsky (01:11:15):
Okay.

Ivan Zhao (01:11:15):
DM me. Yeah, that's probably the best way.

Lenny Rachitsky (01:11:19):
Okay. Oh boy, here you go. And then you guys are hiring. Anything specific you're looking for? Anything people should know if they're like, "Oh shit, I want to go work here"?

Ivan Zhao (01:11:29):
We're trying to hire misfits. So if you think you're a misfit, if you're exceptional at many things especially, you want to build Lego for software, you want to take interesting spin on AI with Lego for software, then DM me.

Lenny Rachitsky (01:11:45):
Amazing. Ivan, thank you so much for being here.

Ivan Zhao (01:11:47):
Thank you for having me.

Lenny Rachitsky (01:11:49):
Bye, everyone.

Ivan Zhao (01:11:50):
Bye.

Lenny Rachitsky (01:11:53):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Bending the universe in your favor | Claire Vo (LaunchDarkly, Color, Optimizely, ChatPRD)
**Guest:** Jackie Bavaro  
**Published:** 2024-04-07  
**YouTube:** https://www.youtube.com/watch?v=aXGo1o_baBo  
**Tags:** growth, onboarding, metrics, roadmap, experimentation, analytics, funnel, conversion, pricing, revenue  

# Bending the universe in your favor | Claire Vo (LaunchDarkly, Color, Optimizely, ChatPRD)

## Transcript

Lenny (00:05):
If you're PM, you've almost surely read and been influenced by Jackie Bavaro. And if you haven't, you're in for a treat. Jackie is behind two of the most important books in the PM cannon, Cracking the PM Interview and Cracking the PM Career. And she's also one of the smartest people I know on the essential skill of product strategy in our chat. We go deep into all the ways that you can become better at developing your own product strategy, including what is strategy, what makes a good and bad strategy and how to very tactically put together a strategy. We also chat about what she's learned going from the first PM at Asana to head of product at Asana, plus a ton of tactical advice on getting to senior PM and then to manager PMs. A big thank you to Jackie for sharing her wisdom with us.

(00:51):
This episode is brought to you by flat file. Think of the last time that you imported a spreadsheet, did it work the first time? Chances are it did not. You probably got some weird error and to try a bunch of things like removing the blank title rows above your column headers, or Googling how to save with UTF-8 in coding. What even is UTF? Who cares?

(01:09):
You're just trying to get your file where it needs to go. So you can do your actual job, your customers running to the same issues when it matters most, right after signing up for your product. Enter Flatfile. Flatfile is the data onboarding platform built to take the acute pain out of importing customer data into your product so they can see the magic that you promised them. Flatfile has sought type one and two certified GDPR compliant and even HIPAA compliant, ensuring your customers no matter where in the world are located, are sharing their data securely, any compliance, every step of the way. No more emailing files back and forth, no more help articles that just don't land. Just clean data on day one, when it matters most. Get started importing millions of rows of customer data in minutes at flatfile.com/lenny.

(01:55):
This episode is brought to you by Amplitude, the number one product analytics solution. Amplitude helps product teams, growth teams, marketing and data teams build winning products faster, and turn products into revenue. Amplitude has everything you need, including an integrated CDP, self-service analytics and even an experimentation platform to help you better understand your users, drive conversions and increase engagement, growth, and revenue. Amplitude is built for teams that want to learn as fast as they ship, and ship as fast as they learn. Ditch your vanity metrics, press your data, work smarter and grow your business.

(02:31):
With over 1700 customers like Atlassian, Instacart and HBO, Amplitude is helping companies build better products. Try Amplitude for free. Visit amplitude.com to get started.

(02:49):
Jackie, I am so excited that we are chatting again. We've done a bunch of fire set chats over the years in various events, and you've always been really generous with your time. I just want to say thank you for joining me. And I'm really excited to chat again.

Jackie Bavaro (03:01):
Yeah. I'm so excited to chat with you. I'm so excited that you're doing a podcast and I'm glad I get to be one of the early people on it.

Lenny (03:08):
Absolutely. It's my honor. Okay. You are a famous PM in the world of product management. You rode Cracking the PM Interview, Cracking the PM Career, both of which I own and love. And fun fact, my sister was just interviewing as a PM and she used your book and found it, really helpful. So thank you for that.

Jackie Bavaro (03:08):
That's awesome.

Lenny (03:26):
Yeah. And then also you've written a bunch of classic PM post on Medium that I reference often share with people. And also you were the first PM at Asana ended up being the head of product management at Asana. And that's actually where I left to start. Could you just share how you got into product very early on and then how you worked your way up to the head of product management at Asana?

Jackie Bavaro (03:47):
Yeah. I was just really lucky in finding product management. I went to Cornell, studied computer science and economics, and I'd never heard of the job. One of my friends who'd been a PM intern the summer before I was like, "Jackie, you have to apply for this internship." And I said, "I'm sophomore. I can't be a manager." And they're like, "No, you manage the product, not the people and just go apply." I applied having no idea at all what the job was. Through the interviews, I tried to figure it out. I loved the interview questions. I thought they were a lot of fun and got the job, became an intern on Microsoft SharePoint services and stayed with the team. Loved that team. Went there full time. When I moved to New York, that I started to think about changing companies.

(04:29):
Microsoft didn't have any product management in New York. So I applied to Google and I was like, "Yes, I'm a good product manager. I'm sure I'll get this job." And I got rejected. And I was shocked. I really had thought that I would pass the interview. A year later I applied again and that's when I got into the Google APM program. And of course at the time I thought this was one of the biggest mistakes in my whole career. But looking back, it certainly is what gave me the impetus to write these books and say, "You know what? Even good PMs don't know how to answer these questions. There's a lot we can do to help." And beyond that also then when I be joined Google, I very quickly got sent into being an interviewer. And immediately I noticed there was this real difference in how people would answer the questions.

(05:08):
And some people didn't seem to understand what the question was trying to get at. And some people sounded really good because they'd say, "Well, I'll tell you three things. Number one, number two, number three." And then when I paid attention to my notes, I'd be like, "Wait, their three ideas weren't actually good ideas. They just sounded like they knew what they were doing." Those really drove me to want to share more about how to do well in these interviews.

(05:28):
And at the same time, I constantly had people saying, "Jackie, my friend's applying to Google,. Can you talk to them?" And I was like, "Sure, of course. I'll like tell them what we're looking for." And I'll help them understand the interview process. And after doing this three times, I was like, wait a second, "If it's only my friends of a friend who are people who work at Stanford and are already very privileged and I'm telling them how to pass these interviews, that's not fair."

(05:51):
If I'm willing to tell it to a friend of a friend, I have to be willing to put that out on the internet and share that with everyone, because we really want to level the playing field that we don't want to make things more unfair.

(05:59):
While I was at Google, one day, I get an email from a friend, from an engineer I'd worked with at Microsoft. And he's like, "Hey, you want to grab coffee?" And I was like, "Oh, cool, sure. I'll be friendly." And at the time I did not realize that that's how all these recruiting chats start. I honestly did not realize that this was like, "I'm being recruited." I thought it was like, let's just catch up. But I said, "Yes." And then he told me about this company and he is like, "Hey, it's like, imagine if SharePoint was really fast." And I was like, "Oh." I love SharePoint, and I would love to work on a fast version of that. And that's how I ended up moving over and becoming the first product manager at Asana and achieve.

Lenny (06:32):
There's so many things I want to pull on in what you just shared there. On the book, an interesting point you made is that you wrote the book because it was something you were struggling with and then you saw a lot of other people struggling with it. And I find that that's often the case. When you look at books, people have written or posts, it's just like, "Oh, I had this question and this a way for me to get better at it by forcing myself to write about it." Is that basically what happened?

Jackie Bavaro (06:53):
Yeah. I had this belief that almost anybody can learn anything. People have different interests, not everybody wants to learn everything. But I find that if you're having trouble learning something, it's just because something's not clicking. There's just something that you're misunderstanding or that other people see that you're not seeing. And if people could just describe it in the way that matched YOUR mental model, then you could learn it.

(07:13):
That's how I feel about this interviewing. Is that the reason that some people don't do as well as they could on interviews is just because a lot of these interview questions are trick questions. When they say, "Oh, how would you design a bathroom?" I used to think that meant, "What do you want in a bathroom?" And that's not what it means at all. It means "Who is the best customer for a bathroom? What would they want?" But if you haven't been trained in this, you wouldn't know.

Lenny (07:34):
We're definitely going to talk about interviewing and career and come back to these topics. But going back to Asana, you look at this journey that you took and it sounds amazing and it went great, and someone that's starting out, they may feel like, "Man, how am I ever going to not make any mistakes along my journey and get to a place like Jackie ended up?" A question is just, is there a mistake or some wrong journey took along this journey that you can share?

Jackie Bavaro (07:58):
Yeah, I'm sure I've made lots of mistakes. One of the ones that comes to mind is that in probably my first or second year at Asana, I very much saw the PM's role is a person who wants to say no to everybody. I was like, "All these people want us to do stuff and we would do way too much and we would never get anything important done if we just said yes to them. I need to say no to people." And I got into this defensive mindset and sometimes people would come to me with ideas and I'd be like, "Are you telling me I can't do my job right?" And I would just try to say no to them as efficiently and effectively as possible.

(08:28):
And I did this one day to my boss and he had some idea for design that I thought was a bad idea. And I was just like, "No, we're not going to do that." And he's like, "Jackie, you have to stop shutting me down." And I was like, "I'm about to get fired." I was like, "Oh, I have really, really messed up here." It definitely made an impression on me and I was lucky enough to have a coach at the time. I went to her to talked to her and really started to rethink how I saw the role, this urgency that I felt of "I need to shut people down as fast as possible to the save time," as opposed to take the time to consider that other people probably have good ideas.

(09:03):
And even if their solution, isn't what I think is going to be the absolute best solution, the problem they're talking about is probably real. And I can interpret their solution as a way of sharing the problem and exploring and brainstorming around that.

(09:17):
It wasn't an immediate change, but I remember at one point she challenged me to, "For the next two weeks, say yes to everything." And I was like, "I can't do that. I wouldn't be doing my job." And she's like, "I think you can find a way to do your job and still say yes to people. You can say, 'yes, I agree. That is a real problem. Yes. I think we could test this design with users' and just see what's different with two weeks of saying yes to people instead of no." And I realized that this protectiveness and lockdownness that I had really wasn't something I needed and it wasn't something that was serving me because it meant that I couldn't have real collaboration with the other people around me.

Lenny (09:51):
Wow. I love that story. A little thread I want to pull on there, two questions. How far into your time at Asana did this happen? Because it's surprising how often things like that come up really late in a career and you're like, "Oh, shit. This is a fundamental thing that I imagined isn't maybe as true as I thought in changing course there." Maybe let me ask that question, how far into your career was that?

Jackie Bavaro (10:10):
This was probably pretty early. I'm imagining what room it was in and I'm like, "Okay. I know what that time was." It was definitely the first year, maybe six months in.

Lenny (10:17):
Okay. Okay. Cool. Okay. So you have this coach, what impact have you seen from just having a coach? Something that a lot of PMs ask me about is just like, "Should I get a coach? How do I find a coach?" I guess just roughly your experience been with a coach and then any advice for folks thinking about getting a coach.

Jackie Bavaro (10:31):
There's two different models. Some people like to have a coach all the time and that's a person that they can go to and they can explore their ideas and their feelings and how they're just bounce ideas off of all the time, have this person who isn't in any way going to be the person who evaluates them later on. They can be totally honest with them.

(10:48):
For me, I find it's better to have a coach when I have a specific thing I want to work on. I tend to be a little bit results oriented, action oriented, and I don't like to show up and be like, "So, what are we talking about today?" Or make something up. I talked to this coach to deal with this issue of how do I not shut people down and how do I still be a good PM if I'm not saying no to people all the time.

(11:10):
I worked with her for several months, but then once that was gone, then I did start to find that personally I would make things bigger when I had a coach, because I had something that I knew how to solve on my own. And I'd bring it to the coach, and then all of a sudden it felt like it was a big deal rather than a little deal. I've gone in and out of coaching, but I do it when I have a thing that I want to work on.

Lenny (11:27):
Going back to Asana, you were there for eight years about, what kept you there for that long and then how did you know that it was time to move on?

Jackie Bavaro (11:35):
I loved working at Asana. And Asana, I think today is incredibly successful, but it was not always obvious that it was going to be incredibly successful. We had some lulls in there. There was a time when we were updating our entire engineering framework from an old version to a new version. And we had like a literal 50% of our engineers working on this. Set aside half of our engineers to work on new features, and the other half was just working on updating this framework. Which meant that we felt like we were moving at half speed. It felt like we were moving really slowly. Customers hated how slow the app was and this framework changed was needed to change that. But we really were not sure that the company was going to be successful.

(12:14):
Staying with the company through those days, it really was this feeling that I was getting good growth opportunities, even if the company itself didn't succeed. One of the things I think was really important for me in my career at Asana and growing into head of product management is, at one point in my career, my manager, one of the co-founders had a meeting with the two co-founders, the planning committee. The planning committee was the two co-founders, the head of engineering and the head of business. And they would meet.

(12:39):
And after these meetings, he would come back to me, my boss, and he'd tell me "Okay, here's the direction we have. Here's what you're going to need to do." And I had to ask some questions and I'd be like, "Well, what about this? And what about this?" After a little bit of time, I would start to be like, "Hey, you have your planning committee today. Here are the three questions I want you to go in and get answered at that committee. And if they say this, I want you to ask this and this."

(13:01):
And after a little bit of that, I was like, "It might be easier if I just go, I might be able save you some time and some energy if I just joined you." And it was a way that I took myself into this higher level meeting, framing it as something that was going to help out my boss. And it did. It wasn't dishonest, but it was a pretty effective way of advocating to get into this meeting.

(13:19):
I think once I was in the planning committee, I just got a real front row seat to understand how a company is built and what kind of decisions are happening, and what goes on beyond the realm, the narrow perspective of building features. Going from features to strategy, but also understanding business strategy and how do the product choices we make impact our financial plans, and whether or not marketing has to hire people, and whether or not that means we need to open our office.

(13:49):
I really felt like I was getting a lot of personal growth and I was getting an opportunity to learn things that I wouldn't have that opportunity anywhere else. Because of my background and my deep knowledge of this product, that I was able to be exposed to this and have these responsibilities.

(14:06):
For me, I really felt like I was learning and I was growing and I didn't know it all yet. That's really kept me there for a long time. And then I'd say, getting closer to the end of that time, I'd become a manager, I had teams, I've become a manager of managers and I was definitely starting to get burned out. It's really, really tough being a manager. One of the ways that I'd always worked as a product manager is a lot of transparency and authenticity. A lot of explaining to people what our goals are and then showing like "This is the solution I think will hit in our goals, but I'm open to other solutions."

(14:38):
As a manager, there are times when my goal is backfill for someone I know is quitting in a few weeks, but I can't tell anyone about it. Or there are all these personal secrets that you have to keep for people as a manager. And there are times where, what the person on IT wants is a promotion to make more money, and haven't necessarily earned it yet. And it's not necessarily the right thing to do from a company perspective.

(15:01):
Those places where you're torn between these two goals or what I want, isn't always perfectly aligned with what's best for the people that report to me, that weighed a lot on me. That was very heavy.

(15:12):
I was like, "Okay, maybe I could use a break." But for a while I felt like, "Okay, but I don't want to just leave the company and things be in bad shape." So we worked on hiring lots of really, really stellar people, just really talented people and growing people in their roles. And got to a point where I was like, "Everybody's doing great. They don't need me. They can do fine without me." And I thought about, I just felt this surge of energy thinking, "Yeah. If I left that, I'd be excited for what's next," and then started to have this idea of writing the book on careers. That's how I knew it was time to leave.

Lenny (15:44):
It was also eight years, so it makes a lot of sense that eventually it gets tiring. And then I love the glimpse you shared into the downsides of being a leader in product. Is there anything more you can add there? Just like, people want to be the head of everything and then they get there and they're like, "Shit. This isn't what I wanted to be doing."

Jackie Bavaro (16:01):
Definitely. Tooth directions I would say. One is just that being a manager is not as much fun as being an IC. It's a lonely job. When your team goes out for drinks, they treat you differently when you're the manager than when you're one of the other ICs. It's more painful and less fun. For all these reasons, you might not want to be a manager. At the same time, I'm like, "Well, what could I have told younger Jackie, to be like, maybe you don't want to be a manager," and there's nothing. There's nothing you could have told me that would've convinced me not to be a manager. I might say that if you want to try it, consider it a two way door, consider a time that you can try for a while, and if you don't like it, a lot of people are now playing with going back to IC. And also to understand the career paths.

(16:44):
When I started as a product manager, I had no idea what salaries people made, none at all. And I knew I wanted to be able to support a family and stuff when I grew up. So I assumed that I needed to make it to junior VP level to be able to do that. And I just had no idea what salaries were like. Since then, I've looked at levels.fyi, is one of my favorite sites. They'll show you salaries at different levels at different companies.

(17:06):
And if you make it to senior PM, which is one of the middle levels, this middle senior PM level at most of these big companies, you're making as much as a doctor makes, you're making as much as a lawyer makes, you're making a lot of money. You don't necessarily need to climb that career ladder forever to make a lot of money.

(17:24):
And especially at a company like Google, there's a few companies that are known for being the highest paying companies, you can make a lot of money. Much more that you can make in a lot of startups, just by being in IC path, just by continuing to do that job. And companies really need people to do that.

(17:38):
I think understanding that there's different ways to grow your impact and grow your career, other than getting promoted to people management. And for me, I think switching companies is one of the really obvious ways, or teams, of there's one kind of impact you're having at your current job, and maybe you could work on a product that affects more people or has a bigger impact on the people that use it, or something that has more of a social impact type work. But just really thinking about different ways to grow your impact so that you don't make a blind choice towards people management because it seems like it's the only way to grow.

Lenny (18:05):
Along those lines, I know a lot of companies in theory have these kind of IC career tracks. And I find that it's really rare that they end up being really successful, and very few people end up going down to them. Is that what you see too? Or, I don't know, is there a way to actually be really successful going down that path?

Jackie Bavaro (18:22):
Yeah. I think that to the extent that you want to be seeing promotions as like, you want your level number to go up, I think that it is pretty rare. I think that there's not that many companies that have principal PMs, and the ones that have a bunch usually have a partner PM role above that, that's the real principal PM at other companies.

(18:38):
And the reason for that is that the reason a company would give you that high of a title is because they have a business need for PM who can have as much impact as a director, but with the team that's small enough that they can PM the whole team. And there's only a few problems out there like that. Platform type teams can fill that role a lot of the time. Partnerships, someone who's working on a partnership between two major companies can often fit that kind of description. But there just aren't that many, it's a lot easier to have a big impact if you're a manager of managers and you can add up the impact of all the people on your teams.

(19:10):
So yes, I agree that there's not that many opportunities to go from senior PM to principal PM to partner PM. I don't think you need to. I think that if you want to pursue the IC path, which I think is a great path, I think thinking of ways to grow beyond the official promotion. A lot of companies, you can make a lot of money without getting that promotion title. If you're working at a small company, if you're working with other companies that isn't the highest paying company, you'll make a lot more money by switching companies than you will by getting promoted at your current company.

(19:37):
And like I was saying before, the thinking about the kind of impact your work has, do you want to work on something that's more cutting edge? Do you want to work on something that your product that your friends use? Do you want to work on something that's going to save the environment? All of these things I think are ways to grow. There are a career path that is just not climbing the career ladder.

Lenny (19:55):
This episode is brought to you by PostHog. PostHog offers a suite of product analysis tools, including funnels, heat maps, session recording, and experimentation, all in one easy to use platform. PostHog is open sourced, so you can host it on your own infrastructure, which means that you have control over who has access to your data and makes regulatory compliance a breeze, because you don't need to send user info to third parties.

(20:18):
PostHog's app system works seamlessly with your data warehouse, both for importing and exporting data, which enables you to bring your data into one place and easily understand user behavior across a range of touchpoints. If you'd like to learn more, check them out at posthog.com/lenny.

(20:36):
That's a really important insight that you can keep growing, one as a human and maybe even be happier going down one of these other paths, non-manager path. And maybe you don't get the promotions, but maybe you make just as much money as you go the other path. In theory, it's a lot more interesting.

(20:50):
And then the other point that you made is really great, that if you want to go down that route, it's probably going to be an infrastructure team or a new business unit, unlikely to be a user facing piece, because they probably want to build a large teams there with a lot of layers. Interesting. Great stuff.

(21:04):
Okay. I want to transition to strategy. You've written a lot about strategy. I share your pieces often with folks. Diving into that a little bit, first of all just, can you describe what strategy even is? It's like this term that everyone uses all the time and they're like, "Oh, I'm working on strategy. I'm going to get good at strategy." What is strategy in your mind?

Jackie Bavaro (21:21):
Yeah, when I worked at Google, one of the promotions I went up for, I did not get, and I got the feedback that I needed to be more strategic. I was like, "Okay, great. What does being more strategic mean?" And nobody could tell me. And I was like, "Well, who's more strategic?" And they were like, "Oh, this person used to be really strategic before she became a manager. But now she does just those managery stuff." And I was like, "Okay, I have no role models, no words, nothing to explain what it means to be more strategic." Quick shout-out to my book is, I've got a whole list of what it means to be more strategic. So if you pick that up, you can read through that.

Lenny (21:51):
Can we find that on Amazon? Where do you find that book?

Jackie Bavaro (21:54):
Yes. Just the Cracking the PM Career, that's on Amazon.

Lenny (21:57):
Great.

Jackie Bavaro (21:57):
And it's in the strategy chapter.

Lenny (21:59):
Great.

Jackie Bavaro (22:00):
What I did is I wrote a document on the Local Universal Team, so I called it Local Universal Strategy. And I can't remember what I put in this document. I put it in just random... What my plan was. But once I wrote it down and shared it with people, then I started getting feedback on it. And then I could start to feel my way to what people meant to strategy. Then I get to Asana and I worked really closely with JR, head of product. And I'm starting to get a view of what strategy means, and he's got a robust vision for the product. We talked about this idea that when you're playing guitar, you're left and your right hand know how to work together to play the guitar. Wouldn't it be amazing if at a company, all the teams sort of had that ambient awareness of what other teams were doing together so that you worked seamlessly together?

(22:44):
And Asana was the team brain helping this happen. Imagine a world where you didn't have to have these endless status updates and all this work about work, because the teams knew what each other was doing. And as you kept track of your own task that updated the centralized system, that was always up to date.

(22:59):
We had this vision of what the future could be like. And we had our strategy, which got into this team brain. And what's what a good team brain have? Well, has to always be with you. So we need to have good mobile and good security, needs to know about the different kinds of work that exists. So we need to... Right now, Asana understands this kind of work, we need to add this kind of work.

(23:16):
And it has to help you draw insightful connections with the work that it knows. If we know that you have all these tasks with due dates, we need to be able to let you know that maybe you have too many due dates on next Friday. I started to build up this idea of strategy and I was like, "Okay, I think I've got what strategy is." And a few years later we hire Alex Hood, our new head of product. And he's like, "Can you create a strategy for the platform team?" And I was like, "Great, here it is. We have it." And he's like, "That's not a strategy." And I was like, "What?"

(23:44):
I was like, "I've been going all these years thinking I knew what strategy was. And now I, again, find out that I don't know it." We had a lot of conversations and figuring out like, "Well what's missing?" And through all of this, I basically realized that there's three key components to strategy. And not everybody's thinking of all three, but if you have all three, you'll have something that counts as a strategy for anyone you talk.

(24:01):
Three parts of strategy are your vision. This is your inspiring picture of what the future looks like. And this is like, "Hey everybody, this is where we want to get to, don't you want to come join me, come build this future with me? Won't this to be exciting?"

(24:14):
And then you've got your strategic framework. This is where you're saying, "Here is the market we're going after. Here's what success looks like. And here are our big bets on what we think it takes to win that market." That's where you get your pillars, and it's your unique way of breaking down the problem to understand who you're going after and what it takes to win them.

(24:34):
And then the third part is the roadmap. This is where you work backwards from your vision. You say "Okay, I think as a company, we can achieve our vision in five years or 10 years or two years or whatever it is." And you say "Working backwards from that, if we're going to be at our vision in five years, what does that mean we're doing in the intermediate years?" I misunderstood roadmap for the longest time. A roadmap in strategy is not a commitment. Instead, it's a way to double check if your plan makes any sense at all and is even anywhere near feasible. Because what happens to every team I see do these roadmaps, you put it together and you realize "We're not going to hit our vision in five years or 10. This is like a 30 year vision, if we keep going at the pace we're going."

(25:14):
It's this wake up call to say, "Oh, okay. If we want to hit this vision in five years, we need to start working on that big thing now. We need to take much bigger swings at the bat. We need to say no to a lot more of this optional work. Maybe we need to hire a team that's twice as big."

(25:31):
It gives you a way to say that probably your strategy did not actually fit into the timeframe that you wanted and that roadmap helps you see like, "Okay, what would it take?" And then that can be a little bit of an organizing factor for people across the company to understand, "Okay, we're having a major launch in two years, then we need to make sure that we're going to have the marketing support we need for that launch. Or we might need to have an entirely different business model in two years. We need to do a fundraising round now." It really helps kind of pull the pieces together.

Lenny (26:00):
Wow, that's so actionable and easy to understand. I've never heard it describe so simply. Along those lines, say someone creates a strategy, what are signs that it's a good strategy versus a meh strategy? Which should they be looking at?

Jackie Bavaro (26:15):
I'm probably going to write something on this soon. In the past month, I'd actually have two totally different people who came to me with the same problem. And they said, "My CEO brought me a strategy and the strategy is increased revenue by 50%, it's a revenue target number. That doesn't seem like a strategy to me. I don't know what to do." Talking to people, I started to get a deeper sense of what the confusion and the mismatch is here.

(26:40):
I think a good strategy is all about connecting the dots. Connecting the dots from this high level business goal of, "We want to increase revenue by this much" to, "This is the feature we're going to do." And it might have many, many dots in between to help get people from one to the other of like "Given that this is our big picture of view of what we're doing, what's the next step? And what's the next step? And what's the next step?"

(27:02):
"As product managers, if you're given a numerical target, that is not a complete strategy, but it's your job now as a product manager to take all of the great product work you've been doing. Let's say you've been doing lots of customer research and you're getting really deep into what the customer pains are and what their needs are. It's your job to take the things you've got now in your mind, you've got a list of maybe 20 different things your product team could work on. It's your job to take those things you want to work on and the reasons why you think they're important, and match them up against what that larger financial target was or whatever strategy or vision you're getting from the executives. And basically see "Which of these feature work? Which of this product work that I want to do best matches up with those goals and why?"

(27:45):
And there's probably a few more missing dots in there. You're like, "Well, I think that this is going to make us the most money. But why? I think this will make us the most money because it's helping us get more money from our current users. And we think it's going to be really hard to win new users because we're already pretty saturated in the market."

(28:01):
That's where you start to get into strategy, that level of detail. And then you say, "Okay, given that we think it's more strategic to get more money from our current users, here's one thing we could do. What are other things we could do? And how do those stack up against each other? Or maybe it should be that 50% of our effort is on getting more money from our current users, and 50% is from going into new markets. Well, which new markets do we think are most promising and what would it take to win those new markets?"

(28:24):
I think it's that connecting the dots. And the only way you find out what dots are missing is by talking to people and communicating your strategy and communicating it again and again, and really listening for people's confusion. Because people will try to hide their confusion. They won't get your strategy, there's going to be some assumption that you're making that they are not making. So you have to pay really, really close attention to find those missing assumptions so that you can then explain why this connects to this.

Lenny (28:51):
That's really good advice of just looking for confusion and that points out where your strategy is lacking. How could PMs get better at strategy at doing this than getting better at this activity? Advice for that?

Jackie Bavaro (29:02):
Yeah. Strategy really should be collaborative work. I think that there's some amount to which the PM should go off by themselves and think about what strategy they want and have that in their back pocket, because that way you actually can contribute to the conversation, but real strategy should be very collaborative.

(29:17):
I think the best way to learn and improve your strategy, one of them is going to be working with the other stakeholders and listening to their feedback and understanding what do they agree with or not agree with. Sometimes it's as easy as a conversation. I can't remember the details here, but there was one conversation on pricing models that we were talking about, and we were each going to go around the room and talk about which of the five pricing models did we think was best. And I think I was like, "Number three is most [inaudible 00:29:44] number two."

(29:44):
And then our CEO gets, and he's like, "I think really number four is the only reasonable one for these reasons." And I was just like, "I agree, I've changed a mind. You're right. You just saw it in a way that I hadn't seen."

(29:58):
This accumulation of experiences, I think matter so much for strategy, for data analysis, all of these things where... I'm really, really good at data analysis, but only because I've seen so many experiments that when I see a set of results, I can just instantly remember like four similar experiments and what the conclusion was and what went wrong with it. And so I'll be like, "Oh yes, this metric is up. But if you check this metric, you can see it's down, which means that it might be this conclusion." It's talking to people, listening to them, that builds it up a lot. But that's one half of it, because you can't always just learn something by a bunch of leaders sitting in a room talking to each other.

(30:37):
I think seeing things through to a certain amount of time really does help. And I think sticking with the team for long enough to be able to measure the results of what you did and ideally iterate, like being one doing it for eight years, I got to try something and then try something different and then try something different. And I got to really notice the patterns and test what works and what didn't and form those conclusions. I think that sticking around long enough to see your results and especially try something else different and see those results, I think can make a big difference.

Lenny (31:06):
What I'm hearing is you get better one doing it over and over and over to being in the conversations and learning from people directly. Is there anything else that someone that, I don't know, doesn't have a lot of these experiences yet and in the room for these sorts of things that they could maybe study up on or practice just outside of this to get a little bit stronger in strategy?

Jackie Bavaro (31:27):
Yeah. Definitely there's a lot of cross applying of strategy that I think that really is helpful. One of the great ways to learn strategy is to cross apply strategy from other places. One of the people I interviewed for my book was to Shishir Mehrotra, who's CEO of Coda, and he used to work at YouTube. And while he was at YouTube, he had a very big strategic question that the team had to decide about whether if you search for a video that is not on YouTube, but is somewhere else like Hulu, should you link them out to that?

(32:00):
And the team was having a lot of trouble making any progress on that. But one day he went to a product review for Google shopping, totally different product, shopping versus videos. But they were having a similar issue and they talked about this idea of consistency versus comprehensiveness.

(32:16):
They said "Is our product the kind of product where it's better to have consistent results all the time? Like every time you click on a result, it takes you to a Google shopping result or is it better to have comprehensiveness where even though the experience will be different each time we give you a result every time?" That framing, he was able to take from shopping over to YouTube and ask that same question and the answer didn't have to be the same, but it gave them a new way of looking at the strategy that he was able to use.

(32:40):
I think having that broad view and looking at lots of other products and seeing how they make their choices and how do they frame their decisions, that's a good way to improve strategy.

Lenny (32:49):
That's a really good reminder of eigenquestions as a framework. I think if you Google eingenquestions, you can find it and I'll try to link it to it in this podcast. And Shishir has a lot of great stuff that he's put out there. Good call out.

(33:01):
Let me ask one more quick question on strategy and then I want to move on to career stuff. How long should people, I guess, early PMs maybe, how much time should they spend on strategy development? And then, when does it make sense to start investing in that?

Jackie Bavaro (33:15):
Yeah. I think that for your first six months on a product, probably don't worry about strategy. For your six months really, you should be talking to customers, researching your product stuff. Really starting off by saying, "I'm going to learn the strategy, whatever strategy my company already has, and I'm going to do my research, but I'm going to deliver on that strategy."

(33:33):
But all this time, while you're doing your regular product work, so you're visiting customers and you're analyzing data and all these things, you are probably having ideas pop up in your mind. You're starting to notice trends. You're starting to notice what are the pain points people have and just stay open to that. And after about six months, I think is when you can start to put together a draft of a strategy for your own team.

(33:53):
I think you can take half a day. Just block it off, don't take any meetings, put on your headphones, go to a coffee shop, whatever it is you do to get your alone time. And just work on whichever of those three pillars of strategy, whether it's the vision, the strategic framework or the roadmap. Start with whichever one draws you the most and start writing some stuff down, just start getting your ideas out there.

(34:14):
And this will start to give you that framework, you can then go try to take that time, fill it out more, figure out what questions you have, what would you need to know to decide which of these approaches is better, what are the open questions you have. And then you can have something to start meeting with the rest of your product triad. The engineering lead, the design lead, any other key stakeholders you have on your team, and just start working with them and start to figure out how are we feeling about our strategy.

(34:39):
One thing I love to look for is repeated disagreements, "Are there any times when we're fighting over whether to add this feature? And I so strongly believe we shouldn't and you so strongly believe we should," and it's just ends up feeling like a battle of wills. Anytime you have these disagreements that feel really torny or they feel like a disagreement in values, that's a sign that really have a disagreement in strategy and that it's worth it to write down what your strategic framework is or what your strategic principle is and address the problem at that level, rather than fighting over individual features or individual decisions.

Lenny (35:11):
It's such a good tactical tip of just like, if there's continued disagreement, that's a sign, you either craft a strategy or maybe a principle which are related, but sometimes different, just principles of the product or principles of the team. Great advice. And the point you made about not spending the first six months on strategy, I love that because a lot of PMs come in are like, "Oh, strategy. I'm going to figure everything out. I'm going to tell us how to build this thing. This all sucks. Everything you all have done before." Just that rule of thumb, of not allowing yourself to invest deeply there for six months. Love that idea.

Jackie Bavaro (35:42):
Nice. Yeah. I think as a manager, you usually have a reason for hiring someone. And usually at least in your head, you think you've hired them to build on the strategy that you've already created, and there will be room for people to create new strategies and change the strategy. But if they come in on day one saying your strategy is all wrong, raises the question of, "Well then why did you join my team if you didn't believe in my strategy?"

Lenny (36:06):
A lot of times people just want you to help them execute. They're just like, "Come on. We know what we're doing. Just help us ship this thing and it's going to be great." And a lot of people come in like "No, let's just rethink it all. Let's take a step back."

(36:17):
Okay. Last area that I want to spend some time on is around career. Career growth as a product manager and product leader. Luckily you wrote a book called Cracking the PM Career. If you just had to boil down the best advice from the book to one suggestion to a PM, let's say starting off in their career and then maybe a mid-career, what would that be?

Jackie Bavaro (36:41):
I'll start with one piece of suggestion for people at any stage of their career, which is to have a conversation with your manager and say, "I would really like at some point in the future to grow into whatever this goal is," whether it's to become a people manager, become a senior PM, become a director, whatever this next step of what you want is. "I would really love to become a people manager someday. What do you suggest that I work on now so that I'll be ready when the opportunity comes up?"

(37:03):
The reason I love this template is just a really easy way to start off this conversation of saying "Here's my goal, by the way. I do want to get promoted, I do want to grow, I want to become a senior PM," whatever that next step is.

(37:14):
I'm framing it in the future so that it's not threatening. It's not like going to put my manager on the defensive and be like, "You're not ready to be a manager yet. I don't have to prove why you're not ready for that promotion yet." Which is not the mindset you want your manager in.

(37:26):
And then it brings them onto your side. "Can you help me out here? Let's you and me work together to get me this promotion. You and me work together to get me ready there." It brings them in onto your side, so now they'll be in the mindset of trying to help you. It will target the feedback that you get on what you need to do to get that promotion. Because so much of the time, I think the reason that success as a PM is hard is because you get a gazillion pieces of feedback.

(37:50):
They're all true. It's all like "Yeah. In that meeting, you said a lot of filler words." But that's not the thing that's actually holding you back from the next promotion, or it's not the thing that you actually need to improve at to get to that next step.

(38:01):
Being able to focus the feedback you get on what you're trying to achieve, makes a huge difference and will really help make sure that you get that feedback. And at any company, either your manager is going to be the person who decides if you get that promotion, what they say is just true, whatever they think you're missing is what you're missing, or there's going to be a committee. And if there's a committee, your manager's feedback matters a lot. And also if they've been at the company a while, they'll know what they look for.

(38:26):
If you have a new manager at a big company that uses promotion by committee, at any big company, make friends with your manager's peers, find someone who's been at the company a while, who's gotten someone to promoted and ask them that same question. Get them onto your side to get you the experience and the improvements you need to get that promotion.

Lenny (38:41):
Amazing advice. I found that to be super helpful myself. And you're saying that applies to every role. UPMs, everybody.

Jackie Bavaro (38:48):
Yeah. I think you can use that in almost any role because everybody does have different gaps, but then to go into early career people, I think that working at a large company early in your career can be just really, really valuable. If you choose a small company and what's going to be super successful and you pick the winner, that can be better than working at a big company. But big or, I'd say, even medium size companies can be really good here.

(39:10):
But a company where you're going to be able to learn best practices, you're going to be able to grow your network, I think that these large companies really give you... And you'll also be able to make usually a higher salary that starts to build your nest egg, I think that that gives you a really good foundation for anything else you want to do later in your career.

(39:27):
And when you're early in the career, really to have that mindset of absorbing and learning how to be a great PM. One mistake I see people make early in their career is they are trying to overdo it. They've been given some project, usually as a early career person, you get assigned a pretty narrow scoped constrained problem. They're like, "Hey, can you make the print dialogue for our product?" And the right answer to these narrowly scope defined products is not to invent a whole new print dialogue.

(39:56):
A lot of times you've been assigned a problem where a huge creative solution is a bad idea. If you're in one of the situations, just do the simple thing, get it done really well. And that'll earn you the trust to be able to take on bigger things in the future, but you don't need to be outstanding to make it past the APM promotions. You just need to be doing a solid, good job. And later in your career, there's a lot more room for being outstanding.

Lenny (40:20):
What are some of the most common mistakes that PMs make early on in their career that hurt their career?

Jackie Bavaro (40:25):
Yeah. A lot of it is misunderstanding what the role is at different stages in the career and misunderstanding what success looks like. This can show up in a lot of different ways. One of them is, there's lots of APMs who want to become people managers right away, and they poo poo all the regular everyday work you need to do to be a good PM. And that comes across to a manager as immature, certainly, but also just like you don't seem to understand or value what good PMing is, so I certainly wouldn't make you a manager. But also now it's a little hard to convince you to do your day to day job, which makes you a little hard to manage, which might mean put a little bit less of my energy into managing you. It ends up being a bad situation for people.

(41:08):
It's a lot better to show some enthusiasm for the job you're supposed to be doing right now. Other ways that can work is just people optimizing for the wrong things, like leaning in too much or too little. On PMs I see get paired with a really strong designer and you let your designer take the lead on everything. And now you just sit back and you're a note taker and you're not contributing anything. You're not really driving anything. You're not adding your own ideas and making the team better.

(41:31):
That person needs to step up more, to be somebody who's really contributing and adding and being a multiplier on the work of everybody else on their team. And then some people step too much. They're trying to lead everything and they're crowding people out and they're not giving their engineers a chance to present at all hands, and they're burning bridges with their coworkers. And almost every company peer reviews is a huge part of your review cycle. And as a product manager, you need to get along well with the other people in your team. You'll be pushing them and encouraging them to get more done than they would've otherwise, but you don't want to do this by having everybody say, "I never want to work with her again."

Lenny (42:06):
So much of advice I find for early careers, it's just like it should done, make impact, just your job, don't overthink it, if it won't earn your right to move up and take on more responsibility, get promoted on all kind of stuff. I love that so much. It's just do the work, just be quiet, do the work, it's going to go great.

(42:23):
A couple more questions. And before we get to a lightning round. You've exited the PM career path at this point, and I'm curious what made you decide to go in a different direction? And then just, what's next? what's next for Jackie Bavaro?

Jackie Bavaro (42:35):
Yeah. I'm not sure that I've exited the PM career path. I really like working in offices with people. I've been waiting for an end to the remote work era. And once I find companies that are in person again, I'm definitely have some curiosity about that. I might go back to in person work.

Lenny (42:51):
Oh my God. I'm imagining your LinkedIn is about exploding right now, as people are listening to this.

Jackie Bavaro (42:57):
I'm in San Francisco.

Lenny (42:59):
Oh boy. And then were you going to say something else?

Jackie Bavaro (43:02):
Nothing is settled, but I've been playing around with the idea about whether or not to update the Cracking the PM Interview book. Lots changed. Some of the companies there are not the top companies anymore. Some top companies aren't in there, some of the companies have changed their interview processes. I think that could be a lot of fun to get that more up to date. Some of the changes that have happened in interviews over the past years.

Lenny (43:21):
Amazing. I imagine many people will be very excited to see a second edition of Correcting the PM Interview. Okay. Let us get to our lightning round. Okay. I'm just going to ask six questions and just tell me whatever comes to mind as we go through them, real quick. And maybe we'll pull out a thread or two as we go through it. Are you ready?

Jackie Bavaro (43:39):
Yes.

Lenny (43:40):
Okay. What's a book that you recommend most to other product managers other than your book?

Jackie Bavaro (43:45):
I love Getting Things Done by David Allen.

Lenny (43:47):
Ooh, okay. Around productivity. I love that book. That was really transformative for me when I read it many years ago, and I still use a couple of this points. Awesome. Okay. Getting Things Done, David Allen. Other than Asana, what's a company that you recommend to PMs that are looking for a new gig? What are some companies that you're excited about, potentially?

Jackie Bavaro (44:06):
I'm not the most up to date with all of the companies, but I do think that Microsoft is pretty underrated. I had a lot of fun working at Microsoft. I learned a lot of good strategy there. I think I got a really good foundation for a lot of the rest of my career.

Lenny (44:19):
Contrarian pick and they've been killing it. That makes a lot of sense. Good choice. What's a favorite app right now for you?

Jackie Bavaro (44:25):
I have a recipe manager called Paprika. I really like it.

Lenny (44:30):
Ooh. Does it have actual recipes or is it track other recipes you've found?

Jackie Bavaro (44:34):
It tracks other recipes. You can save any URL and it'll extract the recipe from there and you can do meal planning in there. You can turn things into a shopping list. You can use it across your phone and your computer for when you want to sit down and browse. But I really enjoy just browsing recipes and a lot of them I'll never cook, but just the idea that, "Oh, I could imagine cooking that," it's a lot of fun. It's a little bit like traveling.

Lenny (44:58):
Wow. You could say Paprika. Okay. And then who's someone that you love to follow on Twitter or Instagram currently that maybe people haven't heard of? Or maybe they have.

Jackie Bavaro (45:06):
I love Helen Rosner, @hels, H-E-L-S. She's a food writer for the New Yorker, but it's a lot deeper than food. A lot of it gets into society and bigger topics.

Lenny (45:19):
Wow. I see a pattern here around food. Who's your favorite manager that you've had?

Jackie Bavaro (45:23):
I think it's probably JR at Asana who I worked for gazillion years.

Lenny (45:28):
Any particular reason why?

Jackie Bavaro (45:29):
I think there's got to be a match between you and your manager. And I think that we had a lot of mutual respect, and I think that I was really lucky in that he was absolutely amazing at vision. I was able to learn a lot from it from him. And there were a lot of places where I was able to help. A lot of my early experience of even getting to learn strategy and vision he was like, "Jackie, can you help me with the slides for the vision all hands?"

(45:54):
And I would be doing busy work of putting the slides together, but then I could make some suggestions, I could ask some questions. And first year I was just basically doing slides. Second year, I had a little bit of shaping. Third year, he let me take the first stab at it and then he reviewed it. I think he was always willing to help me grow and really saw it as a win-win where if I grew into something, then that would free up his time to take on something bigger and better.

Lenny (46:20):
Awesome. Sounds like an awesome manager. And then last but not least, what's a favorite interview question that you love to use?

Jackie Bavaro (46:26):
I love to ask, "Tell me about a recent project that you're proud of." I feel like a lot of interviews don't give people enough chance to shine, to talk about something that they did really, really well and hear about what made it so good and what are they proud of, and how did they achieve those amazing results.

Lenny (46:46):
And then what do you look for in an answer there? What are a couple bullet points of a good answer to that?

Jackie Bavaro (46:46):
It's so different for every question, but I'm definitely looking for try to get something recent, so I want them to be something that matches the level that they're applying for. There's going to be a really big difference between the way that an APM answers this question and the way that a director of PM answers the question. I look to see how did they think about strategy, what was their judgment on different choices, what was hard. I have a framework for this. The pearl framework for answering questions like this is problem, epiphany, action, result and learning.

(47:15):
It's a little bit like the star framework, but I want it all like, "What's the problem that you thought was worth solving, a problem that I think is big enough? What's your epiphany? What's the insight that you had? Do you notice something that nobody else did and how valuable was it?"

(47:28):
A lot of times that's what makes these PM stories so interesting. Is that meeting with customers, head on and they said one weird word and you dug into it and you learn this whole new customer need that no one else had seen before. And then there's going to be the action. Like "What did you actually do to make this happen? And was it hard?" Because usually it is hard, but understanding the ways in which it's hard and how you overcame each of those challenges. And then obviously a PM should care about results and the thing they pick that they're proud of should have good results or have at least results that they learned from.

(48:00):
And then, yeah, that last part of learning. "Did you grow from this?" Especially if it's a failure, which is lots of people love to talk about the products that failed or sometimes the interviewer asks them to talk about a product that fails, but I don't want them to leave it at "Yeah. It was a big loss. Our company lost $50 million and we couldn't get it back," but then you want to say like, "Okay, but what I learned from that is now I need to always run a load test on a staging server and then I've had many successful launches since then that we didn't have that same problem in."

Lenny (48:29):
Wow. What a fruitful lightning round. So many nuggets. We got a new framework in there too. Okay. Where can folks find you online and then any last words of wisdom?

Jackie Bavaro (48:38):
Yeah. I'm on Twitter, @jackiebo. I'm on Twitter all the time. Send me a message, I'll probably see it pretty fast.

Lenny (48:44):
Amazing. Thank you so much for being here, Jackie.

Jackie Bavaro (48:46):
Yeah. Thanks for having me. Great conversation.

Lenny (48:49):
That was awesome. Thank you for listening. If you enjoyed the chat, don't forget to subscribe to the podcast. You could also learn more at lennyspodcast.com. I'll see you in the next episode.

---

## Building better roadmaps | Janna Bastow (Mind the Product, ProdPad)
**Guest:** Janna Bastow  
**Published:** 2022-10-16  
**YouTube:** https://www.youtube.com/watch?v=W3cvqPCGcck  
**Tags:** growth, retention, activation, onboarding, okrs, roadmap, iteration, experimentation, analytics, conversion  

# Building better roadmaps | Janna Bastow (Mind the Product, ProdPad)

## Transcript

Janna Bastow (00:00):
The whole point about a roadmap is that it's not designed to be your plan. I think about it as being a prototype for your strategy. What I mean by that is we talk about prototyping all the time in the lean world and a prototype is essentially a way of checking your assumptions. Generally, we think about it in terms of a design or like a model, but think about it at the strategy level.

Janna Bastow (00:22):
So at the feature level, you'd prototype by doing a design, a mockup, and you'd take that mockup and you'd share it with somebody and say, "Here's a mockup of the feature that I'm trying to build. What do you think?" And they'd tell you what's right or wrong, and you'd add some new copy or a button to make it more clear, and you'd throw out the original prototype, because it wasn't very good and you'd make a new one. So the value isn't the prototype, the value is in the prototyping process.

Janna Bastow (00:47):
The value isn't in your roadmap, the value is in the roadmapping process. What you're actually doing is laying out your assumptions of the problems that you're solving. So you're saying, "I think we have this problem, then this problem. What do you think?" The whole point is that you just share your early assumptions with other people on the team, with customers, even, like anybody who will listen and just check that you're on the right path.

Lenny (01:11):
Welcome to Lenny's Podcast. I'm Lenny, and my goal here is to help you get better at the craft of building and growing your own products. I interview world class product leaders and growth experts to learn from their hard won experiences building and scaling today's most successful companies. Today my guest is Janna Bastow. Janna co-founded Mind the Product, which I believe is the largest community of product people anywhere. She's also the inventor of the roadmapping framework, Now, Next, Later, and the founder of ProdPad, which makes it easy for you to do your roadmapping in this new simpler way. In our chat, we talk about public speaking, community building, roadmapping, vision, and going from product manager to founder. With that, I bring you Janna Bastow.

Lenny (01:58):
This episode is brought to you by Formsort the leading low-code form builder for product teams. If you work at a startup, you've probably experienced the pain of building forms. Product managers come up with an idea for a new onboarding flow, and then engineers have to build it and then maintain these flows forever. Even tiny changes to the flow can take weeks to get implemented, slowing down your team's experimentation cycle. Formsort removes the engineering bottleneck and gives product managers and marketers full control over the form building lifecycle. With Formsort, anyone can build highly customizable forms, implement complex logic, and send data to destinations like Postgres, BigQuery, and Segment.

Lenny (02:38):
Companies like GoodRx, Candid, and Balance Homes build their most important forms on Formsort, think patient intake data, surveys, and fintech onboarding. They've seen conversion rates increase by over 30%, and have saved thousands of engineering hours. I always tell startups that improving onboarding is one of the most powerful ways to optimize activation and increase retention. Formsort makes this process as easy as possible and it's why I'm a proud investor. You can sign up for a free account on formsort.com and use promo code Lenny for 20% off a Formsort Pro plan.

Lenny (03:15):
This episode is brought to you by Coda. Coda's an all in one doc that combines the best of documents, spreadsheets, and apps in one place. I actually use Coda every single day. It's my home base for organizing my newsletter writing. It's where I plan my content calendar, capture my research, and write the first drafts of each and every post. It's also where I curate my private knowledge repository for paid newsletter subscribers. And it's also how I manage the workflow for this very podcast.

Lenny (03:42):
Over the years I've seen Coda evolve from being a tool that makes teams more productive to one that also helps bring the best practices across the tech industry to life. With an incredibly rich collection of templates and guides in the Coda doc gallery, including resources from many guests on this podcast, including Shreyas, Gokul, and Shishir, the CEO of Coda.Some of the best teams out there like Pinterest, Spotify, Square and Uber, use Coda to run effectively and have published their templates for anyone to use. If you're ping ponging between lots of documents and spreadsheets, make your life better and start using Coda. You can take advantage of a special limited time offer just for startups. Head over coda.io/lenny to sign up and get a $1,000 credit on your first statement. That's C-O-D-A.io/lenny to sign up and get a $1,000 in credit on your account.

Lenny (04:44):
Janna, welcome to the podcast.

Janna Bastow (04:45):
Hi, thanks so much for having me.

Lenny (04:47):
It's my pleasure. Just to start off and set a little context for folks, could you give listeners a 55 second background on what you've been up to in your career?

Janna Bastow (04:57):
Yeah, absolutely. So I'm a product manager by background. I started my career falling into product management like a lot of people do, accidentally. I worked my way up to be head of product at a startup in London. And then saw the need for product management tools, because there wasn't really anything like that out there. So started building ProdPad. One of my co-founders, who I also happened to start Mind the Product with, and Mind the Product turned into the world's largest community of product managers. So I ended up founding two things at the same time, and that's what kept me busy for the last decade or so.

Lenny (05:28):
And currently you have a company, maybe just mentioned that, before we move on, because I think it'll be important.

Janna Bastow (05:33):
Yep, absolutely. So that tool that I was talking about turned into ProdPad, which is software for product people. So it's a tool that allows you to build roadmaps and do your OKRs and capture ideas from your team and feedback from your customer and just organize all your product managements stuff in one space.

Lenny (05:47):
Awesome. So you mentioned Mind the Product and ProductTank, which is kind of this associated component. I'm not exactly sure the difference, but I know they're related. One's a community component, right? Is that right?

Janna Bastow (05:57):
Yeah.

Lenny (05:57):
Yeah. So I think you mentioned it's probably the biggest product community in the world, both online and offline. And as someone that's building their own community around the newsletter and the podcast that I have, I'm always curious just to learn what folks have learned about building communities, especially for product people. So question on my mind is, what do you think has been most important in getting Mind the Product community right early on, and then also just maintaining the quality of the community?

Janna Bastow (06:23):
Honestly, it wasn't so much that we set out to build a community, it was that we got together with some product people with the idea that we didn't know what we were doing. And so we figured if we got together with some other product people and started chatting it through, we'd all learn together. And so it was just the sense of sharing and collaborating and learning from each other and just keeping it as grassroots as possible as it grew. And consistency as well, just always being there, every month, holding a ProductTank, every year of holding an event. But just being there, whenever there was a chance to be there.

Lenny (06:56):
So I'm hearing is just putting in the time, doing it consistently. I imagine a big part of it was having the right sort of people involved early on that are maybe the right exemplars of the type of community you want to build. Is that roughly right?

Janna Bastow (07:09):
Yeah, absolutely. I mean surround yourself with the people who are going to help you continue that community and are going to help you with that consistency, and going to help you surround you with more and more of the right people. One of the things we learned really early on was that we only had so wide of a network. And so being able to get other people to help us curate and bring in other smart people to help find other speakers outside of our network, and help find people to write on the blog when we'd run out things to rant about. Similar to what you do, Lenny, you've got people from all over your community helping to contribute to the wider picture.

Lenny (07:42):
Awesome. What's the scale of the community at this point?

Janna Bastow (07:45):
That's a good question. I don't have the exact number. What you might not know or what you might know is that Mind the Product was actually sold earlier this year, so I don't have-

Lenny (07:51):
Mm-hmm. I did know that.

Janna Bastow (07:52):
... a handle on the exact numbers now. And it did go influx when COVID hit. I know at one point in time the ProductTank was like 200 going on almost 300 cities around the world. I don't know what that number is today. I know that it sort of went up and then down and then back up again. Some of those are digital still, some of those are back in-person. I know that there's thousands and thousands of product people around the world who are taking part in the community in one way, shape, or form or the other. And, of course, some people take part in the big conferences as well.

Lenny (08:22):
I imagine there were some mistakes that you made along the way building this community.

Janna Bastow (08:26):
Oh God.

Lenny (08:26):
Is there anything that stands out as, "Oh, man, we shouldn't have done that"? For folks that are thinking about building communities these days,

Janna Bastow (08:32):
When running a conference, it's one of the most expensive and unleanest things you can possibly do. It's really difficult as a product person to pull that off, because it pulls at your heart. You want to do something that's lean iterative, but you can't. If something screws up with the lunch order, for example, you can't fix it. You have to wait until the next year and you just have to pull out whatever you can to make it good enough for that particular year. There was a year once when we ordered food and it didn't turn out to be enough, because the caters under delivered, and we ended up having to get all our volunteers to go to the local sandwich shops and buy all the food up and bring it in.It was stuff like that that was difficult at the time, but we made do with what we could and we ended up sending cash cards to our attendee saying, "Here, let's make it up to you." Stuff like that, that just becomes logistically really, really difficult when you're just thinking, "Oh, we just pay a supplier and they make it happen." It's not that simple.

Lenny (09:29):
Got it. Okay. But that's a plus one for me to never run a conference, something I never want to do. And this is a reminder of all the pain that goes into them.

Janna Bastow (09:38):
Conferences are ridiculously hard. I mean the thing that I've learned is when something goes wrong in a conference, it doesn't happen in the hundreds of dollars of cost, it happens in the thousands of dollars of cost. A speaker who decides they can't make it for one reason or the other, totally legitimate reason, sure, but you've already paid for their business class flights, and so you've got to find another speaker last minute and get them over. That's thousands of pounds in the hole. It could be things like the printing went wrong and you found out the day before, that's more dollars gone. There's lots of things that could go wrong. Our venue once went bust, the after party venue once went bust three weeks before the conference. That was year one.

Lenny (10:19):
Super.

Janna Bastow (10:19):
All of these things, yeah, that's what we said, "Super, what are we supposed to do?" We ended up having to just make do and found somewhere else and roll with it. So lots of things that go wrong at that sort of level. But the thing is that we built up a lot of goodwill with the community and were able to get help from people around us, get suggestions from people around us. And when things ended up, actually it turns out we ended up with a smaller venue than we expected, or this was slightly different or whatever else, we had people forgive us. It worked out okay, in our favor.

Lenny (10:49):
Just while on this topic, I'm most curious, are conferences like a good business? Do they make a ton of money in some occasions? Is it always just super thin margin? How does that even business work?

Janna Bastow (10:59):
It's not for the faint hearted. It's hugely risky. In hindsight, I'm highly surprised we actually made it through some of those first ones. If you can do it, there are some amazing ways that you can monetize them. But it only starts making a difference at larger figures, and it takes a lot of efforts to actually get to that point. Somebody once asked me like, "Oh, we're struggling to sell tickets. How do you sell all those tickets?" We'll start a community several years before and invite people and run a thing, some sort of community meetup every month time, time again beforehand, and that's your marketing.

Janna Bastow (11:33):
Just if you undersell tickets to a conference, for example, it can absolutely break it. And you see sometimes conferences, they run one and they don't have enough people turning up and it's gone. That can just break it. It's ridiculous. Something like COVID comes by and it can break it. It's a ridiculously hard business. It's really hard to ensure against. It's really hard to think of all the things that could go wrong and protect against. So while there are some upsides, it's not for the faint hearted.

Lenny (12:01):
Okay, cool. That's another plus one. I have a friend who runs events here in San Francisco and I'm always just like, "How can someone be excited about running events over and over? It's so stressful and full of risk and there's always things going wrong. You can't ever have fun at these things." So it's always a different personality.

Janna Bastow (12:16):
Yeah, event organizer or event manager or something like that was once listed as one of the most stressful jobs out there. And you can see why. It's because it all just lands on you all at once. And once the event is over, there's the sense of [foreign language 00:12:29], as in it's over and now what? The next day you're just like, "Yay." You can look at the tweet stream of everything that happened. You can look back at the photos and then you're like, "What do we do next?"

Lenny (12:38):
Start prepping for ext year.

Janna Bastow (12:39):
You start prepping for next year, off we go again. And it's really hard work. But there again, product management was also listed as one of the toughest jobs, one of the hardest jobs out there. I'm not sure if that still stands, but I know product management as it stood 10 years ago, five, 10 years ago, certainly did have a different vibe to it, and it was a really tough job.

Lenny (12:58):
Continues to be a very tough job. On the topic of conferences and speaking, I've watched a bunch of your talks online before we started chatting today. And a couple things I noticed. One is you're just an awesome speaker, and you're also storyteller. And something that comes up a lot on this podcast is just how important communication skills are to product leaders and product managers and storytelling. And you've also seen a bunch of people do awesome talks at these conferences. So I'm just curious, whatever you have in mind, what has helped you become a better speaker and storyteller? And then also what have you seen is important to folks that are really good at storytelling and presenting at a conference, let's say?

Janna Bastow (13:37):
Right. Yeah, such a good question. I mean, I have learned by watching a lot of other people. One of the things that I have been super lucky in my career is that by being part of Mind the Product I've gotten to watch every last Mind the Product speaker, top end speakers. I've been able to see every ProductTank London speaker, and a lot of the other ProductTank speakers around the world. Been able to see what people react to, what works, what doesn't work. So I've been able to develop a taste for a good talk and a good presentation and that sort of thing.

Janna Bastow (14:06):
But also one of the things that Mind the Product has been able to provide to speakers is a speaker coach. So when I was invited to speak on the Mind the Product stage in 2017, one of the things that they provided to me was an actual speaker coach, somebody to take my talk and improve on it. And it was really nerve-wracking taking my half-written talk, which I started months and months before, it started off with just Post-It Notes scattered along the wall, which I tried to turn into something. And I think it was probably six hours worth of content. And I brought this to this speaker coach, and I had a vague script idea of what I wanted to say.

Janna Bastow (14:43):
And she said to me, one of the first things, she said, "Well, I've taken your script and I've turned it around. I've rewritten the jokes to land a little bit better." I was like, "That's great. I had jokes." And she helped turn the stories around, so that they carried through. She helped with posture. She helped with delivery. She helped with even just phrasing of words. Just making sure that everything landed in particular ways. And one of the things she did was make me listen to it and play it back, which I had not done before. And I still hate doing to this day, but am now more used to it than before.And I don't think anybody likes listening to the sound of their own voice. I don't think anybody likes doing that. But it does help with it. If you've got a large presentation, a big presentation, you've got to get up to that level. If you're nervous about doing it in front of a 1,000 people, then getting to that level that you're actually willing to, able to hear yourself do it, and you're able to do the talk flawlessly in the shower, and as you're walking to work, and as you're doing your groceries and all that sort of stuff, then it makes a big difference.

Lenny (15:47):
So one tactic that I love that you shared is record yourself, watch yourself ,keep refining, but watching your actual performance. Looking back at the lessons your coach taught you for new presentations that you do, is there anything else that sticks with you? Or just let's make sure to get X, Y, Z nailed because that'll help make this talk better.

Janna Bastow (16:06):
One of the things that I've stopped doing is I used to sit down with a PowerPoint and start writing my deck in PowerPoint or Slides, now. What I now do is I start with my story points. I start with my narratives. I try to figure out what I'm actually trying to say, and then I fit it into the deck. Because what I was doing before, I would get stuck in this mode of the presentation mode, and trying to make the presentation, the slides fit my narrative as opposed to the opposite way around. Having a great narrative, and the slides should follow more naturally.

Lenny (16:43):
What about just the presenting, the physical anxiety of presenting?, Is there anything you've done there to get better with that and feel-

Janna Bastow (16:51):
Oh, yes.

Lenny (16:51):
... more comfortable?

Janna Bastow (16:51):
So one of the things that actually really does work is the power pose, standing with your hands on your hips and it really does, I'm not sure if it's adrenaline or endorphins or something, it releases some sort of chemicals that really does just help boost your confidence and make you feel better as you're getting ready to stand on stage. And it something that's me and other Mind the Product speakers, and I've done behind all the big stages that I've done in recent years. Stand there with your hands on your hips and just feel better about it as opposed to sitting there balling up in that tense pile of stress.

Janna Bastow (17:25):
One of the other things that I always do, if I get a chance to, is get out onto the stage sooner rather later. So when they do the tech check, just walk out onto the stage and just wonder back and forth and look out to the audience and greet it. There's no one there. It's the day before, it's completely empty. But look up at the audience and just enjoy that sweep of the audience, and just get used to it. And imagine it full of people. Don't imagine them naked, that doesn't matter. But just imagine them there, so that when you actually do see them the next day, it's not so stressful.

Janna Bastow (17:56):
One of the other things I try to do is find the people in the audience who are your fans. And you'll find them in the course of your talk. There's always going to be some people in the audience who just look bored and they're on your phone, just ignore them. They're always going to be there. Find the people who are nodding along and smiling and going, "Yeah, yeah, that's me. That's me." And just speak to them. And if you find one up there and one over there and one down there, no one's going to notice that you're doing your talk just to them. And just keep delivering your talk around the room to these few key people. They're having a great time, you're having a great time, and you're doing a great talk as a result.

Lenny (18:30):
That's such good advice. The power pose piece, you said that it's hands on hips. I think there's also when we raise your hands up and you're like Superman or something. I think there's-

Janna Bastow (18:38):
That could work, yeah.

Lenny (18:38):
Yeah. I think people have different ones. Also, I've seen that, there's like all the science that showed that was effective and then I think it was one of those experiments that wasn't replicatable. People are kind of worried that there's not real science backing that up. But I've done that myself and it actually works. And so it doesn't matter ,if it works for you, just do it.

Janna Bastow (18:57):
Yeah. If it's a placebo, hey, don't tell me that, it works. Honestly, I feel better at the end of it, and get on stage and do a better job.

Lenny (19:05):
Someone made this point, placebo is this magical thing that we have in our brains that gets things to change by not having anything go. You just change things. It's amazing. It's magical.

Janna Bastow (19:15):
Yeah. Placebos are as effective as the actual drug, whatever. I'm happy with a placebo. Just don't break the placebo effect for me. That would be fine, right?

Lenny (19:23):
Yeah. That's right. One last question on the speaking stuff. How bad were you initially? Just because folks probably see you, see some of your talks and they're like, "Oh, my god, I'm never going to be this good. I'm screwed."

Janna Bastow (19:34):
Yeah, I used to be shaky, little fawn, shaky voice, terrified at the front. Okay. So it was one of the first ever ProductCamp events that we were running. And the first one I think I did okay at, but it was a smaller group, it who's only like 50 or so people. And the second one it had ballooned to 200 people. This is more product people than I'd ever known. And they were all super professional, and they're all looking at me. And I stood at the front of this group and I was supposed to just, I don't know, tell them what they were supposed to be doing that day. And I had it all half written down, and I started talking and then I sort just tripped up over what I was saying and forgot everything and blanked. And I just looked up and I went, "I'm really sorry everybody. I'm just going to start again."

Janna Bastow (20:19):
And I started again. I said, "Hi everybody, I'm Janna and welcome to ProductCamp." And I just started again and they were just totally fine with it. Honestly, it was fine. And this is the thing that I've learned since then is people in the audience are rooting for you. They were totally cool with this. They didn't think anything of it and they just rolled with it, as did I. And so whenever I see somebody who's struggling on stage, just give them a nod, a smile, clap them along, give them reassuring looks, and hopefully they'll just pull through.

Janna Bastow (20:48):
And if you ever feel like you're shaking, you're corpsing on stage, you're falling apart, honestly, just take a deep breath and just pick up where you last remembered you were and just keep going. Honestly, no one is rooting for you to fall over and have a bad time. Everyone's rooting for you to finish your point and get on with it.

Lenny (21:05):
That's such a great story and it's a good example of people have this fear of the worst case scenario. Everything's going to fall apart. They're going to be seen as idiots, they don't know what they're doing. It's all going to be revealed on stage, because you screw up in how you're talking. And the worst case scenario never happens, in my experience. And two,, if it does, just do exactly what you said, just try to start again. It's easy to say, hard to do. This isn't a conscious thing that people can get over. It's like your body's just doing crazy shit and you're so nervous sometimes and can't just rationalize it to like, "Nah, it'll be fine." But, yeah, it's fine. To your point, people want you to be awesome and succeed. They're not there to like, "Ha, ha, you stopped. You screwed up."

Janna Bastow (21:47):
And it's humanizing when you screw up, right? People don't like people who are perfectly perfect and don't mess up, and it makes them feel like they can't go up and go do their talk. I mean I think that right there showed everybody else that they could go up on the little ProductCamp stages that day and go do their own talks. And they certainly wouldn't be any worse than that. As long as I just remembered their name, they'd be fine. Crack on, they got it.

Lenny (22:12):
Speaking of screwing up, you have some very spicy takes on roadmap and roadmaps.

Janna Bastow (22:16):
Ooh, yes, I do.

Lenny (22:20):
And then generally the mistakes people make in organizing the roadmap. So I definitely want to spend some time here. So first of all, you have some strong feelings against Gantt based road mapping. Can you talk about that?

Janna Bastow (22:31):
Yeah, sure. I used to do timeline roadmapping. The first version of ProdPad was actually a timeline roadmap. So to take you back, when I was a junior product manager, mid-level product manager, I used to do my roadmap like everyone else was doing the road, as in I looked up what a roadmap was, and it looked like a colorful Gantt chart. I knew what a Gantt chart was. And so I started putting one together, which is where I'd take the features that I was working on and line them up against their due dates. And I would get a little pat on the head from my boss, and they'd say, "Good job, now go deliver it," basically.

Janna Bastow (23:05):
And I would do my best with delivery, and I'd never quite be able to deliver everything. Something would always get in the way. But I sort of assumed that was my fault. I just wasn't great at delivery, and I just had to get a little bit better at adding enough buffer and setting expectations and doing a roadmap slightly better. But I figured that this is how everyone was doing the roadmaps, and it was just me who wasn't finishing the stuff on the roadmap quite right.

Janna Bastow (23:29):
And when it came to creating the first tools for roadmap, I'd envision something that would actually help me manage this format of a roadmap more easily. Which I ended up creating the very early version of ProdPad, which was a digitized version of this, where you could drag and drop ideas onto the roadmap and stretch and squeeze them, and pan the roadmap back and forth. And I shared this with some early product people that I knew, some early users, and they gave me some feedback and some of them absolutely loved it.

Janna Bastow (23:56):
They're like, "Yeah, this is great. Now I can stop using PowerPoints or whatever tool I'm using or drawing it up in whatever I can now start using this digitized tool." But one of the things that we started hearing from early customers is about a month later they said, "Great, but I want to take this, and move all these things here over by a month in the field." We're like, "Oh, that's interesting. We've heard that from a bunch of other people too. Now why is that?" Because had we just asked our customers, had we just built what our customers wanted, we would've just ended up with a multi-select drag and drop. But this was all built in jQuery and it was a little bit difficult to build that.

Janna Bastow (24:35):
So we sort of asked the five whys, we dug in to why people wanted this thing, and we found out that no one was actually delivering the roadmap in the timeframe that they were saying they were. So we're like, "Wait, if it's not just us who's not living the roadmap and none of these better than us roadmap product managers are building the roadmap on time, what's the point of a roadmap? Why are we giving them a roadmap?" So that's when we sat down, it was myself and Simon, my co-founder at ProdPad, and we sat down and we came up with a three column roadmap, current, near term, future, which became now, next, later.

Janna Bastow (25:08):
And it took away the simple concept of a timeline at the top. Now, the problem with the timeline is that as soon as you have a timeline, it turns it into a math chart sort of thing, where you've got time on the X axis and things to do on the Y axis and you basically end up with everything underneath is assigned a due date or a iteration. And it seems that everything that you do has a due date, an iteration just by the format of the roadmap, which is painful. It's just wrong, because we don't have that. The further out you plan, the more you're making it up. We know this.

Janna Bastow (25:45):
And so we wanted more flexibility and we knew that other product managers wanted that flexibility, because we kept asking what they were up to. So we decided to break it down into these three buckets, and provided that as an option and people loved it. It became this first bump in our usage of ProdPad, because people went, "Oh, wait, I can just say what's happening now, what's happening next, and what's happening later? And if I want to, I can add a date to the specific thing, but I don't have to. And I can be less and less granular about that as I go forwards. Yeah."

Janna Bastow (26:18):
So it's taking from the concept of the cone of uncertainty, taking from the idea that things get less certain as they get further away, which is kind of how reality works. So the whole beef with the timeline roadmap is just taking apart the concept of the timeline. It doesn't mean we live in la la land. It doesn't mean that we don't believe in having dates on the roadmap, if there is a date that we have to work towards. It just means not penalizing ourselves by having a date on everything on the roadmap.

Lenny (26:49):
Got it. Okay. I didn't know that you could put dates on some of the things that's interesting, because I was trying to understand exactly how this approach works. We should also mentioned, you came up with this whole idea of now, next, later, which a lot of people use now. Is that right?

Janna Bastow (27:01):
Yeah.

Lenny (27:02):
Awesome. Okay. So as someone that's been using Gantt timelines his whole career, I'm really curious to dig into these ideas and challenge the default assumption.

Lenny (27:12):
I'm excited to chat with my friend John Cutler from podcast sponsor Amplitude. Hey, John.

John Cutler (27:17):
Hey, Lenny. Excited to be here.

Lenny (27:18):
John, give us a behind the scenes at Amplitude. When most people think of Amplitude, they think of product analytics, but now you're getting into experimentation, and even just launched a CDP. What's the thought process there?

John Cutler (27:30):
Well, we've always thought of Amplitude as being about supporting the full product loop, think collect data, inform bets, ship experiments, and learn. That's the heart of growth to us. So the big aha was seeing how many customers were using Amplitude to analyze experiments, use segments for outreach, and send data to other destinations. Experiment in CDP came out of listening to and observing our customers.

Lenny (27:51):
And supporting growth and learning has always been Amplitude's core focus, right?

John Cutler (27:55):
Yeah. So Amplitude tries to meet customers where they are. We just launched starter templates, and have a great scholarship program for startups. There's never been a more important time for growing.

Lenny (28:04):
Absolutely agree. Thanks for joining us, John. And head to amplitude.com to get started.

Lenny (28:09):
There's two questions that this brings up, and you may have answered them in part. One is just without dates on things, how do you make sure marketing and sales and your CEO has things that they need for promising or at least giving a sense of when a product will come out? And the other is just aligning internally with engineers, design being done on a certain date, engineers being done on a certain date, PMs being done a certain day, [inaudible 00:28:32]. How do you deal with those in this format?

Janna Bastow (28:36):
There's a couple ways that you can turn that around. So one is you should still be having regular communication, so they can still see what's coming up in the now call them. So they have a sense of what the order of things are and that things that are in the now column are probably weeks away, not months and months away. You should probably have launch readiness meetings so people understand this is the stuff that's going through testing, and that's likely to be coming out now.

Janna Bastow (28:59):
But one of the other things that you can be doing for your marketing and sales teams is separating your hard launch from your soft launch. So what you should be doing is basically saying your developers are able to launch something on a particular date and it's the date that's convenient for them, right? Let's say they think that they can get something out for end of September. Now, that might be pushed to made October because things go wrong.

Janna Bastow (29:23):
Now at that point, whether it's end of September or mid-October, it doesn't really matter to the marketers because they're busy talking about the stuff that was launched in August. They've got lots of stuff to work on. They're selling and marketing the stuff that's already live and out there. When this new thing comes out, that's a soft launch. As soon as that soft launch is out, great, let's kick off this launch meeting with launch steps. Now you've got something else to go do. And it's so much better for marketing anyways because they're not setting up their launch steps based on something that they don't have eyes on. There's nothing worse than the marketers trying to market something based on pictures from the designers that have vastly changed by the time they go out or that they don't know whether it's going to come out on the right day or not.

Janna Bastow (30:07):
So they've actually got a functional working version that they can share with some customers. They can start getting videos of it working. They can get testimonials from early beta users. And then they can spend, whether it's two days or six days or six weeks or six months planning the biggest, bangest launch they want. They can then spend the next however long they want to launch their hard launch, and then that goes out. And in that period that they're doing that hard launch development is cracking on with their next thing.

Janna Bastow (30:41):
And by the time that they're done that marketing is then, "Okay, great, what have you built? We're ready to work on the next thing." So you're just separating soft launch from hard launch, so that you don't have this stress of trying to line up to completely different types of projects, your marketing projects and your development projects, which is where a lot of those things fall apart.

Lenny (31:00):
Got it. So kind of the basic premise is roadmaps or timelines sound great and awesome. Everyone would love to know when things are going to be done and if it worked it'd be great. Oftentimes, they're all made up, they don't work, you don't hit deadlines, they're always missed. So instead of promising dates for everything you're doing, you're better off generally just giving a sense of, "Here's what we're going to work on now. Here's what's coming up next." And then for the things that really need a date, we're going to put dates on those things and give it our best shot. Is that [inaudible 00:31:29]-

Janna Bastow (31:29):
Yeah. That's absolutely right. If something does have to have a date, we don't live in la la land, if something has a regulatory date, when GDPR came down, everyone had a due date on the roadmap, because if you didn't hit that date then you were going to be in trouble. Sometimes you might have dates that are tied to things like the Christmas rush, or if you're in education it might be like has to be out by the school year.

Janna Bastow (31:50):
At which point, in order to reach something by that date you have to put in more project planning work, as in you have to plan out ahead of time, you have to put in more buffer time to do that. And generally you have to plan to get that thing done well before, so that you can have a soft launch before and make sure it works and do some iteration and fix it before the actual full-on launch happens. Because if you leave it too late, it's going to go wrong and you're going to miss the deadline.

Janna Bastow (32:16):
If you did that for all of your launches, you're just going to end up either cutting quality, because everything's just going to be big crap cause it's going to be pushing it out the door last minute. Or you're just going to end up spending so much time trying to plan things to the nth degree that you're just going to move super slow. This is why you end up with teams who are really big but can't deliver worth anything. Where compared to these tiny teams, who are just out delivering them and just spinning things out the door, they're the ones who aren't spending all their time going, "Are we certain this is going to deliver? And how many hours is this going to take you? And let me go talk to this person, find out how many days it's going to take him," and back and forth and back and forth. They're just building, and it goes faster.

Lenny (32:57):
I'd love to pull on that thread. I was thinking about the fact that you're building software for product teams and so you have a really unique perspective on product teams and you've seen a lot of product teams a lot more than a lot of other folks. And so I was curious what percentage of teams that you see are what you'd call like top notch, highly functional product teams?

Janna Bastow (33:18):
That's a good question. I don't think I've got an answer there because it's going to be biased, because we naturally attract companies who self-select our way of working. We put on our site, no timelines come for the now, next, later. So it's going to be a much higher percentage. People don't sign up for demos with us if they know that they want a timeline nowadays, because we make it really clear. So I would say like 70% of them are like we want now, next, later. And I know that's not real. I know that's not the real state of people, of product teams out there.

Lenny (33:48):
Cool. So yeah, that makes sense.

Janna Bastow (33:49):
I do have a sense that it's increasing. So what I have found is years ago when we first started this thing off, no one was talking this way. It was a whole new concept and people are like, "No, this is crazy doc, you can't do it this way." Then over the years it has just become the natural way that people are working on it. People are going, "Of course this is the way that it works. Why would it work any other way?" It's becoming the expected way. Definitely changed the discourse and changed the expectations of the audience, I guess.

Lenny (34:13):
Putting the now next later piece to the site for one moment. I'm curious what else have you seen separates the best product teams from mediocre product teams? In terms of how they execute, the people they hire, processes, is there anything else that you've noticed of just like this team, when I think of teams that are functioning super well? Other than implementing this process you're recommending, is there anything else that often comes up?

Janna Bastow (34:37):
Yeah, a couple things. A focus on discovery. So this ability to spend time in discovery and asking questions of customers and constantly being able to iterate based on that. And psychological safety, so teams who are able to question each other, speak up when they see that things are wrong, question what's going on at the senior level, question what's going on at different team levels, and generally just have the good sense of what's going on across their business because they're allowed to ask those questions, less silos.

Lenny (35:05):
Thanks. What's a lasting change that a team has made that made them significantly better at building product? Is it these two things, doing more discovery and maybe more safety? I imagine part of your answer will be implementing this way of working of now, next, later. Is there anything else that comes to mind? "Wow, wow, this one team did this one thing and it made things so much better for them."

Janna Bastow (35:24):
Like retrospectives. Retrospectives make such a big difference because they are indicative of psychological safety, which underpins so much, right? Once you start building in this psychological safety, the ability to ask questions and to start saying, "What are we doing that's working? What are we doing that's not working? Okay, determine that something doesn't work. Are we allowed to go change it? Okay, we are allowed to go change it." Okay, this is a team who's now changing their situation. They're talking to each other, they're learning from each other, and they're making a concerted effort to do so. And so these are the teams who are constantly learning, iterating, and moving forwards.

Janna Bastow (36:03):
And they naturally move towards things like now, next, later. They naturally move towards things like doing discovery, because these are just, I don't know, they're kind of common sense. They're not setting in stone expectations of what's going to be done and when. Because that was really only done because some head honcho wanted to see that information. That wasn't psychological safety. That was somebody pinning them down by the neck saying, "Tell me what's going to be done and when." Psychological safety is just saying, "Hey, tell me as much information as you know and then do discovery to learn as much as you can, so that we can move forward with this." It's all about just talking to your teammates and getting the most information as you can from the resources you have, making the most of the collective intelligence that you have within your company.

Lenny (36:46):
Coming back to the now, next, later approach, you're often doing something really hard at companies, which is changing their way of working and changing their product culture. And I'm curious what you've learned about what it takes to change product development culture and product culture and the way of working at larger companies.

Janna Bastow (37:04):
Larger companies are tough. They're tougher. I think of culture as calcification. So calcification being the limestone that is built up as watered run over and that sort of thing. And in order to fix it, you can kind of chip it off over time. You can't just fix it all in one go. And so in order to fix it, you've got to chip away at it. You've got to find a small pocket somewhere. You've got to make use of the tools that you've got. So sometimes it might be finding a small subset of the company and saying, 'Hey, here's the startup lab within the business. Let's let them run off and go do something." Because changing the mindset of the whole company is just too difficult. It's set in stone, and it's stuck where it is and can't change them all at once. But we can change this one little space right here, because we've got a shit hot leader who knows what they're doing and we can take this pocket of people and go do something here.

Janna Bastow (38:00):
And then they're going to teach the rest of the company. They're going to teach this section and then this section and then this section. You don't have to go and change the whole company all at once, but it does take buy-in from above. And sometimes that can be really difficult to take, because the incentives from above are often misaligned with the incentives that it takes to get a company moving this direction.

Janna Bastow (38:21):
Ultimately, a lot of these larger companies, they're incentivized to keep the company as stable as possible, to keep the company just growing quarter on quarter. Which is great for the stock market, they love that stability, they love that quarter on quarter growth. But if the company is actually under threat from startups, if you're a big bank, you're in health tech, something like that, you almost certainly have startups nipping at your heels. And the reality is that you probably have enough cash to make it for the next 20 years or so, but over time it's going to get bitten away at.

Janna Bastow (38:58):
And you've got smaller startups who are going to take the juicier, more interesting parts of your business and leave you with the tougher parts of your business. Take HSBC versus all the companies who are coming out with got a Starling account here and I've got a mortgage with somebody else and you've got your savings account somewhere else. You've got all these smaller startups nipping at their heels. These companies are going to nip away at these larger businesses and if these larger companies don't actually do something with it, they're actually going to end up losing this ability to innovate themselves. And so these companies are essentially stuck in this pattern where they want to continue growing and yet they're not going to, they're going to end up not being willing to take the dip to move upwards.

Lenny (39:42):
What's the biggest company that you've implemented this new way of building? And is that how you approached it, you found a team within the larger company to roll out this new-

Janna Bastow (39:53):
Yes.

Lenny (39:53):
... yeah, this framework?

Janna Bastow (39:54):
Yeah. So that's how it generally works with the way that we work with our enterprise rollouts is like we worked with large enterprises of governments as well. It generally starts with an advocate, somebody who gets the way that we're working, a division, a department, and then it starts from there. Sometimes what we'll find is that we'll get one or two, sometimes three or four many groups starting and then they'll start banding together and saying, "Hey, no, we're starting a thing here." Once that starts happening, it's easier to start that conversation saying, "Okay, yeah, we've got a whole thing going here. Let's talk to the person who is the VP of strategy, or who owns the tech area," and then we can have a bigger conversation.

Lenny (40:33):
What's the impact that you saw at that company having taken on this new way of building product?

Janna Bastow (40:39):
So we're in the middle of a key tool in the middle of transformations right now, which is fascinating to see. These are multi-year pieces of work where you're seeing it being used for ongoing products that are being used and delivered as we speak, as well as part of a mindset shift within the business. Because one of the things about ProdPad is that it's not just a tool to help you deliver your products, it's actually a tool that helps you become a better product manager. It sets in stone better product management practices. Once you start using it, it makes it difficult to go back to bad product management practices.

Janna Bastow (41:15):
When you create a roadmap in ProdPad, it makes difficult to add features and dates to the roadmap. It makes it difficult to make a timeline based roadmap. It makes it difficult to add ideas to the backlog that are not thought through, because it asks questions, thoughtful questions, like what problem does this solve? And why would you want to solve it? And what are the outcomes? And what did you get?So it makes it difficult to fall into a build trap with just saying, "Here's stuff to build," and we built it, and move on to the next thing, like a lot of dev tools are designed to do. Because it has spaces in there to say, "Did you measure success? And was it successful or not successful? This roadmap thing is completed, what was the outcome of it?" So by creating all these spaces, it creates all these reminders for the team to go back and think about this stuff before they do work and after they do work. So it actually actively helps them become better product teams and more cognizant of this sort of work.

Lenny (42:05):
If someone wanted to experiment with now, next, later, what would be a good place to go and just start to play around with it?

Janna Bastow (42:12):
I mean, you can start a free trial in ProdPad, you can start playing around with it. We even have a sandbox mode. You just go to sandbox.prodpad.com where it's got example versions of roadmaps, best practice roadmaps that you can just start playing with. You don't even need a login or a credit card. It's got OKRs and roadmaps and ideas and experiments, feedback. You see how it all sort of fits together. But honestly, a now, next, later roadmap can be done with Post-It Notes on the wall. It's just about saying, "What problems do you have? Let's lay them out in order and just check them with other people."

Janna Bastow (42:45):
So the whole point about a roadmap is that it's not designed to be your plan. I think about it as being a prototype for your strategy. What I mean by that is we talk about prototyping all the time in the lean world and a prototype is essentially a way of checking your assumptions. Generally, we think about it in terms of a design or like a model, but think about it at the strategy level. So at the feature level, you'd prototype by doing a design, a mockup, and you take that mockup and you'd share it with somebody, and say, "Here's a mockup of the feature that I'm trying to build. What do you think?" And they tell you what's right or wrong, and you'd add some new copy or a button to make it more clear, and you throw out the original prototype, because it wasn't very good and you make a new one.

Janna Bastow (43:27):
So the value isn't the prototype, the value is in the prototyping process. The value isn't in your roadmap, The value is in the roadmapping process. What you're actually doing is laying out your assumptions of the problems that you're solving. So you're saying, "I think we have this problem then this problem. What do you think?" The whole point is that you just share your early assumptions with other people on the team, with customers, even, like anybody, who will listen. And just check that you're on the right path. And if they say, "Oh, actually I thought that it was going to go this way, this way, then this way, or that way, then the other way, and what about this problem?" You've actually learned something. You can adjust your prototype for your strategy, you can adjust your roadmap there and your roadmap all of a sudden becomes stronger, becomes better there.

Lenny (44:11):
For folks that are listening and they're just like, "Nah, this is never going to work where I work. It's just too out there, too radical. No deadlines, that's crazy." I know you're not saying no deadlines, but less deadlines. What are the most powerful three bullet points you could share with listeners that are just like, :Here's why you should have confidence this might actually work at your company."

Janna Bastow (44:32):
Other teams are already working this way. Product people are the only ones who seem to be pinned down to be required to give concrete dates as to when things are going to be delivered in this way. Your sales team isn't asked to give exact delivery dates on their work. They work in a very experimentation led way as well. You are VP sales or VP revenue or whoever doesn't go to a board meeting and say, "We're going to close the Acme deal at the end of October for a million pounds." They don't know that. What they do know is that they have a process by which they're going to fill a pipeline, and almost certainly they're going to be able to close a million pounds or a million dollars worth of sales, but they can't tell you who it's going to come from or how that's going to work.

Janna Bastow (45:19):
What they're going to say is, "Give me a quarter million dollars worth of investment into my team, which I'm going to spend that on my account executives, my sales team. They're going to pick up the phone and do a bunch of calls." Think of these calls as experiments. These calls, some of them are going to work, some of them are going to fail. They don't know which ones are going to work and which ones are going to fail. What they do know is that by using a script and by picking up the phone and calling people, some are going to work. And by the end of the quarter someone's going to buy. And they know this because last quarter someone bought and the quarter before that someone bought, they just don't know who's going to buy. If they did know who's going to buy, then they would just call those people and not everybody else.

Janna Bastow (45:59):
Same thing. You're not asking for any more leeway than your sales team. You're saying that you want a quarter million dollars worth of investment, and you're going to spend it on your team who's going to run experiments, right? It's going to be trying this change on the interface or that tweak to the pricing or that change to the positioning or whatever you're going to do. Some of these experiments are going to fail and some are going to succeed. You don't know which ones. But that's okay, you know that by the end of the quarter, enough are going to succeed that you're probably going to move the right numbers in the right direction.

Janna Bastow (46:30):
So you're not asking for any more leeway than your salesperson. What you should be able to do is point at how many experiments you ran the previous quarter, and what numbers moved in the right direction. You should be accountable for your experiments and how you're spending the money and what you're doing. But you shouldn't be accountable for saying what is going to work before you know what's going to work yet. And that's the problem with this timeline delivery, Magic 8 Ball that we're asked to give.

Lenny (46:58):
I like that. Two last questions before we get to a very exciting lightning round, which I didn't tell you about. We'll see how that goes. So one is you have an interesting framework for coming up with a product vision, and I don't know if you have this in your head loaded up, but I'm curious how you think about coming up with a product vision. You have this really handy little framework, and vision is always this thing that people are like, "Man, how do I come up with a vision? How do I phrase a vision? How do I even visualize my team's mission?" Can you share that with us, if you have that in your head?

Janna Bastow (47:30):
The product vision template, you might actually recognize it from the Geoffrey Moore's Crossing the Chasm book. It's the elevator pitch template. But I like it because it answers the same sort of questions that you need to answer for a product vision template. So it asks things like, for your target customer, who the statement of need or the opportunity. The product name is a product category. What's the reason to buy? And then say, unlike this alternative our product, and then say what this statement of differentiation is. So it's actually a template that we have available on our site, and you can actually fill out as part of our product canvas in ProdPad. So happy to share that link with you, so you can link it up and send it to your audience here, Lenny.

Lenny (48:17):
Cool. Yeah, we'll put that in the show notes. I think that's the same framework as the positioning exercise. I might be wrong, but if so, that's cool. So basically you could use your positioning work to help figure out your vision. And just like a vision, it's basically a vision statement, it's not necessarily the vision for your product, it's just kind of how you think about where it's going to go.

Janna Bastow (48:35):
Yeah.

Lenny (48:36):
Okay, cool. The last question, you were a PM now you're founder, so you moved from PM to founder, and a lot of PMs, imagine being founders someday. I'm curious if you have any advice for folks that are currently PMs that may want to be founders in the future. What do you think they should be working on, focusing on, skills, vision rebuilding, things they should be doing to help them in that future career?

Janna Bastow (48:58):
Being a PM actually provides you with a lot of the skills and background to be a founder, to be a CEO. It gives you a lot of chance to work with a lot of the different teams and see a lot of the underpinnings of how business works. I was really lucky in previous roles where I got to work very closely with leadership in a few different roles before I took the step up to take on my own thing. So I felt as if I'd seen it in a few different ways, done well and done badly, and so I got a chance to sort of say, "Ah, I think I could do this. Yeah, go on."

Janna Bastow (49:32):
One of the things that struck me is it's not as hard as it looks, and it's also harder than it looks. There's things that you get started and you go, oh, no one's going to stop you from doing this. You've got lots of leeway. You can just do it, and you've got lots of freedom to run your business how you want to do it. There's lots of resource out there. As long as you surround yourself with people, you're always going to be able to find people to advise you and to help you along the way. And there's always going to be bumps. You don't know what they're going to be yet. There's always going to be things that are going to come by and side swipe you, but that's always the case that you had when you are product manager as well.

Janna Bastow (50:11):
And just be ready for those and be ready to take it on the chin and deal with them as they come. Best thing you can do is surround yourself with people so that you've got somebody to go to for each thing. Going, "Oh, when I run into a problem that has to do with this, I can talk to this person. When I run into a problem that has to do with this, I talked to one of these people." And figure it out as you go. Take each thing a day at time. Certainly, don't stop yourself from starting a business or starting your own thing, just because you don't think that you know how to do it yet. You will figure it out as you go ahead. People less capable than you have figured it out.

Lenny (50:46):
Awesome. Okay. We've reached our lightning round. The way it's going to work, I'm going to ask you five questions real quick. Whatever comes to mind, share an answer.

Janna Bastow (50:55):
Cool.

Lenny (50:56):
If nothing comes to mind, that's also cool. Sound good?

Janna Bastow (50:58):
Mm-hmm.

Lenny (50:59):
What are two or three books that you've most recommended to other people, whether they're product leaders or just generally?

Janna Bastow (51:06):
Art of Profitability, I thought was a really good one.

Lenny (51:09):
What's a favorite recent movie or a TV show that you've watched?

Janna Bastow (51:13):
Oh, Sandman.

Lenny (51:14):
Ooh, and that's-

Janna Bastow (51:16):
Sandman is-

Lenny (51:16):
... like a British show, right?

Janna Bastow (51:17):
Oh, it is British. Yes, by Neil Gaiman. Yeah, very good. Definitely, not for children. Thought it might be, definitely not.

Lenny (51:25):
Noted. What's another favorite podcast of yours other than the one you're currently on?

Janna Bastow (51:31):
Ooh, Startups For the Rest Of Us.

Lenny (51:33):
Wow, I haven't heard of that one. Tell us more.

Janna Bastow (51:36):
Basically, it's Rob Walling's podcast and it's for startups that are either bootstrapped or alt funded. Basically, the startups that aren't the one percent top end funded, unicorns, but the startups for the rest of us.

Lenny (51:52):
Awesome. What's a favorite interview question of yours that you like to ask?

Janna Bastow (51:57):
I like asking people what problems that they're looking to solve. Why are they coming to this table?

Lenny (52:03):
Very PMy question.

Janna Bastow (52:05):
Yes.

Lenny (52:05):
Who else in the industry do you most respect as a thought leader? Who comes to mind?

Janna Bastow (52:10):
I've got to give a shout out to Christina Wodtke. I had a great conversation with her yesterday, and I've had a chance to chat with her a number of times over the years, but she's just got this illustrious career. She's been part of so many amazing teams, built some amazing things, written some amazing books, and is also just an all round amazing product person and amazing person all in one.

Lenny (52:32):
Janna, this has been amazing. I think we covered a lot of different topics, more than we often cover in a podcast like this. Two final questions, where can folks find you online if they'd like to reach out and learn more? And how can listeners be useful to you?

Janna Bastow (52:45):
Wonderful. Hi, I'm Janna Bastow. You can find me all on Twitter, I'm simplybastow there. Or come find me on LinkedIn, connect with me, I'm Janna Bastow. I'm easy to find there. And come check out ProdPad. It'd be wonderful to get your feedback on it, because we are a team of product people and we love hearing what other product people think of the product. We're always open to feedback. We're constantly pushing new releases. So check it out, try the sandbox. We'd love to hear from you.

Lenny (53:11):
Amazing. Thank you for being here, Janna.

Janna Bastow (53:13):
Of course, thanks so much.

Lenny (53:16):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcast, Spotify, or your favorite podcast app. Also, please consider giving us a rating or a leaving review, as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## How to get press for your product | Jason Feifer (editor in chief of Entrepreneur magazine)
**Guest:** Jason Feifer  
**Published:** 2023-10-12  
**YouTube:** https://www.youtube.com/watch?v=LZLdoAq3R7Y  
**Tags:** growth, retention, activation, metrics, experimentation, data-driven, conversion, subscription, hiring, leadership  

# How to get press for your product | Jason Feifer (editor in chief of Entrepreneur magazine)

## Transcript

Jason Feifer (00:00:00):
The editor, the writer, I'll just say it as plainly as possible. They don't care about you. They don't care about you. They care about their reader or their listener or their viewer. That's who they care about. That's who they're serving, and if you can be of use to them in sharing the kinds of information that they are looking to serve their audience, then you can get what you want. But you can't treat them like a service provider because they're not. And so you have to approach them with an understanding of what they're trying to do for their audience and how you can fit into that because if you don't, they are not interested in you.

Lenny (00:00:47):
Today, my guest is Jason Feifer. Jason is editor in chief at Entrepreneur Magazine, previously an editor at Fast Company and a number of other magazines. He's also an author, podcast host, keynote speaker, and startup advisor. In our conversation, we get incredibly tactical about how to get press for your product. Jason shares how to pitch a journalist, how to find the right journalist to pitch, what publications to consider, why freelance writers are more likely to write about your story, why the mission of the publication is so important in how you pitch them, plus what channels to use to reach out to journalists, how to think about your goals and what success looks like from getting press, so much more.

(00:01:25):
I learned a ton from this conversation, and if you're looking to get press for your stuff, you'll find so much value here. With that, I bring you Jason Feifer after a short word from our sponsors. This episode is brought to you by Sidebar. Are you looking to land your next big career move or start your own thing? One of the most effective ways to create a big leap in your career, and something that worked really well for me a few years ago, is to create a personal board of directors, a trusted peer group where you can discuss challenges you're having, get career advice, and just kind of gut check how you're thinking about your work, your career, and your life. This has been a big trajectory changer for me, but it's hard to build this trusted group.

(00:02:05):
With Sidebar, senior leaders are matched with highly vetted, private, supportive peer groups to lean on for unbiased opinions, diverse perspectives, and raw feedback. Everyone has their own zone of genius, so together, we're better prepared to navigate professional pitfalls, leading to more responsibility, faster promotions, and bigger impact. Guided by world-class programming and facilitation, Sidebar enables you to get focused tactical feedback at every step of your journey. If you're a listener of this podcast, you're likely already driven and committed to growth. A Sidebar personal board of directors is the missing piece to catalyze that journey. Why spend a decade finding your people when you can meet them at Sidebar today?

(00:02:46):
Jump the growing wait list of thousands of leaders from top tech companies by visiting sidebar.com/lenny to learn more. That's sidebar.com/lenny. This episode is brought to you by Maui Nui Venison, a mission-based food company, bringing the healthiest red meat on the planet directly to your door. I actually joined Maui Nui Venison earlier this year after hearing their app on the Tim Ferriss Podcast, and I'm excited to be spreading the message further. Not only does this company provide the most nutrient-dense and protein-dense red meat available, their operation produces the only stress-free 100% wild harvested red meat on the market that is the only one of its kind in the world, actively managing Maui's invasive access, deer populations, helping to restore balanced, vulnerable ecosystems, food systems and communities in Hawaii.

(00:03:33):
Also, it is seriously delicious. Not at all [inaudible 00:03:37] and easy to cook. My wife and I made stew and steaks and all kinds of grilled goodies with the meat. We also feel great about it as a protein from an ethical standpoint. I highly recommend trying their all-natural Venison jerky sticks for an optimal protein snack, as well as a wide variety of fresh cuts, all available in their online butcher shop. There are limited memberships available, but you can sign up and get 20% off your first order at mauinuivenison. com/lenny. That's mauinuivenison.com/lenny. Jason, thank you so much for being here, and welcome to the podcast.

Jason Feifer (00:04:13):
Lenny. Thanks for having me.

Lenny (00:04:14):
It's absolutely my pleasure. We've actually collaborated on a couple of things recently, and as we were chatting about some stuff, I was asking for advice on how to help a startup I'm working with get press, and you shared a bunch of killer advice, and so I asked if you could just come on this podcast and share similar advice for how to help startups get press and here we are.

Jason Feifer (00:04:36):
Yeah, I'm really happy that you asked me to do that. This is something people ask me about a lot. I've been in media for decades. I've worked at a lot of different magazines. Obviously, I run Entrepreneur Magazine now, but I was a Fast Company. I was at Men's Health, so I've seen a lot of different sides of media, and it is a very misunderstood tool, particularly for people in business, and so I love demystifying it.

Lenny (00:05:00):
Amazing. I'm excited to learn all this too, and so thanks for doing this.

Jason Feifer (00:05:04):
Yeah.

Lenny (00:05:04):
First question is just, as someone in press, how much volume is there coming at you from startup founders and PR people trying to get you to write about them and also just reporters that you work with?

Jason Feifer (00:05:15):
Yeah, it's tremendous. It's ridiculous. I would say that by the time we are done recording this podcast, I'll have, I don't know. I mean, it could be anywhere from 30 to 50 pitches in my inbox. It comes all day. Now, to be clear, most of that is garbage in the real garbagey sense, right.

(00:05:36):
It's a lot of completely unrelevant press releases that were sent to me and a bazillion other people. But within, there are definitely some people who have spent the time to reach out very specifically to me, and everybody in media gets some kind of volume like that. To reach out to somebody in media is to be shouting over a lot of noise.

Lenny (00:06:01):
Wow. I imagine we'll get to this later, but I'm curious just what percentage of those are PR people and press release versus a founder or someone that is doing it themselves?

Jason Feifer (00:06:12):
The percentage of direct messages from founders that I'm getting is low. I would say probably 20, 25%. And then the 75% is PR in some capacity, either targeted PR where somebody's intentionally reaching out to me or mass blast press releases.

Lenny (00:06:30):
You know what's crazy is I've been getting a lot of these now. People think I'm some kind of journalist, and they're just like embargoed announcement product launch.

Jason Feifer (00:06:37):
It doesn't take much because you just end up on some list, and what's really interesting, and we'll talk about PR later, I know. But one of the great insights that you can get into the challenges of that industry is how completely automated a lot of it is where a lot of people in PR are not thinking specifically about how to tell the right story to the right potential media outlet. Instead, what they're doing is they're just playing a numbers game, and they're just blasting it out to everybody.

(00:07:13):
And that means that you could end up... I write this newsletter, right. I have... Entrepreneur Magazine is the thing that people obviously would pitch, but then I have this newsletter where I don't interview anybody. There's no opportunity to be featured in my newsletter, and I still get pitches to the newsletter because somebody saw it and dropped it in some spreadsheet, and it just... now I get it. And I think that's a real disservice to entrepreneurs who are paying for people to do that, and I really hate that.

Lenny (00:07:41):
Yeah. Okay, so we're going to get into the meat of just how to actually do this well, but a couple more questions just to set a little context. One is in terms of impact. What kind of impact have you seen from getting press for a startup in terms of growth for their product specifically?

Jason Feifer (00:07:57):
So it's a really wide range. I have had entrepreneurs tell me that a single story in Entrepreneur Magazine, like the print magazine or just online, will drive more, whatever more app downloads, more sales that month than any of their paid marketing efforts.

(00:08:16):
But then I have also heard entrepreneurs tell me that it didn't do anything for them or that it did one very specific thing for them, which is to say maybe some potential partner read it and reached out, and it started an interesting conversation. It's all over the gamut, and it's a really important thing for people to remember is that this is not something that I think that you should bank on as a strategy for growth. It's a great add-on. But if you think that press by itself is going to solve your problems, you're wrong because it might, but it's way too unpredictable.

Lenny (00:08:48):
Is there anything else along those lines of just when it's worth somebody investing time into getting press, either stage of startup, type of startup, any just general broad advice of you should not be spending time on trying to get press versus this is a really good opportunity for you.

Jason Feifer (00:09:02):
Think about press the same way that you think about raising money, which is to say you do it when you know what the money is for, and you should do it when you know what the press is for. A lot of people reach out to me at such an early stage that if we wrote about them, it wouldn't get them anything. They're not at a stage where they could use that press in any meaningful way, and so there's really no purpose in chasing it now. You should step back and think really as a starting point, "What do I need press for?" And if you have a good tactical answer to that, that could be because I need to drive awareness to a new product. That could be because I'm going out to raise money, and I need articles to show that the marketplace takes me seriously.

(00:09:55):
These are good reasons, but I get a lot of emails. It's funny because people are... like entrepreneurs, in particular, they're just so vulnerable, and it's kind of a wonderful way sometimes. And sometimes people will just email me, and they'll just say, "You know, I've worked really hard, and I just feel like I deserve this." I respect that, and I relate to it in some ways with my own trying to get attention for my own work. But, "I deserve this" that's not a good tactical decision for your business that doesn't do anything for you. And so I would put that to the side and only think of press as you don't go out and raise money if you don't know what the money is for. You shouldn't go out and try to get press if you don't know what the press is for.

Lenny (00:10:38):
I'm curious to hear other examples when it's not, when it's a bad idea because, as like I said, an outside observer, I would always love to get more attention for my product and more people to be aware of it, more people to check it out. Is there an example or anything that comes to mind of there's no need for you to do that in this moment or for this product?

Jason Feifer (00:10:55):
Oftentimes, it's not even about the moment, but it's about the publication. So I'll give you an example. I spoke at an event once, and afterwards, this guy comes up to me, and he has a small hot dog food truck business in Washington, DC. So he said he's got a couple trucks, and he's doing good business selling hot dogs, and he wants coverage in Entrepreneur Magazine. He's like, "Oh, how can I get a feature?" And the problem with that instinct that he has is that he's really directing his energy in the wrong place because if he is selling hot dogs in Washington, DC, then I understand what press is for him. Press is to drive hotdog sales. That's what he wants to do. Entrepreneur is not going to do that for him. Full stop. Why? Because Entrepreneur reaches a national to international audience.

(00:11:52):
So that means that 99.5% of the people who would read a story about this guy have no ability to go get his hotdogs, which means that that was wasted effort. So fine. Was it that hard to come up and talk to me at the conference? No. But scale that out. How many emails is he sending that are like that? How much energy is he putting into chasing things that ultimately don't have good direct value to him? What he needs to do is think, "Okay, my goal, get more people to buy hot dogs. Where am I? I'm in Washington, DC. How can I reach people who are interested in food in my market?" So stop chasing Entrepreneur and start chasing the local eater or the food section of the Washingtonian or something like that. That small shift can give you a lot more payoff for your effort.

Lenny (00:12:38):
This is a good segue to just let's just dive into how to actually go about getting press, and I know you-

Jason Feifer (00:12:38):
Yeah.

Lenny (00:12:42):
... kind of have this three-step structure for thinking about it. Maybe just start with what are the three steps, and then we'll dive into each one.

Jason Feifer (00:12:50):
Yeah, sure. So I mean, look, it is pretty simple, right. Step one is prep. You want to be thinking about how to tell your story. You want to be thinking about the kinds of stuff I just talked about. What is press for for you? Everything that you need to do to orient yourself towards what is this opportunity, and why am I chasing it, and how to make the most of it. Step two is figuring out who to pitch. Not all press is created equal. There are not reasons to just go chasing everybody arbitrarily. The hotdog example is a good one.

(00:13:19):
So finding the writers and editors who you're actually going to reach out to, who are going to most receptive to you. And also making sure that because you did the prep, you can figure out how to tell your story in a way that they're going to be interested in. We'll talk about that. And then step three is the actual pitch. What does it mean to reach out to these people, to engage the writers and editors? How do you find them? What do you send them? What are you telling them? That's it.

(00:13:42):
I mean, right. But what you need to understand is that you're entering a world that probably doesn't operate the way in which you think it does, and I see that all the time as the recipient of pitches. People don't understand who they're reaching out to and how I and my colleagues think. We should maybe even start with that because a really important thing to understand just again, to go to [inaudible 00:14:07]-

Lenny (00:14:07):
[inaudible 00:14:07] do it. Yeah.

Jason Feifer (00:14:08):
... yeah, the metaphor of the investors, you don't reach out to an investor if you don't understand what that investor does, what they're interested in, or what kinds of companies they invest in. You can't do that with media, either. So I get pitches every single day along the lines of, "How do I get coverage in Entrepreneur Magazine? How do I get a feature in Entrepreneur Magazine?" And to me, it always feels like they're ordering a hamburger from me. Like, "How do I get a hamburger from Entrepreneur Hamburgers, right?" They're treating me like a service provider. That my job is to provide press.

(00:14:44):
And I get it because, of course, if you're an entrepreneur, and you're looking for press, then the... [inaudible 00:14:51] writers and editors out there seem to be in the business of writing about people, and therefore, there's some service that they seem to provide, and you're trying to figure out how to get it. But that's not how the media thinks of themselves, right. The editor, the writer, I'll just say it as plainly as possible, they don't care about you. They don't care about you. They care about their reader, or their listener, or their viewer.

(00:15:18):
That's who they care about. That's who they're serving. And if you can be of use to them in sharing the kinds of information that they are looking to serve their audience, then you can get what you want, but you can't treat them like a service provider because they're not. And so you have to approach them with an understanding of what they're trying to do for their audience and how you can fit into that. Because if you don't, they are not interested in you.

Lenny (00:15:49):
I love that. And more... even specifically, what is it they're trying to do for their audience? I imagine it's just have something interesting that they want to read. Something they can learn. Something they're like, "Wow, I'm really excited to read this."

Jason Feifer (00:16:00):
Yeah. But it's going to be more specific based on the mission of each publication. So, for example, I've worked at two separate business titles. I was a senior editor at Fast Company for a number of years, and now I'm the editor-in-chief of Entrepreneur Magazine. The decision that is made about whether or not a story belongs in a publication, it was totally different based on these two publications. So I can't speak to Fast Company now because they've gone through a couple of leadership changes. I don't know what their mission is, but back when I worked there under Bob Safian, he was the editor-in-chief, that was really a magazine about where businesses going, and the stories that were in the magazine were all supposed to be in some way representative of the evolution of business.

(00:16:50):
And so when people would pitch what we'd really be looking for are, are there insights into... in what this person is doing that other people could read and say, "Aha, that helps me understand where this industry is going or that industry, or it helps me think about how I can shape my own company to match current trends," that kind of stuff. Entrepreneur, totally different mission. The way that I think of Entrepreneur is that it's not even a magazine about business. It's a magazine about thinking. Or what I want to do is make sure that everybody who comes to the magazine walks away with great insights into how to think through the challenges in their business.

(00:17:29):
And so what I'm looking for when somebody reaches out is did they make some interesting counterintuitive decision that solved a problem in their business, and I'll emphasize in. Because, oftentimes, when people hear me talk about solving problems in business, they think, "Aha, but I solve a problem in business, right. I saw that there weren't the best razors in the world, and I made the best razors." That's not what I'm talking about. What I'm talking about is... There's this woman whose name is Joelle Mertzel. She has a company called Kitchen Concepts Unlimited, and she makes a butter dish, and it's a really smart butter dish because it is built on a hinge, right. So this is designed to solve a very specific problem, which Lenny, I don't know if you knew this, I did not, that you don't need to refrigerate butter. Did you know that?

Lenny (00:18:18):
I knew that intellectually, but I still refrigerate it. I know people don't.

Jason Feifer (00:18:22):
Me too, even though I've had multiple conversations with this woman about this. You don't need to refrigerate butter, and if you leave it out, it cuts easier. It's more spreadable. Big problem, the butter dish. So most butter dishes you just lift up. And so if you have warm room temperature butter that's soft, and you lift the butter dish top up, you might bump into the butter, and it's going to make a big mess. So Joelle makes a butter dish on a hinge, right. Opens and closes exactly the same way every single time. No mess. Brilliant, solves a problem. She reaches out to me about this. This is not interesting to us, right. Maybe this is interesting for a cooking magazine, right. Maybe Bon Apptit is interested in this. Entrepreneur's not interested in this because that doesn't help other entrepreneurs to have thought through that problem.

(00:19:13):
But then she tells me something else. What she tells me is that she is, at the very beginning of this, trying to figure out how to answer some basic questions about her audience, like what colors do they want in this butter dish and what price point are they willing to pay? And she wants to do some market research. She goes to a market research company. She says, "How much would it cost to research consumers and answer these questions?" They say, $10,000. She doesn't have $10,000. And then, one day, she's sitting at the airport waiting to board a flight, and she looks around and she realizes that airports are full of people who have absolutely nothing better to do than answer questions about butter dishes, right. Nothing better to do, just sitting there. And you could start at gate one. By the time you get to gate eight, everyone in gate one is new. You could do it all over again, and you could have a 6:00 PM flight, and you could show up at 9:00 AM. Nobody's going to stop you. You can do this all day in the airport. And this is how she starts to do her own market research. She saves that $10,000, and she does it herself. I put that story in the magazine. It's tiny. It's this tiny random company and this random decision. But the reason I did it is because every time I repeat that story to entrepreneurs, they're all like, "Ugh, right, totally. There's always other ways to do things." They love the ingenuity of it. That's what I'm looking for. That's Entrepreneur's stories. So to go back to the point that you were making, it's not just about, "Well, it's a magazine called Entrepreneur. They must write about entrepreneurs, right. I'm an entrepreneur. I belong in Entrepreneur."

(00:20:41):
People think that all the time. No. You have to step back and read what these publications are publishing and ask yourself, "What are they doing? What is the purpose here?" The editors and the writers, they're making decisions about what goes in this magazine, and they're making decisions about how the stories are constructed. Why are they doing that? Who are they trying to reach? When you start to see it through that lens, you start to see the pattern, and you get an understanding a real instruction manual for what it actually means to pitch these publications.

Lenny (00:21:13):
That is such an interesting insight. I had no idea that that was something you should be thinking about. Is there an easy way to understand the mission of the publication? Is there an about page they often add this to or is it, like you said, you just read a bunch of stuff and try to suss it out?

Jason Feifer (00:21:28):
Nobody publishes an about page in that way because the internal logic of the editorial team. But you can certainly make some starting assumptions based on who the publication is trying to reach. Everybody is trying to reach somebody. It gets more complicated the more general interest something becomes, right. What is the New York Times?

(00:21:53):
What is the mission? That's a hard thing to answer. You sort of have to divide it up into sections, right. The mission of the National News Desk is different from the mission of the Business Desk, and even within there, the mission of the Sunday business section is different from the mission of the Monday to Saturday business section.

Lenny (00:22:09):
[inaudible 00:22:09].

Jason Feifer (00:22:09):
So you have to start to really parse it out. And this is the reason why people hire PR is because if they're good at their jobs, they understand a lot of this already. But I really do think that if you spent time with the content and your starting point is, "I understand that this publication is trying to reach X. They're trying to reach these people," then you can start to see the patterns of what it is that they're doing. How are they telling stories? What do these five stories all have in common? They have something in common. There's something that they're all doing, and you can certainly read the tea leaves and try to figure it out.

Lenny (00:22:48):
Awesome. Okay. It feels like we've already gone into step one around prep. What else is involved in preparing to get press?

Jason Feifer (00:22:57):
If we're talking about prep, the very first thing that you need to do is what I had said earlier, which is just ask yourself, what do I need press for? And you need a good answer to that question. And once you have that, the next thing you should do is you should start to think about, "Well, what's interesting about my business? And oftentimes, it's not necessarily what you think, and you can be guided in a way by what's happening in step two, where you start to think about who you're trying to reach out to. Because, for example, the story that somebody might tell me at Entrepreneur is going to be different than the story that somebody might tell Cosmo.

(00:23:42):
There's a reason for a company to end up in, both Entrepreneur and Cosmo, right. Maybe the product is for young women. And so, Cosmo might be interested in some kind of product feature or including the product in a roundup of some kind of products. Whereas Entrepreneur would do the entrepreneur-focused story. What did this founder do? How they do they write? You can take your... You could think about your story and kind of break it up into a whole bunch of different little pieces and then figure out which piece goes to what media. But oftentimes, people make the mistake of trying to do that in reverse, which is to say that they kind of decide what narrative they would like to have out in the world, and then they just go around to different publications trying to sell them on that. I get that all the time.

(00:24:34):
A lot of my pitches that I'll receive in my inbox are somebody who hasn't really thought at all about what Entrepreneur publishes but instead just has something that they would like to get out into the world. I mean, a good kind of dumb example is, yesterday, somebody sent me an email about a company that had just hired a new president. I don't care about that. That's not useful to my audience at all. I'm sure that there is a trade publication, right. Let's say that there was a company in the restaurant industry. I'm sure that a trade publication that follows the blow by blow by blow of a restaurant industry might be interested in your new president. But I'm not because you hiring that new president isn't useful to my audience. Stories in Entrepreneur are not really about the person that I'm writing about.

(00:25:23):
They're really about the audience. They're really me serving the audience through the stories of the people I'm writing about. That's not useful. I wish that they had spent a moment and thought about that, but they didn't. So once you start to think about who it is that you're trying to reach, you can step back and say, "Well, what part of my journey is going to be most relevant to them? And I would push you to be really, really creative about it. Because if you go back to the Butterie example, the butter dish, that little funny story about the airport, I mean, who else is writing about that? It's not central to her story as a brand. It's not central to her sales pitch. It was-

Jason Feifer (00:26:00):
... central to her story as a brand, it's not central to her sales pitch. It was just for us. We were probably the only publication in the world who cared about that, but I really cared about it.

Lenny (00:26:11):
Amazing. Okay, so just kind of summarizing what you shared, think about the goal. What are you trying to get out of press? Goals could be awareness of what we've done, something new, investor interest. What are some other common examples of goals that you see for trying to get press?

Jason Feifer (00:26:27):
Yeah, awareness of something new. But also doesn't have to be awareness of something new, it could just be continued growth, trying to reach into a new marketplace. That's fine. Anything that's tied to growth or reaching a new customer base-

Lenny (00:26:45):
Cool.

Jason Feifer (00:26:45):
... would make sense.

Lenny (00:26:45):
That makes sense.

Jason Feifer (00:26:47):
But it could also be that you're looking to position yourself in your own marketplace a little differently. I see, for example, a lot of people, a lot of big companies, keep knocking on my door because we don't just hear from startups, we hear from major companies as well who are pitching stories. I know why they want to be an entrepreneur. They want to be an entrepreneur because they're trying to position their brand as also being relevant to small business owners. It's helpful to have that kind of context because coverage an entrepreneur can help them go out to the marketplace and say, "Look, we're also reaching X, Y, Z people."

(00:27:25):
So sometimes it's not even about a conversion, but rather it's about a positioning and that's a good reason to also maybe put forward your executives. Sometimes it's just about establishing your CEO or your founder as an authority in a particular area because you want them to be more trustworthy, you want them to be invited to more conferences. Because all of that stuff draws more attention to the company, all sorts of reasons to do this stuff. And then trying to get in front of investors, trying to get in front of partners. Look, there's a million reasons why being visible can be useful, but you need to make sure you understand what you're actually trying to do.

Lenny (00:28:07):
Okay, awesome. That was really helpful. So think about what goal you have in mind for getting press, pick a publication and understand their mission and what their goals are. And then think about some interesting stories that you could pitch them. Not just like we have a new president, but something that you think they'd be excited to share that connects with their mission.

Jason Feifer (00:28:25):
That's right.

Lenny (00:28:26):
Kind of on this topic, I know we want to talk about who to contact and how to figure out who to actually talk to. A couple of questions that come to mind. This is all a lot of work. Founders are really busy.

Jason Feifer (00:28:35):
Yeah, it's a lot.

Lenny (00:28:35):
So begs the question, PR agencies, do you have a perspective on would you recommend working with PR agency? Is there a time when it makes to and doesn't make sense to?

Jason Feifer (00:28:45):
Yeah, I mean it's a ton of work. Everything that I'm describing is a ton of work. And let me be clear, people succeed in getting press without doing any of the things that I'm describing because dumb luck happens in the world. You could very well just bang out an email to some random editor and they might like it. That is entirely possible. You could disregard everything that I've just said. What I'm really helping you do is try to optimize your approach. But yeah, hiring PR can cut out a lot of this. Now you're not doing this research yourself, you're not thinking through these challenges yourself. You're working with people who understand exactly how to identify the most interesting parts of your story and then turn them into good pitches. So why wouldn't everyone do that? The couple reasons. Number one, cost PR can be expensive, so you just have to factor that in. Number two, PR is and can be, I'll say can be, a very frustrating journey because a lot of PR people are very bad at their jobs. They're very bad.

(00:29:52):
And this isn't just me bashing PR people. I have literally been hired to give keynotes at PR industry conferences. And I get on stage and I say most PR people are bad at their jobs and everybody nods. And they all know it. And of course, none of them think that they're one of the bad ones, but they all know it. PR is full of people who are bad at their jobs. Why are they bad at their jobs? They're bad at their jobs because they're lazy, because they're primarily relying upon email blasts, just sending things out, because they have a older idea of what it means to get the word out. For example, if you hire or talk to a PR agency and one of the things that they recommend doing that you should spend money on is a press release, like a traditional press release, run as fast as you can away from that. I don't know if you know this. Do you know this? The press release, there are some purposeful reasons to put out a press release, but the press release is really no longer the primary unit of press attraction.

Lenny (00:31:07):
Yeah, I get that sense.

Jason Feifer (00:31:08):
Yeah. But here's what's fascinating. So a PR agency I wouldn't recommend might do this. They'll tell you, "We're going to put together a press release about this new thing, so you have to pay a little extra money for the production of this press release and then also the distribution of this press release because what we're going to do is we're going to put it out on the wire," because there are a whole bunch of press release distribution wires. So they'll do that, you'll pay the money, it'll go out on the wire. And then they'll send you a report about all the places that this press release ended up on. It ended up on Yahoo Finance, it ended up on Market Watch. And it technically did. The press release is there, it was posted. And zero people are going to see it in the whole world because Yahoo Finance has a section where they just publish every damn press release that gets published by all these different distributors. Nobody saw that.

(00:32:08):
So don't confuse posting press releases even on very big websites with actual success. What you want in an actual PR person is someone who traffics in one thing, and that is relationships. The most important thing that a PR person can have is active relationships with people in media. Why? If a PR person is guaranteeing you press, that's another reason to run out the door as fast as possible because the PR people cannot control this. Writers and editors, they do what they want. It's a completely subjective industry and very frustrating. I completely understand. That was totally subjective. So the best that a PR person can do is shape your story, understand who to pitch, and then get that writer or editor to look at it, to pay attention to it. There are some PR people in this world who I think very highly of. I think they're incredibly smart, incredibly good at what they do, and they only pitch me when they have something that they think I will genuinely be interested in. Instead of a lot of PR people who just send me some random thing every week or every day.

(00:33:21):
I don't pay attention to those people. But, I don't know, just shout out, when John Beer from Jack Taylor PR sends me ... John, I met him in a PR capacity a decade ago and we've since become friends. When he emails me, I pay attention. I don't write about it all the time. I'm not going to write about something just because I like John, but I will pay attention. And paying attention honestly is half the battle because people in media are getting so much email. So you want someone who's going to understand you, understand your industry, understand and know the people who they should be reaching out to, and who really respect you as an entrepreneur and are going to give you the hard feedback. Because there are a lot of people who will go and hire PR and they'll say, "I want you to email this and this and this and this and this publication."

(00:34:16):
And if the PR person just does that, all they're doing is annoying their contacts if they don't really feel like this was meaningful. You should like when a PR person pushes back on you and says, "You know what? I don't think that your story is right for that publication. Here's why." That's someone you should hire.

Lenny (00:34:34):
Is there any other PR people you want to call out as ones that you think are awesome?

Jason Feifer (00:34:38):
The challenge here is that I'm going to regret not including a whole bunch of people who don't pop to mind immediately, but-

Lenny (00:34:44):
We can include them in the show notes, whoever else.

Jason Feifer (00:34:45):
Yeah, sure. Okay, so let's see. Off the top of my head, so John of Jack Taylor, he does a lot of wellness stuff. So PR agencies tend to specialize, and so you want to make sure that you're going with people who really understand you and the media ecosystem that you are reaching out to. So I think John's really smart. Let's see. Hannah Lee at Hannah Lee Communications is great on hospitality stuff. So restaurants, hotels, booze, they're really smart. Jen Sesquila, sorry Jen, if I mispronounced your name. Max Borges Agency, really good on sort of consumer focused products. Greg Delman, he's based in San Francisco, he has a boutique shop called G3 Media and he does a lot of tech startups stuff, just really knows that world. Greg, I'll find writers through Greg because he just knows everybody. I just texted him recently and I was like, "I need somebody who can write about this very specific AI thing." He happened to be at TechCrunch Disrupt and he found some freelancer and connected us. That's great. So those are four. I will have more that'll give you for the show notes.

Lenny (00:35:55):
Amazing. Okay. This is really useful. If any come to mind as we're chatting, feel free to shout them out again. Similar question, when people are thinking about publications to go after, say you're a startup founder. Is there a list you could just share of just like, here's probably the top five, 10 that you should be thinking about? The obvious ones, you talked about entrepreneur, [inaudible 00:36:15] Company, TechCrunch obviously comes to mind. Is there others that are just like, "Here's a good list to start with?"

Jason Feifer (00:36:19):
Honestly, it really, so much depends upon what it is that you're looking to do. You could be a startup, founder and entrepreneur and Inc and Fast Company are for maybe some good reason not at the top of your list because you're a startup founder, but your goal right now is to reach consumers. And those publications don't reach consumers and they don't reach people who are in a buying mindset. They reach people who are in a creating mindset. So I would expect that if you have a startup and that startup is not B2B in some way, that it would be possibly very reasonable that business publications might not be your target right now. Maybe Men's Health is. Maybe, I don't know, anything could be. I think oftentimes people tend to think too close to them about where they belong. Lenny, here's a real kind of exchange that happens, which is if somebody will email me, I don't respond to every publicist.

(00:37:23):
It's just literally not possible. I would not have enough time in the day. I do do my best to respond to every entrepreneur who reaches out because I feel like they deserve a response. And sometimes somebody will email me and they'll send me something and it's just not relevant. And I'll reply and I'll just say, "Hey, thanks. Congratulations on what you've built. But this isn't a fit for entrepreneur." And maybe once a month somebody responds really in a testy way, and they're like, "But don't you write about entrepreneurs? I'm a great entrepreneur success story." It's like, no, that's not what we do. Yes, entrepreneurs are featured in our stories, but no, we're not just a directory of entrepreneurs. Here's a good way of thinking about it. If you have a startup and you're trying to figure out what publications to be in, go look at where your competitors have been featured. That's a great place to start. What audiences are they reaching and how are they doing it? That should give you some direction about where you might want to go next.

Lenny (00:38:33):
Awesome advice. On TechCrunch, do you have a perspective on is it worth investing in getting featured in TechCrunch?

Jason Feifer (00:38:40):
I'll tell you a sort of personal press journey moment, and then I think that it will translate into the answer for TechCrunch.

Lenny (00:38:47):
Amazing.

Jason Feifer (00:38:48):
Okay. Something we haven't talked about so far yet is, and this is sort of almost skipping all the steps that we've laid out to what happens after you get the press. But the point of the press is sometimes to reach the people who are reading it. You get covered in Entrepreneur and entrepreneurs are going to read it and maybe something good will come of it. But sometimes the point of it is not to reach the people who are reading it at all. Possibly a very small number of people are going to read it, which by the way is a real, real possibility. Because although all of these publications that I have mentioned, Entrepreneur, Forbes, Fortune Inc, Fast Company, whatever, these are reaching millions of people, their websites get many, many, many millions of unique visitors each month. That does not mean that your story is going to be read by millions of people.

(00:39:40):
In fact, the largest possibility here is that your story will reach five to 10,000 people, a small number of people because these publications are publishing tons of stuff. So you might get this story, it might look awesome, it might not reach that many people. That might also be okay. Because maybe the reason in your logic for why to get that kind of coverage is not to have reached that publication's audience at all anyway. Maybe what it really is is to tweet it and then put some money behind promoting that tweet because then you can target that you got coverage to the people who you want to notice you got coverage.

(00:40:21):
And I see a lot of people do that. They'll take articles that we ran on Entrepreneur and they'll basically turn them into advertisements. And that's really smart because what they got out of Entrepreneur was the social cachet. It was the validation in the marketplace. And then they're going to do something with that themselves. That's really smart. You also see it sometimes the reason to get coverage, it's just so you can put it on your website. As seen in. As seen in is probably more valuable than anyone actually reading that story to begin with. They probably won't read the story. You might not even have to link it on the website. But you could just get to say as seen in. Because again, it gives you that validation.

(00:40:56):
Me personally, I am building a small podcast company with my friend Nicole Lapin. Nicole Lapin is a bestselling business money expert. And we have a company, she's the founder and I'm an advisor. And it's called Money News Network. We have a podcast on it called Help Wanted that we co-host together. And we got coverage in Variety. And that was the result of pounding on a lot of doors and finally getting someone at Variety to take interest and they ran an article about us. Did we get anything from that story in Variety? The answer is no, like nothing. But you better believe that every email we send out to every potential advertiser, to every partner, includes the link. Variety has covered us. And I guarantee that when someone receives that email, it makes them pay more attention.

(00:41:52):
And I have used it many times too when I reach out to people. It just gives you that validation. So sometimes what you're looking for is a prize to walk around with. And I would bet that the same is true for TechCrunch, which was your original question. Why get the funding announcement in TechCrunch? Probably not because anyone's going to care because they read it on TechCrunch, but now you can use that to your own means. And sometimes that's more valuable than the press itself.

Lenny (00:42:16):
That is an awesome insight. It also makes you realize you may not feel like it was a success after spending all this time getting in a story and entrepreneurs. Like, oh, nothing happened. But the benefits may come later, like weeks, months, years later when you start to share that.

Jason Feifer (00:42:30):
Exactly right. A lot of this is what you make of it.

Lenny (00:42:32):
Amazing. Okay. That was extremely interesting. Okay, let's talk about step two. So initially you prepped, we talked about how to think about who to go after and the mission and goals. Then you get to step two, which just figure out who to reach out to at a publication.

Jason Feifer (00:42:47):
Right. So a lot of people make the mistake of emailing me. If they want coverage in Entrepreneur, they email me. And I understand why they're emailing me. It's really for two reasons. One, I'm the most visible editorial person at Entrepreneur. And so it's easy to find me, it's easy to find my email address. And also they just assume, well, editor in chief, making all the decisions. But no. I mean, think about it. If you have a problem with a purchase that you made on Amazon, you don't email Bezos. He's too busy. And I am not comparing myself to Bezos. But I am the busiest editorial guy at Entrepreneur for whatever the hell that's worth. And I'm just not the guy to pitch because my job actually isn't really to select stories that go in the magazine. My job is to work with editors who develop their own ideas and then I get to say, "Oh, that's a good one," or, "Oh, let's refine that." I'm not sourcing as much. And so you really should start by looking at who's writing about your subject area.

(00:43:57):
And you can do that by going to the website and surfing around. You can do that by Googling around. But you'll find the answer. Every publication is structured differently. Some people have specific beats. Some publications will be like, "This is the person on the transportation beat." And some publications don't. Entrepreneur doesn't really have a beat system necessarily. But if you look, you'll figure it out. "Oh, that editor is clearly interested in food. That writer is clearly interested in food. They seem to write all the food stories." And a good way, again, to do it is to start with the publication and then look at how they're covering your competitors. So a good example is I was once consulting with a guy who has a kind of fun peanut butter company. It's like imagine peanut butter meets Ben and Jerry's, so it's like peanut butter with lots of stuff and fun names. And so he's trying to figure out how to get press. And originally his thinking, the reason why he reached out to me was because he's like, "Well, I'm an entrepreneur. I run a business. I should be in Entrepreneur."

(00:45:05):
I was like, "No, no, no, you shouldn't because none of our readers are going to buy your peanut butter. So who is your target audience? Who's buying your stuff?" And he says, "Millennial moms." I said, "Great. Okay, so Cosmo is a good place to reach them. So let's look at how Cosmo covers snacks." I don't know how they cover snacks. I don't read Cosmo, but let's find out. It's not hard. I went to cosmopolitan.com, searched for snacks. What I found immediately was a lot of stories that are all basically roundup-y and anchored to some time-sensitive things. So it's 10 snacks for Valentine's Day, it's our 10 favorite new fall snacks, whatever. It's all stuff like that. So now we know they are not going to run a thousand word feature on your peanut butter company. Instead, the best that you could hope to do is get into one of these seasonal-ish roundups.

(00:45:59):
So now next step, who's writing these things? Let's look. Let's open some of the articles. The byline is right there. You can click on the byline. You can see what this person does. And in many cases, maybe they're the food editor, maybe they're the lifestyle editor, whatever. You'll see what they cover. And you'll have a good understanding of now how to frame the thing that you're looking for. Now, let me introduce one other possible option. They don't work for the publication at all. They're a freelancer. Publications use a lot of freelancers. Freelancers are basically independent contractors. They're writers who are working sometimes. Sometimes they have longer term deals with publications. Sometimes it's just one-off. My wife is a freelancer. My wife is a freelancer who writes a lot for the New York Times and Washington Post and Guardian. And the interesting thing about my wife versus me is that my wife, whose name is Jen Miller, just so I don't keep saying my wife.

(00:46:58):
So Jen, on a day-to-day basis as a freelancer is hungrier for stories than me because Jen has to hustle for her food. Jen has to find stories and pitch those stories to editors at publications, and that's when she gets paid. So she actually is more incentivized to be looking for stories than I am because I am a salaried employee of Entrepreneur Magazine. And my email address is very easily found and people just send me stuff all the time. And I should add here also, note that a good journalist, a good writer is not actually sitting around thinking that their job is to wait for people to pitch them so that they can just write about the best pitches. Their job as they see it, is to go and find the most useful things for their audience. And they like to do a lot of that themselves. So they're not sitting around just waiting for your pitches. And in fact, your pitches have to overcome their instinct to go find things themselves.

(00:48:02):
So Jen is constantly hustling. Jen is constantly talking to people. Jen is curious about the world and will spend a lot of time hunting things down. But if somebody reads a story that she wrote and says, "Ah, I think I have an idea of what this person is interested in," and then tracks her email address down and then emails her, Jen is getting a lot fewer pitches than me, the chances of her reading it are close to a hundred percent. And the chances of her taking it seriously if it's relevant to any of the publications that she writes for is much higher than me. So sometimes going to the staff person is not actually your best move. Finding the freelancer who's doing the work is sometimes the better move.

Lenny (00:48:43):
So many interesting tactical insights that you're sharing. I love it. With this freelancer tip, how do you know they're freelancers? Is there something in the byline?

Jason Feifer (00:48:51):
If you find them on the publication's website so let's say that you go to Cosmo and you click on a author's bio. If they're staff, it'll say staff. If they're not staff, it'll probably say something else. It might say writer, it might say contributor. It might say Jen Miller is a writer in Brooklyn, New York. But also you can just go one extra step and just Google their name because any smart freelancer has a portfolio website where they should be very easily found.

Lenny (00:49:22):
Awesome.

Jason Feifer (00:49:23):
So sometimes just take their name, plug it into Google, you'll very quickly figure out who they are.

Lenny (00:49:28):
Okay, so let me summarize things that you've taught us so far. One is think about publications that go to people that will buy your thing. So in your example, Cosmo is a good example of someone who would buy this peanut butter thing. Two is don't think of it broad thing. Think about the writer at the thing. So it's not like Cosmo would write about this. It's like, who specifically at Cosmo would write about this? And we find that as go to their site, search for, you talked about search for your competitors, but I think it's even broader, just things related to your area, right? [inaudible 00:50:01].

Jason Feifer (00:50:01):
Yeahs, that;s good point. Search for your category.

Lenny (00:50:04):
Even adjacent things probably are close enough. And then this tip about freelancers is really great, that they're hungrier and that they're more likely to respond to your pitch versus someone that's working there. And then also this point that they're like, their assumption is this is not a good pitch and they don't want your pitch. But freelancers have a higher chance of being interested and will pay attention.

Jason Feifer (00:50:25):
Yeah, freelancers got to eat.

Lenny (00:50:28):
Amazing. Is there anything else along this step of finding somebody at a publication that you want to share?

Jason Feifer (00:50:36):
Well, the next step is going to be how to actually reach out to them and pitch. So at this stage, I think that we've fairly well covered it. And I love your summary. And just to double click on part of that, the reason why you're doing a lot of this is not just for the crazy busy work of it. But it's because you have to understand that the media ... Just sort of go back to translating the media. The media, which is a phrase that is used in all sorts of different ways, is a pretty bad way of actually understanding the media because the "media" makes it feel like it's a unified entity. In politics, the media will be criticized as a sort of multiple publications colluding together in some way. But the way that we're talking about it is just as organizations that you're trying to reach out to.

(00:51:25):
But really and truly, these are just publishing companies made up of individuals. And those individuals are all making fairly subjective decisions about what it is that they're going to write about. And there are layers of approval that they have to pass through. So nothing makes it into the print magazine, for example, without me saying yes. But I'm also trusting my editors to be passionate about the ideas that they're finding and convince me of yes. And so the thing that you are really looking to do is to find the way-

Jason Feifer (00:52:00):
The thing that you are really looking to do is to find the way in to a publication. Because nothing gets covered until a single individual at a publication takes interest in you enough that they go to somebody else and say, "I think that this would be a good story," and that other person says yes.

(00:52:17):
So you have to find your way in. Because media is not a coordinated effort. It's a bunch of people showing up every day trying to figure out how to make the best thing for their audience.

Lenny (00:52:27):
Amazing. Okay, so that's a great segue to final piece, which is actually, get someone excited and write about you.

Jason Feifer (00:52:33):
So how do we do that?

Lenny (00:52:33):
How do we do that?

Jason Feifer (00:52:36):
This is where the rubber hits the road, okay? So things not to do, don't call them, if you track down their phone number. Which is a real thing that happens. People call my personal cell phone number.

Lenny (00:52:48):
Oh, wow.

Jason Feifer (00:52:48):
It doesn't happen often, but it happens. And I don't even know where they get it from. But I don't like it.

(00:52:53):
And media people are torn on whether or not DMs by social are an okay way to reach out. I find them kind of annoying. Because, number one, the format doesn't lend itself very well, right? If you write anything wrong in a DM, it just looks like this endless thing that I got.

(00:53:13):
But also, I don't know, my Instagram DMs, I just kind of don't think of as the place to be pitched. But other people don't care. So I don't know, you can roll the dice on that.

(00:53:21):
Email is just the most traditional way. If you know somebody's going to be speaking at a conference, that's great, come up, you can talk to them. But the question of course is, what are you sending them? And here's what you're sending them.

(00:53:34):
You're really sending them the product of the work that you have done in the previous two steps. Because you have now spent some time thinking about your story, and who you're pitching, and the publication, and how they're telling stories to their audience.

(00:53:51):
And then the individual person who you're reaching out to, who you now have some sense of how they write about this. And you're taking all of that, and you're trying to distill it down into a presentation that they're going to find appealing.

(00:54:02):
Which again, to go back to the thing about how press is not that dissimilar to going out and raising money, that's kind of what you're doing when you go and meet an investor too.

(00:54:12):
If you have meetings with 10 investors, the way in which you talk about yourself and the company should not be exactly the same with those 10 investors, because they're all going to have somewhat different approaches and different thesis.

(00:54:25):
And you're not trying to scam anybody, but you're just trying to be as customized as possible by building in your knowledge of what it is that they do, and what their firm does. And the same is true for media.

(00:54:35):
So all of this is really going to take the form, in its most traditional sense, of a short email. A short email pitch. And what does that look like? I mean, look, there is literally no magic answer to that. I wish that there was, but there is not. There's no format. People always ask me, what should the subject line of the email be?

(00:55:00):
That's is a good question. There's not one answer to that. The closest that I can give you to an answer is that, picture me. Picture me at my computer. I have a lot going on, and I'm glancing at my email, and 40 new emails are sitting there. And my instinct is to delete all of them as fast as possible, but I'm going to glance at each one.

(00:55:23):
I'm not going to open each one, but I'm going to glance at it, which means that I see the subject line and I see the preview text, or just the first thing that somebody had written. What you want to do is write something that makes it pretty clear to me that this is targeted to me. That's step number one.

(00:55:40):
Because most of those emails that I got in my inbox are not targeted to me. They're mass blasts, and I'm delete, delete, delete, delete, delete. So which is the one that actually is reaching me? And sometimes you can do that by referencing something that I wrote in the past. I see people do that a lot. Don't fake it. People fake it all the time. People email me and they tell me they're fans of my work, they've never read my work. It's very obvious, right? Don't do that. But if you've read something, or if you're familiar with something, if you're familiar with the publication in some way, any signals of that are good.

(00:56:15):
Because again, what you're trying to do is just separate yourself from noise to, this is customized to you. Because If you think about it, this is really an efficiency question. What I'm trying to do is, I'm trying to spend my time on the things that have the highest percentage chance of being relevant to me. And I'm filtering out the things that seem not relevant to me, who are wasting my time.

(00:56:41):
So if I see something where somebody's writing me and they have a sense of the publication and they have a sense of me, there's a higher percentage chance that the next things that they're going to tell me are going to be relevant to me. Maybe even turn into a story.

(00:56:53):
Which is great. I like when that happens. Because it saves me time, frankly, right? It's one less story I have to find myself. So I'm happy for it, but it's got to be right. So you want to structure ... And then the email that you're writing is don't go on forever, like three paragraphs max.

(00:57:09):
And you are telling the version, you're not writing an article, but you're telling me the thing that you are pretty sure I'm going to be interested in. It's the difference between, going back to the butter dish example, woman sending me a three paragraph email about the butter dish itself, and opening up, telling me a little bit about the butter dish, and then immediately moving into this very clever story about the product market testing survey.

(00:57:43):
That's the difference. She told me the story that was going to be relevant to my audience. She got there quickly, and it felt like, to me, this is a interesting human being with an interesting entrepreneurial story to tell, and that's why I'm going to engage.

Lenny (00:57:57):
So that story actually came through a cold email?

Jason Feifer (00:58:00):
That was a cold email. Yep. Just showed up one day.

Lenny (00:58:02):
Amazing.

(00:58:04):
This episode is brought to you by Eppo. Eppo is a next generation AB testing platform built by Airbnb alums for modern growth teams. Companies like DraftKings, Zapier, ClickUp, Twitch, and Cameo rely on Eppo to power their experiments.

(00:58:18):
Wherever you work, running experiments is increasingly essential. But there are no commercial tools that integrate with a modern grow team stack. This leads to wasted time building internal tools, or trying to run your own experiments through a clunky marketing tool.

(00:58:30):
When I was at Airbnb, one of the things that I loved most about working there was our experimentation platform, where I was able to slice and dice data by device types, country, user stage. Eppo does all that and more, delivering results quickly, avoiding annoying prolonged analytic cycles, and helping you easily get to the root cause of any issue you discover.

(00:58:49):
Eppo lets you go beyond basic click-through metrics, and instead use your north star metrics like activation, retention, subscription and payments. Eppo supports tests on the front end, on the backend, email marketing, even machine learning clients. Check out Eppo at geteppo.com. That's get Eppo.com, and 10X your experiment velocity.

(00:59:11):
Is there any other examples that come to mind, of someone doing this well? For people to have more kind of examples of here's...

Jason Feifer (00:59:17):
Oh sure. Well here, let's see. We'll have to do this in real time here. But I keep in my inbox a folder called Bad PR Pitches and a folder called Good PR Pitches. We can go through both.

Lenny (00:59:28):
Let's do it.

Jason Feifer (00:59:29):
All right, I just pulled this up. This is, and I haven't read this in a long time. I'm kind of trying to read ahead as I'm talking just to see if this is appropriate to read. But I think so. I don't know, whatever. We're just going to read it and see what happens.

(00:59:42):
All right, so the subject of this was, "Idea for entrepreneur and Problem Solvers, how the Border Closures grew my business." So this was sent to me in September of 2020.

Lenny (00:59:54):
And this is a good or a bad?

Jason Feifer (00:59:56):
This is good, this is good. This turned into an episode of a podcast that I do for Entrepreneur, and I might've also then converted it into an article I can't remember.

Lenny (01:00:06):
Awesome.

Jason Feifer (01:00:08):
And so here's what she did. So her name, I shout her out. So this is Meg O'Hara. And Meg O'Hara is a painter, a Canadian landscape painter. Which again, a small business.

(01:00:21):
And she writes, "Hi Jason, I have an idea for a story I think would be valuable and relevant to you, Entrepreneur Magazine and the Problem Solvers Podcast." That's the show I do for Entrepreneur. And then she says, "Here's what's going on with my business. All entrepreneurs had to be flexible during Covid. This is a story about how one artist in Canada benefited from the border closure." This just sort of intrigues me. Oh, how?

(01:00:42):
"When Covid hit in March, all ski resorts across North America shut down early. Skiers are a high earning demographic in Canada. They fall in the top 5% of income."

(01:00:53):
Okay, well anyway. So she goes on. What she tells me, I remember this now, what she tells me is that her business used to be being hired by ski resorts to come and paint landscapes for their facilities. And when the border shut down and people weren't going to these resorts anymore, she had to come up with a completely different way of doing her business.

(01:01:15):
And so she started to think, well, I can't work for these resorts anymore. They're not hiring me. But all these skiers who used to work at the resorts who have seen my work, or who used to ski at the resorts who were maybe familiar with my work, they're not skiing either. They probably are sitting around wishing that they were skiing. They'd love something to see of their favorite ski location, and they also have money sitting around because they're not spending it on the ski resorts.

(01:01:39):
So then she lists off the problems and the solutions in bullet points. Which I love. Because she has listened to the show, the Problem Solvers Show, which is structured in exactly that way. Tell me the problem, tell me the solution that you came to. So she lists it off.

(01:01:53):
Here are the problems: the skiers can't come, people are spending more time at home.

(01:01:56):
The solution: I create artwork for their homes that depicts their favorite views from skiing as they were. She goes on and on and on.

(01:02:03):
I read this and I just think, there is something here about what this person did to reinvent their business at a time in which one marketplace shut down, but it created a new one that I think people would like to hear. Because at that time everyone was thinking about how to reinvent themselves and their business.

(01:02:21):
And even though I reach people who have very complex and large businesses, sometimes it's really a beautiful thing to hear a single individual who does the simplest thing in the world, which is put paint to canvas, talk about how she did it for herself. Because you can extract these wonderful little lessons about how to reinvent yourself that I think are going to be relevant to a very broad audience.

(01:02:44):
So Meg sent me that email, I replied and I said, "I like it." And we did it. So that's a good example of someone who spent time understanding my work, down to the structure of how I'm communicating, and then sent me a pitch that very quickly and clearly seemed customized to me, and told me her story in a way that I could imagine telling my audience.

(01:03:12):
At that point, it's a pretty easy yes,

Lenny (01:03:14):
That is an amazing example. I just took some notes on things that she did right based on things you've shared in the past.

(01:03:19):
Even just from the subject line or the first sentence, it was clear that she knew you. She knew you had this podcast, she knew the magazine, and she even expressed this specifically, you're going to be interested in this. She mentioned how this, she has a story. She starts immediately with a story. There's not the value prop of the company, here's what we do and here's why we're awesome. And then the lessons, the mission of Entrepreneur you talked about, is insights and lessons that people achieve, and she just went straight to here's what we've learned.

Jason Feifer (01:03:49):
That's right.

Lenny (01:03:50):
So I could see why that resonated.

Jason Feifer (01:03:51):
Yeah, it was great. And the next thing that made it a real success, by the way for her, was that once I got her on the phone, she was, and I find this, this is a make or break thing for me. Because I can talk to somebody and then kill the story, or not run the podcast. She was willing to be open about challenges.

(01:04:17):
I mean, she had reached out because of challenges, but not everyone is. I will get a pitch from someone who is presenting like, oh, we had this challenge in the business. But then when I talk to them, they act as if there was no problem. Or the problem was really small and their ingenuity immediately made this a very successful business. And that's not interesting to me.

(01:04:42):
Because success stories are not interesting. They're not interesting to anybody. It's not useful for you to just hear that someone else succeeded. What's useful is for you to hear how someone else faced challenges that you faced. And got through them so that you can see. Aha, that's an interesting strategy to use for me.

(01:05:01):
I hate success stories. I love problem solving stories. And that's why when I talk to an entrepreneur, I expect them to be really open about that stuff. And if they're not, I basically lose interest.

Lenny (01:05:13):
The hero's journey. I'd love to hear another example. But before that, hearing this, obviously it takes a bunch of time to do this for a founder. I guess, two questions. Just, how many places should somebody probably try to reach out to give them a chance of being successful? And then do you have any thoughts on how much time they should put into something like this? I know it's a very broad question. But, any thoughts there?

Jason Feifer (01:05:35):
Yeah, it's a really broad question. So again, this is in some way why, in a large way, why a lot of people hire PR. Because PR can just move this along. They can reach a lot of people very fast, whereas you as an individual cannot.

(01:05:51):
One way to think about it is, you're going to be on the hunt. You're going to try to make this work, and you're going to take a couple bets and hope that some of them pay off.

(01:06:01):
Another way of thinking about it is, this is a passive activity. And I'll spend some time when I'm reading media, thinking about this, kind of developing an idea. Another thing that you can do, follow a bunch of writers and editors on social media.

(01:06:20):
Meg, I can't remember the order of operations here, because I know that Meg follows me on Instagram now, because she's DMd me many times. And I respond to everybody. I can't remember if she followed me before, but she might've. And maybe she even DMd me a few times. Usually it's somebody's responding to an Instagram story or something.

(01:06:38):
And I've seen a lot of people use this strategy with me, and I think that it's a really smart one. Which is basically, before you ever pitch, just get me to recognize your name. Just engage in social media in a very casual way, such that when you email me, I think, do I know who that person is? Meg O'Hara, I think I know who that person is. It just makes it more likely that I'll open the email.

(01:07:08):
And I see a lot of people do that. They'll spend a long time engaging with me on social media before ever pitching me. I know what they're doing, I understand that it's probably calculated. I still like it. It's smart. Because it means that by the time that they've reached out, I think you have a pretty good sense of my work. Which means that what you're bringing to me is probably in pretty good faith. And for that, I like it. It's a good filter.

(01:07:36):
So if you've been listening to this whole thing, and you're thinking, this is a tremendous amount of work, I have a new product launch, or I have a bunch of budget that I can spend on this, this individual kind of approach, it may not be for you. You might want to just spend a bunch of time instead interviewing different PR firms. And find the one that seems most aligned with and understands your story, and your vision, and knows people in your space shortcuts a lot of this.

(01:08:06):
But even then, even then, I think that having heard this is really useful. Because at some point, if the PR person is successful, you are going to get on the phone with the writer or editor. And it's very useful to understand how they think. That they're not there to serve you. That this isn't a service that they're providing you.

(01:08:27):
So you better understand what they're entering into this with, and what they have in mind. When they're asking you questions, they're asking questions, thinking, this is what my audience is going to be curious about. This is how I'm going to drive this person in this interview towards the kinds of insights that my audience are going to find gratifying.

(01:08:44):
So the more that you understand who you're dealing with, the better.

Lenny (01:08:48):
And also just having done it yourself, you'll better understand what to ask your folks, how they're going to work, find opportunities to improve the way they're operating. On that question of quantity, say you're doing this, say you're spending the time. I'm going to really invest in understanding Jason and whoever else.

(01:09:05):
Is there a rule of thumb you'd recommend? Try to do this for three publications to get one, or is it five? I don't know. Is there anything there that you could recommend?

Jason Feifer (01:09:14):
So it's really dependent upon how easy you are to write about. I may just sort of note, if you are some kind of B2B service, especially in some kind of very niche or wonky space, it's going to be really hard for you to get [inaudible 01:09:40]. So hard that it might actually not even be worth trying. Because there are other things that you can do, or things that we haven't even talked about yet.

(01:09:46):
You could say, you know what? Screw it. I'm not going to try to get coverage for my company. Why don't I just try to position myself as an expert? Right? It's a totally different kind of approach. Where instead, what you're maybe trying to do is just hook onto the news, try to get a quote or a perspective to a reporter who might be writing about something. I get these all the time.

(01:10:07):
Something breaks, some news breaks, and people start reaching out to me. And they'll say, "This just happened in the news. And my client," or sometimes just the individual, "I have this insight into this, and here's what I would say if you want to interview me."

(01:10:22):
It's not going to be a feature about you, You're not going to be the subject, there's no photo of you. You might get a quote. You might get a quote in a story. Which again, is all you need to be able to say as featured in on your website. So that's the reason why people do that.

(01:10:33):
So sometimes it's about that. Sometimes it's about you could just be a writer. You might try to just pitch authoritative articles by you to different publications. Get yourself out in that way. Sometimes, again, you're not going to be able to be easily written about. And sometimes you are. Sometimes you made some insane technology that everyone's going to be talking about, and it's going to be super easy for you to get press.

(01:10:56):
At which point your hit rate is going to be much higher. That's why going into this with really realistic expectations, and if you're going to work with PR, having PR who can set and hold you to those realistic expectations, can just save you a lot of heartache.

Lenny (01:11:12):
Along the same lines, there's always this idea of exclusivity and people want to write first about a thing. Say you talked about an awesome technology. Do you have advice on, do you just pitch the same thing to all of them and hope they all write about it? Do you pitch them different stories? Do you offer one an exclusive, any advice there?

Jason Feifer (01:11:29):
Everyone has a different approach to this. The number one rule here is just, don't do it in a way that the people in media feel like you're playing them. Because they won't have tolerance for it. I would rather walk away from something like this than do some funny dance with somebody.

(01:11:48):
So my favorite version of this goes like this. Actually, there's a founder who recently, I met him years ago. So when he reached out, I recognized the name immediately. And he reached out and he's like, hey, we did this really interesting thing and we haven't told anybody about it yet. And I'd love to see if it's a fit for entrepreneurs.

(01:12:10):
So I hop on the phone with him, and he tells me. And I'm not going to tell you what it's yet because we haven't run the story. But after 15, 20 minutes, I say, yeah, you know what? This is a really interesting story.

(01:12:20):
And frankly, I know other media outlets are going to be interested in this too, particularly because a finance element to it. So I think the Wall Street Journal, and Bloomberg, and those kinds of places are going to be interested in this.

(01:12:32):
He wants to go to Entrepreneur for whatever reasons he wants. I mean, I think probably two. Because number one, he wants to position himself towards that audience. And then number two, there's a trust factor. He knows me in a way that he doesn't know the editors over there. And so he feels like I'll probably treat the story more carefully.

(01:12:49):
So we worked out a deal, which he proposed. And the deal is that we'll get the exclusive, and there's going to be a three-hour window after our story runs, and then they're going to start responding to everyone else. And then they're going to start talking to other people, or maybe they'll even line it up and reach out to some other media.

(01:13:10):
And that's fine with me. I understand. And we're going to create a little embargo window. And we'll go first, and then they're going to talk to everybody else.

(01:13:21):
Sometimes you can offer an exclusive to someone in that you are going to release the news to everybody, but only one media outlet is going to get the interview. Which works really well if you have a big personality.

(01:13:35):
So for example, recently a company that Mark Cuban has invested in offered us that, right? They're like, we have this news. We're going to reach out, we're going to send the news everywhere, but we're going to give you the exclusive interview with Mark Cuban. He's going to do one interview and he'll do it with you. You can parse it out in any way. You just want everyone to feel like you're being upfront with them.

Lenny (01:13:57):
And that they're getting something special, as much as possible. That makes sense.

(01:14:02):
You touched on this relationship piece, and that's something I wanted to ask. It feels like in tech, a lot of reporters end up writing a negative story, because a lot of times that's what people want to read. Why is this destroying the world?

(01:14:14):
I actually had a fast company do a thing on me, and I talked to the reporter, and I had no idea. Was he going to just completely tear me apart, or is he going to be really friendly and positive over what I'm doing? And I have no idea, and it just comes out.

(01:14:24):
It's not like I look at it before it comes out. So do you have any just advice to give you a set, help if this is going to turn into something positive or negative? I know you have no idea

Jason Feifer (01:14:34):
What happened, by the way? Was it positive or negative?

Lenny (01:14:35):
Super-positive.

Jason Feifer (01:14:35):
Great.

Lenny (01:14:37):
I was very happy with it, yeah.

Jason Feifer (01:14:38):
Okay, good, good. I'm glad to hear that.

(01:14:40):
So part of it is the publication itself, right? Entrepreneur, and I would say Fast Company, are just sort of not in the business of running negative stories. And the reason is, it doesn't serve our audience. My audience is coming to me to learn things for their business. Tearing somebody apart just doesn't help them in any way.

(01:14:59):
So part of it is just what ecosystem are you dealing with? You can also look at the past work of the writer. And if you work with a PR person, it's funny because occasionally somebody has accidentally forwarded this to me, and I'll see the dossier that a PR agency will put together on me.

(01:15:17):
But a PR agency, if they set you up with an interview with someone, they'll usually do some digging. And they'll find, what does this person usually write about? What kind of stories do they do? What are they generally interested in? So you can have a sense, right? What kind kind of thing are they doing?

(01:15:33):
And past that, there's also a question of, well, what are you doing in the world, right? I mean, if there is something somewhat controversial about you, and especially if you're engaging with an outlet that is interested in that kind of stuff, there's a halfway-decent chance they're at least going to explore it with you, and ask you about it. And if you're weird and cagey with them, they're going to think that there's more to it, and they're going to start digging more.

(01:16:03):
But the ultimate answer here is that every part of this, and this has come through, I'm sure, in our whole conversation, every part of this process is really out of your control. Does somebody pay attention to you? What do they write about you? When do they write about? All of it is outside of your control,

(01:16:23):
Which again, is the reason why it's not smart to think about press as a primary strategy for driving growth. It's a good add-on, but these people are going to do what they're going to do. And the best you can do is read the tea leaves.

Lenny (01:16:37):
Yeah. It was a very weird ... I don't get press often, it's not like something I pursue. But it was just like, this is wild. I'm just going to talk to this guy, and then something will come out. I have no idea what it might be.

(01:16:46):
He might have things wrong, because I didn't get a chance to review, and might skew things. But it's a strange experience to go through. But it all worked out great.

Jason Feifer (01:16:55):
Yeah, it is. It's very strange.

(01:16:58):
It is, it's strange. And I find that people often don't ... In business, people understand the structure of what's happening. They understand that we're a business magazine, we're going to write a story about a business. It's going to take a certain form.

(01:17:14):
But I've done a lot of different writing, and I have had the experience many times over my career where I will spend a lot of time with people, and they will have really no understanding of what it is that I'm doing at all. They can't conceptualize it.

(01:17:30):
And then the story will come out and then they'll always reach out to me and they'll be like, oh, now I finally understand what you were even trying to do. It's fascinating.

(01:17:40):
It is a vulnerable experience, and you have to know that. And the more you try to control it, the more the reporter is going to be annoyed at you. And the more, in fact, the reporter might try to take a shot at you in the story as a result. Because they found you too controlling, because they felt like you...

Jason Feifer (01:18:01):
They found you too controlling because they felt like you had something to hide. This is not a comfortable thing. You have to go into this being vulnerable and you have to know that there's a chance that it could blow up in your face. That's the price that you're paying for reaching their audience.

Lenny (01:18:19):
Great advice. How about we do just one more example of an awesome email pitch that you got and then we get to our very exciting lightning round.

Jason Feifer (01:18:26):
I'll tell you about a pitch. I don't know that I have it in my inbox still, do I? No, it's not there, sadly. I'll just tell you about it.

Lenny (01:18:32):
Yeah.

Jason Feifer (01:18:33):
Ii leads to something that is another way of thinking about getting press, which I think is really important for people to remember. So far, Lenny, we've spent the majority of our time talking about press in the form of some kind of feature on you, writing about you or including you in some kind of prominent way in a story that's basically highlighting the thing that you wanted to get out there, your product or something about your business, something. Then we talked a little bit about another way of doing it, which is sort of putting you out as an expert in authority. There's another way of thinking about this, which is that you can either create or present context in which you just happen to be a part.

(01:19:18):
Here's the story pitch that I got that leads into this. This is years and years and years ago. I had just started at Entrepreneur. I hear from a guy named Fred Ruckel. Fred Ruckel has got a cat toy and it's called the Ripple Rug. It's basically, imagine a rug and then another rug kind on top of it, but ill-suited. The rug is lumpy, there's a lot of lumps in and there are holes. This is for a cat to kind of crawl in and out these spaces and bat and do whatever cats do. I don't know. I don't know a cat. He wanted to tell me about the sales of this Ripple Rug and about how the sales are skyrocketing and all the things that he thought made it special. It's made out of recycled bottles and whatever the stuff, made in the USA, all cool stuff, but not relevant to me because we're not cat toy monthly and we're not reaching a whole bunch of cat owners, not that I know of.

(01:20:16):
I replied and I said, what I usually say, "Congratulations on what you've built, but it's just not a fit for coverage." Now Fred stumbled his way into this, but he did really a very smart thing because what he responded with was he said, "Totally understand. If you're ever interested in learning about a gigantic scam that's happening on Amazon and eBay that we've been caught up in, let me know." I was like, "Oh, well, yeah, I guess I am interested in hearing about that." I said, "Tell me more." He sent me this long email. Fred loves long emails, and I got him on the phone and had him explain, and finally I understood it.

(01:20:53):
This is, and maybe people are familiar with this, but this is sort of known as Amazon to eBay arbitrage. Basically the idea here is that Fred is selling his Ripple Rug on Amazon, or at least he was then, I don't know if he still is, but he's selling his Ripple Rug on Amazon. There are a lot of people who are copying the listing for his Ripple Rug and making their own postings for it on eBay. They sell it for a slightly higher price. Let's say that, and again, I'm making these up, but let's say the Fred is selling his Ripple Rug for $30 on Amazon, so somebody will sell it for $40 on eBay. Then somebody buys it on eBay, they find it, they buy it on eBay, they pay $40, that person gets $40, takes $30 of it, goes to Amazon, buys the Ripple Rug, and then just has it shipped to the buyer. It's arbitrage.

(01:21:47):
You might think, "Well, why would Fred care about this? He still gets the sale." The reason he caress about this is because the Ripple Rug shows up at the customer's house and it shows up in a Amazon box, even though they bought it on eBay. They think, "Why did that happen?" Then the next thing they do is they go to Amazon and they discover that it's cheaper on Amazon and now they feel ripped off. Who do they feel like they got ripped off by? Fred, because they don't know about the arbitrage. They don't know that they exist.

(01:22:21):
This person who has at this point opened the cat toy and probably had their cat roll around in it, now shoves the whole thing back in a box and returns it and Fred gets dinged and that's why he doesn't like this. He has tried and tried and tried to get Amazon and eBay to stop this, but he said, "Nobody seems to care and all these small businesses are losing tons of money on returns because of this." I had never heard of this. I thought it was fascinating. It's like a problem small business owners are dealing with. I was like, "Fred, do you know other people who are dealing with this?" He's like, "Yeah, I talk to them on the line all the time." He sends me off.

(01:22:54):
I reported this whole thing out. I wrote this three 4,000 word story on this thing, and Fred was the main character because he was the way to understand this problem. I did all the reporting and I contacted the platforms and I contacted the people who make the arbitrage software. I did a whole report, but Fred got his press because sometimes, and here's the lesson, sometimes you are not the story, but you can be part of the story. Sometimes that means if Fred stumbled into it, but I get plenty of people who've reach out and maybe they have a real estate startup and there's something really interesting happening in the real estate space and they reach out and they tell me about this really interesting thing that's happening in the real estate space and the role that they happen to play in it. Now I think, "Oh, well that's interesting. Maybe there's a story about that."

(01:23:46):
My wife, the freelancer, Jen Miller, she's done this many times where she once did this story about there was a bunch of startups that were all related to helping people prepare for death in some way or another. She's not going to write about one of them, but when somebody reached out and said, "Hey, here's a trend happening and we are one of them." Well, great, that's an interesting story. She wrote that and the company that reached out to her got kind of prominent billing because they were the ones who reached out. You know Barbara Corcoran from Shark Tank?

Lenny (01:24:14):
I think so. I think so.

Jason Feifer (01:24:15):
Yeah. She's been a regular Shark Tank since the very beginning.

Lenny (01:24:19):
Mm-hmm.

Jason Feifer (01:24:21):
She made her fortune by building a real estate company called Corcoran, realtors, buy and sell property. The way in which she built this company is fascinating. Barbara, before she was Barbara Corcoran of Corcoran Realty, Barbara Corcoran was random New York City realtor Barbara from New Jersey. She was trying to figure out a way to distinguish herself from the masses. She came up with an idea which was to take her own sales data, the only window she has into the Manhattan real estate market at that time is what she is what her clients are buying and selling, which she's facilitating. She has that data, is going up or down relative to last year. She puts all this data together in what she calls the Corcoran Report, and she starts sending the Corcoran Report out to the New York Times and the New York Post and whatever.

(01:25:18):
Because nobody else at the time was putting together a report on the health of the Manhattan real estate market, everyone started reporting on the Corcoran Report as if it was an authoritative thing. It's produced by Barbara Corcoran, which immediately put her in the position of being an authority in this space. That was so smart, and I see it happen all the time.

(01:25:37):
My inbox will also be filled with, for example, a company that specializes in remote work consulting. Especially remote work consulting, you can hire them, it's a B2B service. It's hard to get press for that, here's what they do. They pay a surveying firm to find all sorts of things. The top states for remote work, the top companies for remote work, the top whatever for remote work. They produce all these surveys and they send the surveys out. The surveys get covered because now they're creating a piece of news. They're creating some context in which they just happen to live in. Hard to write about them, this random company, but you write about the survey, that's interesting stuff. Oh, it turns out that Utah is the top, I don't know if that's true, is the top state for, that's something that people will write about. You're giving people things to write about. Then once they do that, you are a part of the story. I get those pitches all the time. I occasionally bite on them and Fred from Ripple Rug got himself a big feature as a result.

Lenny (01:26:38):
That's an amazing other strategy. I imagine if I was a founder, I'd be like, "Hmm, what trends can I think about that I can tap into?"

Jason Feifer (01:26:44):
Yeah. Sometimes you have it in your own data. If you have a lot of data, you might, Zapier. Zapier is a great example. I get a pitch from Zapier every single year about the fastest growing business apps of the year based on Zapier data because they see what people are using and they just compile that together into a top 10 list and people run it. It's very smart.

Lenny (01:27:09):
Amazing. We've gone through all three steps. Is there anything else that you wanted to touch on that we haven't touched on? Anything else that you think would be really valuable for founders or product leaders trying to get press that we haven't already shared?

Jason Feifer (01:27:23):
This has come up in different ways, but I'll just put a point on it as a maybe final way of thinking about this. Be human, be human. Press releases don't work because they're not human. I don't like interviewing people who are on talking points because that's not human. You're ultimately engaging in a human business. A subjective decision is being made about how to serve an audience of humans. There's no right or wrong. There's no way to know. Media is a sort of barely data-driven industry because every story is kind of different. It's like it's hard. It's hard to optimize the product because the product changes every minute. You're dealing with humans and the more that you can be human in every step of this process, when you pitch, write a human email, don't write a thing that looks like it came off of some marketing copy. Write a human email to another human and then when that person engages with you, be very human with them.

(01:28:26):
I mean, Lenny, the reason why that fast company reporter liked you, I am very sure was because when they got on the phone with you, you were just like a normal nice guy. If you presented yourself differently because you just wanted to frame yourself in some way or you felt protective or something or whatever it was, the reporter would've thought, "This guy is a dick," and he would've written a totally different story.

Lenny (01:28:53):
Mm-hmm.

Jason Feifer (01:28:54):
Be as human as you can and you will be dealing with a human who will receive that.

Lenny (01:28:59):
Amazing advice. With that, we've reached our very exciting lightning round.

Jason Feifer (01:29:04):
Yeah.

Lenny (01:29:05):
Are you ready?

Jason Feifer (01:29:06):
Let's do it.

Lenny (01:29:07):
Let's do it. What are two or three books that you've recommended most to other people?

Jason Feifer (01:29:12):
Andrew Chen's, The Cold Start Problem has come up over and over again for me because they're just really great lessons about network effects. I've been having a lot of conversations about anxiety and perfectionism with entrepreneurs lately, and a book by a psychotherapist named Katherine Morgan Schafler called The Perfectionist's Guide to Losing Control, is, I think, just a really great read.

Lenny (01:29:34):
Super cool. What is a favorite recent movie or TV show that you've really enjoyed?

Jason Feifer (01:29:38):
Movie? I don't get to see a lot of movies these days. I have two little kids, but I took my eight-year old to see the new Teenage Mutant Ninja Turtles, which was great and a really nice way of, I loved them as a kid, and so it was cool to see the modern version. Then my wife and I just finished Better Call Saul like years late, but it was just perfect.

Lenny (01:29:56):
I haven't watched that series yet. I loved Breaking Bad.

Jason Feifer (01:29:59):
Oh, it's worth it. You got to.

Lenny (01:30:01):
Okay. Another series I got to get started on.

Jason Feifer (01:30:03):
I know it's too much, too much television.

Lenny (01:30:05):
I usually ask this next question too, like product leaders and growth people, but I'm curious what the answer for you would be is. Do you have a favorite interview question you like to ask people you're interviewing? Usually it's about people you're hiring.

Jason Feifer (01:30:16):
Interviewing a job candidate?

Lenny (01:30:16):
Yeah, that's the ideal, but take it either way.

Jason Feifer (01:30:19):
I'll take it a little bit different because we've been talking about press. This is a really great strategy for interviewing people, and I'm going to tell it to you because I think that it's also good in any other context, and it might be a thing that somebody will do to you in an interview. My favorite strategy for interviewing people is to throw a theory at them, and I don't mean a theory of the world. I mean that maybe 10 minutes in after they have told me a couple different things and answer some different questions, I'll make a connection in my head and I'll say, "I want to run a theory by you. Do you think that the reason why you are really interested in this or you made that decision is actually because of this other thing that you told me a little bit about?"

(01:30:59):
You're listening. It's really active listening, and you're combining things together into some theory. The reason why the theory works so well is because it forces people to think in real time in front of you. I like that because I often interview people who have been interviewed a million times before. I interview Jimmy Fallon and The Rock and whatever. They've been interviewed a million times before, so how do you get them to think in front of you? The answer is to ask them the thing that they haven't been asked. What I love about the theory is that it shows them that you're really listening and you're trying to understand them. "It's so interesting that you did that. I wonder if it's because of," X, Y, Z thing. That gets them to react in a really earnest honest way.

(01:31:49):
I would say for what it's worth, as a job candidate tactic, it's not that bad either. My favorite job interview that I ever did as a candidate that I didn't even get the job was years and years ago, I interviewed for a job at New York Magazine. I interviewed with Adam Moss, who is not there anymore, but he was the legendary editor in chief. He made me, on the spot, drill down specifically into an idea. He was like, "What's your favorite section in Strategists," which is one of the sections of magazine. I was like, "I really like the real estate section." He's like, "All right, what would be a good neighborhood that we should feature in the real estate section?" I was like, "Oh, I don't know," I named a neighborhood. He's like, "What would be three good elements of that?" He just kept pushing me, drill down, drill down, drill down. There was no right or wrong answer. He just wanted to see how I thought. I found that to be incredibly powerful, and I do a version of that when I interview people.

Lenny (01:32:48):
Awesome. I love that. What is a favorite product you've recently discovered that you really like?

Jason Feifer (01:32:54):
I use BIGVU, I don't even know how to pronounce it, BIGVU, B-I-G-V-U, all the time. It's a teleprompter app. I spent like $150 buying an actual teleprompter because I make a lot of video and that teleprompter is, it's actually for people who are just listening to this, I'm pointing at another desk across my room where it's sitting there and I've never used it. The reason is because then I discovered BIGVU, which is just a app that runs a teleprompter very close to the camera, either in horizontal or vertical mode. I've tested it out in a million different ways, and it really works like you're reading it and it really looks like you're looking directly at the camera. I love it. It has saved me so much time.

Lenny (01:33:33):
That is cool. You basically put your phone on your screen next to the camera or wherever your camera is?

Jason Feifer (01:33:39):
No, no, no. This would be for if you're recording, if you're recording on the phone.

Lenny (01:33:44):
Got it. You're staring at the phone and it's telling you what to say. I get it.

Jason Feifer (01:33:44):
Yeah. Yeah.

Lenny (01:33:44):
That's awesome.

Jason Feifer (01:33:47):
You write a script and then you just import the script and then you choose the speed and you can fuss with it, how many words per minute, and then it'll run the text very close to where the camera lens is.

Lenny (01:34:01):
Amazing. All right.

Jason Feifer (01:34:02):
Yeah.

Lenny (01:34:02):
I'm going to check that out. What is a favorite life motto that you'd like to repeat yourself, share with friends, something that comes up a lot,

Jason Feifer (01:34:10):
Something that I've been repeating a lot to people is something that I heard, so I recommended Katherine's book, The Perfectionist Guide to Losing Control. I met Katherine because I, we've since become friends, but I interviewed her for the podcast when her book came out. We were talking about feeling overworked and being stretched too thin, and she gave me this question, which I think about almost daily, and I repeat to people all the time, and that is, "What's the point of building something if you can't maintain it?" I love that question because I, like probably everyone listening to this, pushes themselves really hard, and at some point you have to step back and think, "Am I building something where at some point there is sustainability for me here, or is this unsustainable and what's the point of building something if you can't maintain it?" It's a great reminder for why you're building something and how you have to build it.

Lenny (01:35:03):
I have a very similar quote that my sister's partner once said that has stuck with me forever, which is, "Life is maintenance. Basically everything that you buy or bring into your life, you have to maintain."

Jason Feifer (01:35:16):
Yeah.

Lenny (01:35:17):
We got a new air conditioner. Now, we have a guy that comes every year to check it. You got a generator, someone's got to check that thing all the time. We got a toy, now I got to think about where does it go and do we throw it away? Do we keep it? Everything that you bring into your life, you have to maintain basically for the rest.

Jason Feifer (01:35:17):
Yeah, it's really true.

Lenny (01:35:33):
Yeah, so it's really, I think specifically for work, it's like you start a new project, you're going to have to-

Jason Feifer (01:35:39):
You're going to have to maintain it.

Lenny (01:35:40):
... maintain it, like this podcast, right? It's like, do you want to start a podcast and do it forever?

Jason Feifer (01:35:45):
Yeah.

Lenny (01:35:46):
That's a part of it. Part starting something is you have to maintain it.

Jason Feifer (01:35:49):
Yeah.

Lenny (01:35:49):
Yeah.

Jason Feifer (01:35:50):
I know we're in the lightning round and we've defied the logic of lightning rounds, but I'll just add one other thing to that, which is that I interviewed Michelle Pfeiffer for the cover of the magazine, and one of the things that I thought was most fascinating was that she started this fragrance company, and it's called Henry Rose. She said the major difference between making movies and building a company that she found, was that when you make a movie, all the work happens in the beginning. You make the movie and then the movie is out, and then you are done. You don't have to work on the movie ever again. She was not really mentally prepared for a company being the exact opposite, that the launch of the company is actually the start of the work and there's an endlessness to it. She said that it took her a solid year to adapt to that reality, and then it became fun. I think it's the thing people forget.

Lenny (01:36:42):
Mm-hmm, Well, that story, it's cool that you got to interview Michelle Pfeiffer.

Jason Feifer (01:36:45):
Yeah, she's great.

Lenny (01:36:46):
Final question. I was reading your profile line and you said that the only reason you were able to achieve what you've achieved in life and got to where you're today is something that you called the opportunity set B.

Jason Feifer (01:36:57):
Oh, yeah.

Lenny (01:36:58):
Can you just explain what that is and why that is so important to you?

Jason Feifer (01:37:02):
Oh, yeah, sure. In front of you right now, you, Lenny, you everyone listening, watching, there are two sets of opportunities. Opportunity set A and opportunity set B, opportunity set A is everything that's asks of you. If you have a job, it's what your boss expects of you. If you have your own company, it's what everybody expects of you. Doing good at those things is really important. That's a measurement of success. That's opportunity set A, everything that's asked of you. Then there's opportunity set B and opportunity set B is what's available to you, even though nobody's asking you to do it. That could be, again, if you have a job, that could be taking on new responsibilities or joining a new team or something. Personally, it could be pursuing a hobby. It could be starting a podcast because you like listening to podcasts, anything.

(01:38:01):
What I have found throughout my own career is that opportunity set B is always more important, infinitely more important. The thing is that if you only focus on opportunity set A, then you are only qualified to do the things that you're already doing. Opportunity set B is where growth happens and where you push yourself in different directions. I found a long time ago that it was just really helpful to think about these two things. Oftentimes, maybe we don't do opportunity set B because we don't know how it's going to pay off, or we don't know where we're going to find the time. I have always found, always, that engaging in these things of what is available to me, what's available to me right now around me, and nobody's asking me to do, leads to the next growth either because it turns into an actual opportunity or because it informs some future opportunity.

(01:38:58):
I got to Entrepreneur Magazine, zero, zero people, when I became editor in chief, zero people said, "You should hit the speaking circuit. You should get really good at being interviewed on podcasts. You should write a book." Nobody said any of that. My job was to make a good magazine and direct the editorial of the brand, but all those things were available to me, and once I recognized that, I realized that I can pursue them and in doing so, also think differently about who I am. Am I a magazine editor? Not really anymore. That's one of the things that I do now. I think of myself as an entrepreneur, as a person who is now in the business of helping others. I'm an entrepreneur who helps entrepreneurs. That's what I think of myself as. I only got there because I was thinking, I am here and therefore I can get there. Nobody's ever going to ask me to do it. I have to do it myself. It's the thing that I always think about, and it's the thing that keeps me up at night. What am I doing now that is leading me to something else? I'm the only one who can figure it out.

Lenny (01:39:59):
Beautiful. It reminds me of a recent podcast guest's advice, which is the best way to track your progress in your career and in life too is just measuring how many, "Oh shit" moments you have because those are the moments where you're growing, you're doing something. I think maybe it's an example of an opportunity set B where it wasn't the default path that's like, "oh, I think I should do this, even though it's really hard."

Jason Feifer (01:40:20):
Yeah.

Lenny (01:40:22):
What a beautiful way to end it. Jason, not only do I want to start working on press, it feels like very achievable to get press now. That was really energizing, like, "Holy shit, I could do this. I could just find some people, pitch them. Here's how I do it."

Jason Feifer (01:40:33):
Yeah.

Lenny (01:40:34):
Not only that, I'm going to look for some opportunities set B routes for myself too. Thank you so much for being here. Two final questions. Where can folks find you online if they want to reach out, maybe pitch you on their story? How can listeners be useful to you?

Jason Feifer (01:40:47):
Oh, so Lenny, thanks for all the work you do, which I just really love, and for creating the space for me to share all this insight. How can you find me? Well, I'll offer two things. An opportunity set B, like a good launching point for both of them, I wrote a book, it's called Build for Tomorrow. It is meant for anybody who's going through any kind of change in their lives or their work. There's an audiobook version that I read myself, but also hardcover and eBooks, just find it wherever you get books. Again, it's Build for Tomorrow. Opportunity set B, that whole thing, is actually a chapter in the book, so I go into a lot more detail there.

(01:41:20):
Then if you want to get in touch and also get those kinds of things, I have a newsletter, which is called One Thing Better each week. One way to improve your work and build a career or company that you love. Again, the kind of opportunities set B, that's the kind of thing that I put out. It's very much about the personal and emotional side of work. You can find that by going to the web address onethingbetter, that's one, O-N-E, onethingbetter.email. Just plug that in. Onethingbetter.email. I said that's a good way to reach out to me because if you get the newsletter and you reply to it, it goes to my inbox. I guarantee I will write back to you.

Lenny (01:41:56):
Inside track. Jason, thank you again so much for being here.

Jason Feifer (01:42:01):
Oh, thanks Lenny. This was so fun.

Lenny (01:42:03):
Bye everyone.

(01:42:05):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review, as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Building a meaningful career | Jason Shah (Airbnb, Amazon, Microsoft, Alchemy)
**Guest:** Jason Shah  
**Published:** 2022-09-18  
**YouTube:** https://www.youtube.com/watch?v=nMsA5VeLoOM  
**Tags:** growth, acquisition, onboarding, experimentation, analytics, pricing, revenue, hiring, culture, leadership  

# Building a meaningful career | Jason Shah (Airbnb, Amazon, Microsoft, Alchemy)

## Transcript

Jason Shah (00:00:00):
Pushback is, I couldn't imagine a word more viscerally that makes you feel like you're sort of physically going against what somebody else wants, and it gears people into a mindset of then, well, how should I push back. It starts from a place of I need to disagree, I need to say no. It's a very negative mindset, purely based on the word that has come to label a behavior that alternatively could be about how do I shift the direction on something, or how do I help the business actually succeed when I disagree with somebody about something, and that's a very different mindset. And so, the two things that I've seen be most successful would be, I think number one is actually understanding what a goal is or what somebody's kind of issue is with something, and then actually aligning those things in some way.

Lenny (00:00:53):
Welcome to Lenny's Podcast. I'm Lenny, and my goal here is to help you get better at the craft of building and growing products. I interview world-class product leaders and growth experts to learn from their hard-won experiences building and scaling today's most successful companies. Today my guest is Jason Shah. I was lucky to work with Jason while I was at Airbnb, and when I started working on this podcast, I knew that I wanted to have Jason on. He was actually my very first guest on this podcast when I was pre-recording some episodes, but as you'll hear in our chat, we decided to take another crack at it for reasons you'll soon understand.

Lenny (00:01:28):
In this episode, we cover what it's like to be a PM in Web3 and how that's changed as crypto winter has returned, how to lead a team through ups and downs, which leaders in Web3 know all too well, including how to keep morale up and people focused when so much is changing around you. We also get into a ton of killer advice on leadership, hiring, pushing back on your CEO, working backwards, career advancement, and a lot more juicy stuff. Jason is a gem and I am really excited to share this episode with you. With that, I bring you Jason Shah.

Lenny (00:02:05):
This episode is brought to you by Coda. Coda's an all-in-one doc that combines the best documents, spreadsheets, and apps in one place. I actually use Coda every single day. It's my home base for organizing my newsletter writing. It's where I plan my content calendar, capture my research, and write the first drafts of each and every post. It's also where I curate my private knowledge repository for paid newsletter subscribers, and it's also how I manage the workflow for this very podcast. Over the years, I've seen Coda evolve from being a tool that makes teams more productive. It's one that also helps bring the best practices across the tech industry to life, with an incredibly rich collection of templates and guides in Coda Doc Gallery, including resources for many guests on this podcast, including Shreyas, Gokul, and Shishir, the CEO of Coda. Some of the best teams out there like Pinterest, Spotify, Square, and Uber use Coda to run effectively and have published their templates for anyone to use.

Lenny (00:03:03):
If you're ping-ponging between lots of documents and spreadsheets, make your life better and start using Coda. You can take advantage of a special limited time offer just for startups. Head over to coda.io/lenny to sign up and get $1,000 credit on your first statement. That's C-O-D-A.io/lenny to sign up and get $1,000 in credit on your account. I'm excited to chat with my friend John Cutler from podcast sponsor, Amplitude. Hey, John.

John Cutler (00:03:36):
Hey, Lenny. Excited to be here.

Lenny (00:03:37):
John, give us a behind the scenes at Amplitude. When most people think of Amplitude, they think of product analytics, but now you're getting into experimentation and even just launched a CDP. What's the thought process there?

John Cutler (00:03:49):
Well, we've always thought of Amplitude as being about supporting the full product loop. Think collect data, inform bets, ship experiments and learn. That's the heart of growth to us. So, the big aha was seeing how many customers were using Amplitude to analyze experiments, use segments for outreach, and send data to other destinations. Experiment in CDP came out of listening to and observing our customers.

Lenny (00:04:09):
And supporting growth and learning has always been Amplitude's core focus, right?

John Cutler (00:04:14):
Yeah. So, Amplitude tries to meet customers where they are. We just launched starter templates and have a great scholarship program for startups. There's never been a more important time for growth.

Lenny (00:04:22):
Absolutely agree. Thanks for joining us, John, and head to amplitude.com to get started. Jason, welcome to the podcast.

Jason Shah (00:04:34):
Thanks so much, Lenny. Really excited to chat with you today.

Lenny (00:04:36):
Something listeners don't know that we know is that we actually recorded an episode between you and I back in April. It was actually my very first episode that I ever did for this podcast, and it was before I launched. It was kind of like a pre-launch launch episode, and interestingly enough, by the time the podcast launched and it was going to go out, well, let me also add that we chatted mostly about Web3, forgot that detail. So, most of our chat was about Web3 in the state of Web3 and PMing in Web3, and by the time the podcast's supposed to come out, Web3, things have changed in the world of Web3, and so, it kind of felt a little stale and out of touch, and so, we decided let's do it again. And so, how do you feel about that?

Jason Shah (00:05:15):
I appreciate that, Lenny. I'm honored that you would have me back. I'm going to count it as the personal record of two times on Lenny's Podcast, even if the world only knows it as one.

Lenny (00:05:26):
Wow. Good one. Okay, first ever guest and first two-time return guest. Amazing. Okay. To set a little context for folks on your background, your career, could you just give us a 60-second overview of your background and your career and how you got to what you're doing today?

Jason Shah (00:05:45):
Yeah, for sure. Thanks again for having me, Lenny. So, my career has all been about solving important problems in a unique way. I think the latter part is the youngest child in me who has to be special and do things different than other people, and the former is about making sure that my time is spent well since we're all limited there. So, I actually got started in a sense in tech when I was 15. I started my first company, much like a lot of teenagers, it was around test prep and getting people ready for college, and it was my first exposure to using technology at scale to help people, and I just found it addictive ever since.

Jason Shah (00:06:20):
And so, I ran that company for seven years through school, was lucky to do a small acquisition to a partner of ours that we had worked with throughout, and then I would just hooked, and I moved to San Francisco without a job. I was really arrogant. I said, "I'll never work for anybody else," and then lo and behold, Yammer comes along, I'm super excited about it, I had been working on a product actually in the same space. And so, that was actually my first formal product management role, and I stayed at Yammer, I stayed through the Microsoft acquisition back in 2012. Low and behold, I was at the world's largest productivity company at Microsoft, and most people there in my opinion were wildly unproductive and I wasn't shipping a lot. I got the itch again, so started another company called do.com and ran that for about four years, and then eventually, we found a better fit with Amazon. They were growing their AWS offering, SAS products. So, we partnered with them to kind of do a small acqui-hire and help build the team out and the product there for a little over a year.

Jason Shah (00:07:18):
And then again, to be honest, I got bored and excited about what Airbnb was doing and the mission around belonging. That's why I was lucky to meet you and so many other really wonderful product leaders and just human beings in general at their core, and then to keep things brief for now, I got to work on a lot of really exciting products and businesses there, but eventually got the itch for Web3 after being a kind of observer from afar, investor, and I wanted to be a builder in Web3 specifically, and to me, it's a new vision of a better version of the internet. I'm really excited about that. So, I've been with Alchemy which is a blockchain infrastructure company for the last year, and really excited about all the opportunities. I've gotten to work on products that have been part of most people's everyday lives, and I'm hopeful that we'll get to do that with Web3 and Alchemy as well.

Lenny (00:08:05):
Amazing. I just realized as you're chatting there, do.com, I'm pretty sure I used that back in the day. I think I just realized that.

Jason Shah (00:08:12):
I hope so. That would be a new, I'll add that to my second podcast achievement is if I got Lenny to use a product that I worked on, especially a startup.

Lenny (00:08:20):
Wow. Cool. Okay, so we're going to go a little bit backwards through your career and start with Web3. We're not going to spend most of the time on Web3, but just thought it'd be good to chat about some of these things, partly because you guest authored the sixth most popular post, online newsletter of all time, currently at number six, and it was about how to be a PM in Web3. Basically it's called The Product Manager's Guide to Web3. And so, a few questions there I wanted to touch on. One is just like, how would you describe the current state of Web3? We're recording this at the end of July, and so, we'll see when this comes out. But I'm just curious from someone working within it, kind of going through the boom and the busts, not the bust, the winter that we're kind of in a little bit right now. Yeah, how do you feel about it right now?

Jason Shah (00:09:01):
Yeah, for sure. So, as much as I'm a techno optimist, I'm also realist, and with that being said, I genuinely believe Web3 is in the strongest position that it's ever been in. I think it's important to remember that the term Web3 has barely existed in kind of popular lexicon for barely a year. We've definitely had crypto for more than a decade now as technology, arguably as a financial instrument of some sort, but specifically the number of companies that I'm seeing be formed, the number of products that are starting to actually achieve some form of early product market fit, some products that are starting to scale. There's definitely been obviously a huge drop in price. There's definitely been some huge scandals in terms of financial mismanagement and the contagion from that.

Jason Shah (00:09:46):
But I think it's been my experience that a lot of new technologies don't move up in a straight line, and Web3 is especially challenging here because so many things have been financialized from the outset, whereas generally speaking, you'll see startups or new technologies mature over many years, whether it's the internet itself, artificial intelligence, QR codes, all sorts of things that kind of have gone through different periods of adoption, and so, I think we're seeing things kind of record Ethereum transactions happening, new Layer 2 technologies launching all the time that are going to help scale Layer 1 Blockchains, Solana has announced its phone that's going to be the first sort of Web3 native phone out there. So, there's so many new exciting product developments and users entering the space that as much as prices have come down, I'm really optimistic about the state of Web3.

Lenny (00:10:32):
I think about a little bit is going through this shift in excitement about Web3 as a PM within a company working in this space, I imagine it tests some of the core skills of a PM, like keeping people focused, prioritizing effectively, keeping morale up. If people are getting like, "Oh man, all my cryptos going down," I'm curious how you've been able to leverage those skills and what you've learned going through this experience, keeping people focused, morale up, prioritizing effectively, those sorts of things.

Jason Shah (00:11:00):
Yeah, it's a great question. It's really important, right, because we've seen in this space that there are these cycles, and I think that morale and ability to keep building are the determinants of long-term success, and if everybody kind of takes the ball and goes home, that uncertain future won't necessarily materialize. So, in my opinion, I think that the only way to maintain moral is to make progress. I think that no speech, no sort of extrinsic motivators like we're going to give everybody some free crypto to keep motivated about it or something like that really works. I think people get really excited when they see progress.

Jason Shah (00:11:37):
So, for example, at Alchemy, we see more developers than we've ever had on the platform today, and then we're shipping, we just launched Solana support and people are like, "This is real." We're actually doing things, building things. We just had our team out at EthCC which is a big conference in Paris for the Ethereum community, and it was wild the number of people that were there, products being built. Pretty much every crypto conference has a hackathon, and so, it keeps the spirit of building so alive.

Jason Shah (00:12:03):
And so, I think it at Alchemy and just in other situations that I've been in as a leader over time, I think it's all about a focus on progress and moving forward. We saw this at Airbnb when the business had a draw down in revenue, and I know you'd covered this with Sanchan recently, right? It was 85, 90% revenue and you didn't know when it was going to turn around, right? It's not just like, "Oh yeah, this will come back in six months and we can just keep plowing forward." But I think what worked was making progress and actually focusing on product and your customers, and ultimately if you hire the right people who are motivated for the right reasons, I think that recipe keeps people highly motivated and highly effective at building for when things do eventually turn around.

Lenny (00:12:44):
One of the most interesting and maybe surprising points you made in the post that you wrote about being a PM in Web3 is that there's much less need for a PM, especially early stage Web3, and it feels like, the stuff you're talking about feels like a PM's really helpful along these lines. So, I'm curious, are things changing at all there? Have you changed your perspective on PMs and Web3, and then I don't know, where do you see the evolution of product management and Web3?

Jason Shah (00:13:09):
I actually am seeing things change a lot, and one thing in Web3, if one learns nothing is the ability to admit when they're wrong or when things change. And so, I think that that's exactly what I'm seeing. So, basically, I'm specifically noticing a lot of teams hiring product leaders, more product managers. Those product managers are actually now working kind of increasingly in sort of more traditional product management fashion, in addition to some of the differences that we discussed in the post around the community management and role in marketing and things like this, but specifically, Uniswap just made a big hire out of Meta. I saw that Gemini also did the same. We're seeing OpenSea hire a lot of talent along these lines too, even through the ups and downs that their business has seen, and at all levels. Whether it's kind of product manager, senior product manager, director, VP or CPO, you're seeing it across the board.

Jason Shah (00:14:03):
And so, I think that's partially happening because you're seeing a maturation of products, right, and so, maybe you can start early with a few engineers, a community manager, get the ball rolling, but eventually the product is more mature, the complexity has grown, the role of the product manager is far more useful than they can differentiate. I also think the market is getting increasingly competitive. So, there's many NFT marketplaces. There's many Layer 1 and Layer 2 blockchains. As a result, I think product is always a competitive advantage, right? If it's working, it improves strategy, it improves execution, and improves team collaboration. And so, maybe that was less of a difference maker before where these teams didn't need that competitive advantage as much because maybe they launched a token and the token was mooning, and so a bunch of people were adopting the product, but that only lasts so long, and first principles still come come in to focus, whether it's one day or one month from now.

Jason Shah (00:15:00):
So, I'm definitely seeing it shift. It's definitely making a huge, positive difference in the cases that I've observed, and my hunch is we're only going to continue to observe this because with more user adoption comes new challenges, and for all these players that are growing and getting some form of adoption, the product complexity is only going to grow, and having somebody to help lead teams, help prioritize between all the different products that they could build or strategies they could pursue is going to only increase in importance.

Lenny (00:15:27):
I know we're like we're PM people talking about the value of PM, but something I find is that people that are kind of anti having a PM or don't see why they need a PM in my experience just haven't worked with a great product manager because my experience, you find a great PM, they just make everything better, and so, it's not surprising to hear what you're sharing which is people are kind of discovering that value of bringing on a product manager, even if it's mostly engineering work. And so, that's promising, and I wonder if that's just a natural evolution of a new space where people are like, "Eh, I don't need PMs in this one," and then like, "Oh, okay, well, I see. All these things aren't happening. We need someone to help. Who can do that for us? Maybe it's a PM."

Jason Shah (00:16:06):
Yeah, that's a great observation. I think that combination of having a direct need for something that emerges as well as if somebody's had either a bad experience or not even had any experience with somebody who can play this role which is quite common in Web3, especially because a lot of folks are relatively early in their career, given the kind of accessibility of the space, and I think frankly the more adept understanding of the space naturally that a lot of people have when they're early in their career and less set in their ways. And so, that's a great point, and as a result, the better PMs we see in Web3, hopefully the value will prove itself out over time.

Lenny (00:16:41):
And hopefully they do well so people don't keep getting burned out by bad PMs.

Jason Shah (00:16:45):
We're rooting for all PMs, but definitely Web3 PMs too.

Lenny (00:16:49):
Yeah. What's surprised you most about working in Web3 as a PM?

Jason Shah (00:16:53):
I mean, I think that the biggest surprise to me, despite what we were just talking about, was how big some products have gotten without kind of the traditional either product manager role or without the playbooks that we're so used to from the last 20 years of the internet. And so, for example, Uniswap has done more daily volume on certain days than Coinbase, and Uniswap is about a hundred people versus 5,000-plus at Coinbase, right? So, that's astounding to me.

Jason Shah (00:17:21):
I think a lot of these NFT collections and communities that have grown. I met with a lot of these at NFT.NYC recently, and a lot of them, aside from the price speculation and things like this, have actually built, the Bored Ape Yacht Club is actually building a metaverse project that does look better than some of the digital games that I've used in the past of Second Life and things like this. Obviously, a lot of time has passed and so there's a greater foundation of technology to build off of and they're working with a partner on that product as well, but there's a ton of progress being made without some of the traditional product structure or individuals. And so, again, I think PMs play a really strong role, but it's been incredibly surprising to see how far products can get without the product playbooks and resources that somebody who's worked in the internet space from the last 10 or 20 years is so used to.

Lenny (00:18:11):
Awesome. Okay. We're going to move on from Web3 and chat a bit about some of your other career accomplishments and companies you've worked at. So, you worked at, you mentioned Yammer, Microsoft, Amazon, Airbnb. I'm curious which of those companies has most informed the way you approach product and build product and run teams because they're all so different in how they operate, and I'm always curious what company is the formative experience for you that's like, "Here's how I like to build product most." I know it's always a combination, but how do you think about that?

Jason Shah (00:18:39):
Yeah, it's definitely a combination, but I would say if I had to pick, Amazon, even though I was only there for about a year after the acquisition. I say that because of this blend between product and business thinking that is especially present there. And so, people say Google is an engineering culture. People said Facebook is a product culture, Airbnb or Pinterest, sometimes a design culture or things like this, and I think that Amazon was a place where you couldn't divorce business and product. You couldn't be a product manager without thinking about revenue growth, without thinking about go to market, and I really like that because as a startup founder doing product in a bigger company, it gave me the chance to exercise a lot of those skills.

Jason Shah (00:19:24):
It's very similar actually to how I feel at Alchemy now where I remember my first month there I was like, people ask me how's it going, I'm like, "I feel like an athlete. I feel alive again." I can do M&A one day, I can be doing product another minute. I could be figuring out, oh, we need to hire our first lawyer to write onboarding plans for employees the next minute, and it wasn't as siloed as sometimes a product role can be. So, I think Amazon, I went there to learn and understand. That was my biggest goal was this is an incredible company that's gone into... The Whole Foods acquisition happened when I was there, and I was wondering how does the same company kind of within retail win with the AWS, go create studios, and I think the Amazon culture ultimately more than anything else around ownership, being vocally self-critical is right a lot as one of the leadership principles. All these things combined I think created a really unique culture.

Jason Shah (00:20:12):
So, I would say Amazon's had the biggest impact on me, and there have been certain lessons that I've taken from, like you said, all these places, but Amazon was by far the place that I think left the biggest mark on my view on product and leadership.

Lenny (00:20:26):
That's quite amazing that you were there for a year and that's the one that's most informed and impacted you. Do you feel like people should try to go work at Amazon as a training ground as a PM? Is that something you encourage PM to try to do?

Jason Shah (00:20:37):
In general, I certainly had a positive experience, but I think that as you know and as I'm sure you've advised countless people, it's so context dependent. Are you learning the zero to one? Are you learning the one to scale? What's your aspiration? Is somebody trying to start a company eventually, or are they trying to work the ranks of the product leadership trajectory? And so, I definitely enjoyed it a lot, and I think to your point, there's often a non-linear sort of correlation between factors that we traditionally think are linked, right? So, my time there was one of the shortest, but my learnings were some of the greatest because I was really intentional and maybe because of the sort of moment in time and what I wanted to get out of it.

Jason Shah (00:21:17):
The same way for what it's worth, while we're talking about this disconnect, when I went to Yammer, I also interviewed with kind of... This was the era of TaskRabbit. I talked to Square and I remember people always say, "Well, what stage do you want to join seed, Series A, Series B?" And the crazy thing is that Yammer was, it was already passed a hundred people, it grew to 500 by the time of the acquisition, and it felt almost like the culture was so tightknit, it felt like a seed stage company at some points, even though eventually it kind of felt like... Well, once it was acquired from Microsoft, we'll just say it didn't feel like a seed stage company anymore, but it felt smaller than a lot of the actual smaller companies than I was at. So, I think that's something I've noticed a lot is that a lot of the proxies don't necessarily match the internal realities in certain cases.

Lenny (00:22:01):
You mentioned you picked up a bunch of tactics and kind of lessons from some of these companies. What's one concrete process or tactic that you took it away from either Amazon or one of these other companies that stuck with you that you like to kind of share with folks?

Jason Shah (00:22:14):
Yeah, definitely. I mean, I think one that Amazon is well-known for is the working backwards process, and for those that don't know, the idea is try to define effectively an ideal end state which funnily enough is very similar to some of what we both experienced at Airbnb and took away, and usually the mechanism for doing this is what's called a PRFAQ, and that's a press release and frequently asked questions, and it forces a certain degree of clarity to have to actually write a press release about the product that you're going to eventually launch.

Jason Shah (00:22:44):
Every employee goes through actually like a business writing class after they start at Amazon. They give you a little card with five tips that you're supposed to keep on your desk about concision and specificity in the words you use. For example, you should never write the word great in an Amazon press release. You should write user friendly in X, Y, Z way and will save customers time 20 minutes each day through this. It's intended to be very concrete in a way that avoids some of the fluffiness that frankly... It's funny, when people try to move from slides to docs, they really just import the same mindsets that they use in slides, but just with more words now.

Jason Shah (00:23:22):
And so, I think the working backwards process of establishing the long-term goal using a mechanism like a press release and the FAQs where every word matters, and even the FAQs, for what it's worth, there's a section for external FAQs that you would include for example as an appendix, but also internal FAQs that are meant to de-risk launch or raise the elephant in the room or dogs not barking as Amazon likes to call it often. So, that was a really helpful process that felt very true to me as a way I like to live my life as well, and then also very applicable.

Lenny (00:23:55):
The tidbit about not using the word great is so interesting. Is there anything else there that you could share about just basically just like how to write effectively and communicate and launch. Is there any other tidbits along those lines?

Jason Shah (00:24:07):
Yeah, that's a good question. In addition to not using the word great and words like it that are either subjective in what they mean or unclear in what they actually mean, definitely using numbers more than adjectives. Strict concision, I would go over these documents countless times, and there's a phrase, I can't remember, it's either Mark Twain or another famous writer who said kill your darlings, right? Cut, cut, cut, and just remove. And so, I think I found that really useful in emails I write or documents I write to this day is just going over, not because you're saving ink by cutting words, but because it forces clarity of thought. Fewer words means every word is 10 pounds in weight instead of one, and that means that the decisions you're making, the trade offs are far more intentional, and in the case of great, if you say something is great because we're going to deliver something in two hours versus Amazon's great because the selection is very wide, the implications on strategy are completely different. And so, that's one of the benefits of being very specific and very concrete in language.

Lenny (00:25:12):
I didn't intend to go too deep into this topic, but no one's ever covered this working backwards process on this podcast, so it's kind of interesting to talk about it a little bit more maybe. How does that actually work? So, you sit there and you actually write out a press release that would go out when you launch this thing. Is there like a template used? Is there anything you could share for folks that want to try this out and/or point them to a resource that will help them down this road?

Jason Shah (00:25:36):
Yeah, definitely. That's a great question. So, there definitely is a template, and so, it's a combination of an internal training where you have to write one of these documents. You review kind of good, bad, medium versions of this. It's generally used if there's let's say a proposal for a new product or even a proposal to buy a company. This helps really simulate what it's going to be like.

Jason Shah (00:25:56):
With respect to a template, what I recall is it was often sort of an introduction where you get kind of right to the point. You say what you're announcing. Then usually you would describe the problem in one paragraph and in very clear language. Again, all of the writing is this way. Then the solution, you briefly describe the product. After that, there's always a customer quote, and this is an example of this customer obsession that Amazon is so famous for that many companies like to say or emulate, but I think it really kind of may not be true if you evaluate the mechanisms that they use, for example, product specs that either don't have customer data or don't have quotes from customers, things like this. And so, there's a customer quote, and you have to literally put yourself into the shoes of... Let's say you were launching Prime. Put yourself in the shoes of Lenny from San Francisco. What exactly is he going to say when he has access to this, and how's it different than his life today, and what are the words that he's going to use?

Lenny (00:26:52):
You can't use great.

Jason Shah (00:26:53):
I mean, if great is one of your favorite words, maybe you could stretch it, but I think if you were in a room with your peers at Amazon, they might put some red pen through any greats that are used there. So, I found that really helpful, and it also helps force out of this box that product managers, product leaders tend to get into of thinking that they are always the customer and being a little sort of intellectually lazy, where I'm like, "Yeah, I would like Prime, so let me write the quote for what I would like," but maybe I'm only a small segment within our total customer addressable market.

Jason Shah (00:27:26):
So, anyhow, there's a customer quote, then there's one leadership quote similarly that this achieves a complimentary goal, like how does this fit into our strategy in a way that you would express to the public but is still true to what the internal sensitivities and mechanisms would be. And then a call to action towards the end, and not just download here, but this will be available to customers next month. They can go access these portals within these Whole Food stores at this state. It again forces clarity of thought with respect to not only the rollout plan, but taking a step back. When you read it, do you feel like you would actually want this product? Would you use it? So, I found that really helpful as a structure.

Lenny (00:28:05):
Can you just summarize those again real quick?

Jason Shah (00:28:07):
For sure. So the structure of the PRFAQ docs was generally an introduction where you're announced the product, problem, solution, customer quote, leadership quote, and a call to action.

Lenny (00:28:17):
So, interesting how similar that is to a one pager potentially. The other thought I had while you're chatting, so the Airbnb approach is work back from the ideal, Brian talks about it, the 11-star experience versus the Amazon approach which it doesn't need to be the ideal, it just needs to be an awesome launch. So, that's an interesting difference, both effective in different ways.

Jason Shah (00:28:37):
I think people tend to, when they see that both companies have some sort of working backwards process of thought, I would say working backwards on one hand and then 11-star experience on the other. Listening to how you describe it, I want to almost frame it as working backwards from sort of a moment in time or a launch like you said with Amazon versus working backwards from a quality standard in some sense of an 11-star experience.

Lenny (00:28:59):
Going in a slightly different direction, one of the things I wanted to chat about is you worked at all these different companies and they have different types of leadership and different approaches to leadership. And so, I'm curious, what have you learned about effective leadership watching all these awesome operators work, and what kind of separates them in your experience from folks that maybe aren't as effective?

Jason Shah (00:29:18):
Yeah, it's a great question, and to briefly recap, right, I've gotten to see somebody like David Sachs who've been the CEO of PayPal and then the founder of Yammer and gone to do many more things since then. I've gotten to see sort of Jeff Bezos at a distance. I was never that close to him obviously and never got to work with him, but got to observe his impact on the organization. Obviously, I've gotten to witness Brian Chesky and his leadership in sort of the pre-IPO days as well as through the ups and downs of COVID, and then also now at Alchemy, our co-founders, Joe and Nikil are leaders that have really had an impact on me as well, and I would count myself, but I've also see myself as a bad leader in the start of [inaudible 00:29:56] and learn from that.

Jason Shah (00:29:57):
I think it's a really important thing to reflect on, and I think for me there are three things that have stood out the most. I think number one, nothing is above them. I've seen whether it's Brian caring about the full bleed image on the homepage, whether it's Jeff Bezos who famously would receive customer emails, read many of them, forward them, and he's famous for question mark emails where for his time's sake he would just forward an email to a leader with a question mark and you would just have to figure it out and then report back in 24 hours with the resolution thereof. But nothing's above them, and a lot of founders or a lot of CEOs or even CPOs and leaders think you get to a certain point and then I'm above a product spec, I'm above looking at the data running a sequel query, and I think that that is a mistake in a lot of ways, especially from a standpoint of who people come to respect as well as efficacy at one's job.

Jason Shah (00:30:51):
And then the other two things would be, I think they're in the details. So, it's less about being above something, but this is kind of Amazon's famous for auditing the details for example, and leaders are... For example, when we were going to launch Prime, order a bunch of Prime things and see what happens and really test things out, and write up a long feedback email on Saturday or something like that, and make sure that things are moving forward.

Jason Shah (00:31:12):
So, I think in my opinion, some of the best leaders, David Sachs would do this too. He actually ran the product reviews. It was the CEO of the company doing product reviews, not some kind of middle tier of a director of product who was just running them. They were force involved and there were things to delegate and activate around, but Sachs was in all of those details and ran those product reviews himself and would talk to the product managers directly, and I think that was really impactful, and it also, I think from an accountability and culture perspective, when you're PM and you talk to the CEO and you feel like you're presenting something at product review, it's totally different, and it creates a certain amount of responsibility and quality, frankly, that I think is really important, and it's a way to coach obviously as well for those leaders to really make a mark on the organization.

Jason Shah (00:31:59):
And then lastly, I think they adapt, right? I think that are a lot of leaders who are like, "I've worked 20 years to become a leader in this way and I have a playbook," either based on past experience or based on some sort of philosophy that they've developed over time that they feel committed to in some way, and I think coming back to some of these examples of watching Brian lead through COVID or watching Joe and Nikil now through this particular crypto winter shift gears and figure out exactly like we're still building the core business, but how else can we lean into this and adapt to the unique opportunities that are in front of us. I think that's really powerful. So, what I've seen is nothing is above them, they're in the details, and they adapt to new information and new situations. That's what I've seen the most that I've appreciated in the best leaders that I've gotten to either observe or work closely with.

Lenny (00:32:46):
Awesome. That's super interesting. The first two are kind of connected which is really interesting, and it just reminds me of Brian and how detail-oriented he was about everything. He used to review every product launch and every screen of every new product. We had to show him here's what we're launching this week, and he just kind of went through and either blew it up or let it pass. And then I just remember the founders, when they were designing the office space, just looking at pictures of listings they wanted to... Because Airbnb, the office conference rooms were modeled after Airbnb listings, and Jim just looking through hundreds of listings that the team brought him and he'd just picked the ones that he wanted to turn into conference rooms. Also, obviously Steve Jobs. This is a really interesting through line of great leaders is just this huge attention to detail, and there's probably something about once they let go that thing start to kind of diminish. Is that what you find?

Jason Shah (00:33:39):
Yeah, that's such a great point. You mentioned the Jobs example and there's a great book that you've probably read or in your community seen, I believe it's called Creative Selection by Ken Kocienda about the early days of the iPhone, and I think it was Project Purple or something like that, and you're absolutely right. There wasn't no slides, none of this. They brought in the prototypes for each of those reviews and things like how to do typing on a tiny screen and those early keyboards and how to do auto complete, and Jobs was totally in those details from Ken's telling in this book.

Jason Shah (00:34:10):
So, I couldn't agree with you more, and it's something that people miss because most of their exposure to leaders is on a YouTube video or at all hands, and so, they don't really get to see that side of leaders I think, and it's also not what I think from an ego perspective is kind of what people want it to be about. They want to be about making big decisions or commanding a large group of people, and I think it's hard to do that without these pieces.

Jason Shah (00:34:34):
One other thing I just wanted to briefly touch on to your point on how they're connected, it's a really good point, and at the surface it almost seems like they could potentially be the same thing. One thing worth calling out though I think is the idea of something not being above somebody or a person not being above things. I think the biggest thing I take away from that is humility is that nothing is not my job, right? Anything, could be picking up paper off the floor and putting it in the trash, or it could be reviewing a product spec, whatever it is, and then begin the details in my opinion is about craft, right, and really understanding things at a low level such that you're able to reason about it and make good decisions, like Brian with the homepage or Bezos in some cases with customer processes that he got in the weeds on. I think the two together, humility and being excellent at craft, I think is a very potent combination, especially when you throw in the last thing of being able to adapt to any situation.

Lenny (00:35:29):
That's really interesting. What it also makes me think about is the reason things are less good often if there isn't a person at the top that's being very detail-oriented, and I find this with the newsletter and this podcast and other stuff is no one's going to care as much about it. No one's going to be like, "Oh my god, I really need to get this right so much because I'm just like, I'm personally feeling responsible for the quality of this stuff and it's like it's on my shoulders to make this awesome." And so, I think that's probably why a lot of the best stuff is led by a singular leader or singular opinion or singular person. A lot of the best startups are just someone's vision is like, "Here, this is what we're going to do," and then the more it becomes a community-driven thing, the less often it ends up being successful.

Lenny (00:36:16):
This episode is brought to you by Maven. I've been an investor, an advisor, and a customer of Maven from day one. I even taught my product management course through Maven. Maven is a cohort-based learning platform where you learn alongside peers with a direct connection to your instructor. Maven's got a ton of courses for product managers, founders, and executives to help them level up in all kinds of ways. Over 10,000 people from Airbnb to Coinbase to Google to Tesla have taken courses from real experts and operators that have spent decades honing their craft. As part of their fall season which Maven just launched, there are over 100 new courses starting in the next few weeks. Many of the people I've had on this podcast are teaching courses like Jackie Bavaro on product strategy, Arielle Jackson on startup branding, Emily Kramer on B2B marketing, plus Annie Duke on decision-making, Nir Eyal on behavioral design and how to break into product management with Marily Nika. Check out all of my favorite courses and learn more at maven.com/lenny.

Jason Shah (00:37:19):
I feel like you're totally right, especially, I mean this is the natural progression, but it doesn't have to be that way right? And I think to your point, I think a lot of leaders focus on accountability in an organization once they get large, and so, you see things like performance reviews and things like this. It's a very top-down approach to trying to drive results, but is opposed to a sense of accountability if you drove a sense of responsibility. If people felt like this is my company too, this is my product, this is my office floor. I don't want trash on the floor. I'm going to pick it up and throw it there. Even if we have somebody whose job it supposedly is to clean that up, it's like I take pride of ownership in this and I'm connected to it, and I think that makes all the difference in terms of... At Airbnb, I think people who felt that way were willing to push back on certain things, or they're willing to propose new ideas because they felt invested in the company.

Jason Shah (00:38:12):
I see it at Alchemy all the time. I see an engineer hop in and fix something at 3:00 AM because they feel committed to the code base, and it's not a thousand-person engineering organization where my only job is to make the iOS app 2% more effective at engaging users.

Lenny (00:38:27):
So, you touched on the skill of pushing back on a founder or CEO, and I know that's something you're really good at. I've seen you do this. I'm curious what you've learned about how to effectively do that as a PM at a company pushing back on a CEO or founder when you disagree.

Jason Shah (00:38:40):
I mean, I think this is one of... I actually think it's one of the most misunderstood terms in a sense because I think language like we were talking about earlier is so important, and yet what you call something ends up defining I think 90% of what people understand about a concept, right? And so, pushback is, I couldn't imagine a word more viscerally that makes you feel like you're sort physically going against what somebody else wants, and it gears people into a mindset of then, well, how should I push back. It starts from a place of I need to disagree, I need to say no. It's a very negative mindset, purely based on the word that has come to label a behavior that alternatively could be about how do I shift the direction on something, or how do I help the business actually succeed when I disagree with somebody about something, and that's a very different mindset.

Jason Shah (00:39:34):
And so, the two things that I've seen be most successful would be, I think number one is actually understanding what a goal is or what somebody's kind of issue is with something, and then actually aligning those things in some way. So, in coming back to Airbnb, I remember Airbnb had bought a company, Luxury Retreats. There was a goal to integrate that business and that product into the full Airbnb suite, and there was a lot of potential with that, but I remember that there was part of the product experience that was oriented around chatting with somebody and the idea that the business had had a very large team of wonderful people who helped you as concierges basically for your trip, and so, this was a team that I was on that, to be honest, had fairly low morale. It's always difficult to integrate an acquisition with a company, especially when we were based in different places, et cetera.

Jason Shah (00:40:26):
I remember hearing from a leader who had been at Airbnb for a while who's very effective at persuading senior leadership, and they understood why this was a problem because this chat product was growing in complexity. You'd have to build all these features into it, and nobody could successfully shift the direction, and as a result, it was just this... It was a mess as a result, and there was very low morale because we were taking on too much scope, people weren't sure it was the right product, it was being built up as one giant launch as opposed to an iterative thing. And what was really interesting was that this leader was very effective at understanding that the goal wasn't about building a bunch of features. It was about, as often discussed at Airbnb, a magical experience.

Jason Shah (00:41:06):
And so, when we took a step back, it was reimagined as trip designers, not concierges, and their goal was to design your trip, and part of that meant a very elegant, simple chat experience so that you could have a efficient, fast, positive experience with that trip designer and move on. And it shifted the pushback of like, "We can't build this thing, it's too many features, we don't have enough time, we don't have enough resources" to, "Oh, we all want a really elegant, really smooth, slick experience for our customers. How do we do that? What's a trip design or a new concept that is actually going to elevate things? We're not telling you we want a payback scope. We're not saying we want to settle for less. We're actually just not only going to call it something different, but also envision a simpler experience which is more elegant. It's more on brand with luxury."

Jason Shah (00:41:51):
Boom, all of a sudden, everybody gets what they want. It's a better customer experience, less scope, and it wasn't about saying no. It was about understanding what we're all actually sharing as a goal which was a great simple customer experience and then actually building that. So, I saw that to be really effective and I think that that's something I try to bring into my career. I have a couple other examples if it's useful, but that was a big one that I learned from Airbnb.

Lenny (00:42:16):
Yeah, another example would be great. One thought there though is do you think it was mostly the name and the concept or was it that it was a bigger idea? What do you think it was about reframing it that way that got people, "Oh wow, okay, now I'm really excited about it again"?

Jason Shah (00:42:30):
That's a great point. I think it was a big idea, right, with a good reframing, and I think it's like many things where there's the substance of something and then there's the communication of it. And so, this is true often, for example, if a company is changing strategy. Oftentimes people might walk away feeling like, "Yeah, I guess I kind of agree with the strategy, but the way was communicated was really poor," or vice versa, like, "Yeah, they told us in advance and they sat us down all hands, but I really disagree with this strategy and I'm going to be dug into my heels and not disagree and commit now."

Jason Shah (00:42:58):
So, in this case, I think you're totally right. If it was just window dressing of... Founders are too smart, especially at all these companies we've talked about, to be fooled with a simple renaming of something. But I think the combination of a bigger idea, more exciting idea that was at the heart of what we were all going after together, combined with a simple way of communicating it because I've also seen big ideas that are poorly communicated fall flat on their face and not achieve the intended outcome. Those two together, I think were a really potent combination.

Lenny (00:43:28):
Awesome. I'd love to hear another example.

Jason Shah (00:43:30):
Yeah, for sure. So, a recent example at Alchemy actually, right? We're growing, we're hiring, but there are a lot of roles, especially being in Web3 that are not yet created. For example, there's traditionally growth, product growth marketing, we've created new area around growth operations which I'd be happy to talk about if we want to get into it. But it's a really interest interesting area, and we were going back and forth on should we hire for this role, it's not even a real thing. We've looked at some candidates, we're not so sure about them. And when I realize with our founders who are incredibly smart, very talented, have built the company over so many years now, they want to win. That's what they care about at the end of the day. They are so driven to win at the end of the day.

Jason Shah (00:44:10):
And so, ultimately, it wasn't like, "Let me make some rational argument about the role of growth operations or let me defend some issues with this person's resume that maybe you're spotting when we make this hiring decision," but, "Oh, you want to win? Oh, we want to grow faster? Awesome. This is the way to do it, and that's how we're going to actually become the generational company we want to be." Again, a reframing in this case around, yeah, we might disagree or squabble about certain things at a detail level, but I understand what we all came here to do and let's focus on that and how this is a part of that versus just focusing on maybe the means to an end versus the end itself, and the end always brings a lot of clarity in my experience.

Lenny (00:44:49):
What's cool about both these examples, and another guest touched on this, when you're trying to influence the CEO or the founder, coming back to your working backwards concept, you almost want to work backwards from what are they excited about, how do they see the world, what's important to them, and then pitch it that way. So, in the first example, I imagine they were pitching to Brian and he's like, "Yeah, drip design, that sounds like something Brian would love." Then in the second example, "Yeah, we're going to win. Here's how we win." So, that's a really interesting takeaway there.

Jason Shah (00:45:15):
I mean, I think we all forget that we're all just humans, and at the end of the day, we all are busy, et cetera. It reminds me of a lot of sales, right? I was very unsuccessful when I was trying to do outbound sales in the early days of my last startup do.com because I didn't understand this. I'm a product person. I'm not a sales person. I didn't listen to what people cared about. I didn't kind of work backwards from what a CRO or head of people that we might have been selling to cared about. I was just about features and here's what we can do for you and this and that. But all they cared about were one or two things, right? Maybe the CRO's growing revenue. Maybe the head of peoples worried about culture or scaling their talent organization, and we were nowhere near that list.

Jason Shah (00:45:56):
And so, I think it's similar for CEOs, and there's a huge disconnect when say a PM walks into a meeting with the CEO and they're talking about something that CEO is 10 miles away from thinking about, and certainly even the mindset that they're bringing to the conversation is totally different. I think Casey made a lot of great points about this in the recent podcast as well.

Lenny (00:46:16):
Sweet. Casey Winters, podcast plug. Okay, so something else that you're really good at is you don't kind of focus career-wise on working your way up the ladder and being like the top PM, and you seem to be really good at kind of following with what's interesting to you and your interest and your curiosity. Is there something that you've learned there, something you could share for folks that are just like, "Oh my gosh, should I just keep in with this job and work my way up? Should I try something new?" What have you learned about that sort of thinking?

Jason Shah (00:46:46):
There's the framework I like is ladder versus map, and I think that you can be either person that any point in your life. Sometimes there's a bit of a set mindset that somebody might have one way or another, but I like ladder versus map. Ladder is about moving up. It's more influence, more power, a higher title, things like this, whereas map is I just want to go wherever's interesting, right? I literally think of it, I think of my career very similar to travel. I want to go to Greece. I want to be hungry, walking around in India, sweating in a hundred degree weather. I want to go to Australia and kind of get locked out of my hotel and see what that's like.

Jason Shah (00:47:23):
I'm okay with discomfort because it's interesting. Sometimes, for better or worse, maybe this is a privilege, it's certainly a privileged thing to say, but I care more about living a really interesting life than let's say a good or comfortable life. I think that's where the growth comes from. That's where the stories come from. That's to me the things that I'll remember the most.

Jason Shah (00:47:42):
And so, when I think about product and I'm on my deathbed, I'm going to care about the products I built and how they affected people. Nobody's really going to be looking at my LinkedIn, hopefully for their sake and mine, at my funeral. Sorry, it's a very morbid analogy, but I think thinking of the future provides a lot of clarity about what am I going to care about a long time from now, and I think that applies to all facets of life. That's how I thought about my life partner. That's how I think about my career. That's how I think about where I want to live, San Francisco. San Francisco, a lot of people like to talk negatively about it, but I believe in the community. I believe in the place I'm interested in the long term, even if you know the short term it has some challenges to it.

Jason Shah (00:48:21):
So, I personally believe really strongly in this kind of ladder versus map distinction, and I think a lot of people are very intentional in the micro. They think about their next job, their next title, how much salary and equity there is. In good ways too, they think about the team that they're going to work on next with, but they're very unintentional about the macro. What's the big picture? What do I care about as an individual? There's not a lot of classes for that. There's not a lot of blog posts in the product management field about the touchy-feely side of this, and who are you as a person, where do you get energy from. So, for me, I found that really clarifying and it makes career decisions that have seemed risky to other people seem inevitable to me.

Lenny (00:49:03):
Is there a story of or example of how you use this approach to make a decision at where you end up going, and/or or is there something that you maybe regret or are really happy with in terms of the kind of the fork in the road, looking back, using this way of thinking?

Jason Shah (00:49:18):
A few concrete examples, actually. I'll keep them brief though. One is when I first moved to San Francisco, and I had mentioned I did a small sale of that education company, and I could have done a lot of more productive things with my career in the short term. I had all my peers from college who had gone off to their great jobs at Google or whatever. I said, "I'm looking to move to San Francisco and work at my dining table, and I have a little bit of savings from this, so why not? Let's see. It's going to be super interesting." I mean, it was also very boring at times, and so, I didn't want a lot on the sort of micro level, but I built five or six products. I became much better at programming as a result.

Jason Shah (00:49:56):
I remember one time, it's kind of a goofy story, but I was working at my dining table, and I saw Ron Conway on the street. I was disheveled because I was just working from my apartment and I wanted to go pitch Ron Conway on this terrible idea for a startup, and so went out there, and maybe it was fortunate to not shove me to the side, and he listened to me for a minute and then I emailed him after. These are random things that happen that over time I think make us who we are. Are you the sort of person who's going to hustle and do that? When I was building that education company, I went and put flyers in people's cars in various high schools, and I was trying to get things started, and coming back to leadership, that would be below most people. It's like, "Wait, you own a company and you're sticking flyers in people's windshields?" It was like, "What's wrong with you?"

Jason Shah (00:50:40):
So, anyway, I think that was an example of time where it was like, "Okay, if I'm on the ladder," I'm like, "I got to get the best entry-level job or whatever." Even if I had been an entrepreneur before that, I would've thought about my structure in my career, and I was more like, "This is going to be interesting. I'll figure it out. I believe in myself enough that I'll figure it out." So, I did that. Yammer and leaving Yammer was similar where I could have stayed. My equity was finally worth something. I could have learned a lot even I'm sure from the Microsoft structure, but I was bored and I had been talking to a couple angel investors who were willing to put money into whatever the thing was going to be, and I felt like raising money's actually going to be really hard for me. This is going to make my life a lot easier and I can focus on product and so on and so forth.

Jason Shah (00:51:25):
That was a really hard four years. Things like an M&A offer falling through the day before your wedding, or chewing glass and submitting to the Apple iStore and being a featured app and then resubmitting because we wanted to fix a bug, and then actually now it crashes 90% of the time. It's Memorial Day weekend and you can't get in touch with the Apple business development manager who can help you out to reapprove something. It was a really stressful four years, but using the map analogy, that's like getting lost in Croatia and having to find your way out or getting lost to to your hotel in Australia or getting bitten by a dog in Thailand, which actually did happen to me. But these are interesting experiences that I think build characters.

Jason Shah (00:52:05):
So, I'll pause there, but I think there are a lot of career decisions I've made. Do I have regrets? At times, for sure because you see what would've happened if you had joined a different company at that time and it would've been like, "Oh, I would've met so many great people. I would've worked on these products. I mean, my equity would've been worth more," whatever. But I think you only lived once, and I think that these rare experiences have been very true to me and taught me things that I wouldn't learn otherwise.

Lenny (00:52:28):
What's really cool about that analogy, ladder versus map, is a lot of times you think you're climbing a ladder and you think it's innately going to be great, and sometimes that ladder falls over and the company doesn't go anywhere and/or the job sucks, your ladder's heading to some terrible place. And what I find in my experience is anytime I try something totally new and take a risk, especially following things that give me energy, and I'm just like, "Let's just take a leap on this thing," in my experience at least, it's always led to better opportunities and much more interesting work. And so, it's kind of this get off the ladder to get on a different ladder, and sometimes you think you're on a nice ladder and it's not going to get you anywhere anyway. So, explore other ladders. So, I'm kind of picturing a Chutes and Ladders.

Jason Shah (00:53:15):
Totally.

Lenny (00:53:15):
There's many ladders and you want to explore the different ladders across the map. How about that?

Jason Shah (00:53:20):
I mean, I think you're totally right, and the only brief thing I would add to the way that you put it which I think captures the essence here is I think we all have a lot of false precision about what we think a given career move is going to lead to or what it's going to be like, and we forget that a lot of career decisions are made out of maybe 10 hours cumulatively talking to a team and getting signals.

Jason Shah (00:53:44):
So, I think that that false precision sometimes gives us comfort in making certain decisions and folds us back from a bolder decision that might be better, but maybe the ladder is just hidden behind some fog if you really want that, and you can get both. Maybe you can go to the most interesting place in the world, and have the success in life and progress and so on and so forth. It's just that I think a lot of people think it's totally either/or. They think that they've already figured out the precise outcome that's going to happen, and to your point, the ladder often does fall over. If that's what all your hopes are pinned on, it's a very fragile career decision I think is really difficult to navigate.

Lenny (00:54:19):
The flip side, you also don't want to be bouncing around over and over and over. As much as I talked about how I shifted and tried new things, I'm a very serial monogamous in terms of work. My first job, I was there nine years, then a startup for a year and a half, and then Airbnb for seven years, and then what I'm doing now may be forever. And so, there's a lot of value to sticking around and kind of seeing things through. And so, I guess, I don't know if you'll have an answer to this, but do you have any wisdom on when to stick with it and keep exploring opportunities at a place you're at versus trying something new?

Jason Shah (00:54:54):
My hope is that there's a balance here in the sense that the map shouldn't give the impression of 180 countries, let's do 180 tech companies and shorten the tenure from two years down to a month, and we've just created a generation of job hoppers which is even easier because we're all on Zoom. It's a good point and I really respect people like you who have stuck it out through the ups and the downs and somebody sees seven years on paper, but I mean, seven years, I don't know. How many chapters of Airbnb, how many crises moments?

Lenny (00:55:26):
Felt like 300.

Jason Shah (00:55:27):
There you go. So, I think there's a balance, right? For example, I want to be in Web3 for more than a decade. I want to stay at Alchemy for a very long time and help build the company. So, I guess when I think of map, maybe an important way to think about it is maybe when somebody is 50 or 60 or 70 and they might choose to stop working, a lot of people when they start their career actually have 30 years to play with or 40 years or 50 if they're lucky. That's a lot of chips you can play. You could do five, 10 year rounds, right? And so, I think that in terms of sticking it out, maybe I'm biased, I think that some of the absolute sort gems, if you will, in Silicon Valley and tech are the teammates that are willing to stay around for 4, 5, 6, 7 years, and they have institutional knowledge that nobody has. They have a positive impact on the culture that is impossible if there's constant employee turnover.

Jason Shah (00:56:19):
So, to me, I think that you could simultaneously be somebody who's committed to companies, stays for a very meaningful amount of time, but zooms out and looks at their career. Actually, I think maybe this was even more, right? You're now a famous podcaster. You were a successful startup founder. You were a product leader. All these things form a map and I think a really interesting career and life, frankly, that's pretty full with a lot of really interesting milestones and learnings and networks and people that you get to interact with.

Lenny (00:56:47):
Yeah. To your point about how long a career is, when I thought about it recently, this is my fourth career. First it was an engineer, then it was a founder, then a product manager when I got to Airbnb, and now this weird thing that I do, and there's so much time to explore and try new things. I will say though, I feel like the early things you do seem really important. Airbnb for me was not early, so maybe I'm wrong, but it feels like you want to work at a company where people look at that on your resume and are like, "Oh, okay, this person's probably good." So, I feel like there's that piece you got to get right at some point.

Jason Shah (00:57:21):
Yeah, I totally agree with that. For example, I think for let's say a new grad who's thinking about a product career, and let's say on the spectrum there is maybe Goldman Sachs because that's what a lot of people are doing. They're like, "Yeah, I want to do product, but I also feel like I need this gold star or whatever." And then in between is you could join a hypergrowth company of some sort where they definitely have good product people you can learn from, but definitely still room for you to do more than what a very junior person would be assigned to be doing. And then on the other end of the spectrum is I'm going to have no job, I'm just going to completely bounce around from my own projects or just work with a new startup every two months.

Jason Shah (00:57:58):
Personally in that spectrum, I tend to be more towards the middle of that where build a track record, build a network. I mean, it's crazy. Even just this week, next week I'm seeing maybe five people that I know from my Yammer days, and to your point on formative nature, some of those people, that's how I learned how to do product. That's how I learned things like AB testing. It's how I had the first angel investors in my next company. That's how I hire. I still hire people, maybe much to their chagrin, they still get LinkedIn messages for me trying to push them for the next thing.

Jason Shah (00:58:27):
So, I totally agree that those early days are really formative, and there's maybe a balance between nobody wants to be a job hopper, but at the same time maybe there's ways to also not just be a career person who spends kind of 30 years working up the ladder or is fixated on I need to be CPO but is willing to give up a director title to go be a hustler at some startup because they really believe in it and they want to take a bet or risk in their career.

Lenny (00:58:50):
You touched on hiring, and that's something I wanted to ask you. So, you're in my Talent Collective. You're a company that's hiring, Alchemy, and I was looking at the stats recently, and you're one of the most successful companies at getting candidates to talk to you, and generally I think you're just really good at hiring. So, I'm curious what you can share with folks about hiring.

Jason Shah (00:59:10):
I appreciate that, and I get a lot of value out of meeting some really talented people from the Collective. I think hiring, it's funny, it reminds me of sort of push back in a sense of what you call it has such an impact on how people think about it. It's hiring, recruiting, but if people reframe it as the people you are going to work with every day or the people who make the company what it is, it shifts the mindset. It's like how is that not the most important thing to be thinking about as a leader or as a founder. A lot of people have benchmarks. I think maybe on the Google podcast I talk about 30%, 40% of a founder's time maybe spent on recruiting because I think deep down everybody understands that that's incredibly valuable.

Jason Shah (00:59:53):
I think that for me personally, I was reflecting ahead of the podcast on how I approach things now after different stages of hiring, and for context, for what it's worth, I've been at the zero person startup. It's just me and I'm trying to convince some Google engineer to come join us which is incredibly hard and has a low hit rate, to a place like Amazon or Airbnb where you have a large world-class recruiting organization that is effectively doing sourcing for you and setting up interviews and such things like this, and there's formal calibrations and interview panels, to a place like Alchemy where it's very sort of scrappy. We need to figure out who we even want to hire. The founders still meet with every candidate. It's a really different environment.

Jason Shah (01:00:34):
So, this is kind of the spectrum that I've seen, and I was reflecting what do I think works the best, and I like to think of it in very similar motions to a business where I think there is a marketing aspect to it, there was a sales aspect, and there is a product aspect to it. What I mean by that is that on a marketing level, I think what has a person heard about your company. Do they know anybody who works there? Do they read your LinkedIn post about things and already know that you're a known quantity before they even step in the door to interview? Are they even willing to interview based on what they know about the company? And so, I think that the marketing aspect in it, and I mean it's sort of lower case marketing in this sense of course because I think a hard sell of any sort or anything that's not authentic is probably going to fail ultimately, but it's about developing a really positive kind of brand and reputation for a company but also as an individual.

Jason Shah (01:01:26):
And then if you pass that threshold, I feel like there's a sort of a sales process, and we were talking about how bad of a salesperson I am, for example, because I didn't listen to people's pain points and understand the one or two things that were most important to them. I think similarly in this context, if they're an engineer, do they want to work in a world-class engineering organization? If they're a product person or they're just really excited about crypto and they want to find a way in, a place like Alchemy's the best place for them to learn that is how to think about it, and it's not about misdirecting on or matching whatever they say, but it's about really understanding who they are and what motivates them and what they're excited about because I'm as concerned about the kind of post-hiring step as I am the pre-hiring and want them to work out and be happy and be effective.

Jason Shah (01:02:12):
And then lastly, I think there's a product angle to it that not a lot of people think about or talk about a lot because I think the product, it's one of those rare cases where job descriptions are almost like product specs, right? They're here's what the responsibilities are, here's what we need you to do, here's the qualifications we're looking for. And what's really funny about that is that product is very iterative, but somehow we just write a job description, and then it's bait, it's done, it's posted, and nobody thinks about it again until the person's hired and then they take it down.

Jason Shah (01:02:41):
I think taking a product mindset where I meet people all the time now where I don't really know exactly what role they're necessarily going to fill, I'm not really sure about exactly their seniority, maybe they don't have a lot of experience, but maybe they would just totally be a rockstar on our product team. And looking at a product that we can mold flexibly and think of the same way if at Airbnb, if we were going to build Airbnb Plus, if we just kind of came back to the Amazon working backwards and just wrote a document and it was over, that's one thing, but we didn't do that, right? We went and actually built rooms and homes that were supposed to be Airbnb Plus, and then we iterate on it and we changed the pillows and we changed the entrance and we changed the scent that you feel when you walk in. We coach host and learned about that.

Jason Shah (01:03:21):
So, I think a product mindset on hiring and iterating on it based on the candidates you're meeting, the needs of the business. So this kind of marketing, sales, product combination has been what I've found to be really effective at getting people excited, understanding who they are and what they need, and then crafting a role that actually makes the person successful, rather than just checks a box in your recruiting software as some new headcount that was hired.

Lenny (01:03:45):
One last question before we get to our lightning round. For PMs that are listening to this maybe early in their career, what skill have you found to be most important in helping you and helping PMs in general advance in their career?

Jason Shah (01:03:59):
Yeah, this is a really important question, like the others, but I think that understanding and defining what problem matters is the most important skill that I think I've taken away, and it applies to so many things. It can apply to a specific product we're building. It can apply to what a company's mission is. I think I've found it really effective because it affects pretty much everything. It affects what we're going to build. It affects is the team motivated by what we're doing. So, specifically for example, at a place like Alchemy where, yeah, we're a developer platform, but should we build an SDK so there's abstraction that is easier for developers to use? Should we build an NFT API because we think that's a really important stack to move into and an important use case to support?

Jason Shah (01:04:45):
Well, the question is what problem are we solving? It's not this versus that just in a vacuum. It's is the problem developer experienced and we want to make things easier to develop. Is the problem that an NFT marketplace, a whole suite of them are trying to grow and need more support from us, and not understanding these problems clearly? And it goes back to my first company. It was an education company, and the problem was that low-income students didn't have access to the same resources to get into college as other students, and that guided everything. That guided the pricing model which was basically free for a long time, and then we monetize on sponsorships from colleges, right? The problem matter, whereas the problem solve was there's not a... A different problem was there's just no good college readiness program. Fine, then you focus manically on the pedagogy and the curriculum and so on and so forth, rather than say the business model and an initial product that you think can work.

Jason Shah (01:05:34):
So, that's what I've found to be the most useful, and I can give her other examples if it's helpful, but understanding what problem we're actually trying to solve and really getting crystal clear about it, I think has been incredibly useful to me and energizing as well.

Lenny (01:05:48):
It's such a good reminder, even though it's such a cliche of product managers being, "Well, what problem are we trying to solve here?" People hate that, but Michael Paul, and I mentioned this on a different podcast too, he makes this point that when you do drugs sometimes, you have these epiphanies that you come out and you're like, "Love is all you need, man." It's like, okay, yep. But it feels so right. You really feel it. The reason that it's such a cliche is because people have found it to be so true for so long that it's annoying now, but it also tells you how true it is. And so, I think it's a really good reminder of yes, it's annoying to ask that question, and people make fun of PMs for that, but that's because it's so damn important.

Jason Shah (01:06:28):
Just a brief kind of additional, what you share there, I mean, I completely agree. I think it's very true in life, right? It's like, well, what matters? And it's like, well, your health, your family, your sense of purpose. It's like nobody's unfamiliar with the answer, but like most things, it's about the application of it and about the nuance of it, and I think that's what product is ultimately sort of all about too.

Lenny (01:06:48):
Awesome. Are you ready for our lightning round where I'm just going to ask you five quick questions, tell me what comes to mind and we'll have some fun. Does that sound good?

Jason Shah (01:06:58):
That sounds great. Ready.

Lenny (01:06:59):
Okay, cool. I think I'm going to start adding music to these things. I got to figure that out. For now, no music. Okay. What book do you recommend most to other PMs?

Jason Shah (01:07:07):
The Hard Thing About Hard things.

Lenny (01:07:10):
Can you add why?

Jason Shah (01:07:11):
I think it teaches product managers to chew glass and care about outcomes the way that a CEO has to, and I think that's a really useful mindset to have.

Lenny (01:07:21):
Man, this chew glass metaphor, I don't like the sound of that.

Jason Shah (01:07:24):
I saw you cringe. I was a little worried about that.

Lenny (01:07:27):
Oh my god. What a great job we have here, chewing glass. Okay. Other than Alchemy, what's a company you recommend most to PMs to go look for new gigs if they're looking around?

Jason Shah (01:07:37):
I would suggest Polygon, Salon, or MoonPay. I know it's three, but I wanted to give some breath in the Web3 space that might be exciting to people.

Lenny (01:07:45):
Great, great choices. What's a favorite TV show or movie that you've recently watched?

Jason Shah (01:07:48):
The Ken Burns Vietnam War series. I'm really into documentaries and history, and it's a really kind of compelling version of history that I've never seen before.

Lenny (01:07:58):
Awesome. Love that. Okay. Favorite interview question that you like to ask.

Jason Shah (01:08:02):
What is a risk you regret not taking, why, and what did you learn about yourself?

Lenny (01:08:08):
What do you look for in an answer there?

Jason Shah (01:08:10):
I think the biggest thing I look for is a growth mindset, to be able to reflect on an experience like that and be vocally self-critical without unproductively being hard on one's self, and I think that the dimension of asking about risk gets at their psychology and how do they think about not only their career, but if they were to work with me, how would they approach problem solving and taking bets on the business.

Lenny (01:08:33):
Awesome. Okay, final question. What's your least favorite vegetable?

Jason Shah (01:08:36):
Broccoli. I just removed some from a pizza last night that I really didn't want to eat.

Lenny (01:08:41):
Wow. Oh wow, okay. Even like steamed, cook, all the things?

Jason Shah (01:08:45):
There are no circumstances under which I'm excited about broccoli.

Lenny (01:08:49):
Oh man, you got to eat those veggies.

Jason Shah (01:08:51):
I know. I'm working on it.

Lenny (01:08:52):
Okay, Jason, this was amazing. Lived up to what I was hoping our second episode would be. Definitely better than our first which we'll leave on the cutting room floor. Two last questions. Where can people find you online? I assume Alchemy's hiring, so maybe pointing people there. And then how can listeners be useful to you?

Jason Shah (01:09:08):
Yeah, definitely. So, if you're interested in Alchemy and Web3, go to alchemy.com and click through to our jobs page from there. I'm online @0xShah. That is my crypto pseudonymous handle and happy to engage with folks there. And in terms of being helpful to me, I would love any feedback on anything that came up. I would love any products that people are working on. I also invest, and we also partner with a lot of products and teams at Alchemy, and I would love to meet anybody that's listening on the podcast too because I know Lenny's all about community and has kind of given so much back over the years that I would love to meet folks that are out there and get a chance to spend time talking about the products that you're all building.

Lenny (01:09:46):
Awesome. Thanks, Jason.

Jason Shah (01:09:48):
Thanks, Lenny.

Lenny (01:09:50):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## What world-class GTM looks like in 2026 | Jeanne DeWitt Grosser (Vercel, Stripe, Google)
**Guest:** Jeanne Grosser  
**Published:** 2025-11-30  
**YouTube:** https://www.youtube.com/watch?v=RmnWHz8HD74  
**Tags:** growth, retention, metrics, kpis, iteration, experimentation, data-driven, analytics, funnel, conversion  

# What world-class GTM looks like in 2026 | Jeanne DeWitt Grosser (Vercel, Stripe, Google)

## Transcript

Lenny Rachitsky (00:00:00):
I've been getting so many asks for go-to-market help.

Jeanne DeWitt Grosser (00:00:03):
With AI, it's just intensified because you have 10 players pursuing the same market opportunity and so your ability to actually bring the product to market to differentiate yourself from the competition has become more strategically important than it was previously.

Lenny Rachitsky (00:00:18):
I had Jenna Abel on the podcast recently, one of her tips is you don't want to be focusing on here's the pain and problem we're solving and instead focus on here's how you will be better than your competitors.

Jeanne DeWitt Grosser (00:00:27):
80% of customers buy to avoid pain or reduce risk as opposed to increased upside, which is a good thing for startup founders to understand. We all love to talk about the art of the possible, everything we're going to enable in the future, but that's often really a sale that's going to resonate with another founder. For everybody else, particularly enterprises. You're avoiding the risk of not making your revenue target next quarter.

Lenny Rachitsky (00:00:52):
I've heard a lot about how you think about go-to-market as a product.

Jeanne DeWitt Grosser (00:00:55):
We buy a lot of things because of how we feel about them. The experience that you have of being sold to will increasingly actually differentiate a company and drive buying decisions if products are only different at the merchant. And so then you really want to create a customer buying journey that feels like very unique experiences.

Lenny Rachitsky (00:01:17):
Something I've heard from so many people you've worked with is that your superpower is building a sales org that doesn't feel like a sales org to engineers.

Jeanne DeWitt Grosser (00:01:23):
The litmus test I have always given my sales team is if you are an account executive in my org and I put you in front of 10 engineers at our company, it should take them 10 minutes to figure out you aren't a product manager.

Lenny Rachitsky (00:01:38):
Today my guest is Jeanne Grosser. Jeanne was chief product officer at Stripe where she built their very early sales team from the ground up. She's currently COO at Versel where she oversees marketing, sales, customer success, revenue ops and field engineering. Jeanne has built world-class go-to-market teams at multiple unicorns and has advised dozens of companies on doing the same. In our conversation, we go deep on what a world-class go-to-market team looks like, including what the heck is go-to-market, the rise of the go-to-market engineer and how this role is already enabling her team to operate 10 times faster. A bunch of very specific tactics to level up your go-to-market skills, a primer on segmentation, how to think about your go-to-market process like a product, her favorite go-to-market tools, her hot takes on PLG and sales comp and sales hiring, and so much more. If you are looking to get smart on the latest and greatest in go-to-market thinking, this episode is for you.

(00:02:34):
A huge thank you to Claire Hughes-Johnson, Kate Jensen and James Ditt for suggesting topics for this conversation and Kelly Schafer for the connection. If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. It helps tremendously. And if you become an annual subscriber of my newsletter, you get an entire year free of a ton of incredible products including Devon, Lovable, Replit, Bold [inaudible 00:03:00], Linear, Superhuman, Descript, whisperer flow Gamma, Perplexity, Warp, Granola, Magic Patterns, Ratecast JPRD, Mob In Hand, Stripe, Atlas. Head on over to Lenny's newsletter.com and click product pass. With that, I bring you Jeanne Grosser after a short word from our sponsors.

(00:03:14):
This episode is brought to you by Datadog, now home to Epo, the leading experimentation and feature flagging platform. Product managers at the world's best companies use Datadog, the same platform their engineers rely on every day to connect product insights to product issues like bugs, UX, friction and business impact.

(00:03:32):
It starts with product analytics where PMs can watch replays, review funnels, dive into retention, and explore their growth metrics. Where other tools stop, Datadog goes even further. It helps you actually diagnose the impact of funnel drop-offs and bugs and UX friction. Once you know where to focus experiments, prove what works. I saw this first hand when I was at Airbnb where our experimentation platform was critical for analyzing what worked and where things went wrong and the same team that built experimentation at Airbnb built Epo. Datadog then lets you go beyond the numbers with session replay. Watch exactly how users interact with Heatmaps and Scrollmaps to truly understand their behavior. And all of this is powered by feature flags, that are tied to real-time data so that you can roll out safely, target precisely and learn continuously. Datadog is more than engineering metrics. It's where great product teams learn faster.

(00:04:25):
Fix smarter and ship with confidence. Request a demo at datadoghq.com slash Lenny. That's datadog hq.com/Lenny. This episode is brought to you by Lovable. Not only are they the fastest growing company in history, I use it regularly and I could not recommend it more highly. If you've ever had an idea for an app but didn't know where to start, Lovable is for you. Lovable lets you build working apps and websites by simply chatting with AI. Then you can customize it at automations and deploy it to live domain. It's perfect for marketers spitting up tools, product managers, prototyping new ideas, and founders launching their next business. Unlike NoCo Tools, Lovable isn't about static pages. It builds full apps with real functionality and it's fast. What used to take weeks, months or years, you can now do over a weekend. So if you've been sitting on an idea, now is the time to bring it to life. Get started for free at Lovable.dev. That's Lovable.dev.

(00:05:29):
Jean, thank you so much for being here and welcome to the podcast.

Jeanne DeWitt Grosser (00:05:32):
Thanks for having me. Lenny.

Lenny Rachitsky (00:05:34):
What I wanted to get out of this conversation by the end of this to basically have this conversation be the thing that we send people when they're like, "I want to get better go to market. I'm trying to figure out what to do and get to market." We send them this versus having to hire someone for a lot of money and usually they can't find amazing people, because they're all snatched up. So let me start with just the basics. When people hear at the term go to market, what does that mean? What does that encompass?

Jeanne DeWitt Grosser (00:05:57):
I think there are two answers to this. Often what people think of is sort of the tip of the spear of what drives revenue, which is marketing and sales. For me, I think of it as any function that is going to touch a customer or make a dollar, and actually my remit at Vercel is that, so that includes marketing, sales, all of your technical sales roles like sales engineers or post-sales platform architects is what we call them at Vercel. It's customer success, it's support, it's partnerships. And the reason I say that is my experience throughout my career has been that those functions often have this Venn diagram strategy where marketing's pursuing one thing, it overlaps with what sales is pursuing, but not perfectly, which also overlaps with what support is pursuing but not perfectly. Examples of this would be slightly differing segmentation frameworks, et cetera.

(00:06:57):
And so one of the things I think you're going to want to see more in this particular moment is that that become a really integrated lifecycle. In particular, I think we're going to see a lot of the functions of go-to-market get redefined, so we've gone through a period of hyper-specialization in go-to-market depending on how you count them. There are, I think somebody quoted 17 different roles within go-to-market these days and I hypothesize that a lot of those are going to start to collapse. And so if you think of go-to-market more holistically, I think you can kind of go back to what are the jobs to be done from making a customer prospect aware of your product all the way through to high LTV, five years on the platform, fully wall-to-wall, and you're going to want to map that out and orchestrate it the way you would think about that within your own product.

Lenny Rachitsky (00:07:54):
Awesome. We're going to go through that whole cycle of go-to-market, but so is it safe to say just for most companies that are especially starting out when they say go-to-market, that mostly is sales and then there's marketing as maybe a smaller fraction of that and then as you become more advanced and grow, customer success plays into it, tech sales, things like that?

Jeanne DeWitt Grosser (00:08:12):
Yeah, that's probably where most start is getting sales or frankly just because a lot of companies also start PLG, you might actually start with marketing and then you're layering in sales when it's time to do the sales assistant and ultimately sales led portions. So I think it can, depending on your product and your initial target market, it can either mean marketing or sales or a combination of those two.

Lenny Rachitsky (00:08:33):
Awesome. So essentially it's like the term go-to-market tells you what we're talking about. How do you take your product to market, get people aware of it, using it, sticking with it?

Jeanne DeWitt Grosser (00:08:42):
Yep, absolutely.

Lenny Rachitsky (00:08:44):
What has most changed in the world of go-to-market over the last few years? You've done this for a long time at Google, at Stripe, you built it for sales team, now you're doing that at Vercel. What's changed most in the skill and art of go-to-market?

Jeanne DeWitt Grosser (00:08:55):
There are a number of things. So when consumption-based business models started, I think you saw go-to-market shift into being meaningfully more consultative because often that first land was the very beginning of the journey and represented a very small percent of what you were ultimately going to do with that customer. And so you had to go from being transactional to a lot more. You had to more deeply understand what that customer was trying to do so you could align that ultimately to your product. I think that has played out that much more with an AI because right now everyone knows they need to change, but they don't necessarily know exactly what they need to change to, whether that's their customer-facing product or their internal productivity and workflows. And so I think you're seeing a lot more of go-to-market orgs leaning into the art of the possible best practices, helping you actually think things through as if they were a consultant.

(00:09:52):
And so one of the things you see more of right now is forward-deployed engineering, which on some level is kind of a rebrand of professional services but kind of not. And a big part of that is, hey, how do I actually get into your environment, ride alongside you better understand what you're trying to do and then help you actually bring the technology to life and learn a lot along the way.

(00:10:18):
Often you're not only making that customer successful, but you're then taking all of that back to your product and engineering organization to figure out, okay, what was generalizable that we ought to build into our offering versus what is something that ultimately is going to be more of a professional service in the fullness of time. So I think that has been a biggie, is actually just really getting embedded with your customer. And then unsurprisingly, I think bringing AI to bear on the sales process is another big one. And so you've seen the rise in probably the last 18 to 24 months of the go-to-market engineer, which different folks define slightly differently, but it's kind of bringing one technical prowess to bear on go-to-market in general so you can have a lot better tooling, data use, et cetera. And then two, increasingly bringing AI to bear as well to re-architect your workflows and also make it so that it's easier to have a personalized experience with customers but do so at scale.

Lenny Rachitsky (00:11:23):
Amazing. Okay, let's follow the thread on this go-to-market engineer, so what was it like before and what are these engineers doing at companies?

Jeanne DeWitt Grosser (00:11:33):
So I think maybe an interesting story to tell. When I was at Stripe, we went to launch an outbound SDR function. So outbound prospecting and Stripe always ran lean. The company at that time had an operating principle which was efficiency is leverage. And so if you looked at the sales organization I was running, most companies out there probably would've had 30 SDRs and I was going to get four. So there's no way I was going to do the typical SDR approach and be successful. And so we thought to ourselves, okay, what can we do? We'll be super data-driven. And so we went and we started building project Rosland. Rosland is the scientist who originally mapped A-DNA. And what this was was effectively a company universe. So you can think of this as a massive database. Every row was a different company on the planet and every column was an attribute about that company that would help you sell to them in a more targeted fashion.

(00:12:39):
So at Stripe an example would be knowing that their business model was a marketplace was super helpful, because that would mean you wanted to sell Stripe Connect versus vanilla payments. And so the goal was basically, hey, can we create a mad Libs where I will come up with sort of a predefined email template, but 80% of it will be fill in the blank based on the different attributes of that customer. So if they're this industry or this business model, then pull this customer, reference this value prop, send it to this persona, not that. And we were trying to do this in 2017 and it was very hard and didn't actually totally work our ability to the false positive rate and we worked deeply with DSI and it just never really got there. And now that we're literally redoing here at Vercel as we speak and it actually works and you can bring AI to bear on it.

(00:13:41):
And so what's different is we now, I have a data scientist just like I did back in 2017, but I have a go-to-market engineer whereas before I just had someone in systems that was helping me configure outreach or sales off and my go-to-market engineer is helping me build an agent where we're coming up with, okay, well what's the human workflow that you would've done? And then how do you encode that using Vercel workflows as an example in actual code that's both deterministic and less so where an agent's going out and trying to replicate what a human might've done to produce that, fill in the blank, matlit.

Lenny Rachitsky (00:14:21):
I love the ambition of that project. What is this, like eight years ago?

Jeanne DeWitt Grosser (00:14:25):
Yes.

Lenny Rachitsky (00:14:26):
I love the big thinking there. We're going to map the entire universe of companies and then here's how we sell to them. And then just I'm trying to picture doing that without AI. It's like crazy to imagine trying that without AI and that's so much simpler to even imagine.

Jeanne DeWitt Grosser (00:14:38):
Well the thing that's amazing about that, just to geek out on a second, so I was working on that with a bunch of folks at Stripe on my team, obviously at a gentleman named Ben Salzman who went on to go to ZoomInfo and then actually recently just founded a go-to-market startup that is basically sort of productizing that concept of a company universe and then layering AI on it on top of it. And ultimately his view is actually AI will get to the point that you won't have to do outbound prospecting because it will just sort of company and product match. So it's fun to sort of see back in 2017 some of the folks doing that now work at OpenAI, they work at Anthropic, they also are doing GTM Eng. You've got him starting a totally AI native GTM company and then here I'm at Vercel trying to do the same.

Lenny Rachitsky (00:15:29):
Okay, so what's cool is this is an emerging role, an emerging skill that I don't think a lot of people have recognized as something that is happening. So one example I'm hearing of what this role does is they automate outbound emails essentially and outbound outreach. They figure out, they write workflows and agents that figure out here's the company to go after, here's how we message them. Does that end up being kind of like an email that's custom designed and written for this prospect?

Jeanne DeWitt Grosser (00:15:54):
That's one version. So it's broader than that really. Basically the full remit of GTM Eng will be to go through each of the different functions within go to market and break down all the different workflows that they do and then turn those into agents where AI is better placed than the human to do that task. So right now we started with actually inbound and are now moving to outbound because that workflow is most legible. And by legible I mean you can basically write it down. It's relatively replicable, mostly deterministic. So it's more likely that AI will do it well and we actually built the agent and then we keep a human in the loop. But from there we're starting to look at outbound and with an outbound we're starting more at the lower end of the market, where you tend to have slightly less customization because there's a single decision maker at the company.

(00:16:56):
But I think it'll take a while before we're able to really do that in a very large enterprise. There we might use an agent for research but maybe not all the way to actually send a message and that's just within the prospecting function. So other places that we're looking at this would be for install-based sales. So again there it's a little bit more deterministic because you've got awesome internal data on what a customer is and isn't using, what's the next best action? What's the thing they should get most value from? So that's where we're starting to map, hey, what does that ideal workflow look like? But basically you want to get to a state where as long as I've been in sales, they release these annual reports that help us all benchmark ourselves relative to one another. And one of the stats is what percent of time do your sellers actually spend in front of customers?

(00:17:44):
And for the 20 years I've been in sales, it's always been somewhere around 30% to 40%. So the minority of time is actually talking to other humans and I think we're getting to a point where with layering in agents, ideally we finally get salespeople to a point where they're actually spending 70% of their time interacting with humans and we can get the research, the follow-up, the things that are a little bit more rote and don't use the entirety of your human capacity done by an agent and then sort of unleash you to go deeper with your customers.

Lenny Rachitsky (00:18:17):
I love that this is such a great example of where AI is contributing in a very meaningful high ROI way, taking on all this work that people... like, you have to hire say 50 SDRs as you described to do and now you could do with a lot more. So it's a really cool example of leverage that AI gives you. One thing that I know a lot of people think about when they hear this is, okay, I'm going to get more of these really bad emails trying to pitch me on stuff and just like this isn't going to work. I can tell this is AI. What have you learned about how to do this where people actually receive emails that actually convert and do well?

Jeanne DeWitt Grosser (00:18:51):
Our processes all always have human in the loop. And so basically where we'll start is we take a go to market engineer and we have them shadow the highest performing individual in that function. And so you can go and you shadow an SDR and you can see, oh wow, they've got seven tabs open. They're looking up the person on LinkedIn, they're reading about the company, they're doing chatGPT on this, they're looking in this database to get these sets of attributes. And so that's how you sort of inform the initial workflow. And then what we do is we let the agent make a call. So in the specific example with inbound, you have to determine whether or not you think the lead is likely to be qualified and then you have to determine what to say to it. And so we'll let the agent make those two calls.

(00:19:44):
It ultimately then does some deep research, pulls in a bunch of information from our databases and crafts a response, but we have a human review all of those and actually hit send. Now for us, we had 10 SDRs doing this inbound workflow and now we just have one that is effectively QA-ing the agent. The other nine we deployed on outbound, so we got to move them up the value chain. At some point I think we'll get to a place where we feel like, "Hey, the human reviewer is saying yes enough of the time that we feel confident that these will be on brand targeted, et cetera," but right now we're still trying to train the agent and it incorporates feedback on what we choose to reject, edit, et cetera.

Lenny Rachitsky (00:20:31):
And you shared that it's already having a lot of impact. Like you said, you had 10 SDRs and now one can do the job of 10.

Jeanne DeWitt Grosser (00:20:39):
So before we did that move, I mean the other thing that's just incredible about this is the person who built the lead agent was a single GTM engineer. He spent maybe 25-30% of his time on this. It was six weeks before we felt confident going from 10 to one. So it wasn't like this was a multi-quarter process, it actually moved super quickly and then again now we just sort of keep that agent manager working with the agent to get it to a point where we say, "Hey, we're ready to roll." Actually throughout the process we also tracked all of the KPIs that you typically would hold an SDR accountable to. We were looking at our lead to opportunity conversion rate, we're looking at the number of touches it takes the time to convert, and basically what we were able to do is hold that lead to opportunity conversion rate flat. So the agent is as good as our humans were, but it's actually condensed the number of touches it takes to convert because it's so much quicker at responding relative to leads inevitably sitting in the queue or coming in at nighttime and no one can get to it, that type of deal. So that's sort of when we knew it was ready to pull nine people off and shift them into outbound.

Lenny Rachitsky (00:21:56):
That's incredible. Okay, that's interesting. So you shift them to outbound. What I love about this is this SDR that is now doing this is, as you said, doing the things they enjoy more, they're talking to customers more, they're not doing all this kind of top of funnel rote work. I don't want to get into whole jobs AI discussion, but there's always been this talk about AI SDRs basically replacing SDRs. It feels like that's one thing where everyone's like this is a hundred percent going to be AI in the future. What I'm hearing here is it gives one Aster a lot more leverage and obviously you still need people running the show. Thoughts there? Just like do you think AI will replace all this at some point? And then I don't know, you don't need salespeople?

Jeanne DeWitt Grosser (00:22:32):
I think on prospecting it can replace a fair amount because the average SDR wasn't doing overly sophisticated research in the first place. So where I, think the last part to go as I mentioned will be in deep enterprise prospecting where you can be at multiple layers in an org chart, you've got to pick between business lines, you've got to triangulate those. But I do think for the things that are more repetitive that often don't take that much time to learn and get ramped, AI will be good at that. And in my view, no one graduated from college and was like, "Yes, I just went to college for four years to become an SDR." It was more, "Okay, that's where you are forced to start." But I think the average SDR could have gone straight into outbound or straight into an SMB closing role. And so basically what we're just doing is shifting folks into something that uses more of their full capacity right out of the gates rather than sort of the forcing function of working your way up the totem pole.

Lenny Rachitsky (00:23:48):
Awesome. Since a lot of people listening to this aren't salespeople don't have a lot of background in sales, we've used this term SDR, there's also the term AE. Can you just help people understand what is an SDR, what do they do, what's an AE, and then what's the role above?

Jeanne DeWitt Grosser (00:24:01):
Sure. So SDR is typically in charge of generating pipeline. They're meant to talk to prospective customers and get them to a point where it is worth investing time to run them through a sales process. You typically have two types of an SDR, have an inbound one. So this is where people come to your website, they fill out contact sales, they'll be the first call to make sure that it's actually worth a more expensive account executive to go and run a sales process or you then have outbound. So this is where when you want to grow faster than your inbound demand, they will go out and at this point you probably have a point of view on where you think you have product market fit. And so they will target that part of the market and try to drum up interest from folks who weren't otherwise raising their hand saying, I'd like to talk to you.

(00:24:54):
So that's sales development basically. Pipeline generation account executives are closers. So it's their job to take somebody from, "Okay, hey, I'm interested in learning about your solution, I have a legitimate problem. I potentially could make a decision," to, "I now believe that your product is the best in the market for me and I'm willing to pay for it." And then account executives, depending on the segments that your company sells into E.G. small business, mid-market enterprise, et cetera, they may work their way up the food chain from selling to a smaller company like an SMB or a startup. Those tend to be a little bit more of a transactional sale. You often have a single decision maker to then going into a mid-market or a commercial role where now maybe you have an economic buyer like somebody in finance and a technical buyer like somebody in engineering to getting into enterprise where you have procurement and you have committees and 10 people have to weigh in and you've got to help them figure out how to de-risk the fact that they're probably migrating from something so much more complicated coordination effort to sell.

Lenny Rachitsky (00:26:05):
That was extremely helpful. So SDR, pipeline generation, i.e., closer. Such a simple way of thinking about it. Okay, this is great. Going back to the GDM engineer, a few questions for people that may want to try this at their company, what scale do you think it makes sense to start hiring for this role? Having someone automate in the go-to-market process?

Jeanne DeWitt Grosser (00:26:25):
What's interesting about this is it will force companies to be more rigorous about their sales process early. So often startups when they go from founder led sales to say, I'm going to have my first sales person, whether that's an actual account executive who has sales experience or your general athlete, wicked smart, who's going to go figure it out. Often founders will just say, "Okay, sales is showing up and talking to people. Isn't that what I just did for the last couple of years?" But actually sales is more than that. It's a skill just like writing code as a skill or building a financial model as a skill, it's about discovery. So asking all the right questions that help you identify challenges in pain, willingness to pay, et cetera, and then going through a process to handle those objections and showcase where are you at enough value such that somebody ultimately wants to hand over some money.

(00:27:24):
So often startups will get, particularly ones with strong product market fit to pretty significant scale without really having a replicable process. And you can't really apply go to market engineering unless you actually have a point of view on what best practice should look like. And so I think basically this is going to force folks to have more of a playbook out of the gates, what's working, what's not? Can I document it? Do I have content for the different parts of the sales process? And then once you do that, which maybe 10 people is a good size and scale for that, ostensibly a GTM engineer can come in and turn that into an agent. You could also argue that if you're a founder who wants to bring in a general athlete profile and that person is technically minded, that you could have a hybrid AE GTM engineer who figures out what their best practice is and then tries to turn that into an agent that's riding alongside them and making them more effective as well.

(00:28:26):
So I don't know that I have a point of view yet on what's the optimal size and scale, but I forever have given founders the advice that you often want to bring in revenue operations, which is basically the analytical arm of sales earlier than you think because having data, having process is actually what gives you insights as a founder into what is and isn't working. And so I would argue just like it's a good idea to have that sooner than later, increasingly it'll probably be a good idea to have GTM engine and be looking to bring agents to bear on your process at the outset.

Lenny Rachitsky (00:29:05):
While we're on this topic, just a quick tangent, the advice for hiring your first salesperson that I usually hear is wait until you're around a million in ARR. When you have a repeatable process, you can teach someone anything there. Does that seem right? What would you recommend?

Jeanne DeWitt Grosser (00:29:18):
Yeah, I think that seems about right. I do think as a founder you want to stay deeply connected to customers and get it to a scale and get it to a point where you use the word, there's some repeatability there. I think that's one of the things that not all founders get right is founders are incredible salespeople. They convinced a VC angel investors to fork over a bunch of money, so clearly they're going to inspire people to buy. But if you're getting to a million in ARR and the set of customers you have look nothing like one another, you still have very much like an evangelist sale, very much founder led sale versus if you can say, "Hey, I now have an ICP here, or ideal customer profile, e.g something you can write down. We are good. Our product fits with startups with less than a hundred employees who are typically building SaaS applications," something like that.

(00:30:14):
Then you're probably ready to hand over the reins. And then what founders have to remember is to actually hand over the reins. So you've got to enable the person who comes in, what is it that you're doing effectively, what's your content, what are the discovery questions you are asking? How are you handling objections so you can transition that knowledge but also don't handle them over entirely. You want to stay connected to the customer because you still have a fair amount of R&D to do to figure out where is the product next going to resonate, where are you getting stock as you scale, etc.

Lenny Rachitsky (00:30:52):
To close the loop on the go-to-market engineer, what's the profile of the ideal go-to-market engineer, may be your first.

Jeanne DeWitt Grosser (00:30:57):
What we have found works really well is somebody who does have go-to-market experience. So at Vercel, our first three go-to-market engineers we're actually sales engineers. So Vercel hires very technical sales engineers, all of them were front end developers before they decided they wanted to get into sales. And so we just said, "Hey, three of you, congrats." You're now founding members of our GTM Eng team. And the thing that works well there is you do understand aspects of what is good GTM, what does a process look like? It's been really interesting actually. So the gentleman who runs GTM Eng for me, we were going through this lead agent and QA-ing it. And so I'm going and I'm looking at some of the responses that we've ultimately had the lead agent send and realized, "Oh, I wouldn't have sent that and that's because I have 20 years of sales experience and we modeled the lead agent off our best person, but our best person who has two years of sales experience." So it actually is important to understand the art and the science of sales and how you bring best practice to bear. Either you've done it and so you know some best practice or you're going to geek out on sales, read a bunch of books, learn a thing or two, and try to incorporate some of those into your agent development.

Lenny Rachitsky (00:32:28):
That is really interesting. So come from the sales side, not from the engineering side. And I imagine this is such a cool opportunity for salespeople to do something completely different and move closer to engineering.

Jeanne DeWitt Grosser (00:32:38):
Yeah, I mean we're having a lot of fun with it. At Vercel in particular, we basically get to be customer zero. So everything that we're building with agents, we're building on Vercel's AI cloud. So these agents now have multiple steps that they go through. So we're using Vercel's workflow SDK and workflow offering. We use the AI gateway to call the different models that we use to do deep research or other enrichment that we do. So for us it's great because we basically sort of bang on everything the engineering team is building and get to go be a discerning customer before we actually get it out the door to real customers.

Lenny Rachitsky (00:33:22):
What a fun time to be alive. I could tell the fun that you guys are having, just from the way you describe it.

(00:33:29):
Stripe handles the massive scale and complexity of many of the world's fastest growing enterprises, including 78% of the Forbes AI 50 and more than half of the Fortune 100 enterprises like Atlassian, Figma and Urban Outfitters use Stripe to create fully branded and customized checkout pages with access to more than 125 global payment methods. There's a reason I've had more leaders from Stripe on this podcast than any other company. They know how to build great products that scale and that people love. And Stripe is a lot more than payments. They've also got a category leading billing solution and a highly optimized checkout experience built specifically to increase your checkout conversion. Join the ranks of industry leaders like Salesforce, OpenAI and Pepsi that are using Stripe to grow faster and to grow the world's GDP, learn how Stripe can help your business grow at Stripe.com. Zooming out a little bit in terms of you mentioned tools and tools that you use. I'm curious just what are kind of the state of the art tools within the go-to-market stack that you love that you'd recommend?

Jeanne DeWitt Grosser (00:34:33):
Well, so I'm going to have an interesting answer to this, so I'll give you one. And it's not state-of-the-art per se, although I don't mean that disparagingly, it's just that it's been around for a while now and a lot of folks use it, but I think Gong has gotten just meaningfully more interesting in the last year. And then second half of my question I will get into, I think the calculus on build versus buy is changing. So all right, Gong. Gong is incredible because you can run agents against it now. So we take all of our Gong transcripts and we dump them into an agent called the deal-bott, and that deal-bott then can do a bunch of things. So the first thing we had it do was lost opportunity review. So we had just finished Q2, we had a list of our top losses for the quarter sorted by deal size, and we ran it against that and it was incredibly interesting.

(00:35:39):
So the biggest loss that quarter according to the account executive was lost on price. And when you ran the agent over every Slack interaction, every email, every GONG call, it said actually you lost because you never really got in touch with an economic buyer. And when you talked to somebody about ROI and total cost of ownership, it was clear from their reaction that they didn't really buy your mass. And so really the reason we lost was an inability to demonstrate value, which upon reflection I've got work to do to build out how we quantify the value of Vercel, which actually is very easily quantifiable. It's one of the things I love about selling this product, but we got to codify that for the go-to-market team. So that was incredibly interesting and now we run it against all of our lost opportunities and actually do a much better job of categorizing why it was we really, really lost.

(00:36:38):
And then either feeding that back into the engineering team or back into marketing sales leadership on, hey, where are we falling short in the sales process? And so that was awesome, but then we're like, well, it's not very fun to lose, so why don't we pull that forward? And so we went from lost bot to deal-bott and now the deal-bott is running in real time and we basically feed insights into Slack. Vercel is incredibly heavy users of Slack, so we have a channel for every single customer, either opportunity or existing one. And so now we're feeding insights into that Slack channel which is, "Hey, you're this far into the sales process and you haven't talked to an economic buyer, you should think about that." Or, "Hey, you just got off that call with an economic buyer, didn't sound like it went that well. Here's some things to consider and how you might follow-up."

(00:37:34):
And last thing before I pause, the other thing that's really interesting and how we're using this too is we are in this moment where I have never seen an iteration velocity exists now in my career. My 20 plus year career has all been in tech. And so for go-to-market teams, that's really hard. If you are launching something every other day, the ability to be enabled on that is actually quite challenging. And so this bot agent is now also letting us, where we're starting to go with it is we'll release something, we'll do our best to enable the team, then we'll go run the agent across calls, interactions, and we'll diagnose where we did a bad job of objection handling, where we're getting stuck. And then at the end of the week we can have a huddle and say, okay, what are all the places that our agent would suggest we aren't selling effectively?

(00:38:34):
And then almost like an engineering team, we'll now run sprints, which is like those are just bugs. They're bugs in your go-to-market process, so you should not have them. And by the next week we're going to add content to our objection handling to guide. We're going to add content to a discovery guide, we're going to figure out something we need to change about our demo, so on and so forth. So that's early. That's a little bit of a preview, but that's where we're talking about taking things right now within our go-to-market orgs.

Lenny Rachitsky (00:39:00):
Jeanne, you're blowing my mind in so many ways, it just sounds so fun and just you guys are going to win is what I'm feeling when I hear all this. Incredible. What I love about this is this AI tool, this agent you built sees things that humans were not seeing. The fact that you were surprised of just like this is a completely different conclusion is such a big deal. This is the whole promise of ai, it's going to do things we aren't even thinking about or capable of.

Jeanne DeWitt Grosser (00:39:26):
It is. We had a really interesting, one of the things we're doing at Vercel, we have an AI cloud, so people use that to put AI-native features into their customer-facing applications, but they're also using it to build internal applications to improve productivity or outcomes. And we are talking to a very large airline and that airline obviously gets tons and tons of support queries. So of course they would want to go apply AI to hey, how can we have AI answer these so that our cost to support goes down, sort of the obvious thing. But the more interesting conversation was actually with one of the C-level executives who said, we also actually transcribe every single one of those support calls. And so what I really want to know is why are they calling and how do I make it so that fewer people call the next week? And so again, this is now with AI, you can rapidly go through all of that content and actually be able to much more quickly than having a human in your CRM sort of pick some status why it was that folks were calling the airline this week and what if anything you can do to make it less the case next week.

Lenny Rachitsky (00:40:39):
I imagine many people hearing this are like, "I need one of these deal-botts and lost bots." These are all internal products that you all built?

Jeanne DeWitt Grosser (00:40:46):
Yes.

Lenny Rachitsky (00:40:47):
Is there anything that you've learned about making them this good? Any tips you can share of here's how to make a really good bot for sales?

Jeanne DeWitt Grosser (00:40:54):
Yes, so actually that's the second half of my answer that I forgot.

Lenny Rachitsky (00:41:00):
That's perfect.

Jeanne DeWitt Grosser (00:41:00):
Which is sort of like bill versus buy calculus. So I think one of our learnings is that it's not that hard to build these agents and they aren't that expensive either. So I mentioned the lead agent that was a six-week process with one human, a third of his time, that deal-bott, the lost bot version was two days basically we riffed on it, he had it 40 hours later. Now we're continuing to refine it for the other things I mentioned. And what's also interesting about them is they for better or for worse for Vercel, but that lead agent which runs full stack on Vercel, will cost us about a thousand dollars to run for the entire year. If you remember I told you we had 10 people in the SDR function, so I'm paying well over a million dollars for that from a salary perspective.

(00:41:57):
I got that down to one. And then behind that I have a lead agent that costs a thousand bucks. So that's like a 90%-plus reduction in total cost there. And there's lots of software for agents out there right now. And I think one of the things we're learning is because this whole space is so nascent, often your own esoteric context, your content, your workflow is really key to unlocking the power of the agent. And so I think there's real value in experimenting with your own internal agent development. We may ultimately end up on better integrated agent platforms in the fullness of time, or we may find that the CIO increasingly goes from a procurer of software to a builder of software and you'll have an AI internal platform with a thousand agents running across your org. I'm not really sure yet. But I certainly think there's value in trying it yourself because you may find that it's meaningfully easier than you think and you get returns pretty quickly.

Lenny Rachitsky (00:43:10):
So what I'm hearing here is that you're finding that there are not tools out there to plug and play. The alpha is essentially in building your own stuff.

Jeanne DeWitt Grosser (00:43:18):
I think that's partially true, and I think because you also have all these tools proliferating right now, you get into the perennial problem where you wind up with 20 of them to do the 20 jobs to be done basically, rather than an integrated platform that's doing all of them. I'm hearing this a lot actually when I'm talking to customers right now where their biggest issue in deploying AI is actually just getting through procurement and it's because got an AI mandate, you kind of have a blank check. I recently heard the term of instead of ARR, it's ERR, which is experimental run rate revenue, which is to say everyone's out there sort of, Hey, we're going to give this thing a go for a year and then TBD on whether or not we keep it. But basically you're having to procure 20 different things. Most things are getting off the ground and so they're solving something relatively narrow and that'll change in the fullness of time. But I do think there's an opportunity to figure out, hey, where do I likely have a more specific workflow internally. For that it might be worth building your own agent and then maybe for the things that are a little bit more generalizable, you go get something off the shelf.

Lenny Rachitsky (00:44:34):
Are there any platforms or tools that you want to shout out that allow you to build these agents so quickly? I know they sit on Versel, so shout out Vercel. But just anything that you point people to you to... These SDR, these GTM engineers, they're former salespeople. Are they learning to code? Are they byte coding these agents? How does that work?

Jeanne DeWitt Grosser (00:44:52):
So our sales engineers all have CS degrees. So they were engineers in a sales capacity, so they're writing code and actually these agents, they're building directly on Versel. So you get the AI gateway that lets you call different models. You have a sandbox if you're running untrusted code, you've got workflows that let you build the process. You've got fluid compute, which lets you really efficiently use compute when you only need it. So we're just sort of building it from the ground up here. Again, it's not that hard. Now you do need to write code for that. Certainly there are a lot of vibe coding tools out there that also give you more workflow builders that are somewhere between fully WYSIWYG, almost like drag and drop and a little bit more code forward. So you've got a bunch out there along those lines. But I do think we've sort of found one of the reasons actually the GTM Eng team at Versel can build these agents so easily is because the Versel platform is making it that easy to use our framework to find infrastructure and get that agent onto into production very rapidly.

Lenny Rachitsky (00:46:11):
What a neat, unfair advantage you all have to do this stuff.

Jeanne DeWitt Grosser (00:46:13):
Yes, it is fun to... I mean, I do think this company is better than any I've seen at eating its own dog food and just everyone is constantly, we say Versel builds Versel with Versel. So you're just always looking for ways to, Hey, how can we use our product to go do what we need to do? And as a result, either understand then what a customer would want or what's missing from our product that we could go make better.

Lenny Rachitsky (00:46:37):
Along these lines, something that's already come across a lot in the way that you described this stuff is I've heard a lot about how you think about go-to-market as a product. A lot of people listening to this, as I've said, are product builders. So I think this is a really nice way of thinking about go-to-market. I'm guessing you've already talked about elements of this, but just what's a way to think about go-to-market as a product?

Jeanne DeWitt Grosser (00:46:56):
Yeah, I've always, so I had this realization probably a little over a decade ago in my career. So my first job out of college was working on Gmail in 2004. So Gmail launched on April 1st, I joined on June 1st. And as I'm sure you'll remember as well, Gmail was this incredible innovation, massive JavaScript application that didn't really exist at the time. And it had this gig of storage. It was a full year before Yahoo Mail caught up and even longer before Hotmail and others did. So that was the level of technical differentiation between Gmail and the next best. And a decade later, you had cloud computing enabling folks to do stuff that you never would've been able to do previously. And so I kind of felt like, huh, software's starting to commoditize a little bit. And so when that happens, when technical differentiation kind of narrows, what are other things that will differentiate you?

(00:48:01):
And I was started thinking outside of tech, we buy a lot of things because of how we feel about them. And so I started to develop this thesis that actually the experience that you have of being sold to will increasingly actually differentiate a company and drive buying decisions if products are only different at the margin. And so if you believe that, then you really want to create a customer buying journey that feels like very unique experiences. And so we did a lot of this at Stripe and now we're looking to replicate this here. But an example of one of the things I think we did really nicely at Stripe was a lot of companies sales, the first call after you're qualified, we've decided you're worth engaging in sales process is discovery, which is basically let me ask you a lot of questions to try to under-uncover paint, figure out where buying power lies, et cetera.

(00:49:03):
And so that is kind of boring sometimes for a customer. You're basically being quizzed often on the phone. And so what we started to do at Stripe was that first session was a whiteboarding session, and we would actually get together and have you draw your architecture for payments and all the other things that were under the hood to enable you to take money and drive customer outcomes. And through that we would learn a ton about what was in your stack, what we were going to have to compete with, displace where value lied. But the customer also learned a lot themselves because in many cases they'd never drawn their architecture diagram. And so they left that meeting with an asset and a sense of like, "Wow, this is a really collaborative person who's deeply interested in helping me develop a mental model for how to think about this." And then we had other things that we would do.

(00:50:00):
So that's sort of how I think about building go-to-market-like a product is basically you need to go through from the first time you become aware that the company exists to again, that sort of five-year heavily retained wall-to-wall customer a set of experiences. And those experiences can feel transactional, flat, boring, or they can feel very human, personalized and unique. And so we try to go map those out and figure out how do you bring the product to bear, make it really human, and hopefully that creates a customer for life in the end.

Lenny Rachitsky (00:50:37):
I love that whiteboarding example. Are there any other examples of what you've done to make it actually work really well in this way?

Jeanne DeWitt Grosser (00:50:43):
Yeah. Another principle, we really developed this at Stripe too and I brought it to Vercel, was just the idea of adding value at any touch point regardless of whether or not that customer bought. Because even if customers don't buy, you often find that if you miss them on that buying cycle, three or four years later when they're in another buying cycle, they do come back. I was at Stripe for nine years and so I saw the number of customers that we lost and then half a decade later, here they are and they bought. So that was sort of another one. So examples of this that were doing at Vercel is there's great data on the internet that helps people understand the performance of their website and how fast your website is actually impacts SEO. And SEO impacts AEO and everybody's thinking about AEO right now. And, so one of the things we try to do when we reach out is actually give folks insight immediately into how they're performing on an absolute basis, how they're performing relative to peers. So ideally that piques your interest and you want to learn more from us, but even if it doesn't, you still have insights that you may or may not have been aware of that maybe make you contemplate whether or not you've got the optimal setup.

Lenny Rachitsky (00:52:07):
Awesome. So what I'm hearing here is when you say, think of it like a product that's basically a product person thinks about the experience of their product, that every step of the journey, here's the flow, step 1, 2, 3, 4, 5, how do we make every step awesome, keep them going along that journey. And so what you think about is just from the prospect's perspective, how do we make every step of that journey awesome, continue them down that journey.

Jeanne DeWitt Grosser (00:52:30):
Yeah. How do you make it be an experience rather than a transaction

Lenny Rachitsky (00:52:35):
Versus just feel like sales coming at you trying to sell you stuff?

Jeanne DeWitt Grosser (00:52:37):
Yeah.

Lenny Rachitsky (00:52:38):
Okay. Staying along this track of staying tactical, I want to go even further there. So what are just some go-to-market tactics that you find really effective these days for people trying to just to be more successful in getting people to pay attention to their stuff, to buy their stuff?

Jeanne DeWitt Grosser (00:52:57):
I mean, one I would sort of say dovetails with where I just ended, but is what are the unique insights that you can bring to bear about your product or how that customer may be in a suboptimal state? So I do think investing in data to tease that out is one thing. I think the other thing this is straightforward but often not done enough is a lot of good companies invest in docs, good thing to do, but they stop there. And particularly if you are selling into a slightly larger company doing things like, AWS calls it well-architected guides or blueprints, a lot of customers, particularly larger ones, really want to know the best practice for how exactly to implement your product with their particular setup. A great example of this, this is from Stripe, was Stripe was excellent at marketplaces. Most, Lyft, Instacart, DoorDash, they were all on Stripe.

(00:54:07):
And so Stripe definitely knew the best way to set up payments for a marketplace because we'd seen them all. And so when you then would go and sell a marketplace and say, "Oh yeah, we've got docs, go check them out." They didn't like that, because they're like, "Hey, every marketplace runs on Stripe. I don't want to look at generic docs. I want you to tell me what's the best way to set up payments for a marketplace." And so I think that's another key thing to be doing, particularly as you move past that sort of solo developer startup founder as potentially a target audience.

(00:54:39):
And then, I don't know if this is a tactic per se, but I do think just a good reminder for founders in particular who are still in that maybe founder-led sales moment is just the value of really good discovery. I often find founders are so excited about talking about their product or you ask one question and now they've got a hook of like, oh, I can fix that for you. But excellent salespeople typically will talk well under half the time in a conversation because they're out asking questions, probing often helping a customer arrive at conclusions on their own. And so learning how to do five why's, go deep rather than immediately going into problem solving mode. If they ask a question, you respond often. If they ask a question, you should ask a question about the question and then respond. So learning to be great at that, I think differentiates people.

Lenny Rachitsky (00:55:43):
So the last tip, I think there's something a lot of I bet everyone could learn is just listen more and talk less.

Jeanne DeWitt Grosser (00:55:48):
Yep.

Lenny Rachitsky (00:55:49):
On that first piece of advice, this kind of sharing unique insights and how your suboptimal, is there an example you could share of how you did that? Maybe a story of just how you convinced someone you're selling Striper or Vercel like care or something you're missing. Here's how this could help you become much better.

Jeanne DeWitt Grosser (00:56:04):
So with Vercel, sort of giving an example, but I'll make it more specific. So the performance point, you can go and look at core web Vitals, and so we can actually see the different things within their site that are fast or load correctly, et cetera, so anyone can go look that up. But what we can do is actually then help with benchmarking relative to peers. So that's been a big one that we've gone out and done. The other one that we've spent some good time on is just around helping customers understand MCP servers and when it would make sense to use one. So I think those are all the rage, but often people don't know how to contemplate them within their own product. So that was another one that we've gone pretty deep on and then related to, the first one is AEO Answer engine optimization is actually somewhat tangential to Vercel right.

(00:57:09):
So we drive performance, performance drives SEO. SEO is an input into AEO, but we have spent a ton of time sharing insights on AEO because we ourselves focus deeply on it and think we understand it better than many. And so again, as part of just building a trusted relationship, folks may go from those AMAs or that content into, okay, great, you taught me a lot and therefore I want Vercel to help me with performance. But in many cases, they actually now are just like, "This is a company that seems insightful, it seems like one I can learn from, and now I'm going to pay a little bit more attention to them." And over the fullness of time, maybe they see something that triggers them to decide, "Now is the time I want to go investigate that aspect of Vercel."

Lenny Rachitsky (00:57:55):
Awesome. So what I'm hearing here in many ways, and this resonates, I had Jenna Abel on the podcast recently and it was all about sales skills and how to sell.

Jeanne DeWitt Grosser (00:58:02):
Nice.

Lenny Rachitsky (00:58:02):
And one of her tips is you don't want to be focusing on here's the pain and problem we're solving and instead focus on here's how you will be better than your competitors. Here's the big gap and alpha that you can achieve. If you use Vercel, you were missing out on speed and you're going to get screwed in AEO and all these things. Here's how you can architect your entire payments system to be top tier. Does that resonate?

Jeanne DeWitt Grosser (00:58:27):
Yeah, I was told this stat. It's round numbers, so I can't imagine it's entirely accurate, but basically that customers, 80% of customers buy to avoid pain or reduce risk as opposed to the other one out of five to increase upside, which is a good thing again for startup founders to understand. So we all love to talk about the art of the possible, everything we're going to enable in the future. It's very exciting. Everyone's visionaries, but that's often really a sale that's going to resonate with another founder. And for everybody else, particularly enterprises, you're avoiding the risk of not making your revenue target next quarter, the risk of being outdone by the competition, the risk of having brand damage, et cetera. And so it's really hard actually for many startups to make that pivot because it feels off brand, but it does actually drive more buying behavior, is setting up a little bit of that concern that either I might not be well positioned or again through good question asking. I know exactly where I'm not well positioned and you can help me, that

Lenny Rachitsky (00:59:53):
That is such an important stat you shared. This has come up actually before in this podcast that buying, people are buying in large part to reduce risks, to basically not hurt themselves in their career, not hurt the company. That's a bigger factor in the buying decision than, "I have this problem I need to solve. And okay, thank you, this is solving." And the way April Dunford came in the podcast and talked about this of just like it's such a massive career bet. We are going to bring in product X and it's going to become, like Stripe, let's say, let's not talk about Versel. But let's say Stripe, we're going to adopt Stripe. That's a huge decision. If it doesn't go well, your career is hurt, your manager is going to be mad at you, it's going to set your company back. So a lot of the buying decision, as you've said is I just don't want to screw this up.

Jeanne DeWitt Grosser (01:00:36):
Right. Absolutely.

Lenny Rachitsky (01:00:37):
Okay. Along the line of tactics, something that I know you're a big fan of and help people think about is segmentation.

Jeanne DeWitt Grosser (01:00:45):
Yes.

Lenny Rachitsky (01:00:45):
This is something a lot of founders struggle with. They know, "Okay, I need to figure out my segmentation strategy and here where we're going after." Can you just give us a primer on segmentation, what people should know about why this is important and then how they might approach this.

Jeanne DeWitt Grosser (01:00:59):
So segmentation is basically how do you carve up the world of companies that exist on the planet to reason about them where they buy differently? So I'll give examples from Stripe and Versel to bring this home. So a very typical company segmentation is small, medium, large. That's a rational way to do things. Small, you often have a single decision maker, medium, a small team, and large, it's complex, it's a committee, et cetera. So the buying process does change across SMB, mid-market enterprise, but if you stop there, you are likely missing. But what are the things within your offering that also change the way something gets sold? So at Stripe, there were two ways we further cut the business. Way one was, so think of segmentation as a graph. So X-Access was size, so small, medium, large, y-access was growth potential. And that was important for Stripe because it was a consumption-based business.

(01:02:10):
So if you were going to grow at 200% year-on-year, you were more valuable to Stripe than if you were going to grow at 8% year-on-year. And so we wanted to spend more time, spend more money going after the 200% growers than the 8%. So that was one that informed your strategy on who you targeted. And then for Stripe, the other thing that we cut it was business model. So are you a B2B? Are you B2C? Are you B2B2B, E.G. a platform or B2B2C, E.G. a marketplace and why is that relevant? Well, if you're B2B, you are going to need business payments. Credit card was useful for a PLG function or PLG sale, but you were going to need ACH wires, etc. And you probably had a recurring business, so you were going to want Stripe billing. If you were B2C, that's consumer.

(01:03:00):
So you're going to want consumer payments. Apple Pay is super important. If you were in the platform or the marketplace, you were going to buy our connect product. So it helped us basically then craft a more targeted and replicable sales. Vercel, sort of similar deals. So small, medium, large buying complexity. We also do the same thing on growth potential because we are similarly a consumption based business, but for us, a couple other things on the X-axis, we layer in promote, which is one of the things that is observable is traffic, site traffic on the internet. So Google publishes a Crux score, which is basically they have a bunch of data in Chrome, and so they know that Lenny's site gets a million XC amount-

Lenny Rachitsky (01:03:48):
Millions.

Jeanne DeWitt Grosser (01:03:48):
... volume that Jeanne's site does. And so basically if you are a small company but you have super high traffic that's going to be more complex, Vercel is going to make more money and so we want to promote you.

(01:04:02):
So great example of this would be OpenAI. OpenAI, I forget these days how many employees it has. Let's say it's 3,000, it's probably more than that at this point, but so that's going to put it in the mid-market at most companies, but they're a top 25 traffic site on the internet. So for us, that's going to push them in our enterprise because we need to go lean in with a much more in depth sales process. And then the other thing we layer on is a workload type. So if you are an e-commerce company, that's going to be a very different sale. You actually use different language. You talk about product listing pages and product description pages, and you've got an order management system as the back end. Super different from a crypto company where you might be running soup to nuts on AWS. And so again, that helps us start to then have a really different buying content for you.

Lenny Rachitsky (01:05:06):
Okay, this is awesome. So essentially what you do is you break up this universe coming back to your original story at Stripe to help you sort essentially which companies are most likely to buy your product. And what you're coming up with is these attributes that are correlated with they're likely to be great potential customers.

Jeanne DeWitt Grosser (01:05:22):
Yep.

Lenny Rachitsky (01:05:22):
Do you recommend using this XY axis as the approach versus something else? There's like a spreadsheet with five columns. I don't know, how do you start?

Jeanne DeWitt Grosser (01:05:31):
There's probably something to be said for X and Y. like do you think size is going to play into most buying decisions and then these days there is a fair amount of consumption happening? So there'll be aspects of this that I think are somewhat universal. But I think basically when I came to Vercel, because new product market product offering, for me it's a new market. I had a lot to learn, but this is one of the first things I did in the first 30 days. And so basically I sat down with the gentleman Abhi who leads data science here and said, okay, what drives revenue? So what are the things that you can look at X ante about a customer to know this person's likely to pay us a hundred thousand dollars versus a million? That's probably going to be part of a segmentation framework. And then similarly, okay, what attributes would we look for to cluster where we seem to be winning repeatedly? And that was how we ultimately got at, okay, Crux rank is going to be super important because what you pay Vercel is correlated with your traffic. And then workload type was super important as well.

(01:06:46):
And for Vercel, when we did that, it was really interesting because we saw, wow, we have a lot of penetration and e-comm not that surprising actually, given that we drive highly performant sites and e-comm having a superfast performance site really matters. But at the time, if you looked at as an example, an enterprise SaaS companies, we didn't have a lot of penetration, even though you would've thought, okay, front-end cloud, very developer oriented. Of course software companies would be on us, but in enterprise, most of those companies built that SaaS offering before Vercel existed. So migrating 2 million lines of code to Vercel, that's a big lift. So it helped us really understand where are we winning, where are we not? And now as an example, within SaaS companies and enterprise, we're actually seeing a lot of interest in the AI cloud. Those are some of the earlier adopters of, "Hey, let's add AI native functionality to our existing SaaS app." And so again, it helps us figure out what to target where.

Lenny Rachitsky (01:07:55):
So essentially you're doing this regression analysis on what's working and then here's the attributes that are most correlated with success. Something I always recommend when founders ask me for how do I figure out my CPE? How do I figure out where to focus, my heuristic is just think of three attributes that narrow them down. So it's like series A company that's angel-led, that's the marketplace, something like that. Does that feel like a good just rule of thumb just to start?

Jeanne DeWitt Grosser (01:08:18):
Yeah, I think beyond three, that's getting pretty detailed and reasonably speaking, you're not going to cut. You have five sellers. So, what, you're going to put one seller in five different segments? So I do think three is something you can reason about. The other thing I'll say on this topic that I think is really important is a lot of times folks think segmentation is a go-to market thing. I really think it's a company thing. So when you Vercel, I actually deliver and every new hires first week, one of our company values is KYC, know your customer and I deliver the KYC section and talk through our segmentation framework how our customer base maps into those segments because it's really important as those new product managers leave the room that when they're building something, they think to themselves, okay, I'm building a new back end product. Who is this targeted at? Is it targeted at an enterprise or a startup? Basically, do I have a point of view on where I'm trying to win and why? And if you're doing that out of the gates, then it's much easier to then go speak the same language with the go to market org and figure out, okay, how are we going to take that to market in line with the other emotions that we have in play?

Lenny Rachitsky (01:09:36):
Okay, this is a great segue to, there's a couple other things I want to talk about. One is something I've heard from so many people you've worked with is that you are amazing at building a go-to-market org that works really well with product and engineering. So I'll read this quote from your former colleague, Kate Jensen. She said that your superpower is building a sales org that doesn't feel like a sales org to engineers. So the question she suggested asked just what does it take to do that? What are the ingredients to building a sales org that engineers and product teams really like working with?

Jeanne DeWitt Grosser (01:09:59):
The litmus test I have always given my sales team is if you are an account executive in my org and I put you in front of 10 engineers at our company, it should take them 10 minutes to figure out you aren't a product manager. And what I'm trying to get across is you need to have incredible product depth. And the reason for that is twofold. One, it gives you credibility with the product and engineering org. And two, I also believe that the best go-to-market orgs on the planet are equal parts revenue driving and R&D and D. And the reason I emphasize the latter is if you think about a product management organization, you may have a UXR team out doing research, product managers certainly should be out talking to customers. Well, if I have a 20-person sales team, think of the number of customers that we talk to in a week. And so if we can do an excellent job of translating all of that feedback into signal and then feeding that into the road map, we can be actually an extension of the product management org. But that takes being really good at discerning signal from noise, understanding when something is an objection that should be overcome versus an opportunity in the market. So I think those things have helped.

Lenny Rachitsky (01:11:27):
I just love this as a product manager, maybe form a product manager. I don't know what the hell I am these days. I just love the idea of the salesperson. Like you not knowing the difference between a product manager and a salesperson. The most classic challenge is sales orgs ask for all these features and PMs are constantly having to push back and think about does this fit into everything. So it feels like that's a big part of this is to understand that deeply.

Jeanne DeWitt Grosser (01:11:51):
Yeah, you want a sales org that can think like a general manager, so that's not just trying to get deals done but is trying to help build a business. And so again, knows when to say no, knows when to do objection handle versus knows, Hey, I've actually heard this on the last three calls and I do think this would be a really big unlock that would make us more competitive, would be something that new that nobody's doing. So I think that takes looking for a profile that both has sales skills but also is going to think with that product mindset.

Lenny Rachitsky (01:12:31):
I love that. Okay, so another quote from Claire Hughes Johnson, former podcast guest, amazing sales leader, worked with you at Stripe. She said something along these lines, but a little different. Jeanne is probably the best go-to-market person at connecting with product and engineering, deeply understanding the product and providing the most valuable input to her counterparts of any I've ever seen. It sounds like just another ingredient here is just sales feeling like a real partner to product engineering actually, not just being like, "Hey, do these things for me, but actually feeling like a partner."

Jeanne DeWitt Grosser (01:13:01):
Ultimately company strategy is basically product strategy meets go-to market strategy. And so I spend guess as a go-to market leader, I'm constantly trying to figure out how do I make more money more efficiently? And you typically do that by having a winning product in the market that is well commercialized. And so that means that I really lean into thinking about product strategy and thinking about pricing strategy because if those two things are optimal, you're going to win more often and there'll be less friction in it. And so that's sort of where got to put as a revenue leader, like a GM hat on and not just think, how do I sell? But actually how do I enable the insights I'm getting from talking to customers constantly to have the company strategy be more effective?

Lenny Rachitsky (01:14:00):
Speaking of product, going in a slightly different direction, PLG product-led growth, it felt like it was very hot for a while where everyone's like, "You got to go PLG, that's the only way to win. It's impossible to do sales. The future is PLG." It feels like that's gone away. And in large part, obviously still companies grow through PLG and work through PLG. What's just kind of your thoughts on PLG and when does it make sense for a company these days to actually think this is how they'll grow for a while?

Jeanne DeWitt Grosser (01:14:28):
PLG makes sense for a lot of companies at the outset, unless you are very explicitly building a product for enterprise. So Sierra as an example, right? They are very clearly going after Global 2000 or something close to that. PLG is not going to be overly useful to them because they are trying to win eight-figure deals from day one. But for a lot of products, folks are targeting a startup audience at the outset and then they're adding more functionality so that they can ultimately continue to scale up market. So I think PLG is still super relevant. It's a major driver of Vercels growth. It was a big driver of Stripe's growth. The thing that folks get wrong is it does typically have a ceiling. So people are generally not going to give you $1 million via self-serve flow. So at some point if you want to sustain growth rates, you're going to have to have your deal sizes get bigger and bigger. And where I think folks get stuck is waiting too long on PLG because it does take a while to build a replicable sales process and a sales process, which often you're getting fed by inbound at the beginning and then you got to add outbound. It takes a while actually to turn outbound into a predictable engine. So I think where you see companies hit walls is just when they don't add the sales portion of it soon enough.

Lenny Rachitsky (01:16:00):
So essentially every company ends up having to build a sales org, some start product-led and then at sales, some just start sales and have it from the beginning.

Jeanne DeWitt Grosser (01:16:09):
Yeah, I would agree. There are probably some good examples of large vertical SaaS platforms that are SMB, but even they wind up with Velocity sales team. So yeah, I don't know that I can think of a 100 billion company that's PLG-only.

Lenny Rachitsky (01:16:30):
Yeah, it just feels like you're leaving money on the table even if you are growing really fast. I know Atlassian was a long-time PLG company but eventually succumbed. I don't know if that's the right way to put it. Okay. You mentioned pricing. I know you have strong opinions on pricing and pricing strategy. What's just a couple of tips you might share with someone thinking about how to price their product?

Jeanne DeWitt Grosser (01:16:52):
Yeah, this is kind of on the theme, but I think the first thing is you got to think about pricing like a product. So it's another one where it actually really matters how you choose to price a product. Do you really understand where customers are going to drive value? Do you really understand where you incur costs? And are you doing a smart job of aligning those things? You've got lots of examples of companies grossly underpricing, you're sort of afraid to charge for the value that you actually provide. I think there are a lot of examples where people default to including a freemium strategy without that actually being a strategy. A good example at Stripe, we launched Stripe Billings years ago. It had a freemium strategy because that's what you do. And then we sort of looked at it and we're like, "actually integrating straight billing takes a little bit of work.So if you do that, you're probably going to stay."

(01:17:56):
And so we killed that, killed the free trial to zero downside. So that's another one. At Vercel, we've been going through that transition where we're a consumption-based business model ultimately, but at the outset we basically kind of bundled that into what looked like a SaaS-like price and as we've added a lot more functionality that wasn't working anymore. And so we did an unbundling and right now actually we did a pretty substantial pricing change in August where we have an enterprise at a pro-skew. And if you looked at the enterprise skew, it's called Enterprise for a reason, enter, it's meant to be sold to an enterprise. And actually about half of the folks on the enterprise skew were startups, which suggests that there's stuff in the enterprise skew that a startup really wants. So we kicked a lot of that stuff out of the enterprise skew and made it so you could buy it self-serve online and what do you know, people are.

(01:19:03):
So now that's really driven a lot of growth in our PLG funnel, which is awesome for startups because it's super efficient. They can just buy things, they want that. It's awesome for us because you don't have to have a human intermediate that. So getting all of these knobs really tuned is a key to both a great customer experience and optimal revenue outcomes.

Lenny Rachitsky (01:19:24):
Maybe just one more question before we get to a very exciting lightning round. It's going to be a combo question. I hear you have a hot take on sales comp, how to comp salespeople that's different from other people and also who to hire when you're hiring folks in sales. Can you just talk about your takes there?

Jeanne DeWitt Grosser (01:19:41):
I struggle with sales comp because it's all about pay for performance, which I'm obviously a fan of, but it makes your organization less flexible because you basically have to decide 12 months in advance, these are things I value and particularly in this moment that could be different. As a great example of this, when we wrote the sales plans for this year at Vercel, the AI cloud did not exist. We were selling our front-end cloud and we were selling VZero and introduced the AI cloud halfway through the year. Now we had all sorts of good ways to still incentivize that, but I think you want to be able to be innovative and pivot and when you have a well-designed sales plan or a very structured sales plan, that can be challenging.

(01:20:44):
So that's a little bit of my hot take is just I'm trying to figure out how do you have the upside of sales of motivates people. It's a quantitative function, which is great, but also the flexibility to change your mind because I think a lot of companies right now are having a hard time doing annual planning. So that's one. On profiles, I have always valued just sort of a diversified portfolio. So I strongly believe that sales is a skill and so you want salespeople with actual sales experience in your organization, but I think there's value in pairing them with more nontraditional backgrounds, in particular consulting or banking background. Those folks are really good at more quantitative and analytical aspects of sales. So getting into that consultative part, which I think we talked about at the outset. And so I find that when you mix these together, the sort of consultant banker profile realizes, "Oh wait a minute, sales is a skill and I didn't really have it." And so they go learn from your account executives with that background and then your AEs learn more about, okay, how do I think about a P&L? How can I talk to a CFO? How do I present a TCO analysis more effectively? And so just creates a much richer learning environment where people are bouncing ideas off each other.

Lenny Rachitsky (01:22:22):
That is awesome. I love that strategy. Okay, final question. Just is there anything else you wanted to share? Anything else you want to leave listeners with before we get to our very exciting lightning round?

Jeanne DeWitt Grosser (01:22:31):
Oh man. I feel like we've been very thorough.

Lenny Rachitsky (01:22:34):
All right, thanks So too.

Jeanne DeWitt Grosser (01:22:35):
Yeah, you stumped me on that one.

Lenny Rachitsky (01:22:38):
Okay. That's the goal. With that Jean, we've reached our very exciting lightning round. I'm going to make it very quick. I know you got to run. I'm going to ask you just two questions.

Jeanne DeWitt Grosser (01:22:46):
Okay.

Lenny Rachitsky (01:22:46):
One is I'm going to skip to your life motto. Do you have a favorite life motto that you often come back to find useful in worker and life?

Jeanne DeWitt Grosser (01:22:54):
I do. I actually have found that I'm known for saying a handful of things that I didn't necessarily realize it, but when you leave an organization, people tend to tell you what stuck with them. But there is one that I think I am known for saying growing up, my mom always said to me, when the going gets tough, the tough get going. And in sales, you're always going to have a quarter when you're not on pace. And so that's one that I feel like I pull on, not infrequently because in my view, there's another version of this, my mom also always says was where there's a will, there's a way. So I think you can always choose to find a path forward even when that's not super clear.

Lenny Rachitsky (01:23:45):
I love these. Okay, last question. I read that you were a very competitive diver in college early on. I'm just curious if there's something you learned from that experience that brought with you that helps you be as successful as you've become?

Jeanne DeWitt Grosser (01:23:59):
Well, I mean, first of all, I should say I was generally coming in third place out of three on my team.

Lenny Rachitsky (01:24:04):
Third place, that's not bad.

Jeanne DeWitt Grosser (01:24:07):
I managed to do it in college, but that was the extent of that career. So diving is a precision sport and it is a repetitive sport. And it is also a sport where when you land flat on your back, and literally as you are swimming to the side of the pool, welts are forming on it, you always 100% of the time will be forced to immediately get back on the diving board and do that exact same dive again. And so I think that has a lot of stuff that's transferable to work and to sales. So for me, I just have an obsession with excellence and within sales. sales is about replicability. How do you drive predictable outcomes, how excellent are you at your ability to forecast? And so I think I bring that to bear within sales a lot. And then similarly, you get a lot of nos in sales. So another phrase that a sales guru said to me once or in a training was yeses are great, nos are great, maybes will kill you. And so how do you get really comfortable that no is a great thing and that just gave you data and now you can go do something with it.

Lenny Rachitsky (01:25:25):
This is a really inspiring and empowering way to end the conversation. Jean, thank you so much for being here.

Jeanne DeWitt Grosser (01:25:33):
Thanks so much for having me, Lenny. It was a lot of fun.

Lenny Rachitsky (01:25:35):
Bye, everyone.

(01:25:37):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## The ultimate guide to founder-led sales | Jen Abel (co-founder of JJELLYFISH)
**Guest:** Jen Abel  
**Published:** 2024-11-24  
**YouTube:** https://www.youtube.com/watch?v=969dwgu98qc  
**Tags:** growth, acquisition, churn, roadmap, customer discovery, mvp, experimentation, funnel, conversion, revenue  

# The ultimate guide to founder-led sales | Jen Abel (co-founder of JJELLYFISH)

## Transcript

Lenny Rachitsky (00:00:00):
I've always wanted to create a very tactical episode on how to do sales, especially with a focus on founder led sales.

Jen Abel (00:00:06):
A lot of early stage founders get tripped up as they're taking late stage sales advice. The founder is the product. You have studied. You have experienced something that most of the market hasn't even had a chance to maybe see or visualize yet.

Lenny Rachitsky (00:00:19):
A billion SaaS tools emailing me constantly about their product. How do you get someone to even want to talk to you and be open to learning about what you're doing?

Jen Abel (00:00:25):
So if you can focus the messaging in a way that speaks to something that is a bit of shock value or is counterintuitive, you'll get them to continue reading. When a problem is truly being felt by the market, people will get on a call, people will respond.

Lenny Rachitsky (00:00:39):
The next step I imagine is you're on the phone with them trying to convince them to actually care. What do you do there? How do you get them to engage further?

Jen Abel (00:00:45):
You need to be vulnerable. I would be very open and honest with where you are. Hey, I'm an early stage startup. We have a lot to learn. Can we kind of gain your insight into how this problem is manifesting on your side? Founder led sales is not about revenue on day one. It is about learning as fast as humanly possible to get to that pulse, so that you can earn the right to sell.

Lenny Rachitsky (00:01:12):
Today my guest is Jen Abel. Jen is the co-founder of Jellyfish, where her and her team help early stage founders learn how to sell, do early customer discovery, and set up a repeatable sales motion. Prior to Jellyfish, Jen was an enterprise sales director at the Muse and a general assembly, and she's obsessed with helping founders in the zero to one stage of their journey. In our conversation, we get extremely tactical and in the weeds on how to actually do sales as a founder. We talk through each step of the sales process, and Jen shares what you should be doing and saying at every step. We go through how to find your first set of leads, how to reach out to them, what to say in your message, how to structure your first sales call, how to get through procurement, and how to get that final signature.

(00:01:55):
She shares actual words you should be using, and phrases and structures, and pitfalls that most people run into at each of these steps. I've never heard a podcast episode with this much advice that you can put into practice tomorrow, and I am very excited to hear how it goes for you. If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. It's the best way to avoid missing future episodes and it helps the podcast tremendously. With that, I bring you Jen Abel.

(00:02:24):
Jen, thank you so much for being here. Welcome to the podcast.

Jen Abel (00:02:27):
Thanks, Lenny.

Lenny Rachitsky (00:02:28):
What I've always wanted to do is to create a very tactical episode on how to do sales, like how to actually have sales conversations, how to find leads, how to close deals. Especially with a focus on founder led sales, where founders are doing the early sales versus hiring salesperson. Which one, I know you're a huge advocate of and we'll talk about this. And two, you basically spent all your time working with founders and founding teams, helping them learn how to do sales, how to set up their go-to-market motions, how to scale teams, sales teams, how to hire sales people. So I'm very excited to have you here to create a very in the weeds, hands-on episode on how to do sales. How does that sound broadly?

Jen Abel (00:03:07):
That sounds awesome, and thank you so much for having me, Lenny. I mean, it's a true pleasure to be here with you.

Lenny Rachitsky (00:03:12):
It's my pleasure. Many people have recommended you come on this podcast. I'm excited we're doing this. Let me start with just this kind of question, our founder led sales. Maybe just briefly explain what that term means and then talk about why this is so important, why this is the way you recommend companies start doing sales?

Jen Abel (00:03:29):
Founder led sales is really that first milestone that a startup goes through on the commercial side, which is, how do I go out and get my first few customers? Some people might say zero to one, which is, how do I get my first million? Others might say, how do I go out and get my first 10 customers? It's all kind of in the same vein. And founder led sales is really, really, really important because in the very, very, very early days, when there is no brand equity, when there is no marketing engine running, when there is limited to no reference ability, the founder is the product, right? Because the product is still, could be abstract, could be an MVP or in it's really early formation. So the founder is the product. When people say, well, what does that even mean? It means that you are a subject matter expert on something highly specific.

(00:04:23):
You have studied, you have experienced something that most of the market hasn't even had a chance to maybe see or visualize yet. So you have this novel insight that you are building a business around. And it's that novel insight and the way you see the world that gets the market excited, in absence of a product. And that's actually happens even before you even show the product. So founder led sales is how do you bring the founders vision into the world and have the market, and understand what part of the market accepts it, and then what part of that vision are they accepting? So it's aligning the founders vision with the market reality.

Lenny Rachitsky (00:05:01):
This episode is brought to you by Brave Search. Brave Search is the private independent search engine that doesn't bias or censor results. Brave Search and its answers with AI feature are available for free to all users on desktop and mobile devices. With Brave Search, you get real answers faster, served from their own independent index of the web. Their AI search engine can give lightning fast, incredibly accurate results for almost any question. But Brave isn't just AI answers, it's also a powerful traditional search engine with real innovations versus big tech options. It fights bias and SEO spam. It brings a cleaner results page with fewer ads. Reddit threads in the search engine results page, powerful local results, and even community-driven ranking options. Tired of big tech, same old list of links? It's time to try Brave Search. Visit brave.com/Lenny to get started. That's brave.com/Lenny.

(00:05:58):
This episode is brought to you by Vanta. When it comes to ensuring your company has top-notch security practices, things get complicated fast. Now you can assess risk, secure the trust of your customers, and automate compliance for SOC II, ISO 27,001, HIPAA and more, with a single platform, Vanta. Vanta's market-leading trust management platform helps you continuously monitor compliance alongside reporting and tracking risks. Plus, you can save hours by completing security questionnaires with Vanta AI. Join thousands of global companies that use Vanta to automate evidence collection, unify risk management, and streamline security reviews. Get $1,000 off Vanta when you go to Vanta.com/Lenny, that's V-A-M-T-A dot com slash Lenny.

(00:06:50):
And this is counter to what many founders hope is, I'm just going to hire a salesperson, they'll handle sales. I'll build the thing, I'll wait for them to find deals. And this is like a lot of people think this way. And founder led sales is the movement of just like, no, no, you should be doing the sales for a long time as a founder.

Jen Abel (00:07:06):
Absolutely. I mean, it is the competitive advantage. I don't think people realize how much of a competitive advantage the founder led sales motion is, for three specific reasons. One is that the founder is the visionary. No one's going to be able to speak to it like they can. No salesperson, really no non-founder. The second is that they are the highest order in the hierarchy of the startup. It's the founder. So the market is excited to talk to a founder because they usually know something that the market doesn't know. And they want to learn and maybe they want to experience something differently. So being able to speak to the person that's running the vision, speak to the person that's crafted the vision.

(00:07:50):
And then that third piece is that the founder can see something budding in a conversation that a salesperson won't be able to see. And it's those budding moments that's where all the gold lives. And I don't think a lot of founders realize that. Their day one market vision is never the same vision that takes them in a product market fit. And I say that all the time. It's these little budding moments where it's like I was able to get to that budding insight because I went deeper and deeper and deeper and deeper through these calls and these conversations, to fully refine how we want to go out and sell it. And only a founder is going to be able to see those things.

Lenny Rachitsky (00:08:26):
I love this because this connects really well with an episode I just did with the CMO of Wiz. And the founders went through this exactly. They had 10 to 15 conversations a day for weeks, and then they're like realizing people keep telling us they like it, but no one's buying, no one's excited enough to want to actually move forward. And that was only happening because the founders were on these calls.

Jen Abel (00:08:49):
Yeah, I mean, the other thing too is that it becomes a game of telephone. It's like, hey, this salesperson says that no cares about this. What do you think the first thing the founder's going to say is? It's the salesperson. So much easier to say that than, is it me? Is it my vision? So it also kind of brings the accountability closer to the pulse where decisions are made.

Lenny Rachitsky (00:09:10):
It's interesting how similar this is to product building, where there's this idea that a founder top down can tell the team what to build, and it's this very waterfall cycle. When in reality the idea of the product and feature is just like step one, and then there's actually building it, testing it, talking to customers about it, that actually turns that initial seed of an idea to the real thing that people will want.

Jen Abel (00:09:33):
Totally.

Lenny Rachitsky (00:09:34):
Okay. So the catch 22, I don't know if that's the term here. The challenge is, okay, so great, founders should be doing sales. Most founders have never done sales. They just want to build product. They're mostly product people, design people. Sometimes there's founders that are salespeople. Rarely is that the case in my experience. So doing sales is very hard, not something that comes naturally to a lot of people. A lot of people are very afraid of it. So with that, let's get into how to actually get better at the sales process. I think a nice framework for how we can go through this is basically first let's talk about the sales cycle, the steps, the key steps of a sales cycle. And then we'll just go through each step and help people learn some tactics to get through each of those conversations.

Jen Abel (00:09:35):
Sounds great.

Lenny Rachitsky (00:10:22):
Okay. Yeah. Cool. So what's the simplest way to think about the steps of a sales cycle?

Jen Abel (00:10:26):
The traditional sales stages that most CRMs are even set up as is you have your intro call. You have your second call, which sometimes could be the demo depending on the stage of market you're selling to. Then you have your third call, which is going to be more about walking through a proposal, a scope of work, maybe going deeper into the demo to contextualize it to everything you've learned. The fourth call is going to be getting their feedback and kind of co-authoring that scope of work even further. The fifth call is going to be around probably an introduction to procurement. And then selling into procurement in itself, it's its own little sales cycle, but we could talk about that in a sec. And then post-procurement, it's going to be obviously getting that signature and knowing who the actual signatory is. Sometimes it's not even the business unit, it's sometimes legal, CFO, procurement themselves. So just understanding who that is.

Lenny Rachitsky (00:11:23):
Okay, great. So let's walk through each of these steps. So I love that each call has its traditional goal, demo, proposal, then co-authoring, and then procurement, and then post-procurement. I love how consistent everybody is.

Jen Abel (00:11:39):
Yeah, well, it's also, it's interesting because it's also predicated on their buying process as well. So if they're really used to buying, if they're very mature in their buying process, they actually might guide you to what the steps are. But most startups are turning non-consumers into consumers. So that's why this kind of fits well.

Lenny Rachitsky (00:12:00):
Got it. So there's this intra call step. So kind starting about where it begins. I think where a lot of people struggle most is getting anyone to even pay attention. You don't want to talk to them. A billion SaaS tools emailing me constantly about their product. So maybe we start there of just like how do you get someone to even want to talk to you and be open to learning about what you're doing?

Jen Abel (00:12:19):
Yeah. And this is why that founder led sales piece is so important. One is when it's coming from the founder, it's an entirely different weight. You're like, oh, interesting. This founder is reaching out to me. Okay, I'm going to seek to go a layer deeper, knowing who is sending me this note. The second piece is this is why that novel insight, that technical insight, that business model insight that you've uncovered needs to lead here. People are inspired by a new way of thinking, usually something counterintuitive, something that's really different. I really try and stay away from better, because that's really hard to define, and better means something different to everyone. So if you can focus the messaging in a way that speaks to something that has a bit of shock value, or is counterintuitive, you'll get them to continue reading. So first and foremost, I usually like to open it with, which is why is this relevant for me in my role?

(00:13:20):
Why are you reaching out to me? So first and foremost is relevancy. I think that matters even more so than personalization right now. I think it's so easy to personalize anything, and it can also come across as really stressed when you're like, hey, I noticed you were on such and such podcast, and that was when they were previously two roles behind. So I always say relevancy. If you can get to relevancy, that's the most important piece. The second most important piece is really getting to that level of differentiation or counterintuitive nature. So say something that would literally make them say what? Or that makes no sense. Maybe not that makes no sense, but what or how could that be? Or I've never thought about it that way. Or I actually don't fully understand what they're saying, but there's something there that's interesting. Get them to pause for a minute.

(00:14:13):
And the most important piece is getting this done where, if they get it on their mobile phone, which everyone is looking at their mobile phone and on email, they don't have to scroll. So usually three to four sentences max. That also, that's how a founder writes. That's how an executive writes if you're selling top down. But most importantly, leave them wanting more. Don't say everything, don't even talk about the solution. Talk about the problem that you want to solve, and why it needs to be solved or why it's not good enough today. So those are the four main components. Just to reiterate, relevancy, bring some level of counterintuitive or really different approach to the conversation, focusing in on a problem that's predicated to them, and really concise.

Lenny Rachitsky (00:14:59):
I love this. Is there an example you could share that helps make this even more real? Maybe an email you helped with. And by the way, this is email and LinkedIn, I imagine is where you're communicating mostly?

Jen Abel (00:15:11):
LinkedIn, email, you would be shocked to hear this, but cold calling. I never used to do this. It is one of the most... The interest rates on cold calling are a lot higher than email in many cases.

Lenny Rachitsky (00:15:26):
So it's calling, email, cold email and LinkedIn DMs, is that the three channels generally?

Jen Abel (00:15:31):
Yep, those are the three, yeah, the main ones.

Lenny Rachitsky (00:15:33):
Cool. Yeah. Is there an example? It doesn't have to be word for word which you've done or people done, but just how do you... Yeah.

Jen Abel (00:15:38):
Actually our first three years were built on cold email before we actually had clients, before we got word of mouth from the founders we worked with, I cold emailed the first 20 customers we had at Jellyfish. And the line I used in there was zero to one sales talent doesn't exist. That's why I want to have a conversation with you. So that was kind of that leading, wait, what? What does that even mean? And what I would do is tie that to them in some respects. If they recently raised the seed or series A, where they are in that journey. But I would lead with that and then tie it into like, hey, I noticed you're looking to target X, Y, and Z based off of what your website. I'd love to have a conversation with you.

Lenny Rachitsky (00:16:25):
And that first piece is the relevance. Here's why this is relevant to you.

Jen Abel (00:16:28):
Yeah. And then I say, our belief at Jellyfish is zero to one sales talent doesn't exist. That's why we built this model.

Lenny Rachitsky (00:16:34):
Awesome. And you kept it really short. So it's relevance, counterintuitive, keep it really short. And then what was the fourth piece?

Jen Abel (00:16:42):
The fourth piece is just make sure it's concise so that you don't have to scroll on mobile phone.

Lenny Rachitsky (00:16:47):
While we're on this topic. What's a good conversion rate of these sorts of cold outreaches?

Jen Abel (00:16:51):
Conversion rate is interesting. Because everyone's so focused on conversion rate. I get that in the beginning until you have some wins, you have to focus there. But I just want to reverse engineer it backwards a bit. Once you kind of have this, and I'll talk about it in a sec, which is win rate. Win rate is if I got Lenny on a phone call, and he went through the sales process, and I signed him up. And I spoke to 10 Lenny's and only Lenny R was the one that signed. That's one out of 10, that's a 10% win rate.

(00:17:23):
So if you have a really high win rate, let's say 30 or 40%, you actually don't need as high of a conversion rate on the outbound, because you know if you get someone in the funnel, the throughput is very healthy. If your win rate is really low, you need that conversion rate to be much, much higher, because you need more and more and more at bats. So conversion rate is a funny thing. In the beginning I get it because you don't have a lot of customers going through the pipeline yet. But there's people focus on it in a little bit of a false sense because interest rate truly is also dictated by win rate. So I just want to specify that.

Lenny Rachitsky (00:18:03):
That's a really good point.

Jen Abel (00:18:05):
I would say if you're doing a win rate around 15 to 30% and you need to carry, oh I don't know, a million dollar quota. I would say a healthy conversion rate from outbound probably sits around, when it's mature, around five to 7%. Sometimes it could be two to 3%. Sometimes I've seen eight to 15% because it's coming from the founder, and they're solving a really heartfelt problem. So interest rate is also predicated on the problem that the founder has decided they want to solve for, and their insight on that problem.

(00:18:51):
And everyone wants to keep going back to, well, email rate is really low, email doesn't work anymore. LinkedIn, I'm not getting the connects I want. Yes, you can argue that the game has changed a little bit, but when a problem is truly being felt by the market, people will get on a call. People will respond. And if I can compare two engagements at a time that we're running, I see one where it's a 2% interested rate and then I'm seeing another one that's actually at 12% interested rate. And we're doing nothing different. The only thing that's different is the insight that the founder has on the market, which is a hard pill to swallow. And I know that's hard to hear too.

Lenny Rachitsky (00:19:32):
And those are two different companies selling different things?

Jen Abel (00:19:34):
Two different companies selling to two different markets, but they're not fundamentally drastically different markets.

Lenny Rachitsky (00:19:43):
Got it. But one's basically got more product market fit essentially?

Jen Abel (00:19:46):
That's exactly right. So everyone always comes back to we have the sales problem, we have the sales problem, we have an outbound problem. And yes, there could be some technical things going on that you need to look at. Maybe you leveraged clay and you blasted a thousand people and now your domain health has been impacted. But the vast majority of the time, maybe you're just not saying anything interesting at all. Maybe the problem you're looking to solve just isn't widely felt. Maybe the perspective you have needs another level of refinement because you're just not getting those bites.

Lenny Rachitsky (00:20:21):
I feel like this question you just touched on is something a lot of founders are always wondering, is this product not the thing people want? Is it my sales skills? I guess I imagine this is a very difficult question to answer, especially quickly. I guess is there anything there that's more likely because of this, it means your product isn't something anyone's want, versus you're not doing a good job selling it?

Jen Abel (00:20:41):
Remember that amazing chart you drew where it talked about the length of time it took? I think you picked the top 25 startups.

Lenny Rachitsky (00:20:50):
For product market fit timeline [inaudible 00:20:51].

Jen Abel (00:20:51):
Product market fit. Yeah, that amazing image that I think has been reshared more times than anything I've ever seen. It's interesting because if you look at, I was looking at this closely the other day. If you look at the top section where the time to product market fit is consolidated, and you go all the way down to the air tables and the figmas, which a long time to get to product market fit. If you think about the earlier ones, which were, it was like GitHub that had product market fit pretty quickly. The SOC 2 compliant company.

Lenny Rachitsky (00:21:22):
Vanta.

Jen Abel (00:21:23):
Vanta. There's this thing in my head and I haven't fully validated it but I'm going to share it with you, which is did they start with the market problem first and then build the product? Because they knew who their market was right off the bat. Versus an air table and a figma that I think started with a technical insight and then were trying to find their market.

Lenny Rachitsky (00:21:46):
I think that's absolutely right. Vanta, the way they approached it, Christina, she was searching for a pain. She was obsessed with talking to everybody about a pain that they needed solved, and then she just built it in spreadsheets. So she started with the market very much so.

Jen Abel (00:22:00):
And I think product market fit when you start with the market first, it's accelerated. But I will say this, I think that it's also capped on the upside. Because you're starting with the market versus the air table and the figma, which started with the technical insight and has uncapped upside. But one is certainly riskier than the other. Starting with a product is a hell of a lot riskier. And this is where I come back to so many people will say, how did you get funding and not know who your market is? And it's like, because if they do find it, that's a really, really, really big win. Versus I think if you start with the market first, you could potentially get a good win but is it more capped?

Lenny Rachitsky (00:22:47):
Interesting.

Jen Abel (00:22:48):
I don't know, it's just a thought. I was staring at your grid for so long, I was like, there's something here. And I kept coming back to those were more like I kept breaking it down to market versus product.

Lenny Rachitsky (00:23:01):
Yeah, I love this. I think there's definitely something there. There's also horizontal versus a very specific problem you're solving.

Jen Abel (00:23:06):
Totally.

Lenny Rachitsky (00:23:07):
Okay, so you mentioned clay and you kind of nerd sniped me there of just what tools do you find useful? And it makes me think about finding leads, which is kind of going backwards through the sales process, but it might be okay, so maybe let's spend time there. Just like what do you recommend to founders to find the good leads? Glengarry Glen Ross good leads.

Jen Abel (00:23:28):
So I say before you buy any tool, don't even think about tools. I feel like people turn everything into this complicated mess with all of the tools that they start integrating. And then they're engineers, I get it. So now they start to engineer these sales tools together and then they blast their market, and now they have 5,000 notes out in one day and their domain takes a hit. So I think before you even overthink about the tools right now, can you manually find 30 people that you want to spend 15 to 20 minutes writing a rock solid note to? Are there 30 people that you are deeply excited to learn from, that you are willing to invest 15 to 20 minutes to write a really thoughtful note? Let's just start there. So some questions. One, are they even discoverable? How hard is it to find 30 people?

(00:24:21):
What have you noticed across those 30 people? Are there any interesting insights? Maybe it's the size of the team they work on, maybe it's the industry they're in, maybe it's the length of time they've been in their role, maybe it's their previous roles in their career. Are there some commonalities? There's always some level of a commonality usually in most cases. Okay, so now you're starting to collect some parameters. Just by doing this exercise, you're starting to collect some parameters around who you want to learn from and sell to. Now if you send out those 30 notes and you wrote them specifically, and you spend good quality of time on it. And you've hit them on email, you've hit them on LinkedIn, maybe even tried to call them, maybe you've sent them a Twitter DM, pulled out all the stops. How many people respond? 1, 5, 0?

(00:25:15):
If it's zero, it begs the question, do you now want to do another 30 in a very similar fashion? Do you want to change the messaging a little bit? Now it forces these natural experiments. Or do you want to maybe go after a different role? So it forces you to answer these questions in a very manual way before you even think about integrating and spending time on tools. And then you get to a point where it's like, okay, now I'm starting to get some learnings and now I've realized, okay, it's this group of people, I've spoken to maybe two or three, now I want to go out and actually build a campaign to now talk to the next 10 to 15 people in that group. Truncate this as much as you can because I think people focus so much on volume in the beginning.

(00:26:06):
Even if you're selling down market, mid market, enterprise, volume comes once you've identified it and know the parameters. Parameters then allow you to do really strong enrichment with a clay. You now know the types of questions to give it. If you're not asking it the right questions, these enrichment tools, these sales tools will yield nothing. So it all comes back to even before you start your sales call, you need to make sure you're asking the right questions with am I even engaging, or do the people that I want to learn from or sell to, am I even messaging them in the right way? Are they even the right person? And the only way you can do that is by actually truncating these little experiments.

Lenny Rachitsky (00:26:49):
I love how tactical that is. And what I love is even one of your nuances you mentioned is can you even find them? This gives you a signal of how are... You're going to have to have hundreds of these, thousands of these eventually. If 30 is hard or impossible, you're in trouble already.

Jen Abel (00:27:06):
Totally. And it was funny, I was talking to someone today that said they had a target segment of high net worth individuals that they wanted to go out and serve. I'm like, how do you find those people? I guess when you get to a certain level, your net worth may be public. I don't know. That stuff's very hard to have certain parameters that are undiscoverable. And then if they're undiscoverable and it requires you getting on a call to understand if they are a fit, that does impact conversion rates. Not necessarily in a bad way, but now you need to kind of bring that back into the math equation, which is like, okay, if I speak to 10 people, I know two out of these 10 will be qualified. But I don't know which of those two out of 10. Well, that means you probably need more of those numbers.

Lenny Rachitsky (00:27:52):
So to quickly recap a few of the key things that I've written down as we're talking. So if you're just trying to figure out who to reach out to, make a list of 30 potential prospects that you think are good fits, that would be excited about what you're building. Spend 15 to 30 minutes writing them each an email. Do these emails have to be really short the way you described previously?

Jen Abel (00:28:12):
I would say the shorter the better, but would you respond to that? If you got this email, would you respond it?

Lenny Rachitsky (00:28:17):
Got it.

Jen Abel (00:28:17):
One of a great little tactical test is on Gmail, you can highlight the message and then have it replay it back to you from an audio perspective.

Lenny Rachitsky (00:28:28):
Oh wow.

Jen Abel (00:28:28):
You'd be shocked how many notes I've changed when it replays it back and I'm like, oh, that sounds really passive-aggressive.

Lenny Rachitsky (00:28:34):
Interesting. And so you also shared the structure for how to reach out to folks. So let me just share that again. And that applies to this initial email too, but it sounds like as you automate, you want to make it more precise and focused and not... Basically they're not as customized as you start reaching out to more folks.

Jen Abel (00:28:53):
Totally.

Lenny Rachitsky (00:28:54):
So start with something, here's why this is relevant to you. You're looking for salespeople in this market. Here's something that's unexpected or surprised, like zero to one salespeople don't exist. Keep it short and then I always forget the last one.

Jen Abel (00:29:14):
Focus on the problem.

Lenny Rachitsky (00:29:16):
Focus on the problem.

Jen Abel (00:29:17):
You don't even need to talk about the solution. That's the big takeaway, which is if you get any sales email, you get what's the primary focus of that email? It's usually like here's what we do. But I bet if someone reached out to you with a novel insight and said, I'm really passionate about solving this problem, if it's something you're focused on, you'd probably reply.

Lenny Rachitsky (00:29:39):
If it's a big problem. If it's like, oh yeah, you're so right, I need this.

Jen Abel (00:29:42):
The beauty with the American market, and I say this because we do a little bit of work with international startups too, is if something doesn't feel right, people love to complain about it. And it's like use that to your advantage. Get that intel.

Lenny Rachitsky (00:29:54):
A note that I just looked at, that I wrote down, that I think is very important is avoid using "this is better" as your pitch.

Jen Abel (00:30:01):
Yeah, yep.

Lenny Rachitsky (00:30:02):
Different. Here's something shocking about what we're doing. Here's something that'll surprise you.

Jen Abel (00:30:07):
Yeah, or counterintuitive. Exactly.

Lenny Rachitsky (00:30:08):
Counterintuitive.

Jen Abel (00:30:09):
Yeah, it's interesting. I spoke to a good friend that leads procurement at a massive organization. And he said to me, he goes, "One of the worst things someone can say to me is we're better than X product. Then I ask them to define that. And then I ask them, okay, how do we measure that? And then I say, okay, should we give this company another year to give them this feedback before we make this huge transition and disrupt momentum?" Yeah, better is a dangerous place.

Lenny Rachitsky (00:30:40):
I invest in a bunch of startups and I find it's impossible to get anyone to care if things are good enough with what they got today. I'm happy not using the best possible product if my life is okay. And I have so many other things I got to do, I'll just deal with this good enough solution for now.

Jen Abel (00:30:57):
Absolutely.

Lenny Rachitsky (00:30:59):
Okay, amazing. So we talked about how to figure out who to go after, how to pitch them to get them to want to talk. The next step I imagine is you're on the phone with them trying to convince them to actually care. What do you do there? How do you get them to engage further?

Jen Abel (00:31:15):
One is you need to be vulnerable. You're an early stage startup, okay. The market, we're at a point now where the market is smart. I always assume that the buyer I'm speaking to is highly educated and knows way more than I do. So just have that perception because what I've learned is a lot of the market will play dumb, and you can get yourself caught pretty quickly. So when you speak to them, I would be very open and honest with where you are. Hey, I'm an early stage startup. We are deeply passionate about solving this specific problem. We have a lot to learn. Here's how we are thinking about it from a problem priority perspective. Can we gain your insight into how this problem is manifesting on your side? And then let them open up. Now you have them one, talking about the problem. Now you're getting the intel about their perception of the problem, and is it even a problem? When you say you're early stage and there's still a lot to be done, it is easier to be honest.

(00:32:20):
If you tell them you have a fully baked, ready to go product, they're not going to give you honest feedback. It's very hard to say to a founder and look them in the eyes and say, hey, we built this product, can I show you what it is? You're just going to get someone that's going to say, oh, this is great, this is wonderful. But when you're vulnerable and when you tell them it's not fully built yet, even if it is, you will get more raw and honest feedback. Because it is easier to tell someone, hey, before you make this mistake, I actually don't care about that. If you've already built it, they're not going to give you that feedback. So the further you suggest you are, you're actually going to hamstring a lot of the intel, hamstring yourself on gaining a lot of the intel. So that's one counterintuitive thing that I think a lot of founders don't realize.

Lenny Rachitsky (00:33:07):
This episode is brought to you by Paragon, the developer platform for building native customer-facing integrations with third-party apps. Our native integrations on your product roadmap, whether it's to ingest context from your user's external data and documents, or to sync data and automate tasks across your user's other apps, integrations are mission-critical for B2B software products today. But building these integrations in-house cost an average of three months of engineering according to the 2024 state of integration survey, which results in difficult roadmap trade-offs. This is why engineering teams at Copy AI, AI21, and over 100 other B2B SaaS companies use Paragon, so they can focus their efforts on core product features, not integrations. The results, they've shipped integrations seven times faster, all while avoiding the never-ending maintenance that comes with rolling your own integrations. Visit UseParagon.com/Lenny to see how Paragon can help you accelerate your products integration roadmap today, and get $1,000 in credit on their pro and enterprise plans. That's use P-A-R-A-G-O-N dot com.

(00:34:14):
So I had April Dunford on the podcast a while ago. I don't know if-

Jen Abel (00:34:17):
She's awesome.

Lenny Rachitsky (00:34:18):
Amazing. And her last book, it actually has the opposite advice, but I think I know why, which is she focuses on later stage companies and her advice is the buyer. She has this really interesting insight that it's harder to buy software now than to sell it, because there's so much to consider and your job is on the line if you make a mistake. It's easier just to be like, forget it, I'm just going to go with what we have today. I don't want to put my ass on the line for buying this new thing that someone's trying. And so her advice is you actually have to educate the buyer on the market and here's what's happening. Here's where things are going, and here's why I think this is the future. But I think again, I think that's focusing on later stage stuff.

Jen Abel (00:34:55):
A hundred percent. And you raised such a good point, Lenny, which is late stage sales and early stage sales are very, very different. And I think that's where a lot of early stage founders get tripped up as they're taking late stage sales advice, usually coming from an investor. Or they've maybe hired a salesperson that's focused on more mature sales. But I think she's spot on. Buying is just as hard, if not harder, than selling right now. Because who wants to make a mistake and also who wants to go through switching costs? Oh, it's so painful.

Lenny Rachitsky (00:35:30):
Yeah. I think the other really important point here that you're making is that part of this initial sales experience of founder led sales is not sell as much as you can. It's to learn what people want. And so I love that you're sharing here's how to get the best possible feedback, not necessarily close the most deals.

Jen Abel (00:35:47):
Totally. And founder led sales is not about revenue on day one. It is about learning as fast as humanly possible to get to that pulse, so that you can earn the right to sell. There's this concept that I talk about, which is you're going out to run sales to collect the research, which is what founder led sales is. And then you have sales for revenue, which is that post founder led sales stage.

Lenny Rachitsky (00:36:13):
And your milestone that you suggested of how far to take founder led sales, you said around a million ARR, right?

Jen Abel (00:36:20):
Yeah. I think it's about, some people say 500, some people say a million. I think if you get to 500K really, really fast, then I think absolutely you can move out of it. If you get to 500K really, really, really slow, you might not want to get out of it right away. You haven't reached that velocity point yet.

Lenny Rachitsky (00:36:41):
Awesome. I have a post that we'll link to that has actually numbers and when all these big startups move from founder led sales. It's in that same series about product market fit. There's two stories this makes me think of I'll share real quick. One is Sprig. They shared a story of first round capital at their first round and their partner there is just like, we will not let you hire a salesperson until you hit a million ARR. We're going to help you. We're going to have salespeople helping you through it, but we're not going to let you hire someone. And he was really happy about that. The other is Zip, which just raised a $2.3 billion valuation, a procurement company that I was lucky to be an investor in. And their first founder led sales motion was they just reached out on LinkedIn to heads of procurement, and just leaned into what you're saving more, which is we just want your advice on this product that we're building. Just tell us what problems you have. It was very advice oriented versus we want to sell you this thing.

Jen Abel (00:37:33):
Yeah, no, absolutely. I have this theory that maybe you shouldn't hire any salespeople until series A, right? Because seed is all about experimentation and proving out that experiment, and then obviously series A is about exploiting that learning. But I see so many people, I mean hiring for early stage sales is the odds are actually more against you than trying to get your next round of funding. Because it's truly, truly such a counterintuitive stage.

Lenny Rachitsky (00:38:08):
Interesting. Okay, so I kind of took us on a whole tangent. You were sharing advice on how to get someone excited. So the first is when you're engaging, you're talking to the prospect and company ABC. Your advice is be very honest and vulnerable about your stage. Tell them you're early stage. You're building this thing. You're deeply passionate about this problem. Here's what we're trying to do, here's our priority problem perspective, and where we're focusing, and kind of get their feedback on your approach. Cool. You were going to go to the next tip and I took us off course.

Jen Abel (00:38:44):
Testing the questions to ask. Where is that aha unlock for you? But more importantly, where's that aha moment unlocked for them? Because when they start getting their gears churning in their head about, and this is the beauty about not having a product and not showing them anything, they're visualizing in their head now. This is a really powerful thing, which is like, so tell me how this looks in your head? How are you seeing this? And they're like, I don't know if I can see it. And I'm like, great, we'll show you that. Great insight to know by the way. Or so I think this is how, I guess this is how it would work. Walk me through what's living in your head right now. You pick up on so much and then all of a sudden they're like, wait a second, we've tried solving for this and it's still not solved for. Or you know what? We hired someone last year to manage this. Great understanding. Is it being measured? Is it being managed and have they tried to solve for it? The leading indicators that you're onto something here.

Lenny Rachitsky (00:39:44):
I love this thread because this is what everyone's always like, how do I know if I product market fit? There's these signals that you're talking about of signs that there's something here. Like a big enough pain point where they're excited to basically they want to pay for it, they will pay to solve a problem. So maybe just again, say the things you notice that are signs like, okay, you have something here.

Jen Abel (00:40:03):
So I think the first is it has to be a growing and widening problem. No one's going to spend time fixing a pretty fixed problem, because it's not necessarily really a priority anymore. It's maybe a pain in the butt, but it's not a priority if it's not growing or widening. So gate check one is like, what is the implication? Are you measuring? Are you managing this problem today? Yes or no? If they don't know, great to know. If they said no, okay, move on to the next. That's pretty powerful. No, we're not measuring or managing this. Okay, there's probably not much there. If it is being measured or managed, then the next question you want to get into is how have you tried to solve for it? Is it through that head count that you just hired? Is it through another tool? Is it just still an open gap because nothing exists yet to solve it? Just understand their maturity around how they've tried to plug it. These are all that make the secret moments in intel to close that gap.

Lenny Rachitsky (00:41:06):
That's awesome. And essentially it's showing you that there's a pain here that they're paying attention to and are trying to solve.

Jen Abel (00:41:14):
And what you're psychologically doing is now you're flipping them into a buyer where they're like, wait a second, hold on. I need to bring on so-and-so on the next call, they also think that this is not good enough.

Lenny Rachitsky (00:41:26):
That's funny because that's exactly what Wiz noticed, is they moved from people being like, oh, this is cool. I like it, I like it. To, okay, I'm going to pull in this person. I'm going to pull in this person to talk about it and make sure we're... And they were pulling in other people exactly as you described it, because they wanted to move forward on this thing.

Jen Abel (00:41:44):
Absolutely. And that's when you know there's some momentum behind it, which is when they're bringing in other colleagues. Whether it be the potential users, if you're reaching out to the executive, or the users like, hey, I actually want to bring my boss on to the next call.

Lenny Rachitsky (00:41:57):
Good sign. Cool. Anything else along these lines of how to get someone excited slash understand if there's going to be pull there?

Jen Abel (00:42:04):
I guess the one thing is please, please, please do not ask questions like what keeps you up at night? If you had a magic wand, what are your pain points today? I can guarantee you that answer changes every single day.

Lenny Rachitsky (00:42:19):
That's super interesting. Is there any tip for how to end one of these calls, as someone that's never done sales is like-

Jen Abel (00:42:23):
Yes.

Lenny Rachitsky (00:42:24):
Okay.

Jen Abel (00:42:25):
Get the second call booked on the first call.

Lenny Rachitsky (00:42:28):
Love it.

Jen Abel (00:42:28):
Pull up calendars. Look at calendars. Who else should be invited? It's just a natural evolution to ending the call.

Lenny Rachitsky (00:42:35):
Great. So that's in 30 minutes though, right?

Jen Abel (00:42:38):
And if they say, ah, I'll email you.

Lenny Rachitsky (00:42:42):
I could say.

Jen Abel (00:42:44):
That's also kind of a leading indicator. Yeah.

Lenny Rachitsky (00:42:46):
So do you recommend not getting off the call, trying to avoid that, or is it just-

Jen Abel (00:42:50):
If they won't give you time on the calendar, you could say, listen, great. Feel free to email me. Maybe they're just being honest and they don't have their calendar available, but nine times out of 10, it's usually I don't have the heart to tell you I'm not interested.

Lenny Rachitsky (00:43:04):
Yeah, it's hard. It's hard to tell people you're not interested. Very cool. Okay. This is amazing. Okay, so the next step, if I remember correctly, is kind of co-authoring and co...

Jen Abel (00:43:13):
Yes.

Lenny Rachitsky (00:43:14):
Okay, cool. Talk about that.

Jen Abel (00:43:16):
In the early, early days, one of the biggest ways you can get folks excited is it feels like it's going to be built specifically for them. The power of specificity, the power of being extremely focused. With that, you can literally turn a customer into a guide by asking them to co-author the scope. The scope of work. The co-authorship piece is important for two reasons. It helps you understand where they're on their biomaturity. Let me explain. If they do not have an existing process or strategy to solve X problem, they can't buy a technology yet, which means you need to sell them. And this is why I go back to you need to sell them some form of a service, right? Why? You want to be the one in there educating. You also want to get the logo. You also want to show the revenue. While it's not recurring revenue, it still shows intent.

(00:44:13):
And I think that that's really important. Every founder I speak to is like, well, my investor really doesn't want service-based revenue. That's fine. But then you can also tell your investor, great, should I wait 18 months to when they're ready to buy a solution, and be the one that's not the one selling them because someone else educated them? These are all of the implications of waiting. So yes, is service-based revenue great? No, we all know why it's not great. But it's great in the sense that it shows intent. It's great in the sense that you can call them a customer. It's great in the sense that now you can use their logo. And it's great in the sense because you are getting paid to educate them. You are getting paid to help them design their process. This is where all the power lives. And this is why so many AI startups a year and two years ago were going in on services contracts, because they wanted to set the mindset with the buyer around what this would look like.

Lenny Rachitsky (00:45:07):
Is there anything you recommend to time box contain the services piece? Because I know a lot of companies-

Jen Abel (00:45:12):
Yes, such a great point, Lenny. You absolutely need to time box this. I would time box it as 90 days and then what you can say in the next 90 days, we'll scope where we are and what you need. Scoping out more than 90 days, listen, so much is going to change. You might also not want to do it anymore, so you don't want to lock yourself up. So I would look at 90 day increments. A specific example. We had a founder that my colleague was working with, and they were selling a very specific technology to a non-traditional... Sorry, a very traditional industry. I don't want to be two bleeding with what it is, but a very traditional industry that's not used to working with startups, or necessarily plugging in a new technology right away. And they were very honest. They said, listen, we haven't changed vendors or partners in over five or six years.

(00:46:04):
I actually don't even know how we would do that today. Could you come in and explain to us, understanding where our workflow is and how we would integrate this, before we even consider the technology? Which we did. We got paid a nominal amount, but we're now a customer and now we get to set the stage for how they think about this. And then they won the technology contract. But everyone is so focused on selling the technology really, really, really quickly. That works in markets that know how to buy that technology, have a process in place, have a strategy in place, have an implementation team in place.

(00:46:40):
If it's a new technology like AI right now, they need a strategy and process like who's the human in the loop? Is it them or is it you? How do we measure success? What does success look like? What risks should we be aware of? Our legal team's not even aware of all these risks. You want to be careful because legal can immediately, and procurement, can shut these things down if it seems too novel, where it's foreign versus they're so used to buying services, especially at market. It's their largest budget line item.

Lenny Rachitsky (00:47:10):
So it's interesting because most founders are very afraid of moving into services. I hadn't heard this advice before.

Jen Abel (00:47:15):
Probably going to get slapped for saying all this stuff, by the way.

Lenny Rachitsky (00:47:17):
Well, so along those lines, what percentage of companies that you've worked with or see do that or have to do that step?

Jen Abel (00:47:25):
This is going to be a shocking step. So I would 40 to 50% have to sell some form of service before they can sell a technology.

Lenny Rachitsky (00:47:34):
Wow. Of B2B SaaS company?

Jen Abel (00:47:36):
A B2B SaaS. And this, again, this is specifically more top-down sales. But yeah, because the user and the buyer are different, which means there's user value, there's buyer value, there's all different players, there's procurement you have to go through. But yeah.

Lenny Rachitsky (00:47:50):
And just to make it even clearer, what's an example of a service that you've seen company offer in a step?

Jen Abel (00:47:55):
So I've seen, hey, can you come in and actually help me pitch this, design a custom pitch to my boss as to why we should do this today? And we literally got paid to build a sales pitch.

Lenny Rachitsky (00:48:09):
So it's not necessarily providing a service. It could be just helping them sell this.

Jen Abel (00:48:15):
Yeah. It could be helping them sell in a way that makes you... You need to get a lot more context on their business. It can also be, hey, we haven't actually thought about a process for how we can actually deploy something like this. We're currently using this technology, which we want to change from. You've kind of hit this at the right time. How would we implement or how is it best to integrate with this tool? Can we get both of you guys in a room to map this out?

Lenny Rachitsky (00:48:43):
Got it. So it's like consultants almost, like coming in to help you solve this problem.

Jen Abel (00:48:47):
It's a great point. It's consulting them towards the acquisition of the product. It's not consulting as one-off consulting.

Lenny Rachitsky (00:48:53):
Got it. And they know that obviously you're biased, but they also want the problem solved. And they're like, great, you're going to help us solve this problem, because it's on my plate and I need your help convincing leadership that this is-

Jen Abel (00:49:04):
And I need to craft the storyline as to why we need to do it anyway, so I will pay you to do it, but here's the format it needs to be in.

Lenny Rachitsky (00:49:10):
Fascinating. Wow. Okay. Anything else along those lines?

Jen Abel (00:49:15):
And then of course, if you're in a position to actually sell the technology, because the market is able to acquire and adopt it and not have to create a new strategy or process, then obviously sell the technology. You don't need to be selling services.

Lenny Rachitsky (00:49:26):
I want to come back real quick. The previous call, I wrote this note down as you were talking. You recommended not doing a demo and just talking about it broadly.

Jen Abel (00:49:34):
Yes.

Lenny Rachitsky (00:49:34):
Is that your advice there?

Jen Abel (00:49:36):
On the first call. Yeah. On the first call, my fundamental belief is that the demo is a bit of the only carry you control in the sales process, right? Once they see it, it's kind of like pitching an investor. Once they take a look under the hood, that dreaminess in their eyes, they're like, oh, I saw it. So leave them wanting more. And the demo is that, leave them wanting more. Even when you do a demo, don't demo everything. Leave it for a second call. Let them invest a lot of time in you. Again, if it's qualified. Preface that, if it's qualified. But everyone races through the sales process like let's do a demo call as quickly as humanly possible.

(00:50:20):
Yes, that is important down market. That is important if you're selling a $3,000 tool, you absolutely want to be demoing as fast as humanly possible because it's a high-volume game. Upmarket, when you're talking about hundreds of thousands of dollars, you want to slow that down as fast as possible. Because you want to, one, make sure all of the right people are in the room. As soon as there's one lead on this, and if it requires other people involved, it doesn't feel like anyone else's baby. So you want it to make it feel like the group's baby versus this one individual's baby because it's very quick. Someone can easily say, I'd rather use this tool. And then there's this stalemate of nothing happens.

Lenny Rachitsky (00:50:55):
Just to maybe reiterate, so far we've talked about figure out who to talk to, pitching them on talking to you, then having that first conversation. Maybe there's another conversation in there to get them excited. And then there's just getting them past the finish line, keeping everyone aligned. Is that roughly the next step or how should we think about this?

Jen Abel (00:51:14):
Yeah, so if you are selling upmarket and you now need to go to procurement, who is the group involved in the bot. They're the professional buyers. Procurement is a very interesting function. They are very smart, very, very smart. They do this for a living. They are professional buyers. So there's a couple things that you need to be aware of. You need to sell them as well. You need to really make this sound... Don't over complicate it. Don't add in jargon. Make it feel like, okay, I can wrap my head around this. The second piece is it's got to feel different from anything else out there. Because the professional buyer, it's much easier to say, wait a second, we have these 17 other preferred vendors that do similar ish work. Why don't you just go use one of them? Because, oh, by the time this gets through procurement, it could be another three to four months.

(00:52:05):
I've seen deals die on the vine because procurement actually suggested they go use another vendor in the system, that this buyer wasn't even aware of, because they didn't differentiate. It didn't feel different. It just felt slightly better. That's how it was positioned. The third piece is when you get to procurement, you're going to have to do all the work. Make their job easy. You are probably a very small piece into the very large deals that a lot of these people buy. So you can get easily sidelined just because you're just a small buy. So do the work for them. Literally say, I want to make this as easy as possible for you. Give me the forms that you need to fill out. I'll fill them out for you, and you can do it yourself. You can edit them. Do the lift for them. If you don't, it's so easy for it to just go there and die.

(00:52:55):
Another piece that's important with procurement is explaining exactly what you do and don't do. Because if you say you do a bunch of things and they can't really place you, they're going to send you to the kitchen sink of contracting an MSA, which is going to ask you for $5 million in an insurance policy and all sorts of other things. And the ability to look at your book at any point in time. And the reason they did that is because they can't classify you. So the easiest thing to do is classify you as high risk. So make it easy for them, make it simplified. You can also truncate your contracts, meaning let's say IT is maybe, and you want to ask this, how long does it take to get through IT due diligence? They might say, oh, it's a 90-day backup, it's a 60-day backup, it's a 30-day backup.

(00:53:43):
There's no backup. If there's a backup, you also don't want it to die and you want it to give an incentive. So this is when you want to truncate contracts to a technology contract and a service contract. Service contract allows you to onboard them, get them prepped, come in and educate all of the users about what they're about to go through. So that then there's an incentive to get that technology piece through. There's all these little things to think about, and I think everyone... Getting to procurement is also creative. And knowing who you're dealing with and how to make their job as easy as humanly possible. Because what you said and what April said is spot on, which is buying is just as hard as selling.

Lenny Rachitsky (00:54:23):
As I'm hearing you describe this, I feel like we might be discouraging people from selling because this feels very not fun. All these steps, all these procurement work, anything you can say to get people to feel like, okay, this is worth it?

Jen Abel (00:54:35):
Yes, I can get people very excited by this. Once you are in, you are in. Once you are in, you are now a preferred vendor. You now have the ability to cross over into other business units. You are now the reason that, hey, if your competitor comes in, well, you got there first. So what do you think procurement's going to say? This is why it's so important to get into the enterprise as fast as humanly possible. While it's a headache to get through, if you project manage it, you'll be good. If you make an accountability, just like if you were to go through fundraising. If you are a part of a team that had to raise money, it's no different. There's always some level of due diligence. There's always you doing more of the work than them. That's just enterprise sales. But if you prove value, your hundred thousand dollars deal could be $500,000 next year. Your $500,000 deal could be a million dollars the following year.

(00:55:36):
This is where stuff begins to compound, and this is where your growth journey really gets accelerated. So the beauty with enterprise is once you're in, you're in. You beat out your competitor for a short period of time. There is a little bit of a moat there, but it's not forever. You all have intel that no one else will have. Meaning you're a part of the conversations, you have the badge, you can join the meetings, you can ask for introductions. They'll do it. It doesn't feel like sales anymore. You're now a partner. This is why it's so powerful to get into the enterprise because there's so many compounding effects. If you put the effort in on the sales side, the return is insane.

Lenny Rachitsky (00:56:20):
That was awesome. Nailed it. I'm excited. Just for folks that are listening, just to calibrate what size of company you're talking about selling to here, what's the size of the advice you've been sharing so far? Roughly?

Jen Abel (00:56:33):
So I've been talking a lot about enterprise sales, which is I would say anywhere north of 500 to a thousand employees. Just mental model. I'm talking about enterprise sales specifically because there's so much nuance involved in it, because the user and the buyer are very different, right? As you go down market, let's talk about small business for a second. The user and the buyer are the same person. There's no procurement. If they like what you've built, it's pretty straightforward process. In the mid-market, mid-market is a funky place because you either are anchoring towards the lower end of mid-market, which is more upper end of small business, or you're anchoring towards lower end enterprise. Those are two very different divides. So mid-market, just if you're talking about lower end enterprise, again, this is all relative. If you're talking about lower end small business, again, your user and the buyer probably are the same person, which makes sales a lot more streamlined.

(00:57:31):
But churn. Small business, challenge with small business is the churn. If they get pissed off, if they don't feel like it's good enough, they are gone faster than you don't even realize. And they might even tell you. They'll just cancel. And we always see this on Twitter. They'll call American Express and say, cancel these charges. I don't want to talk to these people anymore. They're just more irrational because sometimes maybe it's their money if they're a small business. So small business in mid-market, while sales is a bit faster, you really got to be on the product market fit side, worried about churn.

Lenny Rachitsky (00:58:07):
And they also go out of business at a higher rate.

Jen Abel (00:58:07):
Exactly.

Lenny Rachitsky (00:58:07):
And so you have that kind of churn.

Jen Abel (00:58:12):
A churn piece too. Yeah, exactly.

Lenny Rachitsky (00:58:14):
Amazing. Okay. What comes next? So we're kind of in procurement at this point.

Jen Abel (00:58:19):
Okay, so now we're at signature, right?

Lenny Rachitsky (00:58:21):
Okay.

Jen Abel (00:58:21):
Okay. So as you enter procurement, okay, you want to know before you get to the next stage, who is signing this deal? Here are some examples of signers I've seen. Chief financial officer, chief legal officer, the business unit head themselves, the head of procurement. You want to know who that person is so that you can literally say to the head of procurement, hey, listen, I want to make sure this person has everything they need when they review this, to know what they're signing. Who is it and how can I give you a few bullets to share that you can maybe respond to, that we get tight so that they know exactly what they're looking at?

(00:58:59):
This was two or three years ago, I was involved in getting a deal over procurement that was just truly, it was a pharmaceutical company and it was very, very long process. And we got to the finish line and the CFO was the signature. And this is when I made the mistake. CFO responds back to the procurement lead who sent it to the business unit, who sent it to me and was like, what am I signing? I don't actually understand what these people are doing and why are we doing this?

(00:59:32):
So then she quickly said to me, hey, listen, we need to defend this. Can you put together some bullets? And I'm like, well, what kind of bullets do I need? What does this person care about? And again, it created so much anxiety and now I'm back in the bottom of the queue. Probably he or she's looking at the things that come in in an order of priority. So now I've elongated this by another month simply because I didn't plan. So this is just to say I'm learning from my own mistake of know who the signature is, because if they don't know what they're looking at, they're going to kick it out and you're going to lose your queue spot.

Lenny Rachitsky (01:00:06):
So many ways to fail. And this was you selling Jellyfish or this was you working with a company?

Jen Abel (01:00:11):
This was me helping [inaudible 01:00:15].

Lenny Rachitsky (01:00:15):
Oh man. Okay. Anything else in that step that might be helpful to folks?

Jen Abel (01:00:19):
Yes. One thing to caveat is you do not get paid until you are approved by finance, and procurement has a signature on the contract. Meaning don't start any work. Or if you do start work, know that there is no payment. The business unit can't just pay you. It's paid through a purchase order, which is paid through by finance.

Lenny Rachitsky (01:00:45):
So don't rely on that money unless it's finally, unless the signature's on the paper. Quick tangent, thoughts on discounting at any parts of the journey?

Jen Abel (01:00:54):
If there is a reason as to why. So discounting just to get the deal over the line, you're negotiating with yourself. Unless they ask for it and then ask them to defend it. Certain segments, like small business, you should leave a little bit of room for buffer because sometimes that's their own money. It's like their own small business. Mid-market and enterprise, there's got to be a reason why and ask them. Be like, hey, so if I give you a 30% discount, can I remove 30% of the value? You can kind of play it a little bit like that. I don't recommend it, but that's kind of what they're saying. But discounting is great if they're doing something for you far and beyond. For example, if they're a design partner, if they're going to be a reference for two years, if they're going to give you something far beyond just using the technology, then yeah, I think a discount is a good reason to give back to somebody that's giving to you, but not as a strategy to get a deal done.

Lenny Rachitsky (01:01:57):
Okay. Is there anything beyond this step of getting the signature? Are we done?

Jen Abel (01:02:01):
Yeah. I hope you celebrate because-

Lenny Rachitsky (01:02:03):
Okay, great. You got a signature from this whole process.

Jen Abel (01:02:08):
Yeah. Hopefully I'm not making this sound too daunting. I'm just really trying to lay out all the mistakes I've made.

Lenny Rachitsky (01:02:12):
Yeah, no, this is exactly what people need. This is amazing. And your pep talk was really helpful too. Along the way. What's the general timeline for sales process like this in your experience, with these 500 plus ice companies?

Jen Abel (01:02:26):
So there's three things that dictate sales cycle. One is how well are you project managing it? For example, I'll say, let's have our second or third call in two weeks. Two weeks? Do a week. Why are you elongating this? Keep your calls as tight as possible because that shortens your sales cycle. The second is just how complex the organization is. If you're dealing with a highly regulated industry, just know it's going to take a bit longer, sometimes 20 to 30% longer. So a highly regulated industry, nine to 12 months on conservative, on the conservative side. Again, it's tricky because is there a budget line item dictated towards it yet, or are you creating budget? How painful is the problem? And how senior have you gone? If you're talking to the SVP or chief of whatever, they're pretty good at about being able to navigate the traps.

(01:03:28):
If you're dealing with a director or mid-level person, they maybe have not purchased something before and just make some internal mistakes. I always say it can range anywhere. I've seen enterprise deals close in 90 days, believe it or not. Rare, but I've seen it. I've also seen enterprise deals typically take anywhere between six and 12 months. Really important but. Enterprises know that the process and the length to get the deal done is what costs more than the technology itself. Meaning the effort it takes to get through their system. That's why they're willing to spend so much. Sometimes that's actually more expensive than the technology itself. So don't negotiate with yourself, understand the value you're delivering, but don't be crazy. I've seen people try and go in with a million dollar deal as a seed stage startup. Oh, interesting thing. So interesting tactic. I've seen contracts in the enterprise that state that the deal cannot exceed more than 20% of the existing revenue.

(01:04:39):
So there are these things just to be aware of. In most cases, you can ask them be like, is that a hard line? Is that hard, hard line? Or how negotiable is that? Sometimes it's negotiable. Sometimes it's like, no, this is a hard rule. But then it seems silly because you take a hundred thousand dollar deal and bring it down to 20,000. It's just be careful that you're stripping some of the value out. But I kid you not. I've seen an enterprise deal go from, it lands at 60 and it turns into 280,000 in four months. So again, I want to encourage, yes, this is a lot of work, but the payoff is exponential.

Lenny Rachitsky (01:05:19):
What's a good ACV to start with if you're trying to sell to enterprise, to make it all worth it for your startup?

Jen Abel (01:05:25):
I would say anywhere between 50 to 200K depending on the business unit you're selling to. That's kind of like sweet spot. They're used to something in that realm.

Lenny Rachitsky (01:05:35):
And this is a startup selling [inaudible 01:05:38].

Jen Abel (01:05:37):
Early stage startup, like founder led, early stage.

Lenny Rachitsky (01:05:42):
Initial contract. Wow.

Jen Abel (01:05:43):
Yep. Initial contract. I would say, okay, probably caters more towards like 50 to 100K. But I've seen people sell to... Again, it's how big is the problem? Who are you selling it to? Is it the SVP that you started with and they've got a large budget, and it's a pretty healthy business unit? Or are you selling to a director?

Lenny Rachitsky (01:06:05):
If you're not able to sell your product at that price? What's your advice to teams?

Jen Abel (01:06:10):
If you are a startup, I always ask the founder, did you build this for the enterprise and is that the model you want to play? Or did you build this for small business? Small business is a marketing game. Marketing intensive activity, right? It's high velocity, high volume, lots of dials. It's a very different game than enterprise. So which game do you want to play? Let's just start there. Which game is more attractive to the founder. Or who is more exciting to serve? What's the storyline you want to tell investors? That plays a lot of it into it too. And do you have an enterprise product? Are you solving an enterprise problem or do you think you're solving an enterprise problem but you're not sure yet?

Lenny Rachitsky (01:06:53):
And your point is also mid-market is it's rarely to be successful.

Jen Abel (01:06:57):
It's hard to start there because you're straddling two very different go-to-markets, right? One that's of high value, one that's of high volume. And also mid-market companies, this is where a lot of people don't... If it requires heavy integration, they don't have those resources. That's usually outsourced to an Accenture or some of these consulting firms, and now you're having to rely on third parties to be involved. It gets messy.

Lenny Rachitsky (01:07:25):
This is fascinating. I have a list of questions from the audience that you pulled from Twitter. You asked on Twitter what questions to ask you as you're coming on here. So there's one that's very related to this, which is someone said, if you're still very early in pre-product market fit, but get initial validation from both small to medium businesses and enterprise, how do you decide which one to focus on? Is there a counter argument against starting or SMB going up market over time like most companies do?

Jen Abel (01:07:51):
I've seen companies successfully do in both of those motions. Truthfully. We know all of those. We know people that started small business and worked their way up into enterprise and were successful. We've seen people be really successful by starting at the enterprise, like a Wiz. That's more of an internal question, which is like, who did you build this for? Where's the problem most felt and which go-to-market game do you want to play?

Lenny Rachitsky (01:08:15):
And I think that latter part is so important. It sounds like why should it be what I want? It's like what's going to make a big business? But I think people forget, this is going to be your life for 10 years. Do you want to be selling to enterprises and building all the enterprise features? Would you prefer to build for small companies? Pros and cons to both but it's important to think about the life you're creating for yourself and your team.

Jen Abel (01:08:36):
A hundred percent. And I built my career in enterprise sales, upper-end mid-market enterprise sales, and yeah, that's just the game I know the best.

Lenny Rachitsky (01:08:46):
Yeah, that's also an important part of it. Just to double down on that is like what do you have experience doing? Not like...

Jen Abel (01:08:52):
Exactly.

Lenny Rachitsky (01:08:53):
Yeah. Where's the opportunity? Okay. Another question that I love is, and we touched on this initially, but I think it's good to come back to this. Someone said, customers are fascinated with what we're offering from the initial calls, but responsive momentum is too slow from their end. Would be great to know how to fix this.

Jen Abel (01:09:10):
Yeah, it's tough because unless you're in the weeds to understand why. I'll give you a few examples that it could be. Did you speak to a buyer who now is trying to sell this up to their boss, and it's just getting sidelined and they don't know the executive value? They've just been selling the buyer value the whole time. That's one reason things can slow down. Another reason things can slow down is you haven't really framed the problem well and they don't understand the full implications of why they need to solve it. So it's kind of just sitting there a little bit. The third is they've just been really nice and it's not going to go anywhere.

Lenny Rachitsky (01:09:49):
I guess that that's usually the latter. Was that true or it's kind of all over the place?

Jen Abel (01:09:54):
It's so hard to give a founder hard feedback. Because they've just dedicated their life to this thing. Who wants to be the bearer of bad news? And sometimes you just need to let the actions speak louder than words.

Lenny Rachitsky (01:10:11):
We've talked about all these steps. I'm curious, when you come to a founder or your team, where do you find the most on lock often? Which of the steps of the sales process do you find the biggest opportunity to improve conversion in sales?

Jen Abel (01:10:25):
It's qualification. Qualification because if you spend your time on the wrong leads, that equates to a zero. So if you don't get that first level right, let me put it this way, everyone that I know says they have a bottom of funnel problem. It's never a bottom of funnel problem. It's a top of funnel problem. I've actually never seen a bottom of funnel sales problem. It's always qualification, which is a symptom of not reaching out to the right person, not having the right messaging, not solving the right problem, or not being different enough.

Lenny Rachitsky (01:11:06):
I love this. So basically the biggest pitfall people fall into, in your experience, is they're just talking to the wrong people, wasting their time?

Jen Abel (01:11:15):
Yeah. Talking to the wrong people or using the wrong message or...

Lenny Rachitsky (01:11:20):
Pitching them something they can't actually deliver.

Jen Abel (01:11:23):
Yeah. Here's the other thing too. Sales is supposed to feel fun for the buyer. They should be like, this feels fun. This person's invigorating. They're going to change my world. They're going to make me see things differently. They're going to get me promoted. They're going to help me increase my influence internally. And so many salespeople are so boring. How many times have you got off a call and you're like, I can't wait to get off this call? And founders too, just like all of a sudden their passion, they go like stone cold face. And it's like bring the passion. Bring the energy. That is felt by the market. Remember, some of these people are in boring jobs. Give them an outlet.

Lenny Rachitsky (01:12:01):
So along those lines, I think a lot of people are just not... Like me included. I feel weird doing sales. It's a weird experience trying to convince someone to buy something. Is there any advice you could share to get someone over that hump?

Jen Abel (01:12:13):
If you have built something that you believe in. Very hard to sell something you don't believe in. I think everyone agrees that. If you've built something you believe in and they have a problem, that's a beautiful thing. Truthfully, that's what makes the world go around, is I have a solution to your problem. Now you just need make sure that the problem, you just need to be honest, that the problem they have, your solution truly can solve for. And you're not short selling just to get a logo and a deal over the line, and see them churn in six months or nine months or three months. That what you are selling is truly going to solve their problem. And be honest about it. I can't tell you enough when I tell someone, listen, I don't think I'm the right fit for you. They try and sell you on them.

(01:12:58):
They're like, well, wait a second. Hold on. What if we did this, this, and this? And it's like, no, no, no. Here's what we're great at. And then they can say, well, I also need that too. And all of a sudden, this level of trust comes out. And trust is the number one currency in sales. If you are a trusted salesperson, people will recommend you all day and every day. If you're a trusted founder, your market will continually send you leads and word of mouth. So don't try and sell something just to prove to investors you sold something, because it'll be quickly seen on the other side when they churn.

Lenny Rachitsky (01:13:32):
Amazing. Okay, Jen, so I'm going to cut the lightning round. I know you also have to run and do real work. So let me give you a chance just to talk about what you do, how you help companies in case folks can find value in working with you.

Jen Abel (01:13:44):
Deeply passionate about sales, as I'm sure you can tell. We specifically help founders through this pain. Navigating enterprise sales, mid-market sales, and really trying to crack that first million of ARR. Or sometimes even that first 500K of ARR if they move fast enough. And it is really hard. It's counterintuitive to what most people think, but it can be really, really fun when we show you the way.

Lenny Rachitsky (01:14:13):
And you described to me how it works, and I think it's important to clarify this. You basically embed with the team and help them do this.

Jen Abel (01:14:19):
Yes. So I fundamentally do not believe in outsourcing the heartbeat of the organization, which is sales. So what we do is we embed alongside the founder and drive a lot of the execution, but make sure that they are the tip of the spear engaging directly with their market, and learning directly from the market's mouth, not playing this game of telephone.

Lenny Rachitsky (01:14:40):
Amazing. And I mentioned this when we were chatting, but I think of it again, is when I was interviewing all these companies about how they started selling early on. One of the interesting threads that I heard again and again, is how many of them hired a coach or a consultant as a founder to help them learn to do sales. And that's essentially what you do. And I didn't even know a service like this existed, so this is super cool. It'll point people to what you do. I also have to ask you, the question I ask everyone at the end is just, how can listeners be useful to you?

Jen Abel (01:15:08):
Help each other out. I think so many people have helped me in my career, and in this journey, that the pay it forward model that exists in the technology space is so beautiful. So just don't let that die.

Lenny Rachitsky (01:15:28):
Beautiful. Well, Jen, thank you so much for being here.

Jen Abel (01:15:32):
Lenny, this was awesome. Thank you so much for having me.

Lenny Rachitsky (01:15:34):
So awesome. So excited for folks to hear it. I've learned a ton. Okay, I'll let you go. Bye everyone.

(01:15:41):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at Lennyspodcast.com. See you in the next episode.

---

## How have I been complicit in creating the conditions I say I dont want? | Jerry Colonna
**Guest:** Jerry Colonna  
**Published:** 2025-05-08  
**YouTube:** https://www.youtube.com/watch?v=PJE7etZQ9us  
**Tags:** growth, roadmap, iteration, a/b testing, experimentation, analytics, monetization, leadership, management, strategy  

# How have I been complicit in creating the conditions I say I dont want? | Jerry Colonna

## Transcript

Jerry Colonna (00:00:00):
We're socialized to bullshit not only ourselves, but everybody else, especially in the entrepreneurial community. All our companies are moving up into the right. Every product is working. We don't really have any problems because we're crushing it, and that's just a lie. The question that I often ask is how have I been complicit in creating the conditions I say I don't want. The purpose of this question is actually to evoke your own agency. A perfect example of that would be, I say I don't want to feel busy all the time, but the truth of the matter is I feel really unnerved and disconcerted if my agenda isn't jam-packed. So if you want to create a high-functioning team, do your work, and it starts with the person who has the most power.

Lenny Rachitsky (00:00:49):
Today, my guest is Jerry Colonna. Jerry is one of the most well-known and respected executive coaches in the world. He's co-founder and CEO of Reboot, an executive and leadership development firm grounded in the belief that better humans make better leaders. Prior to coaching, Jerry co-founded Flatiron Partners with Fred Wilson, which ended up being one of the most successful early-stage investment funds in the world. He's also a partner at JPMorgan Chase and the author of two books, Reboot and Reunion. As you might expect, this ended up being a very real and very open conversation about being busy and self-inquiry and the dangers of a growth mindset and the reasons that leaders and teams most often fail, and it's not what you think. Also, we talk about a very simple equation that Jerry and his team use to cultivate great leaders.

(00:01:37):
This is an episode that everybody should listen to and spend time with. It'll make you a better person, a better partner, and a better leader. If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. Also, if you become an annual subscriber of my newsletter, you now get a year free of Linear, Superhuman, Notion, Perplexity, and Granola. Check it out at lennysnewsletter.com and click bundle. With that, I bring you Jerry Colonna.

(00:02:05):
This episode is brought to you by Eppo. Eppo is a next-generation A/B testing and feature management platform built by alums of Airbnb and Snowflake for modern growth teams. Companies like Twitch, Miro, ClickUp and DraftKings rely on Eppo to power their experiments. Experimentation is increasingly essential for driving growth and for understanding the performance of new features. And Eppo helps you increase experimentation velocity while unlocking rigorous deep analysis in a way that no other commercial tool does.

(00:02:35):
When I was at Airbnb, one of the things that I loved most was our experimentation platform where I could set up experiments easily, troubleshoot issues, and analyze performance all on my own. Eppo does all that and more with advanced statistical methods that can help you shave weeks off experiment time and accessible UI for diving deeper into performance and out-of-the-box reporting that helps you avoid annoying prolonged analytics cycles. Eppo also makes it easy for you to share experiment insights with your team, sparking new ideas for the A/B testing flywheel. Eppo powers experimentation across every use case, including product, growth, machine learning, monetization, and email marketing. Check out Eppo at geteppo.com/lenny and 10X your experiment velocity. That's geteppo.com/lenny.

(00:03:22):
This episode is brought to you by Contentsquare, the analytics platform that helps companies build better digital experiences. Ever wonder why customers drop off before converting or why some pages perform better than others? Contentsquare takes the guesswork out of digital experiences, giving you real-time insights into how users interact with your site or app. With AI-powered analytics, automatic frustration detection, and clear visualizations, you'll know exactly what's working and what's holding your customers back. Whether you're optimizing an e-commerce checkout, refining a B2B lead flow, or improving a mobile app experience, Contentsquare pinpoints exactly what needs fixing and why. Contentsquare powers better customer journeys across 1.3 million websites and apps. Discover the insights you've been missing at contentsquare.com/lenny. Jerry, thank you so much for being here and welcome to the podcast.

Jerry Colonna (00:04:19):
Well, thanks for having me, Lenny. It's really a delight to meet you and to be with you today.

Lenny Rachitsky (00:04:24):
I want to start with a very classic Jerry Colonna piece of advice that I've heard you share in other places, and I just want more people to hear this advice, and this is a question that you ask people when things aren't going their way, and I'll give you a hint. The question contains the word complicit.

Jerry Colonna (00:04:40):
Right.

Lenny Rachitsky (00:04:41):
Can you share this question and why it's so important to ask this of yourself?

Jerry Colonna (00:04:45):
The question that I often ask is how have I been complicit in creating the conditions I say I don't want? And if it's helpful, let me break down the question a little bit.

Lenny Rachitsky (00:04:55):
Please.

Jerry Colonna (00:04:58):
So I purposely chose the word complicit because complicit does not mean responsible, and that's a really important distinction. And as I often say, to understand the word complicit, think of the word accomplice. As I will share, you are driving the getaway car, you're not sticking up the bank teller. The second half of that question is I say I don't want. And sometimes people hear that question and they interpret it as, how have I been responsible for the shit in my life? And that is not the purpose of this question. The purpose of this question is actually to evoke your own agency, is to look at the ways in which you may have been diluting yourself.

(00:05:56):
A perfect example of that would be, I say I don't want to feel busy all the time, but the truth of the matter is I feel really unnerved and disconcerted if my agenda isn't jam-packed. And the reason that this is all really important is part of my approach not only to coaching, but to the process of growing up, is to use what I call radical self-inquiry, to really cut through our own delusions and say, how does it serve me to feel completely busy to the point where I feel exhausted? And perhaps there's another more conscious way of getting that feeling than feeling like crap all the time.

Lenny Rachitsky (00:06:56):
This is a good segue to something that I hear you. You have this equation that you and your firm use to think about how to create and cultivate great leaders, and it includes one of the variables is radical self-inquiry. Can you share this equation and just how you work with folks to build this in them?

Jerry Colonna (00:07:14):
Sure. I'll tell a little story about that. I remember one time I was, this is how the equation came to be. I was doing a talk, I think here in Boulder at Naropa University where I used to be on the board of trustees. It's a Buddhist university, and as is often the case, I'm winging it as I go and I'm walking around probably without shoes on because that's what I do. And there was a dry erase board behind me and I was trying to explain what it was that I do, what it was that I encourage people to do. And I jumped up at the board and I wrote practical skills. And in writing that, what I was trying to convey, what it is that people typically come to a coach for. They want to understand how to do their job. They want to understand how to live. They want to understand the how.

(00:08:11):
And then, I wrote plus, and then I sketched out radical self-inquiry. And I said in that moment, I said, "People will come and ask me how, and I will drive them crazy because I will say something like, tell me about your father, or tell me why you chose to be in the job you're in the first place, or tell me about your relationship to money, or tell me about your relationship to self-worth." And then, I expanded it and I put another plus sign and I said, "Shared experiences." And then, I drew an equals equation line underneath the whole thing, and I said, "Enhanced leadership plus greater resiliency."

(00:09:05):
And so, the equation is practical skills plus radical self-inquiry plus shared experiences, that is the process of actually talking about the craziness that goes on in your head equals greater leadership. That all makes sense. But then, there was this other piece, enhanced resilience. And when I do this on a dry erase board, I will often circle that phrase, and I say that is the purpose of this whole thing, because the truth is, if you follow my story at all, you know that in my late 30s, the depression that had really marked most of my life had gotten so bad that despite my outward success, I was suicidal and lost.

(00:09:58):
And I will turn to the audience and I say, "I get you want to be a great CEO, I get you want to be a great executive, but what I really care about is you not killing yourself in the process." So if we take a step back, the whole point of what we refer to as the equation really boils down to that point, how do we grow up and become the leaders, the adults we were born to be without feeling like crap?

Lenny Rachitsky (00:10:31):
And there's this huge implication here that a lot of people think that when they reach a certain point, become successful, make a certain amount of money, get a beautiful house, still be happy. And essentially what you're saying here is that's very often not the case. Maybe in most cases, not the case.

Jerry Colonna (00:10:48):
It's not only not the case, it's the big lie that we're socialized with since childhood. I remember one time I was on the road doing a talk for, I was promoting my first book, Reboot, and I was at, I think it's called the Fitler Club in Philadelphia. I was doing a fireside chat. And after talking with my conversation partner, a guy named Chris Fralic who was one of the co-founders at First Round, really, really good guy. We turned to the audience and there was a Q&A as there often is, and this young guy shoots his hand up and he introduces himself and he says, "I'm 19." And he looks over to his right and his mother's sitting there and he says, "And my mother brought me here," which I laughed.

(00:11:40):
And he said, "So what you're telling me is you don't have to be an asshole to be successful." And I could not think of a better summation of everything that I'm about than for a 19-year-old kid to look up and say, "You don't have to be an asshole to be successful." And of course, the corollary to that is you don't have to feel miserable just because you're trying to create a career.

Lenny Rachitsky (00:12:12):
As people start to think about this and think, okay, I feel like I've been heading in this direction of I just need to keep climbing the ladder, making more money, as they hear you talk, what's the pivot that folks should make in their mind around where they should actually be heading? What is a direction where they'll end up not wanting to kill themselves, in spite of being successful?

Jerry Colonna (00:12:34):
To be clear, not everyone ends up in that level of depression, but the hack, if you will, is consciousness. So what do I mean by that? Part of what makes radical self-inquiry radical is we're socialized not to ask certain kinds of questions. So for example, someone says, "It's really important for me to be ambitious and achieve a particular goal." What's radical, a radical question to ask is, and what will that do for you? What is it that you believe being "successful" will do for you? How do you define success? Where does that come from?

(00:13:30):
In Reboot, my first book, I tell the story of what I refer to as my pursuit of lemon drops. And briefly, when I was a boy, there was a lot... I grew up with an enormous amount of chaos and insecurity, financial and otherwise. And a big source of stability in my life were my mother's parents, my grandfather and grandmother. And Grandpa Guido, who was an ice man and emigrated from southern Italy in early 20th century, always seemed to have, well, he had this endless supply of lemon drops, and they were always kept in this green pantry outside of the kitchen. And for me, the stability and what I considered wealth seemed to match to this notion of this endless supply of lemon drops. And when I got to my 30s and I was outwardly successful and I was a hot shot BC, I had lemon drops, but I didn't feel safe, which was a mindful.

(00:15:02):
And so, I told that story in Reboot as part of my exploration into the core question of how did my relationship to money shape my career choices, shape my school choices, shape my own sense of safety and self-worth? So long-winded response to your question, what I encourage people to do is to ask themselves these kinds of questions so that they can raise their level of consciousness so that they can be in the driver's seat of their lives and not some learned behavior that they developed as a child to answer perhaps their parents or grandparents' anxieties.

Lenny Rachitsky (00:15:56):
I feel like a lot of people hearing this are afraid to ask these sorts of questions. The reason they don't ask these questions is because they worry that this is going to be like, okay, I got to quit my job, move to the woods, give up all these luxuries they have. I don't even want to think about that. I got a whole family to support. I got to succeed. Advice for getting over that hump of just like-

Jerry Colonna (00:16:17):
So let's just pause, Lenny. Okay, so what you're doing in this moment is empathetically imagining what may be going on for your listener, but the empathy is actually based on your own question because you invited me on the show, you knew I was going to get to this point. So I'm imagining that as you take this in, that thought stream shows up for you. "Jerry," says Lenny, "If I open up that closet, all the shit's going to fall out, and what am I going to do with it?" Does that resonate at all?

Lenny Rachitsky (00:16:58):
This is why I was nervous to have you on this podcast. I knew what you-

Jerry Colonna (00:17:05):
So answer my question.

Lenny Rachitsky (00:17:07):
I don't think it's that strong for me to be afraid of that because I've taken a different path already and gotten off the career ladder climbing treadmill. On the other hand, back to your original question, we talked about being busy. I'm very guilty of that. I'm constantly trying to do less, but constantly doing more, and my life is just very busy.

Jerry Colonna (00:17:28):
Thank you for giving me more of that answer. And trust me, your listeners are going to appreciate you being fully there in just the way you were. So let's take a step back. The fear is, if I can reflect back to your original question, the fear is if I go there, I don't know what's going to happen as a consequence of that. If I pause and ask myself, is this relationship working out for me? I might end up leaving this relationship. If I pause and ask myself if this career isn't working for me, I might leave my career.

(00:18:25):
And the good news bad news is that's true. That is absolutely true. And if we look at some of the other observations we were making before like anxiety and depression, we have this belief system that if I pay no attention to the thing that I'm afraid of, it's somehow going to magically go away. If we pay no attention to the source of discomfort, it's somehow going to go away. And that's not actually how life works. More often than not, what we do is we respond to the source of challenge, whether it's a discomfort in our relationship, whether it's a discomfort in the way my life has unfolded. We respond to it by plasting over band-aids and sometimes they're relatively healthy, we become obsessed with working out, or sometimes they're unhealthy. We become obsessed with work or substance abuse or that kind of thing. Or sometimes, and this is super popular right now, we lean into what I would call as a spiritual bypassing where we go to Peru and we go do ayahuasca or we spend the weekend doing mushrooms with friends...

(00:20:08):
And what we're really not doing, Lenny, is confronting the parts of ourselves that need some tending to because we're afraid of the consequences. But I'll tell you a quick quote. One of my favorite books is Bruce Springsteen's autobiography, and about in the middle of the book, he has this passage where he talks about having spent 25 years in psychoanalysis. So let me just let that statement land. Bruce fucking Springsteen, 25 years in psychoanalysis. And he has this passage where he talks about the unsorted baggage of our childhood. And what he rightly asserts is that we all have unsorted baggage, and at some point we're going to pay the price of not sorting that baggage. And the price more often than not is in tears.

(00:21:21):
Now, this is Bruce Springsteen talking about this. This is not some airy-fairy transpersonal Jerry Colonna coach. And the reason I draw that out is we as children are socialized not to develop these consciousness skills. We are socialized to develop what I would call bypassing skills. And as he correctly points out, if you continue to bypass sorting out your baggage, there's going to come a day where you're going to have to pay that price. It could be in your own depression, it could be in, I've seen this a thousand times Lenny, entrepreneurs sabotaging their successful businesses because the belief system from their childhood goes something like, I don't deserve success so let me blow it up. We put this all under the rubric of midlife, but I don't know, when does midlife begin, 35? When does it end, 70? What I do know is it's the bulk of our adulthood.

Lenny Rachitsky (00:22:46):
Okay, I think you've done an excellent job convincing me and others to spend time on this now, and I think there's an assumption of it gets harder, the tears get more intense as you wait longer. There's this ticking time bomb that better some amount of tears now than 10 times more tears later. Is that right?

Jerry Colonna (00:23:04):
Well said.

Lenny Rachitsky (00:23:06):
Okay. So coming back to this equation, I think I want to give people some things to do now that they may be likely convinced, okay, I should really rethink what I'm doing. So back to the equation, practical skills plus radical self-inquiry plus shared experiences equals enhanced leadership and greater resilience. So the three things you can work on are practical skills, radical self-inquiry, shared experiences, skills I think people get. So radical self-inquiry, these are essentially questions to dig into what drives you, what makes you happy. What are some questions again that people should be asking there as they're listening or maybe after they finish listening?

Jerry Colonna (00:23:40):
In the time since I've been a coach, which is now going on 27 years, the popularity of journaling has gone up, which is awesome. And part of what happens is people journal, but they don't know what they should be journaling or how they should. So let me give some questions then, and this is a way to approach it. Let's imagine that what we're trying to do, whether we're sitting in meditation, whether we're journaling, whether we're taking time away, we're just pausing and starting to ask ourselves questions. So my famous questions include things like, what am I not saying that I need to say? So let's imagine ourselves in a relationship that's not working.

(00:24:30):
Talk about something that could be terrifying. What am I not saying in that relationship that I need to say? By the way, this is a good question to ask if one is responsible for leading people too. Corollary questions to that would be, what am I saying that's not being heard? And then, of course, what's being said that I'm not hearing? So if we just pause and look at those four questions, how have I been complicit in creating the conditions I say I don't want? What am I not saying that I need to say? What am I saying that's not being heard? And what's being said that I'm not hearing? Can you feel the power of all of that in those questions?

Lenny Rachitsky (00:25:25):
Yeah. Scary questions.

Jerry Colonna (00:25:27):
They are scary questions. You know you're in the radical self-inquiry zone when the questions take your breath away, when the questions, and by the way, you don't have to share the answers to these questions with anybody but yourself. Now, there could be some power in sharing them in a group of friends and sharing them with a group of colleagues, sharing them with a coach, sharing them with a therapist. But the most important person with whom you should share the answers is oneself. This is a little bit of Buddhism here. Self-delusion along with attachment are the biggest contributors to our own suffering. Self-delusion. Everything's great. How you doing? Everything's great. Bullshit. Can we just not bullshit each other?

(00:26:30):
So let me just pause. Those are just four questions. My first book Reboot has a set of questions after every single chapter. We also have a journal that we put out that has questions and questions, but the more important thing to take away from this is questions that startle us, questions that may cause us to be a little afraid of the answer, that's where the gold is.

Lenny Rachitsky (00:27:02):
And we'll point people to the book for many more of these questions and the worksheets. For the third party equation, shared experiences, can you explain what that is?

Jerry Colonna (00:27:11):
We were talking about socialization, for example. Prior to launching Reboot, the company, my co-founder, Ali Schultz and I, the roots of Reboot the company began with me designing, or Ali and I designing these boot camps. And the original iteration of the boot camp, we used to call CEO Boot Camp because it was originally we would get first-time CEOs together and we would do a bait and switch. We would pretend to sell them practical skills, and then I would start asking really tough questions like who would you be without the story of who you are? It's like what?

(00:27:57):
The notion of shared experience as an important component grew out of that. Because what would happen is imagine sitting in a circle of people who just have your back, who really care about you as a person. And imagine then discussing some of the answers to those questions. Who would you be without the story of who you are? What is it that you wish that people in your life knew about you, but you're too afraid to tell them? And imagine sitting in a group of people who can just hold that space without fixing you, without telling you what you're doing right or wrong? We, too often than not, especially in what I would say the entrepreneurial community are socialized to bullshit not only ourselves, but everybody else. All our companies are moving up into the right, every product that's working, we don't really have any problems because we're crushing it, and that's just a lie. Imagine having the capacity to be in relationship with people where you can just tell the truth. That's what shared experiences are about.

Lenny Rachitsky (00:29:26):
My wife does a women's circle where they gather and just share what's really going on within in their lives. And it's-

Jerry Colonna (00:29:26):
That's it.

Lenny Rachitsky (00:29:34):
And it's very confidential. There's a ritual to it, and it feels like that's a really good avenue for things like that.

Jerry Colonna (00:29:42):
What circle do you sit in?

Lenny Rachitsky (00:29:44):
No circles. This is my circle.

Jerry Colonna (00:29:49):
But there is something powerful here. I think in the last 15 years, the rise of podcasts, good podcasts. What I think what happens is let's hope this is happening for your audience right now, good quality intimate conversation between people who are authentic and real, creates space for someone to be authentic and real, even if it's just with themselves. So you're doing a mitzvah, you're doing a good deed by creating this space.

Lenny Rachitsky (00:30:24):
Thanks, Jerry. Let's go back to the busyness point, and I'll talk about myself a bit to get it real again, because I think it's also something a lot of people struggle with. I listen to this, they're just like, I'm so busy, and every time someone ask me how I'm doing, busy, so busy, like swirly eyes emoji, swirly eyes emoji.

Jerry Colonna (00:30:45):
With a little head shake.

Lenny Rachitsky (00:30:47):
That's right. And the melting face emoji. And that's very much me. And it's funny because I started this journey of the newsletter of just like I call the project avoid getting a real job. And it was just like, cool, just do this newsletter thing, not have the job. It'll be chill, write an email once a week. But I just find myself taking on endlessly more and more. And for me, I feel like the drive is it's just fun to see it grow and for it to keep building and doing well.

(00:31:17):
This reminds me, there's a quote that Will Smith shared once that I think you'll like. Someone asked him what it's like to be famous, and he's like, "Really awesome as you're going up to fame. Pretty okay as a famous person. Really bad when you lose that fame." And that's how it feels with the growth of this thing. It's just like growth is up. Oh, life's good, and then it starts to stall. I'm like, oh, no, it's all going to fall apart. So I think that's where a lot of that comes from for me. It's just like, oh, what's next? I got to, let's see what else I can do here.

Jerry Colonna (00:31:44):
Well, how do you feel about yourself when you're on that growth trajectory?

Lenny Rachitsky (00:31:50):
I feel great.

Jerry Colonna (00:31:52):
Say more.

Lenny Rachitsky (00:31:53):
I feel like I'm achieving and heading in a... Part of it is just fun. It's like fun to win. So it's just like, yeah, we're doing it. It's working.

Jerry Colonna (00:32:07):
And when you're not growing, how do you feel about yourself?

Lenny Rachitsky (00:32:13):
About myself. There's this sense that it's all over. Oh, maybe it's all going to fall apart, and maybe I'm not as good at this as I thought, and maybe-

Jerry Colonna (00:32:25):
Okay, so stay in that spot for a moment. So imagine, and I don't know that this is true, but I can imagine that there's a little whispery voice in your head that's always there that says, "Lenny, you're not as good as you think you are. In fact, Lenny, they might even find out."

Lenny Rachitsky (00:32:50):
Yep. Yeah, imposter syndrome.

Jerry Colonna (00:32:52):
Oh, shit. So by being busy and by being on that growth trajectory, that voice maybe sounds a little less persistent, maybe a little less loud. Now, I want to offer a different potential. What if you could enjoy the puzzle of trying to create something new, trying to create magic, something out of nothing, but it doesn't matter to your sense of self-esteem if you succeed or fail. What if what drove you was not quieting that voice, but what drove you was, oh, this is just fun? Seth Godin, who's a dear, dear friend of mine, talks about art projects.

Lenny Rachitsky (00:33:55):
Also a former podcast guest.

Jerry Colonna (00:33:57):
So what if you just approached the project as if it was an art project? I think it's going to show up this way. What if it turns out it's wrong? What if it's this? What if it's that? And your sense of self-esteem is not attached to the outcome.

Lenny Rachitsky (00:34:16):
What's interesting is that's how I started this whole thing. I had no intention of it being a career and way I make a living. It was just, this is cool, people seem to like it, I enjoy it. Let's just see where it goes. No expectations.

Jerry Colonna (00:34:28):
And then what happened?

Lenny Rachitsky (00:34:29):
And then it worked.

Jerry Colonna (00:34:30):
It became successful.

Lenny Rachitsky (00:34:31):
That's right. It worked out.

Jerry Colonna (00:34:33):
Right. It became successful, meaning you developed an audience, meaning you developed a following.

Lenny Rachitsky (00:34:41):
And then, income. That was a big part of it.

Jerry Colonna (00:34:43):
And then you developed an income, and then the stakes went up, and then all of a sudden, my heart, the anxiety.

Lenny Rachitsky (00:34:54):
Not quite that strongly. At times it is, but there's a bit of just, oh, wow, I am relying on this now. I can't just let it fall apart.

Jerry Colonna (00:35:03):
Because my life would fall apart if I let it fall apart.

Lenny Rachitsky (00:35:07):
Yeah, life would change in a big way if this whole thing ends.

Jerry Colonna (00:35:11):
Right. Right. So what you're talking about, what we're talking about right now, remember before I said in Buddhism, we talk about self-delusion and attachment. Now, we're talking about attachment. When we become attached to the outcome, we inadvertently fuel our own suffering. When we become attached, and in this case, okay, I get it. There's a financial reality. This is important because it helps pay the bills, if it doesn't entirely pay the bills. Great. Got it. Fabulous. But really the deeper attachment is see, I'm not nothing. See, I'm not a nobody, I'm a somebody, and that's the source of the suffering.

Lenny Rachitsky (00:36:09):
That is so true. That is very much a part of what has driven me is I was always a very shy kid growing up, and I don't think people expected a lot of me except my mom and dad, I guess. And so, I always had the sense, I'll show them, I'll show them what I could do, and that's always, it's this chip on the shoulder thing that I know drives a lot of people.

Jerry Colonna (00:36:29):
How old are you, Lenny?

Lenny Rachitsky (00:36:30):
43.

Jerry Colonna (00:36:30):
Okay. So maybe now at 43, you can take in the fact that you are somebody regardless of what you do. What's your wife's name?

Lenny Rachitsky (00:36:48):
Michelle.

Jerry Colonna (00:36:49):
Is she going to love you even if the podcast fails?

Lenny Rachitsky (00:36:52):
Absolutely.

Jerry Colonna (00:36:55):
What, is she an idiot? No, she's a smart person. The people who actually know you and care about you may be proud of your efforts, but their love for you is not dependent upon its success. And that's like a rewiring. Do you have children?

Lenny Rachitsky (00:37:27):
Yeah, we got a 22-month-old now.

Jerry Colonna (00:37:30):
Oh, mazel tov. That's wonderful. My children are 34, 32, and 28. So I'll speak like the old man that I am. When we take that test, that spelling test, and we stick it with magnets on the refrigerator, it's at a pride. The challenging message that we inadvertently can send to our children is that we only love them because they got an A on the spelling test. And so, it's really critically important that we as parents do our own internal work to convey that unconditional love that is our birthright as human beings. And we hold onto the goal because the goal is cool, because solving a puzzle is fun, because doing hard work and experiencing the reward from that is affirming, but your value as a human being is unshakable. Now, as a father, isn't that the feeling you want your child to have?

Lenny Rachitsky (00:38:51):
Absolutely. And there's a lot of parenting advice these days that helps you learn to do that. There's all these TikToks now, don't say good job. Just say good choice or great, hard work. Great job working hard on that.

Jerry Colonna (00:39:04):
Right, right, right. I don't know how I feel about getting parenting advice from TikTok, but okay.

Lenny Rachitsky (00:39:12):
I'm excited to have Andrew Luo joining us today. Andrew is CEO of OneSchema, one of our longtime podcast sponsors. Welcome, Andrew.

Andrew Luo (00:39:19):
Thanks for having me, Lenny. Great to be here.

Lenny Rachitsky (00:39:21):
So what is new with OneSchema, I know that you work with some of my favorite companies like Ramp and Vanta and Watershed. I heard you guys launch a new data intake product that automates the hours of manual work that teams spent importing and mapping and integrating CSV and Excel files.

Andrew Luo (00:39:37):
Yes. So we just launched the 2.0 of OneSchema file feeds. We've rebuilt it from the ground up with AI. We saw so many customers coming to us with teams of data engineers that struggled with the manual work required to clean messy spreadsheets. FileFeeds 2.0 allows non-technical teams to automate the process of transforming CSV and Excel files with just a simple prompt. We support all of the trickiest file integrations, SFTP, S3, and even email.

Lenny Rachitsky (00:40:03):
I can tell you that if my team had to build integrations like this, how nice would it be to take this off our roadmap and instead use something like OneSchema?

Andrew Luo (00:40:11):
Absolutely, Lenny. We've heard so many horror stories of outages from even just a single bad record in transactions, employee files, purchase orders, you name it. Debugging these issues is often like finding a needle in a haystack. OneSchema stops any bad data from entering your system and automatically validates your files, generating error reports with the exact issues in all bad files.

Lenny Rachitsky (00:40:32):
I know that importing incorrect data can cause all kinds of pain for your customers and quickly lose their trust. Andrew, thank you so much for joining me. If you want to learn more, head on over to oneschema.co. That's oneschema.co.

(00:40:46):
Just to close loop on this, I think as people hear this, I feel like, okay, cool, everything falls apart. Sure, my parents will love me, my wife will love me, they won't think less of me. However, it's nice to get that really nice couch and that nice hotel and the income, the comfort that comes with income at a certain level is hard to give up. How do you help people get past that that might go away and feel comfortable?

Jerry Colonna (00:41:09):
Well, the good news is, and again, this is a Buddhist reference. The good news is there's a wisdom tradition that teaches all about this. So very briefly, the Buddhist story is in his mid-30s, he wakes up to the truth of birth, old age, sickness, and death. Birth, old age, sickness and death. And he wanders into the forest and he becomes a wandering mendicant and he becomes a holy man, and he's still not satisfied. And as I like to tell the story, one day he decides, fuck it, I'm just going to sit under the Bodhi tree and I'm not going to move until I figure this shit out. And so, he sits and sits and sits, and the story is he sat for 40 days living on a single grain of rice every day because always right, crazy stuff.

(00:42:05):
And when he woke up, he woke up to the four noble truths and the four noble truths are life is filled with suffering, that which we do to push away suffering increases suffering. The third noble truth is that there's an end to suffering. That's a really important one. And the fourth noble truth is what's known as the eightfold path to the end of suffering.

(00:42:34):
So let's focus on the second noble truth because that's really what you're talking about. When we acquire that nice couch, when we buy that nice house that stretches our income to its maximum, if we're doing it to enjoy the couch or the house, then A-OK. But if we're doing it because we're trying to push away the suffering of am I good enough to be loved, to feel safe, and that I belong, that which we do to push away suffering will increase suffering. And in this case, oh my God, what if they take my house away from me? Oh my God, what if I fall backwards down that staircase of life? Oh my God, what if all of those people who have signed up to my Substack suddenly disappear? You see how the attachment becomes that source of suffering? You see how the thing that we do to make ourselves feel better in fact fuels the tenuous hold that we have on our OK-ness? I'm okay just as I am. I'm okay.

(00:44:03):
It all comes down to why we're doing what we're doing. Now, to be clear, this is hard for me. I think it's hard for everybody. When my first book came out, Dan Harris, who's a really good friend and client from 10% Happier said to me, "Don't read the Amazon reviews." The truth is, I've read two reviews. I read it in the first hour after it was released, and I've never read a review since because there's no way I can experience those reviews without becoming attached to how people feel. So thank you. I'll put it over here and I'll just stay focused on the experience that I get from writing.

(00:45:04):
And yes, do I want to sell thousands of books? Do I want people to feel moved by my writing? I do, but you know who gets the most out of my writing? Me, because when I sit down, this is my file folder for whatever I might do for our next book, what I'm trying to do is answer questions that I have. For example, Captain Chaos is running the country right now. What is it that the world is going to need two or three years from now? And what's my contribution to that world? Now, just as I say that, how does that feel to you? It's kind of settling. So I know that in order for me to feel good about my existence on this planet, I have to ask myself these questions and I have to attempt to answer these questions. Whether it turns into a book that people buy or not is secondary, I have to do this work regardless.

Lenny Rachitsky (00:46:22):
That super connects with exactly again, the way I started this whole thing is I started writing just to crystallize my own thinking, and it ends up being useful to other people.

Jerry Colonna (00:46:33):
Yes.

Lenny Rachitsky (00:46:35):
People hear this and they're like, why would I want to give up this great couch and house and car and all these things? That's really hard. And risking that by just doing something that feels good versus it'll make income, but it actually works. That's what I found. If you focus on a thing that is useful to yourself and interesting and not come at it from how do I make the most amount of money and turn this into whole thing, but more just, this is really interesting. I'm going to see where this goes. It will work for me.

Jerry Colonna (00:47:00):
Lenny, you implicitly asked a how question a few minutes ago. How do I do this? How do I do this radical self-inquiry? And I asked, I responded by offering a few questions. Let's build upon that for a moment, because what you are articulating right now is in the process of asking those questions, you can go back to what Simon Sinek would say is your why. You could go back to your core principle. You could go back to the centerpiece within you, which is what do I believe to be true about the world and how do I want to be in that world? You know what animates me right now is a question? With my children being fully fledged adults, I am really focused on what kind of ancestor to my descendants would I like to be? 20 years from now, 30 years from now, 40 years from now, I'll be gone. What would I like those who follow after me to believe to be true about me?

(00:48:11):
And you just paused. I can tell from the Adam's apple jumping up and down, that that question landed for you. It's a question of legacy. It's a question of meaning and purpose. At the end of my days, this is a question in Reboot, at the end of my days, what would I like the people who come after me to say about me? And what I want people to say about me is that he gave a shit about the world, he cared, and he tried, and he was kind. Those are the things that matter to me.

Lenny Rachitsky (00:49:00):
I'm always reminded of that frame of reference when I go to a funeral and people reading the eulogy and the old advice of what do you want your eulogy to say and making that your mission. But on the flip side, there's this viral video of Mike Tyson. Someone was coming up to him I think before his big match recently, and asked him about his legacy, and he's like, "I don't give a shit about my legacy. It's just a made up thing that doesn't matter." So let me just ask you this. Why is it important to think about legacy? Does legacy even matter? We're dead. What's the difference?

Jerry Colonna (00:49:33):
Far be it for me to criticize Mike, and don't hit me Mike, because even as an old guy, I wouldn't want to be hit by Mike Tyson. I don't know what's behind his response, but I can tell you what's true for me. I made oblique reference to Captain Chaos in the world as it is right now. The world's a tough place right now. We live in a world where it's almost normalized that a teenager will shoot other teenagers in school. It's almost normalized that people are dragged off to jail. Something is happening, something that's really disturbing.

(00:50:28):
Now, to be clear, we've always had disturbing times. I mean, I was reminded recently, I'm reading a book called Soldiers and Kings, which I highly recommend, which is about human smuggling from Central America into the United States, and it's an extraordinary book. And in reading that, I was reminded of policies that the US government has used over the years, whether it's supporting dictators in Central America or other sorts of things, things that I oppose, that feel immoral, if not directly immoral.

(00:51:15):
Why does this come up for me? I can't shake the feeling that someone down the line in my lineage is going to ask of me, "And what did you do, grandpa? And what did you do, great grandpa?" I know what I want that answer to be, which is I tried. Lenny, God gave me the ability to put two sentences together in a way that people listen. I feel a moral responsibility to use that God-given gift to help create the world, that I would like to see, a world of kindness and empathy, a world where poverty is diminished, a world where people feel safe however the fuck they identify. I don't give a damn. So is that my legacy? Yeah, and maybe there's some ego implicit in that, but can I go on for just a bit on this?

Lenny Rachitsky (00:52:54):
Absolutely.

Jerry Colonna (00:52:55):
At the end of Reboot, I write about this moment, and in this moment I am in Marin County. My wife Allie and I are together. And I'm once again torturing myself with this question. Have I been a good man? I drive myself crazy with that question. Have I been a good father? Have I been a good partner? Have I been a good man? And she says, in a very frustrated way, "All right, already. Enough. You're a good man. Stop." And so, I go for a walk, and as I'm walking, I encounter this toppled over oak tree and the roots are all torn up and you've seen trees like this, and clearly the tree died and clearly a wind came and clearly knocked the whole thing down. And I look at the tree and I say to myself, "Here lies a good man."

(00:53:57):
And I liken myself to this toppled over oak tree, and I imagine that that tree had lived its life with its limbs gnarled and twisted by actions that it should have taken and actions that it shouldn't have taken, but good choices and bad choices. But that for the majority of its 75, 80 years, it lived into its purpose of providing shelter and shade for those that may have come from beneath it. And I make this point that at the end of my days, I want to be like this tree just slowly dissolving into the earth, having done the best job I could of being purposeful. I feel better. My suffering is eased when I can lean into that, which then makes me able to be present for the other person, whether it's a coaching client, whether it's a podcast conversation, whether it's just going for a walk with one of my children. I just feel better, and I think I am a better person when I think about things like that. So far be it from me to disagree with Mike Tyson, but I think he's wrong.

Lenny Rachitsky (00:55:34):
Good callback. It sounds like The Giving Tree to me.

Jerry Colonna (00:55:38):
Oh, yes, yes. Shel Silverstein.

Lenny Rachitsky (00:55:43):
To give people something to do with this area of legacy. How did you approach coming up with figuring out what you wanted your legacy to be? Are there some questions you asked? Is there something you recommend folks do to help think through this for themselves?

Jerry Colonna (00:55:57):
Well, it's delightful that we've ended up here because I think that I'm still working through those questions. As I said before as we both connected with, I use my writing to find my way to answers to questions. So part of what I'm dealing with right now is, look, I'll turn 62 this year. That feels old, but it also feels settled. And part of what I'm trying to figure out is what do I want my elderhood to be like? And I'll be honest, I'm enjoying this time of my life where I'm finding myself being a voice of comfort, being a voice of maybe even sanity in a time where that feels really insane and challenging. So maybe that's what my legacy will be. I'm not 100% sure.

Lenny Rachitsky (00:57:03):
Is this maybe hinted the new book you're working on? Is this the topic you're thinking about or is this not?

Jerry Colonna (00:57:09):
Yeah, and other things. That's right. That's right.

Lenny Rachitsky (00:57:15):
Speaking of the world being very crazy right now, you talked about your kids, AI is very top of mind for a lot of people in particular. It's stressing a lot of people out. In a lot of ways, it's quite unsettling in future careers, in skills, people-

Jerry Colonna (00:57:29):
It is unsettling, isn't it?

Lenny Rachitsky (00:57:31):
Quite unsettling, but there's a world where we don't need humans in the future, potentially. Just what advice do you share with clients to help them work through this period of worry with the future, with AI being the core of it?

Jerry Colonna (00:57:45):
Well, if we go back to the equation for a moment, I think it's really important that we actually talk about these things. I would say a year ago, I likened it to the experience that I had. Remember, I'm old enough to remember when not everything had an IP address. Now, our refrigerators have IP addresses. I mean, it's freaking crazy. I'm old enough to remember when you had to install an IP stack into your personal computer in order to connect to the web. That's how old I am.

Lenny Rachitsky (00:58:22):
Did you have the phone modem where you had to put the phone?

Jerry Colonna (00:58:26):
Absolutely. Absolutely. It was a big, big deal to go from 1,200 baud to 2,400 baud to 56K. Oh my God, it was like a rocket ship. A year ago, I thought we were going through a similar kind of transition. We're clearly not. This is different. And in the coaching therapeutic world, everybody's like, "Oh my God, ChatGPT is going to replace me." And I don't know, maybe. What I am finding is... I wear glasses. So for those of you who are only listening to the audio, you may find that news. What I am finding is in my own life, it's like I have put on a pair of glasses that are really, really sharp and helpful, and it is disturbing and unsettling because I think it does challenge this question of what is our role as human beings?

(00:59:46):
Now, what I come back to, and I could be wrong, but what I come back to is we're talking through a medium, a mediated experience. My signal is bouncing up into the sky and to a satellite. I won't name the company, it's coming back down. I don't know what your access is. We're using this platform or a site to record this, but somehow we're still finding the capacity to be present for one another in a heart-to-heart way.

(01:00:30):
And so, when I look at these phenomena, what I lift up is that. What I am hopeful about is that that which does not matter in the experience of being human gets burned away and is taken care of, call it by AI, but that that which matters, which is presence and connection, human-to-human contact, strategic thinking, formulation, you want to talk about it in terms of engineering, the conceptualization, that that gets elevated and our skills get better at doing that. And in the most optimistic point of view, what ends up happening is we spend more time on that which matters, and less time on that which doesn't matter. And I could be completely wrong and we could all be out of work and making sure that the robots are well-oiled, and that becomes our purpose.

Lenny Rachitsky (01:01:47):
Along these lines of glasses and even coaching, the world of coaching, there's a really interesting use case I saw today that Dan Shipper shared that I think you'd love, which is now that ChatGPT has memory, remembers everything you've said, and you can think back, you can ask it, "What are blank spots in the way I see the world that I'm not seeing?" You could also upload all your chat transcripts from your meetings and ask it what could you do better in meetings?

Jerry Colonna (01:02:14):
Look, one of my colleagues in the coaching company, he has uploaded, he kept all of his journal entries, I think over 10 years journal entries from Evernote, and he uploaded that. I think he uses Claude, and he's asked Claude to highlight things. What am I not saying that I need to say? What am I saying that's not being heard? He's asked it to reflect back, and I think it's been incredibly helpful for him. I think the result is that he is a better coach, which is interesting, because the feeling is, well, does this replace it? I am finding, I'm using ChatGPT really as a writing and thinking partner in a way that I did not have before, and I'm still using my live real human writing buddies, which are really important to me. Where does this all end up? I had no idea. It is unsettling, it's uncanny, and it's also enlivening and exciting.

Lenny Rachitsky (01:03:31):
Well put. I love that you can ask these hard questions of Claude/ChatGPT, these questions that make you really scared could ask it what are the answers, and even not have to do the hard work and maybe get a better answer. I doubt that that will give you the best answers.

Jerry Colonna (01:03:47):
Well, what it might do, which I think would be wonderful, is it might give you more questions to ask yourself. I'm a huge fan of powerful questions and the answer I give to a question like what am I not saying that I need to say? That question, you can ask yourself that question every single day. The question of how have I been complicit in creating the conditions I say I don't want? You can ask yourself that question every single day. To take a step back, the subtitle of my first book is Leadership in the Art of Growing Up. The Art of Growing Up is a practice. It's not a scientific moment where one day you wake up and you're done. It's an ongoing practice of not continuous improvement, but continuous inquiry that can feel exhausting when you contemplate it, but enlivening when you live it.

Lenny Rachitsky (01:04:57):
All this, some people may think of as this whole idea of growth mindset. I know that you're not a big fan of this term, that it's used in a harmful way a lot of times. Can you just talk about that why you find that growth mindset as a concept isn't necessarily useful?

Jerry Colonna (01:05:18):
Here's what I have a problem with. First of all, having a growth mindset is a very, very helpful thing. What I have a problem is in having and how we can turn a notion like a growth mindset into a fixed mindset, which is, it's this funny little trick the ego does, and the ego says, "Okay, well, this is a growth mindset. Oh, this is not a growth mindset. Okay, then this is good. This is not good. This is bad. This is..." What Buddhism has taught me is that everything's falling apart all the time even our growth mindset. When we get too fixed on the proper way to do things, we're setting ourselves up for attachment and therefore suffering. So if you can hold something like a mindset loosely with that attachment, go for it. Have a blast. Enjoy it. But the minute you start to nail it down to the floor and say this is the way it ought to be, I ought to always have a growth mindset, you've become fixed. And that's what the ego does.

(01:06:48):
To be more explicit about it from a business context for example, the great business writer Peter Senge says, "It is virtually impossible to challenge the assumptions that made you rich in the first place." So think about it in our experience of starting a business. We have what the Zen Buddhist would say, beginner's mind, all things are possible. And then, we experience, you were talking about it a little before, a little bit of success, and the ego, which is so terrified of not having success, start to say, "Aha, this is the way to do it." And then, we start to deviate from that because life happens and then the anxiety starts. So the question is, how do you hold a growth mindset loosely knowing that you ought to stay present to the world as it is, respond to the changing dynamics, figure out what's next because that's the growth. So put succinctly, stay attached to the growth and hold mindset a little loosely.

Lenny Rachitsky (01:08:07):
I love that. It reminds me of advice. I did a meditation retreat once, and there's always a sense with Buddhism, and it's interesting how often Buddhism and advice from Buddhist teachings comes up on this podcast by the way.

Jerry Colonna (01:08:18):
When the student is ready, the teacher will appear. You are inviting it in, but keep going.

Lenny Rachitsky (01:08:25):
That makes sense as you say that. Interesting. So there's this fear I think people have with Buddhist teachings that you will not be as ambitious and you will not achieve as much if you're not attaching.

Jerry Colonna (01:08:41):
If you're not anxiously chasing something.

Lenny Rachitsky (01:08:42):
Yeah, exactly. If you're just like, "Why do I need that? I don't need to be the CEO of the VP because like, oh, I won't attach to that." And then, so people fear that downside. So I asked this question at this retreat and the advice they shared there was don't attach to this idea, but just point your cart in that direction and head there.

Jerry Colonna (01:09:02):
Yeah, I like that. Look, the fear you're talking about is the fear of complacency. And if we look at the structures of the mind and we look at our socialization, the way we're socialized to ward off complacency is anxiety. And so, if we go back to some of the things we were saying before, if I grow up believing that the way I'm going to make my parents love me is by achieving, then if I become complacent, then what's at risk is their love for me. So just like we made the connection before where unconditional love exists, unconditional positive regard for self, otherwise known as self-compassion can be a powerful motivator, especially when you get to the point where you say, "As painful as it is for me to write, I enjoy writing. I enjoy working out. I enjoy pushing myself. I don't necessarily enjoy it in the moment." But I certainly, when I look at two books on my desk and I say, "You know what? That feels good. That makes me happy."

(01:10:43):
To me, the ability to hold the seeming contradiction of those things is a hallmark of my adulthood. It's to get satisfaction out of hard work for me is a much greater motivator than fear of complacency. As I've sort of slip-slided my way into that place, I have found... I work seven days a week. I don't have to, but I enjoy it.

Lenny Rachitsky (01:11:29):
There's another, maybe a last area I want to spend some time on, which is around teams and what often causes trouble for teams. What breaks teams? What breaks companies? You have this point, you make that it's rarely lack of talent on the team, lack of strategy, lack of execution, that it's something else. What is that something else? What often do you find as the source of the problem for teams that aren't working?

Jerry Colonna (01:11:56):
Well, it's the unresolved, I'll be dramatic with the language, demons from their childhood. It's the unsorted baggage. Here's what happens. Teams are groups, and there are group dynamics that always happen. There is the scapegoat, there is the truth-teller who has to say, "Let me tell you what's really wrong with everything going on." Without the individual's radical self-inquiry skills, groups tend to be condemned to repeating patterns oftentimes of their family of origin.

(01:12:40):
I'll tell you a quick story. There's a very famous software blogger, blogger-owned software that I coached for many years, and we were doing an executive team meeting, and something happened in the group as we were talking that I observed once, twice, and three times, and finally, I said, "Okay, guys, I'm seeing something happen here. Every time we get close to talking about something that's really painful, somebody makes a joke and all the energy disappears and everybody laughs and everybody's nice." And as soon as I said it, my client who was CEO at the time said, "Jesus Christ, that's just like my family." It was like, yes, that's just like your family.

(01:13:35):
Carl Jung once said, "Until you make the unconscious conscious, it will direct your life and you will call it fate." Let's apply it here. Until you make conscious the unconscious patterns operating in the group, the group will continue to repeat those patterns and you will blame somebody in the group. Romantic relationships from a Buddhist perspective, part of what we do in romantic relationships is we find the perfect foil for us to work out our unconscious phenomena. When we join a group, when we form up in teams and organizations, we are unconsciously finding the perfect foils for us to work out our own shit. So if you want to create a high-functioning team, do your work, and it starts with the person who has the most power in the group. If that person refuses to do their work, the entire group will become a manifestation of early dysfunction in the individual's lives. Does that make any sense?

Lenny Rachitsky (01:14:59):
100%. And this comes up a number of times on this podcast, just the impact the leaders issues have on the rest of the team, and also just this idea that the conditions they're trying to avoid are the conditions they invite in because they're avoiding.

Jerry Colonna (01:15:14):
That's it. That's it. One of my favorite teachers and dear friends is Parker Palmer, and he builds on, I think it was Socrates who said, "The unexamined life is not worth living." And he builds on that and makes a joke, and he says, "But if you choose to live an unexamined life, please don't take a job that involves other people." And that's it. You have a responsibility to examine your own shit.

Lenny Rachitsky (01:15:43):
So say you're on this team, so there's two sides of this. You're on a team, the leaders clearly got some stuff that they need to work through, but they're not. Is there something you can do there other than just, "Hey, please, this is hurting us?" And then from the leader's perspective listening to this, what should they do? Is it get a coach? What can you do?

Jerry Colonna (01:16:01):
So for the one who has less power?

Lenny Rachitsky (01:16:04):
Yeah.

Jerry Colonna (01:16:05):
One of the things to ask oneself is what draws me to this position in the first place? How have I been complicit, not responsible in creating the conditions I say I don't want. How have I benefited from the dysfunction that exists in this organization? And benefit is a funny word. It doesn't necessarily mean I'm making more money. It means, for example, a benefit might be, boy, this feels familiar. I always find myself working on teams that are dysfunctional in this way. What is there in that experience for me to learn? So that's one thing.

(01:16:55):
You asked about the person who has power. You were using the word leader. I will talk about power, and you threw out, well, should they get a coach? Let's put it into larger context. Should you examine your life with radical self-inquiry? Yes. I would argue that the more power you have, the more moral responsibility you have to actually pause and figure out what it is that you're doing to be complicit in creating the conditions you say you don't want.

(01:17:28):
To be a very quick example what I'm talking about. A couple of years ago, I was doing a talk at a venture firm's CEO portfolio summit, the portfolio company's CEO summit. And we're sitting in a room, and of course I'm walking around again with shoes off and whatever, and people are firing questions at me. And one woman says, "Well, I'm the CEO of this 15-person company, and I have a question for you. Why is it that nobody on my team can make a decision without me?" And I said, "Who hired them?" And she, "Well..." I said, "Okay, how does it make you feel when they make a decision that you disagree with?" She said, "I'm furious." "Well, how can you hire people whom you expect to make decisions without running them through you if you can't tolerate them making a decision that you disagree with?"

(01:18:37):
You want to build a scaled leadership team, you have to be willing to have them make boneheaded decisions. And that's really, really hard, especially if we're "in founder mode" driving all the decisions. So that's your growth edge. We were talking about before about growth mindset. That's your growth edge. How can I be with the people in my life making boneheaded decisions about something that I care so much about and what is the best way for me to be in relationship about that?

Lenny Rachitsky (01:19:18):
So much of this comes back to that question we started this with of just how are you complicit in creating the conditions you don't want? A big takeaway for me here, and it just keeps coming up and again and again, is if you're struggling as a leader, if your company's not working as well as you wanted to, if you're having a hard time with your team, going back to that equation, it's not about building more skills like public speaking skills or email skills, or I don't know, financial skills. It's self-awareness, radical self-inquiry, understanding what drives you, what makes you happy. Is that generally correct?

Jerry Colonna (01:19:51):
Lenny, I was just going to say, you just made me so happy you saying what you just said. Yes. I've been coaching now, as I said for a couple of decades. Before that, I was a VC for 15, 17 years. What you just said is the wisdom of my 40 years as an adult. That's it. This is why radical self-inquiry is so damned important because it leads to a little bit less suffering and a lot more resilience.

Lenny Rachitsky (01:20:28):
For folks that want to actually do that, well, they can rewind back to the middle of the episode where we actually ask the questions that are associated with the radical self-inquiry, and then obviously if they want to dig deeper, they can buy your book.

Jerry Colonna (01:20:41):
Or 10 copies of the book.

Lenny Rachitsky (01:20:43):
Or 100 copies for everyone at the company willing to Amazon. Jerry, is there anything else that we haven't touched on that you think is really important for people to hear maybe as the last piece of wisdom?

Jerry Colonna (01:20:57):
Now one of the hopes that I have you ask me at the start like what would be my hope is that we ended up being closer and friends, and I feel that. Let me extend that out to everybody. What I always hope from all of these intimate conversations that I try to do in podcasts is that people walk away going, "Geez, I'm not alone." We've made different references to the fact that it's a hard time. The truth is it's always a hard time. And what makes it hardest is to feel like I'm the only one who's going through this. So what I appreciate about what you do, Lenny, is that under the guise of talking about product, you're really talking about the process of being human. And that is a mitzvah. That's a good deed. And so, I hope in the process of listening to this, people walk away going, "Okay, I feel a little bit better today."

Lenny Rachitsky (01:22:04):
I really appreciate that. The way I think about these sorts of conversations and episodes, I call them Trojan Horse episodes where people come for the other stuff, tactical, practical stuff, and then they get stuff they really need to hear. And so, I appreciate you. Jerry, thank you so much for being here.

Jerry Colonna (01:22:19):
Thank you for having me. It was a delight.

Lenny Rachitsky (01:22:22):
Same for me. Bye, everyone. Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Building a world-class data org | Jessica Lachs (VP of Analytics and Data Science at DoorDash)
**Guest:** Jess Lachs  
**Published:** 2024-07-14  
**YouTube:** https://www.youtube.com/watch?v=D4PDb_C8Dww  
**Tags:** growth, retention, acquisition, onboarding, churn, metrics, roadmap, prioritization, experimentation, data-driven  

# Building a world-class data org | Jessica Lachs (VP of Analytics and Data Science at DoorDash)

## Transcript

Lenny Rachitsky (00:00:00):
So you've built one of the largest and most respected data teams in all of tech.

Jessica Lachs (00:00:05):
For me, analytics is a business impact driving function and not purely a service function, not just answering the why, but answering the, "What do we do now that we know this?"

Lenny Rachitsky (00:00:15):
One of your colleagues told me that you are incredibly good at defining metrics.

Jessica Lachs (00:00:19):
Retention is a terrible thing to goal on. It's almost impossible to drive in a meaningful way in a short term. Ultimately, you want to find a short-term metric you can measure that drives a long-term output.

Lenny Rachitsky (00:00:32):
You mentioned the early team. I felt extreme ownership.

Jessica Lachs (00:00:34):
Yes, you are a data scientist, but your goal is to figure out what's happening. And if that means that you're going to pick up the phone and call customers, then that is what you're going to do to roll up your sleeves.

Lenny Rachitsky (00:00:48):
Today my guest is Jessica Lachs. Jessica is Vice President of Analytics and Data Science at DoorDash, which has built one of the biggest and most impactful data teams in tech. She's been at DoorDash for over 10 years and was the first GM at DoorDash responsible for launching new markets. Previously, Jessica founded GiftSimple, a social gifting startup and began her career in investment banking at Lehman Brothers.

(00:01:11):
In our conversation, we go deep on how to build and scale your data org, including why a centralized org model is so effective. What to look for when hiring data people, how to pick the right metrics for teams to align incentives and drive the right sorts of outcomes. Examples of how the data team at DoorDash has helped the business make better decisions, a bunch of great stories about the early days of DoorDash and a ton more. If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. It's the best way to avoid missing feature episodes and helps the podcast tremendously.

(00:01:44):
With that, I bring you Jessica Lachs. Jessica, thank you so much for being here and welcome to the podcast.

Jessica Lachs (00:01:55):
Thank you so much for having me. I'm very excited to be here.

Lenny Rachitsky (00:01:58):
So you've built one of the largest and most respected data teams in all of tech. I've heard from a number of people that look to you for advice when they're trying to build and scale their data teams. And then DoorDash in particular is an incredibly complex business. There's three or maybe even four sites to the marketplace. There's this operational element. From the outside, it just feels extremely complicated and wild. I imagine from the inside it's even more wild. Let's talk about some of the things you've learned about building and scaling the team. You have a fairly contrarian perspective on how to structure data teams. This was referenced when we had Elizabeth Stone on the podcast too. She approaches data the same way. So I'd love to hear just your take on how to structure data teams within companies.

(00:02:42):
 This episode is brought to you by Webflow. We're all friends here, so let's be real for a second. We all know that your website shouldn't be a static asset. It should be a dynamic part of your strategy that drives conversions. That's business 101. But here's a number for you. 54% of leaders say web updates take too long. That's over half of you listening right now. That's where Webflow comes in. Their visual-first platform allows you to build, launch, and optimize webpages fast. That means you can set ambitious business goals and your site can rise to the challenge. Learn how teams like Dropbox, IDEO, and Orangetheory trust Webflow to achieve their most ambitious goals today at webflow.com.

(00:03:30):
This episode is brought to you by Anvil. Their document SDK helps product teams build and launch software for documents fast. Companies like Carta and Vouch Insurance use Anvil to accelerate the development of their document workflows. Getting to market fast is a top priority for product teams, and the last thing that you or your developers want is to build document workflows from scratch. It's time-consuming, expensive, and distracts from core work. You could stitch together multiple tools and manage those integrations or you can use an all-in-one document SDK.

(00:04:04):
Most product managers will tell you, "Paperwork sucks." Anvil's document SDK helps teams get to market fast, incorporate your brand's style, and give you back time to focus on your company's core differentiated features. For your users paperwork often starts with an AI-powered web form styled and embedded in your application. From there, you can route data to your backend systems and to the correct fields in your PDFs via API. Complete the process with a white labeled e-signature. The best part about Anvil is the level of customization their SDK provides. Non-technical folks love Anvil's drag-and-drop builder and developers love their flexible APIs and easy-to-understand documentation.

(00:04:46):
Build documents software fast with Anvil, that's useanvil.com/Lenny to learn more or start a free trial. That's useanvil.com/Lenny.

Jessica Lachs (00:04:59):
There's two main things that I think are important when you're structuring a team. The first is I believe that analytics should have a seat at the table just like engineering and product and the business folks, the operators. For me, analytics is a business impact driving function and not purely a service function. I think there are analytics teams at other companies where they are answering people's questions, maybe even through Jira tickets, we're building dashboards. That was never really of interest to me. That wasn't the team that I wanted to build.

(00:05:35):
For me, it's about finding opportunities, about having a point of view on the decisions that we should make, not just answering the why but answering the so what. "So what do we do now that we know this?" And so that's definitely one thing as far as my point of view on building a data team. I think the second thing which may be a little more contrarian is I think there are people out there who think that analytics should be embedded into business units. I strongly disagree. I believe a central model, a center of excellence is superior and I'm happy to talk about why, but that's something that I feel quite strongly about. We've tried it or I shouldn't... well, we've experimented in the past with the alternative, so putting it into a business unit and it's just much more problematic and I think the value you get from a central model is far greater than some of the things that you might lose.

Lenny Rachitsky (00:06:36):
Yeah, let's definitely talk about it. And just to make sure people understand, when you say central versus embedded, is that in terms of reporting lines, in terms of their goals?

Jessica Lachs (00:06:44):
It's a great question. So mostly it's in terms of reporting lines because I think on the goal side, that is something where we have the same goals that our partner teams have, and I think that that's actually an important part of a successful central model. So when I say central model, it just means that for marketing analytics, marketing analytics is part of the broader analytics team. It does not sit and report in through marketing. Just to clarify.

Lenny Rachitsky (00:07:13):
Got it. So the reporting functions at some companies, there's the head of marketing or some partners to the head of marketing where the data, say, analyst or biz ops people or data scientists would report potentially to them and that's it. And they're not as connected to the core, to the rest of the data team, the rest of the analytics team versus-

Jessica Lachs (00:07:30):
Exactly. Yeah.

Lenny Rachitsky (00:07:31):
Yeah.

Jessica Lachs (00:07:31):
So you'd have a bunch of smaller, of course, data teams that sit embedded within the functions. And I understand why business leaders like that. You're embedded within the function, so you're a part of the team. That ownership, that camaraderie that comes with that, I think you can solve for that. But I do understand that that is a benefit. I think the other benefit of course is the business leaders control the roadmaps so they get to dictate the work. They know that they have help and resources in that area when they need them. So that certainty, that control, I totally understand the value there, but I think that those are two things that you can solve for if you know that those are the biggest issues with a central team. So for us, we have a central analytics team, but we are divided up into pods that map perfectly with how product engineering, operations marketing are structured as well.

(00:08:33):
And so our team de facto has these folks embedded with our partner teams, even though the reporting structure is up through a central org through me. And that helps the team to feel like they are one team, both in terms of the analytics team feeling like it's one team, but also to use the marketing example, the marketing folks are one team and because the analytics shares the same goals as the marketing leaders, your incentives are aligned to work on the most important things and your success is their success and vice versa. So I think that that's been really a happy medium, but still preserves all the benefits of a central org. And there are a lot of them.

Lenny Rachitsky (00:09:23):
I want to hear about them, but I think something that some people may think when you say essential org is like a silo data team that sits there and they're like a service org a little bit within the company. It's like, "Hey, I need some data help." And you try to convince that, "Hey, I need some help on this thing." And that's not what you're saying.

Jessica Lachs (00:09:41):
Oh, no. No, no, no. That job seems terrible. I don't want that job. No, to the earlier point, we have a seat at the table. We are business partners, we are thought partners with our product counterparts, with our engineering counterparts, with our ops counterparts, and we again, share the same goals and have the same initiatives that they do. And it's just our job to come at it from a data-driven place. We bring to the table insights on things that we've noticed, deep dives that we do to understand the problems that we're trying to solve better. If we need to grow, what are the most efficient ways to grow? What are the trade-offs that we have to make? Where are their pockets of opportunity? That is what I expect my team to be able to bring to that table, the proverbial table, that we want to see that. And in order to earn their spot, that's the deal. We get the seat at the table and we need to earn it by bringing opportunities that we all can go and go after.

Lenny Rachitsky (00:10:52):
Awesome. So in a sense, it is embedded. They're embedded in cross-functional teams across the org, but they report up to essential org to you essentially in the end?

Jessica Lachs (00:11:01):
Yeah.

Lenny Rachitsky (00:11:02):
Cool. What are some of the benefits of this approach?

Jessica Lachs (00:11:05):
Oh, there's so many. Okay, so the first thing is a consistent and high talent bar. I think this is something I saw when we would have some pockets of analytics folks embedded is having a consistent bar for talent in terms of what we're looking for, what are the technical skills, what are the soft skills? And being able to evaluate candidates with that same bar, using our same rubric. You just get more consistent and higher talent in my opinion. I think that's number one. Number two is actually growth opportunities. So if you're siloed, you may be the most senior data person within... I keep picking on marketing. But you might be the most senior data scientist within marketing. Where do you go from there? I think when you have the central org, you're able to see if there are growth opportunities in other areas within the company.

(00:12:04):
And so that really helps folks to stay engaged because they can look at new problems if the problems they've been working on for several years are getting maybe boring and they want something new, there's an opportunity, move from marketing over to merchant analytics. And then I think similarly, if there isn't a promotion or room to grow, if you want to be a people manager and there just isn't a people management role within your functional area, well, you've got 10 other ones to look at and maybe there is that opportunity. So I think it helps with the growth opportunities for the team, which helps to retain talent. So that's a second thing. The third thing is just consistency of methodologies and metrics. So you don't have sales that was as defined by one team and sales as defined by another team. You just have sales and everybody is using the same metrics, the same methodologies, and you're able to improve your methodologies with input from more people.

(00:13:10):
And rather than recreating the wheel, building the same churn prediction model on six different teams. You can instead build one and have the input of six different teams. I think that's definitely another benefit. Also helps you just scale because you start to see the same problems across teams and so you're like, "Ooh, this is an issue that we need to get ahead of. This is something we need to automate," or, "This is something that we need to improve upon," or, "a problem that is going to grow as our business, as our teams scales." So I think it helps you see around corners a little bit more.

(00:13:45):
And then just lastly, there's a team culture brand. I think that's really important, not just externally for recruiting top talent, but the team is really proud to be members of the analytics team. We have a unique culture of learning, of sharing. You have someone you can go to talk about your challenges. You have someone who can peer review your work. I think just having that team culture that we have is really important. And it's a lot harder to get when you have the individual silos, particularly in an earlier stage when it's a smaller team, you just don't have as many people around. Everybody wants to have friends at work and we're creating an environment where they can find like-minded data nerds.

Lenny Rachitsky (00:14:33):
It makes me think about Airbnb's first data team. I don't know if you know Riley Newman well, but he built Airbnb's first data team and it was actually an analytics team. They called themselves the 'A-Team' on the point of culture, and that always felt a lot of fun and they loved being part of that team.

Jessica Lachs (00:14:49):
Yeah. We have the same, but now I feel a lot less special for coming up with that name.

Lenny Rachitsky (00:14:55):
Oh, you called it A-Team also?

Jessica Lachs (00:14:56):
Yeah, we got the A-Team, yeah.

Lenny Rachitsky (00:14:59):
And then I think they moved away from it when there was a push. Now we're data scientists, we're not analytics or analysts. And that was like, I don't know, 10 year ago, like [inaudible 00:15:08] data science. We're data scientists.

Jessica Lachs (00:15:09):
We'll always be the A-Team.

Lenny Rachitsky (00:15:11):
There's so many threads I want to follow here, one that's a tangent, but something that I think a lot of people struggle with is you talked about how you want your data team, your analytics team to be proactive, to find opportunities, to give you ideas, to help you figure out what to build, not just answer questions. At the same time, there are many questions that teams need to get answered. Do you have any advice for just how to set up a team where they both find time to explore, dig, show opportunities and come up with big ideas and also, "Hey, we just need to figure out the funnel conversion on this thing," or "Hey, what do you think? What's happening in China right now?" Thoughts there?

Jessica Lachs (00:15:47):
Yeah, such a good question. I think it's something that never gets easier. You have to be very intentional to carve out time for exploratory work for deep dives because as you mentioned, there are always more questions and more work to be done than hours in the day. And so I think being intentional about it and setting goals for your team around finding these insights through self-directed work is an important mechanism for holding ourselves accountable to that goal because it tends to be the first thing that goes when you get a lot of inbounds, you're like, "All right, well, let's deep dive on something that I don't know if it's really something. It could be high ROI, it could be low ROI, I don't know." So the expected value is lower than this known thing that I can deliver and make someone happy.

(00:16:42):
So I think to prevent that time from just slipping away, you really have to be intentional. We would do hackathons for our team to carve out days to just go and look into these really interesting things and find opportunities. And I think we have the support of our business partners because so many great insights have come from these deep dives and it really has been some of the work that drives future roadmaps. So they're always really great at allowing us to have this time and actually encourage us often to have this time for some self-directed work, to go find the next big opportunity.

Lenny Rachitsky (00:17:23):
If there's no answer that comes to mind, that's totally cool. But is there an example of one of these insights that someone on the data team came up with that led to something big for DoorDash that you're able to share?

Jessica Lachs (00:17:35):
So one interesting example was from a hackathon we did a couple of years ago where we were looking at referral as a channel for consumer acquisition. And when you compare that channel to others, it was below average in terms of the engagement you'd see from consumers who came through that channel and the payback period. And rather than just lowering spend on referrals and moving right along, we really wanted to understand what was happening. And so during the hackathon, we did a deep dive into referral. We actually tried referring each other. We tried committing referral fraud, creating new accounts to get around rules. And we uncovered a lot of fraudulent behavior through this deep dive. We ordered so many cupcakes to the office. I remember using referral credits because you had to place an order to be able to get the referral bonus. So we would create the account, place the orders, and we just kept ordering cupcakes.

(00:18:39):
And what we noticed was that referral as a channel was a bit misleading when you would look at the average in terms of payback and that it was really a bimodal distribution and you had one group of really great consumers who were referring other really great consumers, and the payback on those consumers was really strong. In fact, if that's all you saw, you would spend a lot more on that channel.

(00:19:08):
And then what was happening was you had this other group of consumers that were not as good people who were posting referral codes online and getting people who were just in it to get free discounts and credits. And we had at that point in time, pretty lax fraud rules. And we didn't have caps on these things. All of which came about from this deep dive where we found that this group of consumers was really a drag on the efficiency of this marketing channel. And so I think that's an example of a few things that we like to do at DoorDash. One being these deep dives and taking the time to really understand the problem and then ultimately make a bunch of recommendations for what we should do, including better fraud checks, caps on referrals, et cetera, et cetera. But also how the average can be incredibly misleading. And so looking at distributions and trying to break down what you're seeing to find ways that you can optimize in ways that you can gain in efficiencies.

Lenny Rachitsky (00:20:21):
That's an awesome story, great memory to come up with that one. So this is a really good example of a way to carve out time for the data team to think long-term, think look for opportunities, find big ideas. So the hackathon is one idea. Imagine many data people are struggling often to push back on asks that are just like, "h, we need to know. We just need this one thing. Here's a question, just answer this one question part." Do you have any advice to data to get better at pushing back? Sounds like a bit of cultural like, "We have time, we need to work on these bigger things." But just any advice for data leaders or data ICs to find time for these sorts of things?

Jessica Lachs (00:20:59):
Yeah, saying no to someone is never fun. I think as a self-proclaimed people-pleaser, you don't want to say no, especially when it's something you can do and you know that you can very easily with maybe an hour's work, make someone happy. I think it's really important to establish a culture and for leadership to really establish the rules of working and that operating model so that some of the junior folks aren't forced to always have to say no. And I think one of the ways we do that is through our goaling. So because our goals are the same as our business partners, we're able to pretty easily say, "Hey, we've got a limited amount of time. These are our goals. What are the most important things that we are going to work on this week or this month in order for both of us to hit our goals?"

(00:21:49):
And so when something comes up to be able to say, "Hey, this data poll that you want me to do, is this more important than these other three things that I was going to be working on? Yes or no?" And I think sometimes people don't necessarily realize the trade-offs, and when you make them apparent and you put them front and center, they realize that, "Oh, actually, you know what? That asset's not important. That can wait." So I think that that's definitely something I would recommend, which is always share the trade-offs. Don't suffer in silence with, "How am I going to do all four of these things?" Bring it up and say, "Hey, this is what I was planning to do. If you want me to do this extra new thing, then one of these other things is going to have to drop.

(00:22:36):
I personally don't think that your ask is more important than these three things, but maybe there's new information, maybe there's context I don't have, so let's talk about it." Rather than just being like, "No, I won't do that." That's not a great approach either. I think having the conversation and constantly reevaluating your prioritization to make sure you're working on the most important things or your team is working on the most important things is really good hygiene to have with your business partner. So some teams do that through a weekly standup like, "Here's what we're going to do this week. Do we like this prioritization? Do we not?" Some folks do it less formally than that. I think you got to figure out what works for you. But to the earlier point, it's a conversation with your engineering partner, your product partner, your ops partner, you're all on the same team, you're all trying to achieve the same goals and you're all incentivized to have your analytics team working on the most impactful things.

Lenny Rachitsky (00:23:32):
This advice is great for any role basically. And if I were to summarize it to a couple words, it's just prioritize and communicate what your priorities are and then align on the trade-offs of shifting your priorities.

Jessica Lachs (00:23:45):
Every once in a while you just throw one over and say, "You know what? This is quick. I'll do it." At least I do. I think sometimes just knock it out, build some goodwill. I think that that's also important. But usually it's not something you can do in five minutes and in that case it's that ruthless prioritization for sure.

Lenny Rachitsky (00:24:05):
And then there's also the side that you talked about of just show that you can provide value doing these things that are longer term, like prove your worth. "Hey, look at all these opportunities I found for our team over time, I should keep spending time on these other areas," versus the on fire stuff.

Jessica Lachs (00:24:18):
Exactly.

Lenny Rachitsky (00:24:19):
When you're hiring people for your team, I'm curious what you look for and you think is incredibly important that maybe other people aren't prioritizing as much. What do you focus on when you're hiring?

Jessica Lachs (00:24:31):
Yeah. So everybody needs to have a certain set of technical skills. I think that's a non-starter. We have a technical bar, we do a technical screen. So I think that's table stakes. There's some really unique characteristics that I've noticed when I look at some of the top talent that I've had on the team or have on the team. I think the first thing is just curiosity. You can't teach curiosity, or at least I haven't found a way to do it. If somebody else knows how, please let me know. Somebody who is just self-motivated to pull on the threads when they find them. So they don't just answer a question. They're like, "Hmm, this thing seems a little odd. I'm going to dig in and look. Even though I could say I'm done, I answered the question, I did the thing I was going to do." The person that has that curiosity, something seems off, something doesn't really make sense and goes and proactively looks into what that is. That is just so valuable. So I really look for that curiosity and that self-motivation to do it without being told.

Lenny Rachitsky (00:25:39):
How do you test for that? How do you do that in an interview and get a sense of if they're good at that?

Jessica Lachs (00:25:43):
One way you can do it through the questions you ask is have something that is not quite right within the case that you're presenting and see if people notice first and foremost. And even if they don't, if you point it out like, "Where do they go with that?" I think that that's something that you can test for. I think you can also ask for examples that for these folks typically will highlight this, they'll talk about, "I noticed this thing, and so we decided to investigate." So I think that there are ways that you can get that signal through the interview process, but it's really hard. I think testing for hard skills is a lot easier than testing for soft skills. And I think in some of the questions we ask, we'll ask a question with the idea that we're assessing something separate than what the question is necessarily asking. And I think that this is one example of where that really works.

Lenny Rachitsky (00:26:47):
You said that you give them a case. What does that look like? What is the actual approach to how you do this interview?

Jessica Lachs (00:26:52):
Our interview process has in the early stages a coding exercise. So we do our technical screen and a shortened version of a business case. So real world problem solving. Typically, it's something actually from DoorDash history, like a real problem that we had to see how people can problem solve on the fly. I think that that's an important skill to be able to have, which is, how do you take a problem, break it down, talk through it. A little bit like some of those consulting cases that you hear about, but something that's really rooted in real problems. And I think you can learn a lot from those types of cases where, yes, you get to see how people handle ambiguity and structured problem solving, but ultimately most people get something wrong. They make an assumption that's wrong because well, I would hope that the interviewer knows the business better than the interviewee.

(00:27:56):
And seeing how people react to being told they're wrong is a really important signal in my opinion. Seeing how people respond, how they're able to take new information and pivot, how they're able to make a decision. So that's another thing that I like to see in cases where, hey, you may not know the real right decision. You might say, "Hey, I could see it going one way, I could see it going the other way." But I always push people to say, "If you had to make a call right now, what would it be?" So are people able to have a point of view without full information because that's life. Sometimes you have to just pick a direction and make a decision even though you don't have perfect information. So I like to see some of these softer skills and how they manifest throughout a case interview, even if it's not specifically what I'm asking with the literal problem we're solving in the case.

Lenny Rachitsky (00:28:57):
Along these lines, but in a different direction. You don't actually have a deep data science data background before you got into this stuff. I know you had some art background, you had an art portfolio back in school, and I think a lot of people wouldn't imagine that for someone being head of analytics for a company like DoorDash. I don't exactly know the question, but I guess is there anything there that you think would be interesting for people to know or hear?

Jessica Lachs (00:29:24):
Yeah, it's funny. I joke that I have a job I'd never be hired for because I don't have a traditional data science background. And I know that Elizabeth Stone on her podcast with you talked a lot about her non-traditional background for a CTO. So hey, maybe there's something to it. But I became a data scientist out of necessity. I completely self-taught in terms of SQL and Python and I did it because there was a need at DoorDash for someone to help figure out what the right goals were, how we set those goals, how we were performing different markets early in the DoorDash story, so 10 years ago at this point. And I think I just gravitated towards that type of work and Tony recognized that superpower in me even though I don't have that formal training. So yeah, I'm a bit of an artist for fun, but I guess a data scientist in practice or for career.

(00:30:31):
But I think that that non-traditional background has been a great thing because I'm able to hire people who have the technical skills that I don't have, the folks with PhDs in statistics and the data scientists, machine learning and otherwise. I am able to hire those folks and yet keep them really focused on driving business impact because my background was on the finance side, and so I've always been a pragmatist. And for me, the purpose of our team is to drive business impact. And so the mix between the technical skills of the smarter people that I've hired, the smarter than myself, and my grounding in driving business impact has been a really great partnership.

Lenny Rachitsky (00:31:21):
That's quite an inspiring story for someone that is just starting out and doesn't necessarily have a lot of experience in data, but also just generally. I think this is a really cool example. You could be successful in a field that you don't have a ton of background in. I'm curious what you think it was in you that allowed you to succeed in this and get to where you are today. What do you think you did right or what is some habits or ways of thinking that you think helped you achieve that?

Jessica Lachs (00:31:52):
First off, I have imposter syndrome like everybody else. So it's not like I have this crazy sense of confidence of like, "Oh, I can do anything." I definitely have the same doubts that others have. I think part of it was probably not even realizing what I was doing. When you're at a startup and things are moving quickly and you see a problem, and I've always liked solving problems, so I was like, "All right, how do I solve this problem?" It was like, "Oh, well, I need access to the data. I don't have access to the data. All right, I'll ask an engineer to get me the data. Well, this isn't going to scale. I can't always bother an engineer, so how do I figure out how to get the data myself? Well, let's learn Python." So I think it happened organically and I don't think I realized at the time what I was even doing.

(00:32:41):
And then I think if you think about things from first principles about what you need right now in front of you to unblock yourself or solve a problem, and you just focus on that instead of thinking about a global org that you're trying to build. I think that that helps. So for me, it was always about solving the problem in front of me the best way I could. And if that meant I needed to hire an engineer to report into me through the finance org, then that was what we were going to do and nobody was going to tell me I couldn't do it. So I think it's a belief in yourself, and ultimately it's just my desire to solve problems and figure out what has to get done is, I think, ultimately how it came about.

Lenny Rachitsky (00:33:30):
I love that so much. There's so many elements there that I think a lot of people can learn from. I feel like there's also this underlying current of you're just motivated for this to work. You wanted DoorDash to succeed, and you're just like, "I will do what I need to do to make this happen. I need to solve these problems. I'm not going to overthink. Do I have the skills necessarily to do these things [inaudible 00:33:48]?"

Jessica Lachs (00:33:48):
Yeah, I think I'm competitive. I think that's a trait that you find in a lot of early DoorDash folks and current DoorDash folks, to be honest, just wanting to win and being willing to do whatever you need to win. So roll up your sleeves, do something that's not your job. I think back to early days of taking out the garbage on Saturday nights because it needed to get done. I think that that was something that is ingrained in our culture from Tony Xu, from our founder and CEO, and I think that really resonated with me, and I feel like I've always operated that way as well. And I think that that helped me in my career to be able to do what I've done without really thinking about it too much.

Lenny Rachitsky (00:34:40):
Are there any other memories or stories of the early days of DoorDash that would be fun to share? Something that sticks with you of like, "Wow, I can't believe that's what it was like?"

Jessica Lachs (00:34:49):
Oh man, there's so many, including so many mistakes that we've made. But I think something that really stands out to me is before I moved to the analytics area, I was actually a GM. I was the first GM at DoorDash and I was in Boston in 2014 launching the city of Boston when nobody knew who we were. And we would wake up early in the morning, 5 A.M. and we would go out, it was the winter of 2014. We'd go out and we'd hand out promo codes consumers outside of the [inaudible 00:35:30] in Boston, and these promo cards would be attached to kind bars so people would take them. And the whole team, it was a small team, there were four of us, but the whole team would go out in the morning to do this. And I think back to our sales guy, shout out to Joey G. So Joe Graccio is our sales guy in Boston-

Lenny Rachitsky (00:35:47):
[inaudible 00:35:47] Joey G.

Jessica Lachs (00:35:51):
And he was gold on signing merchants on the platform.

(00:35:55):
That was how he was gold. His compensation was tied to that. And yet in the morning when we would go out, he was with us handing out promo codes because he was part of the team because he wanted to win. We wanted to grow the business. And I think that that is just a great example of the culture that Tony and the early employees and Stanley and Andy, other co-founders really instilled in all of us early in those days. So I think that that ownership, that extreme ownership of the outcome is definitely one of the things.

(00:36:32):
I think the other is just being very customer first. And I say customer, I mean consumers, dashers and merchants as all being our customers. And the first time I ever went to the office headquarters in Palo Alto, which at the time was in an animal hospital. The first time I went there, there was a huge site outage and the whole company, it was like 20 people at the time, the whole company jumped online to do customer support, to answer the phones, to make sure that folks were getting refunds for orders that weren't going through, make sure the orders that were out there were getting delivered, just dropped everything and hopped on to do support.

(00:37:15):
And I was brand new, didn't really know how to use the tools, and so it was like, "How can I be useful?" And so back in those days, we used to order dinner to the office using DoorDash. And so in order to preserve about three dashers who would've had to deliver food to us, I was like, "I'm going to go out, go out dashing, go get everyone pizza so that we could feed the masses doing credits and refunds and do what we had to to make sure that we were serving our customers well." And I think that night was one of the largest refunds as a percent of our bank account that we had ever given out. And I think Tony, there were two examples that he's talked about where we just gave a lot of money back to customers because it was the right thing to do because our service failed and we wanted to do right by them.

(00:38:06):
So I think that those are two stories that stick out in my mind and really highlight culturally what makes DoorDash unique and what I think has been a really important part of our success.

Lenny Rachitsky (00:38:20):
It reminds me of the story that Tony and all the early employees, and I imagine you did this just like, "We're dashers," it's like a rotation where you dash for a while. Is that part of the culture?

Jessica Lachs (00:38:32):
Yeah, so we have a program, a WeDash program, and Keith Yandell, who's our chief business officer, did your podcast last year and he talked about this. But four times a year all the employees go out and go dashing or do customer support, and it's part of our culture that I love. I actually go pair dashing, so I go together with one of my colleagues. We've done it for years now, and it's a fun thing that we do together four times a year. Actually, usually more than that. And it's important because you get to use the product, you build empathy with all the audiences. I think all of us order DoorDash a lot, so we've built empathy with consumers. But being able to go and understand what it's like to go out dashing and when you're in the restaurant going and talking with merchants and seeing the experience from their point of view, I think it's just incredibly important. And of course we find a lot of bugs like, "Hmm, this doesn't work the way it should, let me report this." So I think it's also just great for catching bugs in the product.

Lenny Rachitsky (00:39:43):
This episode is brought to you by Attio, a radically new type of CRM. There's a world where your CRM is powerful, easily configured, and deeply intuitive. Attio makes that a reality. Attio is built specifically for the next era of companies. It syncs with your data sources, easily configures to their unique structures and works for any go-to-market motion from self-serve to sales led. Attio automatically enriches your contacts, syncs your e-mail and calendar, gives you powerful reports and lets you quickly build Zapier style automations.

(00:40:17):
The next era of companies deserves more than an inflexible one-size-fits-all CRM. Join modal, replicate 11 labs and more, and scale your startup to the next level. Head to at attio.com/Lenny and you'll get 15% off your first year. That's attio.com/Lenny.

(00:40:39):
I want to come back to a thread, something you mentioned where you and a lot of the early team had felt extreme ownership over the company and that's why a lot of this stuff happened. For people, every founder, every product team, they're going to like, "Yes, we need that. Let's make sure everyone on the team feels extreme ownership." Is there anything that you think that the early team did to create that or is it hiring, just pick people that will have that feeling already, or is cultural?

Jessica Lachs (00:41:05):
I think it's both. It's definitely cultural. I think it comes from the top and I think that Tony exhibits this extreme ownership and looks for it in others. So I think that helps. But I think even today I expect of my team that same extreme ownership over the outcomes. And so I'm more interested in our team figuring out how to solve a problem than the box that someone fits in like, "I'm a data scientist and so I only do these things." Right? It's like, "No. I mean, yes, you are a data scientist, but your goal is to figure out what's happening, and if that means that you're going to pick up the phone and call customers, then that is what you're going to do." And I think that expecting that and setting that as the norm for the team, this ownership of the outcome is something that we continue to do at DoorDash and instill in everyone whether you were early or just joined last month.

Lenny Rachitsky (00:42:09):
Is there an example of that that comes to mind of someone practicing extreme ownership, like a data scientist calling someone or something along those lines?

Jessica Lachs (00:42:16):
Yeah, so I actually had a meeting yesterday morning with the team that's working on some of our affordability initiatives and we had shipped something that we expected to work, and it didn't. And instead of, "You can dig into the data," to understand the segments of consumers that you would expect it to work with and those that it wouldn't, of course we did that. But ultimately it was like, "I don't know why." And that's where qualitative research is superior to quantitative research, it's asking for the context, to actually talking to people to figure out what was the motivation, what worked, what didn't for them. And so the team, data scientists included, just sat and made phone calls. And so they were talking about what they found from those phone calls and that's going to inform future decisions. And I think rather than saying, "Well, that's what the qualitative research team is supposed to do," it's like, "No, no, no, that is what our team, anyone's team is supposed to do because that's what's needed to unblock us from this next test that we want to run because we need to know what we are testing."

(00:43:23):
So I think that it happens every day. I think I really love when I see team members go outside the traditional bounds of what a data science role might be and do some product management work, do some engineering work. I think that that's part of what keeps the job interesting. I think it's part of what makes our team special is that that is not only allowed, it's encouraged, and probably also a reason why we've had folks who've gone from my team to the product org and to the ops org and to the finance org is because they get to do and experience parts of that job and get a good sense for what that's like and then realize it's something that they love. So I think it's definitely something we encourage at DoorDash.

Lenny Rachitsky (00:44:17):
I love that. I want to move in a slightly different direction. One of your colleagues told me that you are incredibly good at defining metrics, which is so important to get right for a business, especially when it's complex at DoorDash. And I hear you're especially good at finding the right metric to drive the right incentive, especially when the business is really messy and things like that. So I'm just curious what you've learned about how to pick good metrics and align incentives well.

Jessica Lachs (00:44:45):
I've learned a lot of things about metrics, mostly from bad metrics. I actually think you learn a lot from picking the wrong metric. Ultimately, you want to find a short-term metric you can measure that drives a long-term output. So people always talk about, "Oh, we want to drive an improvement in retention." Retention is a terrible thing to goal on because it's almost impossible to drive in a meaningful way in the short term, and yet you want to be able to experiment and iterate quickly. So what are the things that drive retention? What are the inputs? So I think it's really important to find the right inputs, and then through experimentation test whether or not those short-term inputs are driving the long-term output that you're looking for. I think that's one thing. I think keeping things simple is another thing I've learned over the years, maybe it's data scientists, but they tend to love these composite metrics with a coefficient.

(00:45:44):
"We're going to wait this input at X and this input at X+2." And then you end up with a metric that nobody really understands that doesn't actually mean anything. And you're like, "I don't know if a 0.1 increase is it a lot? Is it good? Is it bad?" So they're just hard to work with.

(00:46:07):
And so I always encourage folks, just pick something simple, even if it's not perfect and your composite would be more perfect. If people understand it, if they have an intuition around it, if it's something that people can talk about across the company, it's going to be a much better metric in terms of driving real outcomes than your made up composite score that nobody understands. So I think keeping things simple is also really important. And then I think the last thing I'll say is it's important to understand how metrics across the company equate to one another.

(00:46:43):
And so we spend a lot of time quantifying things in terms of a common currency. So for example, if I were to lower price by a dollar, what would I get in terms of, we'll say, volume? Well, what if I lowered delivery times by a minute? What do I get for that in terms of volume? And so now you can make trade-offs between maybe your marketing team and your logistics team because you have this common currency that everyone can talk about. And so we've done that. We've tried to quantify all of the levers of our business, price, selection, quality in common terms, so that if we have, say, a dollar to spend, we know what we get depending on where we put it, over what timeframe. I think that that helps us make decisions more quickly because we know what our options are. We know we have our inventory of things that we can do, short-term, long-term, and what we get for it. So it definitely helps us to make decisions more quickly and hopefully better decisions.

Lenny Rachitsky (00:47:56):
These are so awesome. I definitely want to follow up on some of this. This is so good. So maybe on this last one, which we did at Airbnb also like, how does everything translate into Knight's book and booking? Every decision we make, what is the actual Knight's book impact? And so I imagine in your case, I don't know if you want to talk about these things. I imagine it's transactions, or purchases, or GMB or something like that, so I'm guessing is the final metric. I don't know. Is that something you talk about or you don't talk about that?

Jessica Lachs (00:48:26):
We measure things in terms of GOV, so Gross Order Value, and also volume.

Lenny Rachitsky (00:48:33):
Got it. [inaudible 00:48:34]. Okay, so basically every other metric that people are gold on as much as you can translate, there's a model that translates that into Gross Order Value and volume? Awesome. So when a team is saying, "Hey, we're going to change the onboarding flow and impact conversion here." I don't know. I guess what are some examples of other metrics on teams that potentially translate into GOV and volume just to make it even more real?

Jessica Lachs (00:49:01):
Yeah. So everything from the example that you started with, which is an improvement in the login flow, how many more consumers are getting onto the app and ultimately placing orders. And so you can translate that to, of course, orders and GOV. But then something as interesting as selling a Thai restaurant in Sacramento, we're able to say, "What do we think that that gets us in terms of GOV from the consumer by selling that Thai restaurant?" So it's every area of the business, it's mobilizing more dashers on the road. What does that do to our quality metrics in terms of delivery times? How does that translate? So because of that, we're able to figure out if we want to spend the dollar or spend the time, the team's time, on improving conversion or spending more money in marketing or onboarding more dashers or signing more restaurants or adding more grocery stores. So we are able to look across the whole business and figure out what is the right mix of actions to take to achieve our goals.

Lenny Rachitsky (00:50:18):
I could see as you talk about this why this is so important in a marketplace, especially a multi-sided marketplace where there's always trade-off decisions between supply investment and demand growth and dasher growth. I don't even know, my brain would explode trying to think about all these things, so I get exactly why this is so important to business. Okay. And then in terms of the simple recommendation, I think when people hear like, "Yeah, keep it simple," they're like, "Yeah, yeah, we're going to keep it simple." What are some things that point to, "This is not simple," that tell you like, "No, this is way too complicated. You should try to simplify this metric even though it's not ideal. It's not the perfect metric, but it needs to be simpler."

Jessica Lachs (00:50:56):
Yeah. So we had a score for merchant health, which we tried experimenting with, which was a combination of factors that we had found would lead to a merchant being on the platform and getting an order. So we wanted to make sure that the merchant had active hours on the platform and had images and had a full menu that was accurate and robust. A number of different inputs. And we created a composite that weighted all of these different inputs. And then we were like, "What is our merchant health score?" And you were like, "It's 0.35. It's not 35%. So what is that, that 0.35? I don't know what it is." So instead of that, we said, "What are the most important factors in order... First, let's measure how many of the new merchants are getting an order within their first, say, seven days on the platform.

(00:51:57):
And then let's look at how many of our merchants are doing these things we know are important. So these inputs. So let's goal our team on getting merchant photo coverage up. Let's goal the team on making sure that we have open hours, accurate hours." So yes, someone might say it's simpler to have a composite metric, but it was so hard to understand what it was and how to move it that it became meaningless. And ultimately moving to something that was simpler to understand, even if it meant having three metrics instead of one, it ultimately was better for the team because folks knew what they were trying to move. And so yeah, maybe we missed number four, five and six on the list of things, but you got one through three and that's 95% of it anyway. So once we get success with that 95, then let's talk about figuring out the other 5%.

Lenny Rachitsky (00:52:55):
It's so funny because this is exactly what we went through at Airbnb, we had, we call that a healthy host. I led the host quality team for a while and we came up with this healthy host metric that was six factors of a host, like the cancellation rate, the review rate, their response rate and things like that. And then we're just like, "Cool, let's move this, let make more hosts healthy." And then you end up like, "Okay, which one do we focus on?," And, "Oh, what about all these others?" And we ended up basically focusing on one at a time. And so let's just make that the goal for now and then rotate through the different biggest [inaudible 00:53:28] opportunities to move. [inaudible 00:53:30].

Jessica Lachs (00:53:30):
Exactly. I think in hindsight for the example you give, which of those six things are actually the most important? And if you're able to then quantify which one matters most, you work on that one first and you materially move that one and then you work on the next one. You want to move them all. But being able to prioritize and know what you're going to get for a 20% improvement in, say, your cancellation rate, that's where analytics I think can add a lot of value. Because yes, ultimately you'll get to all of them, but the way you do that and the time can have a meaningful impact on your growth. If you can target the most problematic things first and solve those, you get more bang for your buck and that compounds over time. And so doing the things that matter first and most quickly is a competitive advantage in my opinion.

Lenny Rachitsky (00:54:21):
The other thing we found along those same lines is rotating between different metrics is so not efficient because you get good at, "We're going to move this metric." And your team's like, "Cool, we totally understand this lever," like cancellation rate. We become really smart at cancellation rate and then three months later, you need to switch to response rate and they have to learn a whole new paradigm of how to think about it. And it's just super inefficient. So we found basically, just keep a team on the metric until there's no more opportunities and give another team one of these other metrics.

Jessica Lachs (00:54:50):
Yeah.

Lenny Rachitsky (00:54:52):
So many lessons. Okay. And the first thing you said on how to pick a good metric about this idea of short-term metrics that have long-term impact. How did you phrase that again?

Jessica Lachs (00:55:02):
Yeah, so we find proxy metrics for long-term outcomes.

Lenny Rachitsky (00:55:05):
Awesome. And it's similar to the simple metric, and it all comes down to, again, just like the metric should be something probably, you can move, you can understand, that's close enough to this ideal, perfect metric, but isn't necessarily the entire ideal. Okay, awesome. Anything else along these lines of just picking metrics, working with metrics that you've learned that would be worth [inaudible 00:55:28]?

Jessica Lachs (00:55:27):
With metrics, we are often looking at the average, and I think we talked about this a little bit earlier, but making sure that you're looking at the edge cases and your fail states is also really important. And so we often will set goals actually and create metrics around those edge cases. So like the disaster deliveries, the ones that go terribly wrong. So we have this concept of Never Delivered, which is orders that are never delivered. We're really great at naming things at DoorDash, and they're very rare. And so if you were just looking at the average effect or the average consumer experience, it would never come up. If you were just measuring quality based on average values of delivery times and lateness [inaudible 00:56:18], these wouldn't show up because they are so rare, but they're terrible. They're terrible experiences for consumers. They lead to churn.

(00:56:27):
They're incredibly expensive because you're refunding an order or repurchasing food and having to send another dasher to deliver that repurchased food. So they're very expensive, they're costly from a consumer experience standpoint. And I think if you're not looking for these fail states, they are often missed. So I think when you're picking metrics, yes, you want to improve engagement and you want to improve conversion, and there's a lot of things that are averages overall that you want to move, but it's so important to find these edge cases in these fail states and actually set concrete goals around eliminating them because it can be really powerful.

Lenny Rachitsky (00:57:11):
So the tip here is actually make that a goal like, never deliver at some team, just keep cutting that down?

Jessica Lachs (00:57:17):
Exactly. So we have part of our quality analytics team and we have product engineering and ops on it as well. Their goal is to eradicate Never Delivered. And in order to do that, you have to understand why they happen. Sometimes it's human error, sometimes it's fraud. And then figure out ways that you can prevent them, that you can fix them while it's happening and ultimately just get rid of them from the system. And you're never going to completely get rid of them, but you can make a meaningful impact to make them even more rare than a fraction of a percent.

Lenny Rachitsky (00:58:00):
Yeah. And I feel like people may be hearing this and like, "Of course, why would you not focus on terrible work experiences?" But I think in most companies, they look at the big numbers, they look at the averages as you said like, "Oh, it almost never happens. Why do we even spend any time on this?" And your point is, you should actually spend time on these really terrible experiences, even if it's a tiny portion of your business. I guess maybe share why that's important. Is it just because that has trickle-down effects on the brand?

Jessica Lachs (00:58:27):
Yeah, I think it's a couple of things. So just because something doesn't happen frequently doesn't mean that it's not important. So the Never Delivered example is a great one in that this is leading directly to churn and it's also costing a lot of money far more than its frequency would suggest. And I think the fact of the matter is is when you have things that cause churn, you're losing all of that consumer's subsequent orders, and that is not necessarily observed. You're just seeing one bad experience, you're not seeing all of the lost orders because they're lost. And so I think that sometimes this is an area where the data doesn't show you the full picture. And being able to quantify the impact on engagement, on profitability, will make it stand out as something that really, that you would maybe miss if you weren't really looking for it.

(00:59:25):
And then I think the other thing is with something like login errors, sometimes you don't see it in the data because people can't even get into the data. If you're not able to log in, you're not making any purchases, you're not ordering, and so you may not see it in the data that you're looking at. And so that's also something that I think is important for data folks to think about, which is what data don't we have? What data might we be missing? Where might there be opportunities and things that we actually need to identify and fix that we may not see? Because in this case, with login failures, they're not able to log in. They're not in the denominator, and so we're missing out on them from the data set entirely.

Lenny Rachitsky (01:00:15):
Just a couple of more questions. There's one that I skipped that I'm just going to come back to. It's completely out of nowhere, but I think it might be interesting is about a global data org. So you run a global data org, you have data scientists and analysts and biz ops people all over the world, not just the US. I'm curious just how is it different managing data people in different countries versus just the US? What's a big difference?

Jessica Lachs (01:00:37):
Everyone always asks about the differences. What I am surprised by is how similar things are, how similar people are, the data scientists themselves, but also consumers and dashers and couriers, as we call them at Volt. There's a lot more similarities than differences. I do think that when you built a business in the US and then you introduce new countries, having different currencies and different languages adds complexity that you weren't necessarily familiar with. I think similarly in EU countries versus non-EU countries in Europe, there's different regulation. So that adds a fun layer of complexity. So I do think that it adds complexity to the problem set, but ultimately so many of the problems are the same. It feels a little bit like going into a test having seen the answer key. And so for me, there are problems we've encountered at Volt through Volt analytics where I'm like, "Oh, we've had a similar problem.

(01:01:49):
I have an instinct for what the answer might be. Let's still test because there could be differences cultural or otherwise, but I feel like I know where we're going to end." And then sometimes there are problems where it's new for one reason or another, and it's exciting because you're like, "All right, let's see if things are different here." Let's see what ideas might work in a Volt country that don't work in a DoorDash country and vice versa. So I think I tend to focus more on what's the same, and then I'm pleasantly surprised when I find things that are different because that keeps you on your toes and keeps things interesting.

Lenny Rachitsky (01:02:31):
I'm going to take us to AI Corner. This is a segment we have in the podcast where I try to understand how people are using AI in their day-to-day and in their business. I'm curious if you've found some really interesting way of using AI ideally in... you can go in either one of these directions, and how you or your team work day-to-day using AI tools to make you more efficient, or integrating AI into your product, making DoorDash better.

Jessica Lachs (01:02:59):
Yeah, I think that there are opportunities in both. I think one of the things I'm really excited about is actually the former. So in helping to make the team more productive, we do something called Office Hours at DoorDash, the analytics team. And it's something that we started eight years ago, and it was a way to provide support for teams that at the time we just didn't have the bandwidth to support. So we would go, in the early days, we'd go sit in a room and we'd say, "Come on in and we'll help you with anything you need help with. We'll help teach you SQL. We'll help look at some of your work. We'll be a thought partner. You could just come learn what we're working on." Whatever it was. We would do two hours every week of Office Hours at different times to be friendly to different time zones.

(01:03:52):
And I think one of the things I'm excited about is being able to really empower some of the folks that are still coming to Office Hours for one thing or another to be able to use AI to help edit queries on their own for example, to be able to say, "Here's a query. I want to make this. Please adjust this to our grocery business so that I can see the GOV for grocery." And so working to build these tools that will help not just our team in terms of time saving, and also to be honest, folks are going to use it on our team, but really to be able to empower non-technical users to be able to do things on their own and not have to take up bandwidth for the analytics team.

Lenny Rachitsky (01:04:40):
So essentially it's a chatbot that anyone in the company can talk to you to get advice on how to write SQL queries, query data and things like that?

Jessica Lachs (01:04:47):
Yeah.

Lenny Rachitsky (01:04:49):
Is there a clever name for this chatbot per chance?

Jessica Lachs (01:04:51):
So it's not clever. It's called Ask Data AI, and that's named for our internal Slack channel that used to be the open Q&A for people to ask data. So it's not at all clever.

Lenny Rachitsky (01:04:51):
But it's clear.

Jessica Lachs (01:05:07):
But again, it goes with the theme of very, very specific naming conventions that we have at DoorDash; Never Delivered and Ask Data AI.

Lenny Rachitsky (01:05:18):
I love it. Just clarity above all else. That's something I've learned from an editor that I work with. Jess, is there anything else that you want to share or leave listeners with? For folks that are trying to build their data teams, make their data teams more efficient, is there any final wisdom nugget you'd want to share?

Jessica Lachs (01:05:39):
I think the only thing that I want to reiterate is that you don't necessarily need a formal training in whatever it is you're building. And I think that also goes towards the folks that you hire onto the team. And so I mentioned earlier that we've had a lot of folks go to product or go to ops from the team. What I didn't mention is how many folks we've actually had join the analytics team from partner teams. So whether that was from engineering or from our ops team or marketing or finance, we are a net importer of talent as opposed to a net exporter of talent. And I think that that's because my own experience coming over from operations, from being a GM and making that transition into analytics, I find that I'm drawn to other folks who want to make a similar transition.

(01:06:39):
Now again, you have to have the technical skills, and most of these folks have acquired these skills on the job, whatever job they are doing at DoorDash before they transition to the analytics team, or they had maybe some formal training in school. But I love seeing the folks that make that transition and actually want to join the analytics team, even if they're not a career or data scientist. I think it creates a really unique environment where you have folks on the team from different backgrounds with different expertise who can teach each other things. So I can teach you how to build a discounted cash flow model in Excel, and I can learn how to make kick-ass slides from someone who has a background in consulting. And I can learn about common gotchas in statistics from someone who comes to us with a Master's or a PhD in statistics, and we've got our econometrics folks and we've got our economists. We just have a group of people with different backgrounds who can all teach each other how to be better. And we're not all carbon copies of each other.

Lenny Rachitsky (01:07:55):
What I'm hearing is you try to optimize almost for a lot of different complementary skills and very different backgrounds almost.

Jessica Lachs (01:08:02):
Exactly. And also people who have experience at different size companies. I think I love folks from startups who have that hustle and grit, but I also love folks who've seen what scale looks like and can help us see around corners as far as what problems we will encounter as the business is growing. And I think it is not just about a diversity of skill and a diversity of background, it's also diversity of prior company and stage. That can be really a unique way to think about structuring your team so that you get the best of both worlds.

Lenny Rachitsky (01:08:40):
Amazing. Well, just when you thought we were done, we reached our very exciting lightning round. Are you ready?

Jessica Lachs (01:08:47):
I am. Let's do it.

Lenny Rachitsky (01:08:48):
Let's do it. Okay. First question, what are two or three books that you've recommended most to other people?

Jessica Lachs (01:08:55):
I tend to read fiction, particularly historical fiction, and I love spy novels. So I think my brain is always in problem-solving mode even when reading. A recent book that I read that I enjoyed was The Rose Code by Kate Quinn, and it's about women code breakers in World War II, and I really enjoyed that. But rather than recommending a book... I guess I did just recommend a book, but rather than recommending another book, I am going to recommend the Libby app and supporting your local public library because I love the library and I love Libby, so I'll give that as my other recommendation.

Lenny Rachitsky (01:09:37):
Beautiful. Very on brand with sharing economy, company stuff. Libby. Cool. Okay, next question. Favorite recent movie or TV show?

Jessica Lachs (01:09:46):
Yeah, another one. I don't actually watch a lot of TV, definitely don't watch a lot of movies. In fact, haven't seen some of the movie greats. I get yelled at a lot by my friend. "I can't believe you haven't seen that." I tend to re-watch things, so series from the past, over and over again. I think it's just like how I shut my brain off. So I've recently re-watched The West Wing, which is one of my favorite shows of all time, probably for the 50th time.

Lenny Rachitsky (01:10:15):
Oh my God.

Jessica Lachs (01:10:16):
And Alias, which was a Jennifer Garner series from the early 2000s. Also, Spy. So I'm noticing a theme. I think I really love the spy genre. But yeah, I've watched those. They're both great, but not at all current.

Lenny Rachitsky (01:10:33):
Perfect. Perfectly acceptable. Do you have a favorite product that you recently discovered that you really love?

Jessica Lachs (01:10:39):
This is a bit of a curveball. So Korean sunscreens. So I burn really easily, so I have to wear sunscreen and I love Korean sunscreens. I was introduced to them by a friend of mine, and they're just far superior to what we have in the US. So I highly recommend people give Korean sunscreens a try, particularly there's a Beauty of Joseon on branded sunscreen. It's just amazing and is delightful to wear, which is important when you have to wear it every day.

Lenny Rachitsky (01:11:09):
I've been trying to wear more sunscreen as I age, and so this is a really good tip. Was that a brand you recommended?

Jessica Lachs (01:11:15):
Yeah. So Beauty of Joseon is the brand.

Lenny Rachitsky (01:11:15):
Beauty of Joseon.

Jessica Lachs (01:11:18):
There's another brand, Isntree, which also has a great sunscreen. But I'll be honest, almost every Korean sunscreen I've tried is great.

Lenny Rachitsky (01:11:28):
Okay. I'm Googling this as soon as we get off. Do you have a favorite life motto that you often come back to and share and or share with family and friends even more [inaudible 01:11:39]?

Jessica Lachs (01:11:40):
I do. So there's a John Steinbeck quote, which I'm not big on quotes, but I like this one, which is that, "It's a common experience that a problem difficult at night is resolved in the morning after the committee of sleep has worked on it." I find that that's something I really live by. First off, I love sleep and I try to get as much of it as possible. But the other thing is that if I'm stuck on a problem or if I am writing a response to something like a tense issue or an emotional issue, often I find that if I put down my thoughts, go to sleep, check it in the morning, I end up with a better outcome. So all of a sudden you have a new perspective and clarity on a problem you were stuck on, or you realize that you weren't clear in the way you were communicating your thoughts because you were emotional about something and you're able to put together a much better response to an e-mail or to whatever problem you're handling. So sleep can solve lots of problems.

Lenny Rachitsky (01:12:46):
I love sleep as well. I'm always telling my wife, "Let's go to sleep." Like, "Okay, I'll be there soon." I love that advice. Okay, two more questions. Who's influenced you most in your career? Is there someone that comes to mind?

Jessica Lachs (01:13:00):
So I think two answers, a multi-part answer. So I think first my career has been in male-dominated industries and I've worked with just some incredible women who've really influenced me. When I was a banker, there were two senior bankers, Vanessa Roberts and Gina Tarone at Lehman Brothers where I worked. And they were just so incredible. They were just so good at their jobs and I found that really inspiring.

(01:13:29):
And then at DoorDash, Tia Sherringham, who is our GC, and Liz Jarvis-Shean, who leads comms, are just dominant in their fields. And I think that that's really empowering and have been big influences on me to just see strong, powerful women kicking ass and that helps me believe that I can do the same. So that's one answer.

(01:13:54):
And then the other answer, sort of cliche, but my parents. My mom was a statistician at the UN before she got married, and she actually chose to stay home and raise three children, so I'm the youngest. And when I was in, I think it was elementary school, decided to go back to school, switch careers and become a nurse. And so the fact that she embarked on this completely new career in her forties after 15 years as a stay-at-home mom and my father supported this. I think that that was really, really influential and was probably the first time I saw that you can do whatever you put your mind to, no matter your age, no matter your circumstances. So that was really influential and I don't think I've ever told her that. So hi, Mom.

Lenny Rachitsky (01:14:44):
Hi Mom. Thank you, mom.

Jessica Lachs (01:14:45):
Yeah, I think that was influential for my career. Definitely.

Lenny Rachitsky (01:14:49):
That's a beautiful answer. Fun fact, I worked with Liz at Airbnb. Your person you just mentioned in the comms team.

Jessica Lachs (01:14:57):
[inaudible 01:14:57]. She is great.

Lenny Rachitsky (01:14:58):
She's amazing. Final question. So when you joined DoorDash, imagine it wasn't obvious that it was going to work. I imagine it was still like, "This was a crazy idea. Maybe it'll work, maybe not." Is there a moment you recall where you're like, "I think this is going to be a big success? I think this is actually going to work out?"

Jessica Lachs (01:15:14):
To be honest, I went into DoorDash because I wanted to learn for the experience. I thought it was interesting, problems with interesting people. I never thought too much about whether it would work. I of course wanted it to work and was very competitive and wanted to win. I think there's two moments that stand out. One was when the third party market share data showed that we had become the number one player after, I think we started at number four or five. And I think that that was really exciting to see the trajectory and to see us gain in category share. That was exciting. I probably didn't see it until months after it had happened because we don't spend a ton of time focusing on it, but I do remember somebody wanted to include the graph in some presentation, some sales material, and we're like, "Oh, we're number one. That's incredible. We used to be number five." So I'd say that that was one.

(01:16:17):
The other one that stands out was, the first talk I gave in a lot of these startup talks in the early days in Boston, and I'd asked the audience, "How many of you have used DoorDash?" And there'd be like three people who would raise their hand. And then it was a few years ago, maybe 2018, 2019, and I was giving a talk and I asked the audience, "How many of you have used DoorDash?" And almost everyone's hands went up. And that was actually pretty memorable for me because in my mind, we were still the small startup that no one had heard of where I had to over enunciate the D's in DoorDash. So people didn't think I worked for Jordash, the nineties' denim company. And so that was pretty meaningful to me when just so many people had used the product or were consumers of DoorDash. It was pretty exciting. And I still get excited. I saw DoorDash mentioned in a book recently that I was reading. It was like, "We're in the book." So those little things when you become part of the cultural lingo that I think are really, really special.

Lenny Rachitsky (01:17:33):
Well, I'm a very happy customer of DoorDash. I've never had a Never Deliver. It's always there, sometimes a little late. Usually it's perfect. Thank you for everything you do. Go team DoorDash.

(01:17:44):
Two final questions. Where can folks find you online if they want to follow stuff that you do? I know you've been doing more writing on LinkedIn and things like that, so just help people understand where to find you and how can listeners be useful to you?

Jessica Lachs (01:17:55):
Yeah, so as you mentioned, to find me LinkedIn, I don't have a huge social presence, but I am on LinkedIn and I am currently writing a series of blog posts about my experience building a global analytics org at DoorDash. Some of the lessons I've learned over the last 10 years. So definitely check those out.

(01:18:16):
And as far as your second question of how listeners can be useful to me, I guess read the post on LinkedIn and I'd love to hear what people think, whether you agree with my point of view or not. That being said, be nice. I want honest feedback, but I want kindness as well. So yeah, just engage with the content and let me know what y'all think. I think I do have a broader ask, which is just to encourage folks listening to TruthSeek, something I take seriously at DoorDash. It's a company value. But there's a lot of misinformation out there and it's often up to us as individuals to figure out what's fact and what's fiction. So I have a plea for folks to do your best, to search for the truth and speak the truth, and I think we'll all be better off for it. And of course, use DoorDash.

Lenny Rachitsky (01:19:13):
Of course.

Jessica Lachs (01:19:14):
Yes, there are three things that listeners can do.

Lenny Rachitsky (01:19:18):
You're at DoorDash.com. That was awesome. I love that last point as well in addition, to use DoorDash. Jessica, thank you so much for being here.

Jessica Lachs (01:19:27):
Thank you for having me. It was a lot of fun.

Lenny Rachitsky (01:19:29):
Same for me. Bye, everyone.

(01:19:32):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcast, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## How embracing your emotions will accelerate your career | Joe Hudson (Art of Accomplishment)
**Guest:** Joe Hudson  
**Published:** 2024-08-08  
**YouTube:** https://www.youtube.com/watch?v=DYkE1gf37ts  
**Tags:** growth, retention, okrs, roadmap, user research, iteration, experimentation, pricing, subscription, culture  

# How embracing your emotions will accelerate your career | Joe Hudson (Art of Accomplishment)

## Transcript

Joe Hudson (00:00:00):
A lot of the people in my circles may have spent hundreds of millions of dollars to try to arrange a life that they enjoy, and it doesn't fucking work.

Lenny Rachitsky (00:00:08):
What is holding people back?

Joe Hudson (00:00:09):
It's the fact that they have emotions that they are not sitting, feeling, or expressing. Whatever emotion that you're trying to avoid, you are inviting into your life in exactly the way that you're trying to avoid it.

Lenny Rachitsky (00:00:20):
What the hell? Why would... Why does this... You have this really amazing insight. The voice in your head is often telling you bullshit.

Joe Hudson (00:00:27):
What most people try to do is they try to stop it, and that doesn't work very well. I think the best way to work with the voice in the head is to pick an experiment every day and respond to the voice in the head in a new way every day. One of my favorite responses is, "Oh, I see that you're really scared. Don't worry. I'm right here with you. I got you."

Lenny Rachitsky (00:00:43):
You're really big on helping people feel joy.

Joe Hudson (00:00:45):
It's such an important tool for productivity. If you say, I'm going to figure out how to enjoy what I do 10% more and you succeed, you are 10% more efficient. Not only that, usually, the quality is going to get a lot better too.

Lenny Rachitsky (00:00:57):
Is there just one thing you recommend that basically everyone try to experiment with?

Joe Hudson (00:01:02):
Yeah, it'll change your life dramatically really quickly.

Lenny Rachitsky (00:01:09):
Today, my guest is Joe Hudson. Joe is one of the most sought-after executive coaches amongst tech leaders and has worked with folks from OpenAI, SpaceX, Apple, and other world-class companies. Joe's unique approach to coaching draws from his spiritual, psychological, and neurological practices. In his intimate courses that he runs a few times a year, and in his podcast, he helps people create the life that they want with enjoyment and ease. In our conversation, Joe shares the two things that he finds most often keep people stuck in their life and in their job, and how to work on getting these things unstuck. Why the critical voice in your head is always wrong, contradictory, and telling you bullshit, and how to build a different relationship with that voice.

(00:01:51):
Why falling in love with your emotions is so important and so powerful. Why you'd be better off focusing on what you want versus what you think you should do or think that you need to do, plus a bunch of amazing advice on how to make better decisions, help your team run more effectively, and why a seven-minute daily gratitude practice will change your life. This episode is basically for every single person. It will make your life and your work better. If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. It's the best way to avoid missing feature episodes and helps the podcast tremendously. With that, I bring you Joe Hudson. Joe, thank you so much for being here and welcome to the podcast.

Joe Hudson (00:02:34):
Oh, thanks. Good to be here.

Lenny Rachitsky (00:02:36):
It's good to have you. I'm curious if there's any common themes that emerge often in terms of what is holding people back from success or just living the life that they want, especially ambitious tech people, which I know is a lot of the folks that you work with. Are there archetypes of like, here's the thing, often come up most often and hold people back?

Joe Hudson (00:02:57):
A nonspecific answer to that would be a critical voice in their head and a relationship with that critical voice that is not productive. Oftentimes, the critical voice in the head says, "You need me to be productive," but it's usually a huge detriment to being able to really be successful. Even if you are successful with a really critical voice in your head, you never get to enjoy it. You might have the money, but then you're like, "Oh, shit, I'm still miserable." Or, "I got the car, I got the house, I got the money, I got the successful career, and why am I unhappy all the time?" That would be, I would say one of the biggest ones. Another really big one that in a large category I would say is their relationship with emotions is all fakata. They are either trying to pretend they don't have them or compartmentalizing them or trying to manage them rather than harnessing them and falling in love with them. That would be a big place.

Lenny Rachitsky (00:04:06):
This episode is brought to you by BuildBetter.ai. Back in 2020 when AI was just a toy, BuildBetter bet that it could cut down on a product team's operational BS. Fast forward to today, 23,000 product teams use purpose-built AI in BuildBetter every day. First, BuildBetter uses custom models to turn unstructured data, like product and sales calls, support tickets, internal communications, and surveys into structured insights. It's like having a dedicated data science team. Second, BuildBetter runs those structured insights into workflows, like weekly reports about customer issues, context-aware PRDs and user research documents with citations. It even turns standups into action items that automatically get assigned and shared into your tools. Plus, with unlimited seat pricing on all plans, BuildBetter ensures everyone at your company has access to this knowledge. Truly, no data silos. In a world of AI demos over-promising and under-delivering, see why BuildBetter has a 93% subscription retention, yet a personalized demo and use code LENNY for $100 credit if you sign up now at buildBetter.ai/lenny.

(00:05:19):
This episode is brought to you by WorkOS. If you're building a SaaS app, at some point your customers will start asking for enterprise features like SAML authentication and SCIM provisioning. That's where WorkOS comes in, making it fast and painless to add enterprise features to your app. Their APIs are easy to understand so that you can ship quickly and get back to building other features. Today, hundreds of companies are already powered by WorkOS, including ones you probably know, like Vercel, Webflow and Loom. WorkOS also recently acquired Warrant, the fine-grained authorization service. Warrant's product is based on a groundbreaking authorization system called Zanzibar, which was originally designed for Google to power Google Docs and YouTube.

(00:06:05):
This enables fast authorization checks at enormous scale while maintaining a flexible model that can be adapted to even the most complex use cases. If you're currently looking to build role-based access control or other enterprise features like single sign-on SCIM or user management, you should consider WorkOS. It's a drop-in replacement for Auth0 and supports up to one million monthly active users for free. Check it out at workos.com to learn more. That's workos.com. These are awesome. Okay, so the voice in your head, you have this really amazing insight that I heard on one of your podcast episodes that the voice in your head is often wrong, often contradictory, often telling you, and that your advice is to learn how to work very differently with this voice in your head, which a lot of people just assume, oh, that's just like what it is. It's telling me how it's trying to help me, but it turns out it's not. Can you talk about that?

Joe Hudson (00:07:04):
I would say every single time the voice in your head is wrong. That critical voice in your head. To be specific, I'm talking about the voice in your head that is critical and repeats. There's the voice that says the same thing over and over again. You got to work out more, you got to work out more, you got to work out more. Whatever that is, it's always wrong, and that doesn't mean there isn't truth to what it says, but it's incorrect. As an example of this, you should work out more, you should work out more, you should work out more, or you need me or you just sit around on the couch as a great example of one. If I was your boss and I was sitting right next to you and I was criticizing you every couple of minutes, there's no way that you would say, "Wow, I really need you. I couldn't be productive without you." It's a bunch of crap. Or you should work out, you should work out.

(00:07:58):
I see the truth that I'd be healthier if I work out. I get that. Should I? Is it really a should? There's another question. What makes it not say, "Oh, hey, why don't you enjoy working out? How do we get you to enjoy working out? What would motivate you to work?" It's not doing any of that. It's, "You should work out, you should work out." It's never an accurate thing that's happening inside of your head. Until you can see through that, it's hard to work with the voice in your head. You can do it, but until you see through it. The second part that I would say is that if you want to work with the voice in your head a new way, what most people try to do is they try to stop it. They try to control the voice in the head, and that doesn't work very well. Instead, I say, change the way that you relate to the negative voice in your head.

(00:08:46):
Instead of being, "Okay, stop doing that, stop doing that." Say, "Oh, I see that you're really scared and I'm right here with you." Or sing a musical to it or just go, "Eh, I don't believe you." As a matter of fact, I think the best way to work with the voice in the head is to pick an experiment every day and respond to the voice in the head in a new way every day to have an experimental approach and say, "Oh, what's the relationship I want with this negative voice in my head?" Because right now, what it's typically doing for most people is that it says something and the person's like, "Yeah." Or, "Yeah, but I'm not going to do that, so fuck off." Or, "Yeah, that'll never work." Something like that is the response. What happens if you change the response to the voice in your head? That gives you a crap ton of freedom, and it's the beginning of what can be a state where the negative voice in the head disappears, which is really, really quite lovely.

Lenny Rachitsky (00:09:43):
Oh, wow. I love this so much because there's so much that comes from this thing in your head just shooting you down or scaring you about stuff. It's so hard. I hear this, but it's so hard. Next time I'm, I don't know, giving a big presentation, I'm going to hear like, "Oh, something could go wrong. You could look really stupid or you could totally forget what you're saying." It's hard to really intellectualize, okay, I don't have to listen to this. Is there anything more there just how to turn that around and be like, just shut up?

Joe Hudson (00:10:11):
The shut up usually doesn't work. Experiment with all of it. To me, one of my favorite responses is, "Oh, I see that you're really scared. Don't worry. I'm right here with you. I got you." Because part of the deal is that the voice in the head has assumed the position that it's like the boss, but it's really a little kid having a temper tantrum. If you listen to it, if you just dictated everything it said, it sounds like usually like a five-year-old having a temper tantrum, or it sounds like the way your mom used to chastise you or the way your dad used to chastise you or whatever, a teacher. It isn't, it's not logical, it's not thoughtful, it's typically not thoughtful, it's usually abusive. It's a lot of fear. It's one of my favorites, one of my favorite ways to respond.

(00:11:06):
I've tried, I mean, gosh, dozens of ways, and there's a lot of neat effective ways. I particularly think it's really good to set up a series of experiments rather than just take the one that I have because the experimental mindset means that you can never really fail. Typically, somebody, like worse with the voice in the head, they fail and they go, "Ah, fuck it." Because we have this part of our brain called the habenula, and the habenula basically is the part of our brain that is trying to teach us not to fail over and over again. It's the thing that when you go on a diet or you go to work out and then you don't do it one day and you say, "Ah, fuck it, I messed up," and then you don't try anymore or you don't try for a couple of weeks or whatever, that's basically what's happening in that part of the brain.

(00:11:48):
If you do it as an experimental thing, then you can't lose, you're just learning about yourself. You're learning about the voice in your head. The way I like thinking about that is people are like, "I understand the problem, but I don't have a solution." I'm always like, "If you understood the problem, there would be no question about the solution." If you fully understand the problem, you know the solution. All you have to do is really fully understand the voice in your head through a series of experiments and the whole thing goes away.

Lenny Rachitsky (00:12:16):
The advice here is next time you're hearing something in your head that you don't think is going to be helpful to you is try to respond to it in a different way from what you've been doing.

Joe Hudson (00:12:25):
I would be even more subtle than that, which is I really wouldn't care if you think it's helpful to you or not. I would just experiment with different ways of interacting with it. I wouldn't even do it as a goal of, okay, I want the voice in the head to be nicer to me. I would do it with the goal of just, hey, how do I learn? How do I understand this thing? It's a far more productive self-development. Generally, it's far more productive to learn, say about the river valley by walking through it, putting your feet in the river, going down the river with a canoe, smelling the soil, looking at the plants, than it is to say, "Okay, I am going to dam this river valley and try to..." You're not going to understand it the same way. You're going to make some mistakes.

Lenny Rachitsky (00:13:18):
Amazing. The second bucket that you shared of what you find most often is the root of what's holding people back is the way you described is your relationship with your emotions, which I don't think a lot of people would think of as the thing that's holding them back. Can you talk a bit more about what that looks like?

Joe Hudson (00:13:31):
Yeah, a great way to explain it. For the logical folks, so in 2012 or so, there was a person who wrote a book called Descartes' Error, and in Descartes' Error, the whole idea is that I think therefore I am, and this person's like, "Yeah, that's the error." It's a neuroscientist who looked at people who had damage in the emotional center of their brain, and they just basically ceased to be able to make decisions. Their IQ would stay the same, but it would take them half an hour to decide where to have lunch or decide what color pen to use. It would take hours and hours to make simple decisions, so their IQ would stay high, but their entire life would completely fall apart. What it tells us, and this is not exact, I'm paraphrasing for a podcast, but we make decisions in the emotional center of our brain. We use logic to try to figure out how we're going to feel.

(00:14:23):
You can see this just by asking yourself the question, how many decisions have you made to feel like a success or to not feel like a failure or to feel happier, to not feel trapped? There's these huge buckets of emotions that we are trying to feel and not feel, and we're making decisions based on those. There's no such thing as a logical decision. That idea is like, I'm just going to be logical and just make a logical decision, it doesn't. Neurologically, it's just untrue. If you learn to fall in love with all of your emotions, then solution sets become available that you didn't have before. If you are like, "Oh, I can't feel like a failure." Well, then you're probably not going to take certain risks. If you are, "Oh, I want to feel loved and I can't feel unliked by people." Well, then you're not going to say your truth, and then the world is going to not give you the things that are truthful to you.

(00:15:20):
I go into my boss, I say my truth, I get fired. Okay, I get fired, but then probably my next boss, I say my truth, I'm going to find a location where my truth is and how I want to be in the world is going to be acceptable. If I don't do that, if I'm constantly managing myself, then I'm not going to have that reality. It's really important, just for the decision-making part, how important emotions are to be able to fall in love with each of the emotional experiences so you're not making decisions based on your inability to feel stuff. That's like one, there's literally a thousand others. Most people, they feel stuck. They can have a big emotional release and they don't feel stuck anymore. When people feel overwhelmed, it's usually not the amount of crap that they have going on in their life. It's the fact that they have emotions that they are not sitting, feeling or expressing. That's another huge chunk of stuff.

(00:16:11):
Depression is usually unmoved anger, is another example. There's so many levels in which people not able to feel really limits their life. Just one that's like almost everybody can relate to is feeling excitement is something that most people can only do for about 10 to 20 seconds. Most people aren't like, "Oh, I'm excited." If you walked into a Denny's and there was this person, a 60-year-old man and just excited and was excited for 10 minutes, you'd be like, "What's wrong with this person?" When we're excited, it's contagious. I walk into a meeting and I'm excited, probably other people are going to walk out excited. We're limiting just our ability to create collaboration by the fact that we're limited by our excitement. I could go on forever. There's so many experiences like this.

Lenny Rachitsky (00:17:06):
What I'm hearing is the core issues, we're not able to feel our emotion, but there's something there, like we are angry or scared. Because we can't feel it, we just can't break through that.

Joe Hudson (00:17:17):
Not quite. If you have somebody who's experienced a lot of emotional abuse in their life, then they might not be able to feel the emotions that they're having, and particularly where you experienced the emotional abuse. That might be the case for them. For instance, if you had physical abuse and I put a quarter in one of your hands and a key in another one of your hands without telling you which was which, you wouldn't be able to tell me if you'd suffered enough physical abuse because you've literally cut that sensation off. Similarly, people who've experienced emotional abuse can often not tell what the emotions are. Now, emotional abuse is, it's a big word. Generally, people don't even like equating the two. Just to agree on terms here, when I say emotional abuse, I mean you were told that you weren't allowed to have a certain emotion. That's what I mean by emotional abuse.

(00:18:08):
Maybe you got fed every time you got angry or you got your love removed, or you got punished, or maybe every time you cried, you were made fun of. My particular background was that. It's when you weren't allowed to feel certain emotions, you were told to cut it off because it wasn't going to be safe because you're either going to get bribed out of it or punished out of it, or loved removed because of it or made fun of or whatever it is. That might be a step that one has to take, but the place you want to get to is where the emotions are fluid, where it just moves right through you. It doesn't mean that you lose control. As a matter of fact, losing control means that there's still resistance in it.

(00:18:53):
The way I think about this is that emotions are like a tube, let's say, and there's water moving through the tube. You kink a tube one way, the water comes out a little funny. Kink the tube the other way, it comes a little funny. Let's say you have anger and that's the tube of, and you kink it one way and it's like, "You son of a bitch. You blah, blah, blah, blah, blah." You kink get another way and it's like, "Nice dress. You crank it another way and it's guilt. It's like, "Why would you ever do that to me?" Then if it's unkinked, then it's like Gandhi or Martin Luther king. It's this very loving boundary that's set. It's this clarity of purpose. That's how I think about it. The idea is to get to fluidity, to unkink the hose so that all of the emotional experiences come out with love.

Lenny Rachitsky (00:19:44):
I did a meditation retreat, a 10-day silent meditation retreat, which I know is a big part of your practice and something that led to the work you do now. A term that's coming up for me is non-judgmental awareness. Basically, experiencing the thing you're feeling and just letting it go, not attaching to it, not judging it. Is that along the lines of stuff you'd recommend?

Joe Hudson (00:20:03):
Yeah, it's definitely a huge part of it. There's a couple of things that I noticed get in the way, or the translation gets in the way there. One is it's like, think about emotions as like kids in your house. If a kid came into your house and you're like, "I will be non-judgmentally aware of you." You're probably going to get a very different response from the kid than if you're like, "Oh, I'm so excited to see you. I welcome you in my house." The emotions feel different if you're like, "I am non-judgmentally aware of this emotion," or, "Oh, cool. Oh cool, I'm sad. This is fantastic." If you have that welcoming invitation. One of the quotes that I'm most famous for is joy is the matriarch of a family of emotions and she won't come into a house where her children aren't welcome. A very joyful life is a life where all the other emotions are deeply welcomed, not accepted, not non-judgmentally aware of. I think those are really great steps, don't get me wrong. If you can be in non-judgmental awareness of an emotion, fantastic.

(00:21:14):
The other thing that's a little bit different about what you said is that emotions do need to be felt. If you stop feeling an emotion, you have to constrict your muscles. I can watch somebody come in, come up for one of my coaching rapid coaching sessions. By the crease in their eyebrow, I can know that there's repressed anger. By the hunch in their shoulders, I can tell you about the critical parent that they had. The body takes on a shape that's based on the emotions that you've been taught to hold. You don't just by sitting there, well, it's not entirely true, if you just sit there and feel them in that way without the full expression, they will move eventually, but it might take a couple of decades. You can actually just move them. You can actually make the sound, move your body. All mammals do it. Like mammals releasing fear, they all shake. It's part of how we exist. That's also a really big part of emotional fluidity. It's not just being still and feeling them, it's letting the muscles move, making the sounds.

Lenny Rachitsky (00:22:22):
For someone that wants to get better at the skill of feeling emotions, being more in touch with emotions, helping their emotions be more fluid. I know this is a lifelong practice and not something you would just hear on a podcast, okay, I've installed this. Is there anything tactically you can recommend to a listener of just like, here's something you could do this week that'll help you, along these lines?

Joe Hudson (00:22:40):
We have a free audio on our website called Emotional Inquiry, and that would be the easiest way that I would, that's a really good entry level first step into emotional fluidity. The bigger problem is that every step has a different thing. If you're in the not aware of emotions, then that step may not be the right step for you. Though, if you are aware two or three emotions and you can do emotional inquiry, usually, it'll open up a lot of the other ones. There might be a point where you really need expression, and so emotional inquiry is not going to work. Just generally, the emotional inquiry practice is a really good one. What it is, is imagine you're a little kid and you pick up a toad.

(00:23:28):
You're going to pick it up, you're going to look at it, you're going to feel it, you're going to smell it. Some little kids are even going to lick it a little bit. They're going to really want to explore this toad, and that's what emotional inquiry is, is a somatic mental experiencing of an emotional experience in your body and what is it like and what happens when you welcome it. What happens when you love it. What happens when you resist it. It's a series of experiments that you're playing with the emotion and observations and felt sense of the emotion, and that I find to be incredibly, incredibly useful for people.

Lenny Rachitsky (00:24:05):
Just getting very curious.

Joe Hudson (00:24:06):
Yeah, a lot of wonder.

Lenny Rachitsky (00:24:09):
By the way, the quote you shared about joy being the matriarchy of all the other emotions, imagine people have said this, but inside out too, I think is exactly a representation of what you're talking about, where joy is actually, she's like the protagonist almost. I don't know if you've seen it yet.

Joe Hudson (00:24:25):
I think I've heard about this. I haven't watched it, but I think where you think it's all about being happy and you find out that you have to accept everything for happiness to really work, kind of.

Lenny Rachitsky (00:24:34):
Exactly.

Joe Hudson (00:24:35):
Yeah, I have heard about it.

Lenny Rachitsky (00:24:36):
Anxiety takes over, and then things don't go well. Something else that I've noticed listening to a bunch of your conversations, you do these lightning round coaching sessions with people, and so I listen to a bunch of them. Something that was really interesting to me is that a lot of people come to you and they're like, "Hey, I have this problem. I can't do this hard thing I know I need to do." Or, "I have imposter syndrome just keeping me from doing this thing I need to do." you're often like, "No, that's not actually what's going on here. I can see that's not a problem for you. It's really this other thing." Is that super common where people think they need to work on this one thing, and it turns out that's not at all, they're actually okay at that and something totally else?

Joe Hudson (00:25:13):
I'd maybe put it a little bit differently. They're living in a story that describes an old version of themselves or they don't see themselves clearly enough to be able to see the whole issue, and so they're just kind of living with a story that's in the past. That's a really common thing. Oftentimes, if I do that in a coaching session, typically it's because they're showing me right there that it's not true. Somebody's like, "I'm so scared, I can't do anything." I'm like, "You just got in front of a hundred people to ask me a question. Clearly, you're not so scared that you can't do anything, so I'm not buying it." I don't do it quite like that, I do it with a lot more love than that.

(00:25:54):
Oftentimes, I see that people's stories are a culprit, like how they describe themselves. A great way that you can really see this in folks is that nine out of 10 times that you compliment somebody, I really appreciate this thing about you, they're going to go, "Nah." Or, "Well, my sister is even more." Or, "If you knew me." They're going to do some sort of version like that. It basically is one of the indicators that they can't actually feel who they are. They would rather, in effect, call you a liar. You're lying to me or you're wrong than they would to actually accept the experience of being seen in that way. It does a couple of things. One of the things it does is it stops people from seeing themselves clearly. The other thing it does is it makes people forever want to be seen and complimented and acknowledged and validated because they're getting the food, but they can't digest it.

Lenny Rachitsky (00:26:59):
Do you have any advice other than working with you and you telling them, "Hey, here's actually going on," for someone to like, okay, maybe revisit, maybe this isn't actually a problem to see what's actually going on?

Joe Hudson (00:27:09):
We have a set of five kind of what we think are foundational tools for transformation, and we do these free workshops on them, and one of them is question the assumption. That's a really great way to have people start to see through their stories. At the beginning, I said, "Nothing in the critical voice in your head says is true." This is how it applies, so typically, there's an assumption that you have to make for the problem to be real. If somebody says to you, for instance, if somebody comes to me and says, "I am an asshole to my girlfriend." That's their problem. One, you have to assume that the girlfriend doesn't want you to be an asshole, as an example. Two, you have to assume that you know what being an asshole actually is. It's not just what your mom told you an asshole was.

(00:28:04):
Three, there's some validation, there's another assumption, there's some clear thing that says this in the world. Everyone's like, that's an asshole and that's not, rather than what actually happens in the world, which is 50% of the people think that this person is an asshole and 50% think they're a hero. It's something like that. Also, another assumption there is that the problem is that you're an asshole, instead of that you're resisting the fact that you are an asshole, and therefore, it comes out sideways instead of really clear. There's so many assumptions in there. If you see through those assumptions, usually the problem starts fading away.

(00:28:40):
It's like, "Oh, okay, what do I mean by asshole, exactly? How do I define that?" It seems like a silly thing when I am using this example of asshole. I remember this moment in my own development, I was in Bodega Bay, out of all places, and this very good friend of mine at the time was like, "Joe, you're an asshole." I was like, "No, I'm not." He's like, "Why resist it? Just fall in love with the fact that you're an asshole. Just allow yourself to be an asshole for just a minute, just one minute." I stopped, and I thought of like, I was doing venture capital at the time, and I could think of all the things that I had done that somebody would call an asshole, and all the ways in which I was unattuned to people, and I could, "Oh, yeah, okay, I can totally see that I'm an asshole."

(00:29:32):
In that scene, not only in the scene of it, but as the shame fell away, oh, this is nothing I have to defend. This isn't something that I'm a bad person because of, I don't need to be ashamed of it. This is just some actions that I took. As that faded away, then and then over the next couple weeks, lo and behold, I became less of an asshole. It's a strange thing when you really grok that, that it's often shame that holds bad habits in place. Is it a problem that I'm an asshole, or is the problem that I'm ashamed of being an asshole? Is the problem that you're a smoker, is the problem that you're ashamed of being a smoker? Typically, there's so many assumptions built into everything that we call a problem, and if we look through those assumptions, the problems disappear. As in this case, it disappeared for me.

Lenny Rachitsky (00:30:25):
Wow, okay. There's a lot there. It connects to something I know you recently talked about, which is the emotion we want to avoid is the thing we end up experiencing a lot by trying to avoid it. What's going on there?

Joe Hudson (00:30:46):
Since I'm coach executives, let's do an executive example, so conflict avoidant executive. I don't want to feel the out of control in this that I do when people argue. I don't want to feel that level of out of control, so I am going to be conflict avoidant. I'm going to avoid conflict. Every way that we go to avoid a feeling, becomes the way that, that feeling gets invited towards us. We all know what it's like to work for a conflict-avoidant CEO or a boss, people get really fucking upset. Eventually, people get really upset. Decisions aren't being made. There's all this tension. It's never relieved.

(00:31:30):
Then wow, sure enough, the conflict-avoidant CEO is dealing with a whole organization that's tense and they feel completely out of control and the fact that they can't do anything about, so that's an example. Or when I was younger, it was emotional abandonment. My dad was an alcoholic, and I didn't want to feel that emotional abandonment again, and so I would get really hard when I felt like people were leaving me, I'd be like, "What the dah, dah, dah, dah, dah?" Which of course, made them abandon me quicker, or I would try to caretaker people, which would build resentment, which would make people abandon me. Whatever emotion that you're trying to avoid, you are inviting into your life in exactly the way that you're trying to avoid it.

Lenny Rachitsky (00:32:14):
What the hell? Why does this happen?

Joe Hudson (00:32:14):
That doesn't sound right.

Lenny Rachitsky (00:32:14):
This is counterproductive.

Joe Hudson (00:32:20):
It is counterproductive. I think that the really cool thing about it is you can look at any issue that you're having in your life, so you can say, oh, one of the problems that I have in my life is that I am constantly in an argument with my girlfriend or boyfriend, let's say. What is the thing that you don't want to feel in that argument? I don't want to feel ashamed. You're getting in arguments because you don't want to feel ashamed, and that's making you feel more ashamed. What am I doing at that first time to not feel ashamed? I'm defending myself. Oh, and me defending myself is actually the thing that's starting the fight. You can backward engineer it to, oh, I don't want to feel ashamed, therefore I'm going to defend myself, which creates the fight, which makes me feel more ashamed.

(00:33:10):
Any problem that you're having, you can actually backwards engineer it and see, oh, I can solve that problem by just being okay with that feeling. God damn it, you didn't take out the trash. Oh, that's a shame I don't want to feel. I'm not going to defend myself. I'm going to feel that shame. Oh, yeah, then maybe I'm going to say I'm sorry I didn't take out the trash, or I'm going to say, I don't feel ashamed, I don't want to take out the trash. I have to defend myself to get in the fight, and then I'm going to feel ashamed. You can reverse engineer all your problems this way. It's like it's such a cool hack, but it's very hard. For somehow or another, it's very simple, but very hard for people to utilize.

Lenny Rachitsky (00:33:53):
This is amazing. The advice is basically feel the thing and just come to terms with this is the emotion I'm feeling, and maybe, like an example, the asshole. Well, maybe I'm an asshole.

Joe Hudson (00:34:03):
It's what's required for you to love and accept yourself would be, and love and accept the emotion that you're having in the moment instead of resist it. There's that saying, what we resist persists. How do you fall in love with and stop resisting the reality on the ground? In doing so, it changes the reality on the ground.

Lenny Rachitsky (00:34:30):
In this argument with your supposed girlfriend, say you disagree about her perspective on what's going on. I guess that's not the root issue here. It's your feeling, it's not her perception.

Joe Hudson (00:34:41):
Hey, sweetheart, I really hear you want me to take out the trash, and that's not my truth. That's going to be very different than defending that shame. The defending the shame is going to be like, no, it's not my job to take out the chat. You're trying not to feel the experience, which is what's going to do it. The response isn't the important thing. It's really where the response comes from. It's so interesting because people are taught constantly, this is something we teach in the connection courses that it's really not about the conversation, it's about where you're at in the conversation. For instance, when my friend said to me, "Hey, you're a dick." Here's what he didn't do, he's like, he didn't go, "You're a dick. You asshole. You're being an asshole. You're being a dick. Fucking stop it." He was like, "Eh, you're a dick, so what? What's the problem?" He was coming from a place of love for me, and so I could not be defended in my response to him. It's really where you come from.

(00:35:49):
It's the emotionally where you come from, that's the important part. Not as much what you say. You can see this, a perfect example of this is, this happens all the time in my work. Let's say there's a person who has a CEO and the person is scared of their CEO. Let's say this is the CMO, and they're, "I'm scared of the CEO. I can't say my truth. They're always getting upset. They're going to yell, blah, blah, blah, blah, blah, blah, blah, blah." I'll say, yeah, there's one person who says it though. The answer is always yes. That CEO has one person who they don't yell at, who they listen to, who they'll take the objection from, that they don't get angry with. It's because there's somebody who doesn't approach them in fear. It's because somebody approaches them a different way. Not with judgment, but like, "Hey, look, this is what we have to pay attention to." It's really about how you're coming at it and not what you're saying typically.

Lenny Rachitsky (00:36:52):
This episode is brought to you by Coda. I use Coda every day to coordinate my podcasting and newsletter workflows. From collecting questions for guests to storing all my research to managing my newsletter content calendar, Coda is my go-to app and has been for years. Coda combines the best of documents, spreadsheets, and apps to help me get more done, and Coda can help your team to stay aligned and ship faster by managing your planning cycle in just one location, set and measure OKRs with full visibility across teams and stakeholders, map dependencies, create progress visualizations, and identify risk areas.

(00:37:27):
You can also access hundreds of pressure-tested templates for everything from roadmap strategy to final decision-making frameworks. See for yourself why companies like DoorDash, Figma, and Qualtrics run on Coda. Take advantage of this special limited time offer just for startups. Head over to coda.io/lenny and sign up to get six free months of the team plan. That's coda.io/lenny to sign up and get six months of the team plan. Coda.io/lenny. This is amazing, Joe. I'm very happy with what advice we've already shared and there's more I want to tap into.

Joe Hudson (00:38:04):
You keep using the word advice, and I just want to, so for anybody who's listening, do not take my advice. Do not, do not, do not. Test it. Experiment. Set up an experiment, try it out. See if it's true for you. It's one, I just made this shit up. Somebody else could make up something different. It's like Jeff Bezos made up Amazon. We make stuff up, but we're humans. Two, is if you instead of just listen to it as a soundbite, if you actually do it and make an experiment out of it, you get to learn. It's in your bones. You get to see what's actually real for you. What's real for you in this moment might not be real for you what's in the next moment. For instance, I could give the advice that says, hey, you can't even control your thoughts.

(00:38:55):
You can't even decide what thought you are going to have next is, it's just going to fucking happen. you're completely out of control, and so it's all a gift. Can you look at life as all a gift? Wow, that could be really useful for one person, but the other person, they feel so disempowered that they're like, "I can't even control my own thoughts. Man, I am totally trapped." They might really need at that moment to learn that, "Oh, I have empowerment, I have choice." That's the advice that they need to hear. Do the experiment, find out what's true for you in this moment. If there's a piece of advice, that's the one I want to give.

Lenny Rachitsky (00:39:40):
let's share more experiments people can run. Another is this thread that I feel comes up a lot in your work is you're just really big on helping people feel joy. Feels like that's the core of what you're trying to help people is feel more joy. Why is that so important? Why is joy so important, so powerful?

Joe Hudson (00:39:57):
I definitely would not want anyone to feel joy. I wouldn't want to push somebody into or like, "Hey, you should feel joy." What I would say that's a close cousin to that is that enjoyment is such an important tool for productivity. Enjoyment is such an important tool for living a meaningful life. Enjoyment is an amazing tool. As an example, let's say you drive a Ferrari, you're not going to say, hey, that's an efficient car. That's a super-efficient car. You're going to say, no, that's a fast car. Somehow in our own lives, if we get something done quickly, we're efficient, but that's not efficient. You can go and get something done quickly and then you're so exhausted. What's efficient is if at the end of whatever you did, you feel like you have more energy, like you're stoked, like, oh, I can't wait to do this again tomorrow. That's efficiency, is that you've actually used the least amount of energy to get something done. If you say, oh, I'm going to figure out how to enjoy what I do 10% more and you succeed, you are 10% more efficient.

(00:41:13):
Not only that, usually, the quality is going to get a lot better too. If you enjoy running, you're probably going to run more than if you don't enjoy running. If you enjoy doing a podcast, you're probably going to make a better podcast and you're going to do it for longer if you enjoy doing it. There's something really, really important about enjoyment because it's not only a measure of efficiency, it also has a strong correlation with hire in most things has a strong correlation with how long you're going to do it, your staying power, the quality of what you're going to do, all of that. That's one of the reasons that I think enjoyment is really great. The other thing is that if you enjoy things, they feel different. I think one of the things that people do is they say this, they say, "I want to enjoy my life more, so I'm going to do less things, take out the trash, and I'm going to do more things like go on vacation."

(00:42:14):
That's not how enjoyment works. You can enjoy taking out the trash or you can hate taking out the trash. That's a choice. Right now, somebody listening to this as an experiment that they can run is like, okay, you're going to stay listening to this for the next minute. How do you enjoy it 10% more? Typically, what will happen is somebody will take a deeper breath, they'll settle into their body a little bit more, they'll relax a little bit more. They might physically get more comfortable. There's a thousand things that they might do to just enjoy the experience 10% more. That, and in that, they're becoming more efficient in that the quality is getting better in that they're hearing what I'm saying differently. It's just a really powerful tool. What I know the problem to be is that some people will go, "Okay, now I have to enjoy life. I'm going to disregard all these negative emotions so that I'm in enjoyment." That doesn't work. It's horrendous. It's just a recipe for shit stew.

Lenny Rachitsky (00:43:18):
Along these lines, how much of the work is learning to enjoy the thing you're doing more versus finding something that you innately enjoy? Which one is more powerful? I guess, which do you point people to? Which experiments do you find people should run more?

Joe Hudson (00:43:31):
In our society, typically, it's how to enjoy what you're doing more. What happens typically is that if you find a way to enjoy the thing that you're doing more, you're more likely to do the things that you enjoy. It's just an order of operations thing. As compared to there's people, a lot of the people in my circles because of who I coach and everything, they're billionaires and they have spent hundreds of millions of dollars to try to arrange life that they enjoy and it doesn't fucking work. They actually have more power to make everything that they're doing exactly what they want to do, but that doesn't work. Flying the jet or buying the island or blah, blah, blah, blah, blah, doesn't do it.

(00:44:25):
Whereas if you really learn to enjoy what's in front of you, all of a sudden, one thing that happens is that you're not as scared of enjoyment. You start saying, "Oh, wow, enjoyment makes me really effective, and so I'm want to do the things that I enjoy." You're more likely to do the things that you enjoy. Instead of having this story, I have to do X, Y, and Z so that at one point in the future, I can do what I enjoy. It's just an order of operations things. If you learn to enjoy the things that you're doing, you're going to naturally start doing the things you enjoy. If you only do the things you enjoy, you will not learn how to enjoy what you're doing very well.

Lenny Rachitsky (00:45:03):
You show this tip of how can I enjoy this 10% more? Just ask yourself, how can I enjoy this 10% more?

Joe Hudson (00:45:09):
Yes, right now.

Lenny Rachitsky (00:45:10):
Is there anything else that you find helpful for helping? Yeah, right now, how can I enjoy this 10% right now?

Joe Hudson (00:45:14):
That's right. It's not about changing anything in the external world.

Lenny Rachitsky (00:45:19):
Got it. Internally, what can I do? What can I change about the way I'm experiencing this?

Joe Hudson (00:45:23):
Yeah. I like to ask it as how do you enjoy it 10% more, because if it's what can I change, then there's trying, trying is usually not more enjoyment. It's actually usually letting go of trying that creates more enjoyment. The phrasing can really make or break the question.

Lenny Rachitsky (00:45:41):
Enjoy it 10% more. Say someone's sitting in a boring meeting that's really sucking their soul, look, they should ask themselves this question, how can I enjoy this 10% more?

Joe Hudson (00:45:51):
Well, should, they can. They get to, it's a great experiment.

Lenny Rachitsky (00:45:54):
It's an experiment. Okay, perfect.

Joe Hudson (00:45:58):
The reason I do the should thing is that as soon as you say you should and then you don't then you can fail. If you fail, then you're less likely to try it again. That's why the should, it ends up usually in stagnation. If you think about the way it feels in your body when you say, I should do something, and there's a stagnation, there's a, hmm. whereas if you say something like, oh, I want to do it, or here's an experiment I can do, or here's what I enjoy, there's less stagnation, there's more movement.

Lenny Rachitsky (00:46:31):
This touches on something else that you talk a lot about, and we've been circling around this idea of authenticity versus improvement, where you help people realize that you are good as you are, you don't need to necessarily improve. We've talked a lot about these sorts of things already, but just what else can you share there just how to help people learn this?

Joe Hudson (00:46:49):
My favorite metaphor on this one is at what time in the journey of an oak tree is it perfect? Is it when it's an acorn, when it's sprout, when it's 20 years old, 40 years old, 150 years old, 200 years old, depending on the oak tree? Now, I'm perfect. The idea is ridiculous. It's a similar thing for us. The idea that I need to improve myself, it really disturbs the natural process that's at hand, which is we evolve. We as human beings evolve. If it's like, oh, I'm evolving and I can enjoy it, and I'm acting from my authenticity, then that has a lot of alacrity. That moves quick. If it's I need to improve, there's something wrong with me, I need to improve, I should do it, that all goes really fucking slow. Because there's a lot of emotional stagnation in that.

(00:47:55):
There's a lot of should shame. There's a lot of stagnation in that, and so you don't actually get that natural flow of life. The Taoist talk about this as kind of like a river always finds its way, it just always goes in that direction. We are naturally evolving. That is our nature. Then to put a whole bunch of shoulds and shits in the way just slows the process down. The other thing about authenticity that I think is really important too, is that if you are one of the few people, I'd say 10, 15%, who can say, I should be this way, this way, and this way, and then you do it, which is very few people can actually do that. What most people do is they say, I should do this, should do that, should do that, and then a decade later, they're still saying they should do the same things. Let's say you're one of those really successful people, then you have a life for not you. Then you have a life of who you think you should be, not for who you actually are.

(00:49:02):
If you move from authenticity, naturally, certain things aren't going to work, certain things are going to work. Certain people are going to work, certain people aren't going to work. Certain jobs are going to work. The ones that you end up with over time are going to be the ones that are right for you, not right, for who you think you should be. The most obvious of this is you meet a woman and you're like, oh, this is how I should be for them to love me, and you just do it. You just do everything that you think you should do, and then you get married, and then they love not you, they love who you think you should be. They don't love who you are. What kind of marriage is that? As opposed to, this is who I am and I'm going to be as genuine. I'm going to show you all my parts. I'm going to be as genuine as I can with you. Then if you do get married, you're married to the right person, you're married to the person who actually sees all that and loves that and wants that.

Lenny Rachitsky (00:50:01):
How do you hold that idea with I also want to get better, I want to develop myself, I want to feel my emotions more, those sorts of things?

Joe Hudson (00:50:10):
I love that I want to, the better part is kind of just, gets a little bit in the way. We all want to, like a little kid wants to run faster. They might want to be a better runner, but the part that they missed, the reason that they develop so fucking quickly is because they don't think they're going to be a better person if they run faster. The idea is like, yeah, you have this natural want, that want is the thing that moves evolution. A plant is like, "Oh, there's sun. I want to move in that direction." As compared to I should. Both of them are human concepts, but the want, it's the thing that what allows us to know that's our evolutionary path. Oh, I have this want to be closer to people. Oh, I have this want for great sex. Oh, I have this want for being able to have a business that supports me.

(00:51:07):
These are great wants, and they show where the growth is occurring or wants to occur. It's like that's our natural evolution. It's great. What makes it need to be better? I want to be better. It just slows it down instead of, it's like saying that what I am is broken and therefore, the whole thing slows down. We try to word everything as more in the experimental framework, but also, we try to word everything as self-awareness, self-experimentation, self-discovery, instead of self-improvement. Because if you understand the problem, then the problem goes away. Just explore it. Just understand it as compared to making a list of things that you should do to get better, that you will eventually fail and then you'll just be stuck in this should loop where you beat yourself up and where most people hang out a lot.

Lenny Rachitsky (00:52:10):
The experiment here that I'm taking away is think more about your want versus the should, and then things you think you need is okay.

Joe Hudson (00:52:20):
Because typically, when you say, I want to improve, it means the subtext in that is once I do X, Y, and Z, then I'm lovable. Once I do X, Y and Z, then I'm okay. Once I do X, Y and Z, I'll be worthy. Once I do X, Y and Z, I'll be enlightened, whatever the fuck, the thing is. That's just not how it works. What works is the person who loves themselves has loving relationships. It's not the person who's done X, Y, and Z so that they can be lovable, has loving relationships. The people who do X, Y and Z, so they can be lovable have relationships where people are critical and constantly telling them that they have to be better.

Lenny Rachitsky (00:53:01):
Coming back, you just said this interesting quote that you also shared at the beginning. This idea, once we understand the problem, it goes away.

Joe Hudson (00:53:06):
Yeah.

Lenny Rachitsky (00:53:07):
Let's make sure people understand what that means. Is it related to this idea once you feel like I'm an asshole, okay, and then like, oh, okay, and then it starts to kind of away, is that the core?

Joe Hudson (00:53:15):
I just mean practically. It's like, can you really fully understand a problem if you don't understand the solution to it? There's a principle, and I can't remember the name of it, like it's Strickland principle or something. It's something that this CFO that I used to work with said, and he would say, "Problems get solved if you spend time on them. If you just give enough attention to a problem, the problem will solve." That's the way it works in business. An unsolvable problem, obviously, it's not going to work that way. The reason that, that works is because the more you spend time on a problem, the more you understand it.

(00:53:58):
Another one, love him or hate him, one of the things that Elon Musk has said that I found it very valuable in my time, is that if you really want to interview somebody and they claim that they've done something, you ask them six levels down. You improved sales. How did you do that, exactly? Well, we improved the pipeline. How'd you do that, exactly? Oh, well, we made the pipeline more measurable by having things that could be. How did you know? What were the seven stages of the pipeline and what made you pick them? You go six levels down and you can really understand if somebody was the person who solved the problem or if they're the person who is claiming that they solved the problem. It's the same thing.

(00:54:47):
If we just explore a problem enough, the solution is apparent. If we understand the problem enough, the solution is apparent. Typically, if we come to a problem with a kid's mind, wonder, if we come to it, what could I learn here? What's exciting? What are the experiments I can run? Then typically, that's the most efficient way, enjoyable way to solve a problem as compared to, I have to get to this problem by this time and we're going to do it this way. Usually, that doesn't work. I could geek out on why that lets democracies win over autocracies because they're far more experimental by nature, and it's not one person saying how things are going, but just generally, just we're more efficient when we're exploring. We're more efficient when we're exploring ourselves and understanding ourselves and trying to improve ourselves.

Lenny Rachitsky (00:55:46):
There's a couple of more experiments I want to help people try to run. One is you have some really good advice around decision-making and how emotions and getting better at understanding and working with your emotions helps you make better decisions. Can you talk about that?

Joe Hudson (00:55:59):
That's similar to what I said before, which is if you learn to fall in love with the emotional experiences, then you have more solution sets. Let's say I want to have all human beings, I want to be a part of a great team. Nobody has ever raised their hand and said, "I'd like to be a part of a team." Yet, grand majority of people at their work right now have shitty teams or not A teams, not great teams, even though nobody wants that. If one of the things you're unwilling to feel is that conflict, that tension, as we talked about if you're conflict avoidant, you're not going to be able to make an A team because there's nothing that is alive doesn't require tension. A cell requires tension. Breathing requires tension. Playing pickleball requires tension. A good team requires tension. If you're going to avoid that experience, you're not going to be as easily, if at all, be able to create a quality team.

(00:57:05):
To be able to look forward to any emotional experience, creates more and more solution sets for more and more optionality. In creating a great team, for instance, you need to be good with people hating you. You need to be good with drawing boundaries and having people upset. You need to be able to have high expectations. You have to be okay with somebody being disappointed with themselves. You have to be okay being disappointed with yourself. All these emotional experiences have to be available to you if you're going to find the solutions to make an A quality team. The more you can fall in love with each emotional experience, the more you have and then the clearer the decision making gets. That's one thing for making great decisions. The other one that I find really, really useful and very hard to execute on until you really understand it is creating a set of principles to live by.

(00:58:06):
We all have a set of principles to live by that we're doing it. For a lot of people, those principles are what do I have to do to get likes on Facebook? I'm going to make a decision based on getting likes on Facebook. I'm going to make decisions based on whatever it is. Pretending that I want to get wealthy or trying to get wealthy or there's a series of things. If you really take a look at what it is you're making your decisions on and then really think about, well, what would be the five or six things that if I made decisions with these principles, I'm guaranteed success? Then experiment with them and then refine those principles and then experiment with them. Then there'll be these moments where you don't want to do it, but those are your principles, so you're going to go and do it.

(00:59:03):
As an example for this, one of the principles that I live by is embrace intensity. It's not create intensity, it's embrace intensity. It means that right now, any moment in my body, for instance, there's going to be a sensation that's more intense. How do I welcome that sensation? At any moment in running my business, there's going to be something that we don't want to talk about. How do we lean in and talk about that? We start all of our meetings with what are you scared to say in our business? What are you scared to say? Not all of our meetings, but some of our meetings are started with what are you scared to say? Because we want to embrace that intensity because we know that if we lean into the thing that we're trying to avoid, our life is going to get better, our business is going to get better.

(00:59:57):
If you can see what those principles are for you, and then run experiments to see if they work and then refine them every once in a while. Because of that embrace intensity, if somebody comes to me and says, "You're fucking up this business. You're doing it all wrong." I don't have to think about what I'm going to do. I'm like, "Oh, cool. Tell me what I'm missing." It's going to be immediate because I live this way. Maybe I don't want to hear it. Maybe I'm having a bad day. Whatever it is. Maybe I'll say, "Hey, I want hear you give me, I'm not able to, give me a day and I'll come back to you." all of a sudden, my decisions get made automatically if I live by a set of principles and very effective, I find very effective living by a set of principles

Lenny Rachitsky (01:00:51):
For someone that wants to create their own set of principles. Is there a guide you have? Is there any advice for how to actually go about starting this list, putting it together?

Joe Hudson (01:00:58):
We have a decisions course, which is a large part of it is about how to do that. It's a difficult one to explain because there's a lot of nuance in it. Just as for instance, one of the nuances is defining the principles, not just by what it is, but what it isn't is a really significant, very minor thing, but it ends up being incredibly major. If you're going to do your set of principles and you want to do them on your own, the main thing I would say is keep it to five. I wouldn't even do six. I don't do six, but I keep it to five. I would test each one of them for five days.

(01:01:39):
Make your principle and then see if it works for you for five days and then keep on experimenting until you find five. When you look at those five and you say, "If I do that, if I live by those principles, I am just almost a hundred, if not a hundred percent confident that, that's going to create the life I want if I live by those principles." Then you have a really good start and make them simple. Mine are things like embrace intensity or connection first or everything is in iteration. As soon as I live by them, things work, company works.

Lenny Rachitsky (01:02:20):
Amazing. We'll point folks to that course if they want to take it themselves. Cool.

Joe Hudson (01:02:25):
It's only once a year, so it's a rare one.

Lenny Rachitsky (01:02:27):
Oh, wow. When is the next one?

Joe Hudson (01:02:29):
January.

Lenny Rachitsky (01:02:30):
Okay. Not too far away for folks to want to wait. Again, the two pieces of advice you shared, and that's our experiments that we can run to help become better decision makers. One is create a list of life principles, and there's a course that will point people to, to take that. The other is the thing you keep coming back to over and over and over, this idea of falling in love with your emotions, embracing your emotions, welcoming your emotions. There's also, I know you do a lot of work with teams. I imagine there's very similar advice for how to help your team be more effective. Principles, I imagine is a part of it, falling in love.

Joe Hudson (01:03:02):
We've run principles for teams, yeah. That's one of them. Teams would be more effective. We have a lot of, I mean I think I have, at this point, I have 12 things that I'll go into a company and do with a company. Typically, the way I like to do it is I will go in and I'll talk to the leader typically and they'll say, "This is what I want." Then I really want to assess. Typically, if the person who is a big part of creating the problem has a hard time seeing the way through the problem, or it wouldn't have been created generally. This is not demeaning any leader, we all have these issues. Usually, what I like to do is I like to go in and I like to talk to three or four people, see what their perspective, not just the leader's perspective.

(01:03:57):
Then I like to sit in a meeting or two and just see actually what the dynamic is. One of the things I like to say about how to change a company is that the atomic structure of a company is the meetings and the decisions. It's particularly true in Silicon Valley, but it's really true in all businesses that all we are as a company is a group of people's relationships and ideas. Especially, like Amazon, you got a couple of buildings and some servers. There's not a lot of hardware there, and they wouldn't be useful without the people anyways. Anybody, whether you're running a farm or a shoe factory or anybody's successful is going to tell you it's all about the people. The atomic structure is what are our meetings like and how do we make decisions? I'll just really pay attention to a meeting. One of the things we do is we talk about what we call five-star meetings, which is how do you make every meeting enjoyable?

(01:05:04):
Literally, how is it that everybody when they walk out of a meeting, they're like, oh, fuck, that was great? It turns out, we've all been in meetings that are hard as shit, and we've walked out and gone, oh, those are great meetings. We've all been in meetings where nothing happens and we're like, "Oh, God. Fuck, another one to just drive a nail through my head. I don't want to sit there." What's required to make one of your meetings five stars? If you do that, that's one of the things we'll do inside of a company is work with them to figure that out. If you do that, every single problem with your company will come to the surface. Every single one of them. I had ten five -tar meetings, but these two meetings sucked. That tells me exactly where we need to focus as a company.

(01:05:53):
That tells me exactly where to look for the problem that's happening. It's the same thing with decisions. If you really start unpacking how the decisions are made where people are frustrated in the decision-making process, you're going to find exactly the problems in the company. An example of this, I was working with a friend and he's a content person, and we were just talking about how do you make every one of your meetings a five-star meeting? He's like, "Okay, great." He's like, "Yeah, I'm never going to do this." I was like, "Really? Tell me why." He's, "My YouTube meetings fucking suck." That's not where he makes most of his money, but these YouTube meetings suck. They're never going to get better.

(01:06:39):
Luckily, there's a couple other people around at the time and everyone's like, "No, wait, I love my YouTube meetings. What do you mean? How could this not work for you?" He noticed, oh, the team didn't, the content, none of it was working for him. None of it was him. He was just like, "Ugh." He changed it. He was like, "Okay, I'm going to commit to that. I'm going to see what it's like for me to just say every one of my YouTube meetings have to be something that's super enjoyable to me." When he did it, his YouTube numbers went off the charts in a very short period of time. It's just that common. Wherever the meeting is that sucks, it means there's something else that's a problem that needs to be worked on. That's typically how. I can just look at, usually sit in any team meeting and see at least three or four of the major problems that are happening in the company.

Lenny Rachitsky (01:07:29):
Such a cool way of thinking about where to focus decision-making meetings. I love that the story comes back to something you shared earlier with the more you enjoy something, the more joy there is, the better it's going to go anyway. The more you can find those moments and make things enjoyable, the better.

Joe Hudson (01:07:45):
The other cool thing is most of the executives or the CEOs that I've worked with, when they get to a point, and it usually takes them like, we always have the goal of a month, it usually takes two months to make sure every one of their meetings is five-star meetings. Once they've done that, then it's like, how do you make sure all of your teams have five-star meetings? Usually, it's like within two months and they usually have half the amount of meetings at the end of it. Half the amount of meetings in their companies are more effective. It's an incredible tool.

Lenny Rachitsky (01:08:18):
I could see why people enjoy that if you were meeting as well. Is there anything more along those lines before we start to close out our conversation, either around teams or decision-making?

Joe Hudson (01:08:30):
I'll say for anybody who's running a team, Harvard has got a couple of these, but we used to do these tiny pulses. As a VC, one of the strategies that was really effective that I saw very few VCs doing was I would want these pulse, I would like to read the pulse of teams with these short surveys and stuff. It was the most effective way of not very happy, didn't want to come to work on Monday. They weren't going to make their numbers. The likelihood of them making their numbers is going down. There was this interesting thing that just about how Drucker, I think said it first and then the Virgin guy.

Lenny Rachitsky (01:09:15):
Branson?

Joe Hudson (01:09:16):
Branson said it. He's like, "Culture eats strategy for breakfast," or some such. If that's true, then it's measurable and it can be a leading indicator, and it absolutely is. If you really pay attention to the culture on a team-by-team basis, it's an amazing, very effective way to drive results, but also, a very effective way to know when bad results are coming. What's interesting to me is most people feel like they can't control the culture, like most people feel like.

(01:09:52):
Most people, I notice, they feel like, it's more likely for me to hear from a CEO, "God damn it, everybody agrees when I get out of the table. When I get off the table, everyone's like, yeah, we're going to do it. Then they don't do it. Why aren't they doing it?" I'm going to hear that more often than I'm going to hear a CEO say, "Oh, wow. I really noticed that the way the email system was working in our company, we were disempowering people by not requiring an action after every..." I'm going to hear more complaints about why shit isn't working than I'm going to hear about strategies, like very gentle, simple strategies to change the culture. it's an amazing thing to me that it's so powerful and yet people feel so out of control with it

Lenny Rachitsky (01:10:40):
To give people something they can do, say today or tomorrow to work on a lot of these things we've been talking about. Is there just one thing you recommend that basically everyone should try to experiment with in the next day, couple of days or weeks, just to help them be better and more successful and happier?

Joe Hudson (01:11:00):
I would do seven minutes, no less than seven minutes. You can do more than seven minutes. Seven minutes of gratitude with another person every day. It can't be, I'm grateful for this, I'm grateful for this, I'm grateful for this. It has to be feeling the gratitude and then seeing what comes out of your mouth when you're coming from the felt sense of gratitude and doing it back and forth. You're savoring the experience of gratitude and you're going back and forth with another human being. Call mom, dad, sister, brother, business partner, friend, and every day just express gratitude back and forth for seven minutes, coming from the feeling, not from the thought. If you have a full body sensation of gratitude and you experience that for seven minutes a day, it'll change your life dramatically really quickly. Really, really quickly.

Lenny Rachitsky (01:12:02):
Wow. I already feel it. The practice is you are expressing gratitude to the person you're with.

Joe Hudson (01:12:09):
It can be gratitude for anything in your life. As a matter of fact, I would say do it for a couple of weeks and then do it on the places where you feel lack. That's where the superpower comes in. In my own personal life, I was meditating. I spent seven, eight hours a day meditating for years.

Lenny Rachitsky (01:12:31):
That's a lot of hours.

Joe Hudson (01:12:32):
You can imagine, I didn't have a lot of money. The joke I used to make is I would meditate and worry about money most of my day. It's funny, but it's truth. One day, I was thinking about money and thinking I was driving in my car and I was thinking about this billionaire I knew and I was thinking about how I didn't have enough and then I thought, "Oh, this billionaire doesn't think they have enough either. I know I'm well enough." I'm like, "Oh, I have the experience of a billionaire right now." I was like, "He's probably driving in a car somewhere thinking he doesn't have enough, and I'm driving in a car somewhere thinking I don't have enough. This is great. I'm a billionaire."

(01:13:20):
It tickled me, the idea tickled me. Then I was like, well, what happens if I start focusing on everything I do have instead of focusing on what I don't have? Which is where the gratitude practice came from. My wife and I would sit every day and just be grateful for all the physical stuff that we had. We were living in a hobble, were living 15-year-old year cars. We had no money. I was in debt. I was in, I think $40,000 in credit card debt or some crazy shit. We just did it. Literally, was it three months later, my credit card debt was gone. Six months later, I had $60,000 in the bank. Entire life changed because I no longer defined myself by somebody who didn't have, I defined myself as somebody who did have. All of a sudden, I could look out the window and it wasn't, "Oh, shit, I can't have that. I can't have that. I can't have that."

(01:14:18):
I look out the window, I'd say somebody made money on that. Somebody made money on that. Every fucking thing I looked at, somebody made money on. 20 people, 20 companies made money on the fucking lamppost. The person who installed it, the energy company, the rubber company, there's just, holy crap, it's all over the place. Then in that definition, all of a sudden, it became really clear. It doesn't matter if the thing that you feel like you lack is time, or the thing that you feel like you lack is love or the thing that you feel like you lack is money. If you can really do a gratitude practice on the thing that you lack, there's a superpower in that one, changes everything.

Lenny Rachitsky (01:14:57):
Do you still do this?

Joe Hudson (01:15:00):
I do gratitude, yes. Do I do gratitude on stuff I lack? I don't really have an experience of lack. That's not really...

Lenny Rachitsky (01:15:07):
You still do this gratitude, seven minutes?

Joe Hudson (01:15:09):
Of course, yes. That's like asking if I still have sex. Why would I give that up? It feels great.

Lenny Rachitsky (01:15:16):
Just to be clear, you find someone seven minutes every morning, probably think about things you're grateful for and share back. Focus not on your intellectual thing you're grateful for, but just what's coming out of your emotional body.

Joe Hudson (01:15:28):
Feel the gratitude.

Lenny Rachitsky (01:15:30):
Yeah, then gratitude.

Joe Hudson (01:15:30):
Let the feeling of gratitude speak rather than your mind, so that you get the felt sense of it.

Lenny Rachitsky (01:15:38):
Joe, I'm incredibly grateful for you. I really appreciate you sharing so many experiments for people to run. I think this is going to make a real impact on a lot of people's lives. Two final questions. Where can folks find your courses? I know you have a podcast. Where can folks find the stuff they do online, and then how can listeners be useful to you?

Joe Hudson (01:15:55):
First of all, Art of Accomplishment, the podcast, it's Art of Accomplishment with Brett Kistler and Joe Hudson, I think. Then Art of Accomplishment, the website will show you where all the courses are. It'll give you a whole bunch of experiments you can run. There's all sorts of really great information there. The other thing that we just mentioned also is just that we really want to make sure that you think that the courses are for you. The way we do courses is that it's a very felt experience thing. It's not intellectual at all. It's really in your body. The way we like doing it is that you bring real problems that you're having and you use the tools that we teach you. The foundational course for that is called the Connection Course. If you want to get into it, go to the Connection Course.

(01:16:45):
To find out if it's right for you, if you're not already know that it's right for you, we do these little hour and a half free workshops and it'll give you a taste of what it is that we do because it's like anything that's going on out there. It's people doing, they're like, "What the hell was that?" It's just a completely different thing. It's not like learning in the normal way. You literally sit down with another person and run experiments face-to-face with how you're being in the moment. You learn all this stuff through direct experimentation. If you find out it's right for you, you can do it through these workshops, and I'm sure there'll be a place where they can find out where to go for that.

Lenny Rachitsky (01:17:27):
There's one coming up in September, I believe.

Joe Hudson (01:17:30):
The Connection Course is coming up in September. It's a great place to start. It's foundational for everything else we do.

Lenny Rachitsky (01:17:37):
Then how can listeners be useful to you?

Joe Hudson (01:17:39):
I want my children to grow up in a fantastic world. The best way that, that can happen is that if the people listening to this discover who they are and their nature and the truth of how they operate. Not for them, but for their children and their children's children. You want to do me a favor and make my daughter's world a better place.

Lenny Rachitsky (01:18:08):
I also just had a son, and so I totally resonate with that.

Joe Hudson (01:18:11):
Yeah.

Lenny Rachitsky (01:18:13):
Joe, thank you so much for being here. What an amazing podcast episode. This ended up being as I expected.

Joe Hudson (01:18:19):
Pleasure. Thanks for having me. Appreciate it, Lenny.

Lenny Rachitsky (01:18:22):
Bye, everyone. Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## What differentiates the highest-performing product teams | John Cutler (The Beautiful Mess)
**Guest:** John Cutler  
**Published:** 2023-01-15  
**YouTube:** https://www.youtube.com/watch?v=Y4PdUItyXUk  
**Tags:** growth, retention, acquisition, activation, metrics, roadmap, prioritization, experimentation, analytics, pricing  

# What differentiates the highest-performing product teams | John Cutler (The Beautiful Mess)

## Transcript

John Cutler (00:00:00):
Let's say you're a founder and you're trying to decide, should I invest more on processes, or should I invest more in people. The first thing is introspection. What do you believe in, really? What do you believe in, and what do the people around you believe in, and how can you be a coherent leader? And you know what? You can nudge yourself a little bit away from your happy plate, but you're not going to go super far. You're not going to go from like a process-driven meritocratic, X, Y, Z person all the way to like I'm going to start a collectivist company where everything is sort of a consensus decision to do that. You're not going to do that. But I think it starts with self-awareness and then that's how people form their authentic leadership vibe, and then they flex a little bit and then they embrace other perspectives.

Lenny (00:00:49):
Welcome to Lenny's Podcast. I'm Lenny, and my goal here is to help you get better at the craft of building and growing products. I interview world-class product leaders and growth experts to learn from their hard-won experiences building and scaling today's most successful companies. Today my guest is John Cutler. John is one of the most prolific, beloved, and longtime writers and sharers of product wisdom online, and as you'll hear at the start of this episode, thanks to his really unique role at Amplitude, he's worked with a large percentage of product teams and product managers around the world. I've learned a lot from John's writings over the years and share his stuff often, and so it was a real honor to chat in depth with John. I anticipated this would happen and it happened, this ended up being the longest episode I've done yet, and honestly, we could have kept going for a lot longer.

(00:01:35):
We chat about what differentiates the highest performing product teams from less well performing product teams, what it takes to create real change within a company, why you should be skeptical of frameworks and tools that you read about online, why all underperforming teams fail in similar ways but high performing teams succeed in many different ways, and so much more. I am confident you will love this episode and I cannot wait for you to hear it. With that, I bring you John Cutler after a short word from our wonderful sponsors.

(00:02:05):
This episode is brought to you by Merge. Every product manager knows the pain of slowing product velocity when developers struggle to build and maintain integrations with other platforms. Merge's unified API can remove this blocker from your roadmap. With one API, your team can add over 150 HR, ATS, accounting, ticketing, and CRM integrations right into your product. You can get your first integration into production in a matter of days and save countless weeks building custom integrations, letting you get back to building your core product. Merge's integration speed up the product development process for companies like Ramp, Drata, and many other fast-growing and established companies, allowing them to test their features at scale without having to worry about a never-ending integration roadmap. Save your engineers countless hours and expedite your sales cycle by making integration offerings your competitive advantage with Merge. Visit merge.dev/ lenny to get started and integrate up to five customers for free.

(00:03:06):
This episode is brought to you by Eppo. Eppo is a next generation AB testing platform built by Airbnb alums for modern growth teams. Companies like Netlify, Contentful, and Cameo rely on Eppo to power their experiments. Wherever you work, running experiments is increasingly essential, but there are no commercial tools that integrate with a modern growth team stack. This leads to wasted time building internal tools, or trying to run your experiments through a clunky marketing tool. When I was at Airbnb, one of the things that I loved about our experimentation platform was being able to easily slice results by device, by country, and by user stage. Eppo does all that and more, delivering results quickly, avoiding annoying prolonged analytics cycles, and helping you easily get to the root cause of any issue you discover. Eppo lets you go beyond basic click-through metrics, and then set you to North Star metrics, like activation, retention, subscriptions, and payments, and Eppo supports test on the front end, the back end, email marketing, and even machine-learning clients. Check out Eppo at geteppo.com, get E-P-P-O.com, and 10 x your experiment velocity.

(00:04:18):
John Cutler, welcome to the podcast.

John Cutler (00:04:21):
Yeah, thanks for having me, Lenny.

Lenny (00:04:23):
I kind of know you as John Cutler. I feel weird to call you just John. Do you find that to be true, and also do people call you John Cuttlefish because of your Twitter handle?

John Cutler (00:04:32):
Yeah, John Cuttlefish. There is this, I learned yesterday, there's a DJ, a famous DJ called Jon Cutler without the H, so I don't know if are people into house music knew that. Yeah, I think usually it just, like most Johns, it forms into Cutler or JC or something like that, but just John is good, yeah, for now, or Cuttlefish, you could just call me Cuttlefish. That'd be fine.

Lenny (00:04:51):
You said that actually, we were talking before this, you said you do some music, so is that DJ actually you?

John Cutler (00:04:57):
No, but that would be really funny. In fact, the person yesterday who reached out over Twitter said, "Dude, I don't know what you're doing now in your career, but I really like your earlier work." But that would've been pretty cool to be Jon Cutler, the DJ. I wrote songs and played rock music and stuff, not like a house DJ.

Lenny (00:05:15):
Okay, this could be the next phase of your career which we'll talk a bit about. But let me just say that I'm so incredibly excited for this conversation. I've been hoping to do this for a long time, and now that you're between gigs, we finally found an opportunity to do this, and I just have a feeling this is going to be one of the longest episodes we've done because there's so much I want to ask you, and there's so much interesting stuff that you've had access to and that I think that you can share. So, I hope you're ready for potentially a marathon of an episode.

John Cutler (00:05:40):
Sure, yeah, I'm ready. This is exciting. I'm on vacation now between jobs, so this is the highlight of my day. We can go all day if you want.

Lenny (00:05:47):
All right. Eight hours. Let's do it.

John Cutler (00:05:49):
Terrific.

Lenny (00:05:50):
So, I was thinking that we start with a little bit about this unique role that you had at Amplitude which you just left after about four years, and what's most interesting about it is it give you access to an incredible number of product teams and product managers, unlike anything else I've seen or any other role I've seen before. So, could you just talk a little bit about this role that you had at Amplitude, and what it was like to work with so many product teams and so many product managers?

John Cutler (00:06:16):
Yeah, absolutely. So, first off, I remember almost specifically the day that Sandhya from Amplitude reached out and was sort of floated this idea of this role to me, and I'm so grateful for Sandhya, and Justin, Matt Althauser, Spencer, the whole team, because it was really, it was really kind of a weird role from the beginning. They were starting to get more and more customers who were not traditional startups or kind of growth stage startups showing up, and they needed to figure out how to convey expertise and convey things to the broader product public in a way that would land with those companies, right? I guess, kudos to them thinking this weird idea could work. So, I'm really, really grateful for that.

(00:07:06):
But yeah, my official title was product evangelist. I don't think that I super fit that role, but that was the title that we had, and basically my job was to wake up every morning and do things that would overlap Amplitude the product, but then help uplevel our customers, sort of uplevel the broader product community. I call them current customers and future customers. That's how I woke up every day, I'm either talking to a current customer, I'm talking to a future customer. This product transformation's happening all around the world, just means it's a matter of time, eventually they'll become Amplitude customers, so I should just try to make them awesome and try to help them with different expertise.

(00:07:46):
But my day-to-day was spent a lot advocating for different ways of working, doing coaching, doing workshops. I wrote the North Star Playbook in partnership with Jason who was a co-writer with that. We did a lot of one-to-one coaching sessions. I had these things called product therapy sessions when I would just wake up in the morning and just kind of soak in whatever problem people were having for the day. I did meet with hundreds and hundreds of people and did workshops for thousands and thousands of people and talks for more than that, tens of thousands, really, in terms of the talks. So, it was just a, yeah, crazy experience doing that. So, the technical details is I predominantly reported into marketing and product marketing, and then I did a stint actually where I was on our product team as we were sort of getting our education efforts going, ultimately we moved that over to customer success, and I went back to marketing. So, that's the technical side of it, I reported into marketing.

(00:08:45):
But I do remember the day I arrived and probably a couple weeks later, we had our all hands annual kickoff, and there was a big presentation about our goal being the trusted expert, and that still resonates with me the whole time I was there that an evangelist is there to help uplevel the world with trusted expertise, and in a product like analytics product, there's the product analytics, but then there's whole other ways of working that overlap that. So, yeah, generally that was my role. It kind of is a crazy role, for sure.

Lenny (00:09:16):
That is wild. You're basically like a free product coach for product team. You just come in, help them uplevel the way they build product, and then Amplitude becomes... You need to figure out how to work with data, Amplitude can help you be more data informed. I imagine that's kind of the general idea.

John Cutler (00:09:30):
Yeah, it's funny, I joke with our professional services team. I mean, so if you're a SaaS company, I think sometimes you have a professional services team. At Amplitude, especially the way that we saw that is companies put money in and that sort of creates skin in the game. They're really paying you less for the professional services and more for the accountability and the access to the expertise. So, I would joke with Jenna from that team that maybe we should have monetized all these workshops. I know Gibb and other people, they're charging a good chunk for North Star workshops and here we were just kind of doing them for free.

(00:10:04):
So, ultimately, maybe there was another strategy there, but that we did those generally for free, and sometimes I kind of stuck my foot in it. In the middle of the pandemic at one point we were like, "What are we going to do? We can't travel for workshops." And I would put in my newsletter, "Hey, anyone want a workshop?" And then suddenly, our sales team, we had to grapple with what are we going to do with these 120 leads, how are we going to work with them. It was funny having to deal with it.

(00:10:32):
But yeah, in general, this is a unique role. I would definitely consider a SaaS company's think about a role like this, but it's really nuanced. We can share some links later as I reflected on what we did right and wrong, but ultimately, I think you shouldn't rely on individual people. You should think of evangelists as almost like concentric circles of your community and some people who just happen to have more expertise. Look, our internal team's amazing, Ibrahim, Justin, and Abbie, and when Sandhya was at the company, and just, everyone's an advocate. Everyone's a potential evangelist. It's just that there's only so many hours in the day. So, you could think of your community as just these concentric circles of evangelists and advocates. It's just like how you design it right that does it. So, yeah, recommended. It's a little tricky, but yeah, it was a cool move to do.

Lenny (00:11:19):
That sounds like a future post, how to do this in a different way where they don't have a John Cutler in place. You said you worked with hundreds of teams. Maybe just give us some numbers roughly of how many companies have you worked with, how many product managers do you think you've spoken to in this career.

John Cutler (00:11:32):
Oh geez.

Lenny (00:11:33):
This phase of your career.

John Cutler (00:11:34):
So, I think I did it... There might have been over the four years, maybe 800 one-on-ones, individual leader one-on-ones. I'm thinking it was at the peak, it was in one year's 150 workshops and then overlapped in the next year, then between 200, but mostly the average maybe let's say three or 400 workshops, a hundred a year. It's heavy. And then there was these just general conference talks and other things that we're doing. I tried to total, I exported all my Google Calendar invites, I tried to categorize all them at some point, but really also you have to think about it is that what we did with the North Star Playbook, it was truly a team effort at Amplitude.

(00:12:19):
We started to have our, I think it was Sandhya who needed to like, we had three days to go in to close a customer and they were looking for us for trusted expertise, and she pulled together this workshop and she came up with these three games of product which is a really tricky and cool way to describe how your North Star inputs and North Star should be, and it started this ball rolling, and then they wrote a blog post about it.

(00:12:42):
So, if you search North Star, you get to Sandhya's post. It's an amazing post, and then our CSM started to learn how to do it, and then we were like, "We should write a playbook for it." And then it got to the point where if you go on LinkedIn, people are like, "We used," and I made a whole point of saying we did not invent this thing, but people will say, "We use Amplitude's North Star framework," and I have to always chime in, like, "No, we did not invent that thing. You should go to Sean or you should go to any of these people who've done it in the past." But yeah, the whole point is that a lot of this stuff was evolved over time. It wasn't just some snap marketing campaign to do it.

(00:13:17):
Same thing are our retention playbooks and engagement playbooks. When I arrived at Amplitude, people would send pictures of those playbooks sitting on their desks and people thought, "Oh, it's just this piece of marketing content. How did they pull it together?" I did some research and our CS team developed 110-page bulk of research from working directly with customers around retention engagement, then we had a PM and a great content writer, Archana, zero in and kind of make it palatable, then we did ARC for it. So, it didn't just magically appear. People think that these artifacts that Amplitude has just magically appeared, but they were just... It's a company filled with passionate experts of these things, and it was like tested, iterated, tested, iterated, expanded, tested, put into motion, put into practice, and that's how you create these kind of franchise cornerstone pieces of content for your company. You don't just snap your fingers one day. So, anyway, I wanted to point that out. Huge group effort for all these things.

Lenny (00:14:22):
How does it feel to have left Amplitude at this point? I imagine you're going through some rollercoaster emotions.

John Cutler (00:14:26):
Oh geez. Well, the immense amount of gratitude, definitely, mention that, wonderful people, wonderful customers. Just imagine like if you're a product nerd, one day you're with Amazon, one day you're with Ikea, one day you're with LEGO, one day you're with Intercom, then you're with a two-person startup, and then you're with Figma. So, really, once in a lifetime experience to be able to do that. In fact, if I had been a paid consultant, I never would've been able to do that. Another thing too is that there's this sort of selection bias. If you're a consultant, people come to you to work with you, but often I just had to talk to whatever team wanted access to expertise at Amplitude, not necessarily me. So, I didn't get to dictate A lot of times the conversation. It's like, shit, I'm not doing a very good job here. This person thinks in a very different way to do that.

(00:15:18):
So, yeah, a lot of gratitude. I would say it got really heavy a lot in the sense that my son was born, three months later, I start the job, and then the pandemic kicks in, and every day you're absorbing just attention from teams. You're meeting leaders who are about to leave. Five days later, you're meeting people who are trying to save their team from the pandemic, imploding everything they're doing. Yeah, I'm joke about the product therapy thing, but I would finish the day at 2:00 or 3:00 and then have to do another one. Wake up at 5:00 to do an EMEA workshop, 5:00 to 7:00, be two in workshop, then take a break, then do another two-hour workshop, and then talk to a leader about how everything was going to explode, and then another leader. And then I was still on a team in Amplitude, so I might go to my own meeting where we're working through our own challenges, and then it's 4:00 or 5:00 in the afternoon. I'm done. Oh, to be able to do that.

(00:16:16):
And then I think it also left me with a couple key lessons we could probably go into later when we're doing it. One, you are talking to a bunch of different companies, achieving the almost similar results in very, very different ways. They behave in different ways, the context in the pandemic or the economy. You would see the pandemic kick in and then you would talk to 50 companies that were dealing with the ramifications of it. So, it's kind of funny, I joked with someone at Amplitude, they're like, "We were going through our own shit," and I'm like, "Yeah, and I've seen how 50 other companies are going through their own shit," where this is you're doing it. So, the power of context.

(00:16:52):
The regional differences were so fascinating. I was on with a teen that was based in India and just the passion and curiosity. There was not one jaded person in the room. There was not one person like, "Been there, done that. When's the performance review cycle ending?" or anything like that. It was just all-out passion and hunger for information. So, those days were amazing. So, yeah, you talk a lot about it, but it definitely, it feels like a relief in some ways because the amount of tension to do it. And so, for my next plan actually what I'm doing is I'm going to work at Toast in a couple weeks, and I've been in touch with a leader there, Craig Daniel, for a long time, kind of really liked what he did at Drift.

(00:17:40):
But I think that what I realized over the course of these four years is that I wanted to pivot back to help put most of my energy into helping my own company. They're growing super fast, so the numbers are in the hundreds of everything or in the thousands of everything, and they're not just the POS business. They've got these different businesses, like guest services and back office stuff and things. Amplitude is a super horizontal, if you think about it, it's almost like a diagonal, and so it made your head spin, and I kind of wanted to go back to a vertical SaaS. There's a company here in Santa Barbara called AppFolio that I like working at, and I really had a soft spot for vertical SaaS, but I'm thinking put my energy into an internal team for a little bit to pivot back into that. And so, I'll be helping enable product teams and sort of doing what I was doing, but within a company as well. So, it's going to be an interesting shift.

Lenny (00:18:29):
You touched on so many topics that I want to dig further into, and you also talked about where you're heading next, which I was going to ask, so that's great. Thank you for covering all that. By the way, I was just going to also say, lucky Toast, wow, to get John Cutler. Go them.

John Cutler (00:18:42):
Oh, lucky me. I mean, Jesus, Toast is this gem. I just was joking with Craig the other day. I was like, "I did not know all that stuff was going on at Toast."

Lenny (00:18:52):
Awesome. Okay. So, before we dig into some of the stuff that you brought up like cultural differences between companies, what the best teams are doing differently, things like that, I actually, and you noticed, I asked on Twitter what I should ask you. You have a lot of fans on Twitter and there's a ton of questions, and one actually got pretty spicy and I want to touch on it briefly. This guy, Jason Cohen pointed out that a lot of the stuff you share online in your newsletter and tweets and things like that, it often doesn't have a clear recommendation of here's what you should do or concrete piece of advice you could take away. It's kind of messy which is appropriate because your newsletter is called A Beautiful Mess. And so, my question to you is why have you found that you like to embrace the mess in your writing and your thinking and your advice?

John Cutler (00:19:38):
I was reflecting that the newsletter, it's almost like an emo band, The Beautiful Mess, it's so angsty. It couldn't have been more... If I had a band, I did not have an emo band when I was 16, but if I did, I would've called it The Beautiful Mess. So, it's probably pretty consistent with personality to do those things. I mean, I actually really appreciated Jason pointing that out, and in fact, at the end of this year, I put this post out to people saying, "Hey, here are things I'm grappling with, like the actionability of the content that I put out there, diversity of product advice, it's important to me," and then what it's like to just be a weirdo. We all have our weird freak things to do these things. And so, what does it mean to embrace those things? So, it was really timely I thought that Jason put that out there, and so maybe I'll give a little background about the newsletter and what I was looking for that.

(00:20:29):
And so, I think that the first thing that I did was four years ago, I kind of scanned the product advice landscape and I noticed three things. First, there's sort of three perspectives that pervaded, and again, I just want to make a huge caveat, this is not a judgment on any of these particular perspectives. It's more like I noticed a lot of it. And the first was that to be successful, number one, maybe success is tools, skills, mindset. So, that's kind of one group of particular things. The second that in terms of worldviews, we mentioned international worldviews too, but there was a high percentage of product advice that was kind of grounded where you think it would be grounded. So, it was grounded in this idea of meritocracy. Success is primarily about merit, very highly individualistic, and we don't realize that in the US until you do meetings with other teams, just how individualistic we can be when it comes to how we think about teams should be set up and stuff.

(00:21:28):
And then I think the third thing I realized was that it was very often very context free, and I mean that actually in the nicest way. It was optimized to make sure that it could be actionable, that someone could take that away. That's what I really like about the content that you put out there, and I like about a lot of the guests on the podcast. They kind of lay it out in those particular things. And so, to kind of go through, yeah, those tools, skills, mindset, that makes sense, right? Who does not want tools to be better? In fact, a lot of the podcasts I like, we can get into that later, are like, "We're going to give you the tools and tactics that the best people do." So, I really like that kind of stuff as well.

(00:22:04):
The second part of that is this idea of success be mostly about individual skills in jobs. So, this idea of great leaders, high performing teams, 10 x people, kind of go on and on. And then the product mindset stuff which is a little bit like you have it or you don't, or you develop or you don't. It's very mysterious. So, again, I'm going to go through these things and then think about how they inspire me. Part of me was like, "Okay, there's a lot of that stuff, but maybe not as much stuff kind of unraveling the dynamics that happen behind those things."

(00:22:36):
So, the meritocracy stuff and the individualism stuff, it's basically the people rise to the top, they try the hardest, they work the hardest, the best in companies employ them. There's top tier companies, there's second tier companies. So, there's this very hierarchical view, and as I started to also dig in more into the stuff in Amplitude, I was like, "Wait, there's something right and wrong about this at the same time, there's something true but not true at the same time." So, that's something that I wanted to be able to explore in doing it. And then the context free advice was obviously I noticed more and more that people trying to put tools in play out of context sometimes had worse effects than them just not doing it at all to do that.

(00:23:18):
So, anyway, I kind of thought about it as a product, like, "Okay, what's my opportunity here? There's a lot of this great advice. It's very actionable. I don't know. In the US were pretty individualistic, so the advice probably lands with people really, really well, and then also it's really actionable," and said, "Okay, well, what would be my particular angle?" So, I thought about the angle, about wanted to explore three things. I think the first one is this idea we do work in these complex adaptive systems, and so I really went deep in that particular area.

(00:23:47):
So, we work in environments. There's lots of things that are interdependent on each other. We don't work in closed systems. I mean, if you're in the Bay Area, you're in this broader system called the Bay Area that's in this broader system called California that's in this broader system called the United States. Your team is in a team of many, many teams in your company. The systems are non-linear. The bird flapping its wings in Brazil creates the tornado type of stuff. And so, I wanted to make sure that we got dug into that particular stuff in The Beautiful Mess stuff.

(00:24:21):
The next thing is that I'm a sucker for weird counterintuitive dynamics in companies. I don't know what it is. I absolutely love that. And so, maybe I'll give two examples. One, I'm obsessed with this idea of high work in progress, from a human level and a team level. How even though we know that if you try to do less at once, you'll be more effective, teams routinely just load themself up with work? And so, in the newsletter, I wanted to explore stuff like that, like why, when a bunch of people know irrationally that you should not load yourself up with work, why do really, really smart, capable, intelligent, passionate people in their personal lives and on their teams just load themself up with work? What are they optimizing about? So, that'd be like one example of counterintuitive stuff.

(00:25:09):
The other stuff is strategy stuff. Every company has these three pillars, and it seems really smart for the CEO to have this really clear three pillars, but then everyone walks away from the meeting and be like, "I don't know what we're with doing." That's another example of a counterintuitive thing. So, that was the second thing, the counterintuitive stuff. I love the complex stuff. And then frankly, I think the other thing is I just wanted to help people who are weird like me do those things. So, I would say I'm really, really triggered. People will say, "But it's probably triggered by Jason." He said, "Why? Bring solutions not just problems." That's my krypton, right? I like the systems thinking stuff. I like all that. So, anyway, long story short, wanted to help people like me. I like the complexity stuff. I like all these weird counterintuitive dynamics. And then I thought that there's a lot of representation for the very deterministic advice that people have.

Lenny (00:26:02):
That's a really good explanation. There-

John Cutler (00:26:00):
... advice that people have.

Lenny (00:26:02):
That's a really good explanation. There's a piece of what does the market want and let me deliver it, and then there's a piece of how is my brain working?

John Cutler (00:26:10):
I love the fact that people scan the market and say, "People want to know about prioritization and so I'm going to tell the world about prioritization." I really like that. In fact, I admire, I'm jealous of people who can produce that kind of content realistically. Interestingly enough, probably in my doodling in post I've probably given frameworks to do that. I just don't think too much about it. I just kind of go in these things. There's always this balance and one way that I think about is to get anything done, we need to reduce the world a little bit. That's the difference.

(00:26:41):
Back to this thing of complex problems, I think it's the difference between oversimplification and focusing. You can have a really complex problem and you can oversimplify it and that's not great, but you can have a complex problem and be like, "You know what? I need to hold some things constant." Not going to make any progress unless we hold some things constant to do that. That's, to me, the balance I'm playing all the time between how many variables to hold constant to make sure that people can get some value out of it. I don't know about you, but that's the tension I have. But you write really actionable stuff and so I really admire that too. I'm jealous.

Lenny (00:27:15):
I try, but then I'm jealous of always having to nail it down to something very concrete and simple. This last post actually was a little bit of an balancing act where I wrote about how virality is mostly a myth, and I added the word mostly to it at the end. Then I was like, "Should I just go for it and be like virality is fully a myth?" But no, it's not actually, so I can't really go that far.

John Cutler (00:27:35):
See, it's kind of messy.

Lenny (00:27:36):
It's kind of messy.

John Cutler (00:27:38):
I love that. In the spectrum of advice, every post of mine will say mostly, maybe, it depends, so we all have some opportunity to flex into the other direction.

Lenny (00:27:49):
Shifting a little bit, coming back to just the bigger picture of John Cutler, you've had more exposure I think to product teams and product managers, you're definitely in the top 1% of people that have talked to and met with and seen what happens within product teams. There's a lot of stuff I want to dig into there and the first is around what you've found differentiates the highest performing teams. Let me just ask you this very succinct question and see where it goes. If you had to just boil it down, what have you seen most differentiates the highest performing product teams?

John Cutler (00:28:26):
First of all, they're top 1%, they're super, super productive, they can levitate, they can do ... they have no emotion. No, I'm just kidding. No. Okay, this is my tack for answering the question. First of all, I have this friend Josh Arnold and he had this great principle that held true in my experience talking with teams and he calls it the reverse Anna Karenina principle. In Anna Karenina, Tolstoy is basically the like, "The dysfunctional families are all different and the happy families are the same," and what he said is it's the reverse of that with product teams, that actually the dysfunctional companies are all the same and then the happy companies or the higher performing companies can be very, very different.

(00:29:07):
That's something that stuck with me because either you have easy to identify anti patterns, and I'm going to admit earlier in my career, maybe five or six years ago, my content was about identifying things that people would be like, "How did you know that was working in my company?" and I would just be like, "Well, I just know." Even Spencer and I had this thing. I put something on Twitter and Spencer writes me, he's like, "John, is this about amplitude?" and I'm like, "No man. It's like that Carly Simon song, Spencer. You probably think this song is about you, but it's not." It just is. It's just like those things. Either you have the very easy to identify anti patterns or you have the high level principles, like you must trust each other or you must do something like that.

(00:29:50):
But the way that companies achieve those particular high performing things can be vastly, vastly, vastly different. Let's just start with that as a basic thing, which is one reason why it makes me hard to answer the question. A great example here is great product leadership. We need great product leaders. But you meet [inaudible 00:30:11] product leaders and you see that some people are these humble, curious servant product leaders. They're not really talking a lot and they're just growing the system that way. You know what? There's other companies with really successful people that are just badass, strong, dominant, they like to spar. I need people who can spar with me. That's just one potential example there of okay, you meet enough teams and you see that there's many ways to achieve great leadership [inaudible 00:30:41] example.

(00:30:42):
Another example would be, and then I'm going to start listing these things off and then hopefully this makes more sense.

Lenny (00:30:46):
Yeah, it feels great.

John Cutler (00:30:48):
You meet lots of great teams and the better teams make high, better decisions faster. Now, that's like that high level thing that I say that to you and you're probably like, "Well, no shit. That's what I would assume to do that." But if you think about good decisions and stuff, like what do you need for good decisions? You need information, pays to have diverse perspectives, you need to be able to analyze the data. You probably need chops, some kind of chops in the domain to be able to do it. You usually need a goal in mind, like what are you optimizing for? It's very hard to make a decision just to make a decision to be able to do that.

(00:31:21):
Those are the basics, but still none of that's all that interesting, right? You're like, "Oh, you're saying you need information to make decisions and it's kind of not very satisfying to do that." But then if you think about three companies. We could even play the game together. I'll give you two, you could give me the third one. But let's say company A buys into the whole idea of an extremely rigorous decision-making process. It's very process driven. It's like you do this, you do that, we red team our decisions, we bring in people to push back, we've got this particular thing. Maybe that's how they achieve it. Company B, maybe they're just all about this kind of mushy, diverse perspectives thing. They're not very process driven, but they achieve really good decisions by making sure that there's these serendipitous connections between people at the right time with the right set of [inaudible 00:32:08].

(00:32:08):
There are highly successful companies that achieve both of those particular things. I don't know, what am I missing? Lenny, you think about it. There's the rigorous process driven approach, then there's the company that's all about the ad hoc work together collaborative approach. What's another way that some companies make really good decisions all the time?

Lenny (00:32:28):
What comes to mind is a very top down CEO driven, here's what we're doing, here's the roadmap.

John Cutler (00:32:32):
Absolutely. So this is the thing, I'm sitting there and the very idealistic product managers are like, "You got to have empowered teams and you got to push decision-making down to the bottom," and I'm like, "Huh, well that company's doing pretty well and the CEO just tells everyone what to do and in fact, they attracted people who just don't mind that and like their vision and they do it." You find people who really like the process driven approach and you find people who do those things. That's one principle done a different way. But then I'll just take a couple principles. I just wanted to get that out of the way, that every one of these I mentioned could be achieved in a couple different ways.

(00:33:10):
The first thing you notice is the companies that are very high performing have coherence between the structure of their company and their current strategy. This is a structural thing, I think when there's startups, things are very fluid and the strategy's in flux, and so they have a fluid structure, but then as companies grow, there's sort of a physics to the problem that starts to catch up to the particular things. Their funding approach, their incentives, the org structure, the architecture, even their technical architecture supports their strategy back and forth. The reason why I mentioned this one is you can have brilliant teams. You meet these brilliant teams where they've just hired in the best of the best and they're just struggling with a strategy structure mismatch and no amount of let's empower people or no amount of doing whatever is going to knock them out of that.

(00:34:01):
So what do you need? You need a strategy, then you need to line the structure around it. This is different than saying ... you're asking me what do I observe when they're doing really well? Now, the tactics to achieve this might be different depending on the company, but you could get that. I think the second thing, if I admit it, is the strong opinions loosely held, which is there is this balance of believing in certain things, believing maybe in the power of products or the power of connecting with customers or maybe key strategic things that they need to do, or even believing that this is a done deal and you just need to move faster than everyone else in the space, or even the belief that you need to just go straight to commodity pricing like Amazon with whatever you're doing.

(00:34:41):
There is just a stubborn, strongly held belief that is then balanced with their ability to have the loosely held thing. I would just observed this in meeting after meeting with these teams that seem to be having a bout of being more high performing. They would be stubborn about some things that they were doing even when it didn't make sense in the short term and then they would do that. I think that that's another thing. I think related to that when it comes to the product world is just a core belief in the power of products. The Jeff Bezos thing, that the success of today was set in motion three years ago, that product is a layer cake and that you are layering on decisions, the success you're having now is a layer cake of decisions from the last bunch of years that you're doing it.

(00:35:26):
You could rationalize that all you want, but at the end of the day, it's often because either the founders or other people involved have seen how that can work because there is a leap of faith and there's a leap of faith that no amount of data or no amount of AB testing or no amount of rationalizing or no amount of spreadsheet math to figure out the ROI of what you're doing will ever help you. It's just not. I just noticed that pattern over and over that there was just a slightly irrational belief in the power of what it would take to have a nine craft level product versus a seven craft level product or six craft level product. I think that that's another component. I have a couple more in depth like that.

(00:36:10):
Definitely the leadership is coherent, so that's walking the walk, talking the talk and I think this is one of the most fascinating ones because it's very much about being who you are and not being embarrassed about that thing. There are companies probably all know that outspoken, domineering believe that the company just should be run a certain way and they set this vibe, this coherent ... that their actions and words match together. When you think about it that way, it makes more sense. The company that's like, "Oh, well we want to empower our teams and do whatever and we believe in our customers," and their actions don't match those particular things, that's not very, very coherent to do these particular things. I think that that's one, the coherent things.

(00:37:06):
Okay, so you've got those high level ones. I think you can definitely add skills and experience. I mean, those definitely matter. I think one thing that happens a lot is how the company views its skills. Here's a challenge we had in Amplitude, just sharing this, is you could view Amplitude as just another B2B SaaS company or maybe just an analytics company. But one of the challenges we had when it was how to build our team is to think about where do you draw the line between someone who's just done B2B SaaS for the last 10 years, is a pro at what they're doing and then how someone could embrace this kind of weird problem, sort of bottom-up motion, top-down motion. It's in product, it's a messy space. You need to be more strategic to do that so the skills need to be mediated obviously between the environment to do those things.

(00:37:51):
Then like all the other, they know how to build software, things don't break, they can experiment without risks. I don't know. They have positive habits. I could go on and on. Hopefully this is helpful just hearing my thought process to go through these things. But I think that the TLDR of this whole thing is those top ones I mentioned seem like common sense and it's like how do you put it in motion in your company? I was just reading that working backwards book about Amazon and they're in this chapter about basically their bar raisers thing and I share it with my partner who's the head of HR at a company. She's like, "Yeah, this is sort of common sense hiring. They're just talking about de-biasing the hiring and having standards and having those linked into the jobs and just not rushing it."

(00:38:41):
It's like these things that seem so common sense are actually hard with what they're doing. I don't know if you've noticed that, but it's like a lot of the advice is common sense. That doesn't mean it's easy to put in motion.

Lenny (00:38:53):
Yeah, and there's also a lot of power to just making it a very important value to the company. Just calling it bar raisers-

John Cutler (00:39:02):
[inaudible 00:39:02]. I'll use the example of a company. I mentioned this company AppFolio here in Santa Barbara, but Klaus and Jon who founded that company, it's just a gem of a company, it's an amazing vertical B2B SaaS company. But I think in the story that they tell us when they started AppFolio, they're like, "We want to find a place where the money flows and we want to be really close to customers and we just want to ..." Well, they were engineers who had seen the light around customer development, just getting close to customers, just being in service to the customers, not just gold plating every technical decision you did. They bought in early to the ideas of test-driven development, pair programming because they believe that the quality ... you should never be worried about the quality. They just believe that quality wasn't something you sacrifice as the norm. It's just got to work.

(00:39:51):
They believed that was possible and when you think about it, those things are always debated. Like, "Oh, should we get technical debt or not? Or how much customer contact is it not?" These two founders basically are like, "That's it. We don't sacrifice on those things." They've done really well with that.

Lenny (00:40:08):
That's a thread I want to actually follow up on, is just the power of culture and values and things like that. But before we do that, let me just summarize maybe the top five attributes and kind of traits you just shared and then I have a two part question around this. I wrote these down. Basically the things you've found are true for the companies that seem to be best at building product and software and running product teams. One is coherence between what they're doing and what their strategy is. Two is strong opinions loosely held. Three is belief in the power of product. Four is the leadership is coherent, that their advice matches their words and their actions. Then five is just the necessary skills and experience in building stuff they're building.

John Cutler (00:40:51):
Contextual skills too. Yeah, exactly.

Lenny (00:40:54):
Kind of a two part question. One is if there's a pie chart of what contributes to this working out, what percentage would you say is just the people that they hire that contributes to them succeeding here? Then related question is just like can you change a team to be high performing? Does that happen or is it often just like this is just the way they are and their culture and their founders are this way and it's really hard?

John Cutler (00:41:18):
The pie chart, that's the problem. I mean, that is the trillion dollar question so I don't really have an answer. I have a couple thoughts on it. What do we know? We know that you can have a bunch of geniuses in the room and if there's not coherent leadership and there's not coherent structure in what you're doing, they'll fail. Okay, so we know there's a limit on one side of this particular problem and we know on the other side of the problem is if no one's done this before, who knows? Because how many startups were started by people who hadn't done it before, who had passion for doing something? Now, they made a lot of mistakes. Now, granted people would say, "All right, now after three failures, I'm going to tell you what we need to do to succeed," so maybe they have to fail a couple times to do that.

(00:42:03):
With the right things in motion, you can do that. Also, another data point. At a lot of companies that are known to be higher performing, they're one of two categories. Either everyone in the company is this extremely vetted genius at what they're doing, or they have a culture where people stay for three, four, five, six years, they build their career or seven, eight, nine years. There is a concentration of people who are very skilled, but they have a knack for bringing people up. They have a knack for taking someone who has some of the raw materials to be able to do it and making them really good at their job to be able to do it. I'm not going to throw out a percentage point into it. I'm just going to note that I think that the biggest challenge is that we all need to challenge our biases.

(00:42:46):
I do too. Four or five years ago, I would've said, well, personal skill's nothing. It's all the environment. There's people on Twitter who do this all the time. They're like, "Bad management kills everything. Skills aren't important. You should just be able to do anything with anyone." I used to be one of those particular people and I also have this sort of humanist bent to what I'm doing, and so I very much want to believe ... I'm always the person that's like, "Oh, we should give them the seventh chance." I know myself right to do that and I would suggest that there's people on the other end of the spectrum who could benefit from shifting a little bit to embrace some other ideas too. They're the people who are like, "Well, it's 100% their skill. We will hire complete A plus players all a particular time. Everything will work out as expected." Or they trace everything back to leadership anyway. So when anything's wrong, they're like, "Well, this happened under this person's watch, therefore they are a failure."

(00:43:37):
But how many companies in general will hire a string of highly qualified people into a particular department and then fail each particular time? I don't know. I don't have the answer for you on that one, but I think that everyone can benefit from challenging maybe their happy place, me included [inaudible 00:43:57].

Lenny (00:43:57):
I like that. It's like it's an optimistic perspective basically and anyone can change, anyone can improve. Don't assume that it's just not possible.

John Cutler (00:44:05):
And give it a shot and then can you create a coherent environment where maybe that could happen. Frankly, we're maybe getting into this later, there's a lot of companies that were flying high and are not flying high anymore. High performance is not this state you achieve. It's actually a continuum that you're always ... we have this in our personal lives too. We're flying high and we think we do everything and then we get to that point and then we go back down into feeling we don't know anything again and we feel those lows. That's kind of how I think about that particular thing.

Lenny (00:44:37):
This episode is brought to you by Vanta, helping you streamline your security compliance to accelerate growth. If your business stores any data in the cloud, then you've likely been asked or you're going to be asked about your SOC 2 compliance. SOC 2 is a way to prove your company's taking proper security measures to protect customer data and builds trust with customers and partners, especially those with serious security requirements. Also, if you want to sell to the enterprise, proving security is essential. SOC 2 can either open the door for bigger and better deals or can put your business on hold. If you don't have a SOC 2, there's a good chance you won't even get a seat at the table. But getting SOC 2 to your report can be a huge burden, especially for startups. It's time consuming, tedious and expensive.

(00:45:24):
Enter Vanta. Over 3000 fast growing companies use Vanta to automate up to 90% of the work involved with SOC 2. Vanta can get you ready for security audits in weeks instead of months, less than a third of the time that it usually takes. For a limited time, Lenny's podcast listeners, get $1,000 off Vanta. Just go to vanta.com/lenny. That's V-A-N-T-A dot com/lenny to learn more and to claim your discount. Get started today.

(00:45:55):
Coming back to the first question about people, and maybe you just answered this, but do you find that it's all about the people and who you hire and may be at the top that lead to the result at the company? Or you're saying it's sometimes the right amazing people? Sometimes it's the process, sometimes it's the market, [inaudible 00:46:12]

John Cutler (00:46:12):
It's the latter and I think that's why I called the damn thing the beautiful mess. Because I think we all have confirmation bias. We'll point to that company and say ... I mean, let me just use an example. Satya Nadella and Microsoft. You could argue you obviously have someone who's this very humble, very capable leader in that particular thing. But I imagine that at some point in the future there'll be books written about that and they'll say like, "Hey, it was kind of that. But you know what he did? He got rid of some bad people and created the air cover and set in motion the couple of strategic imperatives that we're going to let the things going." Now imagine Microsoft didn't have all the wealth of talent that it had, or all the wealth of structures or the good parts of the tradition, or let's say the bad parts served them well for a long time, but maybe they started to become a little bit outdated and then they were putting them in a competitively bad situation.

(00:47:07):
Even that situation, you can idolize that particular leader for doing it, but there's many things that could happen to be able to do that. There's this idea of great man theory, and this is something I talk about a lot where in great man theory success is the result of these highly influential, highly effective men, in a lot of cases, and that you can explain history through these heroic men. That's sort of a thing. A lot of people base history on doing that. I think that this, again, just the other perspective here is that things are a lot messier and you can't just trace everything to these sort of single heroes men in many cases that make it happen. I'm just presenting both sides of it as we kind of dig into it. I think, though, let's say you're a founder and you're trying to decide, "Should I invest more on processes or should I invest more in people?"

(00:47:57):
The first thing is introspection. What do you believe in really? Not just what do I believe in that you think the whole rest of the world ... I think the rules of the world are that blank happens. It's like what do you believe in and what do the people around you believe in and how can you be a coherent leader? You know what? You can nudge yourself a little bit away from your happy place, but you're not going to go super far. You're not going to go from a process-driven, meritocratic, X, Y, Z person all the way to I'm going to start a collectivist company where everything is sort of the consensus decision to do that. You're not going to do that. But I think it starts with self-awareness and then that's how people form their authentic leadership vibe and then they flex a little bit and then they embrace other perspectives. That's just my perspective on it.

Lenny (00:48:49):
That really resonates. It makes me think about companies, especially in the past couple years, that did really well because the market was pulling them and everything was just killing it. They're just growing crazy and you would assume it's the founder, the CEO, that's the result of that. But then when the market tanks, things stop working, and that's a really good, I think, example of just, it's not necessarily the person. Could just be other factors that make it feel like everything's going great.

John Cutler (00:49:16):
And people are great. There are people that have an outsized effect in particular companies. A great example there is people forget that, for example, leaders or CEOs also have a lot of formal structural power at their disposal to be able to change things. So well, there's that great man leaders, genius. They do have more knobs to move, and even then they're not the boss. You know what? There's a board, there's investors. If you talk to any CEO, they'll be like, "You think [inaudible 00:49:47]. I've got people bossing me around too." It's always a mix. That's the way I see it.

Lenny (00:49:54):
Which is why if things don't go well, their ass is on the line.

John Cutler (00:49:58):
Yeah, exactly.

Lenny (00:49:59):
Coming back to a thought I had as you were talking earlier about values and culture, it's interesting that wasn't on your list of just the power and importance of, I don't know, strong value, strong culture. Have you found that that's just not essential? What are your thoughts on-

John Cutler (00:50:13):
No, I think it's kind of the fabric that creates those other things. It's the fabric that creates coherence. Coherent around what? If culture is what we're doing, is what we're acting and the way we act is sort of a function of some of the belief systems and the culture and the value systems that we have, maybe I just almost take it for granted that that's sitting underneath those particular things. But here's an example where sometimes nuances matter. I'll just use Amplitude. We had some values and we had HOG, humility, and it's this idea of ownership and a growth mindset to do these things.

(00:50:52):
Ownership defined in an individualistic culture is going to look very, very different than ownership defined in a collectivist culture. What I find with companies is that ... and certainly we struggled to communicate this too, and I think we were pretty good at communicating where we sat on this particular thing, but a lot of times people write up these cultural documents and they're just like, "Well, this is our culture. We're into ownership." It's not saying much, saying that you believe in ownership without the addition of ... what we would do successfully and Spencer and other people do successfully is talk about the behaviors that represented that level of ownership, then that tells you something about what the culture is. Maybe when I was answering that, I kind of took that for granted. But there's a set of beliefs and values that sit underneath all those things, I bet.

Lenny (00:51:38):
When you think of the companies you work with over the years, and you don't have to answer this if you don't want, but when you think of the companies with the best culture or the best way, or some of the best companies in terms of how they build product, who comes to mind?

John Cutler (00:51:52):
I will mention some companies, but I'm not going to mention what people think in doing this. I'm just going to mention moments where I was like, "This thing is really clicking," and not because it wasn't easy-

John Cutler (00:52:00):
I was like, this thing is really clicking.

Lenny (00:52:01):
Yeah.

John Cutler (00:52:02):
And not because it wasn't easy, or there is a leader at Lego and her name is Angela. And when I'm talking to her, I'm just like, this person just has it dialed in. This is really hard. This business is transforming. They've got one of the biggest, most iconic brands in the whole world at their hands. And I'm sitting and I'm just going to single out her. Yeah, there's this situation here. It's not easy, it's not great. It's not high performing by any, you take a tiny Silicon Valley company. Yeah, it's hard to be Lego with thousands of people trying to build this and trying to take an iconic brand and turn it into something having to do with digital stuff. But I just want to give a shout out to her.

(00:52:47):
That's what I got to say to this question. I think of it more of these moments where I'm like, "Wow, this shits hard. It's not ideal." And that people are coming to work every day and there's a group of people in this room who are extremely well-meaning. And you know what? The impact of their work might not even be seen in their tenure at that company.

(00:53:06):
Some of these larger companies might take a decade to really work themselves through. And so I don't know, when you asked that question, I thought more about individual moments where I spent time with teams or like that team I mentioned to you in India where it's like everyone's super humble and whatever. So...

Lenny (00:53:21):
Awesome.

John Cutler (00:53:22):
Yeah, I'm not going to give a lot of names.

Lenny (00:53:22):
No, it's great.

John Cutler (00:53:23):
But just shout out Angela. She's doing an awesome job.

Lenny (00:53:25):
Go Angela. That reminds me of something I wanted to ask around the cultural differences between product teams in different countries. You talked about India, you talked about Lego. What have you found to be the main differences in how product teams operate and companies operate across different countries like say California versus Paris versus Australia?

John Cutler (00:53:46):
Yeah. And again, I'm not an expert in this and I think Erin Meyer wrote that or Meyer, I'm not sure how to pronounce her name, wrote that book, The Culture Map. And so you should just find what those people wrote because they're much smarter than I am about this. But here's the individual things that I noticed is definitely the individualist and what I would call almost like communitarian vibe.

(00:54:05):
The idea of individualism versus the idea of the team being sort of a community of people together. So that's one, and you pick up about that a lot when you go to different places. I mean, in the United States you'll find this situation where you've got this one engineering manager and they are brokering the projects with every single engineer on their team and everyone wants the promotion.

(00:54:27):
And there's this whole, instead of the PM working with the team, it's like the PM brokering stuff with an engineering manager to give everyone their premier project. No one's really working together. There's no pair programming. There's nothing like that. That's a whole other debate, but. And so that's highly individualistic and it might work in that particular environment.

(00:54:47):
In fact, it might be optimized for environments where you're burning through people every 18 months or 24 months or... Because you just want to put another cog into the particular machine so that you can grow and so you can do stuff. And that's an extreme example, but then you compare that to other parts of the world, it's much more consensus driven. The team perceives itself as a team having a team goal.

(00:55:08):
They have a team objective. And certainly even in the Bay Area, there's companies that are more the collectivist vibe and the more. So to say that it's just about the world is not really just right. So I think that yeah, the collectivist individualistic thing is important. I do think that certain cultures are much more sort of hierarchically oriented.

(00:55:26):
There's much more deference to the hierarchy in the particular where people are sitting and the information flows in a certain way. And some companies tend to that being more bureaucratic. And then some countries tend to that being like, it's still a tall company, but it's very much like you manager, you own this, you do this. So it's not like rules are flowing from the top down. It's more just a pretty big org chart. So those are some of the things that come to mind, yeah, as we're going through it. So yeah.

Lenny (00:55:55):
This relates a lot to something else. You often talk about that much of the advice on the internet and books, newsletters like ours is geared towards Silicon Valley type tech startups.

John Cutler (00:56:06):
Yeah.

Lenny (00:56:06):
And in reality, most PMs don't work at companies like that. A lot of them are going through transformations.

John Cutler (00:56:11):
Yeah.

Lenny (00:56:11):
They're trying to transform the way their culture works. And I imagine a lot of companies you work with are trying to get to that point and that just a lot of advice doesn't actually work for them. What have you found along those lines of just companies going through this and things you've learned there?

John Cutler (00:56:24):
So putting myself in the shoes of those particular companies, like I said, I think some of my most rewarding interactions have been with these non Silicon Valley companies. I certainly learn a lot when I talk to companies in the Bay Area and in the United States to do those particular things.

(00:56:41):
I think that the first thing to keep in mind is that those, let's just take these bigger companies for a second, big enterprise companies. Part of the thing is just realizing how much inertia they're up against when you're chatting them. So I do believe that there's some structural things that probably they could avoid, but then there's also just structural things that are just part of the game to do that.

(00:57:11):
So they'll be in situations where maybe none of the executives have shipped product before. They also assume that there's only one way to do things. Certainly in a lot of high performing companies, I have friends who will go and work at those companies. They're like, "Oh no, no one changes the rules here. We just do it this way at Amazon or we just do it," whatever.

(00:57:29):
So this similar thing happens in these particular companies, like there's only one way to do things. They've got these crazy annual budgeting cycles and planning cycles, or maybe there's a big IT industrial complex that they're sort of trying to transform into doing these things. So anyway, my point is, is that they, so many of these companies just have structural things that make it very difficult to just immediately convert that particular advice as they're doing that.

(00:57:59):
So I think the first thing that comes to mind with that is how to adapt that advice maybe for some of those larger kind of transforming companies. And I think that the couple things that I sort of remark on is that one, reps matter in those particular situations. So in many of those companies, they should focus on creating these sort of areas or pods where a company can, a team can get in the reps that they're trying to be able to do.

(00:58:29):
So it's sort of a little miniature version of that. And there's a whole problem with innovation labs. There's a whole problem with that kind of idea. But the idea that you can create these little bastions where a team can get in the reps is important.

Lenny (00:58:41):
And reps meaning shipping, shipping product.

John Cutler (00:58:43):
Shipping and learning, going through the full loop. Can they go through the full loop of what they're doing? And I think that the other thing that comes up with that is that most of those companies need to think of frameworks appropriately.

(00:58:57):
They'll read about these particular frameworks or what particular companies do or don't do. And I think that for a lot of those companies, they see adopting the frameworks as the end goal. They kind of look there. And sometimes maybe even you write a post, it's like, "Well, how does Figma work?" And they're like, "We use these frameworks."

Lenny (00:58:57):
Yeah.

John Cutler (00:59:15):
And so this company's like, "Well, we've got to use these framework." And I think that the way that I tend to think about frameworks is that they're more like a job aid. They're more like a learning tool that the team kind of uses to keep themself on track. But part of the thing is that those companies will reinvent the things they're using when things aren't working out.

(00:59:34):
So I think that that's another thing maybe some of those companies could benefit from doing, where we're getting kind of more into the kind of digital transformation or the big company space. But I think back to that particular question, I think you need to view a lot of advice coming from Silicon Valley just contextually. It's startup. There's a tradition of how these companies work. Many of them are just optimized very much for that first big arc of growth.

(00:59:58):
They've never really been disrupted. The only disruption has come from scale, not from being a legacy, a huge global brand or huge global business, and then being disrupted by new things. The only problems, not the only because it's really hard, but the problems have been primarily scaling. So they're kind of optimized for wrapping their head around that.

(01:00:20):
And then many of them are just pure digital product companies. And so I think this is a thing that a lot of the big rideshare and food delivery conglomerates are figuring out. They're like, " Oh, this is a lot harder than we thought." When you're dealing with moving people around and logistics and things, it's an order of magnitude more complex to do that.

(01:00:42):
So I don't know if that helps kind of explain my perspective on that, but I think that it's like you have to adapt the advice and you also need to acknowledge that for some of these companies there are these sort of just structural areas of inertia that they're trying to work through and that a lot of them maybe need to adapt this advice on the small instead of thinking they're just going to install all the frameworks or install everything they're doing.

Lenny (01:01:02):
Yeah, this is really, really good advice. I imagine folks are listening that may be working at a company like that. It feels like there's two sides to it. One is there should just be an awareness of this may not work at us, we're not going to be Figma.

John Cutler (01:01:02):
Yeah.

Lenny (01:01:15):
And let's just get used to that. And then two, this good reflection for me that I'm probably causing some damage with people reading a post on here's how Figma builds product. And then not adding a little bit of, maybe this won't work at your company.

John Cutler (01:01:29):
But maybe it can. And I talk about this a lot, this sort of I do believe there's sort of this fundamental attribution bias at play where people in these high performings don't acknowledge the amount that luck and inertia has been a part of what they're doing. And that the people in the big companies, or these not, these companies that believe that it's not the way that they can do that actually overestimate the kind of systemic drag in their organization and underestimate what can be possible.

(01:01:57):
And you think about that, we do that a lot in just our lives in general. We see someone being really successful and we'll say, "Well, but my situation is this." And when things are working for us, we're like, "I'm a genius. I'm a genius doing this particular thing." When things work, we're competent. When things don't, it's like the system and everyone else's incompetence to be able to do it.

(01:02:18):
So I do think that there's opportunities. I think there's another thing too, that there's a vast spectrum of companies. We paint some of these large enterprises on one end of the spectrum and then these other company, these modern product companies. But I brought up that plumbing company in Australia. You meet these companies, you know what? Their revenue is literally 50 startups. They are not doing bad. They are not doing bad.

(01:02:44):
And you know what? They're actually doing interesting things. One of Amplitude's customers, Anheuser-Busch has this thing called BEES. And BEES is basically a liquor distribution app. And it's literally one of the biggest B2B companies in the world. And you know what? Anheuser-Busch, it's like what? We're going to distribute beer because the pandemic. And so we're going to have, and I think actually they started to become more even used for logistics.

(01:03:06):
You're a bodega in one of those countries, you can order beer for doing it. So I think that we tend to kind of paint this world of, there's the big smoke companies and then there's the fast nimble companies, but there's everything in between. Another example is a lot of tech companies started 2000 to 2008, kind of are on their third or fourth act at the moment, second or third or fourth act, bought a lot of companies, they're trying to absorb them.

(01:03:33):
They might be trying a product-led growth motion by spanning all the different acquisitions they had. You know what? They are on top of their game. This is not a slouch company, but it's really hard for them to do that. Or we at Amplitude, we'd have a lot of, not old FinTech, but not newest companies. They're printing money and they're just embracing this particular thing. And then compare that to, I did a big Northstar session or more of a coaching session at NewBank in Brazil when there was just 15 people in a room and now they're massive.

(01:04:06):
So I think that we tend to paint things as a form of modern product adoption. There's the high performing companies and the low performing companies when in fact there's just a whole plethora and diversity of different companies riding different waves, adopting different things at different times. And many of them doing really wholesome, humble, good work, just dealing with their circumstances at the particular time.

(01:04:33):
So I think everyone should absolutely know how Figma works, for example. And then we need to try to boost the stories of Angela and her team or some of these companies that you'd never even expect. There's a company here in Santa Barbara that's like, they do refrigeration, use AI to refrigerate industrial facilities. And Carrie, who's the leader there, that company is one of the best leaders I know.

(01:04:57):
And Jesse, who's one of the founders is Harvard PhD student who understands AI doing these things. And I actually would encourage a lot of PMs to think about, look, especially in this economy, what are these unsexy businesses that are kicking butt and small here, it's in sunny Santa Barbara? So I don't know. I think that there's a lot more diversity than just the high performing, low performing spectrum. There's just a whole universe of fun companies out there.

Lenny (01:05:26):
Well, as you were talking, I was thinking about there's a small group of people like you and Marty Kagan and a few other folks that have worked with tons of different and diverse product teams and not just say, Silicon Valley teams. And I'm curious if there's any other names of folks you think listeners should follow if they work at maybe a non-Silicon Valley type team. Marty Kagan is who comes to mind first, but I don't know if you have anyone else. And if not, that's all good.

John Cutler (01:05:52):
Well, yeah, there's a couple people, but I feel like I should go back and just generate this full list for people. Maybe it would be interesting. Maybe I'll take that as an action item to...

Lenny (01:06:00):
Yeah.

John Cutler (01:06:01):
List a couple of these.

Lenny (01:06:01):
We'll put it in the show notes.

John Cutler (01:06:02):
And I'll give you an example of one guy, and his name is John Smart, and he wrote this book called Better, Sooner, Safer, Happier. And he, I think he was at Barclays Bank. I think that's how you say it in England. And what, he led this transformation. And then I think he's gone on to, he has a consultancy now for doing things. And the guy is just awesome to talk to.

(01:06:27):
He's really, really humble about what the thing book, the book is really interesting. And the thing that I noticed when talking to John is the order of magnitude of complexity of problems that has unraveled and what he had to put in motion to take an old school bank and at least try to get some part of some kind of transformation working in that particular company, I think there's a whole realm of people like that. And I'm going to list a, maybe I'll follow up with a couple more lists of people.

Lenny (01:06:57):
Yeah.

John Cutler (01:06:58):
Who can do that. And then I do think there's the people like Teresa Torres and others that have come up with a technique that is universal. You can teach an element of product thinking with her techniques or this opportunity solution tree or this continuous discovery thing that everyone can find accessible no matter where your company is at. And I have a lot of respect for those types of techniques because they're more universal versus some very arcane niche activity.

Lenny (01:07:36):
Awesome. Cool. And then we'll do our best to include whatever full list you come up with in the show notes.

John Cutler (01:07:41):
Yeah.

Lenny (01:07:42):
So I've been asking a lot of very specific questions. I want to give us a chance to kind of zoom out a little bit.

John Cutler (01:07:46):
Yeah.

Lenny (01:07:47):
And see what other advice you may have for product managers and the product community broadly. It feels like you're in this kind of reflective phase after working with all these companies and you take time, you have more time to think. So I'm curious what comes to mind when you think of just, here's advice I have to share.

John Cutler (01:08:04):
Yeah. I think kind of going back to the reps thing, I think that there's this fire hose of amazing information that's out there and I contributed to it and you contribute to it. And there's just, I mean, think what a time to be alive. You can literally just.

Lenny (01:08:04):
Yeah.

John Cutler (01:08:19):
Get these podcasts going. You can listen to anything you want.

Lenny (01:08:22):
Yeah.

John Cutler (01:08:23):
That's pretty amazing. And I was thinking to myself the joke as I saw you put this thing about Andrew Huberman about who gives these sort of life hacks thing. It's like there is absolutely a place for this type of content. I just want someone to summarize what the hell I should do when I wake up in the morning.

Lenny (01:08:38):
Right. Cold plunge.

John Cutler (01:08:39):
Can I be healthier.

Lenny (01:08:40):
Sunlight. Yeah.

John Cutler (01:08:41):
Yeah. I got my sunlight. I went from my sunlight before screens to prepare for our talk today.

Lenny (01:08:47):
Wait, actually?

John Cutler (01:08:47):
Yeah.

Lenny (01:08:48):
That's great.

John Cutler (01:08:49):
I have it in my habit tracker, sunlight before screens every day. Yeah, I got my watch that I got a couple, I'm on vacation. I'm between jobs now. So it's about all health.

Lenny (01:08:59):
Yeah. Optimizing.

John Cutler (01:09:02):
But I think that you need to keep in mind that this is a skill and skill is knowledge times practice mediated by your environment, the habits you form and the motivation that you have and the particular things. And so I think that I learned about that a lot working with learning experience designers in Amplitude that we tend to think that this is just a function of the knowledge that we pick up and the number of podcasts that we listen to. But really it's about going through this loop. So in Amplitude, we have this data informed product loop that we would teach, and it's basically, you need a strategy, you need to develop qualitative models, you need to add measurement to those models. So Northstar framework would be an example of a qualitative model. You need to add measurement to those models, figure out how you're doing it.

(01:09:48):
You need to prioritize where to focus. You need to design bets, you need to measure the impact of those bets. And then you need to circulate what you learned back into the strategy, back into your models, back into how you prioritize, et cetera. And it helps you figure out where you're kind of weak at the moment.

(01:10:02):
So for example, you need a strategy. Without that, nothing is possible. But you could have an amazing strategy and you don't deploy it with the right models, no one can prioritize them. We could do all that right, but you don't design any bets and can't ship anything. Oh, that's kind of a problem. But you could do all that right and you don't know the impact of anything you ship.

(01:10:18):
But you could even do all that right and not circulate the learning back in your company and then you're still not going to succeed in these things. So that's an example of when I mean by the loop. And so one thing you could think about for your career that I think people should focus on, and also in terms of sharing the content that they share.

(01:10:33):
So we're sharing a lot of content around knowledge and job aids, knowledge and job aids, and maybe a little bit of motivation, like how did that person succeed and do that and... But if you think about your career, just think about how many times can you get around that loop and what are you putting, because I worry that people are loaded up with knowledge and feel almost... I meet some of these leaders and they feel beaten up by the advice industry.

(01:11:03):
They feel beaten up that they can never be good enough. They cannot be like whatever company, or they feel like their company's never good enough, like they can't empower their team, they just can't follow anyone's advice. And so I think people are beating themselves up when I think that you shift for some people to focus to taking that knowledge and just getting that loop going for your teams or getting that loop going for your career or getting that loop going for your company is probably a pretty safe bet. So I would think that that's one thing that comes to mind.

Lenny (01:11:31):
Partly being responsible for some of that is what I...

John Cutler (01:11:34):
Yeah, me too.

Lenny (01:11:35):
My advice to people is don't feel like you need to read everything coming across your plate.

John Cutler (01:11:40):
Yeah.

Lenny (01:11:40):
It's instead wait for the moment when you need that thing. I'm working on SEO right now. Cool.

John Cutler (01:11:40):
Perfect.

Lenny (01:11:45):
I saved that thing about SEO, I'm going to go do it. Just like a just in time learning because you learn it so much better and like, "Oh, shit. I have to load all the stuff in my head in case it becomes useful."

John Cutler (01:11:53):
Absolutely. And I think one thing you think of is think about the podcast you listen to and think about that content is almost like you don't know what you don't know often. So I think that the challenge is, is that if you've been doing PM for a while, product management for a while, you don't really, I don't fit everything in my head.

(01:12:13):
I just, for example, pricing. I know pricing is a thing. I know that there's some people are amazing at pricing. I know that if someone told me like, "Well, you should just price it like this," my spidey sense would say, "You don't know what you're talking about because I know that there's more to it than just what you just said." You develop your spidey sense for things and you know that there's people. You have to dip your toes in understanding. That's the beauty of podcasts, your mind can get blown and then it puts in the back of your brain. You're like, there are some people who know a lot about that versus the founder who believes that they're going to figure everything out for themselves and is just like, no, it's actually a thing.

(01:12:47):
Pricing is a thing or you know what? Meeting design is a thing. There's people who obsess about it or service design is a thing or interaction design or strategy [inaudible 01:12:56]. So that's building on what you said, I think that there is a, especially if you're starting out, there is a definite value of almost seeing the 501 level courses or hearing that genius lecturer.

(01:13:07):
When you're in college as a freshman, I remember, I dropped out, but you would see the genius professor and you wouldn't understand any of it, but you'd know it's a thing and then it helped you guide the way you're doing. So I think that you should kind of balance out those things. But to your point, at the end of the day, you got to just put this stuff in motion somehow.

Lenny (01:13:25):
Yeah.

John Cutler (01:13:26):
How to do it.

Lenny (01:13:26):
And then just know that it's there when you need it. Find some way to store it.

John Cutler (01:13:30):
Yeah.

Lenny (01:13:30):
Save it. Maybe even just assume Google will find it for you.

John Cutler (01:13:33):
Yeah.

Lenny (01:13:33):
One more question along that same thread is you talked about the importance of going through these loops. At some companies, you just can't really, the company moves slowly, it's super waterfall, they plan really long. Do you have any advice for someone that's like, "Oh, I want to go through loops more often? This is really good advice."

John Cutler (01:13:47):
Point number one is you often underestimate what loops are available to you in that company. They throw up their hands. I've tried to mentor people like this and I think we've done a decent job, but the first thing I'm like, "Just don't throw up your hands and say it's all going to shit." Just at least document what was the.

(01:14:03):
So even if someone from on high says, "Build X," you can at least say, "You know what? Selected option is X. What would the one-pager look like if X was one of five options?" Write the one-pager. Go and talk to that executive and say, "Look, I know you've told me to do this, but what would we observe if this was working versus not working? I'm here to help you with that."

(01:14:27):
Great. You've got some metrics along [inaudible 01:14:29] is what you're doing. Just nudge it. Just one little thing. Hey, nothing's stopping you from writing down all the potential assumptions and risks that you have. Even if someone's like, "Forget all that, you're just going to build the thing." You've gone through the motions for doing it.

(01:14:44):
And I think people underestimate that because the environments are kind of feel like stellifying, I guess is one word, or stilted. And so they just sort of throw up their hands. But I would say that work with what you've got, because the last thing you want is to have a job opportunity two or three years from then and all you can do is shrug your shoulders and say, "I worked at a fucked up. I worked at a messed up company."

Lenny (01:15:09):
You can curse. It's all good.

John Cutler (01:15:10):
Yeah. Well, yeah. So you, "I worked at a messed up company. It was all shit." You're not really honoring yourself for doing that. So I'd say that that's my point about the fundamental attribution bias. Is it hard? Yes. Is it easier in those Silicon Valley companies? Well, maybe not. Maybe those are a shit show too. I've talked to plenty of them that are shit shows.

(01:15:28):
But do you have an opportunity to kind of nudge things forward in your space? Probably. And bring to the systems thing, is it true that some people don't have the privilege of leaving their company for whatever reason? That is true also. So many things can be true, but that doesn't mean that you can't try, I think to kind of almost write your portfolio as you go. Because if you wait two years, you're going to think it was just all a blur and messed up. Whereas the opportunities might be there in your day-to-day as you're working through.

Lenny (01:15:55):
I love how much your advice is optimistic and empowering and not just, "That's the way it is." And...

John Cutler (01:16:00):
Yeah.

Lenny (01:16:02):
And your point about how top tier companies can also be messed up and everything could be going to shit is very true. Especially a hyper-growth company where you're just...

John Cutler (01:16:11):
Yeah.

Lenny (01:16:11):
Constantly changing. It's also very chaotic and things are just breaking all the time.

John Cutler (01:16:16):
And there's people too who just assume it just has to be that way. I would say that one model that I use is the sort of the chronic and acute challenges of the companies. And especially in the last year, you meet a bunch of companies dealing with the same economic conditions. And I will tell you, no, not all companies are equally dysfunctional.

(01:16:34):
And no, not all high performing companies are equally beautiful in all roses. Legitimately some companies work down the chronic issues, which allows them to face the acute stressors, and other companies are just mired in acute issues to do those things. So it's kind of, again, both things can be true. It's like, yeah, there's nothing perfect in product. However, it is true that some companies are healthier than others.

(01:16:58):
An example of that is the companies that leaned in to responding to the pandemic instead of counting the days until it was over. Massive difference. I've seen this over and over, probably with 15 to 20 companies. The companies that were intentional in designing their response to the pandemic versus being like, "Just let managers deal with it, whatever, we're just going to sort it out," have had an order of magnitude better.

(01:17:22):
Now maybe the share price hasn't necessarily reflected it, but the happiness of the people there, they're going to come out of this stronger than the companies that were just like, "It's going to go back to normal and we're going to delay all these org design decisions until some future date." So I don't know if that tells you about high performing, but it's like the high performing companies saw the threat of what existed and then took deliberate steps, coherent steps to frame what their response would be. So that's just an example of that.

Lenny (01:17:54):
Awesome. I took us off track a little bit. I think you were going to go onto a second piece of advice.

John Cutler (01:18:00):
Yeah, I think that there's, well, okay, so one, definitely slightly annoy.

John Cutler (01:18:00):
Yeah, I think that there's, well, okay, so one definitely slightly annoying to me recently... I'll just get into the stuff that annoys me is that-

Lenny (01:18:06):
Let's do it.

John Cutler (01:18:07):
I personally don't think, I used to use words a lot, like product sense and product mindset and product things like that. I'm personally trying to do a better job this year about trying to unpack those things as legitimate skills and competencies. So if you think about product sense, what is it? Might be the ability to model problems, systems thinking, decision-making under conditions of uncertainty, facilitation tools that you have the ability to look at a competitive ecosystem and maybe see a thing and yeah, maybe there's a little bit of sense to it. It's like, "I want to help customers," or whatever. But I think that I'm trying to make a concerted effort to unpack those things into things that could be taught.

(01:18:50):
And that's going to certainly be part of my role at toast. The last thing I want to do is be like you have a product mindset or you don't. A great example, I was even talking with Craig just the other day and we were talking about how in some environments there's this should/can divide, which I really like, which is some people are just locked into the can. They're uber pragmatic people, so it's like, "Can we do this? Is it possible, given the debt, whatever constraints that you have?" And then there's people who for some reason go in and say, "Should we do it? What should we do here? If those things were not an issue, what should we do?" So it's very easy to... I joked with Craig, it's like it's so easy to go down the path of being like, "Well there's can people and should people, there's high agency people and low agency people, there's this person and that person."

(01:19:44):
It's much more interesting to go and be like, "Yeah, there might be a little bit of a personality component to it, but what skills is the should person bringing to bear on that particular situation?" Maybe it's a level of systems thinking, maybe it's a level of looking at the environment and being able to decouple the current tactics from maybe the optimal tactics for doing it. So that's one thing that I'm excited about, to do that. And yeah, there's a bunch of other things. The diverse perspectives, diverse mental models, maybe working with someone like you to try to raise up some of this more diverse... I really want someone to be like who's working at some company X, to be able to go and say, " Now that leader I can relate to, they're dealing with certain challenges that we are having to deal with at our company," and I'd love them to be able to have role models like that.

Lenny (01:20:41):
Like highlight people that aren't on Twitter that are doing the work.

John Cutler (01:20:46):
And not like meeting here. Not any of these particular people where they can say, "Well that leader..." I was speaking to someone recently, I wrote about this in my newsletter and she was just sort of forlorn. She was like, "I follow these people in this space and I know what my beliefs are and I know that that person has beliefs that I'm not sure vibing with completely. But the message to me is, the only way to get ahead in tech is to have those beliefs. And John, is that right? Do you need to believe this?" In this case, it was this very individualistic, very meritocratic kind of get ahead, push ahead type of vibe, which I respect that thought leader for putting out there, but this person didn't buy into it, which would've all been okay except she said, "Is there a place for me in this environment. Will I need to sacrifice my beliefs to get ahead?"

(01:21:42):
And I told her about some companies that I know. I told her about Carrie, who I just mentioned, who's been working on building the diversity, even in a small company. I told her about different leaders in different companies that, "Hey, there's some companies where it is a real team vibe and there's some companies that that", and she was like, "That's really good to know. So I think that that's one thing I want to work on in the next year, to make sure that people have role models and not the people talking like me, but actual... Maybe I could be a role model to people in my new role, but ideally there's role model leaders who they can relate to. That would be great.

Lenny (01:22:16):
Awesome. I love that. I feel like you just talking about that makes an impact there. Something I'm definitely trying to do with this podcast is not just have all the same people that we see on Twitter all day and have a lot of people people have never heard of, but if you have suggestions, let's definitely talk offline. I'd love to do more and more of this.

John Cutler (01:22:31):
Yeah.

Lenny (01:22:33):
So those are clearly some of the things on your mind as you're kind of in this period of reflection. I'm curious if you are going to keep writing and keep your newsletter up, maybe publish more books and then just broadly, how do you make time, while you have a day job, to write? Because a lot of people always wonder that. I'm curious if you have any pieces of advice.

John Cutler (01:22:54):
I'm obsessed with the writing, obviously, and I think a bit of background about me is I was pretty involved in music and song writing and it was similar kind of thing, I just liked writing lots of songs. I like that there's a certain buzz you get when you're creating. And in the case of music, it'd be like you record the demo and you get it out there. I think what people have correctly picked up on is because I have a full-time job, sometimes it'll be Thursday night and my kid's finally asleep and it's one in the morning and I'm just like, "I've got to write this post." And so sometimes it comes off as being a little bit rough or even accentuating the fact that I don't give them an answer because it's like two o'clock in the morning now and I don't want to give them an answer. I want to go to sleep to do these things.

(01:23:43):
So I think one of the things I'm going to hope to do is maybe be more deliberate about trying to provide at least maybe some mental models for dealing with the mess. I mean there's things like that out there. There's this thing [inaudible 01:23:57], which is a way to understand the systems and decision-making problems have, are you dealing with a clear system, a complicated system, a complex system, or a chaotic system? And I like things like that because that helps do two things I like. One, I want to give people something actionable to be able to address what they're doing, but it doesn't remove the complexity in the particular situation. So I have role models in that. This guy, Simon Wardly does this kind of mapping, which I think is great. There's these other techniques that I want to try to lean into and maybe develop some of my own that sort of help people have something actionable and embrace the mess, if that makes sense.

(01:24:41):
So for example, I recently wrote about something called the leadership, the Pyramid of Leadership, self awareness. And it's a simple model, but it goes deep how I want it to go deep. So the idea is that at first we know nothing about ourself and then the next level is that we start to become self-aware, but believe the whole world is wired just like we're wired. And then you go up to the next level and you believe that the world thinks different things, but you still think your way is the best way to be able to do that. So an example is, I remember talking to an executive and they're like, "People only stay because of their managers and because of their money. That's it." And I said, "Everyone?" They said, "Yes." "Do you believe that?" "Yes, because everyone believes it. It's a physical law of light." And here I am like, "Oh my God, I joined a company because the mission of the company or whatever."

(01:25:23):
So they're kind of stuck down on that second level where they believe that, "Yeah, the world thinks different things, but I'm absolutely right." And then as you get up to the top, you become a little bit more aware that there's other valid views and then at the top you're sort of like, "No, you don't dishonor yourself and throw away who you are, but you realize that this is a huge asset in the world, that there's diverse views that you can bring together to do really, really amazing things." So that's an example of some writing I've even done recently where I'm kind of like, it's a complex topic, but I try to make it more actionable to do that. So that's one whole thing. The other thing too is leveraging all the crap that I have. I think it's like 700, 800 posts, maybe 900.

Lenny (01:25:23):
Wow.

John Cutler (01:26:07):
I had this whole blog beforehand that I did it. And then I have these hundreds of images with these frameworks and then it's like 50, 70 talks that I've done floating on YouTube and then there's all the mural boards I made at Amplitude. It's a different model. So I kind of feel like I could pull some of that together to make it more actionable for people, give people almost like a meta guide to Cutler content so that they're not just dropped into me writing something at 1:00 AM and being like, "Oh, just another one of those." Like, "Damn it, you didn't give me an alternative to NPS. This newsletter sucks." I mean, frankly, I would say the same thing too if I just stumbled into the newsletter to do it. So those are a couple things that I'm thinking about for the content, definitely not going to stop doing those, sharing those things and doing that. So yeah, excited about this next year.

(01:26:52):
Also, the question about writing, I mean, one thing with a full-time job where most of my work is internal, obviously I need to respect my team. Again, I go back to that funny thing with Spencer, he is like, "You're writing about Amplitude." I'm like, "No, dude, I'm not writing about Amplitude. It's like every company has that problem." But if I'm working alongside people, I obviously can't be like, "No," I can't say, "Oh, your manager sucks." It's like Craig's going to read that to do that particular thing, but I can, what I'm really excited about is that part of my job will be involving doing a lot of writing and a lot of teaching, is hopefully work it out with the company so that I can share things that are not too specific about the company, but much more. They've got five different businesses at Toast, they've got all these people, so it's going to be a education every day. So I'm hoping to maybe get that inspiring my work in different ways.

Lenny (01:27:40):
Amazing. I imagine you might rename your newsletter The Beautiful Mess, slightly less messy.

John Cutler (01:27:46):
Yeah. Jam and Toast. The Jam and Toast decision. The addition.

Lenny (01:27:50):
Delicious.

John Cutler (01:27:51):
Yeah, there we go. 2023.

Lenny (01:27:52):
Also, as you were talking, I imagined a chat GBT three type chat bot powered by John Cutler content could be something to try.

John Cutler (01:28:01):
Oh, it could be a funny, yeah, I mean I'm sort of obsessed. I like the ChatGPT thing because I like having things, having a developer inspired by Hemmingway debate, a developer inspired by Tolstoy discussing how to resolve a GIT issue. So that's what I've been obsessed by lately is when you know how ChatGPT works, you can actually make it do really funny things. And back to the worldview things, it's actually really effective. This is a very actionable tip, if you feel you're heavily grounded in let's say the, I don't know, maybe you're like a hardcore objectivist or you believe in individualism, you can just type into ChatGPT and say, "Take this situation and interpret it by five different worldviews." And it'll be like, you'll get the humanist view and you'll get the communitarian view and you'll get the collectivist view. You'll do that. So anyway, it's a fun tool for that. It's really cool.

Lenny (01:28:52):
It is awesome. We checked the checkbox talking about AI, very, very hot these days.

John Cutler (01:28:57):
Yep. Score.

Lenny (01:28:57):
Score. One final question before we get to our exciting lightning round, I'm going to come back to the questions that folks asked you on Twitter. And there's a question that I saved up and the question, it was by Jeff Fedor and his question to you, he was, "What have you always wanted to say but couldn't now that you're between gigs?"

John Cutler (01:29:18):
Oh, that's good. So one thing is I didn't really need to filter myself very much when I was at Amplitude, which is kind of the beauty of the gig. I wrote this blog post, probably six years ago called How to Know You're Working in a Feature Factory. And I've always, this has all been my jam. The outcome, outcome and impact focus thing. So it's not like I've really had to hide anything. And so one thing I could say is the power of qualitative data, but even Spencer says that too. He's talking about early on in Amplitude you can rely a lot on qualitative data. So that wouldn't be all that controversial. That's a funny thing. There's not that much, I pretty much say what I say partially under the guise that I'm talking to so many teams. So therefore it's never about Amplitude. Absolutely not.

(01:30:07):
I think the one thing that I would change, I don't think that many people in the company would disagree with me, but one anti pattern I see a lot on the part of implementing analytics is that people go in and undertake this huge implementation. They want to implement all their events, they want to get, they want to treat it like this big project. And again, I don't think it's too controversial internally, but I think I might have been much more adamant to people that's just like use our free plan and get 20 events going and you might wipe them out later, but you don't even know what you don't know yet. You would see these companies that are really qualified companies and it would be a couple months of back and forth of them trying to document every question they have and every metric they need and everything that you had.

(01:31:02):
And I would watch them and I understood why they were doing that, but I really just wanted to shake them, which again, I wouldn't have done this because then I would've been talking about the companies I was talking about every day. I just wanted to shake them and just, "Sit me down with the developers at your company for three hours and let's like Hello world, a couple events here, this is, you could be getting value this whole time." And again, I don't think that people at Amplitude would disagree, but I think that that's, I wasn't going to talk about that all day because that would be sort of belittling customers who do want this big implementation thing. So pretty kind of inside baseball for analytics, but that's one thing that I was thinking about for Jeff.

Lenny (01:31:41):
Awesome. Great answer. Also actionable advice. How about that?

John Cutler (01:31:44):
Yeah, can do. You just need to find it. You just send me a message and say, "Do you have the actionable advice for it?" I probably do somewhere. I just maybe didn't have the time to organize it.

Lenny (01:31:53):
Good tip. You're going to get a lot of DMs. With that, we've reached our very exciting lightning round. I've got five questions for you. I'm just going to go through and whatever comes to mind fire away. Are you ready?

John Cutler (01:32:06):
Yeah, yeah, absolutely.

Lenny (01:32:07):
What are two or three books that you've recommended most to other people?

John Cutler (01:32:11):
Yeah, this one's pretty easy because they are fairly similar lately. So I really like the book How to Measure Anything, finding Intangibles or Finding the Value of Intangibles in Business. So that's by Douglas Hubbard. And the reason why I like that is again, at Amplitude the number of people who would come in like, "What are all our competitors measuring? We want to know exactly which metric to measure." And again, I'm laughing with you because I know you have these posts. Here's exactly the metrics that you should track. I really respect those posts and that's the power that you have. That's all really good. But what Hubbard reminds you is why the hell are you measuring things to begin with? It's to reduce uncertainty for critical decisions or to achieve certain objectives that you have. The reason why it's important to read that book is A, you figure out someone who's again, actionable, has thought this through. So he gives you kind of a framework to thinking about it.

(01:33:02):
But B, he really challenges this idea of when making decisions in conditions of uncertainty, you only need to reduce the uncertainty to an acceptable amount to be able to make the next decision that you need to make. And we never have, people are like, "Product is science." It's really an art, like a game that's being played out. You never have complete information to do it. So I think that's a good book to remind people about what... To be more creative and thinking about measurement instead of thinking about measurement and metrics is just about adopting the exact metrics that everyone has and doing that.

(01:33:36):
The second one I think would probably be Accelerate. So Nicole Forsgren, Gene Kim, Jez Humble, that's just one of the best books in the world about the factors contributing to performance. And it's built on many... It's six, I don't know, it's been out for a while now, 10 years? They did the Dora report, which was their yearly report where they did big surveys, like 10, 20, 30, 40,000 people responding to it. And Nicole Forsgren is an amazing scientist. So they structure their thing correctly. They would have a hypothesis about what is equal to performance and how all these individual practices contribute to it.

(01:34:19):
And then they've updated it over time. And I think that Google bought Dora, I don't know exactly how all the parts came into place, but that book is amazing, just sort of teaching you how to think about the idea of performance because they'll include things like the Western topology, which is your company operating a bureaucracy or... These certain culture elements to it, but then also the practices and things that you're doing. So that's a great book when you're trying to think about, "How do I model performance?" And then it's also an amazing book because you can just literally put the stuff into motion about improving your development practices and things you're doing.

(01:34:58):
And then I think probably the last one, man, I just love this book, this Jeff Patton book about user story mapping. I love what Jeff Patton did. He took this extremely simple idea, which is that you can lay out a customer journey and then organize, take a slice across that journey and develop it. And he gives this pretty basic straightforward method to do it. But I tell you, I'll go into companies like a year after they had Jeff in and learned this and they're still like buzzing about, "Hey, user story map." And it's just, he's a super humble guy and he would never outstate the value of this. He'd be like, "Yeah, it's just a journey map with a couple sticky notes on it." But I always, when someone's new at product management, I'm like, "Hey, this is a deceptively simple book. You'll learn this very basic idea, but it'll teach you a lot about product when I do that." So those are three that come to mind.

Lenny (01:35:50):
Killer suggestions, I love answers of books I've never heard of that seem really amazing. So you check the checkbox there. Thank you. Next question. Favorite other podcast other than the one you're currently on?

John Cutler (01:36:02):
I'm in a... I got a four-year-old. I don't really spend a lot of time... I'm the sort of, I'm such a lightweight, it's like I'll do knowledge project because Shane sent me, you know what I mean? I'll just listen to some, I'll binge things, but I do really like, I've actually been going through old episodes of Maggie Crowley's podcast that she did when she was at Drift. Lots of good guests and I really like Maggie's perspective and I like the guests that she had on there. So sometimes I'll go back to an old podcast. He does these really great memes and stuff, but Jason Knight actually has a fun podcast that I listen to and some of those things. So I think that, but realistically I'm not a huge podcast listener. I'd like to go back to a podcast that hasn't been out for a while, like Maggie's and just sort of catch up on all the guests because I thought that was really good.

Lenny (01:36:52):
Awesome. Jason, we love hearing that. Next question. Favorite recent movie or TV show that you really enjoyed?

John Cutler (01:36:57):
Oh man, again, I have a kid. It's nothing. There's this thing called, there's a show called Sunny Bunnies. It's these fluffy bunnies. That's really good. And then there's this animated series called Booba and he's this funny guy. I like Booba [inaudible 01:37:13].

Lenny (01:37:13):
Great. I'm sure these will be useful to families.

John Cutler (01:37:17):
Hardcore product, movies. Really, those are going to up your game a lot.

Lenny (01:37:22):
Yeah, I'm sure there's something to learn. Two more questions. Favorite interview question that you like to ask folks?

John Cutler (01:37:30):
Oh, so one that I like to do is, I do the behavioral questions like, "Tell me about stuff," but then I'll ask them like, "Imagine I'm interviewing a person you worked with. Now answer in there, tell me about of the same situation." So you'll be like, "Oh, Lenny, tell me about a time that you were faced with adversity and you did this and then you worked with the team to do it. And you would go through it and then you'd answer it.

(01:37:55):
And then maybe in the process of doing that, you mentioned someone you work with and I'll be like, "Now imagine that you're Mary, who you just spoke about, and things, and how would she answer the tell me about thing as it relates to you?" And so I think it can show some really interesting self awareness. Often people answer that question like they are the hero of the story and the other people are the accomplices in it, but then if you challenge them, "What was that story from the perspective of one of the people you worked with?" I think it's really interesting.

Lenny (01:38:21):
Awesome. [inaudible 01:38:23].

John Cutler (01:38:23):
So it is a behavioral question. I do think that's the right way and if you dig enough you can really get the depth of the story, but I do think it's fun to challenge people to see how flexible their thinking could be about that situation. I don't know if that's right from an HR perspective, but I like it.

Lenny (01:38:39):
I like it too. Final question, you mentioned you have kids. What's the best lesson someone taught you about raising kids?

John Cutler (01:38:45):
It's a challenge every day. I just think they operate better when they are fed. The kid as a product is like if you feed the product, then they were just, everything's better. And when you don't, like everything falls apart. So just have snacks with you. That's basically the advice that I have for people.

Lenny (01:39:04):
Very practical. Look at you, actionable advice left and right.

John Cutler (01:39:07):
Yeah. You got it.

Lenny (01:39:09):
John, and I feel comfortable calling you John now, I feel like I just got to know you. You're just like, "I'm John now." We hit our goal of, I think it's going to be the longest episode I've done. This was amazing. John, we've reached the end. Two final questions. Where can folks find you online if they want to learn more, reach out, ask questions if you want them to? And then two, how can listeners be useful to you?

John Cutler (01:39:32):
I still am using Twitter a fair amount I think, but LinkedIn could be good. John Cuttlefish on Twitter and then just John Cutler at LinkedIn. Yeah, I think what I would love to hear from people is just send recommendations of people we should hear more from. I think that would be really helpful. Even in the role that I have, I want to start like a guest speaker series to bring people in to talk to our team. And so I think that that would be something that I can work on.

Lenny (01:40:02):
Amazing. John, thank you so much for doing this. I'm really excited for this new adventure that you're on, and I'm excited to maybe follow up maybe in a couple years of just what you've learned from this next phase of life.

John Cutler (01:40:14):
I really enjoyed the show and thank you for having me.

Lenny (01:40:17):
Awesome. Thanks, John.

(01:40:20):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcast, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lenny'spodcast.com. See you in the next episode.

---

## The crazy story of landing Uber as a client | Jonathan Becker (Thrive Digital)
**Guest:** Jonathan Becker  
**Published:** 2023-05-12  
**YouTube:** https://www.youtube.com/watch?v=rG4zxf0CAv0  
**Tags:** growth, retention, acquisition, metrics, roadmap, iteration, experimentation, funnel, conversion, revenue  

# The crazy story of landing Uber as a client | Jonathan Becker (Thrive Digital)

## Transcript

Jonathan Becker (00:00:00):
There's a lot of different ways that we are beginning to use AI to do more with less, basically. The effect ultimately that we've seen from a human capital point of view is displacement. We have more people now than we've ever had, but the nature of the work that they do is more strategic. It's more about modeling, validation, asking the right questions, being focused around creative levers. And less so the like trench work of implementation and bid modifiers at the keyword level on Google search, and some of the really hardcore manual analysis we had to do.

(00:00:35):
On our creative group, we can come up with mockups, in literally, 1% of the time that it took. And so you still have to understand what questions to ask of the AI and be capable of iterating, but these rough drafts that you might show the artwork of to a client to say, "Do we like this more or do we like this more?" That's AI generated. It's really interesting.

Lenny (00:01:01):
Welcome to Lenny's Podcast, where I interview world-class product leaders and growth experts to learn from their hard won experiences building and growing today's most successful products. Today my guest is Jonathan Becker. Jonathan is a legend and an OG in the world of performance marketing. On this podcast, we've done deep dives into the many aspects of growth, including SEO, sales, conversion optimization, retention, product led growth, product led sales. But this is the first episode where we get super deep on paid growth. For the past decade plus, Jonathan and his team have planned, built, and executed more than $3.5 billion in paid acquisition budgets for companies like Uber, Asana, Square, Masterclass, Tempur-Pedic, and many more. And they've built their agency, Thrive Digital, into one of the preeminent independent digital marketing agencies. In our conversation, we get real deep into all things paid growth, including what's changed with recent privacy shifts, why focusing on creatives is the new biggest opportunity within paid growth. How to think about attribution, and what's changed there. What to look for in people you hire to run paid growth for you, how AI is already changing how paid growth teams operate, and so much more. Enjoy this episode with Jonathan Becker after a short word from our sponsors.

(00:02:16):
This episode is brought to you by Brain Trust, where the world's most innovative companies go to find talent fast so that they can innovate faster. Let's be honest, it's a lot of work to build a company. And if you want to stay ahead of the game, you need to be able to hire the right talent quickly and confidently. Brain Trust is the first decentralized talent network where you can find, hire, and manage high quality contractors in engineering, design, and product for a fraction of the cost of agencies.

(00:02:43):
Brain Trust charges a flat rate of only 10%, unlike agency fees of up to 70%, so you can make your budget go four times further. Plus, they're the only network that takes 0% of what the talent makes, so they're able to attract and retain the world's best tech talent. Take it from DoorDash, Airbnb, Plaid, and hundreds of other high growth startups that have shaved their hiring process for months to weeks at less than a quarter of the cost by hiring through Brain Trust network of 20,000 high quality vetted candidates ready to work. Whether you're looking to fill in gaps, upskill your staff, or build a team for that dream project that finally got funded, contact Brain Trust and you'll get matched with three candidates in just 48 hours. Visit usebraintrust.com/lenny, or find them in my show notes for today's episode. That's usebraintrust. com/lenny for when you need talent yesterday.

(00:03:35):
Today's episode is brought to you by AssemblyAI. If you're looking to build AI powered features in your audio and video products, then you need to know about AssemblyAI, which makes it easy to transcribe and understand speech at scale. What I love about AssemblyAI, is you can use their simple API to access the latest AI breakthroughs from top tier research labs. Product team that startups and enterprises are using AssemblyAI to automatically transcribe and summarize phone calls and virtual meetings, detect topics in podcasts, pinpoint when sensitive content is spoken, and lots more. All of AssemblyAI's models which are accessed through their API are production ready. So many PMs I know are considering or already building with AI, and AssemblyAI is the fastest way to build with AI for audio use cases. Now's the time to check out AssemblyAI, which makes it easy to bring the highest accuracy transcription plus valuable insights to your customers. Just like Spotify, CallRail, and Writer do for theirs. Visit AssemblyAI.com/lenny to try their API for free, and start testing their models with their no code playground. That's AssemblyAI.com/lenny.

(00:04:46):
Jonathan, welcome to the podcast.

Jonathan Becker (00:04:48):
Thank you. It's a pleasure to be here.

Lenny (00:04:50):
It's my pleasure. What we're going to be doing with this episode, is we're going to be digging real deep into all things paid growth, which we've never done on this podcast yet. And normally I actually skip this part, but I thought it'd be actually helpful for you to spend a little bit of time to give us a little bit of background on your experience in the space of performance marketing, AKA paid growth, AKA paid ads. You tell us what the right term is for this genre. But yeah, just tell us what you've been up to in this area over the past decade and a half, I think.

Jonathan Becker (00:05:20):
Sure. No, that's a great way to kick things off. And again, thank you for having me here. If I think about it, my experience goes back about 15 years into this space. I started off as a web developer. And as I built and structured websites for people, I became pretty obsessed and fascinated with the fact that you could build landing pages or homepages, or whatever it was. Basically the content on a website, and structure it in a manner where you had the chance to surface in organic, so SEO results more prominently. And as I became a practitioner of SEO, SEO really being my first love of marketing, I started attracting attention and people wanted to hire me on as a freelancer. And what I noticed is that as people started asking me questions like, what was the ROI of our SEO campaign? Or, how do I scale this, or whatnot? The answers to their questions ended up being a lot more aligned with what then was the biggest driver in the paid acquisition world, which was paid search.

(00:06:25):
And so I started experimenting with paid search. And what I found was that it was a tangible format and lever through which we could basically give people the types of results they were expecting from SEO, but that were obfuscated in terms of Google's analysis algorithm from an organic point of view being somewhat intangible. And Google slowly removing a lot of the data early on that allowed you to guess and test more easily. 10 plus years later, what started off as this freelancer consultancy that I started running in a walk-in closet in my old apartment, became 130 people. And we manage about $500 million a year in ad spend for small and large companies, including Uber, Asana, Tempur-Pedic. We've worked with Lululemon. Very exciting companies, mostly from the United States, even though we randomly happen to be based in Vancouver, Canada.

Lenny (00:07:26):
There's a number of threads I'm going to pull on there over the course of our chat. But you mentioned Uber and you told me that you had a crazy story about how you actually landed Uber as a customer. Could you share that?

Jonathan Becker (00:07:35):
I had been running Thrive for a couple years, and it was a very excellent regional agency in Canada with really cool local clients. In 2013, I got invited to go down to the TED conference, which was in Long Beach, California. And my friend Andrew Wilkinson asked me to join him at a dinner that night. I didn't know anybody from the TED community at the time. So we have dinner, and then afterwards as it goes at conferences, there's an after party. And so essentially I hop into a taxi, everybody else sped off in their cars, or however which way they were getting there. And as we're talking to the driver saying, "Hey, we're going to this place, can you take us?" There's a knock on the window and the person outside says, "Hey, I think I'm heading to the same destination. Do you mind if I hop in this car with you?"

(00:08:25):
And so we're like, of course. And I turn to him and I'm like, "I'm Jonathan. I run a 10 person agency out of Vancouver." And he says, "Hey, I'm Garrett Camp. I started a company called Uber." And so ironically, I meet the founder of Uber, the company that is in the process of disrupting the entire taxi industry worldwide in the back of a taxi cab. And what happened next basically changed my career forever. We end up at this party. At the time I was spamming Uber's referral program. Kind of a long story, but essentially I was using paid search to camp out on their branded keywords. And as people would sign up with my confusingly similar snippet to Uber's organic snippet, I was essentially siphoning off referral credits. So I would get $20 every single time someone signed up.

(00:09:18):
And I ended up making tens of thousands of dollars doing this. And so fast-forward, I'm getting a drink at the bar next to Garrett, and in my head I'm like, should I tell him about this? Maybe I can land them as a client. This would be really interesting. And essentially I tell him, I'm like, "Hey, I'm doing this. I'm adding zero value, but this is a loophole in your marketing system, and someone should close it." He essentially is like, "I need to report this to the board, but here's my card, write me what you're doing and we'll contact you." And so I get contacted by a bunch of his lieutenants. If you've read the book, Super Pumped. All the people that we dealt with at the time are in the book, and [inaudible 00:09:58]-

Lenny (00:09:58):
I watched the show.

Jonathan Becker (00:10:00):
Yeah, exactly. And they were like, "Hey, this is bad, you have to stop doing this. But can we hire you to solve the problem?" And so what started off as me running projects for local bars in Vancouver, or clothing stores, or whatever it was. Turned into me landing early stage Uber as a client, and really graduating us from competent professionals to leaders in our sector. And so it was a fascinating project, and we worked with Uber for 10 years.

Lenny (00:10:32):
That is an incredible story. I love the arbitrage game you're running there. It's basically siphoning VC money out of Uber. And I guess the lesson there a little bit is just sometimes it's this interesting combination of hustle in terms of just make some money, and also taking advantage of this opportunity you were plopped into.

Jonathan Becker (00:10:53):
Yeah. I think people often talk about entrepreneurs who have been successful and they comment that they're lucky. Whereas, I actually look at that situation and I think that you have to make your own luck. I could have been like, oh, cool, I met this guy in the back of a taxi and that was it. But I decided to take a risk, being that I could get embarrassed or nothing could happen, or they could shut down this referral gimmicky thing that I was doing. I had very little to lose, I guess, ultimately. But a lot of people just don't make these moves in life because they're nervous, or they're worried too much about what the downside might be. And so I very much was like, I'm going to shoot my shot here. And you put yourself in situations where everybody has luck, but you have to capitalize on it basically. And so that was an example of being willing to take a risk, and it paying off pretty big time I think.

Lenny (00:11:46):
Also, being at Ted, that seems like a good move. Networking, paying off. Love that he was in a taxi, that's hilarious. I was going to ask you about that. And clearly, he's doing some research [inaudible 00:11:55].

Jonathan Becker (00:11:54):
Yeah.

Lenny (00:11:58):
Let's start diving into the world of paid growth. And if you think about just paid growth.. And again, actually, what do you refer to this area as? Paid growth, performance marketing, paid ads?

Jonathan Becker (00:12:08):
There's a lot of interchangeable terms. Performance marketing is a common term. Paid acquisition is a common term. Some people think of those two things as growth marketing, whereas I see growth marketing as a bigger practice area within which paid acquisition sits. And then of course there's subsets, there's social ads, there's paid search, there's programmatic. And so there's a lot of different ways of saying the same thing.

Lenny (00:12:31):
I'm going to use performance marketing. I like that term because it really describes what it is. It's like marketing with you can measure performance. Let's see how that goes. As a channel, it's such an interesting mix of, on the one hand it's this incredible growth lever that allows basically any company to spend money and understand the ROI and acquiring the users. This thing that never existed before. Essentially Facebook and Google created these platforms. On the other hand, there's this sense that it's this drug that you start and then you get hooked on and you can never leave. And there's a lot of advice of just, avoid paid growth. That's just not a good healthy way of growing, especially as a startup. And so my question to you is just, how do you think about that element of it? And then even more specifically, what products do you find paid growth as a channel is right for and not right for?

Jonathan Becker (00:13:24):
Yeah, it's a really great question. And so, I think there's a couple different things that need to be unpacked here. Paid acquisition or performance marketing-

Lenny (00:13:33):
Performance marketing. [inaudible 00:13:35]-

Jonathan Becker (00:13:34):
... you can call it, can be seen as a drug, I suppose, when you are entirely reliant on it to fuel the revenue of your business. The analogy that I try and use here is that it would be very dangerous if I was advising you with your life savings and I told you to put it all in a single stock in the stock market. Stocks can be volatile. And as a result of that, your net worth would fluctuate quite a bit in the short-term and the long-term based on a lot of things that you don't control, like the external markets, or things that are happening within the performance of that particular company that you invested in. When I think about all of the marketing mix, so email, direct mail, linear television, performance, marketing, whatever it is, I think about it as investing capital with the expectation of a return. And in the same manner that I would not take all of your life savings and dump it into a single stock, I don't recommend putting all of your money into a single performance marketing channel, and then somewhat exposing you to the volatility of fluctuating CPCs or changing market conditions. I would agree with you that it is a drug, in a sense, if you have all of your eggs in one basket, and that basket takes you on a very intense rollercoaster in terms of performance. But when I think about the fact that Thrive manages $500 million a year, I think of myself to a extent as a fund manager, we are managing people's money with the expectation of a return. And part of the strategy is to diversify across channels. And so we decrease the reliance of any individual project on a singular channel and its performance.

(00:15:26):
And similarly, I always say to people that the first rule of performance marketing is not to forget about offline marketing and the classic marketing that works for organizations. In other words, direct mail can really work, email marketing works beautifully, SEO can really work. There's all of these wonderful things at your disposal. The real crash and burn scenarios that I've seen are these, not fly by night brands, but brands that figured out... Just like with Uber, I figured out this weird tie-in where I could make free money from their referral system. Sometimes people find shortcuts, hacks if you will, to scale rapidly because of one specific nuance of the Facebook ad platform, or something like that. And what they fail to see is that those loopholes come and go.

(00:16:19):
And so if they scale massively and their entire business is predicated on the performance of this one loophole that they found, or investing everything in a single channel, and then the conditions change, they're not going to be very happy and the business will suffer dramatically. And so when I think about this, it's a responsible channel mix, diversity, and understanding that you can't be overly reliant on performance marketing for the success or failure of your business.

Lenny (00:16:48):
What about the second part of that question of when you think about when companies come to you. What do you look for to help you understand this is going to be a really good fit for performance marketing and this is going to give them a lot of opportunity to growth, versus maybe not, maybe it'll be a small sliver but it's not going to be a massive success for them?

Jonathan Becker (00:17:06):
Yeah. I would say that the answer to that question is different at different stages of a company's life cycle. Early stage, look at what the company is doing, look at your own company. Have you established product market fit? Is this an idea that has yet to be tested, and are they entirely looking to performance marketing to scale everything? Are they at risk of it becoming an over-reliance on performance marketing? At a later stage we look at certain criteria that they might or might not possess. Typically, that will come down to resourcing.

(00:17:43):
The question at a later stage is not, does it work? But, to what scale can it work? And so we are looking at things like, do they have adequate creative resources and buy-in? Does creative resourcing tie into performance, and can we create a feedback loop there around testing? I'll talk to you about that in a bit. Do they have professional marketers on staff? Are there people who have experience doing what we do, that speak our language so to speak? Or is part of this an organizational educational, and creating buy-in through stakeholders process that needs to take place? Do they have technical resources? If we say, "Hey, tracking and attribution is broken, here's how to solve that." Can you implement it? And so on and so forth.

(00:18:27):
There's no one magic formula for what works or what type of company will be successful on performance marketing channels. Just as evidence of this, Google, which I think had a down quarter reported sales this week, and it was $70 billion in three months. And Facebook similarly just recorded yesterday evening, and it was $32 billion. That's $100 billion on just Google and Facebook in three months, and the majority of that revenue is from ads. This works really well for lots of different companies, it's just a question of at what scale.

Lenny (00:19:06):
Just to pull an thread a little bit more. Something I've heard from other guests is that paid ads are best for products where you get basically payback really quickly, basically to feed the flywheel of spend so that you're not sitting around waiting for someone to buy something in the future, or it's a small trickle of pay. How important is that, I guess? Do you find that you could just do paid growth for any company, it doesn't matter their business model? Or is there something you're like, okay, this needs to exist for you to invest serious resources? And even hire that team that you just talked about.

Jonathan Becker (00:19:37):
It's always nice when there's a quick turnaround on investment and return. And that's wonderful for like D2C or e-commerce style businesses where they're essentially taking the revenue to fuel additional inventory and operating costs. However, not all businesses work that way. And so, in a B2C or B2B lead generation scenario, we have to undertake pretty sophisticated modeling around these abstract concepts, like lifetime value. Which is difficult, because most businesses are relatively new that we work with, and so the idea of lifetime value is a misnomer. They don't know what that is yet.

(00:20:15):
But we have to model things like LTV to CAC, so cost per acquisition costs versus lifetime value and the period within which the payback occurs. You end up getting to a pretty sophisticated place where you can build out things like a lead scoring model, which predictively can determine in a statistically significant way the likelihood that one lead will convert to revenue over another. And so there are ways around the slower payback period that still end up being pretty accurate based on what you're bidding on today versus the latent revenue that will be accrued to those campaigns through attribution.

Lenny (00:20:58):
Do you have any just rules of thumb for someone listening and trying to decide, is paid a real model for us, either on LTV or CAC, or payback period? Or something just like, here's what you probably should have, especially early stage for you to feel like paid growth is going to be a great lever for you to use, and maybe a primary lever.

Jonathan Becker (00:21:18):
Product market fit. If you know that your business sells into audiences. Let's say you are a social media influencer or you had a really strong email marketing game, or organically your content surfaces within Google search results. Or, you did a lot of direct mail and linear television and billboard advertising and that worked. If other things work, it is highly likely that paid acquisition will work. The issue for most companies is in this incorrect assumption that the data that is provided through paid channels allows you to have full end-to-end understanding of attribution. Which is wrong, it's never been that way. And the other aspect of this is the patience to understand that every business is unique, and these metrics that we know are important are different for every business. Lifetime value, like propensity to repurchase, ROAS, which is return on amount spent, CPA, CAC, all of these different things are different for every business.

(00:22:24):
Even if I worked with two hotels in the same city, they would have different results based on the nuances of their budget, their brand, the market that they sit within, the services that they offer, and so on and so forth. I think that everything else, the main problem here is that nobody should expect an overnight turnaround with performance marketing. It is a very difficult channel to manage, and that's why people hire experts like us to help them with it because it's a never ending problem with constantly changing issues. It's always been like that, that's not a new thing since pandemic, or whatever. And it will take some time to work out what works.

Lenny (00:23:07):
I have this framework of there's these four growth channels, basically growth engines is what I call them. There's paid/performance marketing. There's SEO, there's virality in their sales. And essentially there's some companies whose growth is almost primarily paid. A few that come to mind are booking.com, which we know well at Airbnb, which is almost all paid growth driven. Credit Karma comes to mind as a classic paid performance marketing. I keep coming to paid growth as my term, so I'm just going to stick with that. TikTok initially was very performance marketing, paid growth oriented. Wish was another one I think about.

(00:23:42):
And I want to talk about how much things are changing within this realm. But before we get there, do you think there's still an opportunity for startups to emerge where they get to scale almost exclusively through performance marketing? And this question actually came from Twitter, someone tweeted this randomly the other day. And I was like, oh, that's a great question for Jonathan. And by the way, her name is Liz.

Lenny (00:24:00):
And I was like, oh, that's a great question for Jonathan, and by the way, her name is Liz Georgie asked this question, so there you go.

Jonathan Becker (00:24:06):
I'll put it this way. Every unicorn from the 2010s era that scale did performance marketing, but not everyone during that time who did performance marketing scaled. So I want to remove the bias here that just because all the successful organizations did this didn't mean that it was a magical channel for everyone. We had plenty of projects that we worked on that flatlined during that period. And so the sense that there was a period of time where this was easy or it worked on any project is not correct in my opinion. With that said, we see companies that are spending millions of dollars a month on performance marketing channels like Google and Meta still, despite all the ups and downs that they have faced and they do so profitably.

(00:24:55):
And I think there's some really great examples of companies that have scaled in relatively recent times, almost exclusively through paid. Grammarly is a really good example of this. They have been good at solving for this problem that exists around understanding the cost per acquisition versus lifetime value, how sticky customers are, predicting how much revenue can come from a customer and backing out into therefore how much we can pay per click and per lead and so on and so forth. Athletic Greens is another good example. So Athletic Greens is actually a pretty old company. I think they've been around for 10 years. I think they have retail distribution. I think they have done a lot of the more classic marketing things that are important in terms of developing that channel mix. But I think the amplification of that brand really, really gained traction quite recently where now everybody knows what Athletic Greens is, and that's because they're buying loads of ads on TikTok. They're buying loads of ads on other social channels like Facebook. They're investing in podcasting partnerships. But this is all digital paid acquisition.

(00:26:07):
And so it had a wonderful effect on this really interesting business that they had already built. So yes, it's still doable. We still see people doing it, and I think that there's been a bit of a reckoning in the performance marketing industry pertaining to things like privacy and the changes that Apple made and people being very creeped out at how their data is being used rightfully so. And then obviously the economy in 2022, we had a terrible macroeconomic shift where interest rates rise and inflation's out of control. And so of course the first thing that people cut are typically marketing budgets and we see Facebook and Google and other ad channels directly suffering from that. So all of that said, these storms pass. And so when the economy improves, generally speaking, I imagine people will go back to trying to find as much inventory from a pay per click point of view that they can purchase as possible and figuring out the economics of how to do that.

Lenny (00:27:08):
I was definitely going to ask about that, and I love that you touched on it, just clearly a lot is changing in paid growth/performance marketing recently. You talked about the privacy stuff, you talked about COVID kind of shifted the way people spend and kind of dropped and then came back. So my question is who are you finding has the most success these days in performance marketing? And I will plant one seed, which from the examples you just shared, it feels like it's mostly companies that are very efficient. I think Grammarly, they're just super efficient as a business. And then I think Analytic Greens, they're a sponsor and their negotiations for sponsoring is just like, okay, here's the number that makes sense for them financially, and they're not going to go anywhere above that.

Jonathan Becker (00:27:49):
Yeah. Because they know, they understand how many impressions they'll get and on average what the quality of impression is and how many dollars they can put behind that before it has a cliff in terms of ROI.

Lenny (00:28:05):
Exactly. So broadly, who do you think is having the most success now with the changes and then generally, what should people know about what has changed in the past say year in the space of performance marketing?

Jonathan Becker (00:28:18):
I'm not going to really be able to point to this company is really getting it right and I think that you can do that, but it's like saying, a friend of mine who recently on Twitter tweeted this funny thing where he was like, this is the number that I used to win the lottery said every successful founder ever trying to give advice to other founders. And so in other words, just because they won the lottery doesn't mean you're going to be successful picking the same number.

(00:28:43):
To that extent, there is a bit of a playbook around modern day performance marketing, and that includes everything from really stringent and rigorous creative testing and thinking about that correctly to understanding the subjectivity of attribution and its strengths and weaknesses, doing a lot of work around validity of these campaigns. So really just the measurement and whatnot. Companies that can do those things and then understand their own marketing economics, in other words, quite basically how much can we afford to spend in acquiring a customer on any channel before that acquisition is no longer profitable. So really focusing on the profitability of the bottom line and not just break net growth, for instance. Companies that have those capabilities and see the world that way tend to be successful in performance marketing.

Lenny (00:29:39):
When you were giving your intro, you talked about how you initially started doing SEO, that's where you started, and then you moved to paid growth. Well, how do you think about those two investments as a founder trying to decide which direction to go? What would your advice be of spend your time here versus there if X, Y, Z?

Jonathan Becker (00:29:56):
When I'm asked a question of should we put money into organic search or paid search? My response is often that they're actually not mutually exclusive to one another. So it's a great idea to do both, and that backs into my strategy of diversification of channels. So don't build up exclusively in one area and create volatility within your marketing mix essentially. SEO is a wonderful marketing capability when it's built out correctly. I think the issues that you run into are cause and effect related. So one of the things that people really like about performance marketing theoretically is that we can spend a certain amount and then if we're modeling things correctly, we can essentially determine how much revenue is generated from the actions that we took. Finance teams love that, C-suite teams love that, they can build projections, they can budget around it. There's some degree of predictability around it if it's done properly.

(00:30:52):
Search engine optimization is different in that the attribution can be tough. It's difficult to determine whether ultimately the actions that you took contributed to a rise in organic traffic. You have to essentially correlate that. And the reason is because when you build clusters of content and it's grouped thematically and you're targeting buckets of keywords, whether they're long tail or head keywords, whatever it may be, you can publish all of that on your website. Google still has to crawl it. They run it through their analysis algorithm, which is comprised of 200 different signals, of which maybe 20 to 30 have been publicly disclosed. So it's a bit of a black box.

(00:31:37):
We don't really know ultimately what ROI comes off of that unless you're very sophisticated, like probably one of your other guests, Ethan, in terms of measurement. Whereas paid, the ROI is still a difficult problem to solve, but there was a lot more of a linear relationship as it relates to attribution. And so paid being tangible was the reason why I leaned heavily into paid and ultimately away from SEO. But I do think that if you do SEO properly, the payoffs are indisputable and it is certainly an important part of a modern media mix.

Lenny (00:32:18):
You mentioned this earlier, I've heard this more and more recently that one of the biggest levers these days in paid growth is around creatives. It's not tooling or smarter data, or you tell me if I'm wrong, but it's just getting better creatives. And so I'll let you actually explain, what are creatives? There's a term creatives that people outside the industry don't really necessarily get. And then broadly, what should people be doing to optimize the way they approach creatives?

Jonathan Becker (00:32:46):
Certainly. So when we say creative, we're referring to the assets that power typically visual programmatic or pay per click campaigns on social channels or display networks. And so literally the motion graphics ad that you see on Facebook, the user generated content that you see on TikTok or a static ad that you might see that has a pretty picture in it or whatever. And so I think that when we talk about creative as a big lever around efficiency and optimization, the underlying conversation there is that over time our industry has been heavily automated. So a lot of the levers so to speak around performance have been automated by Google and Facebook over the last seven to 10 years. That's because originally when you ran these campaigns, you needed to have a rocket scientist in front of them. It was so complicated and there were so many different things that you could get wrong, and their solution, the channels like the big tech company solution to this is figuring it out for you. So eventually Google wants you to say, hey, I'm Google, give me your credit card and I'll take care of everything else. Facebook-

Lenny (00:33:57):
And the URL to point people to, and then we'll do the rest.

Jonathan Becker (00:34:00):
Yeah. I don't know if that's a great idea for consumers, by the way. But in the meantime, there's certain things that have just been fully automated. In the context of creative, it's still one of these things that for now is not auto-generated in the world of AI and all the changes that we're seeing. Maybe that's something that will change. But for now, essentially creative directors and their teams are concepting and producing different types of assets. And so there's a bunch of problems that we typically see when people come to us. So number one, performance marketing and brand marketing in a lot of organizations are two different things. And the designers that occupy brand teams bandwidth and whatnot often don't have a sense of how paid acquisition works.

(00:34:48):
And so one of the pitfalls of working with certain companies or the mistake that they make is the design team will hand off a file full of random assets for paid acquisition without any sense of how the channel works. And what I mean by that is these days we're using the analogy, the classic analogy of the funnel to organize our thinking around creative assets. So you can think about this as generating intent at the top of funnel and capturing intent at the bottom of the funnel. When I think about an experience that I want a consumer to have on Facebook, audience targeting and creative, I think about us beginning a conversation at the top of funnel creatively with an audience, having that conversation change as we say different things, and the audience that we're targeting ultimately graduates through different behaviors on our website from one to another, and then ultimately it resulting in an end to the conversation where they take an action hopefully that the brand that we're working with is looking for.

(00:35:56):
And so there's a clear beginning, middle and end to that. And one of the major pitfalls that we see is that certain brands just dump one homogenous message into all of their targeting. You see the same ad over and over again. It creates banner blindness and it's a total lack of efficiency. The antidote to that is to have resources dedicated to paid and essentially iterate upon the creative assets themselves based on the data that we see coming from ad sets and campaigns in various channels. And so what that means is that you have to experiment. You have to take a bit of a scientific approach, although it's a bit of an art and a bit of a science. You have to try and isolate variables, maintain similar conditions across targeting, and then determine which style and feature of an ad performs best at which stage of the funnel versus which audience. And the results that we see are dramatically different from brand to brand. But if you are not undertaking rigorous testing in conjunction with how you are driving the iteration and design of your ads, then you will not make progress essentially.

Lenny (00:37:11):
Is there a specific example that comes to mind here as something we did that just dramatically changed the impact of a change to a creative? Or if you can't think of one, are there just specific tactics that you can suggest for people to improve the way they approach creatives?

Jonathan Becker (00:37:28):
Yeah. So I think from a testing point of view, let's say I was running ads on Meta, beneath the campaign level when I create a campaign, the structure that my testing might take would be that I would have an audience, a single audience at the ad set level, and then I would have two nearly identical creatives within that ad set. The only thing being different across those two creative assets is a single variable. So it might be the copy, it might be an image or whatnot. That allows us to isolate a lot of variables and really test into one singular change across two creative assets. There's a lot of nuance to this. So sometimes the ad-serving algorithms, even when we set up a test structurally in that way, we'll serve one ad a different number of impressions than the other ad, in which case we then have to say, what is a leveling factor that allows us to look at these two ads equally, even though one received dramatically more impressions than the other?

(00:38:31):
This becomes where it becomes subjective in terms of how you want to determine success. But a good example is looking at the click-through rate, which is essentially a ratio or a metric like impressions until conversion, which is a leveling metric that allows us to determine, even though in a scenario where two ads facing the same audience within the same campaign received different numbers of impressions, we can still measure the efficiency or effectiveness of one ad over the other using metrics like that. And so from a testing point of view, I think that this is one way that we might look at trying to assess ad performance so that we can gather learnings, send that back to a creative team and say, hey, it turns out that when this copy is used at this stage of the funnel, it converts 50% more frequently than this other copy.

(00:39:26):
So let's now take that copy, use it as our base copy and challenge it with a different type of copy and see if we can continually iterate and refine. So that's a very practical example of how ad creative testing might work on a channel like Meta. You asked for specific examples where we've seen an unlock. There's two that come to mind. Several years ago we realized that highly produced ads from brand teams, and there's nothing wrong with brand teams, we work with them all the time. They do amazing work. I think we're just trying to work as a singular unit as opposed to being fragmented. But a lot of the brand guidelines of different companies would end up yielding these highly polished assets. And when you launch those on Instagram back in the day or something like that, what we found is that they would always underperform next to user generated assets.

(00:40:23):
So a brand that essentially has an influencer in front of it that says, I tried this product, I love it, I'm filming this ad from my iPhone. Look, check it out. Here's the product, here's me, I'm better off for it. Whatever it is that they're talking about. The unpolished iPhone, mobile phone creative, suddenly we realized massively outperformed these other channels because there was an authenticity to it. And rather than the brands themselves saying, hey, trust us, our product is great, here's a third party essentially validating what is so great about these brands, basically. So I can't speak to specific clients because I'm not allowed to talk about the work that we've done in large part, but that would be one example. And another example is we worked with a furniture company several years ago, which scaled dramatically, but they were having difficulty early on thinking through how to scale social ads.

(00:41:21):
And so paid search worked really well for them. Social ads, again, they had these highly produced styled rooms and one of the owners had their dog in the office all the time, and so they have these models sitting on furniture or whatever it was, and they would take these beautiful styled shots of their furniture in a room and one of the art directors was like, put the dog on the couch and let's take some photos of dogs on furniture, which made it more playful and approachable. That one change resulted in a total unlock of their performance on paid social channels. It would double or triple the ROAS that we were seeing type thing. So it's these minute differences that you can test into that ultimately can drive performance.

Lenny (00:42:04):
That reminds me of Airbnb. The photography team found, and actually the photography team was initially including people in the photos of listings, and that was the [inaudible 00:42:16] images of listing photos. And it turns out when there's no people in the listing photo, much higher conversion. And the theory basically people don't want to see other random strangers in a place they're going to sleep, and that was not expected.

Jonathan Becker (00:42:29):
That's a really great example. And so the question becomes, as a company and as a brand, do you arrive at those learnings anecdotally by accident? Is it the brilliance of one person on the team that the whole brand is predicated upon in terms of performance? Or do you put a very rigorous structure around testing and the iteration of assets and how to determine whether something works over another thing that is a process that yields the outcomes that you're looking for? And so a lot of times with agencies, people talk to us about the obvious hard skills that we have, but the soft skills are around process that can be deployed, that can actually be the difference between being highly sophisticated or unsophisticated. Internal teams do this too, but that Airbnb example is a great illustration of how if you put the right testing in place, you can yield an outcome that becomes an unlock for performance.

Lenny (00:43:28):
Getting even more tactical with that idea of testing a bunch of creatives makes me think about a story from chatting with a guy from Wish who's had a growth at Wish about how they uploaded hundreds of variations. And I think Wish is the epitome of the opposite of brand highly polished ads or it's just the most ridiculous looking product with just banners and numbers and prices and crossouts and all kinds of stuff, just anything that would take to get people to click. Is there a tool or process that you can point people to to help them do this testing on creatives or is it mostly built into the existing tools now and there's nothing really fancy about it?

Jonathan Becker (00:44:04):
We get asked this a lot and I think there are tools for different types of functions that we undertake in the process of running paid acquisition for different brands, but these days most of the testing that we do is within the channels themselves. So Meta ads, Google Ads, I keep touching on those two specifically because they're the most advanced in my opinion. They're really powerful. The good news here is that you don't necessarily need some exotic tool to do sophisticated creative testing. You can do it in platform and you can use the structure that I just kind of outlined as a starting point.

Lenny (00:44:43):
You mentioned Google and Facebook. What is your take on TikTok and YouTube and maybe Snap? Do you recommend people go there and there's a big opportunity? Do you think it's overblown? Do you think people should just take Google and Facebook basically at this point? What's your general advice?

Jonathan Becker (00:44:59):
So when I say Google and I say Facebook, I'm talking about the Google ecosystem of channels inclusive of YouTube. And when I talk about Facebook, I'm talking about Facebook, Instagram, and probably eventually WhatsApp, which I think will probably launch ads later this year. With all that said, some interesting opportunities these days really exist on channels like Amazon and TikTok as well as a number of other challenger channels I think. Snap I'll talk a little bit less about because I think really there's just fewer and fewer people potentially using Snap. There's no knock on Snap. I use Snap, I like it a lot, but at the same time, most individuals or organizations tend to want to place ads where there's a lot of views and engagement and the king of this right now is definitely TikTok. And so TikTok faces its own set of challenges and arguably there is as much an opportunity there as a barrier at the moment.

(00:45:58):
I love TikTok. I'm a consumer of content on TikTok, not a producer of content on TikTok. Their ads platform kind of reminds me of where Facebook ads was like six, seven years ago. It's not super sophisticated and attribution is not great yet, but you can get cheap CPCs because there's just fewer organizations advertising there. Fewer companies have figured out how to make that work. And same thing with Amazon. Amazon is a bit of a bespoke channel. It doesn't work for a B2B SaaS company. It's more specific to D2C I would say. But essentially those channels are wonderful. They're not at the point yet where they're kind of ubiquitous. Every single advertiser that has ever worked with us I think in the last 10 years is for sure on Google. Everybody does that. And then the question is, what else can I invest money in with the expectation of profitability?

(00:46:53):
And so TikTok and Amazon, and even if I want to break out YouTube, they tend to be a little bit more specific and they definitely work, but not for everybody yet. And so the question becomes, will TikTok become as prominent as a social ads platform like Meta Ads? And we just don't know yet. What we see working very nicely on TikTok, by the way, are these founder led brands where the founder is the ambassador and they're doing those handheld videos with their iPhone. They're talking about the merits of the products that they make. They're talking about the problems that they solve. They are great at cultivating a following. Their content is highly engaging. Those types of organizations crush it. Also, companies that got really good at partnering with influencers. So we haven't talked about partner marketing that much, but affiliate marketing companies got into this early, and then influencer marketing networks are all over this. But essentially having these third parties be an ambassador for your brand in an authentic way, partnering with them, having them generate the content. And that's the nature of the partnership. Stuff like that seems...

Jonathan Becker (00:48:00):
... And that's the nature of the partnership. Stuff like that seems to work quite well.

Lenny (00:48:05):
Awesome, I love those bullet points of just what is likely to work on TikTok.

Jonathan Becker (00:48:05):
Yeah.

Lenny (00:48:09):
Just broadly, would you say TikTok advertising today is underrated, overrated, or just right?

Jonathan Becker (00:48:16):
If you are e-comm based, if you're wholesale, retail based, anything direct to consumer, you have to investigate TikTok and try and figure out whether there's a way of promoting your products there, basically. It's a massive, highly engaged audience with somewhat specific demographics. It's a very exciting opportunity. Other brands need to pay attention to this and figure out what their entry point is going to be. And just because the innovation hasn't happened for B2B SaaS yet on TikTok doesn't mean it won't. TikTok wants that to happen, and so the question becomes how. And so someone will unlock that, and they'll make a billion dollars because of it.

(00:48:59):
But I wouldn't recommend that channel to everybody yet, and at Thrive for instance, we don't have a huge amount of people coming to us yet saying, "Hey, I'm spending $750,000 a month on TikTok, can you help me?" Type thing. The other problem with TikTok is that it's extraordinarily creative, asset dependent, and heavy. And so you are launching net new assets several times per week, it is hard for creative teams and brands to produce that much content. It takes a machine, and that's expensive, and so that all factors into the cost of not only just the ad dollars, but the creative resourcing and investment that's required to power that. So it can be done in a more nimble manner if you're spending less, but you can't really get to a million dollars a month on TikTok without having a huge amount of creative being pushed to that channel.

Lenny (00:49:56):
Awesome, that's really good advice. I want to chat out about AI soon, just because I imagine that could help with some of these things. But you mentioned B2B SaaS, and I wanted to ask, I imagine Google is the primary channel for B2B SaaS, and if not, or if it is, where else do you find there's value in spending money to drive growth through B2B SaaS, which channels and ad networks?

Jonathan Becker (00:50:20):
So I'm agnostic here in terms of where people should be spending money. I see this world in terms of impressions and clicks, and does that conform to the marketing economics of a project that needs to be achieved in order for it to grow. It's less about where to place your money and how to think about the placement of those funds. And so the common mistake that we see as people build out a funnel, so to speak, for B2B lead gen projects, or B2C lead gen projects, is they'll be overly reliant on the first of a sequence of metrics that ultimately yields a sale.

(00:50:57):
So typically it's something like cost per lead, marketing qualified lead, sales accepted lead, there might be a couple more metrics there, and then eventually a sale occurs. And so that the thinking is that, okay, for sales to occur, I need more leads at the top of the funnel. The more leads I have, the more marketing qualified leads I'll get, the more sales accepted leads get, and ultimately the more opportunities there will be and the more revenue will generate.

(00:51:24):
And so if I think about this world of lead generation on performance marketing platforms as a function of cost per lead in that sense that I just described, then the tendency is always to want to drive down the cost per lead, thinking that that's the efficiency, I can get more cheaper leads and that will yield more revenue. When in fact it turns out that if you flip that conversation on its head and say, not all opportunities and sales are equal, and instead of focusing upfront on a cost per lead, I now want to focus on what is a high value customer, so the cost per lead is actually higher, but the ROI of targeting those people is also higher. And so to get the higher quality leads, it's not a function of CPL.

(00:52:15):
And so that is a very common pitfall that we see when people come to us. The antidote to this, it's interesting, so Thrive developed an ETL tool, an extract transfer load tool called Thrive Stack. It's not commercially available, but if you wanted a commercially available version of this, you can use something called Supermetrics. Basically Supermetrics is a data connector. There's a world of different data connectors out there, but it allows you to pipe, via an API, revenue data from your CRM into a third party database that can then be joined with data from the channel itself. You can build tables within a database and normalize them together in a manner where you can start to determine the relationship between, again, the audience that a particular cohort of opportunities came from and whether a sufficient degree of revenue is derived from those opportunities.

(00:53:08):
And then you can build upon that what is known as a lead scoring model, which allows you to bid in real time on the audiences that have a higher likelihood to convert to high revenue generating customers. And so the magic there, we talked a little bit about rates of return and instant gratification in the performance marketing world, lead generation inherently is a slow gratification process. And so the problem is that if my pipeline is full of opportunities that yield revenue in two months, six months, sometimes 12 months, how do I determine how heavily to bid on different leads today in order to predictively have an outcome where I'm maximizing revenue? And a lead scoring model basically solves for that.

Lenny (00:53:59):
Today's episode is brought to you by Miro, an online collaborative whiteboard that's designed specifically for teams like yours. I have a quick request, head on over to my Miro board at miro.com/lenny and let me know which guests you'd want me to have on this year. I've already gotten a bunch of great suggestions, which you'll see when you go there, so just keep it coming.

(00:54:20):
And while you're on the Miro board, I encourage you to play around with the tool. It's a great shared space to capture ideas, get feedback, and collaborate with your colleagues on anything that you're working on. For example, with Miro, you can plan out next quarter's entire product strategy. You can start by brainstorming using sticky notes, reactions, a voting tool, even an estimation app to scope out your team's sprints. Then your whole distributed team can come together around wire frames, dry ideas with a pen tool, and then put full mocks right into the Miro board. And with one of Miro's ready-made templates, you can go from discovery and research, to product roadmaps, to customer journey flows, to final mocks, all in Miro. Head on over to miro. com/lenny to leave your suggestions. That's M-I-R-O.com/lenny.

(00:55:06):
You talked about attribution, and I thought this would be a great time to get into that. So the way I think about this is oftentimes the biggest challenge in driving growth isn't the actual work you do to drive growth, it's measuring what impact your work is having and understanding where dollars are spent effectively. And things are changing heavily in attribution land with privacy shifts and ATT and iOS 14.5.1, or maybe whatever the version was that came out that changed everything. And so my question is, what changed, is one, in terms of being able to do attribution. Maybe even explain what attribution means for folks that are just like, what the hell are you even talking about? And then finally, just what do you recommend people do now to do attribution well in this new environment?

Jonathan Becker (00:55:57):
Yeah, it's a really, really great and pertinent question in the industry, and it has a lot of focus on it now, but attribution has always been a conversation that's been very important. So just to kick things off, attribution essentially is how we determine the relationship between what we did and what happened. In the context of performance marketing this means what ads did we serve, what campaigns did we launch, and generally what was the revenue ultimately that was derived from these campaigns? And so there's a funny quote that I love, someone named John Wanamaker in 1919 said, "I know-"

Lenny (00:56:33):
I bet I'm going to guess what it is.

Jonathan Becker (00:56:34):
Do you want to guess?

Lenny (00:56:35):
It's, "Half my marketing dollars are wasted, I just don't know which half."

Jonathan Becker (00:56:41):
Exactly, I love that you knew that. He said this in 1919. The world was a very different place there, but oddly enough we still have these types of problems today and it's because the world of what I did and what happened because of what I did is very complicated. There's so many variables, some of which we know, and then some of which we don't know that we don't know, type thing. And so attribution, as it stands in our industry, is still an incredibly subjective art and somewhat of a science. It doesn't mean that it's impossible, and it doesn't mean that there aren't varying degrees of sophistication as it relates to attribution, but we're still in a place where we have to understand the business and its goals, and then start to work on an attribution model.

(00:57:32):
An attribution model is probably something that is never solved, but I'll give you a couple of examples. So number one around attribution, it's important to determine whether an organization, a company, a client, is focused on profitability or growth. Whether I use one attribution lens or another will drive those outcomes. And so these days, for a number of different reasons, you mentioned iOS 14.5, in addition to third party cookie deprecation, and whatnot.

(00:58:02):
There's no one way necessarily of approaching attribution. The most classic and commonly held version of attribution used to be a cookie-based form of attribution called last click attribution, meaning that the last click in the sequence of clicks that yielded a conversion would be attributed with all the revenue from that conversion. Other models in a cookie-based world involved first touch attribution, so it's actually the first click. So I launch an ad, it's in an audience that doesn't know about my service or my brand, and so the first click that I get should be given all the credit for that sale. And then there's multi-touch attribution, which can take several different forms, but essentially is saying it's not one way or the other of the two first versus last click options, it's somewhere in between. So I'm going to create a weighted attribution model where the first touch gets so much of the credit and the last touch gets so much of the credit.

(00:58:59):
This is very subjective, as you can see. I am essentially looking at my business model, determining what my goals are, and then I'm backing out into an attribution methodology that I think adheres to both the economics of my business and the capabilities of these platforms. And again, we live in a world where a single brand might do television advertising, they might buy media in magazines, they might buy billboards, they might get impressions from Facebook, they might do paid search, so there's a big argument over how to ultimately model this.

(00:59:34):
So there was something called an IDFA that Apple allowed advertisers to use, and essentially what that was, it literally means ID for advertisers, and it allowed Facebook, Google, and other advertisers, Snap, TikTok, whoever was essentially selling ads that were predicated on being displayed on a Apple mobile device or a desktop device, it allowed the advertiser to provide attribution metrics and certain types of customer match metric metrics in their own platforms. And so when Apple ultimately launches its privacy changes, I believe in mid-2021, overnight it allows users to say, "Well, I don't want to share that information, I'm not going to share my IDFA anymore." Or, "Yes, I do want to share my IDFA." And so what you see as a result of that is less of the core data that Facebook in particular would've required to make attribution more airtight and ultimately validate its advertising.

(01:00:43):
So because we can no longer validate attribution on Facebook as seamlessly, we are in a situation where we're not sure any longer which audiences to target, and we're not sure how to run all of our creative testing, and ultimately we can't even determine the degree of revenue that's coming from particular campaigns that we've launched, and whatnot. And so it created quite a stir in the world of attribution, which is obviously this core discussion to is it working or not? People want to answer John Wanamaker's question, but the modern methodology now is through a number of different approaches to validation.

(01:01:25):
So the cookie based attribution, which had been probably the most popular version of attribution in the 2010s, really up to this point, is now one of the ways that we would look at this, but we would also include things like various forms of statistical modeling, customer surveys, population surveys, there's a number of different ways to the same place here. Statistical modeling, by the way, one thing that's very popular these days, which I think was originally created in the 1950s, is a form of statistical modeling called media mix modeling. It's essentially regression analysis, and it is trying to determine the causal relationship between, again, what you did and what the effect was on revenue. That's very topical in the industry these days. If you're looking for a tool off the shelf that can help with this, Recast is something that I see people using. But a lot of organizations build these highly customized bespoke models that ultimately feed the algorithm inside of an MMM model in a customized manner.

Lenny (01:02:27):
What is it, or is there a recommendation of just like, hey, if you're trying to do attribution today, here's what you should do. Is there a clear, do this, piece of advice, or is it super personalized depending on what you're trying to do?

Jonathan Becker (01:02:42):
The advice is that there's no single source of truth. Anyone who claims that they are a single source of truth, whether it's an individual, a model that they've created, or a tool that they've created, is not being accurate. I believe that the approach that works to attribution is that it's an ongoing investigation and it never stops, and essentially what you're doing is looking for evidence that validates the outcome of your performance marketing campaigns one way or the other.

(01:03:12):
There have been plenty of incredibly sophisticated attribution models that we've helped build and invalidated with MMM or other types of tools that have indicated that the campaigns do not work. So I will repeat that, we, a very sophisticated organization, have stood up campaigns that we measure and ultimately determine do not work, and that is an important finding in terms of an organization's determination of whether they want to continually invest, take budget out of these channels, or invest into other areas.

Lenny (01:03:49):
Awesome. You mentioned a company called Recast. I don't think you knew this, but I'm actually an investor, and so obviously a big fan, so check it out. I don't know what the site is, recast.com maybe. I think if you Google Recast attribution, we'll also have a link in the show notes.

Jonathan Becker (01:04:02):
Cool. Yeah, they're working with a couple of our clients right now and it's interesting, I like their approach.

Lenny (01:04:06):
Yeah, they're basically, they're building the model as a SaaS tool to do attribution in a really clever way. Amazing. Okay, just a couple more questions, one is around AI, one is around agencies, and just how to start down this road. How has AI in any way impacted the work you're doing today, or the work of paid growth, performance marketing, and then where do you think this will go in the next few years?

Jonathan Becker (01:04:29):
Interestingly, and I think I alluded to this earlier, but our industry has been influenced by AI for over a decade. So Google, Facebook, even Microsoft, these are some of the organizations that historically have been at the bleeding edge of artificial intelligence, and their goal was always to automate as much as possible within these platforms. And so the effect ultimately that we've seen from a human capital point of view is displacement. So we're actually, we have more people now than we've ever had, but the nature of the work that they do is more strategic, it's more about modeling, validation, asking the right questions, being focused around creative levers, like some of the things that we've talked about, and less so the trench work of implementation and bid modifiers at the keyword level on Google search, and some of the really hardcore manual analysis we had to do.

(01:05:19):
So I think if we are the canary in the coal mine for other industries, what will be interesting is I assume that if you work in an architecture office that you'll be doing less of the drafting, and it's already been a change that's occurred in those offices, but you'll be doing less of the drafting and more of this strategic problem solving around what kind of building is necessary for the client in this scenario, type thing.

(01:05:42):
And so on a practical level, though, some of these conversational AI models are very interesting for us in that when I think about creative testing, for instance, we can have ChatGPT come up with all kinds of variants of copy that we would not have necessarily thought of. It can do a lot of drafting of things like RFP responses, so we can feed ChatGPT 100 previous RFP responses that we've done and have it spit out net new responses to net new questions in a net new RFP, and it's like 80% good and still requires 10 hours of work to massage to the point where we can send it off to a client, but that replaces a week of work with five or six people that it would've previously taken.

Lenny (01:06:33):
And that's already happening today, you're saying?

Jonathan Becker (01:06:35):
That's happening now, literally right now, type thing, all of what I just said. And there's a lot of different ways that we are beginning to use AI to do more with less, basically. So that's how I see it influencing not just our industry, but other people's businesses as well.

Lenny (01:06:55):
That's amazing. So just to repeat what you said, your team now, because of ChatGPT is able to spend more time higher level, and leverage specifically ChatGPT to do this kind of, and RFPs are basically proposals, people are asking you to pitch to work with them, is that?

Jonathan Becker (01:06:55):
Yeah.

Lenny (01:07:12):
Okay, yeah.

Jonathan Becker (01:07:13):
Some of these AI-driven organizations that allow you to type in a prompt and it spits out an image, on our creative group we can come up with mockups in literally 1% of the time that it took. So you no longer have to draw the initial mockups for art. Suddenly what might have taken one person a week of work on a campaign takes an afternoon, type thing. You still have to understand what questions to ask of the AI and be capable of iterating, but these rough drafts that you might show the artwork of to a client to say, "Do we like this more or do we like this more?" That's AI generated. It's really interesting.

Lenny (01:07:55):
What's the tool your team uses for that, is it MidJourney or Dall-E or something else?

Jonathan Becker (01:08:00):
It's Dall-E and it's MidJourney, so you got it.

Lenny (01:08:03):
Got it. And so what you use it for is you're thinking about a concept and you just come up with a mock, coming up with a prompt to pitch what this could be.

Jonathan Becker (01:08:11):
Yeah, the interesting thing there is that these concepts often live inside of someone's head, and we do this thing as humans where we verbally discuss it, and I try and put the image in my mind's eye, in your mind's eye, which is an inherently inefficient process and actually hurts our ability to be creative leaders. Someone might just see it slightly differently than you do. Now that person theoretically can use Dall-E to output what is inside their head, and they can refine that easily through subsequent prompts in Dall-E or MidJourney, or whatever it may be, and then just say, "Do you like this? This is my idea." And so in a way it's helped humans connect more easily in that context than we were capable of doing before, and then in the context of pitching a client on ideas, we are capable of generating more ideas faster and iterating upon them live. So I can have a Zoom call with you, I can present my screen, and if you don't like the output of Dall-E that I just prompted, I can re-prompt based on your feedback in real time.

Lenny (01:09:16):
There's this sentiment that AIs going to take away the fun stuff of jobs, like maybe being creative and coming up with a new concept and photography, setting up a whole photo shoot, whatever.

Jonathan Becker (01:09:30):
Yeah.

Lenny (01:09:30):
Do you find that your team is excited about uploading this to Dall-E, or are they just like, goddammit, this is what I loved, and now I'm just sitting around in docs writing prompts.

Jonathan Becker (01:09:40):
I am not an incredible artist, but now I can take those thoughts in my mind and output them just as well as someone who's pretty skilled in artwork. So in a sense, I'm excited because this technology democratizes the ability to do this across everyone. Anyone who can think a thought can generate an image on an AI image generator. How many scribes do you know?

Lenny (01:10:04):
Zero, I believe zero.

Jonathan Becker (01:10:06):
Because we invented something called the printing press, and the printing press took over what was a cottage industry for very specific individuals that allowed them to control the flow of information. Yet today it's not like we have fewer writers or creative thinkers, they're just using different tools to arrive at the same place. You could say the same thing of the loom. There used to be people who would stitch your T-shirt together, or your sweater together, and none of those people have work anymore. There's still people who knit, I suppose. But your clothes are made in factories with machines, and the quality of the clothing is arguably a lot better than it was, maybe I'm wrong about that point, but you can make more of it and more sophisticated clothing.

(01:10:46):
There's no question that AI is going to displace and replace certain industries of people, certain roles. I'm not going to pretend like I know whether that's a good or bad thing, and I'm also not a poster child for AI, I am really just using the technology that's available to us to run our business the best way we can. We haven't let anybody go yet because of these efficiencies. The people who used to do the artwork are the ones using these tools, and I think they're excited that they're more productive. Is there going to be nuance around that? Of course. Are some people going to be sad about the changes? Yes. I think human nature is that people generally don't like change, but I think over time we've seen change has been a productive and positive thing for society, not a negative thing.

Lenny (01:11:35):
Awesome. Yeah, so it sounds like the team is excited, generally, and that's a good sign, and that's what I find generally. I think some people will be really upset, but most people will be like, amazing, and they never wanted to do this part.

Jonathan Becker (01:11:47):
This generation of people will be upset, and then there will be a subsequent generation that never knew anything different. So the way that I think about this is the people growing up these days have always had the internet, whereas you and I probably remember a time before the internet existed. AI-

Jonathan Becker (01:12:00):
You and I probably remember a time before the internet existed. AI is a platform like the internet and just as when the internet was launched, you couldn't conceive of amazon.com or all of these wonderful or social networks or whatever it was. The permutations of what AI will become, even in the current GPT 4 context or Dolly context or whatever it may be. We don't know what people are going to create with this and so it's difficult for the generation that knew what life was like beforehand, before iPhone, before internet, before AI, but there will be people who know nothing but this eventually, and to them it'll just be normal.

Lenny (01:12:42):
Until we're all just replaced by AI and then it's AI writing ads to get other AI tools to buy products from each other.

Jonathan Becker (01:12:42):
Yeah.

Lenny (01:12:49):
And then we're just sitting around watching Netflix and that'll be great. There's always this question when you're starting to invest in paid growth, performance marketing of should we work at an agency? Should we work? Should we hire someone junior to figure it out? Should we hire someone senior?

Jonathan Becker (01:13:03):
Yeah.

Lenny (01:13:03):
What's your general advice for, say, an early stage startup when it makes sense to work with an agency versus bringing someone in-house?

Jonathan Becker (01:13:12):
Mm-hmm. We need people in-house to do our jobs properly. Agencies are not mutually exclusive to personnel in-house. If we don't have a point of contact, for instance, at an earlier stage company and we're supposed to report to the CEO, CEOs tend to be very busy people and we often just can't get the information and approvals that we need to be successful. If you think that growth marketing is an opportunity and that performance marketing is a subset of growth marketing that you want some focus on, the reality is you're going to need expertise and you probably should start in-house and then hire an agency.

(01:13:49):
Again, there's different stages of companies and different examples of what makes sense at different stages and the nature of the work that we do at different stages changes. Very, very late stage, we're kind of doing a lot of this sophisticated production work. We're implementing sophisticated testing, we're working on attribution, we're building beautiful reporting, but in a sense, we're maintaining this machine that already exists. Earlier stage, we're doing a lot more of net new experimentation, trying to discover what is working and what sequence of audience targeting versus creative asset display will work, what channel mix works, and all of that. A lot of times the body of work that's required to nail that and the inputs to literally out front what questions to be asking isn't something that a small in-house team possesses and so they will work with an agency to scale faster, to get where they're going quicker, to bring in more resources quickly, basically. Then later stage, sometimes it's a permutation of the same thing or we're really just managing a whole bunch of different capabilities that they have because it's very complicated and difficult to staff.

Lenny (01:15:05):
That is really interesting. So it's not like agency versus in-house full-time person. It's you need both is what you're finding.

Jonathan Becker (01:15:11):
I don't think we have any projects that we're working on where there's not a professional marketing person as our POC and generally the people that we report to have a background in what we do, whether they ended up doing something different and now they're a VP or a director level and not directly managing channels themselves is one thing or another. But yeah, we work with people that have in-house expertise all day long.

Lenny (01:15:35):
I see. Sometimes it could just be a generalist marketing person that becomes your point of contact.

Jonathan Becker (01:15:35):
Yeah.

Lenny (01:15:39):
They don't have to be experienced in paper.

Jonathan Becker (01:15:41):
There's one more thing. As agencies, we're constantly solving people's problems in the market and as a result of that, I have a fairly large team of 130 people that think about performance marketing all day long. It's the first thing we think about when we have our morning coffee and it's the last thing we think about as we're leaving the office kind of thing. We have very sophisticated and built out capabilities as well as all kinds of software and processes and capabilities, I guess, that we've created that most in-house teams just don't have because they're smaller or newer or someone might be really sophisticated but they don't have the resources to implement it and stuff. In the same way that a really sophisticated organization might go to Boston Consulting Group or McKenzie to say, "Hey, we did this, but you do more of this all day long and we need advice on how to be more efficient," people come to Thrive saying, "Hey, we're top of our game. We have really strong people. They absolutely know what they're doing," which is always the case by the way, "But we're looking for extra sophistication and additional capabilities that are very difficult to create in an in-house organization." It's why we worked with Uber for 10 years. It was tough to replace us.

Lenny (01:16:59):
Yeah, that's quite the retention. 10 years, 10 years going, I imagine our net dollar retention has gone up too.

Jonathan Becker (01:17:08):
Yeah.

Lenny (01:17:09):
When you're looking to hire someone full-time to drive the paid growth channel and/or work with an agency, what do you recommend people look for specifically, especially things maybe they're not likely to think about when they're hiring someone that people often miss?

Jonathan Becker (01:17:26):
There's a couple of competencies that I think are very important. I found that, so I was a nerd as a child, if you can't tell, I don't know.

Lenny (01:17:35):
Nope.

Jonathan Becker (01:17:35):
Super nerdy, geeky kid. I would take apart-

Lenny (01:17:38):
[inaudible 01:17:38].

Jonathan Becker (01:17:39):
I would take apart my parents' computers, I'd try and rebuild them. I was fooling around with bulletin boards before websites existed, stuff like that. Then I became a web developer and as I transitioned into a performance marketing role, I realized that being technical and having technical aptitudes was extraordinarily helpful in terms of being on the front line of what we were doing and solving problems. If you're making your first hire, you probably want them to have the ingenuity and capability to solve a lot of the problems that you're going to run into within the context of tracking, attribution, data visualization, and then campaign management. Number one, do they have a technical background? That can be multidisciplinary.

(01:18:22):
At Thrive, we have someone who is a nuclear physicist that left discipline and became a performance marketer. We have people who have left mathematics and become performance marketers, people who left finance, full stack engineering, all kinds of stuff. Those are technical fields where people tend to be good at math and good at problem solving, and so that's a strong piece of evidence that they might have a strong aptitude for performance marketing and managing this.

(01:18:52):
Another thing is just literally do they have experience in this discipline? Have they managed on any level Meta ads, Google ads, TikTok, Amazon, some of the things we talked about? Do they have an appreciation for some of the inputs that we just discussed today that ultimately create the conditions for success within a performance marketing environment? Do they understand the role of creative? Do they understand the role of proper attribution and are they capable of understanding the mechanics of your business and so on and so forth?

(01:19:29):
I would say just fundamentally, those are some of the areas that when we are interviewing we're looking for. As an agency too, we are looking for the ability to work with people and be excellent at client services. One of the questions we might ask, I actually borrowed a Jeff Bezos question from early stage Amazon where I asked people without much warning in an interview, I'll ask them whether it's okay to do a bit of a thought experiment together and whether they are comfortable responding to a logic question. I'll ask the question of, "How many windows are there in New York City?" There's two things that I look for in this scenario. One is can they think on their feet? I'm not actually looking for the correct answer. It's a pretty difficult question to solve. But number one, do you realize that windows are not just building windows and windows are also in cars and trucks and stuff like that, so there's more than one type of window. Then can you just do the arithmetic of saying there's so many buildings per hectare or square mile or whatever it is and it's division multiplication type stuff.

(01:20:33):
But also from a client services point of view, I'm trying to see whether in a scenario where I've asked them something that they obviously probably weren't prepared for, that is a strange thing to ask and probably makes them feel a little bit uncomfortable, how they react in that situation. Do they remain composed or do they lose their composure and get frustrated or even angry that I asked them something that's pretty weird to ask? Their reaction there is often a good leading indicator of whether or not in a client scenario working with our clients, they can compose themselves in a difficult situation.

Lenny (01:21:10):
Very tactically, what level of experience do you recommend people look for in their first performance marketing hire year or two, four or five years, longer?

Jonathan Becker (01:21:23):
I've seen people who have 10 years of experience in the industry not be that great and then I've seen people who have one year of experience be absolutely phenomenal. I would say that again, the years of service under their belt is one clue or piece of evidence to their potential aptitude. But really, you want someone who can clearly demonstrate to you that they can competently run the channels I suppose. If what you're asking is literally at the level where someone is managing pay per click and programmatic media buying, then you want to make sure that they can just do that and I would say it's less about the years of experience. A lot of times people only want to do those types of jobs for a couple years before they're like, "Hey, what's your plan for me? I'm tired of running ads and building campaigns. I want to manage the people who do that now." The people who tend to really do that are often somewhat earlier on in their careers. That's just a reality that we see.

Lenny (01:22:25):
One more very technical question. What do you recommend the title for this role be? Growth marketer, something else?

Jonathan Becker (01:22:31):
I've seen so many different names for this. I think again, if the intention is to grow out a growth marketing capability, which again is not exclusive to performance marketing, then you're looking for a manager role of growth marketing manager. I've seen paid acquisition specialist for people who just manage channels. I've seen paid acquisition manager, performance marketing manager, media planner and buyer. I've seen all kinds of different roles. But when we are launching a new role these days, there's such wonderful tools like everything from Glassdoor to LinkedIn to PayScale where you can essentially just look at what other people are calling it and borrow from their role descriptions and then create your own role description and then determine what role is meaningful in the context of your own organization.

Lenny (01:23:23):
Awesome. Last question. We started with the story of how you landed Uber, and I know you also have an interesting story which I haven't heard of how you landed Snap/Snapchat as a client, so maybe tell that story.

Jonathan Becker (01:23:38):
It's a fun story and I think it's about ultimately confidence and knowing your craft. I believe it was like 2015 or 2016, we were essentially contacted to participate in an RFP down in Los Angeles. RFPs are difficult processes and essentially a department of a company is saying, "We want performance marketing and here are all the questions that we're going to ask you and exercises you need to complete in order to vet you as to whether you are the right partner or not." Sometimes RFPs are incredibly thoughtful and they're run by people who have either done a lot of RFPs in the context of what we do or they know specifically what the outcome is. Then in other cases, they're very experienced marketing departments with senior people and an approach that they may take is every stakeholder within that department gets to submit one or two questions to a long list of questions and the respondents have to respond to all of this.

(01:24:38):
The RFP process for Snap was somewhat complex and they asked a range of different questions and we find ourselves in LA at a hotel the night before, it's 2:00 in the morning, my business partner and another team member that we had brought down are sweating and we're like, "How are we going to build a presentation out of this? They're asking so many well-meaning but difficult questions that are zigging and zagging." In a pitch situation you want to tell a story, it's important, and that story has to have a beginning, middle, and end. It was just difficult and yet here we were and we had worked with all these really cool organizations and I was very confident that we knew precisely what we were doing. I kind of had this eureka moment where I was like, "Here's what we're going to do." It was Brent MacArthur, my business partner and I kind of arrived at this together, but we're kind of like, "Here's what we're going to do. We're going to have a completely unique take on how to respond to this and we're going to build a deck that's bespoke around X, Y, and Z."

(01:25:54):
We work till 6:00 in the morning, I think we get a couple hours of sleep and then by 10:00, we're sitting in their offices. Essentially the pitch is something like this. I stand there in front of about 20 different executives from their organization and I say, "You have thoughtfully curated an RFP for us to respond to today, and you have asked us to respond to about 20 to 30 different questions. With the utmost respect, I am not going to answer any of your questions today. I'm standing here because you are looking for a marketing partner and you need expertise in this area and instead of telling you the answers to the questions that you asked, I'm going to tell you what I think you need to do to get where you want to go and if you agree with me and my logic and what I talk to you about here today, then you should hire us. If you do not agree with my logic and you think that we're out to lunch, then you should not hire us."

(01:26:47):
You could hear a pin drop in the room. My own team I think was a little bit surprised. We had a whole bunch of technical difficulties that day. Someone who was supposed to Zoom in couldn't make it and so I have to ad lib part of the pitch that I wasn't prepared for, lots of zig and zags. They thank us for RFP response, lots of handshakes and smiling faces, but we don't know whether we're going to land the client or not.

(01:27:12):
Then about two hours later, I was driving to San Francisco with a friend, immediately leave LA for SF because I had a bunch of follow on meetings, and I get a phone call and they were like, "We loved your approach. Congratulations. You're hired."

(01:27:28):
These days I think Snap is still a really interesting organization, but at the time they were kind of bringing the future of a social platform or what a social platform could be in the same way that we think about TikTok right now. TikTok wasn't on the scene yet and Facebook was very worried about Snap and there was tons of engagement on Snap, so this was the it client of the day and it felt amazing.

(01:27:55):
Essentially the lesson was that you have to trust yourself and understand your strengths and weaknesses. In situations where someone is well-meaning but may not understand what they need, be brave and tell them what they need rather than just conforming to what they're asking for because sometimes inadvertently that leads you down the wrong path. We took a big risk and it had a wonderful payoff and we have, in addition to this story, we had a wonderful relationship with them for a couple years.

Lenny (01:28:28):
I love that story. I love how dramatic all your new customers, your way of acquiring customers and I imagine not all of them are this dramatic.

Jonathan Becker (01:28:38):
Not all of them are this dramatic, but there have been some pretty dramatic ones. I think part of running a business and running an agency has been the curation and experience around all these fun, crazy stories that have accumulated as we run this really interesting services business.

Lenny (01:28:55):
Awesome. Well, with that, we've reached our very exciting lightning round. I've got six questions for you. Are you ready for the lightning round?

Jonathan Becker (01:29:03):
I'm ready. Let's do it.

Lenny (01:29:05):
Okay, great Looking, very excited. Okay, first question, what are two or three books that you've recommended most to other people?

Jonathan Becker (01:29:13):
As a marketer, Storyworthy by Matthew Dicks is a wonderful book. He is a world world-class storyteller. I don't know if you know him. He wrote this book about how to structure and think about the art of storytelling and every marketer should read Storyworthy. It was a huge contributor to how I think about what we do at Thrive. As an entrepreneur, I love startup stories, so Shoe Dog, which is the startup story of Nike. It's basically Phil Knight talking about all the ups and downs, and it's crazy. Nike shouldn't be a company based on all the turmoil and challenges that they overcame. Fascinating read about taking risk and doing what you think is right and ultimately succeeding and building Nike. Then a book by Nick Bilton called American Kingpin, which is the story of the startup of the Silk Road, which was like this dark web marketplace for some pretty bad stuff. But it is half tech story, startup story and half gangster kind of kingpin story. It honestly should be a Hollywood movie. It reads like a Hollywood thriller. So awesome, great book.

Lenny (01:30:30):
Favorite recent movie or a TV show.

Jonathan Becker (01:30:32):
I don't know how recent it is, but I love The Big Short, just love it.

Lenny (01:30:35):
Not recent at all, but it's still great.

Jonathan Becker (01:30:37):
It's still great. The reason why I like it is because someone found truth in the data they were analyzing and then capitalized on it, which is really an analog for what we do in performance marketing. Then recently I have fallen in love with White Lotus for no particular reason. It's just raw entertainment.

Lenny (01:30:54):
What's something you've changed in the way that you all operate that's been relatively minor in terms of how hard it was to change, but that had a tremendous impact on your ability to execute as a team or a company?

Jonathan Becker (01:31:08):
The tools that we use in performance marketing change constantly. The channels themselves change and therefore what problems exist and what SaaS companies or different types of platforms offer as solutions to problems change. I don't think it's one thing necessarily, this might be a bit of a roundabout answer here, but I mentioned that change itself earlier is something that humans seem to not love, whereas in our industry, and I don't think we're alone here, but there's a culture of change. A welcoming of change, aptitude around change, having a playful mindset with new technology and tools rather than being upset about the fact that AI exists or third party cookies are being deprecated or iOS 14 removed IDFA and trying to be creative around those types of solutions has been like a constant for us. I'm kind of sidestepping the question a little bit, but it is the cultural willingness to adapt that I think has been a strong suit for us as a company.

Lenny (01:32:12):
Speaking of tools, final question. What is your favorite most underrated tool for performance marketing work?

Jonathan Becker (01:32:18):
It's Thrive Stack. It's a tool that we built in-house that allows us to pipe third party data and anonymized customer level data into a database and then ultimately visualize it in a format like Data Studio, Google Data Studio, which I think now is called Looker Studio. That has been a profoundly powerful platform from which we're capable of delivering insights that are built upon the data as opposed to just regurgitated data, if that makes sense. We have not released this technology yet. It's basically a tool we use in-house with our clients. But to a certain extent, I mentioned Supermetrics, which is another ETL and has some of the same capabilities but isn't quite as powerful.

Lenny (01:33:05):
Amazing. Jonathan, this is by far the deepest I've ever gone into the world of paid growth. I really appreciate you making time and sharing all of your wisdom with us. Two final questions. Where can folks find you online if they want to learn more, reach out, ask some questions maybe, and how can listeners be useful to you?

Jonathan Becker (01:33:23):
Thank you for having me again, by the way. This was a lot of fun. I'm available through Thrive, so thrivedigital.com. You can contact us through our site by accessing the contact form. Personally, I'm on LinkedIn under my name Jonathan Becker or Twitter, JZBecker. Then things that would be interesting from the audience, always looking for feedback in terms of whether people agree or disagree with thoughts and feelings that we have about what we do. Obviously always looking for amazing people ultimately to join our team at Thrive. If you're a practitioner of growth marketing or performance marketing and you're looking for a top place to spend some time, would love to talk to you. Also, I suppose if you need some help making this stuff work within the context of your own organization, we'd love to be at your service.

Lenny (01:34:12):
Awesome. What is the URL again?

Jonathan Becker (01:34:14):
Thrivedigital.com.

Lenny (01:34:16):
Sweet. You asked for feedback, be careful what you wish for. We get some hilarious C2 comments. We'll see. We'll see what comes in on this one.

Jonathan Becker (01:34:24):
Sounds good.

Lenny (01:34:25):
Jonathan, thank you so much for being here.

Jonathan Becker (01:34:27):
Pleasure. Thanks, Lenny. Thanks for having me.

Lenny (01:34:29):
Bye, everyone. Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## How a great founder becomes a great CEO | Jonathan Lowenhar (co-founder of Enjoy The Work)
**Guest:** Jonathan Lowenhar  
**Published:** 2024-12-05  
**YouTube:** https://www.youtube.com/watch?v=s0jn7eE33nk  
**Tags:** growth, retention, acquisition, okrs, roadmap, iteration, experimentation, analytics, funnel, conversion  

# How a great founder becomes a great CEO | Jonathan Lowenhar (co-founder of Enjoy The Work)

## Transcript

Lenny Rachitsky (00:00:00):
You basically spend all your time working with founders, and through that studying, you create frameworks and training and you use that in your work. I think that's what many, many founders are looking for is how do I avoid pain?

Jonathan Lowenhar (00:00:11):
To be a founder is a state of being, it's an attitude. To be a CEO is a craft. The more founders who can accept that those are two separate things and they're both equally important to build an ascendant startup, the better all of us will be.

Lenny Rachitsky (00:00:26):
I'm kind of tired of talking about founder mode, but it feels like what you're describing is founder mode and manager mode.

Jonathan Lowenhar (00:00:30):
Founder mode gets me angry. That article just got me hot. It really felt like an excuse. We were giving founders a permission to not learn the job. It's not manager mode is bad, it's the greatest CEOs know when to calibrate which one is needed.

Lenny Rachitsky (00:00:46):
Something you talk about, there's these two phases to a startup journey and most people focus on the first phase.

Jonathan Lowenhar (00:00:51):
Phase one is build something people want to buy. Phase two, the one we don't talk about is now you have to build a company around that thing people want to buy. Building a company is always the same. I don't care if it's MedTech or fintech or hardware or consumer.

Lenny Rachitsky (00:01:04):
You've come up with this methodology that you call the Magic Box paradigm that helps founders think about how to lead to a successful exit long-term.

Jonathan Lowenhar (00:01:11):
This is a traditional sales process. You build a list of the companies that might want to acquire you, you ping them and you hope you get a deal. Magic Box argues that the best outcomes for early-stage startups don't happen that way. You're never for sale. In fact, you have seduced a buyer. They see the fantasy, they fall in love.

Lenny Rachitsky (00:01:35):
Today, my guest is Jonathan Lowenhar. Jonathan runs a firm called Enjoy The Work, which I've heard amazing things about from so many people over the years. Their firm has a singular mission, to help founders become great CEOs. They do this through a blend of mentoring and advising services, which are rooted in their study of how the best startups operate. They take these lessons and fold them into frameworks and advice and training that they offer their CEOs, their insight, which you'll hear in our conversation, is that most founders don't come into the job knowing how to be a CEO, which includes learning how to do hiring, how to manage financials, figure out growth strategy, road mapping, planning, people management, and so many other skills that nobody teaches a founder.

(00:02:16):
In our conversation, Jonathan shares the most common CEO failure modes that he and his team have seen, the Magic Box paradigm for successfully selling your startup, a bunch of advice for finding and hiring the best talent, a framework for building a repeatable go-to-market motion, why and how you should learn to trust your intuition more as a founder and so much more. We could have gone on for so many more hours. Maybe he'll be back to share more advice. If you're a founder or hope to be a founder one day, this episode is for you. If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. It's the best way to avoid missing feature episodes and it helps the podcast tremendously. With that, I bring you Jonathan Lowenhar. Jonathan, thank you so much for being here. Welcome to the podcast,

Jonathan Lowenhar (00:03:03):
Lenny, I am damn excited.

Lenny Rachitsky (00:03:05):
So am I. The reason I'm excited to have you in this podcast is that you basically spend all your time working with founders, and through that studying, what causes them pain, what causes them to fail, what causes them to struggle, and then you take that and you create frameworks and training and you use that in your work with founders, and I think that's what many, many founders are looking for is how do I avoid pain? How do I avoid these things that I'm going to probably run into? To build on that, briefly, can you just help people understand what it is you do, what it is your organization does with founders, how you work with founders?

Jonathan Lowenhar (00:03:38):
Yeah, thank you. I'll tell a bit of origin story that I think ends up answering that question.

Lenny Rachitsky (00:03:43):
Let's do it.

Jonathan Lowenhar (00:03:45):
I had run a bunch of different types of companies and they were really different ones. I ran a big division for a public company, then I was a private equity CEO, then I did back-to-back startups. The first one didn't get very far, but we sold it, and the second one got really far. When I left the second one, I was like many founders, grossly unhealthy, 25 pounds overweight, wasn't sleeping enough, all the things. I took a few months to get healthy and then reflect on those parts of my career. One of the things that I noticed at the time was all of those companies, when they got to a good place, when they started to run well, they were all run well in the same way. How could this be? How could public company, private equity, startups, early stage, growth stage, when they were run well, they were all run well the same way?

(00:04:35):
I started to obsess about this question, and what it led me to realize is that every well-run company has a rhythm. It's unmistakable, you can't miss it. You can't not see it. You just spend a couple of days through a spy cam watching a business, you'll see the pattern. How come some startups get there and some don't? How does a founder learn the rhythm? How do they learn how to run a company well? I started to ask investors obsessively, and I asked them, Lenny, I asked them all three questions, same three over and over and over again.

(00:05:14):
First question was, well, describe to me your ideal founder. What's a great founder? The answers universally were the same. Investors would use words that meant grit and tenacity and courage and insight, and I'd say, "Great. Question number two, describe to me a great startup CEO," and they use none of those words. How can that possibly be true? Instead, they describe skills. This is a person who knows how to build stuff and sell stuff and recruit people and raise capital and organize humans and financially plan. Question number three, my final one, well, how does a founder learn those skills while doing the job? I got blank fucking stares, over and over again. It led me down this path that I'm now 10 years into with my colleagues of, well, how do we help founders learn those skills so that their venture investors don't fire them, so that they can actually go build whatever company they want to build and stay in the job for as long as they want to stay in the job? That's origin, that's what got me going.

Lenny Rachitsky (00:06:27):
This episode is brought to you by Pendo, the only all-in-one product experience platform for any type of application. Tired of bouncing around multiple tools to uncover what's really happening inside your product? With all the tools you need in one simple-to-use platform, Pendo makes it easy to answer critical questions about how users are engaging with your product and then turn those insights into action. Also, you can get your users to do what you actually want them to do. First, Pendo's built around product analytics, seeing what your users are actually doing in your apps so that you can optimize their experience. Next, Pendo lets you deploy in-app guides that lead users through the actions that matter most. Then Pendo integrates user feedback so that you can capture and analyze what people actually want.

(00:07:12):
The new thing in Pendo, session replays, a very cool way to visualize user sessions. I'm not surprised at all that over 10,000 companies use it today. Visit Pendo.io/Lenny to create your free Pendo account today and start building better experiences across every corner of your product. PS, you want to take your product-led know-how a step further? Check out Pendo's lineup of free certification courses led by talk product experts and designed to help you grow in advance in your career. Learn more and experience the power of the Pendo platform today at Pendo.io/Lenny. I'm excited to chat with Christina Gilbert, the founder of OneSchema, one of our longtime podcast sponsors. Hi, Christina.

Christina Gilbert (00:07:57):
Yes, thank you for having me on, Lenny.

Lenny Rachitsky (00:07:59):
What is the latest with OneSchema? I know you now work with some of my favorite companies, like Ramp, Vanta, Scale and Watershed. I heard that you just launched a new product to help product teams import CSVs from especially tricky systems like ERPs.

Christina Gilbert (00:08:15):
Yes, so we just launched OneSchema FileFeeds, which allows you to build an integration with any system in 15 minutes as long as you can export a CSV to an SFTP folder. We see our customers all the time getting stuck with hacks and workarounds and the product teams that we work with don't have to turn down prospects because their systems are too hard to integrate with. We allow our customers to offer thousands of integrations without involving their engineering team at all.

Lenny Rachitsky (00:08:37):
I can tell you that if my team had to build integrations like this, how nice would it be to be able to take this off my roadmap and instead use something like OneSchema and not just to build it but also to maintain it forever?

Christina Gilbert (00:08:48):
Absolutely, Lenny. We've heard so many horror stories of multi-day outages from even just a handful of bad records. We are laser-focused on integration reliability to help teams end all of those distractions that come up with integrations. We have a built-in validation layer that stops any bad data from entering your system, and OneSchema will notify your team immediately of any data that looks incorrect.

Lenny Rachitsky (00:09:08):
I know that importing incorrect data can cause all kinds of pain for your customers and quickly lose their trust. Christina, thank you for joining us and if you want to learn more, head on over to OneSchema.co. That's OneSchema.co. There's obviously this new meme of founder mode. I'm kind of tired of talking about founder mode, but it feels like what you're describing is founder mode and manager mode. You basically have to be good at both. This latter part is almost manager mode. Is that a way to think about it?

Jonathan Lowenhar (00:09:34):
Yes. Founder mode gets me angry. That article just got me hot.

Lenny Rachitsky (00:09:39):
Do share.

Jonathan Lowenhar (00:09:42):
It really felt like an excuse. We were giving founders a permission to not learn the job. If we think about an ascending startup, there's this phase of I have to invent something. I now have to figure out how to get my customer in front of this invention and see if it works, and then I have to build a business model around that to see if there's some repeatable way to attract, win, deploy my customer and thrill them with whatever the solution is. Okay, now I have to go build an enormous amount of demand and then I have to build up an operation that can handle all that demand. Oh, and by the way, at some point, figure out how to turn positive revenues into positive cash flows. The idea that the founder who's writing code by themselves doesn't have to advance their skills to learn how to do all those things, and that in fact what the article even implies is learning how to do those other things is a negative is bananas to me.

(00:10:52):
The things required to launch a company are not the same as grow a company as scale a company as exit a company, and the best startup CEOs learn them all along the way. There are lots of ways to learn them. I'm not suggesting there's only one path, but founder mode was almost an excuse not to. I do think what's unique about a founder that felt perhaps where that article was trying to go is that unlike the professional mercenary CEO that gets dropped in, the founder knows everything about what built this company and they can drop in at the most granular level and play anywhere. They can drop into a product feature, they can drop into a customer conversation or a partner conversation or with a long-time employee that's still in IC and be impactful and then rise back up if they've gone the training and get back into a cockpit to run the company again. That's to me the distinction. It's not manager mode is bad, it's the greatest CEOs know when to calibrate which one is needed.

Lenny Rachitsky (00:11:57):
I love that. I'm glad we got there. I wasn't planning to talk about founder mode, but I think this is really helpful for folks to hear that are founders and people working for founders too. Along these same lines, you have a really helpful and really funny also mental model for how to think about common failure modes of founders. You have these labels that I love, and this is actually the first thing I heard about Enjoy The Work is these labels that you guys use, and you also, a similar mental model for failure modes for a startup. Can you just share these modes that you've come up with?

Jonathan Lowenhar (00:12:31):
We do take a bit of a comical approach to some of this. As I've shared with you previously, the name of our company is not an accident. If we can't be playful, we can take the work seriously and not ourselves, so we do fuck around quite a bit. I think if I would separate failure modes for companies versus CEOs for a minute, the company ones are not quite as comedic, but they are ones we see all the time. One is you chose the wrong market. I don't think we need to belabor that one. Lots of your prior guests have talked about the importance of getting that part right or nothing else really matters.

(00:13:05):
Second, back to what we were discussing a minute ago, build something people want to buy, got to go build the right thing. Cool. Third one, founder's function. We like to joke that more companies die from suicide than homicide, and it's grim, but also if the two or three people in charge of the business can't get along, nothing else matters. It's all going to break apart. Then fourth, execution, and execution now leads back to CEO. Okay, so now we have a bunch of playful ones here. We have the robot CEO, who believes emotion should not ever exist at a startup, at which point we train them on a very simple formula. Emotions are messy, humans have emotions, startups need humans, therefore startups are messy.

Lenny Rachitsky (00:13:57):
I love how engineering-oriented that advice is, which makes sense for robots. Yeah.

Jonathan Lowenhar (00:14:03):
Also, a little bit more graceful of an answer there is also our CEOs want urgency and passion and excitement from their teams. They want them working enormously hard for below market comp more often than not with this promise of equity that might return value five or 10 or 12 years later. They want them to bring all of that emotion, but they're supposed to figure out how to surgically cut off the emotions that are inconvenient. That's the robot CEO who believes that we can just have several robots working for us and you just press a button and they do a thing. Second one is a pleaser CEO. This is the person who is far more concerned with being liked than running a business, so they can't tell anyone hard news. They can't break ties, they want a consensus on everything, and that's not possible.

(00:14:56):
If you have a group of thoughtful people working for you, they're going to fight, they're going to debate and you want them to. Then at some point you have to call it and say, "No, we're going left not right." Or, "The two of you need to go get in a room and deal with something." Or, "Hey, the way you just showed up is not the way I want you to show up." The pleaser CEO won't do any of that. They will simply hide and pray It goes away and it won't go away. Next one is a perfectionist CEO. I'd like to say that these are the CEOs with the most beautiful product to be delivered minutes before they file for bankruptcy. This is the person who is far more concerned with being right and believing that there's always a right answer than just moving forward.

(00:15:36):
It creates two problems in a business. One is you're just slow and the other one is you'll never take any bets because you will build a team that realizes the CEO is not allowed to be wrong, so you can't disagree, you can't use intuition, you can't use gut. Everything has to be utterly factual and that is simply not possible. In early-stage startups, you have more questions than you do answers. Everything is circumstantial. It's not like watching CSI entrepreneurship and you get to see a video to say, "Oh, look, the guy did it." No, we have a bunch of little data points you have to come to a conclusion. The next one is the angry CEO.

(00:16:15):
I had a founder of mine a bunch of years ago and we were seeing a pattern across the leadership team and he and I get on the phone one morning and I said, "I have a theory for you. It might be a story, I might be wrong, but I want to share." He said, " Okay." I said, "I think you wake up in the morning angry and you don't know it, and then you get to the office and you beat the crap out of the first employee that crosses paths with you over something utterly unrelated because you're angry. You realize that a few hours later and you apologize and your team hasn't quit yet because they believe you're a good human who doesn't have good self-control." Then I shared with him, "And you just had your first child. My guess is because I'm not a psychologist, I'm not a therapist, that you are modeling something that's happened in your life. Is this something you want to change?"

(00:17:09):
His answer is yes, and I said, "Great. I have good news and bad news. The good news is because you said yes, we can do something about it, and the bad news is I don't know what to fucking do. That's not my job." The point being, no one wants to work for the angry person. I don't care what the equity potential is worth, no one wants to work for that person, and the moment they see greener pastures elsewhere, they're leaving. The next one is the one that drives me particularly crazy, it's the laissez-faire CEO, who insanely believes that I can just hire great people and utterly ignore them and let markets take care of themselves and they will do all the right things. I have never met anyone, Lenny, that didn't benefit from good management and the laissez-faire CEO believes that management is not required, and so what they ultimately find is they have really, really good people doing utterly disconnected things and goals are not achieved.

(00:17:59):
Every CEO we can reductively reduce to one of two characters. They're either comfortable with the brake or comfortable with the accelerator. The challenge with those who are comfortable with the brake, what I mean by that is they don't want to spend any money, so they're driving this beautiful sports car and they're just leaning on the brake the whole time. Yes, they won't run any money, and yes, they will also get lapped by everyone else and miss the opportunity. Where their opportunity is, is where can you take bets? Where can you actually downshift that car in such a way where you give yourself a chance in the market? Separate, those who ride the accelerator, we've all met this one. They're going to run out of money really fast, and this connects to one of our other challenging CEO types, the ready, fire, aim.

(00:18:49):
Most CEOs are really bad at planning and that's because there's this little-known secret in the Bay area, most CEOs have never run a business before. Planning doesn't have to be some heavy bureaucratic multi-month exercise that begins in August and ends in February, but a little bit of bottoms up planning to say, what are we trying to achieve? How do we quantify it? What resources are required? What humans are going to do what? How do we shorten feedback loops so we know in a week, in a month and two months, whether we're on the right trajectory? The ready, fire, aim CEO says, "I don't want to do any of that because they're improvisational and they just want to take bets and they want to take shots," and that's what got the company started, and that's also what will have the company go bankrupt. The micromanager one is the opposite of laissez-faire. They believe that no matter how many employees they have, they can do the job better.

(00:19:42):
The challenge with this one is it is massively disrespectful to those who work for you. We think that, and this is a bit insulting, that everyone that works for a founder can be fit into one or two chunks. They're either an adult or a child. I have a three-year-old, my little girl is amazing. I'm utterly in love. If she doesn't have a lot of structure and a lot of supervision, she's going to run into things, man. Into things, off things, through things, but adults don't need to be given utter instruction and watched all the time. In fact, it needs to be the opposite. We agree on what success is, what resources are, and you let them go and they'll come back to you when they have questions. The micromanager CEO doesn't see the difference between those two humans. They don't trust anybody and that's actually the thing under the thing under the thing, so they want to do everyone's work and that will succeed right up into the point everyone quits.

Lenny Rachitsky (00:20:39):
This is amazing. Okay, so let me recap these labels that you have just for folks. I have them written down here. There's the robot CEO, perfectionist CEO, pleaser CEO, micromanager, laissez-faire, ready, fire, aim, riding the brake and then riding the gas, and as you said, the ever-popular angry CEO.

Jonathan Lowenhar (00:21:03):
You got them all.

Lenny Rachitsky (00:21:04):
As people hear this, I imagine people self-identify a few of these, like I have some of this, I have some of that, and it's not like black or white. No one is like, "I'm a 100% robot CEO, and I need to fix that." It's like a pie chart kind of, I don't know, what's a visual of this? Everyone's got a little bit of this, basically.

Jonathan Lowenhar (00:21:24):
That's right. I enjoy giving this talk on stage and watching different founders in the audience cringe at different moments, but it doesn't mean that they're all one or the other. If they were all one of these and then didn't want to even accept the possibility that there's a little bit of a lot of these that they could work on, they're probably not coachable and they're not going to be in the talk anyway.

Lenny Rachitsky (00:21:45):
It's like I imagine each of these is very particular and it's this journey you go on to work on yourself. Let me just ask, what's the most common issue that you've found across these labels of type CEOs? What's the most common one and what do you often recommend someone to work on specifically to help them through that?

Jonathan Lowenhar (00:22:02):
I think ready, fire, aim is the most common that we've seen, and that has been an affliction that's been growing in the last number of years. It wasn't long ago that CEOs could paper over poor execution with easy access to capital. Suddenly, over the last number of years, we're expecting founders to be better operators. Better operators means eventually being on a path when more cash comes into the business and out of the business. That doesn't happen by accident. The ready, fire, aim CEO has probably suffered this pain where they took lots and lots of bets. Maybe they measured the outcome after the fact and they were wrong and they were wrong and they were wrong in ways that were expensive, and they've raised their hand to say, "I see it. I want to get better at this." Basic, basic business design and business planning is not some corporate effort. It's some thoughtful exercise that starts with what are we working backwards from?

(00:23:02):
Because in any given time, Lenny, companies are working backwards from one of four things, whether they like it or not. I am working backwards from an exit. I'm working backwards from a next fundraise. I'm working backwards from profitability or I'm working backwards from winding down. We don't talk about the fourth one that much, but I got to choose one. I got to choose the top of the mountain. More often than not, they're choosing a fundraise. Then we'll ask that founder, you know your market, you know your investors, you know the next set of investors, we've done some intel. What has to be true to unlock the next fundraise? That's a qualitative and quantitative answer, but we write it down. We need to get better at go to market. We need to land our first partner. We need to launch next iteration of the product and show this level of efficacy, engagement, what have you. Can we codify that? Yes. Can we talk through what actions would be required on what cadence to unlock that quantified set of results? Yes.

Jonathan Lowenhar (00:24:00):
... that quantified set of results? Yes. Do we understand what resources would be required to do those things? Recognize we might have to squint through some of it, but again, the answer is yes. [inaudible 00:24:13] now aimed. If we have a culture that has some accountability, that has a communication architecture, so there's some rituals about how we meet and how we share information and how we talk through problems, and how we work through bottlenecks, well, now we have a plan and now we have accountability. I now no longer have to just guess all the time. And this only works for the CEO who says, "My improvisational efforts got me here, but I don't think they'll get me there."

(00:24:47):
There's a guy I worked for a long time ago, and he had this phrase... He had like seven or eight phrases, he would use them over and over and over again. It was hard not to commit them all to memory, and one of them was, "If you keep doing what you're doing, you keep getting what you're getting." And for the ready, fire, aim folks who realize the weakness of that at scale, the way to counteract that, is to start with good planning.

Lenny Rachitsky (00:25:12):
It's interesting that's the most common type of CO, when with Founder Mode, it feels like it just accelerates that further. The whole meme of Founder Mode, which are what makes you upset. Makes sense. Great.

(00:25:26):
Okay, so I love that you talked about exiting as basically one of these four working backwards paths, because that's where I wanted to go next. I want to talk about some of these specific frameworks and skills and methodologies that you teach, and one of them... I want to almost go to the end of selling your company. And the reason I'm excited to talk about this, is if you think about, and tell me if I'm wrong, but it feels like most startups that succeed end up selling their company. That's the most likely success, right?

Jonathan Lowenhar (00:25:58):
Yes, by far.

Lenny Rachitsky (00:26:01):
Great. Yeah, because the other option is IPO or just run this privately forever. Or fail, basically, and fold. So of the successful options, the most common is selling. At the same time, founders have never done this before, they don't know what they're doing. The other side, often, has done it many times, and so it's a pretty treacherous and scary and high-stakes thing to do and to learn on the spot. And you've come up with this methodology that you call the Magic Box Paradigm that I love, that helps founders think about how to lead to a successful exit long term. Can you talk about what this is?

Jonathan Lowenhar (00:26:36):
I can, and I want to give credit where it's due. There's a book by this name, it's called Magic Box Paradigm, written by an independent banker named Ezra Roizen. And the book's fantastic, and Ezra is fantastic.

(00:26:46):
What we've done, is we've operationalized it so that we could teach founders over, and over, and over again. If the founder wants to hire a banker for this particular process, because we're not bankers, we're not BD, we don't get paid that way, we're teachers. But if wanted to hire a banker, go hire Ezra. But the methodology itself is a inversion for how venture and venture boards have thought about startups being ready for sale for a long, long time. It's utterly counter to so much advice that founders have heard. There are two ways you can get acquired. This is purposely reductive. One is you put up a for-sale sign. This is a traditional sales process. You build a list of the companies that might want to acquire you. You figure out the categories of buyers, the companies there, the contact list within that. You ping them and say, "We're open to a transaction," or some euphemism the like. You contact them and say, "I'll give you some information now. Sign an NDA. Give me an indication of interest by this date." And you work through a process, and you pray you have more than one person at the end of the game, try and ratchet them up, sign a term sheet. They will then re-trade along the way, right up until the point you die and you hope you get a deal done.

Lenny Rachitsky (00:28:05):
Sounds very familiar.

Jonathan Lowenhar (00:28:08):
And it's one that often will just hit the nervous system of any founder that's been through it a couple of times. Because man, is it a fraught exercise? What Magic Box argues, is that the best outcomes for early-stage startups don't happen that way. You're never for sale. In fact, you have seduced a buyer. You have brought someone in. And there are three stages to Magic Box work. There is learn the fantasy, there's prove the fantasy, and there's quantify the fantasy.

(00:28:43):
All right, so what the hell do I mean by a fantasy? You're an early-stage startup, and you meet a company that is in your space, in your vertical, what have you, and they're much more advanced than you. It's a large business. Generally speaking, another oversimplification here, large companies are interested in small companies because they're technology. And small companies are interested in large companies because they're distribution. And there's someone at the large company who becomes fascinated with you.

(00:29:12):
What's the fascination? What they see in their head is, "Oh, interesting. If I buy your company, this thing happens." The classic example of this is Instagram. This is the number one example of this. Lenny, do you remember how much revenue they had when they got acquired by now Meta?

Lenny Rachitsky (00:29:33):
I think it was zero.

Jonathan Lowenhar (00:29:34):
I think it was zero.

Lenny Rachitsky (00:29:35):
Okay.

Jonathan Lowenhar (00:29:36):
Do you remember the acquisition price?

Lenny Rachitsky (00:29:37):
A billion dollars, which was absurd at that point.

Jonathan Lowenhar (00:29:41):
There was no math Facebook could use, historically speaking, that would justify a billion dollars. It had to be a model on the future. This is Magic Box to a T. They had a fantasy that adding Instagram would expand ad revenue. They figured out some way to prove it. I'll explain more on what I mean by proof. And then their quantification was based on the future. And that's the difference between a Magic Box approach and traditional approaches. Traditional approaches are based on the past, Magic Box is on the future.

(00:30:14):
Let me tell a story. In one of our companies in construction tech, their technology was able to suck in video camera data from construction sites for project planning. No one was doing this yet. And the business was doing pretty well. We helped the founders launch the company. We got first product in market. We raised a couple of rounds of capital. The product mostly worked. But we weren't sure it was venture scale as we were going along. And we had some large construction tech companies and real estate companies and development companies leaning into us. And one particular company then said, "Huh, we're really good at construction planning, and we've collected all of this video data that we don't use at all." And the champion on the other side in the product org, he has a fantasy. "Oh, shit. We take your video analytics platform and plug it into what we do, and this is what happens to my business."

(00:31:18):
Now, the person on the other side is a person. And the reason I'm being specific about that, is because you don't sell to a company. Magic Box is about finding the person. You're finding the champion on the other side, the person who has motivated for their own reasons, career, money, reputation, what have you. They see the fantasy. They fall in love. And this person says, "I am in love with this idea. If I can grab security data into my product organization. Now I have to prove the fantasy."

(00:31:53):
What's different about a champion in this kind of process, is they want to find a way to say yes. They're not looking for a way to say no. And this brings us to the four characters you're going to meet along the path of Magic Box. There might be a fifth. You're going to meet your champion, you're going to meet your advocates, you're going to meet your blockers, and you're going to meet your buyer. You might meet Corp Dev along the way.

(00:32:20):
Let me talk about each of those folks. The champion is the one who's fallen in love. They're the ones with the fantasy. They're the ones who are arguing on your behalf. They're the ones fighting for you when you're not in the room. They are texting you, they're telling you things about the business that they're probably not supposed to tell you.

(00:32:33):
The buyer. All they care about is math. It might be a committee, it might be a group, the IC, the EC, the investment group, what have you. They're the ones who actually can sign off on a deal. They care about business case.

(00:32:45):
Advocates... Lenny, do you play chess?

Lenny Rachitsky (00:32:49):
I have played chess, yes.

Jonathan Lowenhar (00:32:50):
You have played chess. So advocates are pawns. They don't matter at all until they matter enormously. These are folks that, like, you are the CEO doing a meeting with your potential buyer, and there are somehow 12 people on the Zoom call, but only two do the talking. The other 10 might be advocates. They're rooting for you, but they will take no political risk. Their value is in giving you intel.

(00:33:16):
Blocker. This is the person who can't say yes, but they can say no. This is OPSEC, this is Procurement, this is Legal. You're going to meet all these characters during the Magic Box dance. Your champion just wants you to get the deal done so in love. So what happens, is they've come up with a fantasy and you as a CEO need to lean into it. This isn't enterprise selling. I'm not trying to sell you this thing that I have. I'm just trying to find ways to say yes.

(00:33:47):
So when, in my story, the person says, "Could we provide you all of our video data that we've collected forever and you now could enhance our ability to predict whether large- scale construction projects are on time"? I don't want the CEO saying anything other than, "We can do that."

(00:34:07):
Now, phase two, I need to prove it. Okay, because I have a champion who wants to say yes, proof can be really easy. And the reason the proof is so important, is not to convince the champion they're in love with the fantasy. They're already convinced. It's because in almost all cases, big company is buying little company and your champion doesn't have unilateral authority. They're going to socialize the deal. They have to get buy-in from who? The aforementioned buyer. They have to be able to survive the aforementioned blockers.

(00:34:43):
So eventually, when they pitch this to whatever committee is in charge, that committee is going to say, "What proof do we have that it works?" And we just want to be able to provide the champion with enough evidence that it works. So in this case, we said to the champion, " Well, give us video data, and we will provide you the evidence that you need." Because we're dealing with a champion who's not a cynic, because champions aren't, we could tell them, "And provide us the data in this way, in this fashion, and here's what we'll send you after. Are we in agreement?" We know we're already going to win the proof, and it's critically important in these dances.

(00:35:27):
Number three, quantify. At this point, we're not up for sale, but we're spending a lot of calories on somebody, and they know it. So we have our CEOs say the following phrase to them: "My board is asking questions. They're wondering why we're spending so many calories on this when it's not really core and we're not selling you our product. I'm convinced of how exciting this could be, together, but I think we need to do some math. So I can explain to my board why this might matter. So let's imagine all this works, because it's going to work, and it's a year from now or five years from now. What changes about your business?" And the champion will tell you, "Retention does this, or deal size goes like this, or market share goes like this." And you'll say to them, "Fantastic. Look, I'm going to build some shitty verse version of the model. You tell me what I got right and what I got wrong, but I have a board meeting in 16 days, and I need to be able to walk them through the justify why I am spending so many calories on this exercise."

(00:36:34):
You build the model, you hand it to them. If they in any way respond to your model, you've won. Because you have now divorced history from future, and you are now playing in future, you are playing the Instagram game in this case. The ending of the story for the company that I was describing, it was a business sub 2 million in revenue. Our prospects of raising series B felt low. We were not yet profitable, and that was an exit that was generational wealth for the co-founders and their families. The CEO went on and spent two-plus years with the now public company that did this acquisition. The technology did get integrated, but it took a long time and they had to do a lot of changes to it, certainly beyond what was envisioned during the diligence process. But all parties are happy. And if we hadn't done it this way and we had just been up for sale, we'd get a dollar for that company.

(00:37:40):
A couple of other side points that are really important here. For any of you founders out there that are thinking about working backwards from an exit, there are two things that I really want to stress. One is the fantasy is beyond just, "What is the business change you can have?" The fantasy is, "Your books are in order." Your fantasy is all of your investors will sign off on the deal and you will have unanimous consent, that the key members of your team are going to stick around, that you're a joy to work with. Please God, founder, do not puncture the fantasy at any time.

(00:38:21):
So whatever is starting to shape in your buyer's mind, get to know it. Live that everybody wins from that game. Second, Corp Dev, they will probably show up in the stands. Corp Dev make deals. They're not deal sponsors, they're not a champion, they're not a buyer. They are an expert negotiator. Their job is to facilitate deals and get deals done. The most important things to understand is that they can be a leverage point to have a deal move with some process and some pace and some urgency. Because either deals have momentum or they die, and Corp Dev can help there.

(00:39:04):
Second, they are way better at negotiating than you. So anytime dealing with a superior negotiator, the only thing you can do to try and even the scales, is move the negotiation async. So founders, repeat after me, I'm talking to you directly now. You'll say to Corp Dev, "You know I'm not alone in this decision. I love what you just said and I'm excited about this opportunity. Once I see it in writing, I can socialize it with advisors, lawyers, co-founders, whoever." But don't negotiate live. You will lose.

Lenny Rachitsky (00:39:39):
Let me just say that was extremely delightful to listen to. I've never heard like a M&A strategy be this fun. And it makes me want to sell a company. It's like, "Okay, let's do this. I'm hyped." I think you got it all. I have a few questions.

(00:39:56):
Interestingly, the middle part is... It feels a lot like enterprise sales, which a lot of founders are used to. Understand the stakeholders move things forward. Here's your champion, here's your blockers, here's the buyer. Is there anything there you want to say, what's maybe most different from enterprise sales, which I think a lot of founders are maybe used to? Or is it pretty similar?

Jonathan Lowenhar (00:40:14):
Yeah, I think three things. One is there are a lot of moments in enterprise sales where we're trying to push for a compelling event. That doesn't work in seduction. The playful metaphor that we'll often use, is you've been dating for a while, this person could be the person, but they're not quite convinced yet that it should be a life together, and you're sitting at dinner. And in enterprise sales, you're eager to get it done. You're eager to move the relationship forward and move in and get engaged, what have you. And so you might be inclined to say, "Hey, either we move this relationship the next step, or there are a whole bunch of people eyeing me, and I'm going to go date someone else."

(00:41:06):
That conversation never goes well, and in Magic Box founders are eager to do the same thing, thinking that competition will improve their deal size, when in fact I think more often than not, that is a negative signal until the very end of the dance. So instead in enterprise selling where I'm pushing, in Magic Box, I'm always trying to entice, I'm never, ever trying to push. So instead I might say things like, "Hey, I'm going to raise my next round in Q1, because I've been intending to do this business independently. Now all I really want to do, is win. I just want my product in as many customers' hands as possible. Whether I do that on my own as I was planning, in partnership with someone, or under someone else's roof, honestly I don't care. But I have a company to run and I'm going to go raise my next round in Q1. And if I do that, probably too expensive for this deal to make sense anymore, and my board will want me to move on anyway." I'm enticing. I'm never trying to push.

Lenny Rachitsky (00:42:15):
This episode is brought to you by Vanta. When it comes to ensuring your company has top-notch security practices, things get complicated fast. Now you can assess risk, secure the trust of your customers and automate compliance for SOC 2, ISO 27001, HIPAA and more, with a single platform, Vanta.

(00:42:36):
Vanta's market-leading trust management platform helps you continuously monitor compliance alongside reporting and tracking risk. Plus, you can save hours by completing security questionnaires with Vanta AI. Join thousands of global companies that use Vanta to automate evidence collection, unify risk management, and streamline security reviews. Get $1,000 off Vanta when you go to vanta.com/lenny, that's vanta.com/lenny.

(00:43:08):
Okay, so I'm thinking about as a founder hearing this, and I feel like what they're probably wondering is that first step of finding that person, starting to build this fantasy. Any advice you could share for a founder that's like, "We probably need to sell this company"? What can they do to start creating these relationships, find this person, create this fantasy in their minds?

Jonathan Lowenhar (00:43:28):
Ezra does this really well in the book. Again, it has to be not solicitous. So one of our companies, we had maybe 20 months of capital left, and the two co-founders and our team were convinced, "This isn't a venture business. We thought it might be a venture business. It's not a venture business. It takes too long to do a deal that's not that interesting with each of our enterprise customers." It was disappointing, but at least we were honest about it. "Okay, so who are we going to sell to? Let's go play this game."

(00:44:04):
So we started with categories, categories of buyers. It could be, for this particular example that was in my head, ERP companies could be a buyer, large banks could be a buyer, the big software companies like Microsoft could be a buyer. There were a few different categories. And we said, "Great. Who are the companies within those categories that make sense?" They're acquisitive, they have the balance sheet for it. There's a Corp Dev department, so we know that they actually know what they're talking about here. Ideally, there's an existing relationship with core team or advisors or board members. Make a list.

(00:44:45):
Now, how do we meet them in a way without selling them? So one of the examples in the book, which I love, is small startup wants to meet the luminaries in a space, and they have their PR agency set up a panel where they contact the CEOs of the potential buyers and say, "We're putting together a panel of the world's foremost experts in X. We're going to put four people on the panel, and it's going to be you and famous person number two and famous person number three, and this fourth person," that is a luminary to us. And it's our startup CEO. And suddenly you're at the table as a peer. It's a completely different conversation.

(00:45:32):
The second one, and this is going to sound a little silly, but I am not exaggerating, it works. If you are a CEO founder and you have that title on LinkedIn, it's amazing the responses you'll get. So we made this list and we just started to send connection requests to the CEOs or CPOs or CFOs on our target list, and said something as simple as this, "You're doing something really cool. So are we. You game just for a 30-minute chat? Because I don't know where it'll go, but I think it'll be fun." Keep it that informal. It's peer to peer. I'm not selling you anything.

(00:46:10):
If you can draw a line to some post that they had or some speech that they gave, even better. But we found without fail, there would be math that would show up, one out of four, one out of five, or one out of six, "Yeah, that sounds fun." There's a lot of those CEOs never talk to startups, and that's fascinating to them, especially when presented with the energy of, "I just want to have a fun, intellectual discussion."

(00:46:37):
What you're looking for in that first conversation, and this is what we ask our CEOs to do, is to ask questions like, "What do you care most about in the next year? What's the mandate? What about for your department? What are the things that keep you up at night? What's the break? What's the thing that could actually kill everything, if you had a pre-mortem for the next year?" Those kind of open-ended questions, because what we want our CEO listening for, is the fantasy to see if there's some intersection between what they care about and what we might be able to squint and say we do.

Lenny Rachitsky (00:47:07):
It's interesting, because it sounds a lot like there's a jobs-to-be-done framework here, or just like, "What is the job they need done?" What is the pain you're going to solve, and then create a fantasy around how amazing it'll be for them if you can solve that problem.

Jonathan Lowenhar (00:47:19):
And ideally they'll say it and you just reflect it back in active listening.

Lenny Rachitsky (00:47:25):
Chris Voss negotiation style. Okay, so you're the kind of guest, Jonathan, where the whole podcast could be about each one of these topics, and so I know there's so much more to talk about here. I want to move to a different topic, but to leave folks with, one is if they want to explore this methodology more, there's a book you mentioned, called Magic Box Paradigm by Ezra Roizen, right?

(00:47:51):
If companies are in this process, starting to think about it, does it make sense for them to come to you and like, "Hey, help me through this process"? I know you said, "Go to an investment banker." Or does it make sense to like, "Hey, let's bring on Jonathan," or someone from your team to help them?

Lenny Rachitsky (00:48:00):
It makes sense to like, Hey, let's bring on Jonathan or someone from your team to help them.

Jonathan Lowenhar (00:48:03):
We meet two types of founders. Founder one says, fix this part of my business, totally transactional. I want to raise the next round, or I'm hiring people badly or my founders aren't getting along, or I want to sell my company. Well, I need to be honest, that's not interesting to us. That's not our work. Go find someone who is, and I don't mean this disparagingly, but like a screwdriver, like fixes one thing, go fix one thing. Then we meet second type of founder and that founder says, most likely to themselves, 'cause it's the only safe audience. There's some gap between the CEO I am and the one my company needs me to be. There are a set of skills that I'm great at and there are these things where I know if I'm really honest with myself, if I listen to the quiet voice, I'm soft at these things or I'm not good enough at these things or I have some imposter syndrome about these things and if I don't get better at them, danger. That's the one we work with. And it's when they care that much about both the hard skill development and maybe the soft skill development in their path to become a great CEO.

(00:49:10):
How to sell the company. It's one of the skills. We teach this to all of our founders as well as hiring and management and planning. I don't care what the thing is. For every one of our founders, we audit them and say, here's what you're great at, here's what you're shitty at, and here's what you've never done before, and which of these do you want to work on next given where the company is in its cycle.

Lenny Rachitsky (00:49:29):
Great segue to where I wanted to go with this, which is hiring. So I hear all the time that a founder's core job is fundraising and hiring an amazing team. Basically that's their main goal. Just like hire amazing people. The people you hire make your company, create the culture. You got to get that right. But similar to trying to sell your company, most founders have never really hired lots of people, they've never hired for all these different skill sets they're trying to hire for and I know that you guys spend a lot of time helping founders hire and find amazing people. Can you just share some of the advice you share with founders for how to find and hire amazing people?

Jonathan Lowenhar (00:50:06):
Yeah, so we actually think the CEO has three jobs. We agree with the two that you said, but we think there's a third. One is, make sure everyone knows where we're going. The second one, pick the right people for the team. Third one, give those people the tools they need to win. And you can abstract from those what they all mean, but-

Lenny Rachitsky (00:50:27):
I love that.

Jonathan Lowenhar (00:50:28):
... most founders are really bad at hiring. They fall prey to all sorts of pretty common human biases. The lazy ones, back to laissez-faire, think it's just gambling like, oh cool, they worked at Meta and Salesforce already, so hire them, just gambling. There was work done by and then codified in a beautiful book. I'm going to make sure I get the names right, Geoffrey Smart and Randy Street. They had a consulting firm that dates back to the mid-nineties. Then they wrote a book in 2007 or 2008 called Who: The A Method for Hiring. We have operationalized that book and then expanded on it 'cause there are some parts of it that we found a little dated, but it's really still as applicable today as it ever was.

(00:51:18):
And I think there are three core mistakes that founders make all the time, that can be really easily rectified. The first one is, you should hire people who have already done the thing you need to have done next. And I know that sounds simple, but founders don't think of hiring that way. They start with a job description. We've been taught that for a long time. Start with the job description. It's a fucking mistake. Start with, it's 12 months later, you hired the person, they started today, 12 months have gone by, you're clinking champagne because of how great it's been. What's changed about the business? What does success look like 12 months later? Document it. And then when you interview people, look for people that have already done that stuff.

(00:52:13):
Second, the notion of does the person in front of you have a history of creating raving fans? They talk in the book about this idea of you being pulled or pushed in your career. If you were an outstanding performer in Job A, it is a high likelihood that in job B, someone associated with you in job A is going to pull you into the next thing and then pull you into the next thing and pull you into the next thing and you'll never do a job search 'cause you were great. And if you see a history of that, ding, ding, ding, ding, ding, really attractive candidate. Third, core values matter a lot. Culture is not an accident. Culture at scale is the codification of what matters to a business and the ritualization of living those values. It starts with whoever the founders are and then it will emanate across as long as the founders are super consistent. But that also means you need a methodology for evaluating the next human in front of you on whether they actually represent your values. We think of these interview stages in a way similar to the book, we use slightly different language, but we think that there is a culture interview, there is a functional interview, and there is a technical interview, but they're designed to get at these notions of have they actually done this kind of work before? Have they been pulled or pushed in their career and are they your kind of human?

Lenny Rachitsky (00:54:00):
Funny on that last detail actually, [inaudible 00:54:03] at Airbnb, there was actually a core values interview team that was formed around studying what the founders Brian, and Joe, and Nate valued specifically and then they codified them to core values at the business and then there's this team that was a very select handpicked team that at every interview loop interviewed the person for their values.

Jonathan Lowenhar (00:54:22):
That is a beautiful example of how interviewing for values is independent of title. 'Cause you'll find people in the company at every stage of a company that are the best ambassadors, the best embodiments of those values. Please use them for interviewing and in addition, they love it 'cause they're protecting their castle. They love where they work, they want to keep it that way.

Lenny Rachitsky (00:54:45):
So true that team is a real special team and it was really honored to be on that team. So let me summarize what you just shared, which I love. There's so much value here, it just keeps going and going. So when you're hiring, your advice is: look for people, one, that have done it before; two, that have been pulled from job to job by someone else that loves their work and wants them to be with them at this new company. And then three, their values match the values of the founder and the business essentially, right?

Jonathan Lowenhar (00:55:11):
Yes. And for the recruiters out there, a really simple way to get rid of a lot of the crap that ends up showing up at the top of the funnel is just to ask the simple question even in the cover letter, of your last ex-bosses, how many would get on the phone and say, you're amazing? If there's any equivocation in the answer, great, move on.

Lenny Rachitsky (00:55:35):
So a couple of follow-up questions here. One is, this point of hiring people that have done it, obviously this implies don't hire junior up-and-comers as much. Thoughts on just when it makes sense to hire someone more junior that's really ambitious, real smart, you think they can learn the job, thoughts there?

Jonathan Lowenhar (00:55:53):
So one of our companies is hiring a team of reasonably junior account execs. We're looking for folks that have been out of school for two years. Now, that means they are highly unlikely to have had three years of quota achievements and a similar... you get the point. Okay, so how do you hire someone who's already done it? We know what success looks like 12 months later. For that role, they've learned how to hunt, they've been able to create pipeline of X and close Y in business, et cetera. What we are looking for then in their history, if they have any sales chops of any kind. They could be selling Girl Scout cookies, or tickets to some event, or they work for a non-profit for while. I don't care, but I want some evidence that they've sold. I want some evidence that they're comfortable getting on the phone or showing up at meetings or showing up at events. So, that they've done it before should be reviewed or thought of creatively.

Lenny Rachitsky (00:57:07):
Got it.

Jonathan Lowenhar (00:57:07):
Now for more senior roles, I want an explicit. We think of, for example, for executives, Lenny, we think there are three types of executives that startups end up hiring over time. We call them the architect, the optimizer, and the scaler. The architect, let's use sales as an example. This is someone who has to build a playbook. So they're going to uncomfortably stay close to the founder, watch and listen, and listen to recordings and pick their brain to pull the magic from the founder of like, oh, here's the dance that she or he goes through to actually close a deal and they write first playbook. And the goal of the codification of that is so you can bring on a first account exec and the next account exec because account execs back to our language earlier in this adult children dynamic are children. You need to give them structure for them to win. That's the architect. The optimizer, this is someone who's now going from a few account execs to maybe 10, 15 and we now have targets we have to hit. The business is now reaching a different level of professionalism and expectation and you have to optimize that earlier playbook to try and find more efficiency and performance out of it.

(00:58:21):
The scaler is saying, okay, now how do I find leverage? How do I have 10X more account execs or how to get other people to sell for me? They're all going to be called VP of sales or chief revenue officer. They're completely different archetypes, and that same person exists in engineering and in product, et cetera. In those cases, I only would want to bring on an architect if they'd been an architect before. If they'd only been an optimizer, they're going to fail because they've never written playbook from scratch.

Lenny Rachitsky (00:58:50):
It touches on a conversation I had recently. It was a live podcast recording with Shreyas Doshi at my summit where he talks about a lot of people are really frustrated at work because they're in the wrong one of those buckets, essentially. Like you enjoy certain type of work and your job is not doing that type of work, whether it's in your case scaling or optimizing. And so, it just reminds that if you're frustrated at work, you're in the wrong job in terms of the type of output they're trying to expect from you.

Jonathan Lowenhar (00:59:18):
The story in my head is that talking to me and my colleagues sometimes can feel a little like death by frameworks. We have one for everything and in this example, I think if you're going to be sustainably successful in any kind of job, I don't care what it is, three things have to be true. You have to be good at it, you have to like it, and the market has to give a shit about it. And if one of those is off, you're not staying in that job long.

Lenny Rachitsky (00:59:40):
Yeah. And this touches on the name of your firm, Enjoy The Work, got to enjoy the work to make it sustainable. Okay, one other thing. So one other follow up question real quick on the hiring and then I want to talk about one other bucket of work. And again, I think each of these could be like an hour, two hour long podcast conversation. I love that there's this recurring theme of working backwards to inform what you do today. So earlier you talked about working backwards from what the outcome you want next for your business, whether it's fundraising or exit or winding down. And for hiring, you have the similar advice, work backwards from what you want this person to achieve in the first year, whether it's drive this sort of growth in the product or drive sales. I guess anything else there of just the power of working backwards versus the typical approach for hiring, you talked about job descriptions.

Jonathan Lowenhar (01:00:26):
Hiring is never the goal and it's often the first thing that we'll hear from a founder, "I have to hire this person." One, that is so dangerous for confirmation bias. The hiring manager is always the one most burdened by that particular bias, but it's also hiring is never the goal. We will pull them back to over and over and over again, which of the three milestones matter, right? Fundraise, exit, profitability. What has to change about the business, for example, to get to that fundraise? How do we quantify that change? Some sort of goal setting framework. OKRs, EOs, I don't care. All goal setting frameworks have the same bones. There's some description of it, there's some quantification of it, there's some work that has to be done. There's some accountability rituals with clear owners and clear agreements.

(01:01:18):
So once I actually have the quantification of here's what work needs to be done, I now know what resources I need to be able to pull that work forward and therefore now I know what kind of humans I need, whether I'm hiring or renting. And that should drive the conversation, not the, "Oh God, I need another PM." It's no, here's the set of features that we've said matter most this year. Here's the gap in the resources we have and the resources we need, that's why we're hiring this role. And here's what success would look like 12 months from now or six months from now. So they're tying back to what would change about the business.

(01:01:57):
And this is this recurring theme of our work with our founders. They're so in it Lenny that they rarely have time to sit above what they're working on. This notion of working in the business versus on the business. And so much of our work is to separate them from the day-to-day, which is enormously important, not in any way denigrating it, and I need to know where I'm headed and why, and how I'm going to measure progress along the way. And so, so much of what we're doing with them is to say, I want to hear from you what you think success looks like. I'm going to push back and pressure test a bunch of things. Can we define that in a way? Can we agree on who needs to do the work along the way, and how we're going to keep checking on it to keep feedback loop short? Now we can go back into business and then we'll check again in a week or in a month.

Lenny Rachitsky (01:02:54):
I love that. That's actually a great segue to the final bucket I want to spend some time on which is growth and go to market. Another area that many founders have never worked on before. A lot of founders are like, Hey, I have this awesome idea. I'm going to build this awesome product. I know how to do that. I know what market needs. But building a go-to-market motion to get it into people's hands is a whole different skill. We spent a lot of time on this on the podcast, you have a really cool simple framework of just how to think about go-to-market. There's all this like, oh, you need a go-to-market strategy. Talk about how you talk to founders about thinking about what it takes to put together a go-to-market plan and how to make it a repeatable motion versus just I'm just going to go to people and try to sell them.

Jonathan Lowenhar (01:03:37):
Our founders, even the most capable of them find this topic pretty overwhelming because it branches into so many areas. So we do try and distill it to something that is in bite-sized chunks. We think of it in four pieces. The first piece is ideal customer profile. Who do we really want to sell to? What are their qualifications? What are the discovery questions we would use to get to those qualifications? What are the kill criteria to know that this is [inaudible 01:04:10] fool's goal, this really isn't the human?

(01:04:13):
Second bucket, loosely called marketing. But within that marketing is also positioning. So what is our uncommon denominator from the enemies? So who are we competing against? Is it actual companies or is it status quo in some sort? What are they great at? What are we great at? What are we great at that they're not? Then how do we represent that in the world? That's branding and artifacts and identity work, et cetera.

(01:04:44):
Next is demand gen, which we'll simplify to say, how do we go find the humans we want? I've long loved the book Traction that Gabriel Weinberg... I'm going to forget unfortunately the co-author's name right now, Jason Mares? Sorry. Where they talk about the 19 channels that all companies have availability to, they're the same ones. Now the book has got a couple of years on it, so there are a couple of new channels that have popped out since, but what we then try and expand the aperture for our founders is rather than just think about meeting your next customer through however you did at your last company, availability bias, instead, which of these might make most sense next? A simple two by two matrix can work here like some experimentation, some brain writing. Love brain writing, not brainstorming. I know you've talked about that on prior pods. And then high impact, low effort. Can we think of the three or four experiments we want to run by channel? Let's go play.

(01:05:48):
And then fourth, sales. And this is the codification of a playbook. How are we having the conversation? How are we doing discovery? How are we handling objections? How are we doing demo? How are we moving to close? If we can get through those four, then we can start to talk about deployment and customer success and upselling and account management, et cetera, et cetera. Those are good problems to have. Oh my god, my install base is so large, I need to manage it. Great, great fricking problem. But we try and break this complexity of going from individually selling to building a machine into just these four buckets. Who am I selling to? What do we want to say about ourselves? How do we reach them? How do we close them?

Lenny Rachitsky (01:06:28):
Amazing. I was going to summarize that. You did an excellent job there. Before we follow up on this, you mentioned this term brain writing. What does that mean?

Jonathan Lowenhar (01:06:35):
Oh, first time I heard of this was Adam Grant. I don't know if he's the originator of the idea. Brainstorming, you talked about this a bit in your Annie Duke podcast as well of how horribly coercive meetings can be.

Lenny Rachitsky (01:06:55):
For brainstorming, especially.

Jonathan Lowenhar (01:06:56):
For brainstorming especially. And so, what many of our founders don't recognize because they just see like, Hey, I'm just sitting around a table with a group of folks I respect, so we can just debate things as peers. No, you can't. You're a founder. Your voice has a megaphone attached to it even if you can't hear it. So you have to turn down the megaphone if you actually want to learn what your people have to say. So brain writing is I'm going to expose an idea and I want everyone to now write and weigh in on there... it could be in a survey, it could be in a shared doc, what have you, my preferences in through some sort of methodology, you are now sharing your opinions, comments, edits, dreams, in an async way that no one else can see until it's all combined, maybe even ideally without authorship identified.

(01:07:50):
Then when the founders weigh in, you don't know, they're just a part of the mass. Let everyone read the thing. I even like the Amazon, take the first 10 minutes of a meeting, let's just go read so we're all fully present and then have a debate. What it allows for is the dampening of the founder effect in meetings.

Lenny Rachitsky (01:08:18):
You're just so full of golden nuggets. That's just like a random tangent that I think could be really transformative for a lot of teams. So the advice here is just when you're trying to ideate and brainstorm, don't go in a big room and put post- its on a wall and talk throughout ideas and have a discussion. Instead, just everyone individually sits and thinks and shares their thoughts and the founder presents, here's a problem, here's a question we're trying to tackle.

Jonathan Lowenhar (01:08:39):
What it also allows for is an evening of the playing field between fast processors and slow processors, introverts and extroverts, because they're all equally potentially talented in your room, but if you do live brainstorming, you have diminished all the folks that prefer to sit and chew on something first.

Lenny Rachitsky (01:09:02):
That's very much me. That's exactly how I operate. I need to think and process. I'm not on the spot quick thinker person. So 100% fan of this approach. Let me come back to your go-to-market framework. I have the notes pulled up here. So basically if you're a founder or even a product builder and you're trying to think about how do I... people keep telling me I need a go to market plan, I need to grow this thing. How do I think about this? You're basically saying there's these four buckets to think about; who are you selling to? How are you going to motivate them and get them excited to buy your thing? How do you reach them? And then how do you close them?

Jonathan Lowenhar (01:09:37):
Yes.

Lenny Rachitsky (01:09:39):
Luckily I have podcasts and newsletter posts on every single one of these buckets, if folks want to pursue each one of these. I have templates for ICPs, marketing advice, all these things. So that's good news. There's a lot of content for people to read if they want to explore this stuff. Let me ask you, where do you often find the biggest bang for your buck when you come to a founder or if founder comes to you and they're like, I need to figure out, go-to-market motions? Just start from the top and work your way down. Or is there, here's where maybe you want to spend a lot of time.

Jonathan Lowenhar (01:10:10):
Early stage founders, and this is certainly more true for the first timers Lenny than the veterans 'cause they learn this problem. The first timers are like twenty-something year olds in a bar and they're being social for the first time in their lives, and anyone that makes eye contact with them is enough for them to say, I want to go on a date with you. That's it. There's no discrimination of any kind, like, oh my god, they like me, I'm in. That's the mistake that hounds first timers. The veterans and those we get our hands on. Instead, we say, let's imagine you could build your perfect customer in a lab, like a Petri dish and you grew them, what do they look like? And if you have any kind of install base, I'll ask the question. I just did this with the founder the other day. They are enterprise whale hunting business. They have four large customers.

Lenny Rachitsky (01:11:13):
Wait, actually whale... okay, whale hunting in terms of large wealth person or actual whales?

Jonathan Lowenhar (01:11:21):
The extreme of enterprise selling.

Lenny Rachitsky (01:11:23):
Okay, okay, got it. I want to see a whale hunting startup. Okay, go on.

Jonathan Lowenhar (01:11:29):
I said, so which of your four customers is your favorite? Which one, if I got them on the phone, they would rave about you. They would be salivating openly with a chance to evangelize what you're doing for them. And they was like, oh, that's clear. It's this one of the four. Great. Tell me about them. And what you start to see and pull apart from that is the founder does have an ideal profile. They do have a dream. Now, there are all sorts of risks about is the world too small? Is it not a big enough market if they get too tight, and founders get so caught up in that and it's a mistake because all we're-

Jonathan Lowenhar (01:12:00):
... so caught up in that, and it's a mistake. Because all we're looking for in the beginning is a white-hot center of opportunity, a small population that is an enormous fan that's getting enormous impact. We can worry about adjacencies and expansion later. I like to remind them that Amazon just sold books. We can start with one thing and be great at it. So where the founders often get hung up on for us is that they've moved towards selling without contemplating ideal customer profile, without contemplating qualifications, without contemplating discovery questions that get to that. And most importantly, kill criteria, if this is true do not sign them, even if they want to go out on a date with you.

Lenny Rachitsky (01:12:48):
I'm glad you said that because that's exactly what I believe and I hear often on this podcast is how underappreciated picking your customers in early leads are. And if you think about this funnel you described, figure out who you're selling to, how do you motivate them, find them and then sell them, all this trickles down from who are you going after. You will know how to motivate them if you know who you're talking to versus the opposite. If you're talking to everyone-

Jonathan Lowenhar (01:13:11):
It's the most expensive mistake of those four.

Lenny Rachitsky (01:13:15):
Okay. Is there anything else on go-to-market or growth you think might be helpful just to touch on before we close up our conversation?

Jonathan Lowenhar (01:13:25):
The one thing I'll share, this goes back to the ready, fire, aim that we talked about earlier, is that there's implicitly a funnel, mathematical funnel, to what we just described. And founders often make the mistake when planning for the year ahead of I need to be at this revenue to justify this multiple. And then all of the funnel math is a plug, and that's death, as opposed to here's what's been true for the last three months, six months, nine months, 12 months. And then what assumptions can I reasonably make with ways I'm going to influence that funnel going forward, to go build up to where I think I'll be a year from now? And it just lowers the bias that your planning process operates with.

(01:14:15):
But when a founder starts from a place of, "I have to get to 3 million or we're dead," you're already dead. As opposed to what do I really believe I can do to get there, changing top of the funnel, changing conversion rates along the way, changing a deal size or deal length, et cetera based on my recent history, and then have a conversation about the gap between where I think the business reasonably can get with some ambition, and where I think I need to be financially, because that's the more mature conversation and that's the one the ready, fire, aim CEO doesn't have. That's the one most founders have only started to learn to have over the last few years when capital dried up.

Lenny Rachitsky (01:14:57):
I love that. I love just how practical and real talk your advice always ends up being. Speaking of that, I emailed a founder that you work with and asked him, "What should I ask? What should I ask Jonathan when he comes on the podcast?"

Jonathan Lowenhar (01:14:57):
Uh-oh.

Lenny Rachitsky (01:15:09):
And he said something that was really... That's great. It was really unexpected what he said. He said that the biggest lesson he learned from you is to, as a founder, to trust his intuition more throughout the journey of his startup. Can you just talk about that as something you've learned, something you've seen, that maybe founders under appreciate?

Jonathan Lowenhar (01:15:31):
It's impossible not to be a startup CEO and not face many existential moments. Is my company going to survive? Did I make a mistake? Will I ever be hired again? Should I sell the company now? Should I break up with a co-founder? Should I fire this critical employee? They happen to all of us. And fear is not a good decision maker. Our lizard brain is a really bad decision maker in those moments.

(01:16:07):
And so what we'll often share with the founder who's facing one of these scenarios, and I know the CEO you're describing and he's facing one of these scenarios, we'll say to them, "Do you know that little voice when you get really still, the quiet one that says you should marry this person, you should take this job, you should start this company? Watch out for that human, they're a bad one." And most of the time, Lenny, when I frame it that way the person across me says, "Yeah, I know that voice." And I'll ask, "How do you hear it?" And they're usually some version of, "I have to get really alone, really still, really quiet, walk on the beach, listen to music, work out, play with my pet."

(01:17:06):
I said that voice is who you are. It's not your brain. Your brain is a tool. It's our hands, it's our feet, just a tool. It's a pattern recognition machine. But who you are, if you can watch your brain, you know what you're thinking, like, oh, look what my brain's doing. That means you're not your brain. It's something else. And that's the little voice, and that little voice is going to be right. And where we get screwed up in life is when we stop listening to that voice, when the mania of our chaos of our lives get in the way of that voice.

(01:17:42):
And so whenever our founders face one of those moments, it's not a framework, it's not a playbook, or even a directed piece of advice from us to say, "You should just go left. I've seen this before. Go left." Nope. I trust founder intuition. If the founder says this business is still going to work, or this co-founder is the wrong person, or yes, it's time to sell, I'm in. We're just here to support them. And we try and be the only person in their life that is fully on their team because we're not on the preferred side of the CAFS table. We're not fiduciary, we're not board members, not a co-founder, none of those things. And so in those moments we'll just say, "Can you get really quiet?"

(01:18:21):
And the founder you're talking about, I have the story in my head, he was facing a breakup moment with his co-founder, and I asked him, because he's good at getting quiet, "What did the voice say to you way back when?" And the voice said to him, "This is the wrong fit. This isn't going to work. He believes in different things than I do, and that's going to go badly." But the lizard brain didn't want to believe that, and so it took another year.

Lenny Rachitsky (01:18:58):
Wow. I had tingles throughout that entire piece of advice. I love how it's also very applicable to just life, not even just being a founder. It's a good reminder to trust that voice more. It's interesting that this also connects to founder-mode a little bit, and I'm curious how you think about that where a lot of the founder-mode advice is like trust your judgment, don't hire people to delegate things away. Do you see a difference in the core idea of founder-mode and just like, but you should actually trust your intuition more?

Jonathan Lowenhar (01:19:35):
Intuition comes from, in my point of view, a deep understanding of self, and the capacity to get quiet and be well resourced, meaning you've slept well and you've eaten well and you have enough love in your world. And I think what founder-mode can confuse is my intuition says I should just do this job for them and fire these three people. That's not intuition, that's reaction, that's a fear response. And when the founder says, "I sat with this, I felt it out, I can see it. I need to terminate my whole go-to-market team and start over. This isn't working, and I have data that supports it, but I know this isn't working." I'm like, "Let's go with that. I'm in. Let's do it."

Lenny Rachitsky (01:20:36):
And I think you described a lot of times people feel this, and it takes a year, two years, three years, many years to actually realize that. And your advice here is try to listen to that more and trust it more. Yeah. Wow. Okay. Well, Jonathan to pivot our energy, is there anything else want to leave listeners with, last piece of advice, anything that you think might be helpful before we get to a very exciting lightning round?

Jonathan Lowenhar (01:21:04):
To be a founder is a state of being. It's an attitude, it's courage, it's instinct, it's a capacity to push through, despite all sorts of evidence suggesting you're wasting your time. To be a CEO is a craft. The more founders who can accept that those are two separate things and they're both equally important to build an ascendant startup, the better all of us will be. And so what I would encourage every founder out there that wants to go build something substantial, go work on your craft in addition to working on the business. Be honest with yourself about here's the shit I'm bad at. I don't know how to read a financial statement. My board meetings suck. Half my meetings that I have with my leadership team we all walk out of there saying what did we just accomplish right now? Or I get to the end of my workday and I'm like, I didn't get anything done. Those are all examples of just not taking the craft seriously enough. I'll leave with that.

Lenny Rachitsky (01:22:18):
I love that. And I think I've made the mistake during our conversation of confusing founder and CEO and assuming they're the same thing, and I really appreciate you just again pointing out to folks that that's the big distinction you got to start making is there's the founder and there's the CEO. Often they're same person, but different parts of your brain and different skill sets.

Jonathan Lowenhar (01:22:36):
And I'm now fully off the very awkward soapbox I've been sitting on for a long time, so we can go to lightning round whenever you're ready.

Lenny Rachitsky (01:22:44):
With that, we've reached our very exciting lighting round. Jonathan, are you ready?

Jonathan Lowenhar (01:22:48):
I'm ready. I'm ready.

Lenny Rachitsky (01:22:49):
First question, what are two or three books that you have recommended most to other people?

Jonathan Lowenhar (01:22:54):
My number one business book that I've recommended would be Five Dysfunctions of a Team, by Patrick Lencioni. I do think it always comes back to team. The right team can solve all the things. And that book is a beautiful distillation of the most common problematic archetypes that show up in a leadership group. So that's the number one.

Lenny Rachitsky (01:23:16):
Amazing. Anything else you'd recommend?

Jonathan Lowenhar (01:23:19):
The second one, it goes more personal. It's a book called Untethered Soul, by Michael Singer. It was, at least for me, the first introduction to this idea that I am not my brain and that my brain can be a tool that serves me well, and at times doesn't. So that would be number two.

Lenny Rachitsky (01:23:38):
I've started to read that book and then I never finished it, so this is a good reminder to give it another shot. Second question, do you have a favorite recent movie or TV show you've really enjoyed?

Jonathan Lowenhar (01:23:50):
I just watched and really enjoyed, because by the way, I have a three-year-old at home, so the amount of content I now consume is reduced tremendously. Well, my wife and I just watched Will & Harper. This is the documentary between Will Ferrell and his very dear friend who just recently transitioned. They road trip across the country together, and it was freaking delightful. It was sweet and endearing and one of the better things I've watched in a while.

(01:24:19):
TV show, Slow Horses, I'm utterly addicted. I'm only midway through season two, but I've been voraciously sleeping less and watching more.

Lenny Rachitsky (01:24:31):
I love both those. I just watched Will & Harper, and completely agree with your sentiment about it. I wasn't planning to watch it. My mother-in-Law started watching. I'm like, wow, this is really fun. It's also funny, meaningful funny.

Jonathan Lowenhar (01:24:43):
There's so many moments in it that are really sweet. As an aside, this was '20, I don't know, April 2020, and a group of our very close friends said, "Hey, how are we going to keep in touch?" And so we started what we called Movie Club, and we routinely either pick a TV show or a movie. We all watch separately and every two weeks we get together on Zoom at night, we talk about what we just watched.

Lenny Rachitsky (01:25:06):
I love that.

Jonathan Lowenhar (01:25:07):
And some have been great, some have been terrible. But Will & Harper was our most recent.

Lenny Rachitsky (01:25:10):
Oh, such a cool tradition. Okay, we'll keep going. Do you have a favorite product you've recently discovered that you really love? Could be an app, could be something physical?

Jonathan Lowenhar (01:25:21):
Two, and one is I'm going to talk my own book, but I still love it. The first one is Aura Frames. These are digital picture frames. They're amazing. The UX for them is incredible, the quality of it, they're pieces of artwork. So grandparents, in-laws, parents, we have multiple in our house, just love it.

Lenny Rachitsky (01:25:46):
Just to clarify, it's a frame that has picked digital photos and you can give it to your mom and show photos of your kid wherever they live. Is that right?

Jonathan Lowenhar (01:25:55):
And the combination of the ease of the software and the quality of the imagery is better than anything I've tried, and I've tried a bunch of them. A-U-R-A Frames, and this is not an Enjoy The Work company. This is just one I'm a giant fan of.

(01:26:08):
The second one is an Enjoy The Work company called Augie Studio. A-U-G-I-E Studio. This is Canva for video. It can turn anyone with no engineering skills whatsoever, no code video creation, with full editing tools. So suddenly you can create branded high fidelity, high quality commercial video in minutes, with no effort. It's amazing. It was built by two media tech co-founders that were building this thing pre-ChatGPT, and it's just growing like this, and it's super fun, and the guys are great. So A-U-G-I-E Studio.

Lenny Rachitsky (01:26:51):
Sounds amazing. Augie Studio, I could use that. That sounds awesome. Two more questions. I feel like this one's going to be a good one. Do you have a favorite life motto that you often come back to find useful and work on in life?

Jonathan Lowenhar (01:27:04):
The first one, and the one that I probably most commonly refer to, is that there is only one life. The quick backstory, and I know it's a lightning round, but I'm guilty of these stories. I went for a walk with a girlfriend of mine a bunch of years ago. And we did this once a month and we would always have a pretty typical ritual of giving each other life updates to begin the walk. And so I started the conversation with, "So there's the family update and then there's my work life and then there's my social life." She's like, "No, no, no, no, no, stop. That's all bullshit. It's one life. Stop assuming that there are these pretend walls between them or among them." I've lived that ever since.

(01:27:42):
So I try and show up. That phrase lets me show up the same way, no matter my setting. If you and I were having a beer or a meal, or if I'm sitting with one of my co-founders or clients, it doesn't matter, I show up the same way everywhere. Part of the way I enjoy the work is by having a real friendship, a real intimacy with everyone at Enjoy The Work, and including our clients as well, I want that level of conversation. I don't want the sterile stuff over here with my work environment versus my personal versus my family. It's just one version of me.

Lenny Rachitsky (01:28:15):
And the phrase is, it's just one life.

Jonathan Lowenhar (01:28:17):
Just one life.

Lenny Rachitsky (01:28:18):
It's just one life. Final question. So you ran a casino at one point, I believe, and it was like a Harrah's Casino, is that right?

Jonathan Lowenhar (01:28:28):
My first career was in the casino business.

Lenny Rachitsky (01:28:30):
Okay.

Jonathan Lowenhar (01:28:31):
But before I go on, what's the question?

Lenny Rachitsky (01:28:32):
The question is just is there a fun story, or experience, or lesson from that time in your life that might be fun to share? Maybe a mob involvement, or cheating, or something? I imagine that's a unique life experience.

Jonathan Lowenhar (01:28:48):
I'll tell one of my favorite family stories then briefly. But yes, my family goes back in casino gambling in one form or another, several generations. My great-grandmother ran a illicit poker game. My grandfather ran numbers out of a gas station. My father's been in the casino industry since Atlantic City in the 70s. My sister is a prominent gaming attorney, and I worked in the industry for a dozen years, so this is my family. And Lenny, I didn't know any of this was weird until I was in my mid 20s.

(01:29:18):
I turned 21, and I'm old, yes, I'm going to just hide the year. I'm kidding. Anyway, I turned 21 and we take a family trip to Las Vegas because that was normal for us. My father was doing a lot of work out there, so he got us hotel rooms, etc. I'd never been there before, and I was newly 21 and so my parents said, "You have $300 to gamble with. We're going to be here for five days." This is a vacation. My grandparents are coming in. My uncle and aunt were coming in, and they're encouraging me, "This is all up to you, but try not to lose it all on night number one," which was good advice to give me. I was 21 and I was pretty much a schmuck at the time. But also, part of my experience being there was to interview for a summer internship. I was a college going to be junior.

(01:30:06):
So we go and I immediately go sit at some table and start playing some games. And I turn $300 into a few thousand dollars in the very first evening. And that was exciting and it was crazy and it was wild, et cetera. On the third night, which happens to everyone who goes to Vegas for too long, we're all delirious because all of us are staying up all night and being silly and being stupid. And my parents ask me, by the way, this is pre-cell phones, they ask me, "Hey, can you stay awake? Your uncle and aunt are going to arrive late tonight. They'll call the room. You can come down and just greet them and say hello?" Sure. So I get the phone call like 11: 30 at night. Go on downstairs, they're here. I go downstairs in the casino floor. We're staying at the Las Vegas Hilton. It's since been renamed, but I go downstairs and I can't find them anywhere. I think, okay, well I have cash in my pocket and I'm now awake so I might as well gamble.

(01:30:53):
Shortly thereafter, Lenny, I have an experience that happens one in 369,000 occurrences, and I win $35,421.92. For the trip I ended up winning $40,000 that I turned $300 to, and I was just 21 years old, which has left me with one of my mantras that I've had for the rest of my life, which some people roll their eyes at, but that is gambling does pay.

Lenny Rachitsky (01:31:20):
I love that you remember the exact amount. What games did you end up playing that helped you win so much money?

Jonathan Lowenhar (01:31:27):
The primary game that I played was Caribbean Stud Poker, where there's no skill of any kind. You get five cards, the dealer gets five cards, whoever wins wins, and if you have particularly unusual hands you get odds on the hand. And I got dealt 3, 4, 5, 6, 7 of spades in five cards.

Lenny Rachitsky (01:31:44):
I thought you'd say slots or something. I love that you're just sitting there playing poker and went from $300 to $40,000.

Jonathan Lowenhar (01:31:51):
It's not even real poker.

Lenny Rachitsky (01:31:53):
That was a great story. I'm glad I went there. Jonathan, this was incredible. I think we've helped a lot of founders through this conversation. Two final questions. Where can folks find you guys? Who would be a good fit? What should people know about Enjoy the Work? And finally, how can listeners be useful to you?

Jonathan Lowenhar (01:32:10):
Love that. So let me unpack those three. The first one is enjoythework.com, or just find me on LinkedIn. I'm not hard to find. Send us a note.

(01:32:22):
Who should ping us is very simple. If you're a founder out there, or a CEO out there, and you know in your heart that there's some gap between how you're running the business and how the company's going, and how it could be going, and how you could be running the business, if there's some gap there, we're here to help. Now our expertise, as we talked about in this call, is company building. So if you just have an idea on a napkin or you have a science experiment that you're not sure, we're useless, that's not us. But if you have some breadcrumbs worth following, like the business is starting to work, you're a series A into B and beyond, and you know that there's better, you can see it, that's where we help. Send us a note. Love to chat.

(01:33:06):
How can listeners be useful to us? So we are ferocious readers. All we try and do is study how do the best startups do X? From tiny things, like how do they run all hands meetings or off sites to the big meta topics of what is going to repeatable go-to-market even mean? Or what is financial planning in a way that's useful? Or how do you set goals that won't make you roll your eyes? We consistently learn from the ecosystem of podcasters and authors and journalists, like, go look at this material. So if your listeners have a favorite X on whatever topic in running a startup, send them my way. All we love to do is read and chew on that stuff.

Lenny Rachitsky (01:33:54):
Awesome. And the best way to send that is either through Enjoy the Work or LinkedIn.

Jonathan Lowenhar (01:33:58):
That's right.

Lenny Rachitsky (01:33:59):
Awesome. Jonathan, thank you so much for being here.

Jonathan Lowenhar (01:34:02):
Lenny, this was so damn fun. Thanks for listening to my crazy casino stories.

Lenny Rachitsky (01:34:07):
I want to hear more, but we got to go. Bye everyone.

(01:34:11):
Thank you so much for listening. If you found this valuable you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review, as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast. com. See you in the next episode.

---

## Managing nerves, anxiety, and burnout | Jonny Miller (Nervous Systems Mastery)
**Guest:** Jonny Miller  
**Published:** 2024-01-28  
**YouTube:** https://www.youtube.com/watch?v=-kN8Agqee4w  
**Tags:** growth, leadership, vision, mission, market, persona, ui, engineering, technical debt, startup  

# Managing nerves, anxiety, and burnout | Jonny Miller (Nervous Systems Mastery)

## Transcript

Jonny Miller (00:00:00):
I have this idea that I call the feather brick dump truck phenomenon, and basically what that means is when we are showing early signs of burnout, our body will give us feedback usually in subtle ways in the beginning. So the feather might be waking up in the morning and feeling a little bit tired, maybe a little bit exhausted. The brick, maybe you ignore that or you don't notice it, and then three or four weeks later, you have a fight with someone or an argument, or you just feel frustrated and terrible and you lose your cool. And then maybe the dump truck is a month later, or even a year later, there's a full-blown health crisis, or you develop type two diabetes or there's a whole range of things, or maybe you get fired. Ideally, you want to notice when it's the feather and then make adjustments or shift then and not have to wait until you experience the full-blown pain of the dump truck, which unfortunately is what happens to a lot of people, especially when they experience burnout for the first time.

Lenny (00:01:02):
Today, my guest is Jonny Miller. Jonny teaches courses and does one-on-one coaching with tech professionals helping them with something he calls Nervous System Mastery, which is essentially a set of tools and techniques for cultivating calm, upgrading your resilience, and increasing your aliveness. If you can get better at dealing with stressful situations, avoiding burnout and being more confident in meetings and big presentations, it becomes a superpower and a huge advantage in both business and in life. I actually read a post by Jonny about a year ago, and it totally changed the way that I think about nervousness and stress, and I still apply many of his lessons today.

(00:01:41):
In our conversation, we dive deep into Jonny's key insights. We talk about why the best way to stay calm in stressful situations is to focus on the state of your body and not your mind. How to create calm and confidence by changing the state of your body through breath. Jonny shares a bunch of very specific breathing exercises for creating calm and also for creating energy that we actually try out on the podcast. We also get into a bunch of advice for how to tell if you're seeing early signs of burnout, how to release emotional debt that you may be feeling. Also, why feeling the feels gives you a competitive advantage in business. Also, a practice called APE, which reminds you to focus on your awareness, your posture, and your emotions that have started practicing ever since our chat and so much more. If you enjoy this chat, definitely check out Jonny's full course at nsmastery.com/lenny. If you use that URL, you actually get $250 off the course. With that, I bring you Jonny Miller after a short word from our sponsors.

(00:02:42):
This time of year is prime for career reflection and setting goals for professional growth. I always like to spend this time reflecting on what I accomplished the previous year, what I hope to accomplish the next year, and whether this is the year I look for a new opportunity. That's where today's sponsor Teal comes in. Teal provides you with the tools to run an amazing job search with an AI-powered resume builder, job tracker, cover letter generator, and Chrome extension that integrates with over 40 job boards. Teal is the all-in-one platform. You need to run a more streamlined and efficient job search and stand out in this competitive market. There's a reason nearly 1 million people have trusted Teal to run their job search. If you're thinking of making a change in the year, leverage Teal to grow your career on your own terms. Get started for free at tealhq.com/lenny. That's tealhq.com/lenny.

(00:03:33):
This episode is brought to you by Vanta, helping you streamline your security compliance to accelerate your growth. Thousands of fast-growing companies like Gusto, Comm, Quora, and Modern Treasury trust Vanta to help build, scale, manage and demonstrate their security and compliance programs and get ready for audits in weeks, not months. By offering the most in demand security and privacy frameworks such as SOC 2, ISO 27001, GDPR, HIPAA, and many more. Vanta helps companies obtain the reports they need to accelerate growth, build efficient compliance processes, mitigate risks to their businesses, and build trust with external stakeholders. Over 5,000 fast-growing companies use Vanta to automate up to 90% of the work involved with SOC 2 and these other frameworks. For a limited time Lenny's podcast listeners get $1,000 off Vanta. Go to vanta.com/lenny, that's V-A-N-T-A.com/lenny to learn more and to claim your discounts get started today.

(00:04:34):
Jonny, thank you so much for being here. Welcome to the podcast.

Jonny Miller (00:04:37):
It's great to be here, Lenny.

Lenny (00:04:38):
So I read this post that you wrote, I think it was over a year ago at this point. It was called The Operating Manual for Your Nervous System, and first of all, blew my mind when I read it. Second of all, I always think about it when I get nervous or anxious in a situation, it's really stuck with me. And I know that people in the workplace often get nervous and anxious doing all hand presentations, meetings, performance reviews, all the things. So I thought it'd be awesome just to dive into the stuff that you've uncovered about how we can become less nervous and less anxious. Before we get into the meat of it, I'd love to just spend a couple minutes just getting a sense of why you got into this stuff. What actually got you to spend so much of your energy and life force trying to understand how the nervous system works, how to get people to be less nervous and anxious.

Jonny Miller (00:05:27):
My story starts in I kind of have a background in tech. I had a startup, we went through Techstars back in 2012. About five and a half years into that experience, I went through burnout, which is pretty common in the startup world, but that actually wasn't the trigger for me. I find that usually people that get into this type of work, there's some kind of catalyst or some kind of challenging life event. And for me, that was October 23rd, 2017, and my fiance at the time had an anxiety attack and she took her own life. And that completely just destroyed me at the time. And I realized that I'd been so disconnected from my body and my emotions, and it sent me on this five plus year journey to discover all of this inner landscape that I'd been numb from the neck down, and I went into breathwork meditation retreats, did hundreds of breathwork journeys, researched with a breath lab over in Bali, and basically just kind of directed all of my focus and attention onto understanding this inner landscape that I'd been pretty much oblivious to. And since then, I've been working with founders, executives, running courses and teaching what I'm learning and hopefully still researching at the same time as well.

Lenny (00:06:52):
Wow. And I imagine the thinking was that if your wife had these skills, she would've had another path.

Jonny Miller (00:07:00):
Yeah, that was definitely part of it, yeah. And also just since realizing how many people are struggling with anxiety, depression, all of this kind of constellation of mental health challenges both in the workplace and at home as well. And yeah, it's been a very rewarding journey.

Lenny (00:07:19):
All right, this episode's already gotten very heavy and I'm sucked in. I'm excited to learn all these things that you've uncovered. So let's just get into the meat of it. Just talk about this kind of general method that you've found for how to help people become less nervous and anxious.

Jonny Miller (00:07:38):
So I find this top down, bottom up distinction to be incredibly helpful. Most people when they try to calm down, they use tactical reframes or maybe mindfulness or maybe reframing the situation in a positive light. There's lots of different practices that people use which do have some effect. But in my experience, working with the physiology, using what's known as a bottom up approach, primarily using the breath, although there's also other approaches that you can use, it's just such a rapidly more effective way of shifting your state.

(00:08:11):
 And to give a little bit of context and maybe some science as well, we have what's known as afferent and efferent neurons going up and down our body, and there's four times more afferent neurons going from the body to the brain as from the brain to the body. So you can almost imagine there's a super highway of traffic of information going up to the brain and four times less going from the brain to the body. And so by learning how to pull on the levers of our physiology, we can rapidly change our state. And then from there, by changing our state, that impacts the thoughts and feelings that we have. So instead of trying to change the story or trying to fix something or trying to solve something, which is what most people do by default, myself included in the past, if you change your state first, then there's a cascading effect which changes your thoughts and your feelings.

Lenny (00:09:06):
Okay, amazing. Yeah, and just to share how I felt when I was reading this and try to understand this approach is whenever I get nervous, there's always this like, oh, my body's starting to feel anxious. And then I think of a reason. Oftentimes, I don't know why it gets nervous, why my body's starting to create this feeling of anxiety. And then I often realize I'm just now trying to just explain why it happened, "Oh, I have this big meeting coming up, or I have this podcast episode I'm nervous about, or I'm not going to make a deadline for my newsletter." I often experience this where it's just like, "Oh, something feels nervous." And then, "Okay, here's the explanation." So maybe just along those lines, what else is there that might be helpful for people to think about in this context?

Jonny Miller (00:09:47):
I mean, I think it's helpful to understand the process by which, by changing the way that we breathe, for example, it shifts our physiological state and changes our nervous system. So if you're listening to this, maybe you, Lenny, you can try this as well. If you start breathing into your upper chest and shallow fairly, fairly rapid, maybe even through the mouth, that will then there's a part of your brain called the insular cortex, which is basically constantly spying on the way that we're breathing and it will register that change, it will then send information to activate the endocrine system, which then creates shift in our blood chemistry. The sympathetic nervous system gets activated and that increase in adrenaline and cortisol starts to flood your body. Everyone's probably very familiar with that feeling. And then that will then have a cascading impact on the thoughts that you're having and the way that you feel. And so you just shared, we have a tendency to kind of confabulate or make up stories that match the state that we are in. And so that's kind of what happens when we're breathing in that way. And then you can also consciously change your breath to breathe in a different way, which has the reverse effects, which I can go into, but I'll pause there.

Lenny (00:11:05):
Yeah. So I think one of the big actionable takeaways here is that instead of trying to convince yourself, "No, this talk is going to go great, I don't need to worry about how I'm going to look in this meeting." Basically instead of going top down, trying to calm your body through thought, your advice is calm your body first because then your mind will notice, "Hey, I'm actually not as nervous as I thought. Maybe things are going to be okay." Is that right?

Jonny Miller (00:11:29):
Yeah, precisely. And I mean I've used this myself many times before presentations. I gave a TEDx talk a few years ago and I was like my entire body, I was just terrified. And I did in 15 minutes of this breathing practice before and walked on stage almost cool as a cucumber. It's very effective.

Lenny (00:11:47):
Sounds too good to be true. But we're going to do some of these exercises for people. Before we get into, why is it that breath specifically so powerful? It feels like such a strange thing to work so well, just this idea of breathing in a different way. You talked a bit about this, I forget what you called it, that kind of watches how you're breathing. But I guess what else can you share about just why is breath so effective in changing our state?

Jonny Miller (00:12:10):
Sure. Well, it's one of the few things which happens automatically, but we can also control it consciously. And so what scientists have discovered that when the exhale is twice as long as the inhale, it has a calming effect. And when the inhale is either more intense or twice as long as the exhale, it has an activating effect. So you can kind of think of this as an up or down lever on the nervous system.

Lenny (00:12:36):
You also have this really clever way of describing this system. You call it state over story, essentially focusing on the state of your body versus the story you're telling yourself. Is that the way to think about it? And can you just talk about that concept?

Jonny Miller (00:12:48):
Yeah, so it's basically a shorthand for what we've just been talking about, which is most people tend to approach the problem or try to solve things on the level of story. So there's multiple ways you can do that through the breath as we just talked about. You can also defocus your gaze and kind of relax your eyes, and that has a similar effect. It can expand your awareness and kind of bring your awareness to behind you and the sides of you and below you, or you can breathe in these ways which emphasize the exhale. And so when we breathe in a way with say the exhale twice as long as the inhale, that part of the brain, the insular cortex then sends signals to the parasympathetic nervous system, which then has the cascading effect on our endocrine system and calms us down. And what I usually find as well is that the kind of reactive thoughts and feelings that we have when we are in that kind of anxious loop, they can be self-reinforcing. And so if someone has a thought of like, "Oh no, I'm nervous before this important presentation." Then that exacerbates the breathing pattern and then the whole thing just goes into this spiral, which can end up in full-blown panic attacks if there's not an intervention of some sorts.

Lenny (00:13:57):
Yeah, that's what I find with my nerves. I hate talking on stage. I get nervous before every podcast. This is not my natural state.

Jonny Miller (00:14:04):
Interesting.

Lenny (00:14:05):
Yeah, and I hide it well.

Jonny Miller (00:14:07):
Is that still the case with podcast today?

Lenny (00:14:09):
Absolutely. And it's like different levels of nervousness, but it's always just like, "Oh, there we go." I'm not a performer person. Even I kind of push myself to do this podcast as a way to get better at this, to be honest. So it's still a thing that I think about. And what I find is the nervousness comes from exactly what you described is the nervousness of being nervous. I don't know, there's no reason specifically to be anxious, but I don't know how I'll be once I do the thing. So it's nervous of what it might look like or end up being like. So that's exactly what I ran into.

Jonny Miller (00:14:41):
Yeah. And there's obviously people say mindfulness, meditation, things like that, that can increase the psychological space between stimulus and response. And that is something that obviously does help over the long term, but it's in my opinion, nowhere near as rapid and effective and efficient as just changing the way that you're breathing.

Lenny (00:15:00):
Awesome. So let's get into it. I know you have a couple exercises specifically for this, and then we'll go from there.

Jonny Miller (00:15:06):
We can stack a few of the exercises and I'll try and keep it to a minute or so. So yeah, if you want to get comfy in your chair and sit up straight, feel your butt on the seat, and I find it helpful to kind of be aware of the space behind you and above you as well, kind of expanding your awareness so that you are aware of the space behind to the sides and above.

Lenny (00:15:29):
And should we close your eyes?

Jonny Miller (00:15:31):
Yeah, and close your eyes down. If you're listening and driving, obviously don't do that. But yeah, closing the eyes down for sure helps. And now we're just going to do simple breath. We're going to inhale in through the nose for four. We're going to hold the breath at the top for four, and we're going to exhale for eight, and then we're going to repeat. So let the breath go and inhaling through the nose. Inhale, 2, 3, 4, hold the breath, 2, 3, 4. And exhale, 8, 2, 3, 4, 5, 6, 7, 8. Inhale, 2, 3, 4, hold the breath, 2, 3, 4, and exhale, 2, 3, 4, 5, 6, 7, 8. And now you can let go of the breath completely and we'll end with one round of humming, which is surprisingly effect of it calming as well. So take a full breath in and humming through the nose all the way to the end of exhale. Let out a sigh if that feels good and open up your eyes.

Lenny (00:17:01):
I feel extremely calm. I should do this every podcast episode before we start.

Jonny Miller (00:17:08):
A note on the humming. It also releases nitric oxide, which is a vasodilator, and that helps to create that kind of calming effect and it also reduces eye tension as well. So I'll do it if I've been looking to screen for too long. It's really good for kind of reducing eye fatigue as well.

Lenny (00:17:24):
And there's also a vagus nerve component to it because your body's vibrating, is that true?

Jonny Miller (00:17:28):
Yeah, precisely. So it kind of tones or stimulates the vagus nerve, which stimulates the parasympathetic nervous system.

Lenny (00:17:35):
What's your advice for doing this? Is this before you go into a big meeting or a presentation? How do you apply this?

Jonny Miller (00:17:42):
I kind of like to share building a toolkit of different practices that are appropriate for different contexts. So something like the 4, 4, 8 breathing, you could do pretty much anywhere without anyone necessarily noticing. Humming is slightly more obvious, but if you're about to jump on a zoom or something, you can totally do it with your eyes closed. Things like expanding your awareness or bringing your awareness down to your feet and your hands, which creates a kind of grounding calming effect that also you can do if you're in a busy room. Maybe you have social anxiety, even orienting and labeling things that you are hearing and feeling, kind of bringing the awareness and attention back into the body that also has an effect. And then there's longer practices for say, non-sleep deep rests, belly breathing, things that you can do if you have 10, 20 minutes and you're at home and you want a downshift.

(00:18:30):
So I like to kind of give people a big toolkit to see what works for them and then cherry-pick which ones are suitable to different situations. And another way that I think about this is, I call it, if this, then breathe. So it's like if I feel overwhelmed, then I do the humming. If I feel anxious, then I do 4, 4, 8 breathing or alternate nostril breathing and kind of having my own little recipe set that I have for different context is really helpful and I work with people to kind of build those toolkits themselves.

Lenny (00:19:03):
This sounds like it needs to be a website where people can go with these lists of if this, then that is there a place that we could send people in the show notes and if not, you should make one before we go live.

Jonny Miller (00:19:13):
There is not currently. It's part of the curriculum in the course that I have, but-

Lenny (00:19:17):
Okay, great.

Jonny Miller (00:19:18):
... I can maybe see if I can spin one up as well, but yeah.

Lenny (00:19:21):
Okay, cool. We'll link to the course if nothing else. Amazing.

Jonny Miller (00:19:23):
Okay.

Lenny (00:19:24):
Along this line of calming breath exercise, Huberman also has a different version, which I've tried and I'm going to do both now. You breathe in fully and then you breathe in a little bit more. I imagine you've seen that piece of advice?

Jonny Miller (00:19:37):
That's also fantastic. He calls it the physiological sigh, and it's both very effective, especially if you just have five seconds and you just take a full sigh, it's great. I'd also add that the sigh happens naturally as a result of doing these downshifting practices. So if you notice after you do let's say the 4, 4, 8 breathing, at the end, you might naturally just want to let out a sigh, and that's a signal that your body is naturally downshifting. Or if you are with a friend and you feel just comfortable and relaxed, then your body might sigh. And it's something that we do a lot and as you say, you can consciously do it and that will help as well. That's another one of the practices.

Lenny (00:20:18):
Awesome. So link to that. And I think throughout this episode, as you said, we're going to give people a bunch of tools that they can use, and it feels like some are in the moment, "I need to feel calmer right now. Here's a thing you could do." And then there's things you can do ongoing that build... I guess another way to think about it's just make your body more calm as a baseline of practice to work on there.

Jonny Miller (00:20:38):
Yeah, precisely.

Lenny (00:20:39):
Awesome, okay. I think the other breathing exercise we're going to do is the opposite. Gets you all excited, is that right?

Jonny Miller (00:20:45):
Yeah, sure. We can do that as well. I call this espresso breath. So this is the opposite. This is very activating. I would only recommend this if you're feeling lethargic or maybe instead of drinking a coffee in the afternoon, you could do this for a minute or so. In the scientific literature, it's bellows breath or breath of fire, and it basically looks like a series of rapid exhales through the nose. I like to keep it through the nose only if you do it through the mouth, it can be very too activating and it can kind of overwhelm people. Obviously, there's the Wim Hof practice that I'm sure many people are familiar with. So this is a more gentle version of... If Wim Hof is like Red Bull, this is kind of like a small coffee.

Lenny (00:21:30):
I like that. And you call it the espresso breath, espresso breath.

Jonny Miller (00:21:33):
Espresso breath, yeah.

Lenny (00:21:33):
So yeah, that's a good metaphor there.

Jonny Miller (00:21:35):
Yeah, yeah. So yeah, let's do it. So again, kind of sit up straight, and this time you want to be pumping the breath from your lower belly and you pump the breath on the exhale. So I'll demonstrate it briefly. It's like breathe in.

(00:21:56):
Okay. So yeah, take a full breath in and begin.

(00:21:58):
And let go. And full breath in. And sigh on the exhale. I already feel a little bit tingly.

Lenny (00:22:25):
I'm energized. Let's do this. Go, go, go, go. That was great. Okay, look at that. We're back to where we started with the full circle of energy. That was great.

Jonny Miller (00:22:34):
Up and down.

Lenny (00:22:35):
And then how long do you recommend doing that one for?

Jonny Miller (00:22:38):
So it kind of depends on how activating you find it, but I usually find 30 breaths per round and then take a breath, have a long pause on the exhale, and then if you want to do another round or two.

Lenny (00:22:50):
Amazing. And the cases where this might be helpful is maybe you're about to give a big talk, I guess in a talk you both want energy and want calm, so that's kind of complicated.

Jonny Miller (00:22:59):
Especially if you are meetings early in the morning and you haven't quite got going yet, you can do the espresso breath to begin with and that activates you. And then do some of the downshifting practices to kind of ground and stabilize that aliveness.

Lenny (00:23:12):
Are there any other tactical breathing exercises that are worth doing real quick? I know we'll get into some longer practices and deeper stuff, but is there anything else that would be helpful here?

Jonny Miller (00:23:21):
No, I think we've covered the bases. I don't want to overwhelm people too much.

Lenny (00:23:25):
Just as a takeaway, there's these two techniques. One to help you get more calm when you need to be calm in the moment. The other is to get energy. And then I guess are these things that you recommend doing ongoing to build this muscle in your body or are these mostly for you need this now in the moment and it's not worth just doing a few times a day even when you're fine?

Jonny Miller (00:23:47):
Yeah, great question. So I like to recommend both a morning practice, particularly to build the muscle of just doing it and getting used to it. So maybe five minutes in the morning before you start work, before breakfast, something like that. And then you are more likely to remember that you have access to that in the moment because usually the challenge is that when someone is in that flustered state, remembering to do the practice is often the last thing that comes to mind. So by having a deliberate practice for at least 7 to 10 days and so that you get the hang of it, then it feels much more natural to do it when you're feeling. That's kind of like playing the game on hard mode when you are really stressed and anxious, that's when you need it the most, but it's also when you're least likely to remember to do it.

Lenny (00:24:36):
Awesome. Okay, so the first exercise to calm you down is essentially breathe in four seconds, hold it for four seconds, breathe out slowly for eight seconds and do that for about 30 seconds, is that right? Or for a minute?

Jonny Miller (00:24:48):
Yeah, I'd say for at least a minute or two. We kind of did a shorter version. I'll also add that the important thing is that the exhale is twice as long as the inhale. So if exhaling for eight is too long, you could do 3, 3, 6 or even 2, 2, 4 or even 5, 5, 10 depending on your lung capacity essentially and your CO2 tolerance.

Lenny (00:25:08):
Okay, good to know. And then the espresso breath, when you need energy or you just kind of pump air out of your belly through your nose and you do that for how long would you recommend?

Jonny Miller (00:25:18):
Two to three rounds of 30 pumps, yeah.

Lenny (00:25:22):
And again, the reason this is effective and powerful is coming back to your original big insight that our state is driven by what our body is doing and our mind often explains what we're feeling based on what our body's doing. So that if you can change the state of your body and become less nervous in your body, your mind will be like, "All right, everything's fine."

Jonny Miller (00:25:45):
Yeah. And maybe something that we haven't touched on yet, but I think is important to add in is this idea of interoception or somatic awareness. And the reason I bring it in is because if you do this practice but you're not really aware of your body and how you feel, then it'll be less compelling to you. But if you're kind of tuned into like sensations in your body, what's going on, you're more likely to notice the difference in the shifts.

Lenny (00:26:09):
Great. So let's get into that. That was something I definitely wanted to touch on here. This awesome acronym to help you with this process of interoception. So talk about what that is and then how to actually go about becoming better at being aware of what your body's doing.

Jonny Miller (00:26:22):
Yeah. So it's this idea of interoception, which is known as our sixth sense, and basically it's our ability to sense, track and feel our internal landscape. And I like to use the metaphor of a chef in the same way that you train your flavor palette for kind of sweet, spicy, umami, things like that. You can also train your interoceptive palette and become more aware of the internal sensations, whether that's your breath, whether it's tension, whether it's moods and emotions, whether it's the quality of your awareness, the quality of your thoughts. And the more kind of in tune with that you are, the more likely you are to notice the kind of early warning signs of something like anxiety. Because usually, certainly a panic attack doesn't come out of nowhere. There will be a kind of cascade of subtle things that happen in your body that eventually result in anxiety. And so if you can catch those things early and kind of nip them in the bud and do one of these practices, then you can avoid the kind of 10 out of 10 worst case scenarios.

Lenny (00:27:25):
Okay, awesome. So I know that there's also specific things you recommend people pay attention to, to understand what their body is doing in this process of inter...

Jonny Miller (00:27:33):
Interoception, yeah,

Lenny (00:27:34):
Interra... Okay. What is it?

Jonny Miller (00:27:36):
Interoception.

Lenny (00:27:39):
Interoception.

Jonny Miller (00:27:39):
As opposed to exteroception, which is awareness of all the external stimuli.

Lenny (00:27:44):
Got it. I guess before we even get to that, so you mentioned that it's another sense we have, and I think that's a really important point that I think maybe people didn't catch. So we have these five senses, obviously taste and smell and vision and touch. But you're finding and research showed basically this is another sense people don't really know we have.

Jonny Miller (00:28:02):
Yeah, exactly. And it has been studies quite a lot, especially in the last decade or so. And there's a number of interesting findings from the research that I found. One being that ADHD tends to correlate with low levels of interoception, as does if people have PTSD or trauma. Again, interoception is lowered. And I'd certainly say for myself, for the first 25 years of my life, I was fairly numb from the neck down. I was not very aware to what was happening in my body in real time. I was also reading a book recently called The Hour Between Dog and Wolf, which looked at Wall Street traders and they correlated higher degrees of interception with basically making more money and making better decisions. And I think the thesis was that by tuning into what their body was doing in certain moments, they could pick up on things more intuitive decision making essentially.

Lenny (00:28:55):
So I think there's a specific list of things that you recommend people pay attention to, their posture, their breath, things like that. What is that list and then how do we actually do this better?

Jonny Miller (00:29:06):
Yeah. So I simplify this to APE, which basically is an acronym which stands for awareness, posture, and emotion. So to kind of go through each one by one. Awareness is, to give an example, I could narrow my awareness and become really focused and just you kind of tense up and it also is quite activating sometimes or you can relax and expand your awareness and be aware of the space above me, the space behind me, the space below me. And that is generally a calming thing. Posture is fairly self-explanatory. But again, our posture affects how we feel. You're shifting there now. And then emotion, which I include somatic or body-based sensations which arise. So both kind of what is the overall mood and the flavor or the texture that I'm feeling. Like right now, maybe it's excitement, maybe there's some joy. I'm noticing there's some heat in my belly probably from the breathing. Yeah, there's a little bit of tightness in my lower back from working out yesterday. So just sense kind of mapping that landscape of sensation. And for most people it's almost like it's like a [inaudible 00:30:22]. You have those maps of [inaudible 00:30:25] and for a lot of people there's just these big kind blind spots in their body.

Lenny (00:30:30):
And the advice here is, so there's this acronym APE and the advice is think about these three things when you're feeling something that you may not, basically something's going on slash just often come back to this. I imagine just whenever you can think of, "Oh, APE: awareness, posture, emotion." Is that how to use this?

Jonny Miller (00:30:51):
Yeah, exactly. So again, it can be something that you do before you start your day, maybe with a cup of tea. I like to drink tea and just do a body scan essentially and just check each of those three areas. And it's really valuable, particularly if you are having racing thoughts or something doesn't feel quite right. Instead of just tackling the problem on the level of the mind dropping down into the body and bringing that into the picture as well, I find to be really helpful.

Lenny (00:31:26):
Basically, as often as you can. And generally when things are feeling all off, just remember APE, where's my awareness? How's my posture? And then what am I feeling? Am I feeling sad? Am I feeling happy, excited, angry? Things like that. I think you also talk about breath, like you have a list you wrote about this of other things that you might want to pay attention to. Actually finding paying attention to what my breath is doing is really powerful too. So I'm going to try a BAPE version of this or I'm going to try to think about where's my breath coming from, what am I feeling there?

Jonny Miller (00:32:02):
Yeah. So the breath and sensations are two other ones that are really helpful. The breath in particular, often people will... There's an idea of email apnea when people are checking their emails, they will, without noticing it, start to hold their breath, which is generally a very activating thing to do. Or as I mentioned earlier, if your breath is through the mouth and shallow and into the upper chest, that will also be very activating versus is your breath through the nose? Is it kind of into the belly and into the sides of the rib cage and does it feel easeful? Basically, breathing without tension is ideal.

Lenny (00:32:39):
What I think about using this practice is if I were sitting in a meeting and just not feeling amazingly confident, I just come back to this acronym, BAPE or APE, whichever one you want to choose, just like how am I feeling right now? Oh wow, my whole stomach is clenched. I'm maybe nervous about what might happen or I'm not breathing at all, or my posture is really bad. So I think in a meeting would be really helpful Here, maybe you're about to get on a zoom or an important call or something like that. Maybe a one-on-one. Is there anything else, any other moments that kind of triggers for people of like, "Oh, I should really be aware of what's happening right now. Let me do an APE exercise."

Jonny Miller (00:33:16):
Yeah, well, just to kind of piggyback on what you just said, if you are about to jump on a meeting and you're noticing that your stomach is clenched, that's actually really useful data to be like, "Why is this happening?" Is it your intuition kind of saying that maybe you shouldn't do this deal with someone or maybe something is off and so it's a sign to explore that more. Or it could be that you've been triggered by something or something that someone said and you've only just realized it and then that's again, more information or something that you can reflect on or go into.

Lenny (00:33:51):
Is there anything in your life recently that is an example of this where you're feeling unsure and maybe you realize, "Oh, here's what my body's doing, maybe I should pay more attention to this."

Jonny Miller (00:34:03):
Actually, last week I did a podcast conversation, so I have a podcast myself, and I got off the call and I remember I felt or got off the podcast and I felt pretty exhausted and I felt like there was this kind of tension in my chest. And again, my breath was kind of all over the place and I realized that I had very much over committed myself for that week. I'd scheduled back to back podcast interviews. The podcast wasn't even the priority for what I'm focusing on in this quarter, so I then made the decision to just push back all my episodes until the summer basically.

Lenny (00:34:42):
I love that example. I know that feeling very well.

Jonny Miller (00:34:46):
I'm sure.

Lenny (00:34:48):
When you wrote about this idea of interoception, you connected it to burnout, and I think you talked about how this is one of the best tools to avoid burnout. Is that right? Am I remembering that right? And if so, how do you think about this burnout and avoiding burnout in general, something a lot of people experience?

Jonny Miller (00:35:08):
Yeah, so I have this idea that I call the feather brick dump truck phenomenon. And basically what that means is when we are showing early signs of burnout, our body will give us feedback usually in subtle ways in the beginning. So the feather might be waking up in the morning and feeling a little bit tired, maybe a little bit exhausted. The brick, maybe you ignore that or you don't notice it, and then three or four weeks later you have a fight with someone or an argument or you just feel frustrated and terrible and you lose your cool. And then maybe the dump truck is a month later or even a year later, there's a full-blown health crisis, or you develop type two diabetes or there's a whole range of things, or maybe you get fired. There's a bunch of different things that can happen, but normally depending on how attuned or depending on someone's interoceptive capacity, ideally, you want to notice when it's the feather and then make adjustments or shift then and not have to wait until you experience the full-blown pain of the dump truck, which unfortunately is what happens to a lot of people, especially when they experience burnout for the first time.

Lenny (00:36:18):
This is such an important point and such a good way of thinking about it. It reminds me of Andy Johns and the episode we had there of just how long and willing to the episode there of just how all these little things came up along the way and then eventually just became incredibly unsustainable to live the life that he was living.

(00:36:34):
This episode is brought to you by Miro. Do you ever feel like your projects aren't as organized as you like them to be or it's way too hard for people on your team to find all of the documents and files and context that they need for their project? Miro helps you streamline your workflows, organize information, and get your whole team on the same page. If you want to see what Miro can do for you, check out my Miro board that the Miro team helped me create, which includes all of my favorite plug and play templates, like a user journey map, my favorite one pager template plus a brainstorming guide. My board also has a place for you to share suggestions for this podcast and also answer a question that I have for you. You can then take my Miro board and easily create your own to see how it feels. Make sure to check out some of my favorite features, like the sticky notes, the inline comments and charts, and also the really cool diagramming tools. Check it out at miro.com/lenny. Your first three Miro boards are free when you sign up today at miro.com/lenny. Find simplicity in your most complex projects with Miro. That's M-I-R-O.com/lenny.

(00:37:40):
What are some examples of this feather? So your advice here is just pay attention to these little signs that you're not living a sustainable life right now. What are some examples of these kind of feathery signs of like maybe I need to change something?

Jonny Miller (00:37:55):
Yeah, so I'll tie this in with a concept that I call emotional debt, which is basically when our nervous system experiences stress, there's known as a mobilization cycle, and if that cycle isn't completed or we don't get to downshift or relax on the other side, that gets stored in the body as allostatic load, which I call emotional debt. And over time, that creates fragility in the nervous system. And so what that fragility can look like is anything from being impacted by small things in a kind of disproportionate way. So noticing that you are more reactive than normal, maybe you're a little bit more snappy, maybe you get frustrated by little things, maybe your sleep isn't as good, maybe you wake up not feeling fully rested. Maybe relationships are often, especially intimate relationships are usually a place that this shows up or relationships at work. So those are the classic early warning signs. And then as that emotional debt threshold increases in the same way that say with technical debt, if you're building a product in the beginning, it's fine, and in fact it's even necessary in the beginning. It's great that our body can buffer the stress response because it allows us to function. But if we don't pay off that technical debt or emotional debt, then over time it accumulates and it can also come out through health crises, health challenges. It just gets basically progressively worse until that debt is paid off.

Lenny (00:39:25):
I feel like a lot of people listening are like, "Yes, I know exactly what you mean." How does one notice that you're building emotional debt and then how do you start to release this debt and pay off this debt?

Jonny Miller (00:39:38):
What I've seen with some of my founder clients and in the research that we did where we interviewed 260 leaders, what can often happen is that emotional debt will increase and increase and increase until it gets to a point where we are well outside what's known as a window of tolerance. And at that point there's like a crash. It's almost like the fuse switch blows and there's exhaustion. Maybe there's complete inability to get up off the couch. And for some people, people with large nervous system capacity, they can keep going for five years, maybe 10 years, and they can keep building this up, and it becomes normalized to live in a way where you are always on and never really relaxing or coming down. Or one really key sign actually is if you are not able to naturally downshift or down regulate your nervous system at the end of the day without something like wine or CBD or some kind of external substance, that's a sign that you kind of reached a certain threshold of emotional debt.

Lenny (00:40:47):
And then how does one start to pay off this debt if you've spent years just working way too hard, you've had a relationship that just isn't working great, I don't know. I imagine most people go to therapy and just talk through all these things and try to work through the challenges. What do you recommend if you're just like, "Man, I feel like I have this, what should I do?"

Jonny Miller (00:41:08):
Yeah, well, I mean that's a big question. I'll probably get some pushback for this, but I'm not a big fan of talk therapy alone or at least therapy that doesn't have a somatic or body-based component. And from my understanding of the nervous system and how we store this stress, just talking about things and keeping things on the level of the intellect doesn't actually address the root of the challenge. What we need to do is create a certain sense of safety to kind of go into those buffered emotional responses and feel them all the way through and allow that mobilization reflex to complete.

(00:41:48):
And so to kind of give a personal example, when I was living in Bali, I did several hundred breathwork journeys where you breathe in a certain way to get into an altered state, and then in that place, these memories would arise of these things that happened 5, 10 years ago. And my body, it would either move a certain way or the anger would come through. Sometimes there would be sadness or grief. Often there's a lot of stored emotion that's held in our body that just needs permission to kind of be felt through and be released. And so for me, it was a journey of coming into right relationship with my anger and my grief, and honestly my shame as well, giving myself permission to feel this gunk that had been stored in my pelvis.

(00:42:35):
So I'm not saying you have to go to Bali and do 200 breathwork journeys. That's definitely not... I mean, that's a path. But first it begins with, as I said, cultivating interoception and even being aware that there is this tension, there are these things in your body. Secondly, having the practices of self-regulation so that if these things come up, you don't get overwhelmed. You're able to downshift and ground. And then thirdly, it's the practice of what I call emotional fluidity, which is basically creating the conditions of welcoming the full spectrum of emotions as they arise. And often it's very helpful to have a guide or a somatic practitioner, I like somatic experiencing, hakomi, the two modalities I'm a big fan of. And yeah, that's the journey and a process and it depends how many years you've been operating in a slightly numbed way, and it's different for everyone. But it begins by tuning into and listening to the body and then having honestly curiosity about what is there and just following that curiosity and the body starts to show you what is ready to be seen.

Lenny (00:43:49):
I love that it always comes back to the original place we started which is that the way we feel is a very bottom up body-based system, it's not we feel something and our body gets nervous. It's our body gets nervous, and they're like, "Oh, here's why I'm nervous." And your advice is just focus a lot on helping your body release the stuff that you've built up this debt. And then also just when you're nervous in the moment, focus on getting your body to a state versus trying to convince your mind now everything's going to be okay.

Jonny Miller (00:44:17):
Exactly.

Lenny (00:44:17):
And specifically on the therapy route, just to touch on that, so your advice there is if you were to work with a therapist and you feel a lot of this stuff that we're talking about is focused on a somatic oriented therapy where it's body oriented, not just thinking about it and talking through stuff, it's actually convincing your body, "Here's a way to helping your body release this debt, essentially."

Jonny Miller (00:44:40):
Yeah. I mean, you can understand in precise detail about whatever the challenge was from 5, 10 and 15 years ago, but if you're unable to connect it to the correlating sensations in the body... Usually if say, I don't know, if I was to imagine someone shouted at me yesterday and I think about that, there's usually a correlating kind of sematic sensation. The neuroscientist Damasio calls it a somatic marker. So by tracking the somatic markers and then either on your own just kind of following that sensation and allowing whatever emotion was present at the time to complete that is the way that we kind of slowly pay off that emotional debt by one process at a time.

Lenny (00:45:26):
So maybe coming back to this question of say someone is listening and wondering, am I building emotional debt? Am I ignoring things that are these feathers? What are signs and just, I don't know, examples of emotional debt being built up of this trauma, whatever you want to call it, being built up in the body? I don't know, is it just like anytime you feel really nervous, that's emotional debt? Is it anytime you push something down that you are pretty sure you should deal with in the moment, that's emotional debt? What are just some examples of what that feels like and looks like?

Jonny Miller (00:45:58):
Yeah, so it's typically different forms of nervous system dysregulation and that shows up as it could be someone's breathing pattern if they're constantly in this sympathetic or hypervigilant state, if they're always tracking for things, looking for the worst case scenario. Another common one, and this is particularly true in the tech sector, is being very much in the head and living in the thoughts and the mind the entire time. And there's a form of disassociation that happens as a kind of protection mechanism essentially because it's uncomfortable to be with the sensations in the body. And because our society tends to reward people for solving problems and being in their mind, that is a pattern that continues for many, many years or even decades.

(00:46:43):
Other ones are, I think the most obvious one for people is emotional reactivity, where your response to a certain situation is disproportionate to what's happened. So for example, if you said something to me of that doesn't make any sense, and I was like, I freeze maybe... And this is another important point that most people have two versions of reactivity. Some people will freeze, withdraw, shut down and disconnect, and other people will become more aggressive, become bigger and attack and fight back. And knowing which way you tend to orient, for me, it's usually shrink and freeze and shut down, knowing what your pattern is and also knowing what the sensations are when this happens, it's really helpful for you to be like, "Oh, that thing's happening." My priority now is to downshift and kind of find a sense of safety basically in the body and then interact, then make the decision, then have the conversation. Because if you can keep going from that place of reactivity, nothing good happens from that place. No great decisions were made from that place. So again, that's a place where having the interoceptive awareness to know, "Oh, this is what's going on." Being able to then downshift your system, kind of access a sense of, "Oh, I'm okay, actually this isn't so bad." And then moving on from there is a profoundly practical and just useful skill.

Lenny (00:48:14):
Kind of along these same lines, you wrote somewhere this idea that you have a big competitive advantage if you feel the feels is the way you described it. Does that ring a bell? And if so, what can you share around that, just why this is so powerful, especially in the workplace?

Jonny Miller (00:48:28):
Yeah, so I think I wrote about this in one of the Every essays. I think the title was The Best Decision-Making Is Emotional. And I basically wanted to kind of poke at the phrase, I think I saw someone on Twitter say, "Fact over feelings, like don't let emotions ruin good decision making." And yeah, there's so much that I can say about this. But basically there was a landmark study by this guy, Damasio, this kind of famous neuroscientist, and he studied a patient called Elliot. And Elliot had a tumor in his brain that was removed and it basically meant that he was unable to feel emotions. So his entire emotional capacity was removed. And Elliot went from being a successful married businessman to divorced, broke and unable to choose what he could have for lunch. He was unable to make the most basic life decisions, and it's because he didn't have access to that emotional sense in his brain.

(00:49:22):
And so our brain is like a prediction making machine, and as I mentioned earlier, there's this highway of sensory data that's coming up through the body. And if we don't listen to that when we are making decisions, then we're losing out on a lot of information. And what tends to happen, I see this in clients that I work with, is if they are avoiding feeling a certain way, let's say, that they don't enjoy feeling conflict or anger, then they will make decisions subconsciously to avoid feeling that way. And it becomes a huge bias and a huge problem because people make decisions because they're afraid of feeling a certain way. And if you are on the other hand able to just welcome and be with whatever emotions would arise on the other side of a decision, you're able to decide clearly instead of being skewed one way or the other.

Lenny (00:50:16):
Easier said than done.

Jonny Miller (00:50:18):
Yeah.

Lenny (00:50:21):
Do you find there's ever a downside to being too in touch with what you're feeling? I actually not a feeler of what I'm feeling kind of person. I'm pretty stable, partly because I'm not super in tune with what I'm feeling a lot of times, and maybe this is a huge problem that I need to deal with. But I don't know, it's worked out okay so far. I guess, do you ever find that sometimes it's okay, sometimes you don't need to know exactly every moment anything that's hurting you or causing you pain?

Jonny Miller (00:50:49):
Yeah, it's a good question. And some people do have a very high interoceptive capacity, and that can be overwhelming. In which case I would recommend focusing on the breathing practices to build that capacity to downshift, so you're able to just function. And there's definitely people who are overwhelmed by the stimuli of day-to-day life being out in traffic, like they're very easily overwhelmed. And for those people working on increasing nervous system capacity to kind of hold that amount of stress, maybe it's through sauna and cold plunge, maybe it's through gentle titration of stresses and then downshifting, that's actually really valuable.

(00:51:28):
I'd also say that the ability to function well, this applies to a lot of high functioning people, which is probably honestly a lot of your audience. It's very helpful in the moment to, let's say something comes up, you want to be able to buffer intense emotions and say, get through the meeting, get through whatever it is. It's a very helpful skill. But if you don't, then give yourself spaciousness afterwards to downshift and allow yourself to feel whatever was brought up by that experience, you are going to be adding to this emotional debt over time. And as I mentioned, some people, it might be a year before there's some kind of breakdown, burnout. Other people, it might be longer. And usually it's more unfortunate in the longer case because it creates a long-term health crisis and then lower amount of money or time is able to repair the damage that's been done, which can be really tragic.

Lenny (00:52:24):
My chat with Andy Johns is a great example of that happening.

Jonny Miller (00:52:26):
Yeah. And Andy's a superb example, and I love his vulnerability and honesty in what he's been through.

Lenny (00:52:33):
Yeah, I think if you're interested in this topic, definitely watch that episode. Another exercise that you talk a lot about is this idea, it's called NSDR, I think. Talk about that and when that might be useful, how to go about using this tool.

Jonny Miller (00:52:49):
Yeah, so NSDR was a practice coined by Andrew Huberman, who you mentioned earlier. And it basically, it's a more scientific lens on the practice of yoga nidra, which is an ancient yoga practice. But I am a huge fan of it, and I do it myself most days for 15 to 20 minutes. Basically what it looks like is you lie down, put on an eye mask or a blindfold, and you listen to a guided audio. I've recorded some myself, so I can share these in the show note links.

Lenny (00:53:16):
Your voice would be so good for these, by the way. You found your calling.

Jonny Miller (00:53:22):
Nice, yeah. It's really fun for me to do. But basically what it involves is a guided body scan. So this is also a great way to practice interoception. It's something that I didn't mention earlier was that when there's cortisol present in our body, the cortisol basically acts as a numbing agent, so it's much harder to kind of tune into those sensations. But using this, I think it's a 14-minute guided NSDR practice, you're basically lying down, there's a guided body scan, there's relaxing music in the background. And by the end of it, you feel like you've had a two-hour nap. It feels incredible.

(00:54:00):
And particularly for people who myself tend to get tired in the afternoons, if you space this out, usually between 1 and 3:00 PM for me, that will give you a second wind in the afternoon and it'll mean you won't end the day collapse on the sofa. So I think it's great for improving interoception, it's good for allowing your body to downshift and relax instead of being in that kind of high tone sympathetic state all throughout the day. So it gives your body a break, and it just feels really good. Honestly, it's probably my most played practice of everything that I teach, just people listen to it every day. So I'll share that in the show notes as well.

Lenny (00:54:41):
And I imagine if you feel like you've built this emotional debt, this would be a really good exercise to start to do, is that right?

Jonny Miller (00:54:49):
Yeah, it is fantastic. I mean, there's some people who struggle with having enough energy to kind of get out of bed and function. But again, I imagine listeners to your show, people that live in Silicon Valley, their challenge is the downshifting without external substances. And so NSDR is a really great way of strengthening that ventral vagal tone, which is our body's capacity to go from on kind of go, go, go to then relaxing. There's a quote from Kevin Kelly that I interviewed recently, and he said, "If you have a great work ethic that needs to be matched with a great rest ethic." And I think that kind of piece of actually training our capacity to downshift after stress is just completely missing from most people's playbooks.

Lenny (00:55:38):
I think with a lot of the sort of advice, if you listen, Tim Ferriss and Huberman and everyone's got this stuff you should be doing every day list and it ends up being so long and there's so many things to do, cold plunge, sauna. What is it that you practice or come back to slash what would you recommend people try to do daily that is most impactful of all this stuff we've talked about?

Jonny Miller (00:56:05):
First experiment with a bunch of different practices and see which you enjoy and notice how you feel before and then how you feel afterwards. That's kind of the key because once you know that it feels good, you're not going to have to force yourself or motivate yourself to do it. You'll just do it naturally because you know you'll feel great afterwards. I would recommend starting really simple, so starting with the 4, 4, 8 breathing or humming, doing that in the morning for just two minutes, two minutes in the beginning is enough. And I would also recommend listening to the NSDR practice at least once or twice. If you work from home, it's pretty easy after a lunch break, something like that could also be in the evening when you get home as well. Some people use it to help fall asleep.

(00:56:52):
And then the final thing that I would recommend is if you have the resources and you have access, finding a somatic practitioner or somatic therapist is so [inaudible 00:57:03]. I mean, I emerged a completely different human on the other side of the 200 breathwork journeys. I have a different experience of life basically released so much time. Even my voice sounds different. If you listen to the podcast episodes I recorded four or five years ago, my voice is higher pitched. It just sounds different. It has a different resonant quality to it.

Lenny (00:57:27):
Wow. Okay, awesome. So you've kind of summarized, I was going to try to summarize all the advice you've given, but if you were to do the bare minimum next steps based on this advice, try this 4, 4, 8/3, 3, 6/2, 2, 4. Does 2, 2, 4 work too if you just go real fast I guess?

Jonny Miller (00:57:28):
Yeah.

Lenny (00:57:45):
Yeah.

Jonny Miller (00:57:46):
Okay.

Lenny (00:57:46):
Okay, perfect. Okay, so do that for a couple mornings. See how that does try this NSDR practice. We'll link to a recording of how to do that and then was there something else you recommended? Oh, somatic worker, basically maybe a therapist, maybe not someone that helps you with your body.

Jonny Miller (00:58:06):
Yeah, and I'd add in the eight practice for even 15 seconds before the breathing in the morning and after, just so that you notice the difference. And if you do the NSDR, that is basically a 15-minute interoception practice as well. So you're kind of getting two birds with one stone with that practice.

Lenny (00:58:24):
What's your perspective on meditation? Does that fit into this? Do you find the NSDR replaces the need for meditation?

Jonny Miller (00:58:29):
That is a big topic. I am an avid meditator as what I've done many 10 day silent retreats. I was in a dark room for 10 days.

Lenny (00:58:40):
Wow.

Jonny Miller (00:58:41):
With meditation, I think it really depends on what you are training. It's like saying what's your opinion on exercise? Well, are you training mobility or stamina or strength? It's the same with meditation. You could be training loving kindness. You could be training your focus and attention. You could be training spacious awareness. So I'm a big fan of embodied meditation practices. So this is often the classic vipassana body scan is a good example. Again, I mean that's basically interoceptive practice where you are just moving your attention through different parts of your body over and over and over again for days on end.

(00:59:17):
In the case of vipassana retreat, meditation is helpful for the specific skill of increasing the psychological space between a stimulus and your response. So if you have some degree of meditation practice instead of getting wrapped up in a certain emotion or we're even believing a certain thought pattern, there's usually an ability to kind of step back a little bit and see if what it's, so there definitely is a place for meditation. But my viewpoint is that we've kind of over-indexed for mindfulness and meditation in over the last 20 years. There's so many apps, there's so there's much talk about it and we've completely forgotten the body-based approaches. So I'm not saying don't meditate. I think meditation for sure has its place, especially if your goal is more of the traditional waking up and seeing through the nature of the self, that's a different kind of path in my opinion. But if you're looking to function more effectively and be more in tune with your body, then there's a whole different category of practices in this bottom up variety that we've touched on today.

Lenny (01:00:27):
On the topic of bottom up, I imagine you're a big fan of this book that everyone always talks about, The Body Keeps Score, I think it's called. Would you recommend that book? Is it connected in a large part to the stuff you talk about? What do you think of that book specifically? Because I hear about it all with him.

Jonny Miller (01:00:41):
Yeah, it's a good book. It's by Bessal van der Kolk and there's another writer I think Peter Levine says, "The issues are in the tissues." Is basically the concept. And this is the idea that we have these incomplete mobilization reflexes that are stored in our body and often held as tension. It's not strictly true to say that the trauma is in the body. It is actually a cortical map in the brain which kind of tracks these things. But for kind of practical purposes, it looks and feels as if there is stored grief in my right hip or anger in my solar plexus, that's the experience that we have. And the more that you become aware of these sensations and start to develop emotional fluidity essentially, the more that tension is released and the less reactive you become and the more emotional debt you pay off. So I think The Body Keeps The Score, I think a more accurate way would be the body is the scorecard in a way. I think that's kind a slight reframe. And if you're interested in this, the work of Peter Levine, Waking the Tiger is the seminal book on this mobilization reflex stuff that I'm describing.

Lenny (01:01:51):
I never need that part of it. And basically it's actually kept in the brain, but it comes across as somewhere in the body.

Jonny Miller (01:01:57):
Yeah, exactly.

Lenny (01:01:58):
Fascinating. I want to spend a little time on a new segment that we have in this podcast that I call Contrarian Corner. So let's visit Contrarian Corner, I feel like you'll have something interesting here. So the question is there something that you have a very contrarian opinion about, something that you believe that a lot of other people really don't believe?

Jonny Miller (01:02:17):
We've already touched on I'm not a big fan of talk based meditation, which will probably get me some comments I would imagine. I'd say the other one that's worth mentioning is I think that we vastly underestimate the impact of burnout, particularly from a bottom line perspective. There was a research report that I did a couple of years ago where we interviewed these leaders and they'd all experienced burnout of some degree. And we said, if you were to estimate how much this costs your startup or business, what would you say? And the median response was a hundred thousand dollars, which I imagine is more than most people would think.

(01:02:57):
And most people aren't actively investing in burnout insurance. Like it's not something that's on many people's radar besides meditation practices and things like that. And I think part of the reason that the cost is higher is because there are these second and third order consequences of talent attrition, of opportunity costs, lost productivity, you lose great leaders, make shitty decisions in the run up to the burnout itself. There's also this idea of emotional contagion, which there's some research from Wharton I believe, and they show that the leader or the CEO has a disproportionate impact or their emotional state has a disproportionate impact on the people in their team. So something I'd like to say is the nervous system of an organization is a reflection of the nervous system of the CEO. And so I think that's just something which I would like to see talked about more.

Lenny (01:03:53):
Just on this idea of burnout, I don't think you're saying don't work really hard If you want to work really hard, it's that you need to maintain your body and mind and nervous system if you're working insanely hard. If you're working long hours, feel free, but just know there's debt you're building up and you need to be doing things to pay off that debt as you're doing that.

Jonny Miller (01:04:11):
Precisely. It is very much like building technical debt in the early days of a startup. It's worth doing, but just do it intentionally. Know that you're doing that and that. So let's say you work really hard for eight months, you give yourself a month or two off to really downshift. And it's also really worth building that nervous system capacity. It's great to be able to push it really hard and focus and then combine it with that rest ethic as well. So do NSDRs, kind of find a way to downshift so that way of working can be sustainable.

Lenny (01:04:44):
Jonny, we reached our very exciting lightning round. Are you ready?

Jonny Miller (01:04:48):
Let's do it.

Lenny (01:04:49):
First question, what are two or three books that you've recommended most to other people?

Jonny Miller (01:04:53):
I actually had a sense this question was coming and I have the books with me here. The first book is Constellations by David White. This is the book that I've gifted most to friends, I think more than any other book. And he basically has 52 definitions of words like ambition is I think the first word. And his writing, it just blows me away. I open this to a random page, read the definition, and it's probably affected me more than any other book. So that's one that I love. 15 Commitments of Conscious Leadership, which is I imagine has come up before in your podcast. This is by Jim Dethmer and Diana Chapman. They have the Conscious Leadership Group. And this is basically, in my opinion, it's the best leadership book that I've come across and it combines practicality with a lot of great theory. So this is awesome. And then finally, this is a bit out there, but Recapture the Rapture by Jamie Wheal, big fan of Jamie's work, Jamie's writing. This is kind of three books in one. The beginning is addressing the meta-crisis and a lot of the craziness that we're seeing in the world. The second chapter is very related to what we've been talking about, he calls it Hedonic Engineering and it's basically practices for shifting your state of consciousness. And the third is Ethical Cult Building, which I'll leave that there. [inaudible 01:06:22].

Lenny (01:06:22):
Do you have a favorite recent movie or TV show you really enjoyed?

Jonny Miller (01:06:28):
My wife and I love animations and we saw Kubo and the Two Strings recently, which was fantastic. Just so, so great. That and also Wolf Walkers, which was an Apple TV series. Yeah, those have been my two favorite movies I've seen recently.

Lenny (01:06:46):
If you like animated content, check out the Scavengers Reign on HBO. I've mentioned it on this podcast before, but it's incredible. It's a TV show on HBO. So I usually ask, do you have a favorite question you like to ask candidates you're interviewing? But I know you coach people, so to kind of turn this question a little bit around, do you have a favorite question you like to ask executive coaching clients that you work with?

Jonny Miller (01:07:08):
I stole this question from a guy Jerry Colonna who's here in Boulder, and the question is amazing. It is so good. It's basically, how are you complicit in creating the conditions that you say you don't want? And so the word complicit there is key because it's not saying in what ways is it your fault, but it's like in what ways were you complicit in creating the conditions for anxiety, for building up emotional debt? And just the question kind of opens up the door to ways in which you are an active participant in creating these challenges in your life. And it's a really rich journal question or a question to explore with a friend, co-founder colleague.

Lenny (01:07:53):
I remember him sharing that on the Tim Ferriss podcast many years ago and it stuck with me and I often think of it, but I never am complicit of anything that goes wrong. It's never my fault. He has nothing on me. Just kidding.

Jonny Miller (01:08:06):
Excellent.

Lenny (01:08:08):
Do you have a favorite product you've recently discovered that you really like?

Jonny Miller (01:08:11):
One is these blue blocking glasses. These are raw optics, blue blocker glasses. They block out a hundred percent of blue light and they are a lifesaver if I'm ever going out of the house basically after dark, I'll wear these to drive. I'll wear these to even dinners with friends sometimes. And it basically means that I'm able to then sleep well that evening. So that's one.

(01:08:38):
And then the other thing I'll briefly share, this came through the other day, you mentioned the vagus nerve earlier and that device, I have three devices here that are all vagus nerve stimulation devices. This one is called Neuro Sim. This one I believe is Pulsetto, and I think this is a Apollo Strap. I haven't used them that much yet, but they basically work by sending low level electrical stimulation directly to your vagus nerve. So this clips on your ear because the vagus nerve goes through the right side of the neck. Same with Pulsetto. And I'm really curious to compare the effect of these versus say breathwork, humming, the other body-based practices. Obviously, you can do both at the same time, but I am just interested in playing. So I wouldn't recommend them yet, but I think it's interesting that they exist.

Lenny (01:09:29):
How cool would that be? We just put these things on, we don't have to do anything else. We just get up, slap on our device and life is amazing. Don't have to meditate, don't have to breathe in a different way. I'm going to need to do this while I'm on the podcast just wear all these devices, see how that goes. Awesome. Well, I guess somehow report back to us how these go because that feels really great. Next question, do you have a favorite life motto that you often come back to share with friends, either in work or in life?

Jonny Miller (01:10:00):
State over story would be one which we've touched on.

Lenny (01:10:02):
State over story.

Jonny Miller (01:10:04):
And then I think the other one, which I think about often is I like to say, "Make generous assumptions." And by that I mean in any situation, what is the most generous story that I can tell of this person, of this situation? Not kind of naively fabricating something, but usually there's a spectrum of I can assume that they're a bad person and they did this thing out of spite, or maybe they had a bad day, maybe they have a lot of emotional debt. There's there's many stories that can be told. And I usually try to have a practice of telling the most generous story that I can.

Lenny (01:10:47):
I like that a lot. Another way of describing that is just assume good intentions, which I often think about.

Jonny Miller (01:10:53):
Exactly.

Lenny (01:10:54):
Final question. You seem extremely calm always, and very centered and stable. What still gets you rilled up and unsettled, and what do you do when that happens?

Jonny Miller (01:11:07):
Well, I was nervous before this podcast, so I did some breathing practices and some stretching and some humming before jumping on here. I still at times notice ways in which I'm conflict avoidant. I've been working on it actively for a while, but there's a part of me that can sometimes avoid conflict. And so I've actually noticed how there's a relationship between that and having a healthy relationship to anger. So basically giving myself permission to express frustration, not at someone, but just allow it to be there. And then from that place set better boundaries with my time with what I'm doing, saying no to certain things. I think that's the practice that's most alive for me right now.

Lenny (01:11:53):
Jonny, you are awesome. Two final questions. Where can folks find you online and explore the things that you offer? I think you teach a course, whatever else you offer, talk about that and then how can listeners be useful to you?

Jonny Miller (01:12:06):
Yeah, well, this has been so much fun. I am very active on Twitter or X. My handle is Jonny Miller. It's J-O-N-N-Y-M-1-L-L-E-R. And yeah, if this was interesting or listeners would like to dive deeper, I teach a course. Our next cohort is running in the spring, the end of March. Applications are now open, and the website is nsmastery.com/lenny. I've created a custom page and there's a $250 juicy discount for listeners if they want to sign up.

Lenny (01:12:39):
I got to sign up for this myself. I didn't know you're going to do that. That's awesome. And NS Mastery stands for Nervous System Mastery.

Jonny Miller (01:12:47):
Exactly.

Lenny (01:12:48):
Amazing. Anything else? And then the second question of how listeners can be useful to you.

Jonny Miller (01:12:52):
Well, firstly, if any of this resonates, I'd love to hear from you on Twitter or email me as well. I can pass over my email and I would just love it if you experiment with this stuff. I love this idea of just being a scientist of life. So if anything that we've talked about resonates or any of the practices you want to try, just go out and try it and see how it feels and then tell me about it. That would be the greatest gift I think.

Lenny (01:13:23):
And the best way to tell you about it is tweet at you or is there something else?

Jonny Miller (01:13:26):
Tweet at me or my email is jonny@curioushumans.com. So feel free to email me as well.

Lenny (01:13:32):
All right, I'm going to use all these things. Jonny, thank you so much for being here. You're awesome. I am excited for the show notes we're going to have to give people actual tools to use to become less anxious and nervous in their work and life. Thank you again for being here.

Jonny Miller (01:13:46):
Amazing. Thanks so much, Lenny. This was super fun.

Lenny (01:13:48):
Same for me. Bye everyone.

(01:13:51):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## From managing people to managing AI: The leadership skills everyone needs now | Julie Zhuo
**Guest:** Julian Shapiro  
**Published:** 2025-09-21  
**YouTube:** https://www.youtube.com/watch?v=c_w0LaFahxk  
**Tags:** growth, retention, acquisition, activation, onboarding, metrics, roadmap, a/b testing, experimentation, analytics  

# From managing people to managing AI: The leadership skills everyone needs now | Julie Zhuo

## Transcript

Julian Shapiro (00:00):
Why do good ideas arrive after the bad ideas are empty? It's because when you've gone through a bunch of bad ideas, your brain, your mind starts reflexively identifying what elements are causing the badness. Then it becomes way better at avoiding those bad elements and you become way better at pattern matching the novel ideas with way greater intuition. Most creators are resisting their bad ideas. If you sat down, scribbled a few thoughts in a blank document and just walked away because you weren't struck with gold, then you never actually finished the creative process. There's no way you would've come up with gold.

Lenny (00:37):
Welcome to Lenny's Podcast. I'm Lenny, and my goal here is to help you get better at the craft of building and growing products. I interview world class product leaders, and growth experts to learn from their hard-won experiences building and scaling today's most successful companies today. My guest is Julian Shapiro. I actually spend a bunch of time introducing the wondrous Julian at the beginning of the episode. Instead, let me just share some of the things that we talk about. We get into a framework he calls product-led acquisition, which is work that has come out of his working with thousands of companies, helping to figure out their growth strategies.

Lenny (01:10):
We get into ways to increase your product's retention. Then we talk a lot about writing, the importance of novelty in your writing, how to choose a topic when you plan to write, and then a framework that Julian calls the Creativity Faucet. Julian is such a fascinating human, and I'm really excited to bring you this episode. With that, I bring you Julian Shapiro. I'm excited to chat with my friend John Cutler from podcast sponsor Amplitude. Hey, John.

John Cutler (01:37):
Hey, Lenny. Excited to be here.

Lenny (01:39):
John, give us a behind the scenes at Amplitude. When most people think of Amplitude, they think of product analytics. But now you're getting into experimentation and even just launched a CDP. What's the thought process there?

John Cutler (01:50):
Well, we've always thought of Amplitude as being about supporting the full product loop. Think collect data, inform that, ship experiments, and learn. That's the heart of growth to us. The big aha was seeing how many customers we're using Amplitude to analyze experiments, use segments for outreach, and send data to other destinations. Experiment in CDP came out of listening to and observing our customers.

Lenny (02:11):
Supporting growth and learning has always been Amplitude's core focus, right?

John Cutler (02:15):
Yeah. Amplitude tries to meet customers where they are. We just launched starter templates and have a great scholarship program for startups. There's never been a more important time for growth.

Lenny (02:24):
Absolutely agree. Thanks for joining us, John, and head to Amplitude.com to get started. Hey, Ashley, head of marketing and Flatfile. How many B2B SaaS companies would you estimate need to import CSV files from their customers?

Ashley (02:38):
At least 40%.

Lenny (02:40):
How many of them screw that up and what happens when they do?

Ashley (02:42):
Well? Based on our data, about a third of people will consider switching to another company after just one bad experience during onboarding. If your CSV importer doesn't work right, which is super common, considering customer files are chock- full of unexpected data and formatting, they'll leave.

Lenny (03:03):
I am 0% surprised to hear that. I've consistently seen that improving onboarding is one of the highest leverage opportunities for both signup conversion and increasing long-term retention. Getting people to your aha moment more quickly and reliably is so incredibly important.

Ashley (03:17):
Totally. It's incredible to see how our customers like Square, Spotify, and Zuora are able to grow their businesses on top of Flatfile. It's because flawless data onboarding acts like a catalyst to get them and their customers where they need to go faster.

Lenny (03:34):
If you'd like to learn more or get started, check out flat file at flatfile.com/lenny. Julian Shapiro is what I'd call a polymath of the internet. He's an amazing writer, marketer and growth mind, investor, community builder, podcaster, tweeter. He's also an expert on building muscle. He's maybe most known for being the founder of Demand Curve, a YC startup that trains people on growth and marketing. Prior to that, he was a part-time columnist at TechCrunch. He was also VP of marketing at Webflow, which I had no idea about.

Lenny (04:09):
He also created a JavaScript web animation engine that is used by Uber and WhatsApp and Samsung and thousands of companies. Currently he is a full-time investor with his own fund and as a partner at Hyper. He's also one of the most hilarious and generous humans that I know. With that, Julian, welcome to the podcast.

Julian Shapiro (04:28):
This is the greatest honor of my life. Thank you.

Lenny (04:31):
Wow!

Julian Shapiro (04:32):
I'm crying from that intro. Very nice of you.

Lenny (04:35):
That's the idea. This is the greatest honor of my life. We match.

Julian Shapiro (04:40):
Excellent. We'll cancel each other out and we'll see how interesting this is.

Lenny (04:43):
That's right. There's a lot of hype. I know you have something like 250,000 Twitter followers. You're very good at Twitter, but I've noticed that you've only tweeted three times this past year. What is going on there?

Julian Shapiro (04:58):
There's a few things in parallel. One is a lot of people are writing threads and I found this to be very cringe. They're like these fortune cookie threads like here's 21 ways to rework your startup or something. I found them all cringe. What they actually do when you write that stuff is they attract people who think that's valuable information, and then they cause people who you actually want to follow you to unfollow you. I remember just seeing people unfollow me early days of threads when no one was doing them and I was experimenting. They were pissing off people that I actually cared to have dialogue with.

Julian Shapiro (05:36):
I kind of lost the momentum and enthusiasm for writing that sort of stuff. And now I'm only writing anything when it's basically a reflection or a condensed version of a blog post that I happen to be writing from my website. I know it's high quality. I know it's original. I know it's thoughtful. It's not for the click bait. That was part of it. The other thing is that it's kind of like too... Here's a mental model for thinking about the quality of your followers. You have people who follow you for the quality of your brain, and you have people who follow you for sort of you being a glorified curator. If they're following you for being a curator, they're sort of what I call labor followers.

Julian Shapiro (06:16):
They're following you for the work that you're doing, where you're finding cool, funny memes. You're posting cool, funny jokes. You're doing these fortune cookie threads. In contrast, if they're following you for your mind, which is category one, it means they're following you for the original thoughts and insights and takes that you have on the world. Someone like Paul Graham, the founder of Y Combinator, is doing original takes. He's not trying to write threads for the sake of gaining followers. He's trying to write interesting novel ideas. When he does that, he strengthens the affinity that his followers have for him and his mind, because like, "Wow! That was an original interesting take."

Julian Shapiro (06:49):
They're following you for your mind, not for the labor you're doing, putting together a virtual Buzzfeed to count on Twitter. When people follow you for your mind, when they're mind followers, not labor followers, higher affinity means more loyalty, means they pay closer attention to what you're saying. And if you actually try to get them to do something with you, you have an event offline, there's something you're selling, there's a cause you care about, they're way more likely to indulge.

Julian Shapiro (07:12):
Whereas if they're following you for your labor, you're interchangeable with all these other meme accounts and there's no real affinity for you as the individual. I just care more about the quality of the follower than I do the volume.

Lenny (07:23):
I love that. That's such a good reminder, not to just focus on follower, follower, follower. I'm curious if someone... You have a lot of followers at this point and it's just so valuable to have Twitter followers. I've learned for me, anytime I have a question about anything, I just ask and I get so many amazing answers from people. There's this power to having a large following. I'm curious while we're on this topic, if you're just starting out on Twitter, do you have any advice for someone that's just thinking about building their following?

Julian Shapiro (07:50):
I mean, generally speaking, threads, despite everything I've said, are the primary way to get followers. There's a reason why people do threads as opposed to single tweets is because when people get exposure to a thread, they're basically getting exposure to the length of thoughts equivalent to you having sent a newsletter edition or a blog post in many cases. The more exposure, the more surface area you have, the more you give people of your brain in a single tweet, the more they're able to confirm that what you're sharing is actually a consistency from you.

Julian Shapiro (08:21):
Whereas if you just tweet one clever thing, they're like, "Oh, that's probably just a drop in the bucket. Who knows if that person can consistently generate clever stuff?" But in a long thread where it's 30 tweets and they're all good, they're like, "Whoa! This person is a machine. If I follow them reliably, I'll get more great stuff." It reaffirms to readers they should follow you, which is why threads trigger more follows. Basically you do want to do threads, frankly, and that's the backbone of it. Threads with very clickbaity opening tweets kind of how it works.

Julian Shapiro (08:52):
You can also port followers over from other places like your website and newsletter, just to start giving yourself an initial sample audience through which the threads can actually take fire pretty much.

Lenny (09:02):
Awesome. I wasn't expecting to go into Twitter as strategy, but this is interesting because you're really good at it. As you've said, your stuff is actually very thoughtful. It's not just a thirsty Twitter thread trying to find followers and retweets. Thanks for sharing that.

Julian Shapiro (09:18):
Well, it sort of started that way, because me and a few other friends of mine, I felt like we were the first people doing threads at scale. And then when we realized what it turned into, that's when we just stopped.

Lenny (09:28):
I love that. I know what you mean about these cringy Twitter threads. Anyway, what I want to do is instead of asking a bunch of random questions is to focus on five big topics and kind of go deep on these topics. These are topics that are maybe most popular of the stuff that you've put out across your handbooks and writing and courses and things like that and also things that I've found to be most interesting. Does that sound good?

Julian Shapiro (09:51):
Yeah, I would love to.

Lenny (09:53):
Cool. First, a little context, you write these super in depth handbooks on a bunch of different topics on growth and writing and muscle building and things like that. First of all, could you just explain what these handbooks are and why you create them?

Julian Shapiro (10:05):
They're forcing functions for me to hold myself accountable and to be thorough when learning something for my own benefit. That's all they are. Basically if I want to go learn growth or writing well or some other topic, I will go ahead and do a ton of research, read everything I can get my hands on, do a ton of experimentation to try to build a set of novel insights that you couldn't find from other people's research hopefully, and then the next stage is try to make it as concise and actionable as possible so that I can reference it for my own selfish benefit. Here's my guidebook for myself on writing better blog posts, for example.

Julian Shapiro (10:40):
And then by the time I've done that work, what usually happens is its only like, I'm going to make up a number here, an extra 30 hours of work to make it palatable and digestible for the public. If I've done all this work privately, why not make it accessible publicly? At that point, it winds up being acquisition fodder for essentially building an audience and distributing my thoughts further. That's why I do that. But the thing that I pride myself on with them is by no means are they thoroughly unique, but in every one there's a lot of original stuff folks on average have never heard of before.

Julian Shapiro (11:14):
And that's what I'm proud of, is coming up with those insights between the lines that make that thing, whatever the topic is, much more approachable. I've succeeded, in my view, if I've made something that people often mistakenly think of as overwhelmingly complex very simple for them to follow. I think that's where the dopamine hit comes from for them.

Lenny (11:34):
Well, my experience, you definitely hit the nail in my head with the handbooks you put out. It's an interesting middle ground between a newsletter and a book. It's cool to just have a digital way of doing that, of just kind of consolidating a bunch of ideas and going really in depth, but not having to write a book. Well, speaking of the contract there.

Julian Shapiro (11:51):
You have a very large newsletter that goes very in depth. That arguably is a more valuable asset than my handbooks for someone building an audience, because the newsletter has this built-in form of retention recurrence, where they get pinged in their inbox when you have new content, and then it becomes a referable thing and people refer each other and then they sign up for the newsletter. I do love the emphasis on longform via newsletter, but the reason I do it on the web is, and we'll talk about the trade-offs in a second, is it's much more digestible and referencable.

Julian Shapiro (12:24):
No one's going to go refer to the epic guide in their email inbox that's very hard to navigate for building muscle or something. One, it's a UX decision. Two, I get the SEO traffic, which you don't. And then three, it's basically a living asset that I can keep updating over time. It's not stuck in someone's inbox and getting printed out. One of the things that might separate me from other writers, at least many other writers online, is I'm spending as many hours going back and rewriting old blog posts and handbooks as I am writing ones.

Julian Shapiro (12:55):
If you come back to anything I've written over the course of a year or year and a half, it'll be updated, because I consider everything I write to be evergreen. I avoid writing things that I feel like are a drop in the pan, just like talking about a trend or something, something very newsy. I avoid that altogether and I'm just interested in writing stuff that'll be relevant for a long time.

Lenny (13:13):
I didn't know that. That is very cool. I love that you do that. You should make that clear. That's so interesting that this is not stale. Last updated, last week. I don't know if you already do that.

Julian Shapiro (13:21):
Yeah, no, I actually don't and I probably should. People have complained to me that I haven't, so maybe I will one day.

Lenny (13:25):
All right. We got a good idea out of this, if nothing else.

Julian Shapiro (13:28):
There you go.

Lenny (13:28):
Okay. The first idea that I want to chat about is something that you call product-led acquisition. I believe it's the most popular page in any of your handbooks. It comes from you working with thousands of companies to help them figure out their growth strategies through Demand Curve. I'm curious to hear what this concept is and how people can use it to help their products grow.

Julian Shapiro (13:51):
Product-led acquisition to your audience will be more commonly known as product-led growth, but I think product-led growth is a bit of a misnomer. It's often used, as you know, to basically refer to SaaS companies who are using self-serve sales funnels where a salesperson isn't required, right? Bypassing sales and allowing the product to grow itself. That's fine. But I think the term we really care about as growth marketers is product-led acquisition, meaning the use of the product grows the product. For example, if I'm using PayPal and I'm sending $1,000 to somebody else, there is no way they will not create a PayPal account to accept the $1,000.

Julian Shapiro (14:31):
By me trying to use PayPal in its everyday intention and me getting value out of it to settle a debt, I'm automatically enticing someone else, very strongly so, to also become a PayPal customer. That's product-led acquisition. There's a few different categories I've identified, and I think the reason why people like this part of this article I wrote is because it's, in my opinion, the absolute best way to grow any startup. If your startup can grow via product-led acquisition, not all can, maybe some are enterprise-base and all they're going to make work is sales, then it is by far the best way to grow because zero marginal cost to have users invite other users.

Julian Shapiro (15:12):
It's scalable. It creates network graphs typically and has compounding effects there in terms of both moats and the ability to acquire more customers quickly. Basically to the point I just mentioned is basically viral. The other interesting thing here is there are far fewer dependencies. Let's say your company primarily grows via content and SEO, where you're at the mercy of Google releasing an algorithmic update let's say twice a year, which occasionally will absolutely tank your traffic and most people know what I mean by that if they've experienced that. It's awful.

Julian Shapiro (15:41):
Or ff you're a paid acquisition-led company, as opposed to a content-led acquisition company, meaning you're running Facebook Ads, let's just stick a Facebook for now, Facebook and Instagram, you're also at the mercy of the volatility of CPMs and whatever weird updates Facebook introduces or whatever targeting options they suddenly remove. Your entire acquisition strategy is anchored on something that is completely out of your hands and very volatile. Product-led acquisition is like the better you craft your product and the incentive structures for existing users inviting other users, that's entirely in your control and the better you grow.

Julian Shapiro (16:19):
That's the quick context. Now, I'll go into some examples. We started with the example of... Actually one thing that came to mind that I love is Paul Graham, who we mentioned earlier, Paul Graham from YC, has this quote which is "don't start a startup where you need to go through someone else to get users." That always really resonated with me. Here are the categories of product-led acquisition that I've identified. Number one, like I mentioned, is users inviting other users to settle debts.

Julian Shapiro (16:51):
If I'm going to pay you money I owe you for splitting dinner on Venmo, or a business expense that I'm paying you, you're my vendor on PayPal, or anything that's allowing me to just pay you money I owe you and I have to use a product to do so, whoever is collecting the money from me is going to make an account on that product if necessary to claim their hard earned money. Almost guaranteed way for you to have user-led growth, product-led growth. Now, it doesn't have to be money. It can be settling a debt of like an NFT, for example.

Julian Shapiro (17:19):
Someone buys an NFT from you on OpenSea and the only way for them to receive their NFT, I'm just making this up right now, is to also have an OpenSea account or a wallet that's specific to that collection. Again, making this up. The point is if you're settling the debt of something you owe someone and they must make an account to capture the thing owed, they're going to sign up. That's category one. Category two is when you're inviting someone to join the product you're using to partake in a conversation that the otherwise cannot access. Why does Telegram, WhatsApp, iMessage, all these chat apps, Discord, grow so quickly?

Julian Shapiro (17:58):
Pretty obviously because if you and your little clique of friends are having your conversation in that app, then the person who's also in your real life friend group, but who hasn't yet installed the app has to install the app in order to have the conversation with you. Inviting people to critical, social, or business conversations in an app is the other way that you can nearly guarantee you'll grow very quickly from product-led acquisition. The business version of this is Slack. You sign up for Slack. You invite all your friends or all your coworkers. Then you even invite all your vendors via Slack Connect.

Julian Shapiro (18:34):
Slack Connect was a brilliant Slack feature where they're saying, "Hey, we're now going to encourage you to invite people who aren't using Slack who are outside of your work." I don't know how that's done for them as a feature, but in theory, it's a brilliant way to expand the surface area for inviting people via product-led acquisition. Just to recap where we are real quick, one of the ways of acquiring customers is to encourage existing users, to pay other people or to encourage them to come into your app to have conversation that's only happening on the app.

Julian Shapiro (19:04):
If I'm a product person and I'm road mapping my product, I will think, is there anything in my product conducive to either one of those two functionalities, settling debts, or can I introduce chat within my product? And if so, you might be cracking open an amazing channel. When I tell people about product-led acquisition, I'm usually doing it in the context of let's rethink your product feature roadmap to prioritize features that facilitate these things that can lead to explosive growth. I'll pause if there's anything you want to dive in there, but I have three more categories we could chat about if you want to, three more ways of doing PLA.

Lenny (19:44):
Yeah, absolutely. I just want to lob a question over there as you're going through these to maybe touch on this. Most founders would love to find a way to grow through virality and invites and all the things you're talking about. I find that it's often hard to lop onto something they're doing, if it's not a natural fit. As you're going through this, I'd love to know how often have you seen startups succeed adding something like this when their app is not a money exchange app or a chat app? I'm curious how often it works to add something like this when your app's kind of something else, if that makes sense?

Julian Shapiro (20:17):
Well, the real lesson is don't start a company if you have no idea how it's going to grow. Now, that's not categorically true for all startups. It's irrelevant for deep tech and biotech and climate tech and all that stuff, but for a lot of these people starting SaaS companies where they intend to grow very quickly among B2B customers or B2C. The real point of what I'm saying is if you have three ideas before you as a founder and one of them lends itself to product-led acquisition really beautifully, then lean in that direction perhaps if you think that growth is the key differentiator between them for what's going to lead to success.

Julian Shapiro (20:51):
It's like make life easier on yourself. Because if we're relying so heavily on SEO and content, which is extremely saturated, or paid acquisition, meaning ad channels which are extremely saturated, especially if you have low LTVs where we can't really tolerate the volatility of paid CAC or just the cost in general of those CACs, then we have to be thinking more strategically at the product level. It's less about tacking it on later, but sometimes this will work brilliantly if it's very organic. When we cover my next category, we'll actually see some examples of how you can pack it on more seamlessly.

Julian Shapiro (21:24):
But the other response to your question, which is a great question, is people mistake product-led acquisition for referral programs, which it is not. Because the referral programs are a tact on incentive trying to give people something to encourage them to invite because they otherwise are not inviting. Whereas PLA, as I've currently defined it, is through the natural use of the product, you get more value when you invite others. You settle your debt with the payment recipient. You get have a better conversation because now your friend Jack is part of the conversation. You don't have to incentivize them with anything artificial, with any rewards.

Julian Shapiro (22:00):
Referral programs generally are not exciting to me because you're usually trying to... Again, you're like self-selecting for folks who just want the reward very often. And then the people they invite might also just want the dual ended reward and they're not even here for the app really. And then they can bounce. And then they don't invite other people typicall.y. It doesn't have the same compounding sticky retentive nature of PLA. I'm not a fan of it. If you can make a work though, fantastic. Anyway, third category is what I call billboarding. Billboarding is this idea that the use of the product is inherently visible to people around you.

Julian Shapiro (22:40):
The product advertises itself. A few examples. Actually, where I got the term from is I was looking at these billboards above the highway in San Francisco, where I was seeing the company that actually hosts the billboards advertise their own logo on the billboard while also showing you whatever ad they were being paid to show. They were using their own surface area to advertise themselves. Another example is when you're seeing an ad network across the web, like Google banner ads perhaps, and it says they're brought to you by Google Ads, they're using their own surface area to advertise themselves.

Julian Shapiro (23:14):
That's billboarding. It's a brilliant free way to get a ton more exposure. There's a few ways to do billboarding. One is the classic example of Hotmail and iPhone. When you send an email via Hotmail, at the end, it pens a signature saying sent via Hotmail. Same thing, sent from my iPhone. Every single email sent from an iPhone device, unless you remove that signature, is a free billboard for Apple itself, which further furthers the brand awareness and gets more people buying.

Julian Shapiro (23:45):
For example, if you have a feature in your application where people are sending emails or communications to other users outside of the org, like it's an app for sending SMS messages or it's like a way to send invoices to your vendors, when you're facilitating that generated messaging, say brought to you by the name of your startup in the signature of it, really use your own surface area to increase your own awareness. That's billboarding in two different ways. The third way is the very obvious way of having something unmistakably recognizable out in the world.

Julian Shapiro (24:21):
If I drive a Tesla, if I wear Nike shoes, if I have Apple AirPods, all of these are immediately visible to everyone around me, which is why sometimes physical products can really explode because they're just free walking billboards all over the world. And then the sort of most topical hot example right now on Twitter is when you switch your Twitter profile to an NFT in a particular collection, you're billboarding for that NFT collection, right? Same phenomenon that occurred with the Bitcoin laser eyes.

Lenny (24:50):
And also for Twitter Blue, to be able to even do that.

Julian Shapiro (24:53):
Yes, exactly. Exactly right. Like Telegram right now, they released something like Twitter Blue. I forget, I don't know what it's called. But now when you're a Telegram premium paying user, it has a little star thing next to your name that everyone else sees. "Wait, what is that? Oh, that's Telegram Pro. Let me take a look at that." Last example, which is one of my favorites, is billboarding via the nature of your product being something people are compelled to share in order to use. If I have a Calendly account, I have to share my Calendly link with the world in order to create an event on my calendar.

Julian Shapiro (25:28):
If you're like me, you get a million Calendly links every week. That's the phenomenal form of billboarding, people are sharing it willingly. No wonder they've exploded. Same thing with Dropbox sharing file links and you're seeing the Dropbox URL, or GoFundMe, when people share the GoFundMe page. You get the gist. Billboarding costs you nothing, scales infinitely, can have compounding effects. And if your product lends itself to billboarding, it's just a phenomenal way to grow if possible. That's category three, I guess. We'll cover one last one, if you'd like me too, which is basically UGC, so user generated content.

Julian Shapiro (26:05):
Same sort of thing. Basically I hop on YouTube or TikTok or Insta or whatever. I make content. I share it with the world. In so sharing that content, the platforms brand themselves on the content. At the end of every TikTok video on Twitter that you've ever seen or Insta, at the end it'll say, "Here's the TikTok user's account." They're billboarding themselves into the content that users themselves are generating, and the users are incentivized to share that content off platform, which brings users to the platform, because users want to get customers wherever they can. They're going to cross-sell to their YouTube channel and so on.

Julian Shapiro (26:41):
If you have a marketplace like eBay or some marketplace for selling collectible shoes or something where you're encouraging users to create beautiful content of the items being sold, like these cool landing pages that show off the products, and they share it elsewhere, then that's an example of users making content they're sharing off platform that is useful for their own followers. Another example of UGC that people often overlook is Quora or Reddit or Stack Overflow or TripAdvisor, where you're encouraging users to create content in the form of conversation that then surface itself on Google and SEO.

Julian Shapiro (27:23):
Basically if you just encourage users to have conversations that are publicly indexed, that increases your surface area on Google for hitting more keywords and you get way more search traffic. Basically the question that this boils down to is to leverage UGC in your product, you ask yourself, do users use my product to make content in any way, shape, or form? If so, what type of content that they make should we encourage them to then share? And then how can we make the page that they use to share the content as appealing and as easily to consume as possible? And that's basically UGC. We'll pause there, but basically that's PLA in a nutshell.

Julian Shapiro (28:03):
The thing that all of these have in common is you're not spending a dollar. They scale super quickly. You're not reliant on, well, maybe to some extent with SEO, but you're not relying on third party volatility. It's a much healthier narrative for how you're going to grow and scale.

Lenny (28:17):
Awesome. This episode is brought to you by Eppo. Eppo is a next generation A/B testing platform built by Airbnb alums for modern growth teams. Companies like Netlify, Contentful, and Cameo rely on Eppo to power their experiments. Wherever you work, running experiments is increasingly essential, but there are no commercial tools that integrate with a modern growth team stack. This leads to waste of time building internal tools or trying to run your experiments through a clunky marketing tool. When I was at Airbnb, one of the things that I loved about our experimentation platform was being able to easily slice results by device, by country, and by user stage.

Lenny (28:57):
Eppo does all that and more, delivering results quickly, avoiding annoying prolonged analytics cycles, and helping you easily get to the root cause of any issue you discover. Eppo lets you go beyond basic clickthrough metrics, and instead use your north star metrics like activation, retention, subscriptions, and payments. Eppo supports test on the front end, the backend, email marketing, and even machine learning clients. Check out Eppo at geteppo.com, getE-P-P-O.com, and 10X your experiment velocity. I have many questions I'd love to ask, but I also want to make sure we get to the other topics.

Lenny (29:34):
We talked about acquisition, which we'll link to in the show notes, by the way, this whole post. The flip side you could say is retention. If you're a reader of my newsletter, you know how much time I spend thinking about retention and how important that is. I know that's a second topic that we wanted to chat about, because you've also helped a lot of companies think through their retention strategies and to help them retain more users. I'm curious to hear what you've found to be the best strategies for retaining users and increasing retention.

Julian Shapiro (30:01):
Yeah, sure. The way I think about retention, my favorite strategy is what I call building state. It's a concept I stole from video games, where basically the more you play any given game, the more state you're accruing. That might be your armor, your weapons, your character skins, and whatever. As a player of the game, the more state you build, the more you're compelled to stick around, because you don't want to lose everything you've worked so hard for. The more state you have, the more you can exploit that state to get more. The rich keep getting richer. The same mental models apply to let's say SaaS retention.

Julian Shapiro (30:38):
This is as old as time, or at least as old as modern capitalism. If you think of credit card rewards or frequent flyer programs, you spend money. You accrue points. You convert the points into rewards. Once users build momentum doing that, they're less likely to switch to a competitor. That's the age old example of building state. Software, it's unbelievably powerful. This building state concept is why mediocre companies like eBay or Craigslist remain completely unbeatable for decades. Even though the UX is bad, people don't like using them, they fail to innovate, no one topples them and it's because of state.

Julian Shapiro (31:16):
Let's walk through some examples. State, kind of like my PLA mega spiel, mega rant there, subdivides into a few categories, but I'll make this one shorter and less boring. The first subcategory of building state is when you're encouraging your users to accrue non-transferrable reputation, meaning they're doing stuff to build reputation on the platform and they cannot take that reputation to them off platform. They're stuck there to get the compounding advantage of that reputation. For example, let's say you've spent years getting 10,000 or more feedback ratings as an eBay seller.

Julian Shapiro (31:56):
You are not leaving eBay anytime soon, because that reputation's just too valuable. It's producing a huge boost in revenue because of the trust it engenders with buyers on eBay. It probably results in you ranking better in search results for an eBay query. Because you cannot move those 10,000 feedbacks to an eBay competitor, you're not incentivized to go use an eBay competitor. This type of stickiness, this non-transferrable reputation, basically applies to all marketplaces and directories. Same thing on Yelp. You as a restaurant build your reputation on Yelp. The momentum keeps you stuck there. You want to keep getting reviews and hone your reviews.

Julian Shapiro (32:32):
Airbnb with your properties, Etsy, for you as a seller, Alibaba, all of this stuff are examples of companies that are kind of old now, cannot be top old or haven't been yet. People are like, why? Well, because of this exact reason. This is why those companies pester you so much to leave reviews and provide feedback all the time. They want you to play into this game of in market reputation building. The second state building technique that a startup could adopt, and again, this is all under the guise of how do we maximize retention and build somewhat of a moat, for example, the second way you can do this is you encourage your users to accrue a non-transferable audience.

Julian Shapiro (33:14):
If I'm a big YouTuber and I've acquired a million subs, those subs can't be transferred anywhere else. I can't bring them to Twitter. In fact, YouTube doesn't even tell me their email, so I can't even bring them to a newsletter if I wanted to. The more subs you acquire on YouTube, the easier it is for you to go viral on YouTube. This is what I mean earlier by the rich keep getting richer. It's this momentum trap. It's very, very hard to convince any YouTuber to get off YouTube. If anything, they'll dabble with another network in parallel at best.

Julian Shapiro (33:43):
Basically if you have a startup where you're creating a marketplace or an audience graph, you want to encourage users to build a follower graph within that product that they can take advantage of by pushing their product or their content or their insights too. This is why Twitter... By the way, a big shout out to Substack, which actually allows customers to export emails off of Substack. Substack is not playing that same game, which is better for users and a very nice thing for the ecosystem. But this is why Twitch and Instagram and Twitter are just irreplaceable. I mean, not necessarily. Everything dies over time like Facebook, but they're just so darn hard to topple.

Julian Shapiro (34:26):
Let's maybe touch one more. I don't want to ramble so much about this. Well, this one's kind of similar. Basically if you spent a lot of time building a social graph in a product, like if I spent the last 10 years trying to remember the names of all my high school friends and elementary school friends and add them one at a time over the years to Facebook, or I've added all my colleagues for the last 20 years onto LinkedIn and I've built a social graph on these products where I've curated and found people, that's really sticky. You're building state in the form of taking time to expand the graph. The graph is a representative of the state, the work you've put in.

Julian Shapiro (35:04):
You don't want to lose those connections with people. That makes that product extra sticky. This is why social networks in general can be sticky. It's not just the fact that you have your audience there, it's that you've invested time. If Facebook doesn't allow you to export your graph out, then that makes it extra sticky as well, because you don't know how else to talk to old Jimmy from elementary other than Facebook. Anyway, there's actually many more of these examples of building state. I'm going to just stop with that. But the basic concept is what can you encourage users to do within your product that makes them more deeper entrenched in the product, and most apps just completely lack this.

Lenny (35:39):
I like that. It's a little bit like the concept of having skin in the game and just building more skin in the game with the product that you're using. One quick question, is there a company that you've seen do this, like add it on, and succeed and increased retention that you've worked with or out there? Just like is there a good example that comes to mind that added this piece?

Julian Shapiro (35:58):
Again, none of this is really under the context of telling people to add it on after they've decided what they're building. This is all in the DNA of the product you're choosing to build. I'm not sure. I haven't thought of those examples. I'm thinking more so in whose DNA, which company's DNA are they doing this brilliantly? For example, one form of state is... One I did not cover is when you're embedded infrastructure. If you're Twilio, Striper, AWS, it's really hard to move off or segment because it's so much work to redo your code and introduce all this risk to screwing up your code base. People have built patterns around how they work with your API.

Julian Shapiro (36:36):
A lot of modern API startups automatically capture the stickiness by virtue of being so deeply embedded into a product. Generally speaking, none of this is in the context of like, hey, add it on post hoc, pretty much.

Lenny (36:46):
Got it. I like that lens actually through a lot of these things you're talking about is maybe it's less like change your product to make this happen, and it's more idea selection. I know you're also an investor, and so it's a really good lens on how many of these things does this company have that I'm investing in.

Julian Shapiro (37:01):
Earlier I was mentioning why do I write handbooks, I wrote the handbook that PLA and state building come from to cement my diligence criteria for companies I believe might grow super fast and retain customers. You're exactly right. My investor's perspective is if you have a zero cost of acquisition mechanism for customer acquisition, such as PLA, and you can retain them through something like state building, but there are other ways to retain customers, then I lean in harder because I think you'll be more defensible as a company. Actually interesting little side note is you'll often hear retention and stickiness refer to as a moat, right?

Julian Shapiro (37:41):
But I find this term actually very misleading because very few companies have actual moats. To have a real moat, you're basically exploiting kleptocratic, meaning you're friends with the government and they're creating a literal barrier to entry for your competitors, or you have a scientific moat where you have an actual scientific breakthrough in the fusion energy space, plus protected by patents. Those are real moats. But the way most people use the word moat is wrong. In practice, your "moat" is just your mechanism for retaining users a little bit more than the average company.

Julian Shapiro (38:21):
I believe state building is one of the best ways to do exactly that. Really it just comes down to what are you doing to help users build state and get more value over time out of the product, not the same level of value over any time period.

Lenny (38:35):
Awesome. Shifting a little bit away from growth and into writing, which I know you've spent a lot of time writing about, very meta, and sharing on Twitter and all the ways, you have a handbook where you go into this concept of novelty and a framework for how to be novel and why that's important in writing. I'd love for you to talk about why novelty is important in writing and ideally share your framework for creating something novel that keeps people engaged in reading.

Julian Shapiro (39:03):
Sure. This actually goes back to your question about Twitter. What can one do to build an audience on Twitter? It often comes down to writing things that are novel. Novel is what powers click bait in most cases. The other way is via curiosity gap, where you raise a question you don't answer, but the other half is novelty is what gets people to click into a thread and read it. Novelty, I define, as new idea, so something I haven't heard of before, that's also significant, so it's not some trivial fact about Kim Kardashian, and it's something that I wouldn't have easily intuited on my own.

Julian Shapiro (39:44):
When you have those ingredients, it's new, it's significant, and you wouldn't have easily thought of it on your own, that's when you trigger that dopamine hit reaction, I'm not being scientifically accurate here, but you're going to get that dopamine hit like, "Whoa! That's super cool." The more you have readers pausing going, "Whoa! That was interesting," the more novel your writing is. My whole approach to writing is write something out, and then point out all the points of novelty. I do that by actually having 20 friends read something I've written and highlight the sentences that made them go, "Whoa."

Julian Shapiro (40:17):
And then I have this visualized map in a given blog post, where are the areas that people go, "That's really interesting," and then I can see all the white space between the interesting parts. I go in and I condense that white space. I chop it down so that the frequency of novelties as high as possible. This is how you get a blog post that just has this phenomenal momentum that gets the read to completion rate to be very high. The question is, what exactly does novelty look like? I've identified about five different categories for it, and this is the backbone of how I write in many cases.

Julian Shapiro (40:51):
The first category of novelty is what I call counterintuitive information. You tell people something and they go, "Oh wow. I never realized that the world worked that way," or different categories and you tell people counter-narrative information. That's where people respond, "Wow. That's not how I was told the world worked." Whereas counterintuitive novelty is, "That's not how I would've thought the world worked," counter-narrative novelty is, "That's not what I've been told. I've been lied to. Now you're telling me the truth." That also triggers a dopamine hit. Third category of novelty is just pure shock and awe like, "That's crazy. I would've never believed that's true."

Julian Shapiro (41:30):
For example, there's a volcano that's going to erupt the next 15 years that's going to swallow this whole island. Wow, that's shocking. Holy moly. Next category is what a lot of popular Twitter users do is what I call elegant articulation, where you're taking an idea... Naval does this, Naval on Twitter, the founder of AngelList. He'll say something that's a complicated rich thought and boil it down into a very concise sentence. And then the reader goes, "Wow, that's beautiful. I couldn't have said that any better myself."

Julian Shapiro (42:02):
That also triggers that dopamine reaction. There's a few more, but the point I want to get at here is all of these are formats for identifying the types of things you could say to get people to go, "Whoa." That's what I think of as novelty.

Lenny (42:17):
Something I've found to kind of identify something that I've written is going to be interesting is I just read it myself and I feel what I feel when I'm reading it the first time. Often I find that if I'm like, "Oh wow, this is really good and really exciting," I've learned to trust that feeling wherever that comes from. That's just like another way of knowing if your thing is interesting is like, are you excited about it? Are you interested in it as you're reading it? And that fades after you read it like 10 times and kind of edit and edit, but that's just a small tip I've learned, just kind of trust your own gut feeling when you're excited about something that you're writing about.

Julian Shapiro (42:53):
I agree. And that's why I tell people when you first encounter something that to you is novel, write down with a score, like let's say out a five, zero to five, how novel that thing was to you when you first heard it. You want to remember and capture the degree of novelty, because to your point, Lenny, it's going to become less novel over time. And then if you pull that out of your idea bank for a blog post in two years, it'll like, oh yeah, that will blow people's minds, even it doesn't blow my mind today.

Lenny (43:16):
Good tip.

Julian Shapiro (43:17):
To your point, the way you basically get novel ideas is you go live your life and write down every time you come across something that interests or surprises you, or any time you come across something that makes you think, "Well, that's obviously not true," meaning you found something that people say that you know the lie and you're about to tell people the way the world really works. Some examples of novelty... I'm scrolling through Twitter up here. This is a tweet I wrote where I wrote, "Reading many books is the most socially accepted vanity metric for adults." I give zero kudos for reading a hundred books a year, but I give you massive kudos for learning efficiently and making interesting things.

Julian Shapiro (43:59):
This tweet is an example of me using novelty. As we read the key novel part, it's where I say, "Reading many books is the most socially accepted vanity metric for adults." That is counter-narrative novelty, because the prevailing narrative is all the smart people I've ever met, they read a ton of books. They always have a book in their hand. They're reading five books a month, blah blah, blah, blah, blah. I'm saying no, that's a vanity metric how many books you read. That's counter-narrative. That gives people a dopamine hit. They lean in. They want to see what my punchline is and that tweet got a lot of engagement.

Julian Shapiro (44:33):
One more example. See if you can catch the novelty here. New tweet, "The world is not run by exceptional people. This is the hidden reason for imposter syndrome. We mistakenly think imposter syndrome is due to low confidence or low anxiety. No. It's caused by not accepting that your new world-class peers aren't that special. It's just discipline." The key statement there that has the novelty is the world is not run by exceptional people, and the type of novelty being used there is counterintuitive. Your intuition is the world's run by the best of the best or many of these experts are there for a reason.

Julian Shapiro (45:15):
I'm saying not in most cases. Anyway, those are some examples of novelty. Of course, these tweets took off largely due to that reason. People love having their eyes opened. They'll reflexively retweet you to agree with your worldview if they feel like you're finally speaking truth, the power, in some sense, if that makes sense.

Lenny (45:34):
We'll link to those in the show notes. By the way, I love your reading your own tweets voice that you have.

Julian Shapiro (45:40):
I'm adopting my... Who's the guy from Star Trek who's amazing, who reads the kids?

Lenny (45:45):
Oh yeah, LeVar Burton. Reading Rainbow.

Julian Shapiro (45:49):
There you go. That's my voice.

Lenny (45:50):
Julian Shapiro, the new LeVar Burton. I know you have to run in not too long from now. We have two more topics. How about I set up both topics and then you kind of talk through as much as you want with each? That sound good?

Julian Shapiro (46:01):
Sure.

Lenny (46:01):
Cool. The fourth topic we want to talk about is topic selection, how meta, essentially picking what to write about, and you have a bunch of great advice on what's worth writing about and the framework around that. And then the fifth idea is something you called it the Creativity Faucet, which is essentially how to get more creative. I will turn it over to you to share your thoughts on these topics.

Julian Shapiro (46:22):
Sure, sure. My pleasure. The way I think about topic selection, meaning what is it you should write about for your blog posts, for your newsletter, Twitter, company blog, whatever, books, is you choose topics based on two factors, what would you actually be able to complete so you're not going to give a pathway through and what will actually be high quality. I have a framework for helping you figure out what that is. Basically I believe that your likelihood to follow through on something you start writing is a function of the objective you have with writing that piece and how strong your motivation is for seeing that objective to fruition.

Julian Shapiro (47:00):
Here's what that looks like more specifically. Anytime that I write something, I'm first trying to identify what is my objective. Here's a few examples of objectives that I'll use before sitting down to write. Number one, I want to open people's eyes to prove the status quo wrong, or two, I want to articulate something that everyone's thinking about, but no one is saying. I want to cut through the noise. Another objective might be, I want to contribute original insights to my own research and experimentation. Hence, some of my handbooks. Another objective is just telling a suspenseful and emotional story that maybe imparts a lesson.

Julian Shapiro (47:34):
These are all clear cut objectives that give me a guidepost. I know that I'm done writing a piece if I can read the piece and say, "I've accomplished that particular objective," because people don't know when they're done writing, "Oh, I petered out here and this seems like a good place for an outro." With an objective, you know whether you should actually stop. But then the question is, how do you sustain the motivation to see through an objective? Again, an objective might be something like open people's eyes by proving the status quo wrong. To do all the work necessary to accomplish that, you need a motivation in my opinion.

Julian Shapiro (48:08):
I'll pair one of those objectives that I've selected with a motivation. Some example motivations are, does writing this piece get something off my chest that I really badly need to get off? Or does it help me solve a nagging unsolved problem that I've been dealing with and this piece is way for me to explore and find the solution? Or is it like me obsessing over a topic that I want others to also geek out about? These are all powerful motivations that I pair with an objective to guarantee my follow through to get done writing the piece.

Julian Shapiro (48:41):
By the way, everything I've mentioned in this entire chat with you, the novelty stuff, the topic selection, PLA, state building, everything we've covered, I have tons of examples on Julian.com. That's why I'm not trying to go through every single one.

Lenny (48:55):
Yeah, and we'll link to all that.

Julian Shapiro (48:57):
Absolutely.

Lenny (48:57):
Awesome.

Julian Shapiro (48:58):
The flip side I'll point out is that I think writing quality overall is... Again, these are all me being hand wavy and these are not rules. There's no right way to write, just like there's no right way to paint. These are just frameworks I've developed, that when I use them, I'm more frequently arriving at success as far as I define it. The thing I want to point out though is that very closely tied to everything I'm talking about is my framework or my equation for determining how good any piece of writing is, is novelty times resonance. Writing quality equals novelty times resonance.

Julian Shapiro (49:36):
Novelty is like we discussed, here are all these things that are giving you dopamine hits where I'm opening your eyes about how the world really works and shocking you and elegantly synthesizing things, times resonance and resonance means I can tell you the most novel thing on the planet. But if I don't wrap it in a way that resonates and really lifts off the page and into your mind and is something you remember, then it's fairly ineffective novelty. It's more like just trivia. It's bland, dry trivia. When you add resonance to the novelty, now it becomes a beautifully written piece. Resonance is a matter of including examples, analogies, metaphors, stories.

Julian Shapiro (50:14):
Really writing quality is novelty times the storytelling power you have to make the novelty resonate in the back of people's minds. The way that I structure my writing process is draft one, I'm just focused on finding my novelty, just the backbone of what makes anything interesting. And then draft two, I come back and try to increase the resonance by embedding story and analogy and examples. That's basically my process there.

Lenny (50:41):
I like that a lot. Just to add real quick, something I've learned is that if your stuff is really useful, it doesn't have to be written beautifully. A lot of people I think are afraid of writing because they think they have to write really well, like be real good writers. What I've learned is it's okay if you're not like. You just be good enough and you'll get better the more you do it. The most important thing is the content is valuable and interesting, which I think you're describing as novelty. I just want to make sure people don't get scared away and be like, "Oh my god, I need stories and metaphors and all these beautiful writing." Initially you don't is my experience, but it helps in a big way.

Julian Shapiro (51:17):
I agree. In fact, the biggest criticism of my writing is that it is too dry, it's too novelty focused, and there's a lack of the resonance, but I do that purposely because oftentimes people can over-indulge in resonance and then it really bloats the piece. As a reader myself, I like reading super concise pieces, like reference manuals almost. I'm looking for the length from personal anecdotes, personal stories of people's lives or life lessons they've learned that they want to share with me, or actual fiction. To each their own. You're spot on. Do what you would want to read to me is the golden rule.

Lenny (51:52):
Awesome, and also don't be afraid. Don't feel like the bar's that high if you want to get started.

Julian Shapiro (51:58):
What have been your frameworks for sitting down and knowing that one of your newsletter editions is where you want it to be? And what do you think is the framework justifying that a piece is or explaining why a piece is good?

Lenny (52:10):
The thing that I always strive for is this needs to be actionable and useful. It's something someone could take and do something with that day versus just a bunch of theory and pontification and philosophy. It's like, oh, here's a thing you can go do today.

Julian Shapiro (52:25):
That's kind of my bar is make it very actionable, which I think is specific to the type of newsletter I have, not necessarily broad writing the way you're describing, but that's what I try.

Lenny (52:35):
I love that. I agree with you, my rules of thumb are like it has to be actionable, concise, and novel. I'm not sure if you've seen this as well, but to make something truly actionable, I have to leave them with a cheat sheet. Because if I have all these actionable steps, but they're spread throughout a monster newsletter edition, it's too much mental work to go and make my own cheat sheet out of and have a quick to follow series of steps. I feel like compression is a key part of making something actionable as well.

Julian Shapiro (53:06):
There's a book called On Writing Well that taught me a lot about cutting two-thirds of what you've written to get to the core of it. I'm curious, what else are you doing to try to harden each newsletter edition to make sure it's good? Is it just like, hey, this is actionable and we were pretty comprehensive and I checked it past experts? Is that the extent of it, or what are you trying to do to feel like it's fantastic? What's your review process when you pass it by others as well?

Lenny (53:30):
I'm happy to answer that, but I also know you got to run soon. I guess we could touch on... We could just save the fifth topic maybe for a follow up episode is one idea, or we could touch on it.

Julian Shapiro (53:40):
Sure. Up to you. Anything you want, my friend. If you want me to cover the next topic, super happy to. Up to you. Everyone listening right now is like, "Man, Julian's just been fucking rambling for an hour." I realized we were not having a conversation. Now I feel bad because I was so in my momentum of sharing some concepts that I didn't really have a conversation with.

Lenny (53:59):
This is very normal for this podcast, so do not stress.

Julian Shapiro (54:04):
All right. Good. Actually, you should leave this all in here so they know I feel bad. I'm not cutting anything. What was the last topic again? Remind me.

Lenny (54:12):
I was just saying, I think one of the things people really like about this podcast from what I hear often is they like that I'm not talking a lot. They kind of like that I'm letting the guests speak mostly, because a lot of podcast, the guest thinks they know at all, or sorry, the host and they just talk, talk, talk.

Julian Shapiro (54:27):
Oh, got you. The thing is you are brilliant. You're an actual host who is a useful, amazing human being and we want to hear your thoughts.

Lenny (54:35):
What was the last topic again?

Julian Shapiro (54:36):
The last topic was the Creativity Faucet. We can save that for another talk, or if you want to touch on it, we can do that too.

Lenny (54:43):
Sure. Yeah, let's do it.

Julian Shapiro (54:45):
The quick version here is that this is an idea that I saw recur across three of the most prolific creators in the world, John Mayer, Ed Sheeran, Neil Gaiman. Ed Sheeran might work with other producers and so on, but the basic thing between the three is they're very independent creators who are constantly making blockbusters in large part on their own. I was curious, what on earth are those three doing that very few other people are doing? Taylor Swift also. One day I actually found the answer, what is their approach to consistently making phenomenal content? The way I found it was interesting.

Julian Shapiro (55:23):
I was watching a masterclass, like Masterclass.com, with Neil Gaman and he explained his process for writing fiction novels. And then in the same year, I watched the documentary of Ed Sheeran explaining his process for writing songs and they were identical. And then a year later, I came across a YouTube video that I posted on Twitter with John Mayer spinning his process, also identical. I'm like, fuck, there's the answer. They don't have a name for their process, so I just call it the Creativity Faucet. Very quickly, what they do is they visualize their creativity as a backed up pipe of water. The first mile is packed with wastewater, and this wastewater has to be emptied before the clear water behind it can arrive.

Julian Shapiro (56:10):
Because your creativity pipe or Creativity Faucet only has one faucet, there's no shortcut to achieving the clarity, the clear water of good ideas, until you first empty the wastewater out. If we apply that to creativity at the beginning of every writing session, write out every bad idea that comes to mind. Instead of being self-critical and resisting these bad ideas, you have to recognize bad ideas is progress. Because once they are emptied out of you, the better ideas begin to arrive. Here's the key part, why do good ideas arrive after the bad ideas are empty? It's because when you've gone through a bunch of bad ideas, your brain, your mind starts reflexively identifying what elements are causing the badness.

Julian Shapiro (56:53):
Then it becomes way better at avoiding those bad elements and you become way better at pattern matching the novel ideas with way greater intuition. Most creators are resisting their bad ideas. If you sat down, scribbled a few thoughts in a blank document, and just walked away because you weren't struck with gold, then you never actually finished the creative process. There's no way you would've come up with gold. Like Neil and Ed, for example, they know they're not superhuman. What they're doing is in every creative session, they simply have the discipline to allot time no matter how long it takes, it could be an hour, to empty all of the bad ideas.

Julian Shapiro (57:28):
And then they're not worried about whether good ideas will come after the bad ones because they know the following process. You start with a weak imitation. You identify what makes your invitation weak, and then you iterate the imitation until it's finally original. And that is the process you have to just throw yourself into.

Lenny (57:46):
I love that. I feel like I don't do that enough. I feel like when I get to writing, I'm just like, "Okay, let's make this awesome." This is a really good reminder just to get stuff out. It connects to the concept of the shitty first draft. Just write. It'll be bad. And then you edit. You asked me this question, what my process is for writing, and most of it is just refining like a thousand times. I just kind of take a first pass and then I look at it, make it better, look at it, make it better, and just kind of keep editing for days and days and days until it's not bad.

Julian Shapiro (58:15):
I love that. That's what I've always done, until one day I was like, "I need a process here." Anyway dude, pleasure chatting. You're a gent. Sorry to all the listeners for rambling so much at a high pace. Cut anything you want. You can cut all of that. I don't care. Whatever you find interesting, go with. We're just going to have this final goodbye and that's it.

Lenny (58:36):
That was very anti-climactic. Cool, man. Where can folks find you online and how can listeners be useful to you?

Julian Shapiro (58:41):
Sure. You can go to Julian.com. It has everything, Twitter, handbooks, all that good stuff. And that's it. I hope you guys find the handbooks useful.

Lenny (58:50):
Amazing, Julian. I know you don't do a lot of podcasts. I really appreciate you being here. This was awesome. I'm excited to get this out.

Julian Shapiro (58:56):
Dude, truly my pleasure. I think you're awesome and you're why I'm doing the podcast. Really my pleasure, man. Have a great day.

Lenny (59:02):
Thanks, man. Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcast, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## From managing people to managing AI: The leadership skills everyone needs now | Julie Zhuo
**Guest:** Julie Zhuo  
**Published:** 2025-09-21  
**YouTube:** https://www.youtube.com/watch?v=c_w0LaFahxk  
**Tags:** growth, retention, metrics, kpis, experimentation, analytics, hiring, leadership, management, strategy  

# From managing people to managing AI: The leadership skills everyone needs now | Julie Zhuo

## Transcript

Lenny Rachitsky (00:00:00):
We're seeing this kind of flattening of orgs. Everyone's becoming an IC again.

Julie Zhuo (00:00:04):
It used to be, okay, I don't have the skills to do 10 different jobs, but now with AI allows me to do many of those jobs myself. We need to dissolve the boundaries of these traditional roles and call ourselves builders. I'd love for us to get to the world where that's the title.

Lenny Rachitsky (00:00:21):
I also just saw a stat Google let go of so many of their middle managers.

Julie Zhuo (00:00:22):
Management is still really critical. You have a north star, you have a vision, and you're just trying to figure out how to use the resources that you have to get that thing done. Used to be people, but now it's basically models and different models have different strengths. You have to assemble the Avengers so that you can use the right tools for the right purposes.

Lenny Rachitsky (00:00:39):
What do you feel is the biggest change in the role in life of a manager these days?

Julie Zhuo (00:00:43):
It's always been manager's job to manage change. I just think the rate of change is accelerating. Today management is really about this idea of be sturdy while being flexible. So I think about this metaphor a lot of the willow tree. It can survive a lot of storms, disasters, et cetera, but it's also very flexible.

Lenny Rachitsky (00:01:00):
You have such an interesting trajectory from being head of design to now being obsessed with data and analytics.

Julie Zhuo (00:01:05):
You want to diagnose with data and treat with design. Data is not a tool that's going to tell you what you should build. I don't actually think a lot of the fast growing companies are using data well at this point. Traditionally things just didn't grow that fast. These companies are totally getting by on just good instincts and good vibes, but what always happens is eventually things stop growing.

Lenny Rachitsky (00:01:27):
Today my guest is Julie Zhuo. Julie was my first ever guest on this podcast, which I recorded over three years ago, so this is a very special conversation as I've shared many times before in other places, Julie's newsletter The Looking Glass was the inspiration for my newsletter and basically led to everything that I do now. If you're not familiar with Julie, she was the longtime head of design for the Facebook app used by over three billion people. She's also the author of the best selling and very important book The Making of a Manager. And most recently she started her own company, Sundial, which is an AI parent analyst used by companies like OpenAI Gamma and Character.AI. Julie is one of the most thoughtful and insightful product leaders that I've ever come across and she's also got one of the most interesting perspectives on product building.

(00:02:18):
Having worked at a mega large corp like Meta as head of design and now as a founder at a tiny startup that's all about using data to help you make decisions, it's really rare for someone to have this spectrum of experiences. In our conversation, we talk about how learning to be a great manager directly translates to learning how to use AI tools extremely well, which specific skills will become more valuable in the next couple of years, her most valuable and timeless advice for new managers, why she's not hiring product managers at her startup, her simple heuristic for knowing when to use data and when to use intuition in making decisions. There's something in this episode for everyone. And if you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. It helps tremendously. And if you become an annual subscriber of my newsletter, you get 15 incredible products for free for an entire year, including Lovable, Replit, Bolt, n8n, Linear, Superhuman, Descript, Whisperflow, Gamma, Perplexity, Warp, Granola, Magic Patterns, ChatPRD and Mobbin.

(00:03:20):
Head on over to lennysnewsletter.com and click product pass. With that, I bring you Julie Zhuo. This episode is brought to you by Mercury. I've been banking with Mercury for years and, honestly, I can't imagine banking any other way at this point. I switched from Chase and, holy moly, what a difference. Sending wires, tracking spend, giving people on my team access to move money around, so freaking easy. Where most traditional banking websites and apps are clunky and hard to use, Mercury is meticulously designed to be an intuitive and simple experience. And Mercury brings all the ways that you use money into a single product, including credit cards, invoicing, bill pay, reimbursements for your teammates and capital. Whether you're a funded tech startup looking for ways to pay contractors and earn yield on your idle cash, or an agency that needs to invoice customers and keep them current, or an eCommerce brand that needs to stay on top of cash flow and access capital. Mercury can be tailored to help your business perform at its highest level.

(00:04:19):
See what over 200,000 entrepreneurs love about Mercury. Visit mercury.com to apply online in 10 minutes is a FinTech, not a bank. Banking services provided through Mercury's FDIC-insured partner banks. For more details, check out the show notes. Today's episode is brought to you by DX, the developer intelligence platform designed by leading researchers. To thrive in the AI era, organizations need to adapt quickly, but many organization leaders struggle to answer pressing questions like which tools are working, how are they being used, what's actually driving value? DX provides the data and insights that leaders need to navigate this shift. With DX, companies like Dropbox, booking.com, Adyen, and Intercom get a deep understanding of how AI is providing value to their developers and what impact AI is having an engineering productivity. To learn more, visit DX's website at getdx.com/lenny. That's getdx.com/lenny. Julie, thank you so much for being here and welcome back to the podcast.

Julie Zhuo (00:05:26):
Thank you, Lenny. I'm so excited to be here. I've been looking forward to this all week. I love your podcast. I love where you've taken it since our very first conversation and I'm super excited to have a fun and engaging chat.

Lenny Rachitsky (00:05:38):
Can you believe that first episode, the very first episode of this podcast, was over three years ago at this point? Holy shit.

Julie Zhuo (00:05:46):
I'm not sure you had that fire in the background back then.

Lenny Rachitsky (00:05:49):
So funny enough, I don't know how many people have noticed this Easter egg that I've stuck with, in that first studio, I was just watching the episode, I had this funny little mirror. I don't know if I had in the first episode with a fireplace that was showing up in that mirror because the mirror was showing something stupid. And so I've just kind of kept this fireplace across every studio I've moved across in my various places.

Julie Zhuo (00:06:12):
I even remember we chatted. Video was kind of a newer thing. You're like, "We'll record it, but it's really about the audio." And now we moved into the video era.

Lenny Rachitsky (00:06:21):
So as you were saying that, I realized my fire was broken, so I just had to turn that on. So we just cut a little piece. Yeah, that fire was my little funny strike for myself and I don't think anyone's ever realized this.

Julie Zhuo (00:06:32):
It's very cozy. I love it.

Lenny Rachitsky (00:06:33):
That's the idea. I was actually just looking at the stats. So since that first episode, this podcast has done over 20 million downloads. It's approaching 30 million downloads.

Julie Zhuo (00:06:43):
It's really incredible. I think it is a testament to just your curiosity and how much you really care about the craft of building great products and sharing that with the world. And I know I listen to your podcast and read your newsletter, my team does. We're constantly sharing things from all of the amazing speakers that you've had, so thank you for doing this.

Lenny Rachitsky (00:07:01):
My pleasure. I really appreciate that. So the reason we are chatting again three years later is you're re-releasing your incredible book, The Making of a Manager. I've got it right here. You've sold a bazillion copies. It's been on every list that I've seen. You're releasing the paperback version, you're adding some chapters. I guess first of all, just how do you feel on reflecting back on the success of this book?

Julie Zhuo (00:07:24):
It honestly went beyond my expectations, so I'm super happy with it. My big motivation to write it was I think largely because I felt if I had to write this thing, I was likely going to become a better manager. And that was actually a huge part of it because thinking about and writing something I've been blogging for a long time. And I know that part of my process is when I really sit down to try and put down everything I feel and write letters to myself, it really helps me. And so that was honestly a huge motivation. I hoped that it would go out there and it would sell some books. I was thinking about that maybe for people who grew up in companies like mine, like Facebook, high-scale Silicon Valley, it might resonate. I couldn't have expected that it would have much wider reach than that and that's been really awesome.

(00:08:11):
And just how many people will tell me things like I thought I was the only one who felt this way, but this book made me realize that, hey, these are very normal feelings. And that's certainly how I felt, just stumbling through and feeling like an imposter for so many years. And so it really is very gratifying to hear that from readers.

Lenny Rachitsky (00:08:29):
I feel like it's the modern-day high output management. That's the book that's been mentioned most on this podcast and it feels like this is just a modern version. I feel like that book is actually out of date in a lot of ways, so I can see why people are really drawn to it. And this is a great segue to the first area I want to spend some time on, which is it feels like a lot of the skills you learn as a manager translate to being really good with AI and using AI tools really well. And I want to talk through a few trends that I want to get your take on that relate to this general theme. The first is it feels like just everyone is going to become a manager in the near future because of agents being so integrated into our workflows. There's this agentic society that we're coming to and it feels like the same skills of being a manager make you really good working with agents. Just thoughts on that and where you think that's going to go.

Julie Zhuo (00:09:20):
I 100% believe that and agree with that, which is that management is just about, in my mind, having an outcome. So you want to get something done. That's the thing. You have a north star, you have a vision, and you're just trying to figure out how to use the resources that you have to get that thing done. And typically when we talk about management in traditional settings, we talk about the resources being people, and getting the right talent, and making sure that you've got the assemble the Avengers, so you've got the right mix of skills that you need. The second lever is around, okay, what's the purpose? Does everyone know what they're supposed to do with their talents? Do we have a goal? Do we have a purpose? And then the third thing is process, which is how should all of these different people and tools come together?

(00:10:07):
And these are still the fundamentals of working with agentic systems. You still need a goal. You need to be very clear about what the outcome is and you have to understand the strengths of, used to be people, but now it's basically models. And different models have different strengths, so it's like they have different personalities. And so you kind have to get to know it, develop an intuition for it so that you can use the right tools for the right purposes. And I mean, we talk about agents, but we also talk about what are the tools that agents have access to? So you still have to make decisions around that and then there's of course process, which is how you do it. And now I think with better and better models, perhaps the agents get smarter so they can deal with higher and higher levels of figuring out how to do something, but I think it's still very important for us to be able to provide the right context, provide the right high level instruction so that we get what we want.

(00:10:59):
So really, it's the same principles and I absolutely agree with you that more and more of us are going to have to double down on these skills to be able to use these tools very effectively.

Lenny Rachitsky (00:11:09):
So along those lines, I have your book right here. You have this list of a manager's job is to build a team that works well together, support members in reaching their career goals and create processes to get work done smoothly and efficiently, which is basically exactly what you just said. Interestingly, that middle bullet is the part you don't have to worry about anymore with agents. You don't have to worry about their career development and progress in [inaudible 00:11:29]

Julie Zhuo (00:11:28):
That's true. That's true, though some people do joke that if we don't treat our agents nice, what's going to happen when AGI comes? And maybe it still might benefit us to be kind.

Lenny Rachitsky (00:11:39):
I'm one of those people that says thank you to the Waymo when I leave and just thanks ChatGPT when I'm in voice mode. Just like, "Thank you. That was really helpful." So along these lines, I know there's a lot of ways to go here, but just in terms of skills that are important to a manager, which do you think are most valuable to develop in working with agents in AI systems? I think about things like clarity, communication. Just what comes to mind when you think about here's the things you want to double down on as you're learning to be manager that will also help you be really good at AI tooling and working with agents?

Julie Zhuo (00:12:16):
The first is defining the goal and defining the outcome and being really, really crystal clear on what does success look like. If you ask a company to do this, we'll know that this is challenging for humans. I think a lot of times when you talk about why is alignment so difficult at a big company, it often comes down to this question, which is different people may have different pictures of what success looks like. And even if I describe in human words, Lenny, I want to build this product and it's going to be amazing, or this podcast episode, which you asked me, want lots of people to hear it and take away things, that's very general. How do we get even more specific so that we know without question whether we've hit it or not. And this is actually a really, really difficult problem.

(00:13:06):
It's a difficult question for us because, again, we tend to think very high level. So figuring out how to boil it down so that an agent can really understand what success and failure looks like is a lot of the game. And I think this also relates to things like, well, that's why we have to write evals and that's why they're so important, because they're helping us understand what is the objective criteria. And these days I work in data and my company is all about trying to automate data analysis. And the forever question goes the whole point of data and the whole point of metrics and KPIs is we're trying to put a little bit more of an objective measure or get as crystal clear as possible about what success looks like. And I think it's really an art more than it is like a science, but that's the first thing. I think if you're really unclear about what success looks like, the prompt, you're probably not going to get the most amazing work. I think that's true for managing teams and it's very much true for managing AIs.

Lenny Rachitsky (00:14:01):
Okay, so let me actually flip this on you and talk about another trend that we're seeing, which is this kind of flattening of orgs, managers being let go. Everyone's becoming an IC again. I just had the CEO of Airtable on the podcast and his whole shtick was that CEOs have to become ICs again. He's coding more than he's ever coded again and his feeling is you have to know what's possible by being in the weeds in order to figure out what your product should be. I also just saw a stat that Google let go of so many of their middle managers of smaller teams. It's just like this flattening trend. So do we even need managers, I guess is one question in the future, and then just thoughts on how this will play out?

Julie Zhuo (00:14:42):
So I think the real promise and magic of AI that we're seeing in the workplace is that it leads us to each individual is far more empowered. So it used to be, okay, I don't have the skills to do 10 different jobs, so I need to supplement by hiring people to do these jobs. I need someone who's really good at design, I need someone who's really good at coding, I need someone who's really good at data analysis, and then I'll assemble that team. But now with AI and my companion, it's like, wait a second, AI allows me to do many of those jobs myself. Now, I'm not going to do them at what's called the PhD or the highest 1%, 10% level, but if I was at the zero or 10th percentile, it can certainly get me even today very quickly up to the 60th, 70th in terms of what the state of the art is.

(00:15:34):
And I think that that unlocks so many doors. And so the main thing that I felt so excited about, and this is something I tell my team all the time, is we need to dissolve the boundaries of these traditional roles. So in the past, again, we would have a traditional team, engineers, product manager, designer, researcher, data scientist. And I think now the teams can look more like, well, it's just two people. And they could be any of these traditional disciplines, but the key thing is they can now use AI to help themselves do a lot of the things that the other folks used to be able to do. So in some ways we can drop all of these different role distinctions and call ourselves builders. I think that's sort of the most general purpose way of thinking about what we can all be. We can all be builders. We can all be builders and I'd love for us to get to the world where that's like the title.

Lenny Rachitsky (00:16:30):
That's funny. That's the term I've been actually using more and more. I used to orient this podcast as a newsletter around product managers and then I started using just product to be a little more broad. And now I'm actually using that term builder and I love that term because it's exactly what you're saying. And this is very much a theme that comes up often in these conversations more and more, just the lines are blurring. I'm curious at your company, how does that look? What are you doing differently? What are you seeing on the ground within your company that maybe would be different from a few years ago?

Julie Zhuo (00:17:01):
So we have eliminated more roles. For example, we thought we would need a bunch of product managers. It's turned out that actually if you don't have a product manager, I know this might be going against a little bit of the ethos of where Lenny started, but I find that sometimes when you have a designer or a product manager, and let's say I'm an engineer, then when I have a problem, like I need to figure out the product definition, my default will be, well, I've got these people and that's kind of their job description, so I'm just going to delegate that to them. And I think that in doing so, again, we want to be polite, we want to respect everyone's lanes. I think that's a missed opportunity for that, if I'm the engineer, to be like, "Wait a second, I should probably focus a lot, too."I need to understand and have an opinion about what to build or what the user experience is.

(00:17:54):
And so we found that if we actually make teams smaller and we even in the past, pre-AI, just have fewer of these, it allowed everyone to be like, "Wait, we don't have product manager on the team, so communication's up to me. Figuring out how we get greatest value to users is something that is now strictly in my charter. And so that's why I'm such a big fan of we can make teams smaller and we can eliminate these lines. Sure. Again, I'm not trying to say everyone has to do everything. We still can respect the fact that you might be much better at this particular skill than me, but it's less about the role and it's more about the specific context that we're in.

(00:18:32):
And I find that whenever you have teams and you empower them to be able to take more action on their specific context rather than having these higher level of rules or policies or this is how it's supposed to be, then you get better work. You get faster work and you get happier employees because people feel like they actually can have the power to create the thing that they want.

Lenny Rachitsky (00:18:58):
That's really interesting, just that constraint of not having a PM makes the engineer realize they're not going to wait for someone else to do it. They have to figure it out. The obvious trick there is they have to be good at this. It's a very different job from engineering to be really good at articulating here's the problem we're going to solve, here's why it's important that we're solving, here's how we're going to prioritize everything we're thinking about, here's how we get alignment. Is there something you do differently when you're hiring these engineers, knowing you're going to probably not hire PM? And just that feels really hard to hire for someone that's really good at all these things.

Julie Zhuo (00:19:30):
It is true and I'm not trying to say again that everyone needs to be good at everything. I don't think that's very realistic. I do think, for example, if we were going to create a team and we're going to have a couple engineers and none of them are very good at thinking through product requirements or what the user angle is, we probably do need to supplement the team with somebody with that skill set. And that might be a designer, or that might be another engineer who's really good at that, or that might be a traditional product manager, or even sometimes a data analyst who's really good at it. So that skill is still important and the team still needs to have that skill, otherwise it's probably not going to produce the best outcome. But I like to think of it as what are the skills that are needed for this and can we now find a couple people?

(00:20:13):
But it doesn't mean we just automatically go to that script of need a PM, need a designer, need three engineers, need that. Another example for us is even thinking about front end, back end engineering. And it used to be like some people are front engineers. So if you have a project and it's got some front end, some back end, the shortcut is like I need one of these and one of these and that's how it's going to go. But if you say, look, you're an engineer, you're a builder, this has a little bit of front end, but you know what? You can probably figure that out. Use AI to help you figure it out. Get obviously someone who's a specialist to review the code or to give you some high level guidance on things, but just do it. And ever since we started to implement that as well, we see again a little bit of you have to invest a little bit in the beginning. So people are not as comfortable.

(00:21:01):
They have to learn, so initially things take longer, takes a little bit of extra time, versus if you did slot in a front-end specialist and this is a front end project. It probably would've gone a little bit shorter, but in the long run that investment really pays off because now you have a lot more people who are, again, a little more well rounded and can take on many more pieces just on their own. And then in specific scenarios this is super front and heavy. Sure, let's still bring in somebody who is more specialized in that particular skill.

Lenny Rachitsky (00:21:31):
I love that you've had the experience of working at a mega large company at Meta and now you're building your own startup that's small and in the middle of this trend of just staying very small and staying really lean and just everyone doing more things. It's so cool that you're experiencing that. So a couple of questions there, just which functions are you seeing most accelerated with all these AI tools? Is it engineering? Is it something else? And then are there tools that have been most helpful to you? Just AI tools for folks who'd be like, "I should check it out." I'm guessing Cursor, but curious if there's anything else.

Julie Zhuo (00:22:04):
Yeah, certainly engineering is one that, I mean, most of our company is engineers, so that's the one that we focused on a bunch. I certainly do see more people also prototyping things. We have two designers, but we also see engineers. We have a team that's called product science, which is this interesting blend of you can think about it as like a forward deployed person who has a lot of data analysis background and is kind of playing a customer success role and also kind of playing a product role. And you see them starting to take on building more prototypes or getting into some of the engineering. And so it's really lovely to see that blend of everyone can do a little bit of everything else and we're all encouraging each other. The other thing that recently we've also been trying to do a lot more is just obviously we say, "Hey, engineer, now you can do analysis."

(00:22:59):
And their first thing is like, "Oh, I don't really know analysis." This is where ChatGPT comes in. And it's like traditionally we would say, "Well, I have to learn that from a human. I have to ask this person and now I'm going to take a bunch of their time because I want them to explain everything to me." And in fact, I think these days ChatGPT or these other AI tools are better teachers. I find that we tend to maybe not use them quite as much just for the purposes of accelerating our education or even going through something. Sometimes what I'll do is I'll find a curriculum online. And if you take a course, it'll be like this 12 week curriculum and I'll just feed it into ChatGPT and I'll say, "Help me customize a program for me using the ways that I like to learn."

(00:23:43):
I am a person who really needs examples. I need a lot of explain like I'm five. Give me an analogy. And I know some other people on my team are like, "These examples don't make any sense." We're different types of learners and so the idea of a tool that personalizes learning for each of us really helps us, I think, accelerate and just learn these skills much faster than before. So yes, the tools are great. We can use Cursor, it helps us, it autocompletes, it writes a bunch of things, but the acceleration of learning I think is another maybe underutilized tool in all of our arsenals just because I know whenever I talk to people, we forget. We don't think that, wait, yes, we could be doing that and just sitting down and probably in 30 minutes or an hour learn so much faster than what we used to be able to do before.

Lenny Rachitsky (00:24:33):
That's such an interesting point. There's these tools that are in the just in time, helping you move faster, but you also need to learn how to do something, some foundational lessons. What's an area that your team did that? What did they work on learning?

Julie Zhuo (00:24:49):
So I'll give you an example. I was just talking to an engineer this morning and he's written a bunch of these algorithms. So one of the things our company does is we're trying to automate data analysis, so one of the things we have to do is obviously understand the best practices. If there's a type of question ...

Julie Zhuo (00:25:00):
... To do is obviously understand the best practices. If there's a type of question, "Hey, what features are really the ones that people pay for?" We need to kind of figure out what is the right analysis to do. And so the engineer was saying to me, "Julie, I feel like I really understand the how. I know the algorithms, I know we do root cause analysis, how we do that. But what I don't really understand is why or when this would be most useful. In what context in a company would this company come up?" Because he's an engineer, he hasn't done that job of being a PM or an executive that asks these types of questions. And that was like the perfect thing where yeah, traditionally you might've asked someone, but this is more general purpose. There's so much resources in the world on the internet about it. This is like the perfect type of question where if you just talk to ChatGPT, it's probably going to give you a much better answer and allow you to go deeper.

(00:25:55):
And a secondary thing we've been learning too is this idea of, almost like as a... Using ChatGPT it's for to test your learning. So explains a bunch of things. And so what I often like to do is like, "Okay, I read this, so this..." I try to explain back what I heard. "So does this mean... Is that right way to think about it, that this is kind of like this analogy?" And ChatGPT will critique me. "Yes, that is right," or "No, you didn't quite get that right. In fact..." And it always tries to say it nicely. This is a funny part. It'll be like, "That's close, and then eventually it's like, "You were completely wrong." Just in the style. But it helps so much because it's interactive and so we can really test whether we really understand the concept by trying to retell it back in our own way.

Lenny Rachitsky (00:26:40):
It's incredible just how many ways all this AI breakthrough is helping us advance and do more and learn more and become better. I know there's some downsides, but this is incredible. So many ways of getting better and faster. I want to spend a little more time on this data analysis stuff. So again, you have such an interesting trajectory from working at a big company to starting your own small company. From being head of design to now being obsessed with data and analytics. So let me spend a little time there. What do AI companies that have kind of figured out how to use AI for data analysis and data work, doing differently, what are people missing and sleeping on in terms of getting better at working with data? And let me just add this point. It feels like we're almost working through , here's all the blockers to a team moving forward. There's like waiting for the PM to write the PRD and then there's waiting for the data scientists to give you answers analysis. So this is another really cool unblock that every team member will have.

Julie Zhuo (00:27:38):
So your first question was how are a bunch of AI companies using data? So the funny thing, my funny answer to this is, I don't actually think a lot of the fast-growing companies are using data well at this point. And the main reason why is because traditionally things just didn't grow that fast. And so if you got to a hundred million users, your company has probably been around for a while, and if your company has been around for a while, you've had time to set up things like logging and you've hired a growth team at that point and you've hired a data team and they've done a bunch of work to log an instrument and then transform the data. And we've talked about what is the observability for our business. And you just usually had years to build and develop that, because of the rate of growth.

(00:28:25):
And so today we see companies that are growing insane and there's still about 10 people or two people or however many people, but they've got hundreds of millions in ARR and hundreds of millions of users. And you know what? They don't actually have all of that infrastructure, that logging, to be able to truly do data analysis. So I would say that these companies are totally getting by on just good instincts and good vibes and we see that. You don't really need data analysis to sometimes make something that works. But I think what data helps us do is in my mind it sort of is helping us reflect back what is really reality. And so of course if ARR growing, awesome, great, keep doing what you're doing. But what always happens is eventually things stop growing. Growth does not happen forever. And usually when growth stops, everyone has this question of, "What's going on? Why did it happen?".

(00:29:22):
And then you start to be able to see the power of, if you've instrumented everything very well and you have a very good observability model for your business, it's much easier to start to get into the root cause, it's easier to even predict whether growth will slow down at a certain point, it's easier to catch these trends earlier. If you don't have good observability over how your business runs and what the company's key levers are, then you will be scrambling, and at that point, that's usually when people start investing a ton in data. So I wouldn't say that a lot of these hot companies are quite there yet, but what I also think is a trend is that every time there's a new technological shift, we actually have to change the way that we think about... Analysis has to answer the questions that we have, and if technology changes or context changes, we need new methodologies of analysis.

(00:30:16):
So for example, when mobile came to the forefront, looking at sessions or sessions per day or time spent on mobile, or length of sessions became something that was important for us to understand, are people getting value in this new medium? I think that's the same with what we have today. Conversational analytics is totally different. Used to be, let's say in the Google world, I knew you were interested in shopping if you click the shopping tab, I know you're interested in maps if you click the maps tab, we can measure clicks. Today it's just all conversation, and so it's actually harder for us to tease apart what is the user intent.

(00:30:55):
If I worked on any of these LLM, I would say one of probably the biggest questions is, hey, what use cases are growing or what use cases are shrinking? And that's much harder to tell today because it's not just clicks on tabs or pages. It's like we have to probably use an LLM or a machine learning model to bucket user intent. We probably have to ask questions like, is the flow going really well in conversations? Like, if I just ask one question and I don't go back and forth, did the user get value? It's always trying to get back to, we're trying to figure out if this was a good experience, but now it's like we need to actually invent new methodologies to help us analyze that.

Lenny Rachitsky (00:31:40):
Yeah, I think the question is always like with conversation, do you want it to be a long conversation, do you want it to be a short conversation? What's the right answer, what's better?

Julie Zhuo (00:31:47):
Yes.

Lenny Rachitsky (00:31:48):
I had a ChatGPT on the podcast, Nick Turley, and turns out one of the ways they found the most common use cases early on was watching TikTok comments and things going viral on TikTok after they launched. How about that?

Julie Zhuo (00:32:01):
Yep, yep

Lenny Rachitsky (00:32:02):
Okay, so I want to come back to this really interesting, unusual path that you took from being a head of design at Facebook, you're an inspiration to so many designers, now you spend your time on a data startup obsessed with data. I don't know, classically designers aren't the biggest fans of experiments and data and making decisions based on data. When you look at designers and you hear designers kind of push back on like, "No, we don't want to be super data driven, we know better than... We have a sense of what's beautiful and great and intuition," all these things, what do you think designers are missing when they feel that and say that when they're afraid of writing experiments and data and kind of want to push that out?

Julie Zhuo (00:32:46):
There's one phrase that my co-founder and I would always discuss with amongst ourselves very early on in which we shared with a lot of the companies that we work with, which is, what you really want is you want to diagnose with data and treat with design. So data is not a tool that's going to tell you what you should build or what the solution is or how we're going to cure the fact that you don't have really great retention. It's just not. But it can tell you if you have a problem and where that problem or opportunity might be. But you still need to go back and undergo a very creative process to figure out what's the best way to solve that. So that's the first thing I would say, is this framework of, data helps you figure out what's actually happening, what do people like, what are they engaging with, what what not.

(00:33:32):
It just gives you a story that better reflects reality. Because again, we all have stories. We're like, "Oh, my company's amazing, people love us," blah, blah. That's the story I want to believe, but reality may be a different picture. And so what data is trying to do is capture reality. And by the way, I don't think of data just as it's an AB test and it's quantitative things we can measure. To me data is also, well, what did people put onto TikTok and which things went viral, and what are they saying in the Twitter verse or X verse I guess is what it's called now.

(00:34:07):
And if you do a customer interview, that's still all data, it's just that that is a little harder to distill and quantify. Although now with AI, we have better tools for synthesizing. So that's all data in my mind and it's just all trying to help us understand what is really happening, what is the phenomenon that's happening in reality and how do we understand it? You still have to go and invent and create and dream, and there's no formula and there's no science that will tell you exactly how you're going to make a hit. You can experiment, which allows you to try more things maybe and more rigorously understand what that does in the short term. It's all very contextualized. A-B tests don't tell you what will happen in the very long run, and again, it's all still data, you still have to synthesize and figure out what to do.

(00:34:57):
So that's the thing, I'll say. Diagnose with data and treat with design. The second thing I will usually tell designers about, is I find that sometimes, and maybe it's the, let's call it the false precision of numbers that we kind of fall into, right? Because it's like, okay, we got these numbers and the numbers go up. It's like no, the fact that you still have to choose which things you look at, is an art, not a science. And your interpretation of if the number went up 5%, is that good, is that not good, is also an interpretation and is an art, not a science. It's just that sometimes I think we can give ourselves this feeling, and I get it, sometimes there's this instinct to want to control things and we want everything to be buttoned up, and we want to know that if we did ABC, everything will be great, our career's going to be awesome, our product's going to rocket ship.

(00:35:49):
And I think designers are rightly often pushing back and saying, "No, the reality is this stuff is ambiguous and there's uncertainty and we can never know for sure." And I think all that is quite true. So the other thing I would say that I really support is you just actually can't make a really great product by thinking you can A-B test your way into it. So I fundamentally believe that, but I don't think we should throw the baby out with the bathwater. I think there's actually... You know? It's not either or, it's not like data or design.

(00:36:18):
It's like these are just tools for us to use, and I would say every amazing designer that I've ever met is absolutely obsessed with trying to get a better understanding of reality. They want to know what users really think, they want to know what they're really doing. If they could read every user's minds, that's the thing we would all want as a designer is like, if I could just know what everyone is thinking, feeling every time they used it, my life would be a lot easier, because then I would be able to build better and better things. And so that's what it's trying to help us do. It isn't perfect, no metric is going to tell you whatever we hope that it can in terms of the true certainty and precision, but it doesn't mean we can't use it to better our product development.

Lenny Rachitsky (00:37:03):
I was going to say exactly what you just said, which is every great designer that I've worked with was obsessed with data in the most leaning into the data, versus designers that are just like, "Nah, I think I'm good, I have a sense of what's right, and why would we let that tell us what to do?" And to your point, it's not going to tell you what to do, it'll tell you where opportunities arise. Let me take us back to the management chat and maybe just let me ask something broad. What do you feel is the biggest change in the role and day-to-day work and life of a manager these days with the rise of AI?

Julie Zhuo (00:37:34):
I think that managing change. It's always been manager's job to manage change, and there's always the chaos of what's going on. I just think the rate of change is accelerating, and we've seen that over the last couple of decades. And so I find that there's just a great deal more uncertainty that people have about things, like where is AI going to be in two years from now? I don't know. Who really knows? And so are we going to have AGI in five years? That kind of changes a lot about the landscape. Not to mention, I think there's quite a lot of fear that many organizations are feeling. It's like if my career has always been in design and now these tools are getting better and better at what I'm doing, then holy shit, what happens to my career and my future? And do I need to pivot? Do I need to learn different things?

(00:38:25):
And so it's this change, it's this feeling of uncertainty. And I think a lot of times managers have to deal with that in addition to what you were saying before, which is they also have to learn these new skills, which is managing AI and managing these more powerful tools in their arsenal of trying to get things done. So that is very different, I think, than maybe 10, 20, 30 years ago. And so I think that the skills that become more important are obviously communication, feedback, compassion, but just being able to work with humans and to have them understand that yes, we are in a state of change. I think every leader has to do this now, every startup founder that I know, every CEO, is how do you land this message that things are changing and we need to be very open to change?

(00:39:16):
If we go and stick to our old ways, we're probably going to get left behind, our product's going to get left behind, even our way of doing things is going to be left behind. So we need to change. We need to change our product and we need to change the way that we work, as we all talked about in terms of smaller teams, more nimble, blah, blah, blah. But at the same time it's like, how do we do that in a way that doesn't just freak everyone out? And it's like, "Ah, it's chaos. Everything's changing.".

(00:39:44):
So I think about this metaphor a lot, of the willow tree, which is the willow tree is a very sturdy tree. It can survive a lot of storms, disasters, et cetera, but it's also very flexible. The branches are very, very flexible, and that's in some ways what allows it to be very sturdy. So I think today, management is really about this idea of be sturdy while being flexible, and that is a very hard thing to pull off, but I think that's at least when I even go into... I'm like, "Be like the willow tree, Julie. Just imagine the willow tree and try and channel that as the kind of feeling of what it is that we're trying to do together."

Lenny Rachitsky (00:40:23):
This reminds me of a couple things from other guests. I had Marc Benioff on the podcast and I asked him, "Just how do you deal with all this change? It's like agents now, it was, I don't know, there's AGI coming as you said, just like, "How do you survive through this?" And his advice is just, he's like, "I'm always just like, 'Good. This is great. This is what we want. This is exciting. We have so much opportunity, it's just not boring. We can always reinvent.'" And he's always embracing with "This is good." And just I'll never forget the way he responded to that.

Julie Zhuo (00:40:55):
I think if you don't think it's good, it's kind of a painful way to live. It'll be very, very difficult over these next. So I do think that all things be equal, lean into it. If you can wake up every day and see it as opportunity and excitement rather than fear, again, they're all flip sides of the same coin, but I think if we can lean more into what could it be, while recognizing that the other side does exist and it's still there. And I think if managers who try to pretend like it isn't there, it's all good, no one's upset, et cetera, there's something also missing about just addressing and being able to be like, yeah, it's hard. Change is hard. We're probably going to get upset. We're going to have some chaos. This is going to happen, but we will work through it because we're going to be flexible and we're going to be able to put our eyes on the big picture of what is possible, which is exciting.

Lenny Rachitsky (00:41:45):
There's another quote that and came up as you were talking. I forget who it was exactly, maybe Kevin Wheal, maybe Mike Krieger. They said that this is the most normal things will be, ever. Like, it will only get weirder. And I think giving people that sense of like, okay, just enjoy this normal, because this is going to be only weirder, is we'll at least give people an expectation, real expectations where things might be going.

Julie Zhuo (00:42:11):
Yes, yes.

Lenny Rachitsky (00:42:11):
What a time to be alive.

Julie Zhuo (00:42:12):
What a time.

Lenny Rachitsky (00:42:14):
Okay, let me zoom out even further and chat about... I want to ask you just outside of AI, management in many ways is unchanged. It's still a lot of the same work, managing people, helping them be successful, producing great work. What are just some of the, I'd say most timeless, most important lessons that you think managers, especially new managers still don't totally understand, need to hear more? What are just some that come to mind? And then we'll see where this goes.

Julie Zhuo (00:42:43):
The first thing that comes to mind is the importance of managing yourself and understanding yourself. This was chapter five of my book. It's called Managing Yourself. In fact, when I wrote it, I kind of wanted it to be chapter one, and then my publisher was like, "Well, maybe you should get into some of the tactical..." People don't necessarily think managing other people or manage a team starts with them, but I really do fundamentally believe this, because I think all of us, of course, like any human being, we have things that we're strong at, we have things that we're weak at. And I am a very big believer that every strength is its own weakness, and every weakness is a strength.

(00:43:18):
There's no such thing as you're going to somehow get every dimension to be 100%. In fact, I think one of the most interesting concepts or frameworks for myself, and also even, this is also kind of like a data framework concept, is this concept of dimensionality. So what dimensionality means is you're a human being, but we can kind of look at you in infinite dimensions. There is, for example, how good is Lenny at throwing an ax? That's one dimension

Lenny Rachitsky (00:43:49):
Pretty good.

Julie Zhuo (00:43:51):
How good is Lenny at being a podcast moderator? Fantastic.

Lenny Rachitsky (00:43:56):
So-so. Okay, thank you.

Julie Zhuo (00:43:58):
How good is Lenny at doing a zero to one type of project in the AI space? Right? So again, just can think about these as infinite dimensions. And the reality is each of our profiles is very unique, it's like a fingerprint. So for you it's like these are all these areas that you're really great at, much better, like in the top 1%. And then there's some areas where in the top 10%, then there's some areas where you're kind of average, and then there's some dimensions in which you're worse than average compared to other people. And that's just true for all of us. And what I like about that is therefore if you take that as the model, you realize that none of these dimensions are you entirely. So I can make a comment like "Lenny, your ax throwing really could use some improvement."

(00:44:48):
And ideally you're not like, "Julie is saying I'm a bad person, my identity is at risk," right? Because it's just one dimension of who you are. But what happens sometimes is that we can get very attached to certain dimensions because we start to think that that's who we are. And I think managers can do that, and clearly individuals on their teams. And when that happens, it starts to get very difficult to have, I think more objective conversations about, okay, what can you get better at? What can get worse at? And so I say all this because I think this framework for me at least, and many people that I've talked to, has helped them realize that somebody can give you feedback or you can be maybe not great at certain dimensions, you can have room to improve, and that's not who you are because you are all of these infinite dimensions in one, and none of them is representative of your true worth as an individual.

(00:45:42):
I'm a big believer that we are all beautiful and worthy, and sure we have all of these skills and we want to improve those skills, but it does not speak to whether we are worthy or not by saying whether we are strong or weak in these skills. And so I think if you can take that and really internalize that, then you can look at yourself a little bit more objectively as a manager, and you can realize that there are areas where you're going to be really strong, there are areas where you have biases, and often they are one and the same. So I'll give an example. People have often told me, I would get this in my performance reviews from managers in the past, like, "Hey Julie, you're really thoughtful. So when you think about something, you have a way to think about it, you've clearly thought about it in depth and you've got these frameworks and all this. That's a great thing.". And then on the flip side, I'll get feedback like, "Well, Julie, you don't really say a lot in a dynamic discussion. You're kind of quiet and you don't really think that quickly on your feet." And what you realize is these are kind of, again two... Because I don't do that and I'm not just off the cuff, that's what allows me to oftentimes be very, very thoughtful, or at least, okay, when I was younger, it's very clear that that particular weakness also very much is speaking to a particular strength, which is I am the kind of person that doesn't always have a snap judgment. I have to really think about it and internalize it and sometimes get to how I feel, and then I can share it and present it in the world.

(00:47:18):
And so just knowing that about me is supremely helpful. Now doesn't mean of course that I can never get better at this thing, but what I often think about is mastery is where we realize that both of these we can get better at, and what we want to do is just figure out in the context, what makes sense to be. So I got this feedback and I'm like, "Cool, one of the things I need to work on, is figuring out how to be more open in person, how to speak a little bit more clearly in person, maybe say things like, 'I don't know exactly how I feel about it yet, but this is what I'm thinking right now,'" if there's still clear tactics that will allow me to be a more effective team member and to do a better job in the context of what I'm trying to do with my team.

(00:48:04):
So I've tried to build those skills, but the meta skill is now being able to step back and say, okay, in certain context it is really important that we move fast and we are decisive and we just do something. And even if it's not perfect, we just kind of have to do it. And if I struggle with that, I should realize that that's an area to improve upon. But there are other contexts in which the right thing to do is actually to take a step back and be very thoughtful and to not rush into decisions.

(00:48:31):
And that's so what I want to get to is not like let's reject this strength or this weakness, but just know that that's where we come from, that naturally, we might be wired in a particular way. Our growth often looks like getting better at doing the opposite, but not rejecting again the thing that we're good at, but rather over time getting to this balance where we can read the context and the situation and know, "Should I lean a little more thoughtful or is this a time where I need to try and be a little more decisive and just share what's on my mind right now?"

Lenny Rachitsky (00:49:04):
I love this advice that things that we are incredible at and have a downside, and oftentimes the feedback we're getting is something we're not great at, there's a good version of that that people appreciate. And I was going to ask you, and I think you answered most of this, but just when you got this feedback of, "Hey Julie, you're not speaking enough in these meetings, you're not contributing quickly enough," it sounds like, so one option is just like, "Okay, cool, that's me, that's how I am, and I'm just going to solve the problem this other way and then just not going to change anything." What I heard you say is, find opportunities where you want to actually change that behavior, even though it doesn't come naturally in specific situations where things are moving fast. I guess just how far do you recommend people push themselves in things they're not great at, versus leaning further into their strength, let's say?

Julie Zhuo (00:49:54):
Oo, I think that's a really great question. So the way I think about it is it's very dependent on what is your goal. So for example, let's say that you are...

Julie Zhuo (00:50:00):
... on what is your goal? So for example, let's say that you are... Let's even take, for example, ICs versus managers. I think often about the pathway of an IC, an individual contributor, as wanting to deepen a craft. You love this thing and you just want to get better and better and better at this very specific skill or this craft, right? So think about in our dimension, infinite... It's like you pick a couple dimensions, "I just want these to be... I want to be the top 0.01%," and that's kind of the pathway of extending it as an IC. Now, if that's your high level goal and you're like, "I want to be able..." Let's say your high level goal is, "I want to be able to do this 10 hours a day because I love it and I want to be able to support myself doing it, meaning I get paid and I have a great job, and I want to have a bunch of impact in the world by doing this thing."

(00:50:53):
So again, you still have goals. Then you have to see, okay, "Does my strategy of just deepening these things, is there a pathway to reach my goals according to that?"

(00:51:03):
And if there is, awesome. Then if someone's like, "Hey, do you want to be a manager?"

(00:51:06):
You're like, "Nope, don't need to because these are my goals and this pathway actually allows me to do that."

(00:51:13):
But if somehow you get to a point where the skill you really want to perfect is not something that may be commercially viable in the world, that's going to somehow allow you to buy the big mansion that you want to buy to support your family, then I think you have to ask yourself, "Okay, so if I just do this, it's not going to cut it. I might actually need to learn some of these other skills in order to be able to fulfill the job that is going to be valuable enough that people are going to pay me a bunch of money at this certain level so that I can afford my mansion."

(00:51:43):
So I just think it has to go back to, what are your goals? And there are cases in which yes, it'll support your goal to do this and to deepen your craft. And there are cases in which it won't. And I think it's important, it's a very individual question for each person. But what I often think suffering is, is when these things are not aligned. So what you want is the giant mansion and all of that, but you're like, "But I also just want to spend on my time perfecting my egg omelet."

(00:52:12):
And then, you're just in this tension place, and it's very hard to feel satisfied and fulfilled because you're a little bit like, "Oh, why doesn't the world value my deep egg omelet skills?"

(00:52:26):
You can [inaudible 00:52:27] egg omelet, you should maybe not do this thing. Or if you want this thing, you may actually need to be better at just egg omelets. Perhaps you need to expand your repertoire of cuisines, and go and build a Michelin star restaurant or something.

Lenny Rachitsky (00:52:39):
This is really good advice. It's not just definitely always work on your weaknesses or don't worry about them, it's if you need to do this thing to achieve this goal that you have, make sure you understand what your goal is. And then is this thing a thing you need to work on? For example, [inaudible 00:52:52] become a VP, you probably need to be really good in big important meetings, and being on the spot, and just not waiting until everything's over and then sharing an email of all your thoughts.

Julie Zhuo (00:53:01):
That's right.

Lenny Rachitsky (00:53:02):
Yeah. For me, I actually went through a period where I was like, "I do not want to get promoted. I'm so happy in this very specific role, just leave me alone." And that path is very different from the skills I need to build to be a manager. And then things changed and then, okay, now these are the things I need to work on.

Julie Zhuo (00:53:17):
Yeah. I love that you knew that about yourself, because I think it's so easy for a young person to go into their career and everyone is telling them, maybe their whole family has been telling them, "You need to level up, you need to get paid more. You need to get that manager title. You need to get a VP."

(00:53:33):
And at a certain point, I think sometimes people opt into this without knowing what they're actually signing up for. What are the trade-offs? And is that really what you want to do? Does that really align with your passions? And of course, sometimes we have to... Again, it's a compromise for us, but we get to design. We get to design what are goals and what's the right pathway. And I go back to, usually when people are unhappy, it's because these things are a little bit out of sync. They want this big thing, but they're not actually excited about what it takes to do that thing, and therefore it's just going to be a mismatch.

Lenny Rachitsky (00:54:09):
And along those lines it sounds like, oh, sure, I can design my life and design my role. But what I find is if you at least first of all know what you'd love and ideally do, and then at least mention that to your manager, it often is a lot more possible than you think.

Julie Zhuo (00:54:26):
A hundred percent. I think it's so important to be... We often also have this mental model like, "Oh, our managers are our judge, and they're going to judge me on whether or not I did well, I should get a promotion, I should be fired."

(00:54:39):
So there's this sometimes fear that people have, but I think in the very best relationships, the manager is like a guide. It's like, look, the manager has a job, and if you understand your manager's job, which is how to get better outcomes from the team, and also you understand what exactly would your manager consider success for the team, it also makes it easier for you to then be like, "Oh, well if I do this project, then that clearly seems like it's a very direct path to creating value for the team. And that also is a kind of project that suits my skills. It's something I'm excited about." You should suggest that to your manager.

(00:55:16):
But the other is true, right? So you would know that if you actually asked your manager, "What is your job and what do you consider success to be, and what is your greatest hopes and dreams?"

(00:55:25):
And then you might be able to help your own career and yourself because you would know that context. And conversely, if you say, "Hey, manager, these are my hopes and dreams. This is what I think I'm good at. I really want to get better at this skill. I really want to get that VP promotion, but I don't know what it entails. Can you tell me, what does it take?"

(00:55:45):
That's a really wonderful conversation as well because then you'll get all of that context, and then you can actually decide whether you want to do it or not. And if you want to, then ask your manager for help, "Okay, if you see opportunities that are going to help me become a better presenter or increase my communication, please tell me." Even better, "If you have feedback for me about communication, I want to hear it, because that's what's going to help me grow in this particular skill."

(00:56:11):
And so, it becomes this collaborative relationship much more so than this almost adversarial, like I'm trying to get you to give me a promotion, and you're trying to get me to work harder. That is not a very good vibe.

Lenny Rachitsky (00:56:28):
It reminds me of a guest post by Ethan Evans that I'll link to that has a really good framework for how to actually do exactly what you're talking about called, The Magic Loop, where it's kind of a framework for figuring out what to work on and how to help your manager see you're capable of stuff and earn that trust.

(00:56:42):
This episode is brought to you by PostHog, the product platform your engineers actually want to use. PostHog has all the tools that founders, developers and product teams need, like product analytics, web analytics, session replays, heat maps, experimentation, surveys, LLM observability, air tracking, and more. Everything PostHog offers comes with a generous free tier that resets every month. More than 90% of customers use PostHog for free. You are going to love working with a team this transparent and technical. You'll see engineers landing pull requests for your issues and their support team provides code level assistance when things get tricky. PostHog lets you have all your data in one place.

(00:57:21):
Beyond analytics events, their data warehouse enables you to sync data from your Postgres database, Stripe, HubSpot, S3, and many more sources. Finally, their new AI product analyst, Max AI helps you get further faster. Get help building complex queries and setting up your account with an expert who's always standing by. Sign up today for free at PostHog.com/Lenny and make sure to tell them Lenny sent you. That's PostHog.com/Lenny.

(00:57:49):
So along the lines of timeless manager, especially new manager advice, you've shared a bunch. Is there anything else that you think is really important, really interesting, valuable?

Julie Zhuo (00:57:59):
Feedback is one of the other topics that I am super, duper passionate about. And my general impression for both myself, everyone I've worked with, is that we don't value feedback enough or we don't think about it enough. Again, companies have these performance cycles, and so we're all like, yes, every six months we're going to go and do these reviews. That's when I'll get feedback. But feedback really, in my mind, ideally, should be a daily practice. Because the thing that matters for us in the long run as a team is how quickly are we getting better? So a team that just gets 1% better every week compared to a team that gets 1% better a month, even if they start off at a much lower baseline, is going to outperform in a very short amount of time the team that doesn't get better.

(00:58:50):
And so, what is the best tool for us to get better? It is feedback. And what I think about in feedback, it's very similar to what we said earlier about data metrics. It's essentially trying to put your hypotheses and test them against reality. So as an example, maybe I have this perception right now that I am a positive and engaging speaker. So, I have this sense that I'm smiling and I'm very engaging, and I'm telling great stories, but is that really true? I don't know. The reality is that I'm often biased, and we know these psychological effects where sometimes the Dunning-Kruger effect, people think they're way more expert at something than they actually are. You ask people, "Hey, are you a better than average driver?"

(00:59:35):
And it's like 70 or 80% of people, "Yes, I'm better than average."

(00:59:38):
How could that possibly be? We have biases. And imposter syndrome is a bias on the other side, it's like me feeling, "Oh, I suck. I don't actually belong here." Whereas, that also is a bias. It may not actually be true. In fact, I might very well be here and other people value my contribution.

(00:59:56):
So we are just wildly out of sync a lot of times in our perceptions of ourselves, our strengths, our weaknesses, what's going on. And the way that we're going to understand and truly get better is we need other people to reflect back what is actually their truth. And the way I think about it is like, I'm going to ask you for feedback after this podcast episode and you're going to tell me something. And what you're going to do is you're going to give me a gift. Because it'll be a gift of reflecting something back of what you see that I can't see. Just like if I have a leaf in the back of my head, I can't see that. And so if you're telling me, "Hey, Julie, you have a leaf."

(01:00:33):
"Oh, wow, thank you." Okay, maybe I can get rid of the leaf or whatnot. But that is what feedback is. It is essentially reflection back. It helps us calibrate to reality, and it allows me to get this information about whether or not I'm moving in the direction of my goals.

Lenny Rachitsky (01:00:50):
I love that. I completely agree. The challenge for most people, as you know, is giving feedback that people receive and don't feel defensive about, and then receiving feedback and not being like, "Oh, no, they don't know. They don't know anything. How dare they say this about me?"

(01:01:06):
Could you give us maybe a tip or two for delivering feedback well and for receiving feedback well? And maybe even just seeking, how do you get more feedback? This all makes a lot of sense. Most of the time people don't get any feedback.

Julie Zhuo (01:01:18):
The best way... The first tip on getting feedback or delivering hard feedback is first go and actually establish that our relationship is one in which we value each other's contribution, we want to help each other grow, and therefore we're going to be the kind of people that want to give feedback to each other every week. So when you first start working with someone, don't wait until something bad has happened [inaudible 01:01:42] given feedback, because that's already a pressurized situation. Start by saying, "Hey, really excited to work with you. I feel like our best collaboration is I want you to help me get better. I think I'm good at this stuff. I'm not so good at this stuff. What about you? Okay, you think you're good at this stuff? How about we just work together and we just help each other get better at these things? And the way we're going to do that is, all feedback is open. I want you to tell me everything. Ideally, you're going to then say, 'Yeah, I want you to tell me everything.'" And we've already established that.

Lenny Rachitsky (01:02:10):
And this is colleagues or manager or all colleagues?

Julie Zhuo (01:02:13):
It's like everyone. It's like people you're dating, it's like your children. It can be with everyone, just establishing what kind of relationship do we want to have? I think most people want to opt into a relationship where you can be close, you can be tight with one another. You can say things to one another and not have to hide behind... I think most people will opt into it, and if you opt into it, everything gets easier down the road. So the first thing is get everyone to opt in that this is the kind of relationship that we want to have.

Lenny Rachitsky (01:02:41):
One trickle throughout that I've heard that worked really well along these same lines is asking people, "Do you prefer feedback in the moment or do you prefer it kind of every month or every week or something like that?"

(01:02:53):
And everyone's like, "No, no in the moment and just tell me as soon as something happens."

(01:02:57):
And then that gives you that freedom to just, " Okay, yeah, let me give you feedback here."

Julie Zhuo (01:03:09):
So if you get people to opt in, "Yes, I want us to have a great relationship. I want us to help each other get better. I want feedback." That's 60% of the hard part of delivering difficult feedback later on.

(01:03:13):
Then the second tactic I will say is that when you actually give the feedback, it helps a lot. First, you have to check, "Am I actually giving this feedback because it's in the spirit of trying to help one another?" And if the answer is yes, then we've moved from 60% to 80%, it's going to go well.

(01:03:37):
But what can often happen is something happens. You do something, it triggers me, because I don't know, I had a bad experience about that type of thing before. And so, I'm kind of feeling mad and I want to be right. If my real rationale for why I want to give you feedback is I want to validate myself, I want to be right, I want to tell you you're wrong, I want to punish you, it's not going to go well. It's just already there. There's no way you can deliver it, unless you're a tremendous actor. It's just not going to go well. So you have to first check your intention.

(01:04:16):
But if you've done that, you're like, "No, no, no. I thought about it. I'm calm now. I'm not seeing red. I really think that Lenny is just not aware that when he says this, it makes me and other people feel left out," or whatever it is, right? Then I need to be able to give it to you.

(01:04:33):
And so usually then if you're like, "Okay, now I might be nervous because I don't want to offend you. I really value our relationship. How am I going to tell you. I don't want you to get defensive?"

(01:04:44):
Then the third tactic is, just say that out loud. If I sit down with you and I say, "Lenny, I'm so nervous right now. I want to give you some feedback and I'm really worried that it's going to impact our relationship, and I so value our relationship and I don't want that to happen. But I also feel like it's just going to help you to hear it if you can."

(01:05:06):
That does so much of the work of... It's humanizing. You're going to realize that I'm going out on the limb, I'm being really vulnerable, and likely you're going to hear that so much more than if I just find a way to drop it, just lobby it over because it's so difficult. Just actually lean into the fact that it is difficult and expose that because that builds a lot of human connection.

Lenny Rachitsky (01:05:33):
This is amazing advice. Very tactical. Okay, is there anything else? So we've talked about a bunch of timeless pieces of manager wisdom, things that people need to hear, especially as new managers. Is there anything else that you think is really important that you think people are just not fully grokking for being great managers?

Julie Zhuo (01:05:53):
I think the idea of win-win, I think about that all the time in my mind. And I go back to it, because I think that often we have the story in our heads that sometimes things are adversarial. As a manager, I'm trying to get people to be more productive, so I'm trying to get them to do a thing that maybe they don't want to do. I'm going to try and get them to work harder or I'm going to somehow put more pressure on them. If you start thinking like that, that's not a win-win way to be thinking, right? That's like you saying, "My getting better outcomes has to come at the expense of somebody else losing something."

(01:06:33):
And I think if you start thinking like that, it's very difficult to come up with a strategy or to truly be successful. But if you say, "Look, actually, my job is to figure out how to create win-wins." So I actually don't want somebody over the long run to feel like what I've done is just create a ton of pressure for them and now they're super burnt out, real quick, because that's not good for our team, that's not good for me, that's not good for our long-term relationship. How do we find the solution that can be a win-win? And I think if you think like that, a lot of things get easier. So for example, with new managers, I think this is true for me, too, the first time I had to tell someone that they shouldn't be a part of this team was extremely fraught for me. And the main reason was because I'm putting myself in their shoes, and I'm imagining that this is truly horrible, and I've just done a huge disservice to this person, and that's the most awful thing.

(01:07:32):
But there's another way to look at it, which is, hey, if there's persons on the team, they probably want to be successful. They want to do great work, they want to be valued, they want to grow their career. If this is not the place for them, because it doesn't align with their true interests and the things that are going to help them be successful is just not the thing that they either want to do or can do at this point, it doesn't do that person any good for me to somehow try to continue to make it. It's actually going to be miserable. I'm going back to prolonging that misery state.

(01:08:06):
And so, sometimes a win-win thing is to just say, "Look, it's not working, and I respect and value you so much that I know you want to do something that you can be proud of and you can grow in, and that's going to be really valued. And right here, what we got, this isn't it."

(01:08:22):
That's like a win-win way of looking at the situation, not a like, "Oh, my firing them is just definitely going to be a horrible..."

(01:08:31):
I'm not trying to say it's not going to be hard, obviously it's hard, but it's in the mentality and the mental model I think makes all the difference. Because it's going to be different in the way that I convey it to them. It's going to be different and why this actually in the grander scheme of things may be great, and it's going to reduce this adversarial feeling where they're now going to see me as an enemy or somebody with all this power who's making choices that impact them and they feel powerless. It has to be a collaboration. And I think if it's not win-win... And I could be wrong. I would say I don't think it's right. The person could actually say, "No, you're wrong." And that would actually be great information, because then maybe we can go back and we can find a way to make it win-win.

Lenny Rachitsky (01:09:12):
Yeah, I was just going to say, they have to believe this. You can't just make it sound like this, "Here's the win you're getting let go. It's a huge win for you." But in reality, the way you phrased it, it is actually almost always true, "This is just not a place that you'll be happy and succeed at, and it's better you go do something else."

Julie Zhuo (01:09:27):
Yeah.

Lenny Rachitsky (01:09:28):
Okay. I'm going to keep fishing in this pool to see what else we got, but when we run out, let me know. Is there anything else that you think people should know, should hear, especially new managers that they're still not fully getting?

Julie Zhuo (01:09:41):
I think being aware of your own energy and conviction is really, really important. So a lot of these themes, as you can see, go back to, you have to first understand this about yourself and have the right mindset, and when you do, it becomes much easier to be able to be impactful with other people. So this is another one. I think it's very difficult for managers to be able... We talked a lot about the three pillars of what are the major tools of a manager. The first is people. And so, we talked a lot about the importance of dimensionality and feedback and helping reflect and grow people.

(01:10:21):
I think the second one is around purpose. Purpose is like, "What are we here to do? What's our North Star?"

(01:10:28):
And I think it's very hard to actually convey that if you don't have conviction yourself. And so watching your conviction is really important, particularly since a lot of people who are managers, you often start out not as the founder of the CEO of the company, but you might be a middle manager. So in some ways, you didn't create the vision, but you are in some ways expected to execute it or take a piece of it and do it. And I find that sometimes what new managers don't pay attention to enough is what is their true belief. They feel like they might have to be a soldier, so they just get orders and they have to execute it. But it really makes a difference if they themselves have gone through the work of thinking through, "Wait, why are we doing this? Do I believe this strategy? Does it make sense or not?"

(01:11:18):
And if it doesn't make sense, to go and actually have the conversation with their manager or whoever else, just so they can get to alignment on, "I really believe in what I'm doing."

(01:11:29):
Because if you don't really believe in what you're doing or you're just parroting the thing that got passed through the organization, it's very hard for you to then be able to help other people see what that magic is or to be actually really effective as a person who can hold that vision and that purpose. So I just think you have to really check in with yourself on like, "Wait, I know we're told to do this and this is what we have to do, but how do we really feel about it?"

(01:11:56):
Because if you don't feel good about it, then it's not going to be very likely that the project's going to succeed. I can tell you right now, every single manager I've ever managed where they're like, "I don't really think this is a good idea," there's no case where I can think of where the project somehow turned out to be wildly successful.

Lenny Rachitsky (01:12:13):
This is such a classic challenge of managers, is getting things done that you don't really agree with. And I can't help but ask you for advice on someone that isn't in that place of just, "Okay, we have this feature our CEO's prioritizing. This is not a good idea, but I need to have a brave face and not make it sound like I'm just being told what to do and I'm just reporting orders. I don't believe in this." You don't want to do that. You become a terrible unsuccessful manager and people lose trust in you. What's your advice to folks that are in that place of just how to find that balance?

Julie Zhuo (01:12:44):
So I think, first, if you feel that way, you got to actually find a way to get it out and engage in dialogue. So if you're like, "My manager told me to do this, I think it's a terrible idea," you've got to talk to your manager about it or you've got to talk to the CEO or whoever and feel... Because once you engage in a dialogue, what will often happen is you'll learn more, you'll have new information, you'll have new assumptions, and maybe you'll have influenced a project in some manner. But often, the more you can learn about, "Okay, why did some other smart people feel like we should do this? And what parts of it do I believe and what parts am I more skeptical about?"

(01:13:20):
You can probably decompose it from a blanket it's good or bad to like, "Okay, this is a hypothesis, this is a hypothesis, this is a hypothesis. I might kind of believe this one. The reason I don't like the proposal, I don't believe this particular hypothesis, but I believe these other ones."

(01:13:36):
And so, when you can start to get one level deeper into breaking it down into a set of assumptions, that makes it much easier, because then likely find something that you do kind of resonate with. And you might be able to then steer things like, "Okay, if that hypothesis doesn't... I believe in disagree and commit, but now we can be very specific. We can isolate the thing that..."

(01:13:59):
And what we can also often do is like, "Okay, the reason I didn't like this proposal is because I believe that this assumption is wrong."

(01:14:07):
I'm going to come up with a really stupid example. But your suggestion is, "I know we have a great idea. We're going to go and put a lemonade stand on every block. And my core assumption is people do not like lemonade. That's not the hot beverage right now. And so therefore, I think this is a stupid plan."

(01:14:25):
But if I talk to you about it and you're like, "No, no, this is the core assumption we disagree on."

(01:14:29):
Likely what starts to unfold is like, "Well, can we get some data? Can we get some information? Is there a quicker way to validate whether people like lemonade? Perhaps we should just test it in one market before we go and open up the lemonade stands across the entire 50 states."

(01:14:45):
And so what happens is we can likely get to the actual specific area and come up with something. And then, if I have to now share with my team, We're going to try this hypothesis. I'm not sure how I feel about it, but I actually do think... I don't know for sure and our CEO seems to think this is... But we're just going to test it."

Julie Zhuo (01:15:00):
For sure, and our CEO seems to think this is... But we're just going to test it, and we're going to do the test in a way where... That's what we want to find out, is do 18 to 25-year-olds love lemonade if we put them on these neighborhood college campuses? It becomes very specific and everyone's like, "Well, yeah, I don't know for sure, but I'm happy to go in, and test that, and commit to it."

Lenny Rachitsky (01:15:24):
This is such a good advice, and there's also, you could layer on, "Here's the things I do agree with and believe. Here's the ways that I see this as totally right. Here's the piece that I'm not so sure about, but that's why we're going to run this test, and here's why it's the smallest version of this test and why it's a great idea just to figure it out." We'll show them. You probably don't want to say that. As you give this answer, it's so interesting, I almost want to do a whole new episode with you later of just common conundrums managers have, challenges that every manager runs into that are really difficult to figure out on the spot. We could save that for the future. Okay, I'm going to take us to a couple of recurring themes on this podcast, occasional recurring that every episode corners that we take guests to.

(01:16:07):
The first is I want to take us to AI corner. What I like to do in AI corner is ask, what's a way that you've figured out to use AI in your work or your life that's just really interesting, really useful?

Julie Zhuo (01:16:19):
Well, I already shared a lot about education and learning, but I'll share maybe a more fun story. It's my kid's birthdays. One of them just passed. My middle son's birthday is in two weeks and my daughter's birthday is in a month.

Lenny Rachitsky (01:16:32):
By the way, the birthday just passed. The kid didn't pass.

Julie Zhuo (01:16:34):
Okay. Yes, the birthday passed.

Lenny Rachitsky (01:16:35):
[inaudible 01:16:35].

Julie Zhuo (01:16:35):
That's right, that's right. The birthday passed, my kid's birthday. One of my goals this year was to try and build them something, so give them a present that has me going back to being the IC and making something for them. AI makes this really fun, and so just from my youngest son who was six years old, this is an idea that I stole from Eric Antonow, if you know Eric. Have you had him on your podcast?

Lenny Rachitsky (01:16:59):
I haven't, I am trying to. He actually sent me the... What is it? The-

Julie Zhuo (01:16:59):
Yes, yes.

Lenny Rachitsky (01:17:06):
What is it called? The metha-

Julie Zhuo (01:17:06):
Methaphone?

Lenny Rachitsky (01:17:06):
Methaphone.

Julie Zhuo (01:17:06):
Yes.

Lenny Rachitsky (01:17:06):
Methaphone, check this out.

Julie Zhuo (01:17:08):
Yeah, yes.

Lenny Rachitsky (01:17:11):
It's like instead of holding the phone in your pocket, you hold this thing, and then you walk around with it and everyone's like, "What the hell is that?" Methaphone.

Julie Zhuo (01:17:16):
Yeah. I, too, am the proud owner of a methaphone and the next version upgrades with the little stickers, but-

Lenny Rachitsky (01:17:23):
No, I don't have that one yet.

Julie Zhuo (01:17:24):
... Eric is great. You should definitely have him on your... He's such a creative character. One time, I saw him with a parrot on his shoulder, and I was like, "Why do you have a parrot on your shoulder?"

(01:17:35):
He's like, "Well, you can talk to my parrot. It's a talking parrot," and then I spoke to the parrot and the parrot spoke back to me. What had happened is that he had hooked up a microphone, he surgically went into the parrot and added a microphone, a speaker, and connected it to voice mode on ChatGPT so that... It spoken I think like a pirate voice.

(01:17:55):
I was like, "This is the best idea." My six-year-old son is really into raccoons. He has a huge amount of raccoon stuffies. I was like, "I want a raccoon that can talk to him," so I made that using the Eric Antonow method, but it was great. It was a huge hit. Now, my middle son's birthday's coming up, and he is really into parody. He loves video games, so Minecraft, but what he often listens to on his Alexa are these parody songs. It'll be like Justin Bieber's hit or Gangnam Style, but they've changed the lyrics so it becomes a video game parody of some video game that he's playing, and they're horribly sung. They're like off-tune, it's just like some person who produced it. I was like, "Well, if he doesn't seem to mind off-key singing, I'm going to create him an album of video game parody songs, and I'm going to create an..."

(01:18:47):
I created an app on Replit, and what it does is you just give it a song. This is Justin Bieber's Baby and you link to a Spotify song, and I give him some context like, "Oh, Locke likes playing Kingdom Rush right now. We have an inside joke about the gargoyles being free money." Whatever it is, I just give it a bunch of context. I'm like, "Write me a song that just personalizes it and it's a parody of this particular video game." It writes me the lyrics. It's pretty good at doing this. It's pretty high quality. Again, it does it according to the beats of the music, and then I just sing it and record it, and then I got myself a song, so I'm creating an album of this, which I'm going to give to him. He's not going to hear this podcast, so no one spoil it to him. I think this is going to go publish after his birthday, but I'm very excited about this.

Lenny Rachitsky (01:19:34):
Wait, so you're going to be the one singing the song?

Julie Zhuo (01:19:37):
Yes, yes.

Lenny Rachitsky (01:19:37):
I thought you were going to use Suna or some AI thing to actually sing it.

Julie Zhuo (01:19:40):
No, I think I'm going to sing it myself.

Lenny Rachitsky (01:19:41):
Wow.

Julie Zhuo (01:19:43):
All of this made it so easy. All I have to do is just record. Again, I'm not a very good singer, but it doesn't turn him off to hear off-key singing.

Lenny Rachitsky (01:19:54):
Yeah. Wow, that is so beautiful. This gave me so many ideas for gifts I can give to kids in my life, and I just love how AI is making it, I don't know, easier to be a parent and, in some ways, more delightful. These are awesome examples. Okay, I'm going to take us to a different corner, contrarian corner. What's something that you believe that most other people don't, people would disagree with?

Julie Zhuo (01:20:20):
I believe that there's infinity in every direction. That makes me pretty contrarian on pretty much everything that anyone says. If someone says something like on Twitter, I sometimes play this game with myself, which is in what context would that actually not be true? I think the reality is that the world is so, or at least my reality and my understanding of the reality, is that the world is just infinitely complex. For example, if my kids say something like going outside is boring, or taking a walk is boring, or doing something is boring, my general response will be, "Well, it's because you're not seeing the infinity that's in that direction."

(01:21:05):
Even, for example, something really mundane like staring at a blank wall, I think that you can make that actually deeply, deeply interesting, because you can use that as an opportunity to go into your own mind and to figure out how you can make time pass, or you can meditate on the existence or meditate on your breath, or just be grateful for the purpose of being alive. Two people, one person you can say, "Sit in front of a wall for an hour," and, like my kid, they will super complain and be like, "This is the worst thing ever," but you can put somebody else like a monk and they'll have a wonderful experience. It's not really about the environment or the wall. It's really about how we see it and whether we can find the thing that is deep, and rich, and infinite in that direction.

Lenny Rachitsky (01:21:56):
Wow, these are some deep answers. This is very, I don't know, Buddhist, very mindfulness-oriented. I did a retreat once and their advice was just anytime you're bored, just notice all the things that are going on around you. What does your seat feel like right now? What does the air feel like? What are you hearing right now? It's exactly what you're saying, there's infinite things to pay attention to and keep you interested. It's hard.

Julie Zhuo (01:21:56):
It's hard.

Lenny Rachitsky (01:22:21):
Hard to actually do that for a long time and practice. That's why it's a practice.

Julie Zhuo (01:22:24):
That's why it's a practice. But I repeat that to myself, because oftentimes, if I have a bad experience feeling a certain way, it helps me to realize that it's often probably in my head. It's because I haven't gained the skills to be able to see the richness and infinity in that... I can maybe work on that. That feels better than feeling like, "Oh, I'm a victim of my circumstances. This thing happened to me," and that's so awful but not powerless, I can't do anything about it. That, to me, is a worse feeling than the alternative, which is I just don't have the skill yet. I can recognize it for what it is. I don't have the skill yet, but I can grow. I can maybe get better at it. There is a person out there who had the same situation as me and feels much more positively than I do, and don't I want to be more like that person?

Lenny Rachitsky (01:23:15):
It's such a beautiful circle back to our very first episode, which a lot of it was on imposter syndrome and overcoming that and your story there, so I love that that's maybe a way to close this conversation. But before we do that and before we get to our very exciting lightning ground, is there anything else that you wanted to mention, or share, or double down on that we've talked about?

Julie Zhuo (01:23:35):
I just want to say thank you. Honestly, I'm so inspired by the work that you do. I know we've known each other for quite a while, and I just think from the very first idea that you had for this newsletter, for the podcast, has been incredible, and I think the world gets so much from it. I'm sure you hear that a lot, but I am very grateful.

Lenny Rachitsky (01:23:52):
Well, I really appreciate that, and I say this every time we do a chat, is just this wouldn't have been possible without you, Julie. I was inspired by your longtime newsletter, The Looking Glass. Essentially, my idea was what if I do this for product? I started on Medium just like you did, and then I moved to Substack, and then it's like, "What if I charge for this?" That worked, and then I'm like, "What if I do a podcast?" and then that worked. But it all began with your concept, so thank you, Julie.

Julie Zhuo (01:24:22):
Yeah. I think you do it with so much kindness and curiosity as you always have, so I love that.

Lenny Rachitsky (01:24:27):
That's just who I am. Well, with that, we have reached our very exciting lighting round. I've got five questions for you. Are you ready?

Julie Zhuo (01:24:34):
I'm ready.

Lenny Rachitsky (01:24:36):
What are two or three books that you find yourself recommending most to other people?

Julie Zhuo (01:24:39):
The first is Zen and the Art of Motorcycle Maintenance. I absolutely love that book. It's beautifully written. It's so deep. My whole philosophy around quality is beautifully... A lot of it comes from that book, the idea and even all the stuff that we talked about change. What does it mean to be at that forefront of change and dynamic quality? I think he just talks about so beautifully and so masterfully in that book. Old classic, but I try to reread it every few years or so. Second is Conscious Business. It is my favorite management book. It's a little bit of a sleeper head because I actually end up recommending this one far more than my own book.

Lenny Rachitsky (01:25:23):
Oh, wow.

Julie Zhuo (01:25:24):
I read this one after I wrote my book, and I always tell people that if I read it before, I'm not sure I would've written my book, because I would've been like, "Conscious Business is really the book that really, really so much resonates." Many of the things I talked about, this idea of win-win, idea of being a player, not a victim, and how to think about work, not just it's a job but how do you really think about aligning it with your own personal values and what you want to do in the world, I think that this book really speaks to that so beautifully. It is also very tactical. It's got a lot of really wonderful examples. I will tell people, the cover isn't very attractive, and I think that if you judge a book by its cover, this seems very corporate-y. The title also seems like, "What conscious business?" and the first chapter is a little bit more technical. But if you just get past it and get into chapter two and you start with examples of the soccer team, it's just the best management book.

Lenny Rachitsky (01:26:23):
That is good advice to get people over the hump when they look for it. They're like, "Okay, okay, I'm going to stick with it."

Julie Zhuo (01:26:28):
Yes. Okay, third book. I love the book Good Inside by Dr. Becky. It's a parenting book and it's a very wildly popular parenting book, so I really recommend it to all parents, but I also think it's just a wonderful book for thinking about relationships, because parenting is that. It's like a very, very deep and intense relationship and interaction that you have with another human being, and there's so many things that I read in parenting books, including Good Inside by Dr. Becky, that I think could just as well been a management or a team leadership book.

Lenny Rachitsky (01:27:03):
I am thinking about trying to ask Dr. Becky to come on the podcast. I feel like there could be a lot of synergy exactly for that reason. She uses this term sturdy, which inspired maybe your bullet tree process.

Julie Zhuo (01:27:16):
Oh, yeah, I probably got it... I think she talks a lot about sturdiness and that just incepted right in here.

Lenny Rachitsky (01:27:20):
Yes. Yeah. Her whole thing is being a sturdy parent. Strong but flexible, I imagine. Yeah. I love her and I love her stuff. I watch all her videos on TikTok and Emily Oster. Okay, next question. Is there a movie or TV show you recently enjoyed?

Julie Zhuo (01:27:36):
I have not watched anything. I have no good answer for you. I think the only thing I watched this year was a rewatch of La La Land, which I do truly love.

Lenny Rachitsky (01:27:36):
So delightful. Okay. Is there a product you recently discovered that you really love?

Julie Zhuo (01:27:49):
I don't think there's anything too new. I love Granola, I love Replit. I've used all of the different coding lamps. Cursor is big on me for now. I just got a Matic Robot. I think that's been really delightful so far, at least the setup. I haven't used it long, long term, but it's the setup, the way that it worked. The fact that it had little stickers and you could make it into a dog or a cat was a wonderful experience.

Lenny Rachitsky (01:28:17):
The Matic Robot, willing to it, I am also a huge fan. I'm not an investor that's... Essentially, Waymo meets Roomba. For folks that don't anything about it, it's like a very sophisticated robot vacuum built by AI vision people.

Julie Zhuo (01:28:32):
Oh, I just thought of one more as well, the Limitless Pendant. Disclaimer, I am a small investor in Limitless, but what I love about it is that... Okay. It's a pendant, you wear it, and it just records everything that's going on, and later it summarizes things and it gives you feedback. I don't usually wear it out because I find that maybe other people feel awkward that I'm recording everything, I usually try and get people's permission, but I do wear it at home when I'm with my kids, and one of the best things that the pendant does is it gives me feedback on parenting.

Lenny Rachitsky (01:29:04):
What? Automatically or run into ChatGPT?

Julie Zhuo (01:29:08):
No, automatically. There's an app and it will sometimes notify me, or if I check it, it'll... Or I can also engage with Ask It, but what it does is essentially... It's like Granola, but for your life in terms of capturing everything, summarizing it, and then giving you tips and feedback. It's said things like, "Hey, there was that time you were talking about the game and you cut your kid off a lot. Maybe next time, think about letting them speak fully and listening better."

Lenny Rachitsky (01:29:34):
The app itself natively does that?

Julie Zhuo (01:29:36):
Yeah.

Lenny Rachitsky (01:29:37):
I did not know that, because I have one. I haven't used it much recently. That is incredible. I wonder if it gives you relationship advice too if you're talking to your partner. I wonder how it even knows.

Julie Zhuo (01:29:46):
Yeah. It did a pretty good job of inferring. I think I said person two, but it was kind of eye-opening for me.

Lenny Rachitsky (01:29:57):
Incredible. There's a recent episode of our How I AI podcast, our sister podcast, where somebody wears that in their meetings with their CEO and automatically turns what they're asking for into a prototype from the meeting notes, and then sales teams can start showing it to people to see if they're interested. How about that?

Julie Zhuo (01:30:19):
That's awesome. That is super cool.

Lenny Rachitsky (01:30:20):
Holy moly. [inaudible 01:30:22], what is even happening? Okay, I'll keep going. Do you have a favorite life motto that you find yourself repeating to yourself, sharing with others?

Julie Zhuo (01:30:30):
I like make it happen. Just a reminder that, at the end of the day, we could have a lot of motion. Maybe this is another one that I really like. I think about this poster. It used to be a poster at Facebook that says "don't mistake Motion for progress". There's this idea of be the change We want to be in the world, I guess is other ways of saying the same thing, which is I can do things. We can all do things. We have better and better tools to go out there and make things happen. Make it happen.

Lenny Rachitsky (01:30:59):
The common meme on Twitter, you can just do things.

Julie Zhuo (01:31:02):
Yes.

Lenny Rachitsky (01:31:03):
Final question. I like to ask this question to folks that are really deep in AI, and been working with AI, and getting a sense of where things are going. Is there something that you teach your kids or teaching your kids, think about encouraging them to learn, knowing that AI is going to be a big part of their life?

Julie Zhuo (01:31:20):
Emotional regulation is still really, really, really important. That's probably the thing that I think about the most in terms of what I want my kids to learn. I want my kids to be able to introspect, to have a better understanding of where their state of mind is, because we're still human. We still have the same hardware that humans have had for thousands of years, and that's not changing even as the tools and the environment around us change, and so I feel that you have to really understand yourself and you have to understand what's going on for you and where you are biased and where you're not, because AI can make it... This is my great fear, is that it makes things so much more comfortable. I have this great fear that this has been the trajectory that we've been on with technology. This is, again, going back to every strength is a weakness.

(01:32:05):
Technology makes things a lot easier. That's why we invent, that's why we create. Human race has always been about trying to better our circumstances and, in some ways, control our destiny, control our future. But at the same time, all of that control gets to a point where we have so many shortcuts in our lives and you can shortcut a lot of things. You can shortcut relationships, you can shortcut hard feelings, because now you can just watch TikTok instead of actually dealing with a very difficult emotion or tension that you had with a colleague, or with your partner, or with your children. AI makes it even, I think, more attractive, because now there's a person or there's a thing that can be very, very personalized, and if you're like, "Oh, I want a distraction, I want to do something," you got that.

(01:32:51):
But how do we actually still learn to sit with what is our true biology that's not changing, and how do we continue to be the kind of people that want to take on the freedom of doing challenging things? Because I find that if we don't do challenging things, we suffer. We suffer in a different way, and so, to me, true freedom is you can pick the things that are hard and you can feel pride in becoming the thing that you want to be. It's not forced upon you. It's not for survival's sake anymore, but you still have to pick. I want to figure out for my children the fact that it is really important to still find the challenge. Yes, you can use AI to do that, but really, don't think about it as a shortcut tool, because if that's the case, I don't actually think that they're going to be able to become the kind of people they want to be in the world.

Lenny Rachitsky (01:33:41):
What a beautiful way to end this conversation. Julie, it feels like this is just some kind of huge milestone of this podcast. Just like having you back three years later, it's like, I don't know, a chapter in the journey. I appreciate you coming back. I appreciate you sharing all this wisdom with us. Two final questions. Where can folks find you online if they want to reach out and maybe chat about maybe Sundial, maybe whatever else you're up to, and then how can listeners be useful to you?

Julie Zhuo (01:34:06):
Well, I would love to work with people who are at companies building really cool things and want better answers to how we build better, and so if you think your company would be interested in working with us at Sundial and figuring out how do we make every single decision maker into their own expert analyst, please reach out. That's one area, sundial@sundial.so. I am on X, so I've been tweeting a lot more, sharing thoughts. Going back to that skill of practicing, just share what's on your mind.

(01:34:40):
But for the long form stuff, I have my blog, The Looking Glass. It's on Substack. I share articles and thoughts about AI, product building, leadership periodically, and then, of course, I have my book, the revised edition with two additional chapters. One is around managing remotely and the other one is around managing in a downturn or managing in difficult change scenarios. That will be coming out in two weeks' time. The new content will be in the paperback. That's important. I'll send you a version of this when I get a copy myself, Lenny-

Lenny Rachitsky (01:35:15):
Sweet.

Julie Zhuo (01:35:16):
... but the paperback has a gradient type of cover. The hardback will eventually get the new content, but it just takes a while to phase out from all of the different retailers, so if you buy one, I cannot guarantee that it's going to have the new content. But certainly, the Kindle and the paperback will have all of the new content.

Lenny Rachitsky (01:35:33):
Just for the publish day, because this might come out later, what's the date that's coming up just for folks?

Julie Zhuo (01:35:37):
September 9th.

Lenny Rachitsky (01:35:40):
Okay, amazing. I think it'll be out by the time this is out, so go buy it. I imagine available on Amazon, all your local retailers.

Julie Zhuo (01:35:46):
Yes, yes.

Lenny Rachitsky (01:35:47):
Amazing. Julie, thank you so much for being here.

Julie Zhuo (01:35:49):
Thank you so much, Lenny. This was so fun. I hope to be back in another three years or whatever the next chapter is.

Lenny Rachitsky (01:35:56):
Hopefully sooner. Bye, everyone.

Julie Zhuo (01:35:58):
Bye.

Lenny Rachitsky (01:36:00):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## How To Win Friends & Influence Decisions (Julie Zhuo) | Lenny & Friends Summit 2024
**Guest:** Julie Zhuo 2.0  
**Published:** 2024-12-12  
**YouTube:** https://www.youtube.com/watch?v=0Z5FCYDeZXs  
**Tags:** growth, retention, metrics, kpis, experimentation, analytics, hiring, leadership, management, strategy  

# How To Win Friends & Influence Decisions (Julie Zhuo) | Lenny & Friends Summit 2024

## Transcript

Lenny Rachitsky (00:00:00):
We're seeing this kind of flattening of orgs. Everyone's becoming an IC again.

Julie Zhuo (00:00:04):
It used to be, okay, I don't have the skills to do 10 different jobs, but now with AI allows me to do many of those jobs myself. We need to dissolve the boundaries of these traditional roles and call ourselves builders. I'd love for us to get to the world where that's the title.

Lenny Rachitsky (00:00:21):
I also just saw a stat Google let go of so many of their middle managers.

Julie Zhuo (00:00:22):
Management is still really critical. You have a north star, you have a vision, and you're just trying to figure out how to use the resources that you have to get that thing done. Used to be people, but now it's basically models and different models have different strengths. You have to assemble the Avengers so that you can use the right tools for the right purposes.

Lenny Rachitsky (00:00:39):
What do you feel is the biggest change in the role in life of a manager these days?

Julie Zhuo (00:00:43):
It's always been manager's job to manage change. I just think the rate of change is accelerating. Today management is really about this idea of be sturdy while being flexible. So I think about this metaphor a lot of the willow tree. It can survive a lot of storms, disasters, et cetera, but it's also very flexible.

Lenny Rachitsky (00:01:00):
You have such an interesting trajectory from being head of design to now being obsessed with data and analytics.

Julie Zhuo (00:01:05):
You want to diagnose with data and treat with design. Data is not a tool that's going to tell you what you should build. I don't actually think a lot of the fast growing companies are using data well at this point. Traditionally things just didn't grow that fast. These companies are totally getting by on just good instincts and good vibes, but what always happens is eventually things stop growing.

Lenny Rachitsky (00:01:27):
Today my guest is Julie Zhuo. Julie was my first ever guest on this podcast, which I recorded over three years ago, so this is a very special conversation as I've shared many times before in other places, Julie's newsletter The Looking Glass was the inspiration for my newsletter and basically led to everything that I do now. If you're not familiar with Julie, she was the longtime head of design for the Facebook app used by over three billion people. She's also the author of the best selling and very important book The Making of a Manager. And most recently she started her own company, Sundial, which is an AI parent analyst used by companies like OpenAI Gamma and Character.AI. Julie is one of the most thoughtful and insightful product leaders that I've ever come across and she's also got one of the most interesting perspectives on product building.

(00:02:18):
Having worked at a mega large corp like Meta as head of design and now as a founder at a tiny startup that's all about using data to help you make decisions, it's really rare for someone to have this spectrum of experiences. In our conversation, we talk about how learning to be a great manager directly translates to learning how to use AI tools extremely well, which specific skills will become more valuable in the next couple of years, her most valuable and timeless advice for new managers, why she's not hiring product managers at her startup, her simple heuristic for knowing when to use data and when to use intuition in making decisions. There's something in this episode for everyone. And if you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. It helps tremendously. And if you become an annual subscriber of my newsletter, you get 15 incredible products for free for an entire year, including Lovable, Replit, Bolt, n8n, Linear, Superhuman, Descript, Whisperflow, Gamma, Perplexity, Warp, Granola, Magic Patterns, ChatPRD and Mobbin.

(00:03:20):
Head on over to lennysnewsletter.com and click product pass. With that, I bring you Julie Zhuo. This episode is brought to you by Mercury. I've been banking with Mercury for years and, honestly, I can't imagine banking any other way at this point. I switched from Chase and, holy moly, what a difference. Sending wires, tracking spend, giving people on my team access to move money around, so freaking easy. Where most traditional banking websites and apps are clunky and hard to use, Mercury is meticulously designed to be an intuitive and simple experience. And Mercury brings all the ways that you use money into a single product, including credit cards, invoicing, bill pay, reimbursements for your teammates and capital. Whether you're a funded tech startup looking for ways to pay contractors and earn yield on your idle cash, or an agency that needs to invoice customers and keep them current, or an eCommerce brand that needs to stay on top of cash flow and access capital. Mercury can be tailored to help your business perform at its highest level.

(00:04:19):
See what over 200,000 entrepreneurs love about Mercury. Visit mercury.com to apply online in 10 minutes is a FinTech, not a bank. Banking services provided through Mercury's FDIC-insured partner banks. For more details, check out the show notes. Today's episode is brought to you by DX, the developer intelligence platform designed by leading researchers. To thrive in the AI era, organizations need to adapt quickly, but many organization leaders struggle to answer pressing questions like which tools are working, how are they being used, what's actually driving value? DX provides the data and insights that leaders need to navigate this shift. With DX, companies like Dropbox, booking.com, Adyen, and Intercom get a deep understanding of how AI is providing value to their developers and what impact AI is having an engineering productivity. To learn more, visit DX's website at getdx.com/lenny. That's getdx.com/lenny. Julie, thank you so much for being here and welcome back to the podcast.

Julie Zhuo (00:05:26):
Thank you, Lenny. I'm so excited to be here. I've been looking forward to this all week. I love your podcast. I love where you've taken it since our very first conversation and I'm super excited to have a fun and engaging chat.

Lenny Rachitsky (00:05:38):
Can you believe that first episode, the very first episode of this podcast, was over three years ago at this point? Holy shit.

Julie Zhuo (00:05:46):
I'm not sure you had that fire in the background back then.

Lenny Rachitsky (00:05:49):
So funny enough, I don't know how many people have noticed this Easter egg that I've stuck with, in that first studio, I was just watching the episode, I had this funny little mirror. I don't know if I had in the first episode with a fireplace that was showing up in that mirror because the mirror was showing something stupid. And so I've just kind of kept this fireplace across every studio I've moved across in my various places.

Julie Zhuo (00:06:12):
I even remember we chatted. Video was kind of a newer thing. You're like, "We'll record it, but it's really about the audio." And now we moved into the video era.

Lenny Rachitsky (00:06:21):
So as you were saying that, I realized my fire was broken, so I just had to turn that on. So we just cut a little piece. Yeah, that fire was my little funny strike for myself and I don't think anyone's ever realized this.

Julie Zhuo (00:06:32):
It's very cozy. I love it.

Lenny Rachitsky (00:06:33):
That's the idea. I was actually just looking at the stats. So since that first episode, this podcast has done over 20 million downloads. It's approaching 30 million downloads.

Julie Zhuo (00:06:43):
It's really incredible. I think it is a testament to just your curiosity and how much you really care about the craft of building great products and sharing that with the world. And I know I listen to your podcast and read your newsletter, my team does. We're constantly sharing things from all of the amazing speakers that you've had, so thank you for doing this.

Lenny Rachitsky (00:07:01):
My pleasure. I really appreciate that. So the reason we are chatting again three years later is you're re-releasing your incredible book, The Making of a Manager. I've got it right here. You've sold a bazillion copies. It's been on every list that I've seen. You're releasing the paperback version, you're adding some chapters. I guess first of all, just how do you feel on reflecting back on the success of this book?

Julie Zhuo (00:07:24):
It honestly went beyond my expectations, so I'm super happy with it. My big motivation to write it was I think largely because I felt if I had to write this thing, I was likely going to become a better manager. And that was actually a huge part of it because thinking about and writing something I've been blogging for a long time. And I know that part of my process is when I really sit down to try and put down everything I feel and write letters to myself, it really helps me. And so that was honestly a huge motivation. I hoped that it would go out there and it would sell some books. I was thinking about that maybe for people who grew up in companies like mine, like Facebook, high-scale Silicon Valley, it might resonate. I couldn't have expected that it would have much wider reach than that and that's been really awesome.

(00:08:11):
And just how many people will tell me things like I thought I was the only one who felt this way, but this book made me realize that, hey, these are very normal feelings. And that's certainly how I felt, just stumbling through and feeling like an imposter for so many years. And so it really is very gratifying to hear that from readers.

Lenny Rachitsky (00:08:29):
I feel like it's the modern-day high output management. That's the book that's been mentioned most on this podcast and it feels like this is just a modern version. I feel like that book is actually out of date in a lot of ways, so I can see why people are really drawn to it. And this is a great segue to the first area I want to spend some time on, which is it feels like a lot of the skills you learn as a manager translate to being really good with AI and using AI tools really well. And I want to talk through a few trends that I want to get your take on that relate to this general theme. The first is it feels like just everyone is going to become a manager in the near future because of agents being so integrated into our workflows. There's this agentic society that we're coming to and it feels like the same skills of being a manager make you really good working with agents. Just thoughts on that and where you think that's going to go.

Julie Zhuo (00:09:20):
I 100% believe that and agree with that, which is that management is just about, in my mind, having an outcome. So you want to get something done. That's the thing. You have a north star, you have a vision, and you're just trying to figure out how to use the resources that you have to get that thing done. And typically when we talk about management in traditional settings, we talk about the resources being people, and getting the right talent, and making sure that you've got the assemble the Avengers, so you've got the right mix of skills that you need. The second lever is around, okay, what's the purpose? Does everyone know what they're supposed to do with their talents? Do we have a goal? Do we have a purpose? And then the third thing is process, which is how should all of these different people and tools come together?

(00:10:07):
And these are still the fundamentals of working with agentic systems. You still need a goal. You need to be very clear about what the outcome is and you have to understand the strengths of, used to be people, but now it's basically models. And different models have different strengths, so it's like they have different personalities. And so you kind have to get to know it, develop an intuition for it so that you can use the right tools for the right purposes. And I mean, we talk about agents, but we also talk about what are the tools that agents have access to? So you still have to make decisions around that and then there's of course process, which is how you do it. And now I think with better and better models, perhaps the agents get smarter so they can deal with higher and higher levels of figuring out how to do something, but I think it's still very important for us to be able to provide the right context, provide the right high level instruction so that we get what we want.

(00:10:59):
So really, it's the same principles and I absolutely agree with you that more and more of us are going to have to double down on these skills to be able to use these tools very effectively.

Lenny Rachitsky (00:11:09):
So along those lines, I have your book right here. You have this list of a manager's job is to build a team that works well together, support members in reaching their career goals and create processes to get work done smoothly and efficiently, which is basically exactly what you just said. Interestingly, that middle bullet is the part you don't have to worry about anymore with agents. You don't have to worry about their career development and progress in [inaudible 00:11:29]

Julie Zhuo (00:11:28):
That's true. That's true, though some people do joke that if we don't treat our agents nice, what's going to happen when AGI comes? And maybe it still might benefit us to be kind.

Lenny Rachitsky (00:11:39):
I'm one of those people that says thank you to the Waymo when I leave and just thanks ChatGPT when I'm in voice mode. Just like, "Thank you. That was really helpful." So along these lines, I know there's a lot of ways to go here, but just in terms of skills that are important to a manager, which do you think are most valuable to develop in working with agents in AI systems? I think about things like clarity, communication. Just what comes to mind when you think about here's the things you want to double down on as you're learning to be manager that will also help you be really good at AI tooling and working with agents?

Julie Zhuo (00:12:16):
The first is defining the goal and defining the outcome and being really, really crystal clear on what does success look like. If you ask a company to do this, we'll know that this is challenging for humans. I think a lot of times when you talk about why is alignment so difficult at a big company, it often comes down to this question, which is different people may have different pictures of what success looks like. And even if I describe in human words, Lenny, I want to build this product and it's going to be amazing, or this podcast episode, which you asked me, want lots of people to hear it and take away things, that's very general. How do we get even more specific so that we know without question whether we've hit it or not. And this is actually a really, really difficult problem.

(00:13:06):
It's a difficult question for us because, again, we tend to think very high level. So figuring out how to boil it down so that an agent can really understand what success and failure looks like is a lot of the game. And I think this also relates to things like, well, that's why we have to write evals and that's why they're so important, because they're helping us understand what is the objective criteria. And these days I work in data and my company is all about trying to automate data analysis. And the forever question goes the whole point of data and the whole point of metrics and KPIs is we're trying to put a little bit more of an objective measure or get as crystal clear as possible about what success looks like. And I think it's really an art more than it is like a science, but that's the first thing. I think if you're really unclear about what success looks like, the prompt, you're probably not going to get the most amazing work. I think that's true for managing teams and it's very much true for managing AIs.

Lenny Rachitsky (00:14:01):
Okay, so let me actually flip this on you and talk about another trend that we're seeing, which is this kind of flattening of orgs, managers being let go. Everyone's becoming an IC again. I just had the CEO of Airtable on the podcast and his whole shtick was that CEOs have to become ICs again. He's coding more than he's ever coded again and his feeling is you have to know what's possible by being in the weeds in order to figure out what your product should be. I also just saw a stat that Google let go of so many of their middle managers of smaller teams. It's just like this flattening trend. So do we even need managers, I guess is one question in the future, and then just thoughts on how this will play out?

Julie Zhuo (00:14:42):
So I think the real promise and magic of AI that we're seeing in the workplace is that it leads us to each individual is far more empowered. So it used to be, okay, I don't have the skills to do 10 different jobs, so I need to supplement by hiring people to do these jobs. I need someone who's really good at design, I need someone who's really good at coding, I need someone who's really good at data analysis, and then I'll assemble that team. But now with AI and my companion, it's like, wait a second, AI allows me to do many of those jobs myself. Now, I'm not going to do them at what's called the PhD or the highest 1%, 10% level, but if I was at the zero or 10th percentile, it can certainly get me even today very quickly up to the 60th, 70th in terms of what the state of the art is.

(00:15:34):
And I think that that unlocks so many doors. And so the main thing that I felt so excited about, and this is something I tell my team all the time, is we need to dissolve the boundaries of these traditional roles. So in the past, again, we would have a traditional team, engineers, product manager, designer, researcher, data scientist. And I think now the teams can look more like, well, it's just two people. And they could be any of these traditional disciplines, but the key thing is they can now use AI to help themselves do a lot of the things that the other folks used to be able to do. So in some ways we can drop all of these different role distinctions and call ourselves builders. I think that's sort of the most general purpose way of thinking about what we can all be. We can all be builders. We can all be builders and I'd love for us to get to the world where that's like the title.

Lenny Rachitsky (00:16:30):
That's funny. That's the term I've been actually using more and more. I used to orient this podcast as a newsletter around product managers and then I started using just product to be a little more broad. And now I'm actually using that term builder and I love that term because it's exactly what you're saying. And this is very much a theme that comes up often in these conversations more and more, just the lines are blurring. I'm curious at your company, how does that look? What are you doing differently? What are you seeing on the ground within your company that maybe would be different from a few years ago?

Julie Zhuo (00:17:01):
So we have eliminated more roles. For example, we thought we would need a bunch of product managers. It's turned out that actually if you don't have a product manager, I know this might be going against a little bit of the ethos of where Lenny started, but I find that sometimes when you have a designer or a product manager, and let's say I'm an engineer, then when I have a problem, like I need to figure out the product definition, my default will be, well, I've got these people and that's kind of their job description, so I'm just going to delegate that to them. And I think that in doing so, again, we want to be polite, we want to respect everyone's lanes. I think that's a missed opportunity for that, if I'm the engineer, to be like, "Wait a second, I should probably focus a lot, too."I need to understand and have an opinion about what to build or what the user experience is.

(00:17:54):
And so we found that if we actually make teams smaller and we even in the past, pre-AI, just have fewer of these, it allowed everyone to be like, "Wait, we don't have product manager on the team, so communication's up to me. Figuring out how we get greatest value to users is something that is now strictly in my charter. And so that's why I'm such a big fan of we can make teams smaller and we can eliminate these lines. Sure. Again, I'm not trying to say everyone has to do everything. We still can respect the fact that you might be much better at this particular skill than me, but it's less about the role and it's more about the specific context that we're in.

(00:18:32):
And I find that whenever you have teams and you empower them to be able to take more action on their specific context rather than having these higher level of rules or policies or this is how it's supposed to be, then you get better work. You get faster work and you get happier employees because people feel like they actually can have the power to create the thing that they want.

Lenny Rachitsky (00:18:58):
That's really interesting, just that constraint of not having a PM makes the engineer realize they're not going to wait for someone else to do it. They have to figure it out. The obvious trick there is they have to be good at this. It's a very different job from engineering to be really good at articulating here's the problem we're going to solve, here's why it's important that we're solving, here's how we're going to prioritize everything we're thinking about, here's how we get alignment. Is there something you do differently when you're hiring these engineers, knowing you're going to probably not hire PM? And just that feels really hard to hire for someone that's really good at all these things.

Julie Zhuo (00:19:30):
It is true and I'm not trying to say again that everyone needs to be good at everything. I don't think that's very realistic. I do think, for example, if we were going to create a team and we're going to have a couple engineers and none of them are very good at thinking through product requirements or what the user angle is, we probably do need to supplement the team with somebody with that skill set. And that might be a designer, or that might be another engineer who's really good at that, or that might be a traditional product manager, or even sometimes a data analyst who's really good at it. So that skill is still important and the team still needs to have that skill, otherwise it's probably not going to produce the best outcome. But I like to think of it as what are the skills that are needed for this and can we now find a couple people?

(00:20:13):
But it doesn't mean we just automatically go to that script of need a PM, need a designer, need three engineers, need that. Another example for us is even thinking about front end, back end engineering. And it used to be like some people are front engineers. So if you have a project and it's got some front end, some back end, the shortcut is like I need one of these and one of these and that's how it's going to go. But if you say, look, you're an engineer, you're a builder, this has a little bit of front end, but you know what? You can probably figure that out. Use AI to help you figure it out. Get obviously someone who's a specialist to review the code or to give you some high level guidance on things, but just do it. And ever since we started to implement that as well, we see again a little bit of you have to invest a little bit in the beginning. So people are not as comfortable.

(00:21:01):
They have to learn, so initially things take longer, takes a little bit of extra time, versus if you did slot in a front-end specialist and this is a front end project. It probably would've gone a little bit shorter, but in the long run that investment really pays off because now you have a lot more people who are, again, a little more well rounded and can take on many more pieces just on their own. And then in specific scenarios this is super front and heavy. Sure, let's still bring in somebody who is more specialized in that particular skill.

Lenny Rachitsky (00:21:31):
I love that you've had the experience of working at a mega large company at Meta and now you're building your own startup that's small and in the middle of this trend of just staying very small and staying really lean and just everyone doing more things. It's so cool that you're experiencing that. So a couple of questions there, just which functions are you seeing most accelerated with all these AI tools? Is it engineering? Is it something else? And then are there tools that have been most helpful to you? Just AI tools for folks who'd be like, "I should check it out." I'm guessing Cursor, but curious if there's anything else.

Julie Zhuo (00:22:04):
Yeah, certainly engineering is one that, I mean, most of our company is engineers, so that's the one that we focused on a bunch. I certainly do see more people also prototyping things. We have two designers, but we also see engineers. We have a team that's called product science, which is this interesting blend of you can think about it as like a forward deployed person who has a lot of data analysis background and is kind of playing a customer success role and also kind of playing a product role. And you see them starting to take on building more prototypes or getting into some of the engineering. And so it's really lovely to see that blend of everyone can do a little bit of everything else and we're all encouraging each other. The other thing that recently we've also been trying to do a lot more is just obviously we say, "Hey, engineer, now you can do analysis."

(00:22:59):
And their first thing is like, "Oh, I don't really know analysis." This is where ChatGPT comes in. And it's like traditionally we would say, "Well, I have to learn that from a human. I have to ask this person and now I'm going to take a bunch of their time because I want them to explain everything to me." And in fact, I think these days ChatGPT or these other AI tools are better teachers. I find that we tend to maybe not use them quite as much just for the purposes of accelerating our education or even going through something. Sometimes what I'll do is I'll find a curriculum online. And if you take a course, it'll be like this 12 week curriculum and I'll just feed it into ChatGPT and I'll say, "Help me customize a program for me using the ways that I like to learn."

(00:23:43):
I am a person who really needs examples. I need a lot of explain like I'm five. Give me an analogy. And I know some other people on my team are like, "These examples don't make any sense." We're different types of learners and so the idea of a tool that personalizes learning for each of us really helps us, I think, accelerate and just learn these skills much faster than before. So yes, the tools are great. We can use Cursor, it helps us, it autocompletes, it writes a bunch of things, but the acceleration of learning I think is another maybe underutilized tool in all of our arsenals just because I know whenever I talk to people, we forget. We don't think that, wait, yes, we could be doing that and just sitting down and probably in 30 minutes or an hour learn so much faster than what we used to be able to do before.

Lenny Rachitsky (00:24:33):
That's such an interesting point. There's these tools that are in the just in time, helping you move faster, but you also need to learn how to do something, some foundational lessons. What's an area that your team did that? What did they work on learning?

Julie Zhuo (00:24:49):
So I'll give you an example. I was just talking to an engineer this morning and he's written a bunch of these algorithms. So one of the things our company does is we're trying to automate data analysis, so one of the things we have to do is obviously understand the best practices. If there's a type of question ...

Julie Zhuo (00:25:00):
... To do is obviously understand the best practices. If there's a type of question, "Hey, what features are really the ones that people pay for?" We need to kind of figure out what is the right analysis to do. And so the engineer was saying to me, "Julie, I feel like I really understand the how. I know the algorithms, I know we do root cause analysis, how we do that. But what I don't really understand is why or when this would be most useful. In what context in a company would this company come up?" Because he's an engineer, he hasn't done that job of being a PM or an executive that asks these types of questions. And that was like the perfect thing where yeah, traditionally you might've asked someone, but this is more general purpose. There's so much resources in the world on the internet about it. This is like the perfect type of question where if you just talk to ChatGPT, it's probably going to give you a much better answer and allow you to go deeper.

(00:25:55):
And a secondary thing we've been learning too is this idea of, almost like as a... Using ChatGPT it's for to test your learning. So explains a bunch of things. And so what I often like to do is like, "Okay, I read this, so this..." I try to explain back what I heard. "So does this mean... Is that right way to think about it, that this is kind of like this analogy?" And ChatGPT will critique me. "Yes, that is right," or "No, you didn't quite get that right. In fact..." And it always tries to say it nicely. This is a funny part. It'll be like, "That's close, and then eventually it's like, "You were completely wrong." Just in the style. But it helps so much because it's interactive and so we can really test whether we really understand the concept by trying to retell it back in our own way.

Lenny Rachitsky (00:26:40):
It's incredible just how many ways all this AI breakthrough is helping us advance and do more and learn more and become better. I know there's some downsides, but this is incredible. So many ways of getting better and faster. I want to spend a little more time on this data analysis stuff. So again, you have such an interesting trajectory from working at a big company to starting your own small company. From being head of design to now being obsessed with data and analytics. So let me spend a little time there. What do AI companies that have kind of figured out how to use AI for data analysis and data work, doing differently, what are people missing and sleeping on in terms of getting better at working with data? And let me just add this point. It feels like we're almost working through , here's all the blockers to a team moving forward. There's like waiting for the PM to write the PRD and then there's waiting for the data scientists to give you answers analysis. So this is another really cool unblock that every team member will have.

Julie Zhuo (00:27:38):
So your first question was how are a bunch of AI companies using data? So the funny thing, my funny answer to this is, I don't actually think a lot of the fast-growing companies are using data well at this point. And the main reason why is because traditionally things just didn't grow that fast. And so if you got to a hundred million users, your company has probably been around for a while, and if your company has been around for a while, you've had time to set up things like logging and you've hired a growth team at that point and you've hired a data team and they've done a bunch of work to log an instrument and then transform the data. And we've talked about what is the observability for our business. And you just usually had years to build and develop that, because of the rate of growth.

(00:28:25):
And so today we see companies that are growing insane and there's still about 10 people or two people or however many people, but they've got hundreds of millions in ARR and hundreds of millions of users. And you know what? They don't actually have all of that infrastructure, that logging, to be able to truly do data analysis. So I would say that these companies are totally getting by on just good instincts and good vibes and we see that. You don't really need data analysis to sometimes make something that works. But I think what data helps us do is in my mind it sort of is helping us reflect back what is really reality. And so of course if ARR growing, awesome, great, keep doing what you're doing. But what always happens is eventually things stop growing. Growth does not happen forever. And usually when growth stops, everyone has this question of, "What's going on? Why did it happen?".

(00:29:22):
And then you start to be able to see the power of, if you've instrumented everything very well and you have a very good observability model for your business, it's much easier to start to get into the root cause, it's easier to even predict whether growth will slow down at a certain point, it's easier to catch these trends earlier. If you don't have good observability over how your business runs and what the company's key levers are, then you will be scrambling, and at that point, that's usually when people start investing a ton in data. So I wouldn't say that a lot of these hot companies are quite there yet, but what I also think is a trend is that every time there's a new technological shift, we actually have to change the way that we think about... Analysis has to answer the questions that we have, and if technology changes or context changes, we need new methodologies of analysis.

(00:30:16):
So for example, when mobile came to the forefront, looking at sessions or sessions per day or time spent on mobile, or length of sessions became something that was important for us to understand, are people getting value in this new medium? I think that's the same with what we have today. Conversational analytics is totally different. Used to be, let's say in the Google world, I knew you were interested in shopping if you click the shopping tab, I know you're interested in maps if you click the maps tab, we can measure clicks. Today it's just all conversation, and so it's actually harder for us to tease apart what is the user intent.

(00:30:55):
If I worked on any of these LLM, I would say one of probably the biggest questions is, hey, what use cases are growing or what use cases are shrinking? And that's much harder to tell today because it's not just clicks on tabs or pages. It's like we have to probably use an LLM or a machine learning model to bucket user intent. We probably have to ask questions like, is the flow going really well in conversations? Like, if I just ask one question and I don't go back and forth, did the user get value? It's always trying to get back to, we're trying to figure out if this was a good experience, but now it's like we need to actually invent new methodologies to help us analyze that.

Lenny Rachitsky (00:31:40):
Yeah, I think the question is always like with conversation, do you want it to be a long conversation, do you want it to be a short conversation? What's the right answer, what's better?

Julie Zhuo (00:31:47):
Yes.

Lenny Rachitsky (00:31:48):
I had a ChatGPT on the podcast, Nick Turley, and turns out one of the ways they found the most common use cases early on was watching TikTok comments and things going viral on TikTok after they launched. How about that?

Julie Zhuo (00:32:01):
Yep, yep

Lenny Rachitsky (00:32:02):
Okay, so I want to come back to this really interesting, unusual path that you took from being a head of design at Facebook, you're an inspiration to so many designers, now you spend your time on a data startup obsessed with data. I don't know, classically designers aren't the biggest fans of experiments and data and making decisions based on data. When you look at designers and you hear designers kind of push back on like, "No, we don't want to be super data driven, we know better than... We have a sense of what's beautiful and great and intuition," all these things, what do you think designers are missing when they feel that and say that when they're afraid of writing experiments and data and kind of want to push that out?

Julie Zhuo (00:32:46):
There's one phrase that my co-founder and I would always discuss with amongst ourselves very early on in which we shared with a lot of the companies that we work with, which is, what you really want is you want to diagnose with data and treat with design. So data is not a tool that's going to tell you what you should build or what the solution is or how we're going to cure the fact that you don't have really great retention. It's just not. But it can tell you if you have a problem and where that problem or opportunity might be. But you still need to go back and undergo a very creative process to figure out what's the best way to solve that. So that's the first thing I would say, is this framework of, data helps you figure out what's actually happening, what do people like, what are they engaging with, what what not.

(00:33:32):
It just gives you a story that better reflects reality. Because again, we all have stories. We're like, "Oh, my company's amazing, people love us," blah, blah. That's the story I want to believe, but reality may be a different picture. And so what data is trying to do is capture reality. And by the way, I don't think of data just as it's an AB test and it's quantitative things we can measure. To me data is also, well, what did people put onto TikTok and which things went viral, and what are they saying in the Twitter verse or X verse I guess is what it's called now.

(00:34:07):
And if you do a customer interview, that's still all data, it's just that that is a little harder to distill and quantify. Although now with AI, we have better tools for synthesizing. So that's all data in my mind and it's just all trying to help us understand what is really happening, what is the phenomenon that's happening in reality and how do we understand it? You still have to go and invent and create and dream, and there's no formula and there's no science that will tell you exactly how you're going to make a hit. You can experiment, which allows you to try more things maybe and more rigorously understand what that does in the short term. It's all very contextualized. A-B tests don't tell you what will happen in the very long run, and again, it's all still data, you still have to synthesize and figure out what to do.

(00:34:57):
So that's the thing, I'll say. Diagnose with data and treat with design. The second thing I will usually tell designers about, is I find that sometimes, and maybe it's the, let's call it the false precision of numbers that we kind of fall into, right? Because it's like, okay, we got these numbers and the numbers go up. It's like no, the fact that you still have to choose which things you look at, is an art, not a science. And your interpretation of if the number went up 5%, is that good, is that not good, is also an interpretation and is an art, not a science. It's just that sometimes I think we can give ourselves this feeling, and I get it, sometimes there's this instinct to want to control things and we want everything to be buttoned up, and we want to know that if we did ABC, everything will be great, our career's going to be awesome, our product's going to rocket ship.

(00:35:49):
And I think designers are rightly often pushing back and saying, "No, the reality is this stuff is ambiguous and there's uncertainty and we can never know for sure." And I think all that is quite true. So the other thing I would say that I really support is you just actually can't make a really great product by thinking you can A-B test your way into it. So I fundamentally believe that, but I don't think we should throw the baby out with the bathwater. I think there's actually... You know? It's not either or, it's not like data or design.

(00:36:18):
It's like these are just tools for us to use, and I would say every amazing designer that I've ever met is absolutely obsessed with trying to get a better understanding of reality. They want to know what users really think, they want to know what they're really doing. If they could read every user's minds, that's the thing we would all want as a designer is like, if I could just know what everyone is thinking, feeling every time they used it, my life would be a lot easier, because then I would be able to build better and better things. And so that's what it's trying to help us do. It isn't perfect, no metric is going to tell you whatever we hope that it can in terms of the true certainty and precision, but it doesn't mean we can't use it to better our product development.

Lenny Rachitsky (00:37:03):
I was going to say exactly what you just said, which is every great designer that I've worked with was obsessed with data in the most leaning into the data, versus designers that are just like, "Nah, I think I'm good, I have a sense of what's right, and why would we let that tell us what to do?" And to your point, it's not going to tell you what to do, it'll tell you where opportunities arise. Let me take us back to the management chat and maybe just let me ask something broad. What do you feel is the biggest change in the role and day-to-day work and life of a manager these days with the rise of AI?

Julie Zhuo (00:37:34):
I think that managing change. It's always been manager's job to manage change, and there's always the chaos of what's going on. I just think the rate of change is accelerating, and we've seen that over the last couple of decades. And so I find that there's just a great deal more uncertainty that people have about things, like where is AI going to be in two years from now? I don't know. Who really knows? And so are we going to have AGI in five years? That kind of changes a lot about the landscape. Not to mention, I think there's quite a lot of fear that many organizations are feeling. It's like if my career has always been in design and now these tools are getting better and better at what I'm doing, then holy shit, what happens to my career and my future? And do I need to pivot? Do I need to learn different things?

(00:38:25):
And so it's this change, it's this feeling of uncertainty. And I think a lot of times managers have to deal with that in addition to what you were saying before, which is they also have to learn these new skills, which is managing AI and managing these more powerful tools in their arsenal of trying to get things done. So that is very different, I think, than maybe 10, 20, 30 years ago. And so I think that the skills that become more important are obviously communication, feedback, compassion, but just being able to work with humans and to have them understand that yes, we are in a state of change. I think every leader has to do this now, every startup founder that I know, every CEO, is how do you land this message that things are changing and we need to be very open to change?

(00:39:16):
If we go and stick to our old ways, we're probably going to get left behind, our product's going to get left behind, even our way of doing things is going to be left behind. So we need to change. We need to change our product and we need to change the way that we work, as we all talked about in terms of smaller teams, more nimble, blah, blah, blah. But at the same time it's like, how do we do that in a way that doesn't just freak everyone out? And it's like, "Ah, it's chaos. Everything's changing.".

(00:39:44):
So I think about this metaphor a lot, of the willow tree, which is the willow tree is a very sturdy tree. It can survive a lot of storms, disasters, et cetera, but it's also very flexible. The branches are very, very flexible, and that's in some ways what allows it to be very sturdy. So I think today, management is really about this idea of be sturdy while being flexible, and that is a very hard thing to pull off, but I think that's at least when I even go into... I'm like, "Be like the willow tree, Julie. Just imagine the willow tree and try and channel that as the kind of feeling of what it is that we're trying to do together."

Lenny Rachitsky (00:40:23):
This reminds me of a couple things from other guests. I had Marc Benioff on the podcast and I asked him, "Just how do you deal with all this change? It's like agents now, it was, I don't know, there's AGI coming as you said, just like, "How do you survive through this?" And his advice is just, he's like, "I'm always just like, 'Good. This is great. This is what we want. This is exciting. We have so much opportunity, it's just not boring. We can always reinvent.'" And he's always embracing with "This is good." And just I'll never forget the way he responded to that.

Julie Zhuo (00:40:55):
I think if you don't think it's good, it's kind of a painful way to live. It'll be very, very difficult over these next. So I do think that all things be equal, lean into it. If you can wake up every day and see it as opportunity and excitement rather than fear, again, they're all flip sides of the same coin, but I think if we can lean more into what could it be, while recognizing that the other side does exist and it's still there. And I think if managers who try to pretend like it isn't there, it's all good, no one's upset, et cetera, there's something also missing about just addressing and being able to be like, yeah, it's hard. Change is hard. We're probably going to get upset. We're going to have some chaos. This is going to happen, but we will work through it because we're going to be flexible and we're going to be able to put our eyes on the big picture of what is possible, which is exciting.

Lenny Rachitsky (00:41:45):
There's another quote that and came up as you were talking. I forget who it was exactly, maybe Kevin Wheal, maybe Mike Krieger. They said that this is the most normal things will be, ever. Like, it will only get weirder. And I think giving people that sense of like, okay, just enjoy this normal, because this is going to be only weirder, is we'll at least give people an expectation, real expectations where things might be going.

Julie Zhuo (00:42:11):
Yes, yes.

Lenny Rachitsky (00:42:11):
What a time to be alive.

Julie Zhuo (00:42:12):
What a time.

Lenny Rachitsky (00:42:14):
Okay, let me zoom out even further and chat about... I want to ask you just outside of AI, management in many ways is unchanged. It's still a lot of the same work, managing people, helping them be successful, producing great work. What are just some of the, I'd say most timeless, most important lessons that you think managers, especially new managers still don't totally understand, need to hear more? What are just some that come to mind? And then we'll see where this goes.

Julie Zhuo (00:42:43):
The first thing that comes to mind is the importance of managing yourself and understanding yourself. This was chapter five of my book. It's called Managing Yourself. In fact, when I wrote it, I kind of wanted it to be chapter one, and then my publisher was like, "Well, maybe you should get into some of the tactical..." People don't necessarily think managing other people or manage a team starts with them, but I really do fundamentally believe this, because I think all of us, of course, like any human being, we have things that we're strong at, we have things that we're weak at. And I am a very big believer that every strength is its own weakness, and every weakness is a strength.

(00:43:18):
There's no such thing as you're going to somehow get every dimension to be 100%. In fact, I think one of the most interesting concepts or frameworks for myself, and also even, this is also kind of like a data framework concept, is this concept of dimensionality. So what dimensionality means is you're a human being, but we can kind of look at you in infinite dimensions. There is, for example, how good is Lenny at throwing an ax? That's one dimension

Lenny Rachitsky (00:43:49):
Pretty good.

Julie Zhuo (00:43:51):
How good is Lenny at being a podcast moderator? Fantastic.

Lenny Rachitsky (00:43:56):
So-so. Okay, thank you.

Julie Zhuo (00:43:58):
How good is Lenny at doing a zero to one type of project in the AI space? Right? So again, just can think about these as infinite dimensions. And the reality is each of our profiles is very unique, it's like a fingerprint. So for you it's like these are all these areas that you're really great at, much better, like in the top 1%. And then there's some areas where in the top 10%, then there's some areas where you're kind of average, and then there's some dimensions in which you're worse than average compared to other people. And that's just true for all of us. And what I like about that is therefore if you take that as the model, you realize that none of these dimensions are you entirely. So I can make a comment like "Lenny, your ax throwing really could use some improvement."

(00:44:48):
And ideally you're not like, "Julie is saying I'm a bad person, my identity is at risk," right? Because it's just one dimension of who you are. But what happens sometimes is that we can get very attached to certain dimensions because we start to think that that's who we are. And I think managers can do that, and clearly individuals on their teams. And when that happens, it starts to get very difficult to have, I think more objective conversations about, okay, what can you get better at? What can get worse at? And so I say all this because I think this framework for me at least, and many people that I've talked to, has helped them realize that somebody can give you feedback or you can be maybe not great at certain dimensions, you can have room to improve, and that's not who you are because you are all of these infinite dimensions in one, and none of them is representative of your true worth as an individual.

(00:45:42):
I'm a big believer that we are all beautiful and worthy, and sure we have all of these skills and we want to improve those skills, but it does not speak to whether we are worthy or not by saying whether we are strong or weak in these skills. And so I think if you can take that and really internalize that, then you can look at yourself a little bit more objectively as a manager, and you can realize that there are areas where you're going to be really strong, there are areas where you have biases, and often they are one and the same. So I'll give an example. People have often told me, I would get this in my performance reviews from managers in the past, like, "Hey Julie, you're really thoughtful. So when you think about something, you have a way to think about it, you've clearly thought about it in depth and you've got these frameworks and all this. That's a great thing.". And then on the flip side, I'll get feedback like, "Well, Julie, you don't really say a lot in a dynamic discussion. You're kind of quiet and you don't really think that quickly on your feet." And what you realize is these are kind of, again two... Because I don't do that and I'm not just off the cuff, that's what allows me to oftentimes be very, very thoughtful, or at least, okay, when I was younger, it's very clear that that particular weakness also very much is speaking to a particular strength, which is I am the kind of person that doesn't always have a snap judgment. I have to really think about it and internalize it and sometimes get to how I feel, and then I can share it and present it in the world.

(00:47:18):
And so just knowing that about me is supremely helpful. Now doesn't mean of course that I can never get better at this thing, but what I often think about is mastery is where we realize that both of these we can get better at, and what we want to do is just figure out in the context, what makes sense to be. So I got this feedback and I'm like, "Cool, one of the things I need to work on, is figuring out how to be more open in person, how to speak a little bit more clearly in person, maybe say things like, 'I don't know exactly how I feel about it yet, but this is what I'm thinking right now,'" if there's still clear tactics that will allow me to be a more effective team member and to do a better job in the context of what I'm trying to do with my team.

(00:48:04):
So I've tried to build those skills, but the meta skill is now being able to step back and say, okay, in certain context it is really important that we move fast and we are decisive and we just do something. And even if it's not perfect, we just kind of have to do it. And if I struggle with that, I should realize that that's an area to improve upon. But there are other contexts in which the right thing to do is actually to take a step back and be very thoughtful and to not rush into decisions.

(00:48:31):
And that's so what I want to get to is not like let's reject this strength or this weakness, but just know that that's where we come from, that naturally, we might be wired in a particular way. Our growth often looks like getting better at doing the opposite, but not rejecting again the thing that we're good at, but rather over time getting to this balance where we can read the context and the situation and know, "Should I lean a little more thoughtful or is this a time where I need to try and be a little more decisive and just share what's on my mind right now?"

Lenny Rachitsky (00:49:04):
I love this advice that things that we are incredible at and have a downside, and oftentimes the feedback we're getting is something we're not great at, there's a good version of that that people appreciate. And I was going to ask you, and I think you answered most of this, but just when you got this feedback of, "Hey Julie, you're not speaking enough in these meetings, you're not contributing quickly enough," it sounds like, so one option is just like, "Okay, cool, that's me, that's how I am, and I'm just going to solve the problem this other way and then just not going to change anything." What I heard you say is, find opportunities where you want to actually change that behavior, even though it doesn't come naturally in specific situations where things are moving fast. I guess just how far do you recommend people push themselves in things they're not great at, versus leaning further into their strength, let's say?

Julie Zhuo (00:49:54):
Oo, I think that's a really great question. So the way I think about it is it's very dependent on what is your goal. So for example, let's say that you are...

Julie Zhuo (00:50:00):
... on what is your goal? So for example, let's say that you are... Let's even take, for example, ICs versus managers. I think often about the pathway of an IC, an individual contributor, as wanting to deepen a craft. You love this thing and you just want to get better and better and better at this very specific skill or this craft, right? So think about in our dimension, infinite... It's like you pick a couple dimensions, "I just want these to be... I want to be the top 0.01%," and that's kind of the pathway of extending it as an IC. Now, if that's your high level goal and you're like, "I want to be able..." Let's say your high level goal is, "I want to be able to do this 10 hours a day because I love it and I want to be able to support myself doing it, meaning I get paid and I have a great job, and I want to have a bunch of impact in the world by doing this thing."

(00:50:53):
So again, you still have goals. Then you have to see, okay, "Does my strategy of just deepening these things, is there a pathway to reach my goals according to that?"

(00:51:03):
And if there is, awesome. Then if someone's like, "Hey, do you want to be a manager?"

(00:51:06):
You're like, "Nope, don't need to because these are my goals and this pathway actually allows me to do that."

(00:51:13):
But if somehow you get to a point where the skill you really want to perfect is not something that may be commercially viable in the world, that's going to somehow allow you to buy the big mansion that you want to buy to support your family, then I think you have to ask yourself, "Okay, so if I just do this, it's not going to cut it. I might actually need to learn some of these other skills in order to be able to fulfill the job that is going to be valuable enough that people are going to pay me a bunch of money at this certain level so that I can afford my mansion."

(00:51:43):
So I just think it has to go back to, what are your goals? And there are cases in which yes, it'll support your goal to do this and to deepen your craft. And there are cases in which it won't. And I think it's important, it's a very individual question for each person. But what I often think suffering is, is when these things are not aligned. So what you want is the giant mansion and all of that, but you're like, "But I also just want to spend on my time perfecting my egg omelet."

(00:52:12):
And then, you're just in this tension place, and it's very hard to feel satisfied and fulfilled because you're a little bit like, "Oh, why doesn't the world value my deep egg omelet skills?"

(00:52:26):
You can [inaudible 00:52:27] egg omelet, you should maybe not do this thing. Or if you want this thing, you may actually need to be better at just egg omelets. Perhaps you need to expand your repertoire of cuisines, and go and build a Michelin star restaurant or something.

Lenny Rachitsky (00:52:39):
This is really good advice. It's not just definitely always work on your weaknesses or don't worry about them, it's if you need to do this thing to achieve this goal that you have, make sure you understand what your goal is. And then is this thing a thing you need to work on? For example, [inaudible 00:52:52] become a VP, you probably need to be really good in big important meetings, and being on the spot, and just not waiting until everything's over and then sharing an email of all your thoughts.

Julie Zhuo (00:53:01):
That's right.

Lenny Rachitsky (00:53:02):
Yeah. For me, I actually went through a period where I was like, "I do not want to get promoted. I'm so happy in this very specific role, just leave me alone." And that path is very different from the skills I need to build to be a manager. And then things changed and then, okay, now these are the things I need to work on.

Julie Zhuo (00:53:17):
Yeah. I love that you knew that about yourself, because I think it's so easy for a young person to go into their career and everyone is telling them, maybe their whole family has been telling them, "You need to level up, you need to get paid more. You need to get that manager title. You need to get a VP."

(00:53:33):
And at a certain point, I think sometimes people opt into this without knowing what they're actually signing up for. What are the trade-offs? And is that really what you want to do? Does that really align with your passions? And of course, sometimes we have to... Again, it's a compromise for us, but we get to design. We get to design what are goals and what's the right pathway. And I go back to, usually when people are unhappy, it's because these things are a little bit out of sync. They want this big thing, but they're not actually excited about what it takes to do that thing, and therefore it's just going to be a mismatch.

Lenny Rachitsky (00:54:09):
And along those lines it sounds like, oh, sure, I can design my life and design my role. But what I find is if you at least first of all know what you'd love and ideally do, and then at least mention that to your manager, it often is a lot more possible than you think.

Julie Zhuo (00:54:26):
A hundred percent. I think it's so important to be... We often also have this mental model like, "Oh, our managers are our judge, and they're going to judge me on whether or not I did well, I should get a promotion, I should be fired."

(00:54:39):
So there's this sometimes fear that people have, but I think in the very best relationships, the manager is like a guide. It's like, look, the manager has a job, and if you understand your manager's job, which is how to get better outcomes from the team, and also you understand what exactly would your manager consider success for the team, it also makes it easier for you to then be like, "Oh, well if I do this project, then that clearly seems like it's a very direct path to creating value for the team. And that also is a kind of project that suits my skills. It's something I'm excited about." You should suggest that to your manager.

(00:55:16):
But the other is true, right? So you would know that if you actually asked your manager, "What is your job and what do you consider success to be, and what is your greatest hopes and dreams?"

(00:55:25):
And then you might be able to help your own career and yourself because you would know that context. And conversely, if you say, "Hey, manager, these are my hopes and dreams. This is what I think I'm good at. I really want to get better at this skill. I really want to get that VP promotion, but I don't know what it entails. Can you tell me, what does it take?"

(00:55:45):
That's a really wonderful conversation as well because then you'll get all of that context, and then you can actually decide whether you want to do it or not. And if you want to, then ask your manager for help, "Okay, if you see opportunities that are going to help me become a better presenter or increase my communication, please tell me." Even better, "If you have feedback for me about communication, I want to hear it, because that's what's going to help me grow in this particular skill."

(00:56:11):
And so, it becomes this collaborative relationship much more so than this almost adversarial, like I'm trying to get you to give me a promotion, and you're trying to get me to work harder. That is not a very good vibe.

Lenny Rachitsky (00:56:28):
It reminds me of a guest post by Ethan Evans that I'll link to that has a really good framework for how to actually do exactly what you're talking about called, The Magic Loop, where it's kind of a framework for figuring out what to work on and how to help your manager see you're capable of stuff and earn that trust.

(00:56:42):
This episode is brought to you by PostHog, the product platform your engineers actually want to use. PostHog has all the tools that founders, developers and product teams need, like product analytics, web analytics, session replays, heat maps, experimentation, surveys, LLM observability, air tracking, and more. Everything PostHog offers comes with a generous free tier that resets every month. More than 90% of customers use PostHog for free. You are going to love working with a team this transparent and technical. You'll see engineers landing pull requests for your issues and their support team provides code level assistance when things get tricky. PostHog lets you have all your data in one place.

(00:57:21):
Beyond analytics events, their data warehouse enables you to sync data from your Postgres database, Stripe, HubSpot, S3, and many more sources. Finally, their new AI product analyst, Max AI helps you get further faster. Get help building complex queries and setting up your account with an expert who's always standing by. Sign up today for free at PostHog.com/Lenny and make sure to tell them Lenny sent you. That's PostHog.com/Lenny.

(00:57:49):
So along the lines of timeless manager, especially new manager advice, you've shared a bunch. Is there anything else that you think is really important, really interesting, valuable?

Julie Zhuo (00:57:59):
Feedback is one of the other topics that I am super, duper passionate about. And my general impression for both myself, everyone I've worked with, is that we don't value feedback enough or we don't think about it enough. Again, companies have these performance cycles, and so we're all like, yes, every six months we're going to go and do these reviews. That's when I'll get feedback. But feedback really, in my mind, ideally, should be a daily practice. Because the thing that matters for us in the long run as a team is how quickly are we getting better? So a team that just gets 1% better every week compared to a team that gets 1% better a month, even if they start off at a much lower baseline, is going to outperform in a very short amount of time the team that doesn't get better.

(00:58:50):
And so, what is the best tool for us to get better? It is feedback. And what I think about in feedback, it's very similar to what we said earlier about data metrics. It's essentially trying to put your hypotheses and test them against reality. So as an example, maybe I have this perception right now that I am a positive and engaging speaker. So, I have this sense that I'm smiling and I'm very engaging, and I'm telling great stories, but is that really true? I don't know. The reality is that I'm often biased, and we know these psychological effects where sometimes the Dunning-Kruger effect, people think they're way more expert at something than they actually are. You ask people, "Hey, are you a better than average driver?"

(00:59:35):
And it's like 70 or 80% of people, "Yes, I'm better than average."

(00:59:38):
How could that possibly be? We have biases. And imposter syndrome is a bias on the other side, it's like me feeling, "Oh, I suck. I don't actually belong here." Whereas, that also is a bias. It may not actually be true. In fact, I might very well be here and other people value my contribution.

(00:59:56):
So we are just wildly out of sync a lot of times in our perceptions of ourselves, our strengths, our weaknesses, what's going on. And the way that we're going to understand and truly get better is we need other people to reflect back what is actually their truth. And the way I think about it is like, I'm going to ask you for feedback after this podcast episode and you're going to tell me something. And what you're going to do is you're going to give me a gift. Because it'll be a gift of reflecting something back of what you see that I can't see. Just like if I have a leaf in the back of my head, I can't see that. And so if you're telling me, "Hey, Julie, you have a leaf."

(01:00:33):
"Oh, wow, thank you." Okay, maybe I can get rid of the leaf or whatnot. But that is what feedback is. It is essentially reflection back. It helps us calibrate to reality, and it allows me to get this information about whether or not I'm moving in the direction of my goals.

Lenny Rachitsky (01:00:50):
I love that. I completely agree. The challenge for most people, as you know, is giving feedback that people receive and don't feel defensive about, and then receiving feedback and not being like, "Oh, no, they don't know. They don't know anything. How dare they say this about me?"

(01:01:06):
Could you give us maybe a tip or two for delivering feedback well and for receiving feedback well? And maybe even just seeking, how do you get more feedback? This all makes a lot of sense. Most of the time people don't get any feedback.

Julie Zhuo (01:01:18):
The best way... The first tip on getting feedback or delivering hard feedback is first go and actually establish that our relationship is one in which we value each other's contribution, we want to help each other grow, and therefore we're going to be the kind of people that want to give feedback to each other every week. So when you first start working with someone, don't wait until something bad has happened [inaudible 01:01:42] given feedback, because that's already a pressurized situation. Start by saying, "Hey, really excited to work with you. I feel like our best collaboration is I want you to help me get better. I think I'm good at this stuff. I'm not so good at this stuff. What about you? Okay, you think you're good at this stuff? How about we just work together and we just help each other get better at these things? And the way we're going to do that is, all feedback is open. I want you to tell me everything. Ideally, you're going to then say, 'Yeah, I want you to tell me everything.'" And we've already established that.

Lenny Rachitsky (01:02:10):
And this is colleagues or manager or all colleagues?

Julie Zhuo (01:02:13):
It's like everyone. It's like people you're dating, it's like your children. It can be with everyone, just establishing what kind of relationship do we want to have? I think most people want to opt into a relationship where you can be close, you can be tight with one another. You can say things to one another and not have to hide behind... I think most people will opt into it, and if you opt into it, everything gets easier down the road. So the first thing is get everyone to opt in that this is the kind of relationship that we want to have.

Lenny Rachitsky (01:02:41):
One trickle throughout that I've heard that worked really well along these same lines is asking people, "Do you prefer feedback in the moment or do you prefer it kind of every month or every week or something like that?"

(01:02:53):
And everyone's like, "No, no in the moment and just tell me as soon as something happens."

(01:02:57):
And then that gives you that freedom to just, " Okay, yeah, let me give you feedback here."

Julie Zhuo (01:03:09):
So if you get people to opt in, "Yes, I want us to have a great relationship. I want us to help each other get better. I want feedback." That's 60% of the hard part of delivering difficult feedback later on.

(01:03:13):
Then the second tactic I will say is that when you actually give the feedback, it helps a lot. First, you have to check, "Am I actually giving this feedback because it's in the spirit of trying to help one another?" And if the answer is yes, then we've moved from 60% to 80%, it's going to go well.

(01:03:37):
But what can often happen is something happens. You do something, it triggers me, because I don't know, I had a bad experience about that type of thing before. And so, I'm kind of feeling mad and I want to be right. If my real rationale for why I want to give you feedback is I want to validate myself, I want to be right, I want to tell you you're wrong, I want to punish you, it's not going to go well. It's just already there. There's no way you can deliver it, unless you're a tremendous actor. It's just not going to go well. So you have to first check your intention.

(01:04:16):
But if you've done that, you're like, "No, no, no. I thought about it. I'm calm now. I'm not seeing red. I really think that Lenny is just not aware that when he says this, it makes me and other people feel left out," or whatever it is, right? Then I need to be able to give it to you.

(01:04:33):
And so usually then if you're like, "Okay, now I might be nervous because I don't want to offend you. I really value our relationship. How am I going to tell you. I don't want you to get defensive?"

(01:04:44):
Then the third tactic is, just say that out loud. If I sit down with you and I say, "Lenny, I'm so nervous right now. I want to give you some feedback and I'm really worried that it's going to impact our relationship, and I so value our relationship and I don't want that to happen. But I also feel like it's just going to help you to hear it if you can."

(01:05:06):
That does so much of the work of... It's humanizing. You're going to realize that I'm going out on the limb, I'm being really vulnerable, and likely you're going to hear that so much more than if I just find a way to drop it, just lobby it over because it's so difficult. Just actually lean into the fact that it is difficult and expose that because that builds a lot of human connection.

Lenny Rachitsky (01:05:33):
This is amazing advice. Very tactical. Okay, is there anything else? So we've talked about a bunch of timeless pieces of manager wisdom, things that people need to hear, especially as new managers. Is there anything else that you think is really important that you think people are just not fully grokking for being great managers?

Julie Zhuo (01:05:53):
I think the idea of win-win, I think about that all the time in my mind. And I go back to it, because I think that often we have the story in our heads that sometimes things are adversarial. As a manager, I'm trying to get people to be more productive, so I'm trying to get them to do a thing that maybe they don't want to do. I'm going to try and get them to work harder or I'm going to somehow put more pressure on them. If you start thinking like that, that's not a win-win way to be thinking, right? That's like you saying, "My getting better outcomes has to come at the expense of somebody else losing something."

(01:06:33):
And I think if you start thinking like that, it's very difficult to come up with a strategy or to truly be successful. But if you say, "Look, actually, my job is to figure out how to create win-wins." So I actually don't want somebody over the long run to feel like what I've done is just create a ton of pressure for them and now they're super burnt out, real quick, because that's not good for our team, that's not good for me, that's not good for our long-term relationship. How do we find the solution that can be a win-win? And I think if you think like that, a lot of things get easier. So for example, with new managers, I think this is true for me, too, the first time I had to tell someone that they shouldn't be a part of this team was extremely fraught for me. And the main reason was because I'm putting myself in their shoes, and I'm imagining that this is truly horrible, and I've just done a huge disservice to this person, and that's the most awful thing.

(01:07:32):
But there's another way to look at it, which is, hey, if there's persons on the team, they probably want to be successful. They want to do great work, they want to be valued, they want to grow their career. If this is not the place for them, because it doesn't align with their true interests and the things that are going to help them be successful is just not the thing that they either want to do or can do at this point, it doesn't do that person any good for me to somehow try to continue to make it. It's actually going to be miserable. I'm going back to prolonging that misery state.

(01:08:06):
And so, sometimes a win-win thing is to just say, "Look, it's not working, and I respect and value you so much that I know you want to do something that you can be proud of and you can grow in, and that's going to be really valued. And right here, what we got, this isn't it."

(01:08:22):
That's like a win-win way of looking at the situation, not a like, "Oh, my firing them is just definitely going to be a horrible..."

(01:08:31):
I'm not trying to say it's not going to be hard, obviously it's hard, but it's in the mentality and the mental model I think makes all the difference. Because it's going to be different in the way that I convey it to them. It's going to be different and why this actually in the grander scheme of things may be great, and it's going to reduce this adversarial feeling where they're now going to see me as an enemy or somebody with all this power who's making choices that impact them and they feel powerless. It has to be a collaboration. And I think if it's not win-win... And I could be wrong. I would say I don't think it's right. The person could actually say, "No, you're wrong." And that would actually be great information, because then maybe we can go back and we can find a way to make it win-win.

Lenny Rachitsky (01:09:12):
Yeah, I was just going to say, they have to believe this. You can't just make it sound like this, "Here's the win you're getting let go. It's a huge win for you." But in reality, the way you phrased it, it is actually almost always true, "This is just not a place that you'll be happy and succeed at, and it's better you go do something else."

Julie Zhuo (01:09:27):
Yeah.

Lenny Rachitsky (01:09:28):
Okay. I'm going to keep fishing in this pool to see what else we got, but when we run out, let me know. Is there anything else that you think people should know, should hear, especially new managers that they're still not fully getting?

Julie Zhuo (01:09:41):
I think being aware of your own energy and conviction is really, really important. So a lot of these themes, as you can see, go back to, you have to first understand this about yourself and have the right mindset, and when you do, it becomes much easier to be able to be impactful with other people. So this is another one. I think it's very difficult for managers to be able... We talked a lot about the three pillars of what are the major tools of a manager. The first is people. And so, we talked a lot about the importance of dimensionality and feedback and helping reflect and grow people.

(01:10:21):
I think the second one is around purpose. Purpose is like, "What are we here to do? What's our North Star?"

(01:10:28):
And I think it's very hard to actually convey that if you don't have conviction yourself. And so watching your conviction is really important, particularly since a lot of people who are managers, you often start out not as the founder of the CEO of the company, but you might be a middle manager. So in some ways, you didn't create the vision, but you are in some ways expected to execute it or take a piece of it and do it. And I find that sometimes what new managers don't pay attention to enough is what is their true belief. They feel like they might have to be a soldier, so they just get orders and they have to execute it. But it really makes a difference if they themselves have gone through the work of thinking through, "Wait, why are we doing this? Do I believe this strategy? Does it make sense or not?"

(01:11:18):
And if it doesn't make sense, to go and actually have the conversation with their manager or whoever else, just so they can get to alignment on, "I really believe in what I'm doing."

(01:11:29):
Because if you don't really believe in what you're doing or you're just parroting the thing that got passed through the organization, it's very hard for you to then be able to help other people see what that magic is or to be actually really effective as a person who can hold that vision and that purpose. So I just think you have to really check in with yourself on like, "Wait, I know we're told to do this and this is what we have to do, but how do we really feel about it?"

(01:11:56):
Because if you don't feel good about it, then it's not going to be very likely that the project's going to succeed. I can tell you right now, every single manager I've ever managed where they're like, "I don't really think this is a good idea," there's no case where I can think of where the project somehow turned out to be wildly successful.

Lenny Rachitsky (01:12:13):
This is such a classic challenge of managers, is getting things done that you don't really agree with. And I can't help but ask you for advice on someone that isn't in that place of just, "Okay, we have this feature our CEO's prioritizing. This is not a good idea, but I need to have a brave face and not make it sound like I'm just being told what to do and I'm just reporting orders. I don't believe in this." You don't want to do that. You become a terrible unsuccessful manager and people lose trust in you. What's your advice to folks that are in that place of just how to find that balance?

Julie Zhuo (01:12:44):
So I think, first, if you feel that way, you got to actually find a way to get it out and engage in dialogue. So if you're like, "My manager told me to do this, I think it's a terrible idea," you've got to talk to your manager about it or you've got to talk to the CEO or whoever and feel... Because once you engage in a dialogue, what will often happen is you'll learn more, you'll have new information, you'll have new assumptions, and maybe you'll have influenced a project in some manner. But often, the more you can learn about, "Okay, why did some other smart people feel like we should do this? And what parts of it do I believe and what parts am I more skeptical about?"

(01:13:20):
You can probably decompose it from a blanket it's good or bad to like, "Okay, this is a hypothesis, this is a hypothesis, this is a hypothesis. I might kind of believe this one. The reason I don't like the proposal, I don't believe this particular hypothesis, but I believe these other ones."

(01:13:36):
And so, when you can start to get one level deeper into breaking it down into a set of assumptions, that makes it much easier, because then likely find something that you do kind of resonate with. And you might be able to then steer things like, "Okay, if that hypothesis doesn't... I believe in disagree and commit, but now we can be very specific. We can isolate the thing that..."

(01:13:59):
And what we can also often do is like, "Okay, the reason I didn't like this proposal is because I believe that this assumption is wrong."

(01:14:07):
I'm going to come up with a really stupid example. But your suggestion is, "I know we have a great idea. We're going to go and put a lemonade stand on every block. And my core assumption is people do not like lemonade. That's not the hot beverage right now. And so therefore, I think this is a stupid plan."

(01:14:25):
But if I talk to you about it and you're like, "No, no, this is the core assumption we disagree on."

(01:14:29):
Likely what starts to unfold is like, "Well, can we get some data? Can we get some information? Is there a quicker way to validate whether people like lemonade? Perhaps we should just test it in one market before we go and open up the lemonade stands across the entire 50 states."

(01:14:45):
And so what happens is we can likely get to the actual specific area and come up with something. And then, if I have to now share with my team, We're going to try this hypothesis. I'm not sure how I feel about it, but I actually do think... I don't know for sure and our CEO seems to think this is... But we're just going to test it."

Julie Zhuo (01:15:00):
For sure, and our CEO seems to think this is... But we're just going to test it, and we're going to do the test in a way where... That's what we want to find out, is do 18 to 25-year-olds love lemonade if we put them on these neighborhood college campuses? It becomes very specific and everyone's like, "Well, yeah, I don't know for sure, but I'm happy to go in, and test that, and commit to it."

Lenny Rachitsky (01:15:24):
This is such a good advice, and there's also, you could layer on, "Here's the things I do agree with and believe. Here's the ways that I see this as totally right. Here's the piece that I'm not so sure about, but that's why we're going to run this test, and here's why it's the smallest version of this test and why it's a great idea just to figure it out." We'll show them. You probably don't want to say that. As you give this answer, it's so interesting, I almost want to do a whole new episode with you later of just common conundrums managers have, challenges that every manager runs into that are really difficult to figure out on the spot. We could save that for the future. Okay, I'm going to take us to a couple of recurring themes on this podcast, occasional recurring that every episode corners that we take guests to.

(01:16:07):
The first is I want to take us to AI corner. What I like to do in AI corner is ask, what's a way that you've figured out to use AI in your work or your life that's just really interesting, really useful?

Julie Zhuo (01:16:19):
Well, I already shared a lot about education and learning, but I'll share maybe a more fun story. It's my kid's birthdays. One of them just passed. My middle son's birthday is in two weeks and my daughter's birthday is in a month.

Lenny Rachitsky (01:16:32):
By the way, the birthday just passed. The kid didn't pass.

Julie Zhuo (01:16:34):
Okay. Yes, the birthday passed.

Lenny Rachitsky (01:16:35):
[inaudible 01:16:35].

Julie Zhuo (01:16:35):
That's right, that's right. The birthday passed, my kid's birthday. One of my goals this year was to try and build them something, so give them a present that has me going back to being the IC and making something for them. AI makes this really fun, and so just from my youngest son who was six years old, this is an idea that I stole from Eric Antonow, if you know Eric. Have you had him on your podcast?

Lenny Rachitsky (01:16:59):
I haven't, I am trying to. He actually sent me the... What is it? The-

Julie Zhuo (01:16:59):
Yes, yes.

Lenny Rachitsky (01:17:06):
What is it called? The metha-

Julie Zhuo (01:17:06):
Methaphone?

Lenny Rachitsky (01:17:06):
Methaphone.

Julie Zhuo (01:17:06):
Yes.

Lenny Rachitsky (01:17:06):
Methaphone, check this out.

Julie Zhuo (01:17:08):
Yeah, yes.

Lenny Rachitsky (01:17:11):
It's like instead of holding the phone in your pocket, you hold this thing, and then you walk around with it and everyone's like, "What the hell is that?" Methaphone.

Julie Zhuo (01:17:16):
Yeah. I, too, am the proud owner of a methaphone and the next version upgrades with the little stickers, but-

Lenny Rachitsky (01:17:23):
No, I don't have that one yet.

Julie Zhuo (01:17:24):
... Eric is great. You should definitely have him on your... He's such a creative character. One time, I saw him with a parrot on his shoulder, and I was like, "Why do you have a parrot on your shoulder?"

(01:17:35):
He's like, "Well, you can talk to my parrot. It's a talking parrot," and then I spoke to the parrot and the parrot spoke back to me. What had happened is that he had hooked up a microphone, he surgically went into the parrot and added a microphone, a speaker, and connected it to voice mode on ChatGPT so that... It spoken I think like a pirate voice.

(01:17:55):
I was like, "This is the best idea." My six-year-old son is really into raccoons. He has a huge amount of raccoon stuffies. I was like, "I want a raccoon that can talk to him," so I made that using the Eric Antonow method, but it was great. It was a huge hit. Now, my middle son's birthday's coming up, and he is really into parody. He loves video games, so Minecraft, but what he often listens to on his Alexa are these parody songs. It'll be like Justin Bieber's hit or Gangnam Style, but they've changed the lyrics so it becomes a video game parody of some video game that he's playing, and they're horribly sung. They're like off-tune, it's just like some person who produced it. I was like, "Well, if he doesn't seem to mind off-key singing, I'm going to create him an album of video game parody songs, and I'm going to create an..."

(01:18:47):
I created an app on Replit, and what it does is you just give it a song. This is Justin Bieber's Baby and you link to a Spotify song, and I give him some context like, "Oh, Locke likes playing Kingdom Rush right now. We have an inside joke about the gargoyles being free money." Whatever it is, I just give it a bunch of context. I'm like, "Write me a song that just personalizes it and it's a parody of this particular video game." It writes me the lyrics. It's pretty good at doing this. It's pretty high quality. Again, it does it according to the beats of the music, and then I just sing it and record it, and then I got myself a song, so I'm creating an album of this, which I'm going to give to him. He's not going to hear this podcast, so no one spoil it to him. I think this is going to go publish after his birthday, but I'm very excited about this.

Lenny Rachitsky (01:19:34):
Wait, so you're going to be the one singing the song?

Julie Zhuo (01:19:37):
Yes, yes.

Lenny Rachitsky (01:19:37):
I thought you were going to use Suna or some AI thing to actually sing it.

Julie Zhuo (01:19:40):
No, I think I'm going to sing it myself.

Lenny Rachitsky (01:19:41):
Wow.

Julie Zhuo (01:19:43):
All of this made it so easy. All I have to do is just record. Again, I'm not a very good singer, but it doesn't turn him off to hear off-key singing.

Lenny Rachitsky (01:19:54):
Yeah. Wow, that is so beautiful. This gave me so many ideas for gifts I can give to kids in my life, and I just love how AI is making it, I don't know, easier to be a parent and, in some ways, more delightful. These are awesome examples. Okay, I'm going to take us to a different corner, contrarian corner. What's something that you believe that most other people don't, people would disagree with?

Julie Zhuo (01:20:20):
I believe that there's infinity in every direction. That makes me pretty contrarian on pretty much everything that anyone says. If someone says something like on Twitter, I sometimes play this game with myself, which is in what context would that actually not be true? I think the reality is that the world is so, or at least my reality and my understanding of the reality, is that the world is just infinitely complex. For example, if my kids say something like going outside is boring, or taking a walk is boring, or doing something is boring, my general response will be, "Well, it's because you're not seeing the infinity that's in that direction."

(01:21:05):
Even, for example, something really mundane like staring at a blank wall, I think that you can make that actually deeply, deeply interesting, because you can use that as an opportunity to go into your own mind and to figure out how you can make time pass, or you can meditate on the existence or meditate on your breath, or just be grateful for the purpose of being alive. Two people, one person you can say, "Sit in front of a wall for an hour," and, like my kid, they will super complain and be like, "This is the worst thing ever," but you can put somebody else like a monk and they'll have a wonderful experience. It's not really about the environment or the wall. It's really about how we see it and whether we can find the thing that is deep, and rich, and infinite in that direction.

Lenny Rachitsky (01:21:56):
Wow, these are some deep answers. This is very, I don't know, Buddhist, very mindfulness-oriented. I did a retreat once and their advice was just anytime you're bored, just notice all the things that are going on around you. What does your seat feel like right now? What does the air feel like? What are you hearing right now? It's exactly what you're saying, there's infinite things to pay attention to and keep you interested. It's hard.

Julie Zhuo (01:21:56):
It's hard.

Lenny Rachitsky (01:22:21):
Hard to actually do that for a long time and practice. That's why it's a practice.

Julie Zhuo (01:22:24):
That's why it's a practice. But I repeat that to myself, because oftentimes, if I have a bad experience feeling a certain way, it helps me to realize that it's often probably in my head. It's because I haven't gained the skills to be able to see the richness and infinity in that... I can maybe work on that. That feels better than feeling like, "Oh, I'm a victim of my circumstances. This thing happened to me," and that's so awful but not powerless, I can't do anything about it. That, to me, is a worse feeling than the alternative, which is I just don't have the skill yet. I can recognize it for what it is. I don't have the skill yet, but I can grow. I can maybe get better at it. There is a person out there who had the same situation as me and feels much more positively than I do, and don't I want to be more like that person?

Lenny Rachitsky (01:23:15):
It's such a beautiful circle back to our very first episode, which a lot of it was on imposter syndrome and overcoming that and your story there, so I love that that's maybe a way to close this conversation. But before we do that and before we get to our very exciting lightning ground, is there anything else that you wanted to mention, or share, or double down on that we've talked about?

Julie Zhuo (01:23:35):
I just want to say thank you. Honestly, I'm so inspired by the work that you do. I know we've known each other for quite a while, and I just think from the very first idea that you had for this newsletter, for the podcast, has been incredible, and I think the world gets so much from it. I'm sure you hear that a lot, but I am very grateful.

Lenny Rachitsky (01:23:52):
Well, I really appreciate that, and I say this every time we do a chat, is just this wouldn't have been possible without you, Julie. I was inspired by your longtime newsletter, The Looking Glass. Essentially, my idea was what if I do this for product? I started on Medium just like you did, and then I moved to Substack, and then it's like, "What if I charge for this?" That worked, and then I'm like, "What if I do a podcast?" and then that worked. But it all began with your concept, so thank you, Julie.

Julie Zhuo (01:24:22):
Yeah. I think you do it with so much kindness and curiosity as you always have, so I love that.

Lenny Rachitsky (01:24:27):
That's just who I am. Well, with that, we have reached our very exciting lighting round. I've got five questions for you. Are you ready?

Julie Zhuo (01:24:34):
I'm ready.

Lenny Rachitsky (01:24:36):
What are two or three books that you find yourself recommending most to other people?

Julie Zhuo (01:24:39):
The first is Zen and the Art of Motorcycle Maintenance. I absolutely love that book. It's beautifully written. It's so deep. My whole philosophy around quality is beautifully... A lot of it comes from that book, the idea and even all the stuff that we talked about change. What does it mean to be at that forefront of change and dynamic quality? I think he just talks about so beautifully and so masterfully in that book. Old classic, but I try to reread it every few years or so. Second is Conscious Business. It is my favorite management book. It's a little bit of a sleeper head because I actually end up recommending this one far more than my own book.

Lenny Rachitsky (01:25:23):
Oh, wow.

Julie Zhuo (01:25:24):
I read this one after I wrote my book, and I always tell people that if I read it before, I'm not sure I would've written my book, because I would've been like, "Conscious Business is really the book that really, really so much resonates." Many of the things I talked about, this idea of win-win, idea of being a player, not a victim, and how to think about work, not just it's a job but how do you really think about aligning it with your own personal values and what you want to do in the world, I think that this book really speaks to that so beautifully. It is also very tactical. It's got a lot of really wonderful examples. I will tell people, the cover isn't very attractive, and I think that if you judge a book by its cover, this seems very corporate-y. The title also seems like, "What conscious business?" and the first chapter is a little bit more technical. But if you just get past it and get into chapter two and you start with examples of the soccer team, it's just the best management book.

Lenny Rachitsky (01:26:23):
That is good advice to get people over the hump when they look for it. They're like, "Okay, okay, I'm going to stick with it."

Julie Zhuo (01:26:28):
Yes. Okay, third book. I love the book Good Inside by Dr. Becky. It's a parenting book and it's a very wildly popular parenting book, so I really recommend it to all parents, but I also think it's just a wonderful book for thinking about relationships, because parenting is that. It's like a very, very deep and intense relationship and interaction that you have with another human being, and there's so many things that I read in parenting books, including Good Inside by Dr. Becky, that I think could just as well been a management or a team leadership book.

Lenny Rachitsky (01:27:03):
I am thinking about trying to ask Dr. Becky to come on the podcast. I feel like there could be a lot of synergy exactly for that reason. She uses this term sturdy, which inspired maybe your bullet tree process.

Julie Zhuo (01:27:16):
Oh, yeah, I probably got it... I think she talks a lot about sturdiness and that just incepted right in here.

Lenny Rachitsky (01:27:20):
Yes. Yeah. Her whole thing is being a sturdy parent. Strong but flexible, I imagine. Yeah. I love her and I love her stuff. I watch all her videos on TikTok and Emily Oster. Okay, next question. Is there a movie or TV show you recently enjoyed?

Julie Zhuo (01:27:36):
I have not watched anything. I have no good answer for you. I think the only thing I watched this year was a rewatch of La La Land, which I do truly love.

Lenny Rachitsky (01:27:36):
So delightful. Okay. Is there a product you recently discovered that you really love?

Julie Zhuo (01:27:49):
I don't think there's anything too new. I love Granola, I love Replit. I've used all of the different coding lamps. Cursor is big on me for now. I just got a Matic Robot. I think that's been really delightful so far, at least the setup. I haven't used it long, long term, but it's the setup, the way that it worked. The fact that it had little stickers and you could make it into a dog or a cat was a wonderful experience.

Lenny Rachitsky (01:28:17):
The Matic Robot, willing to it, I am also a huge fan. I'm not an investor that's... Essentially, Waymo meets Roomba. For folks that don't anything about it, it's like a very sophisticated robot vacuum built by AI vision people.

Julie Zhuo (01:28:32):
Oh, I just thought of one more as well, the Limitless Pendant. Disclaimer, I am a small investor in Limitless, but what I love about it is that... Okay. It's a pendant, you wear it, and it just records everything that's going on, and later it summarizes things and it gives you feedback. I don't usually wear it out because I find that maybe other people feel awkward that I'm recording everything, I usually try and get people's permission, but I do wear it at home when I'm with my kids, and one of the best things that the pendant does is it gives me feedback on parenting.

Lenny Rachitsky (01:29:04):
What? Automatically or run into ChatGPT?

Julie Zhuo (01:29:08):
No, automatically. There's an app and it will sometimes notify me, or if I check it, it'll... Or I can also engage with Ask It, but what it does is essentially... It's like Granola, but for your life in terms of capturing everything, summarizing it, and then giving you tips and feedback. It's said things like, "Hey, there was that time you were talking about the game and you cut your kid off a lot. Maybe next time, think about letting them speak fully and listening better."

Lenny Rachitsky (01:29:34):
The app itself natively does that?

Julie Zhuo (01:29:36):
Yeah.

Lenny Rachitsky (01:29:37):
I did not know that, because I have one. I haven't used it much recently. That is incredible. I wonder if it gives you relationship advice too if you're talking to your partner. I wonder how it even knows.

Julie Zhuo (01:29:46):
Yeah. It did a pretty good job of inferring. I think I said person two, but it was kind of eye-opening for me.

Lenny Rachitsky (01:29:57):
Incredible. There's a recent episode of our How I AI podcast, our sister podcast, where somebody wears that in their meetings with their CEO and automatically turns what they're asking for into a prototype from the meeting notes, and then sales teams can start showing it to people to see if they're interested. How about that?

Julie Zhuo (01:30:19):
That's awesome. That is super cool.

Lenny Rachitsky (01:30:20):
Holy moly. [inaudible 01:30:22], what is even happening? Okay, I'll keep going. Do you have a favorite life motto that you find yourself repeating to yourself, sharing with others?

Julie Zhuo (01:30:30):
I like make it happen. Just a reminder that, at the end of the day, we could have a lot of motion. Maybe this is another one that I really like. I think about this poster. It used to be a poster at Facebook that says "don't mistake Motion for progress". There's this idea of be the change We want to be in the world, I guess is other ways of saying the same thing, which is I can do things. We can all do things. We have better and better tools to go out there and make things happen. Make it happen.

Lenny Rachitsky (01:30:59):
The common meme on Twitter, you can just do things.

Julie Zhuo (01:31:02):
Yes.

Lenny Rachitsky (01:31:03):
Final question. I like to ask this question to folks that are really deep in AI, and been working with AI, and getting a sense of where things are going. Is there something that you teach your kids or teaching your kids, think about encouraging them to learn, knowing that AI is going to be a big part of their life?

Julie Zhuo (01:31:20):
Emotional regulation is still really, really, really important. That's probably the thing that I think about the most in terms of what I want my kids to learn. I want my kids to be able to introspect, to have a better understanding of where their state of mind is, because we're still human. We still have the same hardware that humans have had for thousands of years, and that's not changing even as the tools and the environment around us change, and so I feel that you have to really understand yourself and you have to understand what's going on for you and where you are biased and where you're not, because AI can make it... This is my great fear, is that it makes things so much more comfortable. I have this great fear that this has been the trajectory that we've been on with technology. This is, again, going back to every strength is a weakness.

(01:32:05):
Technology makes things a lot easier. That's why we invent, that's why we create. Human race has always been about trying to better our circumstances and, in some ways, control our destiny, control our future. But at the same time, all of that control gets to a point where we have so many shortcuts in our lives and you can shortcut a lot of things. You can shortcut relationships, you can shortcut hard feelings, because now you can just watch TikTok instead of actually dealing with a very difficult emotion or tension that you had with a colleague, or with your partner, or with your children. AI makes it even, I think, more attractive, because now there's a person or there's a thing that can be very, very personalized, and if you're like, "Oh, I want a distraction, I want to do something," you got that.

(01:32:51):
But how do we actually still learn to sit with what is our true biology that's not changing, and how do we continue to be the kind of people that want to take on the freedom of doing challenging things? Because I find that if we don't do challenging things, we suffer. We suffer in a different way, and so, to me, true freedom is you can pick the things that are hard and you can feel pride in becoming the thing that you want to be. It's not forced upon you. It's not for survival's sake anymore, but you still have to pick. I want to figure out for my children the fact that it is really important to still find the challenge. Yes, you can use AI to do that, but really, don't think about it as a shortcut tool, because if that's the case, I don't actually think that they're going to be able to become the kind of people they want to be in the world.

Lenny Rachitsky (01:33:41):
What a beautiful way to end this conversation. Julie, it feels like this is just some kind of huge milestone of this podcast. Just like having you back three years later, it's like, I don't know, a chapter in the journey. I appreciate you coming back. I appreciate you sharing all this wisdom with us. Two final questions. Where can folks find you online if they want to reach out and maybe chat about maybe Sundial, maybe whatever else you're up to, and then how can listeners be useful to you?

Julie Zhuo (01:34:06):
Well, I would love to work with people who are at companies building really cool things and want better answers to how we build better, and so if you think your company would be interested in working with us at Sundial and figuring out how do we make every single decision maker into their own expert analyst, please reach out. That's one area, sundial@sundial.so. I am on X, so I've been tweeting a lot more, sharing thoughts. Going back to that skill of practicing, just share what's on your mind.

(01:34:40):
But for the long form stuff, I have my blog, The Looking Glass. It's on Substack. I share articles and thoughts about AI, product building, leadership periodically, and then, of course, I have my book, the revised edition with two additional chapters. One is around managing remotely and the other one is around managing in a downturn or managing in difficult change scenarios. That will be coming out in two weeks' time. The new content will be in the paperback. That's important. I'll send you a version of this when I get a copy myself, Lenny-

Lenny Rachitsky (01:35:15):
Sweet.

Julie Zhuo (01:35:16):
... but the paperback has a gradient type of cover. The hardback will eventually get the new content, but it just takes a while to phase out from all of the different retailers, so if you buy one, I cannot guarantee that it's going to have the new content. But certainly, the Kindle and the paperback will have all of the new content.

Lenny Rachitsky (01:35:33):
Just for the publish day, because this might come out later, what's the date that's coming up just for folks?

Julie Zhuo (01:35:37):
September 9th.

Lenny Rachitsky (01:35:40):
Okay, amazing. I think it'll be out by the time this is out, so go buy it. I imagine available on Amazon, all your local retailers.

Julie Zhuo (01:35:46):
Yes, yes.

Lenny Rachitsky (01:35:47):
Amazing. Julie, thank you so much for being here.

Julie Zhuo (01:35:49):
Thank you so much, Lenny. This was so fun. I hope to be back in another three years or whatever the next chapter is.

Lenny Rachitsky (01:35:56):
Hopefully sooner. Bye, everyone.

Julie Zhuo (01:35:58):
Bye.

Lenny Rachitsky (01:36:00):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## An inside look at Xs Community Notes | Keith Coleman & Jay Baxter
**Guest:** Keith Coleman & Jay Baxter  
**Published:** 2025-02-27  
**YouTube:** https://www.youtube.com/watch?v=8dgyqYHLcCI  
**Tags:** growth, acquisition, okrs, roadmap, iteration, experimentation, analytics, hiring, management, strategy  

# An inside look at Xs Community Notes | Keith Coleman & Jay Baxter

## Transcript

Lenny Rachitsky (00:00:00):
The work that you guys do has had such a tremendous impact on the way the world works. I want to start with just giving people a brief understanding of what is Community Notes.

Keith Coleman (00:00:09):
Someone on X can see a post. If they think it's misleading, they can propose a note that they think other people might find informative. Other people can then rate that note.

Jay Baxter (00:00:18):
We actually look for agreement from people who have disagreed in the past. And what we see is when people actually have that sort of surprising agreement, that's what makes the notes so neutral and accurate and well- written, really, overall.

Lenny Rachitsky (00:00:31):
There's many people that are very polarized. How do you deal with people that are super anti-vax, super Jan 6?

Keith Coleman (00:00:36):
One philosophical thing that's important is that we want all of humanity to participate and sometimes people are surprised by that. We have all of humanity. We then have the data to understand what notes will be helpful to actual humanity. Every post is eligible for notes. We shouldn't exempt Elon. We shouldn't exempt government figures. We should be like everyone... Even advertisers can get notes.

Jay Baxter (00:00:58):
There have been external studies run by people totally independent of us who have found that if you take a post with or without a Community Note, that actually people's agreement with the core claims in the post does change if they see it with a note versus without.

Lenny Rachitsky (00:01:13):
Is there anything else along the lines of just working for Elon within an org Elon runs that might surprise people?

Keith Coleman (00:01:18):
If I were to start a company in that company, it would be even leaner than I would've made it before. I've been amazed with just how much the team is able to accomplish with a small group and I think because of a small group-

Lenny Rachitsky (00:01:33):
Today, my guests are Keith Coleman, Product Lead for Community Notes, and Jay Baxter, Founding ML Engineer and Researcher for Community Notes. This conversation may be my newest favorite podcast episode so far. Community Notes is one of the most impactful and clever and, also, underappreciated products in the world right now.

(00:01:52):
If you ever use X/Twitter and you see a note underneath a tweet correcting the misinformation in that tweet, that is Community Notes. I've never heard a deep dive into the story behind the product and the team that built it and I'm excited to bring you just that. We get into the surprising origin story of the product, how the algorithm actually works, how the algorithm emerged out of an internal contest within Twitter, the principles behind Community Notes, and why staying true to them has been so key to its success. Also, how it survived four different leaders, including Elon and Jack, and why it's now a big part of the solution to solving misinformation on the internet. Including recently being adopted by Meta as their main fact-checking tool. This is an incredibly special episode and I'm so excited to bring it to you.

(00:02:36):
If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. Also, if you become a subscriber of my newsletter, you now get a year free of Notion and Superhuman and Granola and Linear and Perplexity Pro. Check that out at lennysnewsletter.com.

(00:02:51):
With that, I bring you Keith Coleman and Jay Baxter. This episode is brought to you by WorkOS. If you're building a SaaS app, at some point, your customers will start asking for enterprise features like SAML Authentication and SCIM Provisioning. That's where WorkOS comes in, making it fast and painless to add enterprise features to your app. Their APIs are easy to understand so that you can ship quickly and get back to building other features.

(00:03:19):
Today, hundreds of companies are already powered by WorkOS. Including ones you probably know like Vercel, Webflow, and Loom. WorkOS also recently acquired Warrant, the Fine Grain Authorization service. Warrant's product is based on a groundbreaking authorization system called Zanzibar, which was originally designed for Google to power Google Docs and YouTube. This enables fast authorization checks at enormous scale while maintaining a flexible model that can be adapted to even the most complex use cases.

(00:03:51):
If you're currently looking to build role-based access control or other enterprise features like single sign-on, SCIM, or user management, you should consider WorkOS. It's a drop-in replacement for Auth0 and supports up to 1 million monthly active users for free. Check it out at workos.com to learn more. That's workos.com.

(00:04:15):
This episode is brought to you by Productboard, the leading product management platform for the enterprise. For over 10 years, Productboard has helped customer-centric organizations like Zoom, Salesforce, and Autodesk build the right products faster. And as an end- to-end platform, Productboard seamlessly supports all stages of the product development lifecycle from gathering customer insights, to planning a roadmap, to aligning stakeholders, to earning customer buy-in, all with a single source of truth.

(00:04:43):
And now, product leaders can get even more visibility into customer needs with Productboard Pulse, a new voice of customer solution. Built-in intelligence helps you analyze trends across all of your feedback and then dive deeper by asking AI your follow-up questions. See how Productboard can help your team deliver higher-impact products that solve real customer needs and advance your business goals. For a special offer and free 15-day trial, visit productboard.com/lenny. That's productboard.com/lenny.

(00:05:19):
Keith and Jay, thank you so much for being here. Welcome to the podcast.

Keith Coleman (00:05:23):
It's great to be here. [inaudible 00:05:25].

Jay Baxter (00:05:25):
Thanks for having us on.

Lenny Rachitsky (00:05:26):
It's so my pleasure. I'm so thrilled to be having this conversation. The work that you guys do has had such a tremendous impact on the way the world works. So many product teams are always talking about driving impact and want to drive impact. You guys have actually built things that have changed the world in meaningful ways and continue to do that. And I've never really heard the backstory of how Community Notes came to be and how it works and all these things, so I'm really appreciative of you guys making time to chat.

Keith Coleman (00:05:52):
Yeah. First, thanks for saying that. That's why we built this thing is to help people and it's great to hear it. It's great to see people enjoying it and finding it useful.

Lenny Rachitsky (00:06:02):
I want to start with just giving people a brief understanding of what is Community Notes. I think a lot of people kind of heard about it, kind of maybe see it on X. As they scroll through, they see these notes but they're like, "I don't actually know what this is." So can you just briefly describe what is Community Notes?

Keith Coleman (00:06:18):
Community Notes is a way for the people, like the public, to add context to posts that might be misleading. The basic way it works is that someone on X can see a post. If they think it's misleading, they can propose a note that they think other people might find informative. Other people can then rate that note. And if the note is found helpful by people who normally disagree with each other, indicating that it's probably accurate, it's probably really neutrally-worded, it's probably informative, then it will show to everyone on X. The goal is just to get people more information about what they're seeing so they can make better decisions in their lives.

Lenny Rachitsky (00:06:57):
Amazing, and I think hearing this, it's absurd that this works. I think when people originally heard this idea like, "No way this is going to work." And so, just to dive a little bit deeper, can you give us a deeper understanding of how it actually works? Because I think it's the algorithm that you guys designed that is so clever that allowed this to work. So talk a little bit about that algorithm.

Jay Baxter (00:07:22):
Yeah. So I think a key misunderstanding a lot of people have if they haven't really dived into details, they just think that maybe someone can write a note and it appears immediately or we're just taking a majority rules vote of who thinks the note's good. I think both of those approaches would probably lead to biased or inaccurate notes. I think the key thing, really, that we do is we actually look for agreement from people who have disagreed in the past.

(00:07:48):
And what we see is when people actually have that sort of surprising agreement, that's what makes the notes so neutral and accurate and well-written, really, overall. It's just that people who are very polarized, overall, often can't find agreement when things aren't accurate, right? I think it also provides some good anti-manipulation properties. I think people are often... If you said... I think back in 2020 before we started building anything here, whether this could work at all, I think a room of ML engineers would say, "Oh, you have to keep it closed source. People are going to be manipulating this all the time. You have to use ground truth labels from fact checkers. There's no way that you could bootstrap the system without external labels." But it turns out that you can do that with this kind of bridging-based agreement algorithm is what we call it.

Lenny Rachitsky (00:08:41):
Okay. So just to summarize and make it super clear. It's basically people... Someone writes a note. This information is fault... What's a good example, just as we talk about this, like a classic example?

Keith Coleman (00:08:50):
A really classic example is an AI generated image or an out of context image like, "Look what's happening here." But it's actually from five years ago in a different country and a different topic or something-

Lenny Rachitsky (00:09:00):
Oh, man. I've seen this so many times where it's like, "Look what's happening in San Francisco," and I'm like, "No, this is a whole different city and that's not-"

Keith Coleman (00:09:06):
Totally. Yeah.

Lenny Rachitsky (00:09:08):
Yeah. Okay. So someone posts this AI image. Someone writes a note, "This is actually five years ago in a different city," and this algorithm helps understand if this note is true and it's just regular people doing this.

Jay Baxter (00:09:23):
Yep. Regular people who have signed up to be Community Notes contributors. So there are a few checks, like you do have to have a verified phone number for instance. But yeah, at the end of the day, these are regular people. Not necessarily professional fact checkers or anything like that.

Keith Coleman (00:09:40):
And yeah, that was really important to us too. There was a question at the beginning, to the point Jay was making of like, "Did anyone think this was going to work?" Obviously, it was a crazy idea. We didn't know if regular people were going to be able to do this task and certainly people had concerns about whether they would do it effectively.

(00:09:58):
Initially, some people inside the company were suggesting like, "Hey, why don't you have journalists or some select group be the first participants?" But very specifically we were like, "No. We're trying to move away from the idea of curated editorial decisions being made around this. This is supposed to be open to everyone." So we very intentionally try to allow all humans in. People are randomly selected and that's important to it feeling fair, feeling open, feeling trustable.

Lenny Rachitsky (00:10:27):
Yeah. And again, it's just like this sounds like the holy grail of understanding what is true and it actually works. And works so well that Meta recently, as you all know, decided to adopt this exact system for them instead of having tens of thousands of fact checkers reviewing things.

Jay Baxter (00:10:46):
One distinction that I would make, which maybe can come off as nitpicky but I think is important, is Community Notes adds additional context. It's not fact-checking necessarily, right? So there are cases where the post could be true. But maybe, it's just misleading because there there's no context or there's missing context. We cover those cases and I think that's an important distinction. We just have the philosophy that users should be able to make up their own minds, right? Like, "Here's extra context, take it or leave it," right?

Lenny Rachitsky (00:11:18):
Yeah. What I think about, you shared this with me, this example of a picture with a cat and somebody's Community Note was just, "That's a dog." Or is it the other way around or that's a-

Jay Baxter (00:11:31):
Yeah. "A Palestinian boy shares his bread with a dog," was the post and it's a picture of this cat. So obviously, this particular note is not super necessary because it just says, "That's a cat," and links to a Wikipedia for cat. It's a good example that the system is... This is not something a professional fact-checker or whatever or you think would need fact-checking. But it's proof that the system is really run by the users at the end of the day and adds some comic relief, I guess. And the note is correct.

Lenny Rachitsky (00:12:06):
Okay. It's important.

Jay Baxter (00:12:08):
Yeah.

Lenny Rachitsky (00:12:08):
When does a post get triggered to even be considered for Community Note? Is there a threshold or is it just you can write a Community Note on anything and people decide what they would vote on? How does that work?

Keith Coleman (00:12:19):
So every post is eligible for notes and that was, again, another really important principle. It's like, "We shouldn't exempt Elon. We shouldn't exempt government figures. We should..." Everyone, even advertisers, can get notes. So any posts on the platform can get a note. And if you look in practice, you'll see notes appearing on world leaders, on Elon, on ads, on media organizations, and on, obviously, just regular people using social media. But yeah, the idea is really that it's an even playing field. For a note to be proposed, the person proposing it has to have earned the ability to write notes. So there is that aspect where you have to earn in to be able to do this. And the way you earn that ability is through your ratings by demonstrating the ability to help identify notes that are found helpful to a broad range of people. So basically, if you have an ability to see and know, recognize what's helpful with a lot of people, then you have the ability to start proposing notes.

Lenny Rachitsky (00:13:20):
I actually signed up to be on... What do you call these people? Note take-

Jay Baxter (00:13:24):
Contributors.

Lenny Rachitsky (00:13:25):
Okay. Contributors. Yeah. So I've been rating. I haven't achieved-

Keith Coleman (00:13:29):
Nice.

Lenny Rachitsky (00:13:29):
I can't write notes yet.

Keith Coleman (00:13:30):
Yeah. It's not super easy. It takes some effort.

Lenny Rachitsky (00:13:33):
Are there stats you can share about the scale of Community Notes at this point, especially things that might surprise people?

Keith Coleman (00:13:39):
Yeah. I mean, the service is growing rapidly, so there are hundreds of notes per day. And to put that into context, I saw some stats recently from someone at UC Berkeley saying there was something like 10 traditional fact checks a day. So in contrast, there's hundreds of notes a day that are getting shown. They span a huge range of topics from, obviously, politics, news, out to entertainment, sports, gaming. Just whatever is going on that day.

(00:14:07):
In addition to there being hundreds of these individual notes, they can also be matched to multiple posts. So if someone writes a note on an image or a video, like let's say it's AI generated or something like that, that note will automatically be matched to all posts that contain the same image. So you can have a single note matching to thousands of posts. And over let's say the last year, 2024, we had something like 95,000 notes that were seen about 30 billion times. That's more than double the prior year. Prior year was something like 37K notes seen 14 billion times. So that rate is increasing dramatically when you think about 30 billion views, that's a lot of information that is getting out there that might not have been out there otherwise, which is pretty cool. And part of the reason it is expanding like that is the contributor base is expanding. There's something like 950,000 contributors around the world. That's nearing a million people making this happen which is amazing.

Lenny Rachitsky (00:15:13):
Wow. And I'm one of those, right? I count as a contributor?

Keith Coleman (00:15:15):
Yeah. Yep. No. If you're signed up as a contributor, you count.

Lenny Rachitsky (00:15:16):
Okay. Cool.

Jay Baxter (00:15:18):
Then, there's more people on the waitlist too. So there's plenty of headroom for more growth. Regarding the matching on media and URLs, I think that's a huge way to get extra coverage. Also, I do think we've been very careful to make sure that those matches are precise. Because I think one thing that people love about Community Notes compared to other types of fact checking is that, actually, the notes are custom written for the particular claim you're seeing, right? So often, a fact check warning would just say something like, "Get the facts here." And then, there's a link to some generic page about voting information, which is so not helpful to have the information behind a click. So pulling the context up so that you have zero clicks that you need to make and keeping it specific is so important.

Lenny Rachitsky (00:16:11):
One feature I love that I imagine you guys thought deeply about is if I liked the post in the past, I get notified later if a community note shows up, so that I'm not remembering this false information.

Keith Coleman (00:16:22):
Yeah. I mean, we try to make notes as fast as we can, so we want them to appear instantly if possible. But inevitably, there's going to be a time gap between when a post goes live and when people figure out what's going on and when they get the note out there. And so, we send those notifications to try to close that gap. And yeah, we get a lot of love for that. We see people take screenshots and share them. They're excited about it. And it's also a pretty cool example of something you can do on the internet, in the social media world that was difficult in a print or standard news world where you would see maybe a correction the next day in a corner of a paper that was hard to read. Here, you're getting a ping about it if you've engaged with a post and note shows up.

Lenny Rachitsky (00:17:05):
One user feedback point is I'd love the push to just tell me, "Here's what you got wrong." Because I find that I actually have to go into it and read it and I feel like the push could just be like, "Here's more context to this thing." You're like-

Jay Baxter (00:17:20):
Agreed.

Keith Coleman (00:17:20):
We'll go take a look at that-

Lenny Rachitsky (00:17:21):
There we go. Live user feedback.

Keith Coleman (00:17:24):
Nice.

Lenny Rachitsky (00:17:25):
Okay. I want to get into the origin story of this whole thing. But two more questions, because we're on this thread. One is what's the the threshold for a note to show up on a note? Is that information you can share, just how does that work?

Jay Baxter (00:17:35):
So just because of the details of the way the algorithm works, it uses this machine learning algorithm called Matrix factorization where we fit it with Gradient Descent and whatnot. The threshold is it's 0.4 on this made up scale-

Lenny Rachitsky (00:17:52):
0.4. Great.

Jay Baxter (00:17:53):
Yeah. I mean, in practice, what it means is basically a majority of people... If there is a polarized divide relevant to the notes. Obviously, some notes are not about politics or something polarizing. But if there is, then a sizable majority of people on both sides would generally need to find the note helpful. And then, there are other rules that come into play beyond that main one. So even if it's above that threshold, it might get filtered out if... There's a separate algorithm that's looking at agreement between people's incorrect tags. So like maybe people found the note helpful but incorrect, right? It happens. And in those cases, it doesn't matter if it's above the helpfulness threshold.

Lenny Rachitsky (00:18:39):
This is probably the wrong way to think about it, but is it 40% of people that normally disagree, agree-

Jay Baxter (00:18:45):
No.

Lenny Rachitsky (00:18:45):
Okay. It's-

Jay Baxter (00:18:45):
It means nothing like that. It's just like on some arbitrary scale-

Lenny Rachitsky (00:18:48):
Okay.

Jay Baxter (00:18:48):
Yeah.

Keith Coleman (00:18:49):
Yeah. If we change random other things about the algorithm, that number would also have to change to an equally seemingly arbitrary number. We arrived at some numbers like that by gauging user feedback. So we could share a lot of notes with people, get feedback on which ones are helpful, and just a line emerged about indicating where things go from questionable to pretty clearly helpful.

Jay Baxter (00:19:13):
Yeah. And it is set right now, by the way, to be really conservative, I think. We just are pretty particular about quality and we really want note quality to be really high. I think Keith and I both believe that we live or die based on the quality of the notes at the end of the day. So we'd rather not show a note that maybe good, but we didn't have enough signal on than the other way around.

Lenny Rachitsky (00:19:41):
That makes so much sense. I've never seen a Community Note that is wrong and breaking that promise is a big deal. So I completely get why you guys are super conservative there. Okay. Two more questions [inaudible 00:19:53] because I'm just curious. These weren't on my list of questions to ask, but I feel like people wonder this. How many notes are written versus end up showing up and triggering on a-

Keith Coleman (00:20:02):
We probably show about 8% of notes that get proposed. It's been between, let's say, 7% and 10% or 11%, something like that over time. The number can vary a little bit. And as Jay said, there are undoubtedly... And you can see it, there's clearly more good notes than we show, but the goal is to hold a really high bar. We want to show a note when it's going to be helpful, when it's not going to appear biased and undermine trust in the system. We want these to be neutral, informative, helpful. And as Jay was saying, we view the worst possible mistake as showing a bad note because that's going to undermine trust and the trust is why people like the product.

(00:20:47):
So yeah, the bar is there. And like I said, there's clearly some in that remaining, let's call it 90%, that are good. And then, there's a lot that are just not that great and there's some that are bad. And if you write one of these ones that are bad which bad being defined as people who normally disagree find the note not helpful, so it's like the inverse of the ones we show. If you write one that people normally disagree, find not helpful, you actually will ultimately lose your ability to write and have to earn it back. That other 90% is a mix. Sometimes people look at the number, they're like, "Oh, why don't you show more?" It's like, "Well, you probably actually don't really want us showing most of those." The gold here is that the system is able to filter out the good ones.

Lenny Rachitsky (00:21:31):
That makes sense. Okay. One other question is there's many people that are very polarized, like very disagreeable with a lot of things. How do they filter into this algorithm? How do you deal with people that are super anti-vax, super Jan 6, like all these very extreme potential views?

Jay Baxter (00:21:47):
If people really are so polarized that there isn't agreement among people that typically disagree, it's possible that this is one of those notes that might be correct, but it wouldn't be helpful to show as context. Maybe it's about a claim that people have really entrenched opinions about and they've read hundreds of things about it already.

(00:22:15):
Probably this is just not going to improve people's understanding. It's just not going to be a helpful user experience. So it might not be the worst thing in those cases to not show the note. People, a few years ago, were pretty pessimistic that maybe fact-checking never changes people's understandings about what's true. Actually, there have been external studies run by people totally independent of us who have found that if you take a community note or posts with or without a community note... That actually, people's agreement with the core claims in the post does change if they see it with the note versus without. So we are having an impact on this thing that people previously thought was maybe not so easy to do.

(00:22:59):
And so, it's nice to focus on the cases where there is the bridging agreement. I would also say there is this reputation component to the algorithm as well. So if you consistently rate notes in a way that is counter to the bridging-based consensus, then we will stop counting your ratings. So if you're the kind of person who constantly rates bad notes as helpful, we do filter you out. So there's a difference between those types of people versus the good but polarized ones.

Keith Coleman (00:23:30):
Yeah. I think one philosophical thing that's important is that we want all of humanity to participate. And sometimes, people are surprised by that. They'll be like, "Oh, aren't there people who shouldn't be doing this?", or like, "Their thinking is so extreme or something, maybe they shouldn't participate." But our view is it's actually we want to have all of humanity here. Because if we have all of humanity, we then have the data to understand what notes will be helpful to actual humanity. We can better model that better or better understand and better show those notes.

(00:24:03):
So it's advantageous to have people who have all sorts of points of views and we don't expect that every note will be loved by every single person. That's an impossible bar. But we do intend to show the notes that 80% of people are going to read and say, "Wow. I'm glad I knew that." And so, in that sense, it doesn't matter how maybe extreme someone views a person's views as. It's still great to have them in the program. So no matter what your views are, please sign up and participate. It helps identify what's really helpful.

Lenny Rachitsky (00:24:39):
Cool. And we'll link to people if they want to actually sign up, so they know how to do this. Something we didn't actually specify, these are all volunteers. No one's getting paid to be doing these notes and voting, right?

Keith Coleman (00:24:49):
Yeah. It's totally based on intrinsic motivation and we think that's a great reason to be doing it. When you talk to the most active contributors, a lot of them, they want to have better information out in the world and that's a great motivation. So yeah, that's why they... If you think about, like for these people, the impact they can have is nuts. So when we first launched US-wide, this was like in 2022, a note appeared on a White House tweet and the White House deleted the tweet and reissued an updated statement.

(00:25:25):
Imagine being the person who wrote that. You probably have 12 followers. Your posts probably get a couple likes. And here, you just put a note on the White House and they changed their public talking points based on what you did. That is an incredible amount of impact. So you could see why people are motivated to do it when they care about what's going on in the world. You don't have to be a big, well-known person to shape the discourse and information flow in a way that's helpful.

Lenny Rachitsky (00:25:59):
It's insane. There's so much to love about this. One is just the meritocracy of this whole operation of just anybody that is true and correct can participate and have impact. Also, it just shows you how much information we get that is just wrong. We had no idea how often we see things that are wrong and now we do.

Keith Coleman (00:26:18):
Working on this product has made me realize just how many things I used to trust by default, that now I look at more skeptically.

Lenny Rachitsky (00:26:26):
Definitely mean these days. Okay. Before we get to the origin story, is there anything else along those lines you guys think might be really important to share, that are really interesting?

Jay Baxter (00:26:36):
Sure. I guess one other thing is that although we don't actually use the fact that a post was noted in the core ranking algorithm, which we think is a nice property. There is a really big impact just organically, meaning not from the algorithm but just from user behavior, where people will like and re-share or quote posts way less when-

Jay Baxter (00:27:00):
Quote. Posts way less when notes are applied. I don't know, for people out there who typically run A-B tests on big platforms, you may already be familiar with this, but 1% is typically an awesome effect size for any algorithm change. We saw more like 30 to 40% engagement rate drops for likes and reposts in A-B tests we were ran when showing a post with or without a note, which is just crazy big. That's just an A-B test on the engagement rate, so that's not the network effect. If you capture the overall network effect of how post spread less by that person's repost, basically if you look top line with a difference in differences approach, multiple different external research groups have both found consistently that there's a 50 or 60% drop in total reposts, which is just nuts after a note is applied. It's having a really big impact on spread actually, too.

Lenny Rachitsky (00:28:05):
That's so great to hear. It's what I would want to see and it's incredible impact. Basically, an AI image of something false would just go crazy on Twitter, and did before Community Notes came out, and now what you're saying is just adding that context, not actually... Like you're saying, the algorithm doesn't demote it. If there's something incorrect, it's just people are like, "Okay, this is false, why would I want to retweet this?" That makes sense.

Keith Coleman (00:28:28):
Correct.

Jay Baxter (00:28:29):
Right.

Keith Coleman (00:28:29):
Yeah, the notes just totally take the wind out these stories. The thing will be going viral, note appears, resharing drops 50 to 60%, and that's it. At 50 to 60% per generation, the virality quickly goes to zero.

Jay Baxter (00:28:45):
By the way, I have very mixed feelings about this next one, but authors become 80% more likely to decrease, sorry, to delete their post after they get noted, which okay, that's great, because less misinfo out there, but I'm pan about, because those are usually the best notes. If the note was so just good that you had no other option but to delete your post, those notes don't get seen by other people, right? Because-

Lenny Rachitsky (00:29:13):
That's hard.

Jay Baxter (00:29:14):
There's an argument, by the way, that seeing... Just because you might see the same misleading claim elsewhere off X, or somewhere else on X, it might be good to actually show... Better to have seen the post with the note than not see it at all.

Lenny Rachitsky (00:29:28):
Yeah.

Jay Baxter (00:29:29):
Unsure about that claim.

Lenny Rachitsky (00:29:31):
That is so interesting.

Jay Baxter (00:29:32):
Yeah.

Lenny Rachitsky (00:29:33):
Yeah, I'd be so sad if I was that community note writer and just... Man, it's so good. They just can't even keep the post up. Okay. Coming back from today's world, where this small amount of code is changing the way people understand the world and what they believe, and making the White House rescind their announcements, zooming back to the beginning of how this whole project started, what I heard just briefly is, Keith, you were just tired of managing PMs, you wanted to just work on something yourself, you wanted to work on something impactful away from corporate BS, and you basically just started looking for something that was impactful, important, and you found this. Talk about just how it all came to be at the beginnings of the story.

Keith Coleman (00:30:19):
Yeah. I mean, for me, the beginnings actually go back to why I joined, it was then, Twitter in 2016. I had a startup and we'd had some acquisition offers, and one of them was from this company, Twitter. It was 2016, it was the middle of the election between Donald Trump and Hillary Clinton, and there were something like three televised debates, but every day, there was a debate happening on Twitter, and it was very clear, this is where people are talking about these things that matter, where information is being shared, where ideas are being formed. As a user, it was obvious that I could get good information there, but it was also obvious that there was questionable information floating around. I remember just looking, as an outsider, thinking like, "Wow, this is a really hard problem and it also seems really important," so we ended up going to Twitter and the company was in a turnaround at that point.

(00:31:21):
My first three years was just helping to get the company growing again, working on everything that was the consumer product, getting user growth going back and people wanting to work there again, et cetera, but a few years in, I was reflecting on what we had done. I think we had done a lot of good work getting momentum going, and people in the us and in the industry had tried things to deal with misleading information, but nothing was really working. It was obvious nothing was working. Nothing could handle the scale of the problem, nothing could handle the speed, and a lot of people just didn't trust the existing approaches. The existing approaches were either fact-checkers or internal trust and safety teams making decisions about what was or was not misleading. A lot of people just didn't want or trust that to be the way this was decided, which is very reasonable.

(00:32:19):
I'm looking at that, I was still managing a large PM team. That's a whole story in itself. That job required a lot of energy in, and I didn't feel like I always saw the output that I wanted to see from it. I didn't see the change in the product I wanted to see and I was contemplating, "Should I go start a company? Should I do something else?" And I kept coming back to this problem. I'm like, "Man, how is the world going to deal with this information quality issue of what we get on social media?" Wherever get it. I'm at this company where you can make a difference on this problem, why not go and try some crazy ideas and see if one of them might work? I had a kid, I came back from paternity leave, I went to my boss, Kayvon. I was like, "Hey, Kayvon. How about I just stop doing my job and I go work on this instead? 'This' being trying some crazy ideas to see if we can deal with misleading info."

(00:33:24):
He was stoked, so I went off and started working on that. It started with just reading any research I could on the problem and existing solutions. What was or was not working, what were the issues, and then into prototyping. Then it ultimately led to us building and piloting this idea that became Community Notes.

Lenny Rachitsky (00:33:46):
Amazing. I have so many questions and we're going to keep going through the story, but when you joined Twitter, what was the... It was called Twitter. At this point, I'm going to try to call it X now, which I know is important to your boss. What era of Twitter was it at that point? It was Kayvon joined and who was the CEO? Because there's been many.

Keith Coleman (00:34:05):
Okay, yeah. I came in December 2016, so Jack had relatively recently come back as CEO to turn the company around, and just to give you a sense of the state of the company, something like a third of employees were leaving every year. Just imagine a third of your team gone every year. The stock was in the toilet, the product was not really growing, so Jack was working on a turnaround and Kayvon was there already. Kayvon was running Periscope with a bunch of video stuff, and that group continued to... Jack was there up through the start of the Community Notes, then Birdwatch Project, and... Yeah.

Lenny Rachitsky (00:34:50):
Okay, and it was called Birdwatch. I don't think we've used that term yet, but that's an important point. It was called Birdwatch initially.

Keith Coleman (00:34:55):
Yeah. It was originally called Birdwatch when we started the project, but obviously, somewhat famously the name changed along the way.

Lenny Rachitsky (00:35:05):
Yeah, maybe let's just tell that story real quick, and I know we're zooming it forward, but just... I have this Twitter thread that I saw between Jack and Elon when they're debating what to call it, and Elon's like, "Birdwatch sounds creepy, I want to change it". Is there anything there you can share?

Keith Coleman (00:35:19):
Yeah, the story there... The story, that's funny. Elon came in, acquired the company, and we had just launched the product relatively recently in the US. It had been in pilot for a year, but we had just made it available US-wide, and I guess he'd been seeing the notes. Soon after the exhibition, he DM'd me and he was like, "Hey, this Community Notes thing is awesome," and I was like, "I'm glad you like it, let's talk," so we talked the next day and he kept referring to it as "This Community Notes thing." I was like, "It's interesting you keep calling it that, because that's actually the very first thing that I called it." The very first figma mockup I made depicting this thing was called "Community Notes." I don't know why, it just felt really natural, so that's the first prototype we had tested.

(00:36:14):
Later, the project changed the same to Birdwatch, but Elon was like, "Hey, let's just call it that." The next day, we just changed the name. It's always notable for the team when you change the name, but really, the team was excited about it. I think it is a much more understandable name. Jack has made fun of it, calling it "The ultimate Facebook name," or something like that.

Jay Baxter (00:36:41):
The most boring Facebook name [inaudible 00:36:44].

Keith Coleman (00:36:44):
Boring name, which is funny, because they're now launching Community Notes. I think it is a very understandable, intuitive name, and I think it has served the product really well. There's a reason it was the name in the very first mockup.

Lenny Rachitsky (00:36:57):
Yeah, I think descriptive names just makes sense. This connection with Elon, and I want to talk later about just how you've dealt with so many strong personalities over and kept this alive throughout so many changes, but before we get to that, you did something that I think a lot of product leaders, angel leaders, just people that have managed people dream of give up all this power, in air quotes, and career trajectory and influence and just, "Forget all that. I'm going to go back to just building something awesome, small team." Is there any advice there that you could share from that experience that you think might be helpful for other leaders to share or to hear to help them maybe do that same jump? Because that's really difficult in practice. Easy to talk about, hard to do.

Keith Coleman (00:37:42):
Yeah, I think it is a difficult jump. I've done it a bunch of times in my career and I've always been very happy with it, where I started with a small team, that it grew into something bigger, and then I was like, "We're dealing with a lot of big production stuff, team's really big. I want to go back to doing something like crazy and new with a small team again." I've done that sawtooth leap a bunch of times, but it can be hard, because certainly, the natural... The classic career path is, I don't know, rewards or running a large organization or being a manager, or things like that, but I think, at the end of the day, you got to work on stuff you love, you got to be having fun, and I think people want to be having impact.

(00:38:29):
I think there's one myth that can get in people's ways. The idea that the more people you manage or the larger your scope is, the more impact you have. I definitely do not think that is true. I mean, look at Community Notes for example. If I had stayed running a large consumer PM team, what would I have produced? 16 more pages of OKRs? I don't know, a bunch of documents? I think building Community Notes has had way bigger impact on the world. It's become the industry standard for how to deal with this now, which is super cool. People love it, it's the first thing that is plausibly dealing with the internet-scale issue of information quality. I think it's unquestionably a bigger impact than I would've had if I were just doing whatever, doing some standard management track thing like I was doing before. I think that's true of so many other small companies and startups. Someone screenshotted I think it's Blake Scholl's LinkedIn the other day. He went from director of coupons or something to building the first supersonic-

Lenny Rachitsky (00:39:37):
Yeah, from Groupon.

Keith Coleman (00:39:41):
Those stories are everywhere when you look, so I definitely have found that, for me, I love building hands-on, I love trying crazy new ideas. I love the zero-to-one experience. It's fun to scale things up too, and it can be fun to operate at scale, but this team is a good example of one that operates at a very large scale, but that is still very small.

Lenny Rachitsky (00:40:03):
Yeah, I think the way you guys operate is what more and more companies are trying to do, remove middle management layers, create small teams that just execute and build impact, just like Ics. Whenever I say IC, I have a comment on YouTube, where like, "What is IC?" I'm just going to explain, individual contributor, non-manager is when I say the word IC. Let me follow this thread, and when I asked people about how you set up the team to operate effectively and protect it initially, there's this term, "Thermal," that came up a lot. It was like a thermal team, if that's how you describe it.

Keith Coleman (00:40:37):
Yeah.

Lenny Rachitsky (00:40:38):
What is thermal?

Keith Coleman (00:40:39):
Yeah, so anyone who's worked in a larger company probably knows that things can get bureaucratic or bogged-down, decision-making can be slow. There's these large planning cycles, people can try to take someone from one team, move them to another at random arbitrary times that can disrupt a project, all sorts of things like that. Our company, this is a number of years ago when we started this project, we had a lot of founders in the company. Kayvon is an example of founder who is helping to run the company, and he had this idea, "Hey, why don't we create this program, call it Thermal, where we could have teams that were somewhat isolated from that." They could run through their own process, they would have one clear owner. The team would be entirely dedicated to that project and we would just repeatedly make funding decisions as to whether to continue the effort.

Lenny Rachitsky (00:41:31):
Why was it called Thermal, by the way? What was the idea there?

Keith Coleman (00:41:35):
I think it was an old bird analogy of thermals lifting the bird on their wings. Twitter 1.0 obviously had a lot of bird analogies, bless its heart, so that was one of them. I loved the idea, as someone who liked the startup environment, so when we were starting this project, I was like, "Hey, Kayvon. Why don't we make this the first Thermal project?" And he was like, "Yeah, let's do it," so we started with that way of operating and it gave us, from day one, a lot of freedom and autonomy that I think was really important to make the product work.

Lenny Rachitsky (00:42:15):
Just be very specific about it. What makes it a Thermal project? How do you set that up? This is asking from perspective, if a company wants to build their own something like this, what does that look like?

Keith Coleman (00:42:24):
Yeah, I think there's a bunch of key attributes. One key attribute is there's one clear driver of the project, who's effectively a founder. I guess maybe you could have two or something, but really clear, there's driver of the project and also there's one clear decision-maker that they go to.

Lenny Rachitsky (00:42:43):
Outside of the team?

Keith Coleman (00:42:44):
Outside of the team. That was true back when we started and it is true now. If we need something or have a question about something, I talk to Elon. It was like that from the beginning, it's like that now, and I think that's a big reason we're able to make decisions effectively, quickly, in a simple way.

Lenny Rachitsky (00:43:02):
It probably has to be someone very senior, not [inaudible 00:43:05] manager.

Keith Coleman (00:43:06):
Someone senior who can make the decisions you need made, whatever they are. I think that's really important, that clear decision-making structure. Another was 100% focus, so everyone on the project is expected to be totally focused on it. A lot of companies, it can be easy to have people's attention spread across a bunch of things, and it makes it hard to get stuff done. You'll talk to whoever that person is, you'll ask them for help on something, and they'll be like, "Yeah, I'll help you. I got to finish this thing, and it'll take me a week or two and then I'll get to it." A week or two delay totally changes the momentum of a project. When we were 100% focused, we talk in the morning, it's like, "Hey, Jay. Why don't we try this thing in the algorithm?" He's like, "Yeah." Then that afternoon or the next day, we're looking at results.

(00:43:59):
Because of that total focus, the rate of iteration goes way up. Then beyond that, there was also just the ability to use whatever our own decision-making process was. We didn't need to write OKRs or... For others standard practices. Obviously, we had to make sure we were responsibly building the product and everything, but we didn't need to use the standard practices. I think that's another great example, OKRs, I understand why they can be helpful, but they can also be not necessarily the right cadence at which to set goals. I think it's really unclear that quarterly or annual goals are actually the right pace. We would set the goal for the next milestone that mattered, and we would work on that. We reached that milestone, we would have an idea of what was coming after, and then when we hit that, we'd set the next milestone. Whether that was two weeks, a month, three months, whatever it was. We set our own pace and goals at that pace, and that just I think is a lot more natural for the development of something.

Jay Baxter (00:45:06):
The whole OKR determination and planning process took longer than it would take us to pick a goal and then execute on it and finish it.

Lenny Rachitsky (00:45:15):
How big was the team early on that you set up? How many engineers?

Keith Coleman (00:45:19):
It started with just me and then, when we decided to build the thing, we figured we needed about five. We wanted it to be as small as we possibly could. It was clear we needed someone on ML doing scoring, it was clear we needed someone to do some client engineering work, someone to do backend engineering work. There may have been one or two other. We needed a designer and a researcher to help us understand the customer base and make sure we were building the thing in a way that was actually going to resonate with people. I think it was backend, frontend, ML, design research. That was the original team, from what I remember.

Lenny Rachitsky (00:46:01):
Amazing. Basically, one of each function. A question I have for Jay, actually, is there's all this talk of small teams and moving fast, but sometimes you just need more engineers to build the thing. Is there anything you've learned about just how to keep a team small while moving as fast as you are, and not need or need to hire more engineers?

Jay Baxter (00:46:22):
I think, in the beginning when we were iterating on what should even the requirements be, it was definitely good to just have one ML engineer, but I think, at some point, we got clear on what the goals of the algorithm should really be and we tried... I think, at the very beginning, it wasn't clear that we needed to build this bridging-based algorithm. The actual first algorithm that I put into production was very focused on anti-manipulation. It was this page rank variant, but it didn't solve the problem of bias, basically. If there are more users on one side, a page rank type graph algorithm can actually amplify those biases. I think, after building that prototype and getting data from that, it was clear that the bridging-based algorithm was going to be the way that we needed to solve it, and at that point, basically I set up a bake-off. Kind of a Kaggle competition or something. That was the key time where it was really important to pull in other engineers.

Lenny Rachitsky (00:47:34):
That is such a cool story. I want to follow that thread. Before we do that, you just mentioned you guys yell "Thermal." What does that mean? Is that YOLO, like a version of... Okay.

Keith Coleman (00:47:43):
We're just going to ship, because we're thermal project.

Jay Baxter (00:47:46):
Ship it.

Lenny Rachitsky (00:47:47):
Okay. Marketers, I know that you love [inaudible 00:47:52], so let me get right to the point. Wix Studio gives you everything you need to cater to any client at any scale, all in one place. Here's how your workflow could look. Scale content with dynamic pages and reusable assets effortlessly, fast-track projects with built-in marketing integrations like Meta, CAPI, Zapier, Google Ads, and more. A-B test landing pages in days, not weeks, with intuitive design tools, connected tracking, and analytics tools, like Google Analytics and Semrush. Encapture key business events without the hassle of manual setup, manage all your client's social media and communications from a unified dashboard, then create, schedule, and post content across all their channels. If you're working on content-rich sites, Wix Studio's No-Code CMS lets you build and manage without touching the design. When you're ready for more, Wix Studio grows with you. Add your own code, create custom integrations with Wix-made APIs, or leverage robust native business solutions. Drive real client growth with Wix Studio. Go to Wixstudio.com.

(00:48:52):
Okay, so coming back to this algorithm, this is actually really interesting, because I've never heard any of this. I was going to ask just what inspired this actual algorithm, and you basically did an internal competition amongst ML engineers to see who had the most successful algorithm. Netflix-contest style, Kaggle style.

Jay Baxter (00:49:09):
Yeah, yeah. This particular idea of finding content that is liked by people on opposite sides of a polarized divider who typically disagree, this was not an idea out of thin air. I think Keith had found some of Chris Bale's work, he had made this list of accounts that were often liked by people who were on both sides politically. There is other projects, like polls out there that look for agreement among people who typically disagree, but I think that it wasn't obvious that our project definitely needed to use that from the very beginning. When you implement it and compare it against these other type... PageRank seems, obviously, it's designed to be manipulation-resistant. Naturally, if you just have a voting ring of people who all vote themselves up, then PageRank can filter that out very well, but that just wasn't the main attack vector, I guess.

(00:50:15):
We had to get some real data from the pilot to realize that, "Okay, the real thing going on here is people are polarized," so it was only once we got that, the real data from the pilot, that I think it was clear that the bridging-based algorithm was the direction we really needed to go.

Lenny Rachitsky (00:50:34):
I want to come back to the way you operate the team. I hear that you run the whole team off a single Google Doc that's like a four-year-old doc that you just keep adding goals to, bullet points. Is that true?

Keith Coleman (00:50:47):
There is a very long-running doc that has had to be chopped and purged, because it was breaking Google Docs in Chrome at various points in time. It's like a note-taking doc. It's really where we coordinate what we're doing. The team meets on a daily basis, we spend whatever amount of time we need to get on the same page about what we're building. We might talk about anything from what's most important right now to, "What should we work on next?" To, "What are we trying to launch right now, and why is it not launched? What's in the way of launching it?" We might review new modeling or scoring algorithm update and try to understand what's working in it, what's not. We'll just cover whatever we want or whatever feels most important. As you said, we set our goals very dynamically, so whatever seems like the most important thing for us to work on now and next is what we spend our time on. I think that's served the project really well versus feeling attached to some quarterly goals, or something. We'll look at, "What is going to help people the most?" Or, "What's the biggest problem right now?" What are either one of those? And we will go tackle it. We might change our roadmap multiple times in two weeks based on what we see.

Lenny Rachitsky (00:52:08):
I'm hearing no Jira, no Asana, no Monday.com.

Keith Coleman (00:52:11):
No.

Lenny Rachitsky (00:52:12):
Okay.

Keith Coleman (00:52:12):
Yeah, I mean, we have to use Jira to coordinate with some other teams. Sometimes when we file a request, we have to make a Jira ticket. But no, I am not a fan of heavyweight task management. I love being on the same page, being able to keep most things in my head, and having a really light way to write down the things that the team can't keep in its head.

Jay Baxter (00:52:34):
We did use Asana briefly, but my memory of it is that you spent more time in the meeting grooming a backlog of irrelevant stuff than actually talking about the proper priorities. I think it's nice in the Google Doc that, if something becomes irrelevant, it can just fall off without needing explicit backlog grooming.

Lenny Rachitsky (00:52:58):
Just to maybe summarize a little bit of how you guys operate that might inspire other companies to set teams up like this, so I'm going to go through a few things you shared. One is one person in charge of the team, like the founder almost. They're basically the founder of the team. They have one very senior, essentially, sponsor/decision-maker that they interface with. In your case, Elon, no big deal. In other cases, it could be the CTO, CPO, someone like that. The team is focused 100% on its product and goal. You keep the team very small, so you start with one person of each function. One front-end engineer, back-end, ML person, designer, researcher, PM, and then Google Docs is almost basically for your project management. Yeah, it's basically run with Google Docs, stop, don't use big, complicated products.

Keith Coleman (00:53:50):
I think that's a pretty good recipe. On the Google Docs, people can do what they want. If they want to use thumbnails, go for it. I think those first ingredients, really, are key structurally. Then beyond that, it's a matter of having an ambitious goal that gets-

Keith Coleman (00:54:00):
And then beyond that, it's a matter of having an ambitious goal that gets people fired up to go do great work.

Lenny Rachitsky (00:54:06):
Yeah. Awesome. I think there's a lot there that a lot of people think they should do when they set these teams up, but they don't actually do, and it feels like each of these is just a really key ingredient to it to actually succeeding.

Keith Coleman (00:54:17):
It definitely really helped us succeed. I don't know that the project would be here if it was not for some of those elements.

Lenny Rachitsky (00:54:24):
That's a powerful statement. This thing that has changed the way the world understands what is true would not have existed if you didn't set it up in this specific way.

Keith Coleman (00:54:34):
Yeah. I don't know if I would've begun the project had I not known. We had that structure, that ability to make decisions, the autonomy, the speed, the ability to go fast. We started with that in 1.0 and it's been continued and if anything, furthered in X. X as a whole company operates with a lot of those attributes, and I think it's one of the reasons the product is successful. I think those are big reasons why at least, Jay can speak for himself, I have so much fun working on this. I love working on it. It's great to wake up every day and solve these problems. We get to do them efficiently, make decisions quickly, build stuff that helps a lot of people. It's awesome.

Jay Baxter (00:55:25):
This whether thermal or Elon way of operating is definitely more fun and the fact that... That combined with the awesome mission is super important for internal recruiting. I remember when I was first chatting to Keith about this back in early 2020, I had another project. I worked on a few, but one was like personalize the number of push notifications that we send, and it drove a lot of DAU without losing opt-outs significantly. So that was setting me on track, or if I had kept working on that, I could have probably gotten a promotion from that with low risk, or I could take this huge career... It's not as big at a career risk as joining or founding an actual external startup, but there is still career risk, I guess, in joining a team like this. I think all of the same aspects of recruiting that apply to external startups and apply internally, and if you can have an exciting vision, that is key.

Keith Coleman (00:56:30):
Related to that and your list, Lenny, one thing we missed that's super important is that on this project, and I think of successful projects like it in startups, is that people are self-selecting to join. We did not assign anyone to this project. People reached out to join or they applied to join the job. I and the team interviewed every single person that joined the team and we were like, "We want that person on the team. They want to be on the team." And so people are totally bought in to the goal, mission, the way the team works, the other people they're going to be working with. And that makes a huge difference.

(00:57:10):
So a great time to do that is at the start of one of these things. If you're going to try something crazy, it's going to be tough if you're just assigning random people to it. But if you let people opt in and self-select much more likely to be successful. And one thing that I have observed at X, which really surprised me was that this is also possible at a large scale. One of the things that Elon did when he bought the company was he basically asked people to self-select to stay. You had to click the button. And he sent an email out that was like, "Hey, Twitter 2.0."

Lenny Rachitsky (00:57:44):
Fork in the road. Right? [inaudible 00:57:46]

Keith Coleman (00:57:45):
Fork in the road. Fork in the road. Exactly. He's like, "Twitter 2.0, now X, it's going to be hardcore. We're going to do ambitious things. You're going to work your butt off." And you had to click on the form and say, "Yes, I want to join." And I think that was really important for the company because you want people to opt into that. You want the people to be saying, "Yeah, that's what I want to do," and the company's going to be a lot more successful. If people aren't sure, it's better for them probably to go do something else and where they're naturally more aligned and happier. And I thought that was a great approach to taking a large company and getting it down to people who are really excited about working together on a mission. So for us, we did it from day one, which I think is an easy way to do it, but it's possible to do it later as well.

Lenny Rachitsky (00:58:33):
I love that you described it as fun and I think a lot of people when they see Elon laying off a bunch of people, being very hardcore himself, people don't imagine it as a fun place to work. And it's clear how much you guys love working on this, how fun it is and how interesting it is. And it's interesting to hear that 'cause I think a lot of people don't feel that externally. Is there anything else along the lines of just working for Elon within an org Elon runs that might surprise people about just the way of working that's interesting or surprising or you think other companies might want to think about adopting?

Keith Coleman (00:59:07):
I've always liked lean teams, but my experience at X has made me change the way I would think about running a future org-... If I were to start a company and had to change the way I think about starting that company, I would be even leaner than I would've made it before. I've been amazed with just how much the team is able to accomplish with a small group. And I think because of a small group, shortly after the acquisition, we had this product called Spaces. It had been in the product before, but it was pretty small scale, and Elon wanted to run these large spaces. I forget who the first people he was going to bring on were, but he was going to be there. Ultimately, these things have gone on to host politicians and things like that, and he's like, "Guys, we got to scale this up." I forget the numbers.

(00:59:57):
He's like, "We need to be able to scale a million people," or something like that. I'm getting the numbers wrong. "You need to be able to scale way up." This is the kind of thing at 1.0 That would've taken a year if it had ever happened, and the team did it in two or three weeks. And it was really exciting and inspiring to see. I didn't work on that, but I watched it from the outside. I'm like, "Wow, with this tiny team motivated behind a big goal that was like, 'Hey, guys, it's not like, are we going to do this?' It's, 'We are going to do this.'" They got it done in two or three weeks. That must've felt amazing for them. It was certainly exciting to see. But I've definitely come to appreciate just how lean something can be and not just get by but actually thrive because it's that lean.

Lenny Rachitsky (01:00:42):
I think the point you made about people opting into that is important, 'cause I think a lot of people hearing that would be like, "I would never want to be asked to build something like that in two weeks." And I think a lot of people do, and we love that kind of experience, especially working with the Elon, especially shipping something at that scale. But I think there's an important element there of just like, "Okay, I don't want to do that. I have other things to do in my life other than ship spaces." So I think that's a key point you've raised of just there's an opt-in step.

Keith Coleman (01:01:10):
Totally. I think the opt in is important, and it may even be that you want to opt in at one point in your life, and maybe at another point in your life something else is better. I think whatever it is you're choosing to do, it's nice to be opting in to feel like it's aligned with how you want to spend your time.

Lenny Rachitsky (01:01:25):
Something on my mind, and I don't know if you guys want to go here, but it's something I think a lot of people think about is when Elon came in, he let go of 80% of folks. And everyone's just like, "Twitter is dead. It's all going to fall apart. There's no way they can run this thing with that small of a staff," and clearly they were wrong. Clearly, it's working great. It's becoming a massive deal in the world and continues to grow. Is there anything about that that you were surprised by or anything about just how it continues to operate so well in spite of that big shift?

Keith Coleman (01:01:57):
I think the leaner team, the reduced process in bureaucracy is a big reason it does move as fast as it does. It's easier to get stuff done faster here. Yeah. I think that shrinking is actually a big reason for the increased pace of launches, the increased pace of experimentation. One thing that I noticed a result of that is the people who are here, they seem to all really feel like owners. They take the sense of responsibility that an owner takes in the product. They'll try to track down what's wrong, fix whatever is needed, jump in to help build or fix, improve any system that needs help, even if it's outside of their space. And there's the flip side of that too. For people who've worked at big companies, they may have experienced this thing where there's like ano-... You want to change something in some other system or product, and so you reach out to that team. And maybe they're a little resistant, they'll maybe be like, "Oh, we'll get to that next quarter or so-

Lenny Rachitsky (01:03:07):
They have their own goals to hit. Yeah. [inaudible 01:03:08]

Keith Coleman (01:03:08):
Yeah. Exactly. They don't really necessarily want to help you or they're busy. Here, you're like, "Hey, guys, we need to do this thing with that other system you work on." And they're like, "Great! Here's the code. Here are the docs. Send us the fab if you have any questions, and we'll get it in." And it's just the thing, you can just jump in and get it done. And that kind of collaborative effort, like the sense of shared ownership, I think from my experience came from or was a result of the shrinking of the team down to people who wanted to be there and work together to build this thing. So I think that's been a really positive impact. It's not always easy. Certainly, a lot of people have a lot of responsibilities, but they're here because they're up for it.

Jay Baxter (01:03:53):
Yeah. I think one other thing that's key is when you are forced to have such a small team, well, this is important anyways, but deleting code is more important than writing it a lot of the time. So I think so often maybe due to promotion incentives or just regular human tendency, engineers have a tendency to add these little incremental wins that actually add more of a long-term maintenance cost than is clear, because you just run a little one month A-B test, you see this significant win and you don't realize the maintenance burden you just added to your team for the rest of eternity until you turn the thing off. So I think there's a lot to be gained and you get forced to do this, by the way, when you have such a small team. It's just auditing parts of your system and deleting the things where the maintenance cost is worse than the gains. So I think we did have to do this across the company after the big layoffs, and systems are leaner now and they can be worked on by fewer numbers of people.

Lenny Rachitsky (01:05:02):
That's an amazing point. I remember Elon's being like, "Here, we have to throw away the whole thing. We have to re-architect everything. It's stupid the way it's built." And it sounds like that actually worked.

Jay Baxter (01:05:10):
Yeah, so-

Lenny Rachitsky (01:05:10):
Well.

Jay Baxter (01:05:11):
You don't have to rewrite everything from scratch. Some things are good, I guess, to rewrite. But just even deleting the unnecessary cruft and keeping the rest of the core system, that's awesome.

Lenny Rachitsky (01:05:23):
I love that we're creating a formula to run these sorts of companies and teams. There's so much here. I want to go back to the building of the original product. I took us on a long tangent and an amazing tangent, but I heard a story of when you launched Birdwatch at that point. You specifically wanted to keep expectations very low and there was a GIF in the thing, and it just looked like clearly this is not ready for prime time. Talk about just how you did that, how you launched it in a way where people weren't like, "It's never going to work."

Keith Coleman (01:05:53):
We were very disciplined, I guess you could say, about having the product prove itself at every given point. When we built the first mockups, these were just pictures of depicting what community notes might look like. We showed those to people across the political spectrum. We saw, hey, people really like these. Whether they're on the right or left, they seem very open to reading these community notes even when they're critical to people of their own side. So we're like, "All right. That gives us confidence that if we can build this, if we can actually make this as a reality, it's going to work." Then there's a question of can we make it a reality? Will people in the real world be able to write notes that are of this quality?

(01:06:35):
And so we had an internal pilot test version of this where you could write notes. And we first basically ran this through an Amazon MTurk type of participant test just to see if you just put some normal people in there, will they be able to write these notes? All those notes weren't good, but it was clear that there were people out there who could write good notes. So then like, "Okay, this is possible. What will happen if we actually do this out in the real world? And let's run a pilot and find out." And so we took that pilot that we'd run the MTurk of test on, and we released it to at first 1000 people, totally out in public, and we didn't know what was going to show up. You could imagine the notes could have been terrible.

(01:07:27):
And so we were talking, "Well, what do we do? We're going to put this out there. Everyone's going to have all these questions. They're probably going to be really skeptical, and we know it might be a total dumpster fire. And so what do we do to set expectations appropriately?" We felt like we could probably get there in the end, but we just didn't know what was going to happen at first. We wanted to set expectations, and so we're like, "Well, why don't we just stick..." There's the page where you see a post in the notes below. We're like, "Why don't we just stick a dumpster fire GIF on that page?" And you go there, you're like, "Hey, anything you see below here might just be a total dumpster fire. At least it would show we were aware of that as a possible risk." In the end, we did not do that. It cracked me up, but we thought it was like-

Lenny Rachitsky (01:08:13):
Oh, you didn't actually launch. Okay. That was just a concept. Okay.

Keith Coleman (01:08:16):
We had mockups of it, and every time I looked at the mockup, I laughed, but ultimately we had so much to explain on that page, like, what is this thing and how does it work? Ultimately, we're like, "Okay, this is probably going to distract from the point." So we pulled it. I wish maybe it had seen the light of day at one point, but yeah, ultimately we kept it simple and we focused that page on explaining what was going on here. But again, as has happened many times with the project, we put the pilot out there and the notes were good.

(01:08:48):
They weren't all good. It was a mixed bag, but there was gold in there. And from the very early days with just 1000 contributors, it was obvious that people could write notes that were informative, that were neutral, that spoke to controversial challenging topics, and that if we could just identify those from the rest, this was going to work. It was going to work as well as the very first mockups we had made. So that became the focus that is, how do we sift out the gold from the rest?

Lenny Rachitsky (01:09:19):
I think you may have shared with this with me, when someone noticed you guys were testing this and they took screenshots and tweeted it, and I think Elon replied, "This is cool."

Keith Coleman (01:09:27):
Yeah. Yeah. So in the very early days when it was just a Figma prototype, we were running these usertesting.com on moderated studies. I guess one of the participants sent one to an NBC reporter who wrote a bunch of stories on it. Anyway, that day, there was a lot of chatter about it on the service, and Elon... To put this back in time perspective, this is, I think, 2020, so two years before any acquisition stuff happened, Elon is just a Twitter user building rockets and electric cars and other cool stuff and stumbles on this thing that depicts the prototype that we've been testing. And he writes back, "Definitely worth trying, IMO." And I remember thinking that was cool back then and it's interesting to see, he's obviously had a very consistent point on it. I think the idea was appealing and he has obviously been a big fan of it in the product and had been a big supporter proponent. So yeah, it was cool that it came from... that support has been from the very early days before he was ever involved in the company.

Lenny Rachitsky (01:10:36):
I love that moment. That must have felt really wild for Elon to be commenting on this Figma prototype retesting.

Keith Coleman (01:10:42):
It was cool. It was cool.

Lenny Rachitsky (01:10:44):
Oh, man. So when we were preparing for this interview, I asked you guys what's the main thing you want to make sure people get and understand about why community notes has been so effective? And Keith, you specifically said that it was the principles behind how you wanted to approach this and how you continue to stick to this throughout. And we'll talk about how you kept it alive throughout all these different CO changes in leaders. But just talk about these principles, what the actual principles are and why that was so key to it working out.

Keith Coleman (01:11:16):
There are a number of principles that I think when we first shared them with people at the company seemed maybe a little bit crazy. But I think they are the reason the product works, and I think they've been very important, and we do. We come back to them regularly, today, all the time. Probably the craziest one is just that this thing is going to be the voice of the people. It's going to represent the voice of people. It's not going to represent the company's voice. So it is not a tech company deciding what shows. It is the people deciding what shows, and that had a lot of implications on the design. First of all, we don't have a button that will change the status of a note. So if a note is showing because the people have rated it and found it helpful, it is going to show. We can't change that.

(01:12:08):
And that is the kind of thing that when we first propose this, that's unsettling to people. They're like, "Wait, so something can go up and the company can't take it down, or can't change its status, get it to stop showing." And we're like, "Yeah, and it has to work that well. If it doesn't work well enough to do that, then it doesn't work." This is one of our key principles was, if there's a problem with a note that's so bad, you want to do something about it's a problem with the system. We need to redesign the system to be showing good notes. And so yeah, we had to get everyone comfortable with the idea that there was no button to change the status of a note. Similarly, as we talked about earlier, we wanted this to represent all of humanity.

(01:12:53):
And so we didn't want to be arbiters of who can come in and be a contributor and who can't. So we open it to everyone. You just have to meet a really basic objective criteria. You have to have a verified phone to help reduce the likelihood of having bots or things like that participating. But beyond that, it's random selection and it still is that way today. And again, that people took some time to get people comfortable with it. But I think that the fact that this is the voice of the people and reflects their output through an open and transparent process is so key to both why it is good, why it works, but also why it's trusted. So that's number one and I think will forever be the heart of the product. Another one that people thought was crazy was transparency.

(01:13:49):
The previous approaches to dealing with misleading info, it felt to a lot of people, like black box tech companies or media companies or leads or whatever making decisions. We're like, "People need to get comfortable with this. They need to trust this. So the whole thing has to be out in the open." The code that decides what notes share has to be out in the open. All of the data and ratings that make it happen have to be out in the open. People should be able to take the code and data and replicate the whole service and that we have done exactly what we've said we've done. And they should be able to audit it. They should be able to go and look and say, "Hey, I think this part could be better."

(01:14:28):
Or if they think we're biased, they should be able to work with the data and point it out. And if people have good observations, that should factor back into the code. And this is, again, something that's difficult to get people comfortable with, that everything is out there, you can't cover anything up. But I think that's so essential to people trusting it. Yeah, we set these out on day one. We go back to them constantly because we're always evolving the product, and we're always like got to make sure every new change is open. Whenever we update the scoring system, there's an update in GitHub when the data is published daily so you can download it. And so yeah, I think those have been really essential to the thing working.

Jay Baxter (01:15:13):
And by the way, these do not come without a cost. It's actually really hard from an end perspective to actually open source the actual algorithm that's running on the actual data. Because the way large-scale services like this are usually architected does not naturally lend itself to being run as a script by someone who's downloaded a TSV. So we actually have to take weird architectural decisions to make this possible in a way that probably wouldn't have been if we didn't start with this assumption from scratch. We would've had to maybe rewrite the system to make it like this.

Lenny Rachitsky (01:15:49):
What's an example of that?

Jay Baxter (01:15:50):
For instance, there's a matrix factorization that we train. Usually, you would train a matrix factor... train your ML model once and then serve it, I guess with a separate service. But we didn't want to have people externally spinning up services to be able to replicate the system that we had. So basically, I don't think it would've been actually very cool if we had open sourced the code in a way that wasn't actually runnable, I guess, by someone just... At this point, you can download Python code and run a script. You do need a lot of RAM right now, but you can do it on one machine.

Lenny Rachitsky (01:16:35):
Okay. How much RAM are we talking about?

Jay Baxter (01:16:37):
Oh, only like 500 gigs.

Lenny Rachitsky (01:16:41):
Okay. Okay. That's reasonable.

Jay Baxter (01:16:41):
It'll take a day if you don't do anything special to speed it up. Good to know, but yeah.

Lenny Rachitsky (01:16:45):
Cool.

Jay Baxter (01:16:46):
Possible is the key thing, and people have done it. Vitalik Buterin had a blog post where he talks about his explorations, making sure the algorithm really does what it says it does. And I think just the fact that a handful of people have done this, there's enough people who have done it that there's someone you'd probably trust who's verified it.

Lenny Rachitsky (01:17:11):
And that's rolling out to Meta. No big deal. I love just as you described these principles, just I could imagine a PM at a company being like, "Okay, guys. Here, I want to do this project." There's so much idealism to it that rarely works in real life; going to be open source. You're going to give it to everyone. We don't have actual control over what it's going to do, don't worry about it. It's going to just change the way people see this thing that we've been very careful about and then it works. And I think that's very rare and it's really impressive. And what I'm hearing partly is that sticking to those principles was actually really fundamental to it working and not bending over when someone's like, "No, no, no, we can't do this. What if we change this part?"

Keith Coleman (01:17:54):
I think if we had broken with any of those principles, if there was anything black box, if there was whatever, the product would be a lot harder to trust. And so I think it's because we've just stuck to them so cleanly simply that people can trust it.

Lenny Rachitsky (01:18:11):
You've talked about a few moments when it was like, wow, the White House changed their announcement because of the community note. We talked about the dog is a cat. Are there any other moments that after you launched of, "Holy shit, this is working? This is going to actually work."

Keith Coleman (01:18:26):
All along, we saw it working. We wanted to be confident whenever we expanded it to new audiences or new countries or whatever, we wanted to be confident it was going to work. So maybe held our breath a little bit just to see that it would do what we expected, but we always expected that. But that said, there were definitely stress cases. The one that comes to mind is the start of the Israel Hamas conflict in 2023 in October. That was probably the largest deluge of misleading information I've ever seen shared on the internet at one time. It was overwhelming. A number of photos and videos and whatever coming out related to that, it was insane. And just to give you an example, I think it was first three days or something of that conflict, we had 500 notes covering all sorts of different... out of context imagery.

(01:19:32):
Someone would say, "Hey, this is happening here." It's actually from 2013 in Syria. There were people making fake battle footage in the video game simulator Arma 3. So there were notes explaining, this stuff looked realistic. And unless you saw the note, you wouldn't really know. There are all sorts of claims about what was going on in the ground, and that was definitely... The product was still pretty new at that point. We'd expanded in the U. S. less than a year before that. We had been rolling out throughout the world that year and then this large event happened. And I felt like we were just enough prepared at the right time for the system to be able to handle that.

(01:20:16):
Probably one of the most important things we did right before that was launch the ability to write notes on images and videos and have those matched to other posts. I remember at that time thinking, "Wow, I'm glad we launched that feature a few months ago versus still had it on the shelf," because it was really important in that conflict. And I think even it was just a few weeks before we had launched a major speed up in notes too. When we first built the product, the number one focus was always quality. We knew that the product would live and die by the quality of the notes. That was the thing we could never give up on. We also knew it needed to deliver speed and scale, but we're like, "We will get the quality in the right place, and we can speed it up and scale-

Keith Coleman (01:21:00):
Get the quality in the right place and we can speed it up and scale it out over time. And we had actually just launched a speed-up that took three hours off the time it needed to go live, and it was I think a matter of weeks before that conflict happened, so again, super glad that was out there. In the first few days of the conflict the median time from a post going live to a note showing up was five hours, which is like crazy fast. Typical fact checking is like two to four, at least it's really common to see it take two to four days. These notes were showing up in five hours and we're like, we are so glad we got those things out before this happened, it made the service a lot more helpful.

Jay Baxter (01:21:40):
One other thing that was, I think, nice to see working then was, one criticism of Community Notes some people bring up is, well if you always need agreement from people who typically disagree, then in these super polarized settings, that conflict being probably number one, then you wouldn't see any notes. But actually the reality was there were tons of notes about that conflict. So I think there was this kind of nice property where actually, and maybe this is a surprising fact, that there's more agreement out there across polarized divides than maybe conventional wisdom says, and the places where people agreed were really objectively true and verifiable. I guess maybe this is more true the more polarized the setting is, but where the agreement actually lends you, and basically notes that are very neutrally written, very focused on the facts and easy to verify information.

Lenny Rachitsky (01:22:46):
There's this talk for a while of just there's no more facts, nobody believes there is a single true fact anymore, everything is subjective, and I think Community Notes proves the opposite. Facts matter, there are facts that we can all agree with even on the most controversial topics.

Keith Coleman (01:23:04):
Yeah, we saw this really from day one, when we would show those prototypes to people just depicting the idea, it was really obvious that people cared more about, or they cared a lot about understanding reality and what was going on and they were willing to disagree with their side, so to speak, to recognize that. And I think that's not always that obvious to people. The world does feel really polarized, but people definitely are willing to cross partisan boundaries to get to accurate information and that's why the product works.

Lenny Rachitsky (01:23:38):
It feels like as we rely more and more on what we know and understand about the world is becoming social media online and moving this quickly, it's like I'm so thankful this exists because otherwise it'd just be, what do we trust anymore? This being out aligns with we need this thing to exist at the same time. And it feels like at the same time there's also people I just don't trust. I think people have shifted from I trust what I read to, okay, I shouldn't just believe everything I'm reading. Is there anything there you're noticing about just how people think about news they see and their shift of just like, I'm not going to believe everything. Is there anything that you've noticed about just human behavior or just the way we've shifted understanding what is true?

Keith Coleman (01:24:30):
We haven't done any research to look broadly at how people's perceptions are changing there, but I certainly have found myself that particularly seeing notes, I am more skeptical about what I read at first, and I think that's been helpful. And we hear that from people, that they think about things a bit more, and I think that's a good secondary effect and benefit of something like this, which is the more you see the patterns of how what you're reading can be wrong, the more you can thoughtfully question it and try to get a better understanding of what's really going on. So historically I think this was called media literacy, but basic idea of can you understand the ways in which things can go wrong and try to cut them yourself.

Jay Baxter (01:25:21):
Another aspect I think we help with that is discovery of the Community Notes. I think often before Community Notes you could have just been living in a little news filter bubble, or maybe there were fact checks out there that you should have been reading but you weren't discovering them. So the fact that the note applies, it is directly attached to the post and visible by anyone who sees the post helps cross those filter bubbles and can kind of... I think for some people it's the first time they've actually seen counter arguments to claims made in their own little echo chamber.

Lenny Rachitsky (01:25:59):
That's incredible, yeah. I love the point you're making about how it actually teaches people to be a little more skeptical of the things they read. It's an education system more than just, here, this one thing is wrong. I love that.

(01:26:13):
Okay, just a few more questions. There was an audience question asked on Twitter, we all asked on Twitter, "What do people want to know about Community Notes?" one was actually why you guys switched to anonymous contributors, what was the decision behind that?

Keith Coleman (01:26:26):
Yeah, we had this pilot where we were testing with a small number of contributors, a few thousand contributors, and we learned a lot through that pilot. Probably the biggest thing we learned was related to anonymity or pseudonymity of contributors. We had originally assumed that it was important that people contribute under their real handle, or their real name, or whatever it was. The first prototypes depicted that, we kind of thought that would be important for people trusting the note, and actually it was totally wrong. The best option was actually opposite of what we first tried.

(01:27:02):
We found a few things. One, people were hesitant to write a note on a controversial topic because they didn't want to get attacked or harassed online. And so some people were comfortable doing this but others were not, and so it meant there was more potential good notes to be written than were getting written, and this was very clear feedback from the pilot.

(01:27:24):
Two, and this is super interesting, people are actually more willing to cross partisan boundaries when they are anonymous or pseudonymous than when they are under their real name, and it intuitively makes a lot of sense. If you publicly are using your name, you feel are affiliated with one side versus the other, you might hesitate to be perceived as breaking with that side. But you may actually, for example, find a note helpful that's critical of that side, and there's a bunch of studies that show when people are anonymous, they're much more willing to cross partisan boundaries and work with the other side, agree with the other side, and we saw that too. And so by allowing people to be pseudonymous, you actually get more honest answers about what they really think and it helps find disagreement that really-

Lenny Rachitsky (01:28:11):
That's so counterintuitive.

Keith Coleman (01:28:12):
Yes.

Lenny Rachitsky (01:28:12):
You never hear the opposite always, and it's so interesting it's the opposite.

Keith Coleman (01:28:15):
Yeah, yeah.

Jay Baxter (01:28:17):
I think the same principle applies to making the likes private.

Lenny Rachitsky (01:28:21):
I was just thinking that.

Jay Baxter (01:28:21):
Yeah.

Lenny Rachitsky (01:28:23):
Yeah, I like a lot more stuff that's a little, definitely, I wouldn't have liked, yeah.

Keith Coleman (01:28:28):
It allows freedom for honesty, which is pretty great. And one of the criticisms of pseudonymity is it can generate, maybe people have reached the quality threshold that they put out there, but we have so many quality mechanisms in the system that that wasn't an issue, so we could keep quality high while opening up for that honesty.

Lenny Rachitsky (01:28:48):
Another question, you touched on this a little bit, which is around navigating the existing trust and safety apparatus of Twitter, which as you described, basically, previously, it was like we make decisions on what is true and not, and every company works this way, you guys basically upended that like, here's a completely different way, you have no control over what we say is true or not. Talk about just that experience of overcoming that, I imagine, very difficult hurdle of like, okay, forget all that, we're going to do it totally different.

Keith Coleman (01:29:20):
Yeah, it was definitely, what we were proposing was very different. I will say that I think people were sort of open-minded to it, generally speaking, and I think everyone had a sense that what was being done at the time wasn't really working that well or solving the problem, and people were open to new ideas, so that's a good foundation.

(01:29:39):
But I think one thing we did that was probably very helpful in that is we wanted the product to prove itself at any point. First it had to prove that people could possibly find notes helpful, then it had to prove that people could possibly write these notes that would be good quality. And so anytime that we were proposing doing something with the product, like running some research test, or running the pilot, or expanding the pilot, we always had the data that had convinced us that that was a good decision, like we were stepping into the next phase of expansion that made sense. And so I think we probably rarely proposed anything that seemed unwise, because we were holding such a high bar for quality ourselves, and I suspect that went a long way.

Lenny Rachitsky (01:30:33):
So it's partly, what I'm hearing is, take it step by step to prove this is actually working, and partly be confident it is working to yourself before you try to convince the trust and safety team this is the way to go.

Keith Coleman (01:30:46):
Exactly.

Lenny Rachitsky (01:30:49):
Was there a moment along that journey it shifted from no way this is a thing to okay, wow, let's actually consider this? Or was it this very gradual process?

Keith Coleman (01:30:59):
Whether other people were saying no way to wow, let's actually-

Lenny Rachitsky (01:31:03):
Yeah, just internally of just like, okay, we're going to actually stop this trust and safety way of operating and instead rely on Community Notes, was there a moment of like, okay, let's actually make that switch, or was that Elon actually, is that the big switch?

Keith Coleman (01:31:15):
The biggest change there happened in X, the biggest changes prior to that were just the decision to put this out there and have it be operating in public at first US wide scale. But yeah, then the bigger switches came in the X period.

Jay Baxter (01:31:36):
I think even though there was original research before Birdwatch had even started, or Community Notes had even started, from external researchers showing that crowdsourced fact-checkers, laypeople can do about as well as fact-checkers and actually the agreement rates were kind of similar between the groups. I think even though that research was out there, I think there were definitely a lot of people who didn't really believe it could work until it already worked.

Lenny Rachitsky (01:32:04):
Basically prove it, prove that it works. Yeah, that makes sense, versus just a bunch of docs and strategy and thinking, it's just like, look, it's actually working, you can see for yourself.

Jay Baxter (01:32:13):
Yeah.

Lenny Rachitsky (01:32:14):
Makes sense. Okay, possibly last question, we'll see which fractals of questions you guys bring up here. I referenced this a couple times, this incredible achievement of keeping a project alive through Jack and then, I have this note, and Kayvon running the show then, and then Parag running Twitter, and then Elon, and then Linda taking over as CEO, quite rare, especially something this visible, this impactful to everything that X is. Any lessons or keys to that actually working, of this project surviving throughout so many work changes and leaders?

Keith Coleman (01:32:54):
It definitely has been a crazy time to be building something. It's been fun. The craziness has been entertaining. I think one reason perhaps the product has done so well and survived is the nature of the product itself. It is designed to produce information that is found helpful by people who normally disagree. And so even if you have CEOs or leaders who might disagree, there's a good chance actually they'll find it helpful, they'll be like, wow, this thing does produce pretty useful output. So I think there's something in the nature of the product itself, that when people see it, whatever side they're on, left, up, down, they're likely to find it pretty helpful, so I do think that helps.

(01:33:39):
I also think the team executed really well. We had ambitious goals that were exciting, they solved a real problem. This is a real problem that matters in the world. At every step, as we talked about, the product needed to prove itself, and we would make sure it proved itself and we would bring the results that convinced us and we'd share those with people. And so they would say, oh yeah, I agree, it kind of proved itself, let's take the next leap. And we've done that all along the way and we continue to operate that way, and I think that focus on the outcome and goal that matters, and executing against it, really helped.

(01:34:24):
The team did not get distracted by much all through the period during which the acquisition happened. There was a lot of opportunity for distraction. This team was shipping every week, we were super focused on the goal, let's make this thing work, let's get these notes out there, and I think people saw that execution and were excited to support it.

Lenny Rachitsky (01:34:49):
Yeah, like it's working, why would we mess with that? And it's important, and it keeps us from having to hire tens of thousands of people to fact check.

Keith Coleman (01:34:57):
The interesting thing about that is no one ever asked us or brought up or seemed to care about anything related to cost savings in this process. And I think that's an assumption people have outside the company, that this must have been a reason there was interest in it. But that was never a goal, it was not at all why the project was started, it was not why people were excited about the project. And I think that's also, for people outside who maybe don't see the conversations, it's kind of a heartening thing to know, is that the focus was always on solving the problem. The other approach is even if you had 10,000 people doing it, the real issue is that they don't work that well because they're not trusted or they don't scale or they're too slow. And so the goal was really always just help people stay informed at scale. Let's build an internet scale solution to an internet scale problem that people like.

Lenny Rachitsky (01:35:51):
Something I heard about you, Keith, when I was asking people about how this worked and why this worked so well is that they describe you with having a very low ego, and that allowed you to give up this whole team and power and influence and just the name, forget it, whatever you want, we'll call it Community Notes, great. Is there anything in there you can share of just how you think about that and how important that is as a product leader to have a low ego?

Keith Coleman (01:36:19):
For me, this project, I feel like I get to do community service with this project. I see my work as in service of the people and the community, and that's what motivates me. The only thing that I care about is delivering the outcome that the world finds helpful. And so in some ways the project has not been about ego, it's about truth-seeking, let's find... Not truth in the sense of what information is true, but let's find out what's actually going to make this work. How does it need to be structured, what should it be called? Whatever is going to produce the best outcome is what we should do. So I think I feel more attached to the product being helpful than to anything else, and so to whatever degree it might seem like low ego is probably more a result of wanting to actually solve the problem.

Lenny Rachitsky (01:37:15):
And I think partly what I'm hearing is just if you win and succeed, good things will happen, so focus on that.

Keith Coleman (01:37:20):
Certainly satisfying things will happen, it's very satisfying to have people appreciate it. It's satisfying that people on the left and right love it. It's satisfying that even people who receive notes, love notes, and reach out to them and post them, that's amazing, it feels so good to have helped give people that, and yeah, it's very motivating. It's a great reason to wake up in the morning.

Lenny Rachitsky (01:37:44):
It's absurd this has worked, but it's also like of course this would work, of course something like this should work. It's like such interesting-

Keith Coleman (01:37:50):
It's the internet, it's of the internet, that's why it works.

Lenny Rachitsky (01:37:55):
Oh man. Where's Community Notes going from here? What's happening, where's it going, what's the future?

Keith Coleman (01:38:03):
We're always working on basically more better notes faster. So there's clearly an opportunity to get more notes out there, we want them to stay as good or better than they are, we want to get them there faster, so we're always working on core product changes to help deliver that. Recently, for example, we just released an update to what we call the Community Notes bat signal, or the ability to request a Community Note. So anyone on X can say, "Hey, I think this post needs a Community Note," and now they can even add a source explaining why so that when a prospective writer sees that it's much easier for them to write a note. So we're always working on core things like that, core algorithm improvements.

(01:38:47):
I think there are also new frontiers that show a lot of potential, AI and LLMs are one. It's easy to imagine a lot of ways that AI could assist the people in this task they're doing of trying to get information out there quickly. And maybe Jay should talk about the Supernotes work that we've done with some folks outside the company.

Jay Baxter (01:39:13):
Yeah, so one cool thing about having public data and code is that external researchers can collaborate with you, and in this case Supernotes had this idea that we can basically take existing notes as input, existing proposed notes that maybe they have some problem, maybe they have part of the story, maybe they're worded in kind of a biased way. Basically take all these in, have an LLM generate a ton of different variants, and then basically make the simulated jury to basically get a representative group of contributors for community notes who would be rating the note and try to predict based on their past ratings how they would rate these LLM generated notes. And so this way you can actually, rather than just having an LLM write a note from scratch and hoping it's good, you can simulate the entire community notes rating process and explicitly create notes that are likely to be rated helpful by people.

(01:40:18):
So I think ideas like that are very promising for the future, and it's a nice way that LLMs and humans can work together. Obviously agents can browse the web too, and that's one way that you could imagine agents assisting humans is maybe checking whether a note is actually supported by the source. Although then you get into things like, well, are people going to actually be as diligent? Right now I think raters are very diligent because they know just some Community Notes contributor wrote this like, I better check this before I rate it helpful. But hopefully we can design things in a way such that people don't trust the output and actually verify it themselves before issuing a helpful rating.

Lenny Rachitsky (01:41:11):
Yeah, that is such an interesting area to explore where you want to avoid AI hallucinating slop versus make it easier and scale it even further. What an interesting challenge.

Keith Coleman (01:41:23):
What's cool about this project, in addition to the AI element, is that it's being done outside the company. We talked earlier about the open source transparency. The key reason we made this all open source was so people could see how it worked, but the dream is actually that, it's not just that the contributions to the notes and ratings are from the people, but the dream is actually the product is built by the people. What if the scoring algorithm were significantly or entirely written by the public? That would be incredible. And Supernotes is probably the first very substantial potential change in the algorithm of the way it works, that was kind of coming from the outside and plausibly could be part of the core, so we'd love to see the product go in that direction as well.

Lenny Rachitsky (01:42:08):
Sweet, go Supernotes. Well guys, the work you're doing is tremendous. This is every product person's dream, I think to work, on something like this. Small team, lots of support, lots of impact, just innately interesting, and so I think this is going to inspire a lot of people.

(01:42:27):
So let me just ask you, is there anything else you wanted to share? Anything else you think might be helpful for folks to leave them with?

Jay Baxter (01:42:33):
Sure, I guess one thing that just I thought was interesting over the course of working on this product is just there's... I think in a similar way to how retweets originally were not something Jack came up with, I think users just started doing it and then it became a core part of the product. There's a huge way already in which there's just a lot of surprising things that people wanted to use Community Notes for that I don't think we really expected, and it's kind of cool to see those user desires emerge.

(01:43:04):
I think one example, I guess we had always been imagining political type of misinformation, but for whatever reason there's a lot of people who love debating whether Messi or Ronaldo got more goals. I guess it's kind of a funny one. There's a community moderation aspect, so I think we also thought that this would be specifically for adding context to misleading or potentially misleading information, but what you can see is that there are some notes that go beyond that towards calling out content that they think is spammy or something. So I think that's just another dimension in which commuted notes is a product that's driven by the people.

Lenny Rachitsky (01:43:57):
That's so beautiful, basically they're trying to keep Twitter/X healthy and they're just like, no, this should be taken down, this tweet of spam.

Jay Baxter (01:44:05):
Yeah.

Lenny Rachitsky (01:44:06):
I love that. Is there an answer on the Messi versus, who is the other soccer player?

Jay Baxter (01:44:10):
Ronaldo.

Lenny Rachitsky (01:44:11):
Ronaldo, okay. Is there a definitive fact there or is that just unknowable?

Jay Baxter (01:44:17):
Yeah, I guess that's an interesting one because it's a case where raters are actually very polarized. I guess it actually kind of fits into the core algorithm where there's some people who are just diehard Messi fans or Ronaldo fans, just like they could be on politics, so we actually specifically modeled that topic, as well as some other topics, so we can estimate people's opinion on that particular debate. It's kind of funny that something like that would emerge.

Lenny Rachitsky (01:44:45):
You're saying that's the most controversial topic on X, Ronaldo versus Messi.

Jay Baxter (01:44:51):
That's a controversial one.

Lenny Rachitsky (01:44:52):
Oh wow, who knew? Okay. Keith, is there anything you wanted to add?

Keith Coleman (01:44:58):
Yeah, community Notes is cool itself, but I think what it points to about society is actually even bigger. Society often feels really polarized, you hear people talk about it all the time, no one can ever agree on anything, but actually Community Note shows you people really can agree on quite a lot. Even on super controversial topics related to politics and everything, there's a lot of agreement, that's why notes work.

(01:45:23):
And I think that's a really big reason for optimism about the world, is that while it might feel polarized, there's probably like an 80% set of people that agree on quite a lot of things. And imagine if we could use the same kind of approaches we use with notes, but to find agreement on legislation, or policies, or things like that that people want the government or the world to do, possibly we could get a lot more momentum behind these ideas that the people really want and everyone would be a lot happier. Maybe 10% of the people on the edges wouldn't be happy, but I bet there's a lot of agreement that we are not identifying, and if we did it, we'd all be pretty happy. So I don't know, I think it's easy for people to feel pessimistic about the world, but I think this product is a good reason to be optimistic about the future.

Lenny Rachitsky (01:46:12):
What an incredible way to end it. I can also see, Keith, why people want to join you and work with you and work on this team.

Keith Coleman (01:46:19):
Appreciate it. If you do want to join, we are hiring an ML engineer. You get to work on these amazing problems with us and have a lot of fun, so we're accepting applications at x.com/communitynotes.

Lenny Rachitsky (01:46:32):
Okay, great, I'm glad you gave the URL. Oh man, you're about to get flooded.

(01:46:36):
Guys, thank you so much for doing this. Is there anywhere other than that place to go off, join the team as an ML engineer, is there any other place you want to point people to, either your socials or anything else?

Keith Coleman (01:46:47):
I'm KeithColeman on X, please reach out if you have any feedback or want to help us out, whether you may want to work here or want to do something from the outside, we would love to talk.

Jay Baxter (01:46:58):
Yeah, I'm @ _JayBaxter_ at X. Yeah, I think in particular, besides just using Community Notes, it would be great to get more substantial contributions, pull requests, collaborate on projects like Supernotes, I think that's the most exciting type of stuff if people do want to contribute.

Lenny Rachitsky (01:47:22):
Ship some code guys. Amazing. Guys, thank you so much for doing this.

Keith Coleman (01:47:27):
Thanks for having us, Lenny.

Jay Baxter (01:47:29):
Thank you, thank so much.

Lenny Rachitsky (01:47:33):
It's my pleasure. Bye everyone. Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at LennysPodcast.com. See you in the next episode.

---

## How to unlock your product leadership skills | Ken Norton, Ex-Google
**Guest:** Ken Norton  
**Published:** 2022-07-24  
**YouTube:** https://www.youtube.com/watch?v=6P0Es02vIF4  
**Tags:** growth, metrics, experimentation, analytics, conversion, revenue, hiring, culture, leadership, management  

# How to unlock your product leadership skills | Ken Norton, Ex-Google

## Transcript

Ken Norton (00:00:00):
Part of what I think is pretty exciting about product management is you are a leader from day one in product management. There's leadership all over the place, but that's your job. You're a leader. You don't have any formal authority, but you're a leader. You're expected to lead

Lenny (00:00:22):
Over his 14-year career at Google. Ken Norton led product teams at built Google Docs, Google Calendar, Google Maps, and even did a stint at Google Ventures. The products that he's helped craft are now used by over three billion people.

(00:00:37):
Today Ken is a full-time executive coach specializing at working with product leaders. In our conversation, we cover the creative versus reactive mindset, why the art of product management is much more important than the science of product management, how to get over imposter syndrome, the most common PM blind spots, how to find a coach and how to know if a coach is right for you, and so much more. I hope that you enjoy this episode with Ken Norton.

(00:01:05):
If you're setting up your analytics stack but you're not using Amplitude, what are you doing? Amplitude is the number one most popular analytics solution in the world, used by both big companies like Shopify, Instacart, and Atlassian, and also most tech startups. Amplitude has everything you need, including a powerful and fully self-service analytics product, an experimentation platform, and even an integrated customer data platform to help you understand your users like never before.

(00:01:33):
Give your teams self-service product data to understand your users, drive conversions, and increase engagement, growth, and revenue. Get your vanity metrics, trust your data, work smarter, and grow your business. Try Amplitude for free. Just visit amplitude.com to get started.

(00:01:53):
Have you heard of Lenny's Job Board? Well, if you're hiring or open to a new gig, have I got the site for you, lennysjobs.com. If you're a hiring manager, sign up and get access to hundreds of hand-curated people who are open to new opportunities. Thousands of people apply. And I personally review and accept just 10% of them to be part of this collective. You won't find a better place to hire product managers and growth people.

(00:02:18):
If you're someone who's looking around for someone new, join the collective. It's free. You can be anonymous and hide yourself from any company. You can also leave anytime. You'll only hear from companies that you want to hear from. Check out lennysjobs.com to learn more.

(00:02:38):
Welcome to the podcast, Ken. I am so honored to have you here. You're such a legend of product managers and product management circles. Your writing has had so much influence on so many people, including myself. If nothing else, you've led to many donuts being purchased by tech companies over the years. So thanks for being here.

Ken Norton (00:02:58):
Thank you and thanks for having me. The feeling's mutual. Obviously a big fan of your work and all the things you've done for the community and this podcast, which has been fantastic. So humbled and excited to be here. Yes, I do think that I'm at least maybe partially responsible for at least a lot of consumption of donuts over these years.

Lenny (00:03:18):
Are you tired of people asking you about donuts?

Ken Norton (00:03:21):
I'll never get tired of it. Well, back when we met with people in person, people would bring me donuts, and I never got tired of it, nor did any of the people that I worked with who got to eat those donuts get tired of it. So, no, no, I'll never get tired of donuts.

Lenny (00:03:37):
Someone on Twitter asked what's a digital equivalent of bringing the donuts now that we're in a remote world. Do you have any advice on that?

Ken Norton (00:03:45):
That's a great question. I'm not even sure if the physical equivalent of donuts is donuts. I mean when I came up with that, I think it was really to be a metaphor around being a servant leader, bringing whatever needs to be done, filling the white space, filling the gaps, whatever needed to happen. So it doesn't always have to be donuts.

(00:04:07):
I did put that question out to some of the readers in my newsletter a while ago, maybe earlier in the pandemic, and got a lot of really interesting ideas. Maybe that was at a place where people had a little bit more patience for happy hours over Zoom and stuff like that. Maybe that patient set is worn out. The idea that I love the most was actual donuts. There was a PM who got DoorDash codes and found the best local donut place for each of the people on the team and basically sent them a code and said, "Click here and order the donuts to come to your house whenever you want them." So maybe at least partially the digital equivalent of donuts might be actual donuts.

Lenny (00:04:40):
Decentralized donuts.

Ken Norton (00:04:42):
Decentralized donuts, on the blockchain.

Lenny (00:04:46):
Oh boy, let's not go there.

Ken Norton (00:04:48):
I don't know what that is.

Lenny (00:04:50):
So I was perusing your career path ahead of this chat. You had this pretty wild career. You were an engineer initially, and then you were CTO at a part of NBC. Then you're a founder. Then you spent 14 years at Google working on products that folks may have heard of, like Google Docs and Google Calendar and Google Maps. You've also done a bunch of writing. Then more recently, you've become a full-time executive coach focusing on product people.

(00:05:17):
I have so many questions I'd love to ask you about your career and learnings along the way, and the writing. But I'd actually like to spend most of our time talking about the coaching and things that you've learned through that experience. And so, I have a couple questions just off the bat. What does an executive coach actually do? What kinds of things are you helping people with? What does a session look like? Then, two, just how did you decide you wanted to be a coach full time after leaving Google?

Ken Norton (00:05:40):
Yeah, that's a great question. I think coaching does mean a lot of different things. I mean it depends on who you talk to. It is a little bit of who you are, your style, your approach. Some people are calling themselves coaches, doing more mentoring, more advice. Other people are maybe more like me, more peer coaching.

(00:06:01):
To me, I see executive coaching as a partnership or creative partnership. It's all about helping my client reach their goals, their potential, whatever that means to them. So an important thing about coaching is the definition of success does belong to the client. I don't have an agenda. I don't have a set of things I'm trying to share, teach, learn. It really is fundamentally up to them, which means every client is completely different. They have different sense of where they want to go. Different barriers that might be standing in their way.

(00:06:35):
My coaching practice, I coach the whole person. So there is no restriction on what we might talk on, what we might work on together. It's not limited to product. It's not even limited to work or even leadership. It's wherever they want to go, whatever change, transformation means to them.

(00:06:52):
As coaches, we bring a bunch of tools to the conversation. The most important ones, honestly, are probably listening and curiosity, intuition, open-mindedness, really there to help challenge them to see things in different ways, help them tap into their imagination, figure out when there might be underlying beliefs, help them connect dots that need to be connected, help them disconnect things that feel connected. There's a lot of exploration to it.

(00:07:20):
It's very jazz-like. My love of jazz has been shared before, but there is an improvisation to it. What coaching is really powerful is you may not necessarily know where you're going when you start and you follow wherever there is meaning and change for that individual, wherever is they want to go.

(00:07:38):
The question around what brought me into it was actually interesting. I, honestly working with my own executive coach, started to figure out what it is that mattered to me, what I liked, what my values were, what my purpose was, started to unpack that I love deeply connecting with people and I love helping people change and grow.

(00:08:01):
The moments when I had the opportunity to do that as a manager, as a product leader were the most fulfilling parts of my career. And so, I started to unpack that and figure out what would it look like if that was what I did.

(00:08:15):
The other part of the journey was, for several years at Google, I worked at GV. It's Google Ventures, Google's venture capital arm. I had the opportunity to work with founders and product leaders in the portfolio. I started to simultaneously recognize the shortcomings of giving advice, because it seemed like, well, I can meet with these folks, I could tell them what I did, I could tell them what Google did, and that'll answer all their questions.

(00:08:41):
You start to realize advice is not as powerful as you might think it is. It's a little bit like cotton candy. Doesn't have a lot of nutrition. You get a nice sugar high. You feel great, both sides feel happy, but then a couple weeks later, a couple months later, nothing's really changed.

(00:08:57):
That's because it doesn't often confront the real problem. It often isn't relevant. Like what worked for us at Google may not have worked anywhere else. It may not even have worked at Google for all I know. I feel like there were years at Google where all we were doing was making things worse by showing up and we should just all have gone sat on a beach somewhere, and the company would've grown even faster. So who knows?

(00:09:20):
I mean so it was these just twin pillars of wanting to figure out where I could do what I like the most, and then also recognizing that where growth comes from is less around advice and telling people what to do and more about helping them figure out their own path, their own way. Then that ultimately you brought me into, hey, I want to do this full time, and that's what I've been doing ever since.

Lenny (00:09:46):
When do you find people come to you to get advice and coaching? What kind of clients do you find you end up working with?

Ken Norton (00:09:53):
That's a great question. Generally speaking, I work with senior product leaders, however you want to define that. Typically, these are chief product officers, VPs of product at startups, largely director level and above at bigger tech companies, some CEOs, other C-level execs in there. I think really anyone that considers themselves in a product leadership role.

(00:10:15):
Often they come to me because there's a career milestone or a crossroads, and it could be that they now find themselves in the position of being a CPO for the first time. Maybe there's a new industry change, or they've gone from a big company to a startup and a have this sense of what got me here isn't going to get me there. That's oftentimes when they reach out for coaching.

(00:10:41):
I think my clients are also very introspective and surrounded by great mentors and advisors and have all sorts of people in their life who can help them, but are realizing that a lot of the work is going to be internal work that's going to get them to the next level. And so, this transformation is going to be just as much what I need to do as who I am. That's often when people come to me.

Lenny (00:11:08):
You said that the way you coach is about the whole person. I'm curious ... I don't know if there's an answer to this, but when people come to get help and coaching, how much of their blocks, I guess, are rooted in their regular life versus skills, technical skills, and more like the PME, product leadership side, if that makes sense?

Ken Norton (00:11:31):
Yeah, I think ... Well, let me maybe try to illustrate this with an example from my life right now. Indulge me, I'm going to go a little bit left field here, but I promise [inaudible 00:11:45].

Lenny (00:11:45):
Let's do it.

Ken Norton (00:11:46):
So we are teaching our 16-year-old son how to drive. So he just got his driver's permit. Do you remember when you learned how to drive, Lenny?

Lenny (00:11:56):
I do. Yup.

Ken Norton (00:11:58):
Yeah. Yeah. So it's scary. I don't know if you know how your parents might have felt, but-

Lenny (00:12:04):
Nope, [inaudible 00:12:06].

Ken Norton (00:12:06):
... [inaudible 00:12:06] on the other side of it. It's a whole new journey. Look, he's a smart kid. He's going to do great. But it helped me actually think back to when I learned how to drive. Actually, what I think is maybe a little bit more important here is before you learn to drive. And so, if you think about it as a ... When you're a kid, cars just go places. You get strapped in and you just wait and you get impatient. Then eventually you go somewhere. You're not even consciously aware of the concept of driving. Just cars just happen and you're not even aware of it.

(00:12:41):
As you get a little bit older, you start to become curious. You start to figure out, oh, that wheel has something to do with it. You turn the wheel. Maybe you start to understand there's pedals. But it also just seems really simple. Just like you get in the car and you drive it and you go somewhere. Maybe as you get older, you end up maybe even being a little bit of a smart Alec about how easy it looks and you start talking to your parents about, like, "It doesn't look hard. I can do this."

(00:13:07):
Now suddenly you're behind the wheel of the car. This is what my son is doing. Wow. Is it different than you thought it was going to be? Is it way more complicated? You have to remember check your mirrors. You've got to look before you turn. You didn't even know what that sign meant. You didn't know what those stripes meant. It is just overloading with complication and your internal mindset for confronting this challenge is not going to suit you the way you used to approach the world.

(00:13:44):
Maybe to put it in product leadership, product terms, everyone around you has got some real pithy advice about the things you're forgetting to do. It's like, "Hey, don't forget to check your mirror." Everyone's got a framework. It's like, "Ah, do you know about the 10:00 and 2:00 framework?" "Wait, what's the 10:00 and 2:00 framework?" "Oh, you just put your left hand on the 10:00, your right hand on the 2:00. That's the only thing you're missing. Here's a great medium post about that." Then you're like, "This is a problem is I have not adapted to the complexity of the world around me."

(00:14:19):
And so, there is this sense that what is interesting about driving is the world hasn't gotten any more complex. Driving's always been driving. But now your place in the world has shifted such that the internal meaning-making and self-complexity that is required requires a complete reboot of the internal operating system in order to allow you to thrive there.

(00:14:41):
And so, when you talk about this question of how much of this is skills, how much of this is tactics, how much of this is learning versus how much is internal growth, the answer is it's both, but the shift that is required is very much around how your inner self can make meaning and respond to the demands of the world around you so that you can succeed and thrive in this mindset shift that happens.

(00:15:09):
The skills matter, but by this point, you're beyond the place where you've learned the skills. There's mastering the skills, but there is this sense of what developmental psychologists call self-complexity, the ability to respond and adapt to that.

(00:15:24):
And so, I think we go through a lot of those shifts in our career. The driving example is simple. Actually, probably too simple, because the world is actually getting more complex for those of us that work in product. I mean every day something changes. It forces us to respond and adapt. So there aren't even rules of the road in product.

(00:15:42):
But I think this is what we're talking about, this question of the internal operating system I develop my ability to restructure it such that I can succeed given the demands that have been placed upon me.

Lenny (00:15:57):
What an amazing analogy. Totally hits home in a good and bad way. It's a really good segue to something I wanted to chat about, something that we talked about before the recording, which is what you're finding to be one of the bigger unlocks for your clients. It's also a concept that you've been spending a lot of time refining and you're finding is helping people shift, and specifically shift their leadership mindset. And so, I'd love to just hear you talk through your thinking there.

Ken Norton (00:16:24):
Yeah, it does sort lead into this. Maybe another analogy that might work for your listeners, if you think about product management, your career arc and where you are challenged from a mindset perspective, in some ways it does feel like the early part of your career. You're learning to play a video game. Hopefully there's a tutorial. Your first job is learning the ropes, somebody's teaching you. You maybe have managers that are giving you simple little missions that you can succeed at and if you fail, the consequences aren't bad.

(00:17:03):
It does feel like a little bit ... And I felt this way, and I talked to a lot of people earlier in their career. It does feel like you're trying to learn the rules of the game, trying to figure out the physics. You want to run up the score.

(00:17:15):
You get better at playing the game. You fail, but you start to develop some confidence that when you fail, you'll learn from it. You'll get better. You get really good at the game. You get promoted, you get rewarded, you unlock new levels, teach other people how to play the game. You start to feel really awesome about yourself.

(00:17:32):
But then suddenly you're put in a place where you realize that the rules of the game aren't so black and white. Maybe there's a long delay now between when you get to see what you did and the score of it. Things start to behave in unexpected ways. The physics start to get weird. You're on a level where you're floating. I don't know what the right metaphor is here.

(00:17:52):
But you start to recognize that there's been this huge change. The most frightening part about it is you look around and everyone is looking at you like you're the designer of the game, and you thought you were playing. That's often what it feels like when you move into a leadership role, to come back to this sense of what got me here is not going to get me there.

(00:18:17):
I work with a lot of leaders and sometimes that's come with a pretty significant cost, this juxtaposition, maybe your happiness, your health, your marriage. There's been this existential crisis of I don't know if I love this anymore. Maybe it leads to burnout. Maybe it's not even that dire. It's just a sense of, well, I'm looking around and I need to be something. I need to unlock something else to continue on this path. There is a sense of stuckness that comes from that.

(00:18:45):
What I've come to realize is this is the precipice of, I think, this pretty fundamental concept in leadership. I'm not the originator of this, so this has come up again and again and again. It's not new. It's going to sound familiar. It's like the flood myth from Gilgamesh showing up in all this oral histories of the world. It's not new.

(00:19:10):
Conscious Leadership Group, an organization that I'm big fan of, they call it above the line versus below the line. Brene Brown calls it daring versus armored leadership, sage versus warrior. Even in the world of sports, there's playing to win versus playing not to lose. It's this concept that's come up again and again. Leadership Circle calls it creative versus reactive, and that's the term I'm going to use. I like that.

(00:19:35):
Here's the distinction. Very simple. Are you responding to the world from a place of fear, where you see problems and threats, you want to be right, you want to be liked, you're defensive as an inward approach, or are you responding to the world from a place of openness, possibility, curiosity, passion, growth, purpose? Very simple concept. Pretty much everyone understands what I mean. It makes sense.

(00:20:11):
Everyone also then immediately says a couple of different things. "That sounds amazing. I'd rather have that," or, "Here are moments when I've felt that," but that's usually followed up by a couple of questions. "I don't know if that works. It doesn't sound very effective. Is it possible?" Then how do you that?

(00:20:38):
The effective part is actually a question we can answer, which is, yes, it is more effective. Bob Anderson, Bill Adams are two management scientists who've written extensively, done a whole bunch of research, and they have looked at every possible dimension you can imagine of success, both leadership capability, they've looked at revenue, brand, profitability, everything, and it's shown, yes, this creative form of leadership is in every possible way positively correlated with success and reactive leadership is negatively correlated. So, yes, it works yet.

(00:21:17):
Yet, according to their research, some 75% of leaders are primarily operating reactively. So most leaders are operating from a place of fear, reacting, seeing problems, and threats. That's because that other question of how do you do it is such a hard one to answer. It's not an easy thing that you flip the switch of. It goes back to this notion of redesigning that internal operating system, so how you confront the world, what underlying belief systems and assumptions you have that are causing you to operate from that place.

Lenny (00:21:55):
Can I ask you a quick question? Just to clarify the two sides, what's a sign that you're in the reactive side of things? I think one thing you said is you're worrying a lot about how people think about you and make sure that they like you. Is there anything else that's going to tell a listener, "Oh, maybe I'm falling into this trap"?

Ken Norton (00:22:13):
Yeah, you've nailed it, which is that fear, like operating from a place of anxiety. There are different ways, depending on our mindsets, our approaches. I like the word postures because it seems to click different ways that we retreat into this reactive mode. Fear and anxiety is the way. That's how you know. You're just like, "Ugh, I'm below the line." I'm just like I'm seeing problems. I'm seeing threats.

(00:22:43):
Our brains are hardwired to do that, so it's not like that's wrong. These are brains that learn to do that, I don't know, on the tundra being chased by wild animals. So this is our normal way of being. There might be different desires and needs that force you to operate that way. We think there's really three of these postures.

(00:23:11):
Anybody is probably more than one of them, so this is not pathologizing. This isn't putting you in a box. But probably one of these will resonate more than the others. Wanting to be approved, wanting to be loved, wanting other people to like you. This was me in my early part of my career.

Lenny (00:23:28):
Same.

Ken Norton (00:23:29):
Yeah. So you're kind of like the heart type. It's sometimes called move toward other people. A lot of that came from my environment. I was coming up with product management. No one necessarily knew what the job even was. I had no authority and most people could just ignore me if they wanted to. And so, I had to meet other people's expectations, please them, want to be accepted by them, seek their approval. It was this what we call a complying approach.

(00:23:58):
Here, this is why this is so vexing is it actually worked really well. It was pretty effective. Other people liked working with me. I listened to them and I considered everyone's needs and made sure everyone felt heard. But there came a point where I gave away so much power that it was hurting me when it came to purpose and execution and decisiveness.

(00:24:22):
And so, again, these aren't bad. There's usually underlying tendencies that are very good. It just starts to have a cost as you become more senior. It's like the gears start to grind to a halt a little bit.

(00:24:35):
Another way is more of a needing to be right head type, protecting one's own ideas, sometimes called a move away from type, distance, arrogance, criticism, retreating into your own ideas and head. Then the other will not be a surprise, is the more controlling, my way or the highway, autocratic will move against wanting to win, wanting to be number one, wanting to excel, wanting dominance, wanting control, this would be another tendency.

(00:25:10):
Often one of those feels natural to you and another one feels just so incredibly distasteful that you can't imagine possibly operating that way. This goes into the underlying beliefs part. If you had told me early in my career, when you saw me being passive and people-pleasing like that, "You've just got to stop caring what other people think, Ken. You've got to be more pushy."

(00:25:41):
People did say that to me. That was pretty common probably in my performance review. It was very common. Even people who worked for me were like, "You need to push back." My only archetype for doing that was the autocratic, controlling type. I was like, "I don't want to be like that. That guy's a jerk. That's a fascist. I don't want to be a fascist. I do care about other people."

(00:26:04):
And so, many of our examples and archetypes are these equally ineffective reactive ways of being. And so, no wonder I didn't want to be like that, because that's also not very effective either. But there was a sense for me of redefining ... This is where coaching is powerful is this what are the underlying assumptions and beliefs that you have that are causing you to fall back on some of these fundamental ways of operating and not let go of them?

(00:26:35):
Because the answer for me wasn't stop caring about other people. I wasn't going to do that. That's a value of mine. It's part of who I am. But take the caring about other people, the empathy, the connection, and direct it in a more creative way where you're operating now from a place of purpose and vision and not reacting and protecting and defending and wanting to be.

(00:26:56):
For me, the key to that was letting go of needing to be liked and redefining it as an admiration that takes place over time. So rather than I want to leave this room with everyone liking me, I started to realize I want to be the type of leader where, a decade later, people say, "I would work with that guy again in a heartbeat." That was part of the unlock for me.

(00:27:25):
Again, I care about other people. That's a natural gift that underlines it. But it's a redefinition of how that serves me, if that makes sense.

Lenny (00:27:34):
Say someone's in that first bucket ... And I was definitely in that first bucket. I still want people to like me and I still probably have flaws there. But say you're a PM and you're like, "Oh, man. That's exactly how I am acting right now." It sounds like is the core of it just a mindset shift, going from I need people to like me to what you just talked about of, okay, I'm going to shift to I just want them to respect me over time? Is that the core of it? I know it's probably not that easy, but how should someone behave during that bucket right now?

Ken Norton (00:28:03):
Yeah. It sounds easy, right? This is part of what's hard about this, is it always sounds easy when you describe it, having gone through the journey. It's sort of like talk to somebody on the summit of Mount Everest and they'll be like, "Yeah. Well, I could just climb this mountain. That's how I got here." You're like, "Okay, wait, that's not that easy." Again, it is very individualized.

(00:28:21):
I think there's an appreciation that you have to understand what is holding you back. This is a lot of the work that I'll do with my clients is what is those underlying expectations? What are these underlying beliefs?

(00:28:40):
I Believe that my style was incompatible with being the leader. I would've said I can't be a CEO because I'm not tough enough. I'm not strong enough. I'm not commanding enough. I can't command a room. It's like, okay, what is the underlying belief I'm making about what leadership is there? There's an archetype that I have in my mind that is incompatible with this this way.

(00:29:10):
And so, there's a need to confront that. Okay, what makes you believe the only type of leader is the leader that orders people around? Maybe that's all I've ever seen. Maybe I don't believe it's possible to be another type of leader. Maybe there's an inner critic that is convincing me that that's not who I am, because a part of it is redefinition of what does leadership need for you, for you authentically? What would it be like, in my case, to lead with purpose and be decisive and lead with vision and to have other people felt like they're being brought along and listened to and participated and create safe spaces for other people? That was the question there.

(00:29:47):
It took people challenging my point of view. It took working with a coach, asking me questions, forcing me to see places I'd made connections, that the connections don't really need to be made. There's a lot of instruments and tools we work with in coaching. There's 360-degree assessments that are very helpful here that will start to help you understand, hey, here are places where you're operating actively. Here are places where you're operating really creatively, because, by the way, most people are partially somewhere in that journey. It's a developmental process.

(00:30:17):
And to start to be able to get the feedback, the dopamine hit of seeing when I do it this way, actually it's more effective and it doesn't cost me as much. I'm happier and I'm enjoying it, I'm seeing that it's working, is oftentimes a big part of this because there is this belief that it won't work. The number of times when I'm with a client in coaching and say, "Well, what if you did do that?" and they go, "It just won't work." You realize that there is this wiring in there that needs ... And this is what I talk about, this operating system that needs to be rejiggered to start to make sense of what if it did and how might you know.

Lenny (00:30:55):
The point you just made about how you can realize that you can be successful in a lot of different ways and you don't have to be this one archetype of a leader really resonates with my experience. I actually had an executive coach for a few months, and that was probably the biggest unlock for me. We did the strengths exercise, which a lot of people do. The main thing that she helped me see is you can do all the things that you want to do through the lens of the strengths that you have and not have to force yourself to be good at these other things, because there's many ways to accomplish the same outcomes.

Ken Norton (00:31:29):
That's exactly right. Then once you start to understand that, you start to develop a better way of finding the right place, the right environment, the right role. When we began the conversation, you asked me what brought me into executive coaching. I would feel these ... I would describe it as flying too close to the sun in my career, where I would have a team. I'd be managing a small team. I would love it. I would enjoy it. Then suddenly my team would grow.

(00:31:57):
I'd become more senior than I felt comfortable being. Then I felt like I wasn't getting to do the "real" work anymore. Then I would be just completely disheveled and dissatisfied. Then I'd go try to go find a smaller team or even stop being a manager. It was a very meandering, reactive path. It was like every so often I was catching a wave, and I knew what it felt like to be on the wave, but I didn't know what the characteristics of the wave were.

(00:32:23):
Then through coaching, I was like I love connecting with other people. I like helping people grow. I like helping challenge people. I like helping. Then I was like what are those parts? What if I unpack those? Oh, that's why I loved managing that team of five because I got to do a lot of it. That's why I hated managing a team of 35 because there's no time for it.

(00:32:44):
Then you start to say, okay, well, what if rather than just randomly meandering through my career, I actually elevated needing to connect, wanting to be helpful? Then you're like what would it be like if I wanted the helping professions? It's just a reframing of move through your career in a way that seems externally to fit some definition of success and to start to define that internally.

(00:33:11):
That is the very definition of the reactive versus creative mindset. Reactive, allowing the world to set the expectations and try to meet them versus tap into what your real, true sense of purpose and vision is. Then use that to navigate the world.

Lenny (00:33:28):
It's interesting that so much of this is just mindset. It's not like learning a new skill as a leader or a product manager. It's just seeing yourself in the world differently. All of a sudden you unlock your career. Is that what you find?

Ken Norton (00:33:40):
Absolutely. That's why I think so much of the focus on the skills, the frameworks, it can be limited as you develop these capabilities, because it's inner work. Where we're talking about is this is all me.

(00:33:57):
Now that's empowering. There's empowerment to be able to say I want to change something and it doesn't involve a whole bunch of other people convincing and persuading them, getting into an executive ... This is all me. But it also, in some ways, makes it harder because it is all you. In coaching, it's all about you. It's all about that. Who am I and what matters to me? What underlying belief systems, inner voices are challenging me in ways that I want to be challenged? What is my unique ...

(00:34:31):
I love the word authenticity. It's, like you were just talking about, like what is my authentic way to lead, and then how do I center that rather than trying to fit into someone else's definition of what leadership might be?

(00:34:43):
You may recognize I can't be that authentic way of leader at this place or in this place type of company, but I know how to find it and I'm going to go find it.

Lenny (00:34:55):
Do you have any more examples of either someone uncovering this about themselves, or another mindset shift that you can make in one of these other buckets, similar to the idea of I'll think about people over the long term versus immediately?

Ken Norton (00:35:10):
Yeah. It really does vary. You start to pick up on that shift when it's less of the goals being defined externally and more of the goals being defined internally. So you'll have a conversation with somebody who's new to coaching and you'll say, "What do you want?" They'll be like, "Well, I want to get promoted to VP." "Why?" "Because I want to be a VP." It's like, "Well, what's important about being VP?" "Well, because ... " Eventually the answer is, well, because it's there and that's the thing that I'm supposed to do.

(00:35:45):
Then you start to notice the shift and it starts to become more of, "Well, because really what's important to me is creativity. I want more creativity in my life. I want more ability to challenge other people." And so, you start to just sense that's more from in than from out. That's where that shift is.

(00:36:06):
The journey is different for everyone. I think ultimately this is part of why, quite frankly, coaching may not be right for everyone. If we go back to that video game analogy, if you're looking for someone to just teach you the tutorial so you can learn how to play the video game and there's this jackass like me sitting next to you and saying, "What's important to you about playing this video game?" you're going to be like, "Just can you tell me how to hold the controller? Can you stop?"

(00:36:31):
So it's not always right. It's a place where I think oftentimes people recognize that they've gotten all the advice, all the frameworks, all the rules, all the tricks, all the tips. They've learned that, they've mastered it, they've tweaked it, they've optimized it, they've recognized the shortcomings, they've customized it. The emergence that's required for them to get to the next level is just going to come just as much from inside them as it is from outside, if not more. That's when that shift is made.

Lenny (00:36:58):
That's called mentorship, I think, for people that are just looking for actual concrete advice on how to do a thing, is that right, versus coaching?

Ken Norton (00:37:05):
I think so. This is where the words are squishy because there are a lot of people who are mentoring, who are also stepping into a coach role occasionally. There are plenty of managers who are great at coaching as necessary. So skills run the gamut, but it's a question of how much are you looking for someone to tell you the right way versus how much do you believe that there even is no right way? It's ultimately going to have to be your way.

(00:37:33):
That's a different place, a different point in your career at different levels of journey. It's part of why I tend to work with probably more senior executives, because they're not looking to me to tell them how to do the job. They've already learned how to do the job. It's just something deeper that's going to need to break through from that.

Lenny (00:37:50):
This episode is brought to you by Unit. What did Gusto, Uber, Shopify and AngelList all have in common? They've all decided to build banking into their product. According to AngelList head of product, "Banking makes every single feature more interesting. With it, our platform functions as financial mission control for our customers. Without it, we're just another software tool in a big messy stack."

(00:38:12):
Embedding banking into your product not only adds differentiation, but also helps you acquire, retain, and monetize your customers. Unit is the market leader in banking as a service, combining multiple bank partners with a developer-friendly API to empower companies of all sizes to launch accounts, cards, payments, and lending in just a few weeks.

(00:38:33):
Unit is trusted by leading brands such as AngelList, Highbeam, Invoice2go, and Roofstock. To hear more about how Unit enables companies like yours to build banking, visit unit.co/lenny to request a demo or to try their free sandbox. That's unit.co/lenny.

(00:38:51):
For someone that wants to do the work, but can't find a coach, can't afford a coach, is there something people can do on their own that you'd recommend to help them shift their mindset and do a lot of these things that you've been describing?

Ken Norton (00:39:06):
Yeah, it's a great question. Here's the secret about the coaching industry. Anyone can call themselves a coach. It's very democratized. It's great. There's no gatekeepers and barriers and there's no 500 licenses you have to go through.

(00:39:22):
There are tons of great coaches who are at various different price levels, at different levels of accessibility. And so, if you say, "I can't afford a coach," I might challenge that a little bit and say have you looked?

(00:39:36):
The other thing is that you don't need a coach who's done the job before. I mean obviously I've done the job before, so I'm undermining part of my own selling point here. But coaches are trained to coach people on any topic. So when I go through coach training, I can coach you on anything. People can coach you on anything.

(00:39:52):
Sometimes even there might be power in having a coach that's never done the product management job because there won't be any cheating of starting to move into a more of advisor role or maybe as the coach either. There may be, "Well, you tell me what should I should do," and the person would be like, "I don't know. I've never done this job. Let's go back to what you want." So there could be some benefit from that. Again, you don't have to have done that.

(00:40:13):
So I would say coaching is incredibly powerful. I wish I'd had a coach much, much earlier in my career. And so, the answer may be coaching is more accessible than you thought. If not, I think the things that we're talking about here are internal understanding of what matters to you, your sense of purpose, this inner curiosity, and that could be harnessed at any age. So just wondering about yourself at any point in your career, wondering what's important to you.

(00:40:43):
I love doing values work, like, "What are your values? Okay. No. What really are your values?" That's something you can do yourself. That's something you can question. You can read about, you can start to understand.

(00:40:53):
Mentors can be great, especially mentors who are less about trying to tell you the right way and get you to follow directly their path, but are more they're applying some curiosity, asking questions, challenging you in certain ways, being a way that you can bounce ideas off of.

(00:41:09):
Great managers, I think, especially the best product leaders, understand how to put the coach hat on and when it's appropriate to put the coach hat on, and are explicit about that, are like, "Okay, let me take off my manager hat now and put the coach hat on. What do you really want to do, Lenny? What's important to you? What's your career?" And so, I think you can get coaching from everywhere.

(00:41:28):
There's a lot of self-coaching you can do. This is honestly one of the benefits for me having gone through tons of training and coaching is starting to coach myself, like feeling an emotion and asking myself coach questions. Really powerful. That's something you can do when you've had a coach. You can do it when you don't have a coach. You can explore it.

(00:41:46):
So I think this is really all about really being curious and wanting to understand who you really are at the core and what's important to you and what matters. That's something that can be done with or without a coach.

Lenny (00:41:58):
Are there any resources that you love for either the values work or learning these questions to ask yourself? We can put them in the show notes if nothing comes to mind immediately. But is there something you recommend people check out?

Ken Norton (00:42:08):
Yeah, there are some great books. Maybe I'll use this opportunity to throw out a couple suggestions.

Lenny (00:42:13):
Let's do it.

Ken Norton (00:42:14):
I guess we can link it into the show notes. Brene Brown's Dare to Lead. It's a good book. She actually even has a whole section in there around values, confronting her values. I like her approach. There's some free resources on her website.

(00:42:26):
I love Conscious Leadership Group's work here. The 15 Commitments of Conscious Leadership book is fantastic. You don't even need to buy the book. There's a ton of stuff on their website. Jim Dethmer, Diana Chapman and Kaley Warner Klemp are of the authors of that book. That's all about a lot of the stuff we've been talking about. They're the ones that have the above the line versus below the line that fits into this creative versus reactive standpoint. Those are all fantastic.

(00:42:57):
If you want to go deeper into more of the management science behind it, if you're like me and really curious about the psychology and the management science, Bob Anderson and Bill Adams's book, Mastering Leadership, creates the entire integrated system around creative versus reactive.

(00:43:19):
As a teaser, they identify five levels of leadership, of which reactive is the second, creative is the third. So beyond that, you get into integral and unitive. So if you're looking to unlock the advanced stages beyond creative, there's a lot of great stuff in there. Those are where all the research comes in as well.

(00:43:38):
From an adult development standpoint, Robert Kegan is the godfather of the adult-stage development work and the meaning-making that underlines a lot of this. He has a great book called Immunity to Change if you're curious about that.

Lenny (00:43:52):
Awesome. We will link to all those in the description of this podcast so folks don't have to Google around. I have a couple of more coaching questions before we move on to a few other topics. One is just what are you finding are the most common blind spots for product people in general? How are people shooting themselves in the foot most?

Ken Norton (00:44:11):
Oh, that's a great question. I think probably the number one category, I'm not sure it's necessarily a problem, but maybe category or problems, is ... And this is, I think, great lesson for people earlier in their career, is how much all of the challenges that senior executives are dealing with come down to people versus product. So it's like it's fun to think about designing products, optimizing, doing user discovery, and testing what, but it's like you sit down with an executive and it's all about people.

(00:44:47):
That's the hard part. It's about persuading people, getting groups of people to want to work together, trying to figure out how to deal with difficult personalities, figuring out how to set a vision and articulate a vision, create an environment where people can collaborate and play.

(00:45:01):
And so, I think this category of blind spot often is people being confronted with that without having been intentional about thinking of it as a skill or an area that they needed to work on, needed to improve.

(00:45:18):
Part of what I think is pretty exciting about product management is you are a leader from day one in product management. There's leadership all over the place, but that's your job. You're a leader. You don't have any formal authority, but you're a leader. You're expected to lead.

(00:45:39):
Guess what? The hardest part about being a leader is when you don't get to just rely on the formal authority. So you're getting to practice all the hard parts about leadership from day one, because you're nobody's boss. You get to sharpen those skills, develop those intuitions, get better and better at that, so that when you do someday, if this is right for you, become someone else's boss, you've already been able to lean into that.

(00:46:04):
And so, the people side of this is such an incredible aspect of what product management is. What I find, and this may be a category of blind spots, is people realizing that when they're put in a position where they're expected to have impact and realizing that they haven't developed the skills, they haven't developed the capability to actually be able to manage and work through all these people, which is ...

Lenny (00:46:33):
How do you actually get better at that or develop those skills?

Ken Norton (00:46:37):
Yeah. I just think recognizing it is part of the job. It's important. Maybe I came up at a certain time where it was often dismissed as soft skills. It's just like soft skills are helpful, but they're not actually something you want to work on. They're not something you train, not something you ...

(00:46:54):
And this is just as important. This is the equal ... I wrote a piece recently about the art versus the science. The art is communication, collaboration, the more fuzzy, softer skills, people stuff. It's an elevation of that being just as important, if not more important, over time, as all this skills, techniques, tactics, managing a backlog, all that kind of stuff that you have to do. You should invest in that the same way you invest in those other skills.

(00:47:25):
So if you go off to a training to learn a technique for doing, I don't know, some sort of technical dashboard analysis, why don't you go to training to learn how to have difficult conversations? Because there's some great training about having difficult conversations, or do some training about storytelling. These are all really, really important factors that start to come into play.

(00:47:54):
What I would recommend is just appreciating that these are going to really, really matter and practicing and then valuing them and not thinking of them as something that either will matter later or a distraction or not really part of the job.

Lenny (00:48:07):
I think the reason people don't do that work is because it's so hard. Difficult conversations are difficult. We talked about this with Trey Hass. But just like it's a rule of thumb, the thing that is hard is probably the thing you should be doing. It's like a compass point of you to the thing you should do.

Ken Norton (00:48:23):
Absolutely. We are all about doing hard stuff, product managers. That's what we're all about. And so, when something seems hard and it seems squishy and it seems like it's difficult to put a three-step rule around, chances are it's really going to matter. It goes back to this mindset shift. That means that there's an opportunity for you to readjust your inner complexity management system to adapt to that area of complexity that you're now seeing, because this stuff really feels squishy. And so, that's even more of a reason why you want to get your hands around it and grab onto it and value it and learn and grow from it.

Lenny (00:49:07):
Speaking of difficult and squishy, I'm guessing that one of the biggest challenges that people you work with face and one of the most recurring themes is imposter syndrome, people having imposter syndrome, something definitely I went through and it comes up a lot on this podcast. What do you usually advise your clients to do when they're feeling imposter syndrome?

Ken Norton (00:49:27):
Yeah, it's a great question. I always get corrected to say imposter phenomenon by people in the psychology community, because I guess it's not a dysfunction. And so, I've learned to use their terms. But, yeah, I think just about everyone experiences it at some point. Research shows that that definitely is born out ... It's really the moments when you're doubting your abilities or you feel like a fraud or you feel like you don't belong.

(00:49:54):
It's funny because as I'm interrogating my own inner emotional state right now, I'm feeling it a little bit, because there's a part of me right now that's just like, "You're not a trained psychologist." When I said that whole thing, well, it's technically a phenomenon, there's a voice that was like, "What are you talking about? You don't know what you're talking about. Who are you [inaudible 00:50:14] on this?"

Lenny (00:50:14):
We'll put a disclaimer on the episode.

Ken Norton (00:50:16):
Yeah, I'm not a psychologist. So, look, we all feel it. There's a part of me right now that's like I'm going to say the wrong thing and embarrass myself. Product managers, product leaders maybe more so because the role is so cross-functional and ill-defined. There's always going to be an edge of the job that you aren't as qualified as whoever you're interacting with. It's the nature of it. Look, we're never going to be as good as an engineer, as good as a designer, as good ... So there's all these opportunities for that.

(00:50:40):
I find, certainly from client work, that there is a little bit of a softening and solidarity just knowing that. I'm just like, "Oh, you have that, too? Oh, I have that. Yeah, there's some value to that."

(00:50:51):
I think it's important to pause here and say that there is the risk of dismissing or even maybe weaponizing imposter phenomenon against particular populations, particularly women, people of color of all genders, women of color especially, who are facing real external feedback and doubt about their abilities.

(00:51:15):
The environment is reinforcing and the source of a lot of this stuff, microaggressions, bias, real aggressions. And so, I think we always have to be careful in the helping professions to not dismiss it as a problem that just shifts the obligation to the person. So it's like, "Oh, that's just your imposter syndrome. Deal with it." Well, it's really easy to overlook all these systemic issues that are leading to that imposter syndrome.

(00:51:39):
So the leaders I work with, I think we have a special obligation both to confront our own inner dynamic, but also to recognize what our role is in the broader environment that might be contributing to some of this stuff. If you're a leader, you have a special obligation to dismantle those, not when you're meeting with your people, be like, "Ah, it's just your imposter syndrome. You can work through it. Hire a coach," but to be able to recognize, "Okay, wait, what signals are you getting? What issues are contributing to this? What's our role in needing to change that?" So I think that's worth pointing out.

(00:52:13):
By the way, there's a great article in Harvard Business Review from a couple of years ago. I think the title was literally Stop Telling Women They Have Imposter Syndrome. The two authors of that were Ruchika Tulshyan and Jodi-Ann Burey, if you're curious and you want to go into more depth on that.

(00:52:29):
As coaches there, there's all sorts of ways we're trained to work with this. Oftentimes as an inner critic and inner voice, we all have voices, saboteurs. They're often trying to help us, they have good intentions, but they're developed to try to protect us in certain ways. So gaining awareness of those, just sort of like, "Oh, that is an inner critic. That's what it's trying to do." There's a self-distancing that's valuable to that, really kind of ...

(00:52:54):
I like to think of it a little bit as you got inner border directors, and there's some noisy, chatty voices that every so often sit in the chairperson's seat and start taking over. If you start to recognize, "Wait, no, I'm the chairperson. I don't want to hear from you right now. We'll hear from you later," it starts to create some power and you start to notice when it's happening.

(00:53:16):
We bypass inner critic sometimes as a classic coaching technique. It's like, "Okay, I'm sounding that's your inner critic is saying that. What if we just ask it to maybe step aside? Let's keep talking here."

(00:53:28):
You can befriend it. There's a lot of practices and works just actually trying to understand what its motivations are. You can think of it as a board. Give this board member a new job, put it on a new committee, reassign it.

(00:53:41):
There's oftentimes underlying belief systems. We talked before about my impression of what a real leader was and who they had to be. And so, hey, when all those second-guessing of me not being a real leader, of me not being qualified came from some of those underlying assumptions, that that was the only type of leader that was effective, was somebody that was slamming their fist out on the table.

(00:54:02):
Okay, so what if we redefine that? I'm too kind to be a leader. I'm not dominating, commanding enough. When you hear a client say that as a coach, you recognize, okay, there's a connection being made here between what effective leadership is and isn't. Let's interrogate that connection. Is that connection actually true?

(00:54:21):
Again, it get backs to this question of you're often responding to other styles, approaches you've seen. You're comparing yourself to others. So this is the reactive mindset of I'm always comparing myself to that person, to that wave, that being, and seeing myself as lesser then. And so, the inner work of starting to see who I really am truly inside and less comparing myself to others.

(00:54:42):
But, yeah, imposter phenomenon, syndrome, whatever you want to call it, very common and very popular, I suppose. Although when I say popular, it's like popular like a play.

Lenny (00:54:53):
Right. Another inner critic tactic I've heard that I used for a bit that was helpful is to give your inner critic a name, like Jim. I mean like, "Jim, not right now. I don't need you right now." That kind of helps.

Ken Norton (00:55:06):
Yeah. There is a whole school of coaching that I've worked with that's called parts work or internal family systems. It comes from a psychologist named Richard Schwartz who determined this. It can be really, really powerful.

(00:55:19):
I'll word my clients and we will give them names. We will imagine what they look like. They will interview these parts. If you've seen the Pixar movie Inside Out, this notion that like, hey, all these different parts show up in different ways. I'm going to put myself, the real me, the real self into the chairperson's seat. When I hear these voices, I'm going to appreciate them from what they are and who they are. They're not me. They're parts of me.

(00:55:46):
There's something really powerful in that, in that sense of like ... Because, otherwise, they're all me. So I just hear this voice telling me I'm an idiot and I'm a clown and I'm not qualified to be in this room. Then when you can start to go, "Oh, yeah, there it is. That's Larry Loser. My big angry, irritating judge who's, of course ... Oh, yeah, Larry always shows up every time I do something new, because Larry doesn't want me to challenge myself. So, of course, Larry's going to pipe in. I've heard from Larry. I'm going to ask Larry to step aside. Let's go." Yeah, it can be very powerful.

Lenny (00:56:22):
I love that. One last question about coaching. For folks that want to find a coach, do you have any advice of just how to find a coach, and then what are a couple questions you can ask to evaluate if they're a good fit for you?

Ken Norton (00:56:35):
Yeah, great question. So I think, like any helping profession, finding a therapist or really anyone who you're going to have a deep and lasting relationship with, this sort of trust and authenticity is really important. I think we all, as coaches, recognize, and we feel this as well with clients, is it either has to be a fit or not. Sometimes it's hard to put your finger on it. Sometimes you meet with someone and you're like, "Yeah, it clicks. It feels right." Sometimes you're like, "Eh, it doesn't," and that's okay. And so, all coaches worth their salt will offer a free session to understand that, engage that.

(00:57:13):
I always tell everyone in that session, if you don't decide to work with me or I decide ... We don't need a reason. It's fine. It's just not a fit, and that's okay. You don't need to come up with bullet point reasons to let me down. It's part of how it goes.

(00:57:28):
You might prefer certain people, certain gender, certain backgrounds. You may feel more comfortable or less comfortable with ... Maybe you want an old guy like me. Maybe you want an old guy like me, and that's fine. It has to feel right.

(00:57:41):
I would ask them to talk to you about what coaching is to them, because, again, it might combine some of these more mentory things. It might be more tactical. Some coaches are more structured, "Week one, we're going to do this. Week two, we're going to do this. Week ... " Others are more pure coaches like me, where, look, within the first five minutes, I'm going to ask you what you want to talk about today, because you're bringing the agenda. So figure that out. Figure out what works for you.

(00:58:07):
Then I think there's a lot of great places to go. Actually, specifically where to go, the International Coaching Federation is our governing body. So those of us that are credentialed coaches you'll find there. Again, you don't have to be credentialed, but that'll be a great place to find people who are.

(00:58:23):
There are some matchmaking services, BetterUp, Torch, or some of the more accessible ones. There's one called Prismaticco. It's a little bit more higher end for more senior execs. Scale just put out a list of top coaches who work with product managers and product leaders, all sorts of great coaches. We can include that link. Lenny, I think you're involved.

Lenny (00:58:43):
Yeah. Congrats on winning one of their categories for best coach of ... Which category was that?

Ken Norton (00:58:49):
Product leaders. So, yeah, this was just a setup for you to say that. But thank you. But there's tons of great coach, and different styles, different stages of careers. I think all those folks have work with or have worked with product folks.

(00:59:03):
And so, again, just talk to a few. Reach out to a few. Ask them. If you're looking for more names, ask people who you admire, whose leadership styles you like and want to emulate, who they recommend, because oftentimes they have a better understanding of, hey, this is the type of coach that may want to work with, more of the emotional work, or this is the type of coach who actually maybe has a more compatible vision of what you're looking for, because, look, all coaches are different. You can tell I'm a touchy-feely heart coach.

(00:59:35):
There are coaches who are ... Sometimes people want a coach and they're just like, "You grab that brass ring. We're going to pound the table. I'm going to push you. I'm going to challenge you. I'm going to beat you up. I'm going to be more of a drill sergeant." That's a different style of coach that works with other people. That may be more what you're looking for.

(00:59:50):
So I would just talk to a bunch, do some free sessions, get an opportunity to explore it. I coach people in the free session. So it's not just like we're talking. We're going to talk about something. I'm going to coach you. You're going to get a sense of what this looks like. Then come away and just ask yourself, what are your goals and where was there a fit? If there's not, just keep looking.

Lenny (01:00:09):
Amazing. That was very tactically helpful. I really appreciate all those resources. We'll definitely link to all that in the description. I have just a couple questions I wanted to ask you outside of coaching, around some of your posts that you've written before we get to our exciting lightning round. One is around this idea of 10X versus 10%.

(01:00:26):
So you wrote this post about the importance of thinking 10X versus 10%. Truthfully, I actually had a post started, "10X versus 10%." I was like, "Oh, this is going to be great." Then I Googled, "Oh, Ken's already written about it." So I'm glad that you have written about it and written about it so well.

Ken Norton (01:00:41):
Great minds think alike, as they say.

Lenny (01:00:44):
Now I don't have to write it. I'd love to just hear your general take on what this idea is and how to think about 10X or 10% bets.

Ken Norton (01:00:53):
Again, I'm a great synthesizer of ideas. This isn't my idea. This is a lot of ... It came from some thinking at Google and some push. I think it's really the sense that we think too small sometimes. You'll see that as a theme for some of the other things I've written too. There needs to be a push. If you really want to have huge breakthrough innovation, you need to be able to try, you need to be able to fail. You need to be able to shoot for the moon is where this 10X comes from.

(01:01:22):
A lot of it is mindset, but a lot of it is also cultural. It's creating environments where ... And I had the great privilege of working at Google for 14 years. I felt like it was definitely an environment that I got to play in, of being willing to take big swings that might fail.

(01:01:36):
This doesn't mean that the company could all be out of business tomorrow. But it's like if you have a choice between trying something that could have a massive breakthrough, a massive change, and playing small ball where you're going to get a bunch of 10% improvements, you are over time, if you're willing to try, if you're willing to fail, if you're willing to push yourself, if you're willing to think bigger, if you're willing to create environments, great ideas come from places that are unexpected, you'll achieve massive, massive breakthrough.

(01:02:02):
You can find the piece on my website, because I use examples from history, but it is a little bit of being brave and trying big things. If you look at all the great technology, the huge breakthrough innovations that we've had, the coronavirus vaccine, just this ... Man, there is no small balling that. That was a big, big swing that there was no guarantee of success, but we were willing to try it. We were willing to fail knowing that failure was probably the more likely outcome in the chance that we would achieve something that would really have that level of breakthrough.

(01:02:36):
And so, I think it is what I always challenge leaders to do is create the environment where people can step in and bring those types of ideas, and not play it safe or not be like, "Ah, boy, that seems like a big one. If we bring that to the CEO, there's no way they'll take a chance. So let's ramp down our expectations. Let's bring this little idea in that is a little bit more guaranteed to work."

(01:03:01):
And so, it is the obligation of leaders to create that environment for people to be able to innovate, because the ideas are out there. I use the example of Kodak. Kodak invented the digital camera. It wasn't like, oh, people at Kodak were dumb. They didn't know digital was coming. No, they literally invented the digital camera. There just wasn't an environment created where the people who had that idea, who saw that potential, who saw that possibility could step up through the plate and try.

Lenny (01:03:29):
Do you have any rules of thumb of how many of your ideas/resources should go into these big ideas versus incremental 10% bets, or is the general advice just like people aren't thinking big enough, often enough, so you should always think a little bit bigger than you naturally will?

Ken Norton (01:03:44):
I think it depends. I mean it depends on the company. If you work in R&D, in labs, maybe everything is in that category and you build a portfolio. If you're a venture capital seed investor, or if you're working at a research lab, it's like you're building a huge portfolio of these bets. You're just assuming that maybe 99 of them will fail, but one will succeed and it'll make it all worthwhile.

(01:04:09):
Most of us aren't in those environments. We're in places where we have real customers buying our products, wanting our products, using our products. We're like, "Let's bet the entire company own 50 things that may not work out." It may not be right for you.

(01:04:20):
So I think it is a little bit of an approach. I think it needs to be thought of in a fractal way, though, because maybe at the company level, they're thinking Google once upon a time had a 70-20-10 thing, whereas 70% is our core business. It's the time we're searching ads. 20% is adjacent business, and then 10% on crazy bets that may not be anything.

(01:04:43):
But I think that's at the company level. At the individual level, at your team level, you might have your own way of thinking. You're just like, okay, I've got 12 engineers on the team. We're working on, at any time, a bunch of stuff that we know we have to do. This is a bunch of stuff that we hope is like 10%. Then we're going to create some space for some innovation. Maybe it's just one engineer every sprint, or it's like a couple of times a year.

(01:05:09):
You create that type of space in your own little air bubble that isn't necessarily at the portfolio level, to try things that may not work. But if they do, the payoff will be so substantial that it'll make the whole thing worthwhile.

Lenny (01:05:23):
Awesome. Very helpful. Next question is around I think your most popular post that you've ever written, and maybe the thing that put you on the radar of writing, is around how to hire a product manager. Maybe this is where you mentioned donuts the first time. Is that right, or no?

Ken Norton (01:05:40):
It's funny. I think that was later.

Lenny (01:05:42):
Okay.

Ken Norton (01:05:43):
Yeah, I think that was a talk that came after that.

Lenny (01:05:45):
Okay, cool.

Ken Norton (01:05:46):
Yeah, that was definitely the big one for me.

Lenny (01:05:48):
So here's the question, just to keep it simple, what's one piece of advice that you would give people trying to hire a product manager? What's the thing that you think is most maybe missed or useful?

Ken Norton (01:06:00):
Yeah, I think the intangibles. So basically I wrote that originally as an email, that it was a copy pasta thing for me, where people kept coming to me and being like, "Hey, I think we're going to try to hire a product manager or a company. Can you send over a sample job description?" I'd be like, "Yeah. Before we write the job description, let's talk about what the job is, because I'm not sure we all mean the same thing." And so, then I wrote that ... It was in 2005, so this goes back ... to try to define what the role actually is.

(01:06:31):
I actually feel like maybe the pendulum shifted way too far now where it's the interview process is so structured. Everyone's doing all these mock. They know exactly what questions they're going to get. It's SAT prep. Everyone's ready. But we've missed out with can they do the job? Because it's like they can pass the interview, but can they do the job?

(01:06:53):
And so, I think you have to be careful. This is particularly the case if you are a smaller company. You don't have a huge apparatus of Google and Meta, where you've got interviewing monolith of getting persuaded into ... Maybe this goes back a little bit to the science and the art. They passed all the technical questions. They do all this, they do all that. They do all that. But then you neglect to find out can this person show up and work with these engineers, these designers? Can they inspire them? Is this somebody that they want to follow? Do they have the right mindset for what this job entails? Do we even have an agreement on what their job is going to be?

(01:07:35):
The number of people you see earlier in their career will be like, "Well, I thought I was hiring for this, but it turns that's not even product management," or it was like, "I thought I was going to do this, but all they want me to do is build fee." It's like how'd that not come out in the group process? It's like, well, I know how it didn't come out because they answered a whole bunch of structured questions around ... They did a programming exercise and they did a presentation and nobody stopped to ask.

(01:07:55):
And so, I think that's really the big thing from an interviewer perspective. I think same thing goes for the candidate's perspective. You are interviewing a potential employer. You're interviewing a boss. You're interviewing coworkers. What do you want? What do you care about? What is the type of place you want to be in? What do you not want to be in? How are you evaluating that? How are you asking those questions?

(01:08:18):
Yeah, salary matters, title. All that kind of stuff matters. But you're interviewing a place to plop yourself into. How are you approaching that to make sure you're making the right decision?

Lenny (01:08:30):
Well, with that, we've reached our very exciting lightning round, where I'm going to ask you a few questions and whatever comes to mind, just give me an answer. That's it. Very simple. Does that sound good?

Ken Norton (01:08:43):
Yeah. Inner critic is raging right now.

Lenny (01:08:45):
Oh, no. Real-time imposter syndrome.

Ken Norton (01:08:48):
Here we go.

Lenny (01:08:49):
[inaudible 01:08:49].

Ken Norton (01:08:48):
Yeah.

Lenny (01:08:50):
Okay. So question one, what are two or three books that you recommend most to other people?

Ken Norton (01:08:55):
Oh, 15 Commitments of Conscious Leadership. Definitely on that book. I'd just add books I've never recommended before. Probably Innovators Dilemma. It's probably my number one favorite book for product managers and product leaders.

Lenny (01:09:09):
Amazing. What's a recent movie or TV show that you've liked?

Ken Norton (01:09:14):
I love Ms. Marvel. My whole family were really enjoying it. I love all the MCU stuff. We just eat it up. Ms. Marvel has been amazing. Then watching Barry, which is crazy. It's sort of like nothing else I think ever on TV. Then, over the last year, probably Severance. It's my favorite program over the last ... I'd say last year.

Lenny (01:09:34):
Wow. Yeah. That is a trippy show. I've watched it all. We might be severed people, we don't even know.

Ken Norton (01:09:39):
You won't even know.

Lenny (01:09:41):
Okay. What is a favorite interview question that you like to ask folks when you interview them?

Ken Norton (01:09:46):
Well, actually let me flip it because I just talked about interviewing as the interview ... Maybe I'll ask a favorite question for people who are being interviewed to ask the employer. Is that fair or is that turn the tables too much?

Lenny (01:09:58):
I love it. Yes.

Ken Norton (01:09:59):
I think a great question ... Actually maybe I have a couple. I think one question that I love is how does the company define a product team? Because it answers so much. It says so much about culture, collaboration, decision-making, the role of product management. If there's one question and you could figure out what is this culture like, it would be asking that.

(01:10:20):
I think another great question for candidates is to ask them to pick an example of something they've shipped recently and just talk about how it came to be. How did the bill become a law? Was it somebody in sales yelled and it got added to the backlog and it was the next thing? Is it a group of people together understanding customer user needs through discovery and ideating and trying some things and testing it? It says a lot about what it would be like to work there, particularly when it comes to empowerment and product culture. So those are probably two good questions.

Lenny (01:10:58):
Those are really good questions. I'm going to steal them. Final question, who else in the industry do you respect as a thought leader? I imagine this list is very long, but what comes to mind?

Ken Norton (01:11:06):
Well, this list is all of my fellow podcast guests on your podcast, Lenny, which is, speaking of imposter phenomenon, is just an incredible group of all the folks that I love and admire. I think, though, because ... Maybe I'll answer it a little bit outside of product, because I would worry that I would leave out too many great names.

(01:11:26):
In the realms of leadership, Amy Edmondson is somebody I really admire. She's done a lot of the work on psychological safety. I really, really value her work, her contributions. There's a guy named Tom Garrity, who has a newsletter about psychological safety. I think he's collaborated with Amy before. It's one of the best, not the best newsletter I received, Lenny, maybe the second best, about psychological safety for those of us that are wanting to create environments where people can really thrive and do their best.

(01:12:05):
In the coaching profession, I mean the coaching profession emerges from the humanist psychology traditions or the client-first work of ... Carl Rogers and Abraham Maslow are intellectual heroes of mine. They're both dead. I don't know if we're supposed to talk about living people here, but definitely as I think about in my profession, they really set the stage and created the environment that coaching could even exist. So I'll include them.

Lenny (01:12:36):
Amazing. Ken, this was such a special episode, unlike any other podcast that I've had so far. I can't wait for people to listen to it. Before I let you go, where can folks find you online if they want to reach out, learn more, and then how can listeners be helpful to you?

Ken Norton (01:12:51):
Yeah, bringthedonuts.com is my home on the worldwide web. All my writing is there. You can get in contact with me there. I have a newsletter that I am occasionally send out, but you can find all the stuff that I've ever written and get in contact with me there.

(01:13:09):
The how to help be helpful question is a really easy one to answer, but that brings me a lot of joy, which is just keep being awesome product folks. You're so much my tribe. You're so close to my heart, all the work that you do, everything you bring into the world, the amazing products that we get to use that I'm sure you're working on right now that we haven't even seen yet, that you can't wait to share with us, and the cultures and teams that you make better, so your very existence. So I would say you can be helpful to me by just keep doing what you're doing.

Lenny (01:13:41):
What an awesome answer. Thank you for being here, Ken.

Ken Norton (01:13:43):
Thanks for having me, Lenny.

Lenny (01:13:46):
That was awesome. Thank you for listening. If you enjoyed the chat, don't forget to subscribe to the podcast and, even better, leave a review, which helps a lot. You can also learn more at lennyspodcast.com. I'll see you in the next episode.

---

## OpenAIs CPO on how AI changes must-have skills, moats, coding, startup playbooks, more | Kevin Weil
**Guest:** Kevin Weil  
**Published:** 2025-04-10  
**YouTube:** https://www.youtube.com/watch?v=scsW6_2SPC4  
**Tags:** growth, onboarding, roadmap, iteration, a/b testing, experimentation, conversion, monetization, hiring, management  

# OpenAIs CPO on how AI changes must-have skills, moats, coding, startup playbooks, more | Kevin Weil

## Transcript

Kevin Weil (00:00:00):
The AI models that you're using today is the worst AI model you will ever use for the rest of your life, and when you actually get that in your head, it's kind of wild. Everywhere I've ever worked before this, you kind of know what technology you're building on, but that's not true at all with AI. Every two months, computers can do something they've never been able to do before and you need to completely think differently about what you're doing.

Lenny Rachitsky (00:00:21):
You're chief product officer of maybe the most important company in the world right now. I want to chat about what it's just like to be inside the center of the storm.

Kevin Weil (00:00:29):
Our general mindset is in two months, there's going to be a better model and it's going to blow away whatever the current set of limitations are. And we say this to developers too. If you're building and the product that you're building is kind of right on the edge of the capabilities of the models, keep going because you're doing something right. Give it another couple months and the models are going to be great, and suddenly the product that you have that just barely worked is really going to sing.

Lenny Rachitsky (00:00:51):
Famously, you led this project at Facebook called Libra.

Kevin Weil (00:00:56):
Libra is probably the biggest disappointment of my career. It fundamentally disappoints me that this doesn't exist in the world today because the world would be a better place if we'd been able to ship that product. We tried to launch a new blockchain. It was a basket of currencies originally. It was integration into WhatsApp and Messenger. I would be able to send you 50 cents in WhatsApp for free. It should exist. To be honest, the current administration is super friendly to crypto. Facebook's reputation is in a very different place. Maybe they should go build it now.

Lenny Rachitsky (00:01:27):
Today my guest is Kevin Weil. Kevin is chief product officer at OpenAI, which is maybe the most important and most impactful company in the world right now, being at the forefront of AI and AGI and maybe someday super intelligence. He was previously head of product at Instagram and Twitter. He was co-creator of the Libra Cryptocurrency at Facebook, which we chat about. He's also on the boards of Planet and Strava and the Black Product Managers Network and the Nature Conservancy. He's also just a really good guy and he has so much wisdom to share. We chat about how OpenAI operates, implications of AI and how we will all work and build product, which markets within the AI ecosystem, companies like OpenAI won't likely go after and thus are good places for startups to own. Also, why learning the craft of writing evals is quickly becoming a core skill for product builders, what skills will matter most in an AI era and what he's teaching his kids to focus on and so much more.

(00:02:24):
This is a very special episode and I am so excited to bring it to you. If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. If you become an annual subscriber of my newsletter, you get a year free of Perplexity Pro, Linear, Notion Superhuman and Granola. Check it out at lennysnewsletter.com and click bundle. With that, I bring you Kevin Weil. This episode is brought to you by Eppo. Eppo is a next-generation A/B testing and feature management platform built by alums of Airbnb and Snowflake for modern growth teams. Companies like Twitch, Miro, ClickUp and DraftKings rely on Eppo to power their experiments. Experimentation is increasingly essential for driving growth and for understanding the performance of new features and Eppo helps you increase experimentation velocity while unlocking rigorous deep analysis in a way that no other commercial tool does.

(00:03:18):
When I was at Airbnb, one of the things that I loved most was our experimentation platform where I could set up experiments easily, troubleshoot issues, and analyze performance all on my own. Eppo does all that and more with advanced statistical methods that can help you shave weeks off experiment time and accessible UI for diving deeper into performance and out-of-the-box reporting that helps you avoid annoying prolonged analytic cycles. Eppo also makes it easy for you to share experiment insight with your team, sparking new ideas for the A/B testing flywheel. Eppo powers experimentation across every use case, including product, growth, machine learning, monetization, and email marketing. Check out Eppo at geteppo.com/lenny and 10X your experiment velocity. That's geteppo.com/lenny.

(00:04:06):
This episode is brought to you by Persona, the adaptable identity platform that helps businesses fight fraud, meet compliance requirements, and build trust. While you're listening to this right now, how do you know that you're really listening to me, Lenny? These days, it's easier than ever for fraudsters to steal PII, faces and identities. That's where Persona comes in. Persona helps leading companies like LinkedIn, Etsy, and Twilio securely verify individuals and businesses across the world. What sets Persona apart is its configurability. Every company has different needs depending on its industry, use cases, risk tolerance and user demographics. That's why Persona offers flexible building blocks that allow you to build tailored collection and verification flows that maximize conversion while minimizing risks. Plus Persona's orchestration tools automate your identity process so that you can fight rapidly shifting fraud and meet new waves of regulation. Whether you're a startup or an enterprise business, Persona has a plan for you. Learn more at withpersona.com/lenny. Again, that's withpersona.com/lenny. Kevin, thank you so much for being here and welcome to the podcast.

Kevin Weil (00:05:23):
Thank you so much for having me. We've been talking about doing this forever and we made it happen.

Lenny Rachitsky (00:05:27):
We did it. I can't imagine how insane your life is, so I really appreciate that you made time for this and we're actually recording this the week that you guys launched your new image model, which is a happy coincidence. My entire social feed is filled with ghiblifications of everyone's life and family photos and everything, so good job.

Kevin Weil (00:05:45):
Yep, mine too. My wife, Elizabeth, sent me one of hers, so I'm right there with you.

Lenny Rachitsky (00:05:51):
Let me just ask, did you guys expect this kind of reaction? It feels like this is the most viral thing that's happened in AI, which a high bar since, I don't know, ChatGPT launched. Just like, did you guys expect it to go this well? What does it feel like internally?

Kevin Weil (00:06:04):
There have been a handful of times in my career when you're working on a product internally and the internal usage just explodes. This was true by the way when we were building stories at Instagram. More than anything else in my career, we could feel it was going to work because we were all using it internally and we'd go away for a weekend. Before it launched we were all using it and we'd come back after a weekend and we would know what was going on and be like, "Oh, hey, I saw you were at that camping trip, how was that?" You were like, "Man, this thing really works." ImageGen was definitely one of those, so we'd been playing with it for, I don't know, a couple months and when it first went live internally to the company, there was kind of a little gallery where you could generate your own, you could also see what everyone else was generating and it was just nonstop buzz. So yeah, we had a sense that this was going to be a lot of fun for people to play with.

Lenny Rachitsky (00:06:58):
That's really cool. That should be a measure of just confidence into something going well that you're launching is internally everyone's going crazy for it.

Kevin Weil (00:07:05):
Yeah. Especially social things because you have a very tight network as a company socially, so you know each other and you're experts in your product hopefully. And so there's some sense in which if you're doing something social and it's not taking off internally, you might question what you're doing.

Lenny Rachitsky (00:07:23):
Yeah, and by the way, the Ghibli thing, is that something you guys seeded or how did that even start? Was that an intentional example?

Kevin Weil (00:07:29):
I think it's just the style people love and the model is really capable at emulating style or understanding what... It's very good at instruction following. That's actually something that I think people... I'm starting to see people discover with it, but you can do very complex things. You can give it two images, one is your living room and the other is a whole bunch of photos or memorabilia or things you want and you say, "Tell me how you would arrange these things." Or you can say, "I'd like you to show me what this will look like if you put this over here and this thing to the right of that and this one to the left of this, but under that one." And the model actually will understand all of that and do it. It's incredibly powerful. So I'm just excited about all the different things people are going to figure out.

Lenny Rachitsky (00:08:11):
Yeah. All right. Well, good job. Good job team OpenAI. Let's get serious here and let's zoom out a little bit. The way I see it is you're chief product officer of maybe the most important company in the world right now. Just not to set the bar too high, but you guys are ushering in AI, AGI at some point, super intelligence at some point. No big deal. I have more questions for you than I've had for any other guest. Actually put out a call-out on Twitter and LinkedIn and my community just like what would you want to ask Kevin? And I had over 300 well-formed questions and we're going to go through every single one. So let's just get started. I'm just joking.

Kevin Weil (00:08:45):
Cool.

Lenny Rachitsky (00:08:46):
I picked out the best and there's a lot of stuff I'm really curious about.

Kevin Weil (00:08:48):
Well, it's 1 PM here. It doesn't get dark for a while, so let's do it.

Lenny Rachitsky (00:08:53):
Okay, here we go. Okay, so first of all, I'm just going to take notes here. When is AGI launching? When in December?

Kevin Weil (00:08:58):
I mean, we just launched a good ImageGen model. Does that count?

Lenny Rachitsky (00:09:03):
It's getting there. It's getting there.

Kevin Weil (00:09:05):
There's this quote I love, which is "AI is whatever hasn't been done yet" because once it's been done, when it kind of works, then you call it machine learning, and once it's kind of ubiquitous and it's everywhere, then it's just an algorithm. So I've always loved that we call things AI when they still don't quite work and then by the time it's like an AI algorithm that's recommending you follow, oh, that's just an algorithm, but this new thing, like self-driving cars, that's it. I think to some degree we're always going to be there and the next thing is always going to be AI and the current thing that we use every day and is just a part of our lives, that's an algorithm.

Lenny Rachitsky (00:09:46):
It's so interesting because in the Bay Area you see self-driving cars driving around and it's so normal now when four years ago and three years ago, you would've seen this and you'd be like, "Holy shit, what is... We're in the future." And now we're just so take it for granted.

Kevin Weil (00:10:01):
I mean there's something like that with everything. If I showed you... When GPT-3 launched, I wasn't at OpenAI then. I was just a user, but it was mind-blowing. And if I gave you GPT-3 now I just plugged that into ChatGPT for you and you started using it, you'd be like, "What is this thing?" It's like mess.

Lenny Rachitsky (00:10:22):
Flop, flop.

Kevin Weil (00:10:24):
I had the same experience when I first got into a Waymo, your very first ride, at least my very first ride, my first 10 seconds in a Waymo, it starts driving and you're like, "Oh my God, watch out for that bike." You're holding onto whatever you can. And then five minutes in, you've calmed down and you realize that you're getting driven around the city without a driver and it's working. You're just like, "Oh my God, I am living in the future right now." And then another 10 minutes, you're bored, you're doing email on your phone, answering Slack messages, and suddenly this miracle of human invention is just an expected part of your life from then on. And there is really something in the way that we all are adapting to AI that's kind of like that. These miraculous things happen and computers can do something they've never been able to do before and it blows our mind collectively for a week and then we're like, oh, yeah. Oh, now it's just machine learning on its way to being an algorithm.

Lenny Rachitsky (00:11:23):
The craziest thing about what you just shared actually is, I don't know, ChatGPT, which is now feels terrible. 3.5 was a couple years ago, and imagine what life will be like in a couple years from now. We're going to get to that, where things are going, what you think is going to be the next big leap. But I want to start with the beginning of your journey at OpenAI. So you worked at Twitter, you worked at Facebook, you worked at Planet, Instagram. At some point you got recruited to go and come work at OpenAI. I'm curious just what that story was like of the recruiting process of joining OpenAI as CPO. Is there any fun stories there?

Kevin Weil (00:12:01):
If I'm remembering the timeline right, we communicated at Planet I was leaving and I was planning to just go take some time. I wasn't going to stop working, but I was also happy to take the summer. This was maybe April or something. I was like, cool, I'm going to have the summer with my kids. We're going to go to Tahoe or something and I'll actually get to hang out rather than what I usually do going up and down and all that. And then Sam and I had known each other lightly for a bunch of years and he's always involved in so many interesting things like companies building fusion and all these things. So he'd always been somebody that I would call occasionally if I was starting to think about my next thing because I like working on big tech forward, sort of next wave kind of things.

(00:12:49):
And so I called him and I think Vinod also helped to put us in touch again. And this time it wasn't like, "Oh, you should go talk to these guys working on fusion." He said, "Actually, we're thinking about something, you should come talk to us." I was like, "Okay, that sounds amazing. Let's do it." And it goes really fast, really, really fast. I met most of the management team in a brief period of time, a few days, and they were telling me, 'Look, we're basically going to move as fast as we want to move. And if you talk to everyone, everyone likes you, you're ready to go." Sam came over for dinner and we had a great evening together just talking about OpenAI in the future and getting to know each other better. And at the end I was like, I was going to go in the next day for a bigger round of interviews and Sam was saying, "Hey, it's going really well. We're really excited."

(00:13:52):
And I said, "Cool. So how do I think about tomorrow?" And he said, "Oh, you'll be fine. Don't worry about it. And if it goes well, we're basically there." And so I go in the next day, meet a bunch of people, have a great time. I really enjoyed everybody I met with. In any interview, you can always second guess yourself like, oh, I shouldn't have said that thing or that thing I gave a bad answer on I wish I could redo, but I came away feeling like I think that went pretty well. And I was expecting to hear that weekend basically because they sort of set expectations as soon as if this goes well, we're ready to go. And I didn't hear anything. And then it was like Monday, Tuesday, Wednesday, I still didn't hear anything and I reached out to folks on the OpenAI side a couple of times, still nothing.

(00:14:45):
And I was like, "Oh my God, I screwed it up. I don't know where I screwed it up, but I totally screwed it up. I can't believe it." And I was going back to Elizabeth, my wife and being like, "What did I do? Where do you think I..." Getting all crazy about it and then it's still nothing. And finally it was like nine days later, they finally got back to me and it turned out there was a bunch of stuff happening internally and this, that and the other thing, and there's just a million things happening. And they finally were like, "Oh yeah, that went well. Let's do this." And I was like, "Oh, okay, cool, let's do it." But it was nine days of agony and they were just super busy on some internal stuff and there I was fretting every single day and re-going over every line of our interview process.

Lenny Rachitsky (00:15:33):
It makes me think about when you're dating someone and you've texted them and you're not hearing anything back, you assume something is wrong.

Kevin Weil (00:15:40):
Yeah, totally.

Lenny Rachitsky (00:15:41):
They might just be busy.

Kevin Weil (00:15:42):
I have a hard time about it still.

Lenny Rachitsky (00:15:47):
That's wild. I love that it worked out. And I guess the lesson there is don't jump to conclusions.

Kevin Weil (00:15:55):
Yeah. Have a little bit of chill.

Lenny Rachitsky (00:15:59):
Speaking of that, I want to chat about what it's just like to be inside the center of the storm. Again, you work at a lot of, let's say traditional companies even though they're not that traditional, Twitter and Instagram and Facebook and Planet, and now you work at OpenAI. I'm curious, what is most different about how things work in your day-to-day life at OpenAI?

Kevin Weil (00:16:19):
I think it's probably the pace. Maybe it's two things. One is it's the pace. The second is everywhere I've ever worked before this, you kind of know what technology you're building on. So you spend your time thinking about what problems are you solving? Who are you building for? How are you going to make their lives better? How are you going to... Is this a big enough problem that you're going to be able to change habits? Do people care about this problem being solved? All those good product things. But the stuff that you're building on is kind of fixed. You're talking about databases and things and I bet the database you used this year is probably 5% better than the database you used two years ago, but that's not true at all with AI. It's like every two months computers can do something they've never been able to do before and you need to completely think differently about what you're doing.

(00:17:10):
There's something fundamentally interesting about that makes life fun here. There's also something we will maybe talk about evals later, but it also really, in this world of... Everything we're used to with computers is about giving a computer very defined inputs. If you look at Instagram for example, there are buttons that do specific things and you know what they do. And then when you give a computer defined inputs, you get very defined outputs. You're confident that if you do the same thing three times, you're going to get the same output three times. LLMs are completely different than that. They're good at fuzzy subtle inputs. Then all the nuances of human language and communication, they're pretty good at. And also they don't really give you the same answer. You probably get spiritually the same answer for the same question, but it's certainly not the same set of words every time. And so you're much more, it's fuzzier inputs and fuzzier outputs. And when you're building products, it really matters whether there's some use case that you're trying to build around.

(00:18:16):
If the model gets it right 60% of the time, you build a very different product than if the model gets it right 95% of the time versus if the model gets it right 99.5% of the time. And so there's also something that you have to get really into the weeds on your use case and the evals and things like that in order to understand the right kind of product to build. So that is just fundamentally different. If your database works once, it works every time. And that's not true in this world.

Lenny Rachitsky (00:18:45):
Let's actually follow this thread on evals. I definitely wanted to talk about this. We had this legendary panel at the Lenny & Friends Summit. It was you and Mike Krieger and Sarah Guo moderating.

Kevin Weil (00:18:58):
That was fun.

Lenny Rachitsky (00:18:58):
So fun. The thing that I heard that kind of stuck with people from that panel was a comment you made where you said that writing evals is going to become a core skill for product managers, and I feel like that probably applies further than just product managers. A lot of people know what evals are. A lot of people have no idea what I'm talking about. So could you just briefly explain what is an eval and then just why do you think this is going to be so important for people building products in the future?

Kevin Weil (00:19:23):
Yeah, sure. I think the easiest way to think about it is almost like a quiz for a model, a test to gauge how well it knows a certain set of subject material or how good it is at responding to a certain set of questions. So in the same way you take a calculus class and then you have calculus tests that see if you've learned what you're supposed to learn. You have evals that test how good is the model at creative writing? How good is the model at graduate level science? How good is the model at competitive coding? And so you have these set of evals that basically perform as benchmarks for how smart or capable the model is.

Lenny Rachitsky (00:20:04):
Is it a simple way to think about it, like unit tests for model?

Kevin Weil (00:20:07):
Yeah, unit tests, tests in general for models. Totally.

Lenny Rachitsky (00:20:10):
Great, great. Okay. And then why is this so important for people that don't totally understand what the hell's going on here with evals? Why is this so key to building AI products?

Kevin Weil (00:20:20):
Well, it gets back to what I was saying. You need to know whether your model is going to... There are certain things that models will get right. 99.95% of the time and you can just be confident. There are things that they're going to be 95% right on and things they're going to be 60% right on. If the model's 60% right on something, you're going to need to build your product totally differently. And by the way, these things aren't static either. So a big part of evals is if you know you're building for some use case. So let's take our deep research product, which is one of my favorite things that we've released maybe ever. The idea is with deep research for people who haven't used it, you can give ChatGPT now an arbitrarily complex query. It's not about returning you an answer from a search query, which we can also do.

(00:21:10):
It's here's a thing that if you were going to answer it yourself, you'd go off and do two hours of reading on the web and then you might need to read some papers and then you would come back and start writing up your thoughts and realize you had some gaps in your thinking. So you go out and do more research. It might take you a week to write some 20 page answer to this question. You can let ChatGPT just like chug for you for 25, 30 minutes. It's not the immediate answers you're used to, but it might go work for 25, 30 minutes and do work that would've taken you a week. So as we were building that product, we were designing evals at the same time as we were thinking about how this product was going to work and we were trying to go through hero use cases.

(00:21:57):
Here's a question you want to be able to ask. Here's an amazing answer for that question. And then turning those into evals and then hill climbing on those evals. So it's not just that the model is static and we hope it does okay on a certain set of things, you can teach the model. You can make this a continuous learning process. And so as we were fine-tuning our model for deep research to be able to answer these things, we were able to test is it getting better on these evals that we said were important measures of how the product was working? And it's when you start seeing that and you start seeing performance on evals going up, you start saying, "Okay, I think we have a product here."

Lenny Rachitsky (00:22:35):
You made a kind of a comment along these same lines around evals that AI is almost capped in how amazing it can be by how good we are at evals. Does that resonate? Any more thoughts along those lines?

Kevin Weil (00:22:48):
I mean, these models are their intelligences and intelligence is so fundamentally multidimensional so you can talk about a model being amazing at competitive coding, which may not be the same as that model being great at front-end coding-

Kevin Weil (00:23:00):
... may not be the same as that model being great at front-end coding or back-end coding or taking a whole bunch of code that's written in COBOL and turning it into Python. And that's just within the software engineering world. So I think there's a sense in which you can think of these models as incredibly smart, very factually aware intelligences, but still most of the world's data, knowledge, process is not public. It's behind the walls of companies or governments or other things. And same way, if you were going to join a company, you would spend your first two weeks onboarding. You'd be learning the company-specific processes. You'd get access to company-specific data. The models are smart enough, you can teach them anything, but they need to have the raw data to learn from.

(00:23:58):
So there's a sense in which I think the future is really going to be incredibly smart, broad-based models that are fine-tuned and tailored with company-specific or use case-specific data so that they perform really well on company-specific, or use case-specific things. And you're going to measure that with custom evals. So what I was referring to is just like these models are really smart, you need to still teach them things if the data's not in their training set, and there's a huge amount of use cases that are not going to be in their training set because they're relevant to one industry or one company.

Lenny Rachitsky (00:24:40):
I'm just going to keep following the thread that you're leading us down, but I'm going to come back because I have more questions around some of these things. So you came to a space that I think a lot of AI founders are thinking about is just, where's OpenAI not going to come squash me in the future? Or one of the other foundational models. So it's unclear to a lot of people just like, "Should I build a startup in this space or not?" Is there any advice you have or any guidance for where you think OpenAI, or just foundational models in general likely won't go and where you have an opportunity to build a company?

Kevin Weil (00:25:10):
So this is something that Ev Williams used to say back at Twitter that's always stuck with me, which is, "No matter how big your company gets, no matter how incredible the people are, there are way more smart people outside your walls than there are inside your walls." And that's why we are so focused on building a great API. We have 3 million developers using our API. No matter how ambitious we are, how big we grow, by the way, we don't want to grow super big, there are so many use cases, places in the world where AI can fundamentally make our lives better. We're not going to have the people. We're not going to have the know-how to build most of these things.

(00:25:55):
And I think, like I was saying, the data is industry-specific, use case-specific, behind certain company walls, things like that. And there are immense opportunities in every industry and every vertical in the world to go build AI-based products that improve upon the state of the art. And there's just no way we could ever do that ourselves. We don't want to. We if we did want to, and we're really excited to power that for 3 million-plus developers and way more in the future.

Lenny Rachitsky (00:26:24):
Coming back to your earlier point about the tech changing constantly and getting faster, not exactly knowing what you'll have by the time you launch something in terms of the power, the model. I'm curious what allows you to ship quickly and consistently in such great stuff? And it sounds like one answer is bottoms-up empowered teams versus a very top-down roadmap that's planned out for a quarter. What are some of those things that allow you to ship such great stuff so often, so quickly?

Kevin Weil (00:26:53):
Yeah. I mean, we try and have a sense of where we're trying to go, point ourselves in a direction so that we have some rough sense of alignment. Thematically, I don't for second, and we do quarterly roadmapping. We laid out a year-long strategy. I don't for a second believe that what we write down in these documents is what we're going to actually ship three months from now, let alone six or nine. But that's okay. I think it's like an Eisenhower quote, "Plans are useless. Planning is helpful," which I totally subscribe to, especially in this world. It's really valuable. If you think about quarterly road roadmapping for example, it's really valuable to have a moment where you stop and go, "Okay. What did we do? What worked? What went well? What didn't go well? What did we learn and now what do we think we're going to do next?"

(00:27:44):
And by the way, everybody has some dependencies. You need the infrastructure team to do the following things, partnership with research here. So you want to have a second to check your dependencies, make sure you're good to go and then start executing. We try and keep that really lightweight because it's not going to be right. We're going to throw it out halfway because we will have learned new things. So the moment of planning is helpful even if it's only partially.

(00:28:12):
So I think just expecting that you're going to be super agile and that there's no sense writing a three month roadmap, let alone a year long roadmap because the technology's changing underneath you so quickly. We really do try and go very strongly bottoms up, subject to our overall directional alignment. We have great people. We have engineers and PMs and designers and researchers who are passionate about the products they're building and have strong opinions about them and are also the ones building them. So they have a real sense of what the capabilities are too, which is super important.

(00:28:49):
So I think you want to be more bottoms up in this way. So we operate that way. We are happy making mistakes. We make mistakes all the time. It's one of the things I really appreciate about Sam. He pushes us really hard to move fast, but he also understands that with moving fast comes, we didn't quite get this right or that we launched this thing, it didn't work. We'll roll it back. Look at our naming. Our naming is horrible.

Lenny Rachitsky (00:29:14):
That was a lot of questions people had for you. Model names, yeah.

Kevin Weil (00:29:18):
It's absolutely atrocious and we know it, and we will get around to fixing it at some point, but it's not the most important thing and so we don't spend a lot of time on it.

Lenny Rachitsky (00:29:27):
But it also shows you how it doesn't matter. Again, ChatGPT the most popular, fastest growing product in history, it's the number one AI, API and model. So clearly it doesn't matter that much.

Kevin Weil (00:29:39):
And we name things like o3 mini high.

Lenny Rachitsky (00:29:46):
Man, I love it. Okay. So you talked about roadmapping and bottoms up and I'm really curious, is there a cadence or a ritual of aligning with you or Sam or you review everything that's going out? Is there a meeting every week or every month where you guys see what's happening?

Kevin Weil (00:30:03):
On key projects. So we do product reviews and things like that, like you would expect. There isn't a ritual because there isn't... I would never want us to be blocked on launching something, waiting for a review with me or Sam, if we can't get there. If I'm traveling or Sam's busy or whatever, that's a bad reason for us not to ship. So obviously for the biggest, most high priority stuff, we have a pretty close beat on it, but we really try not to, frankly. We want to empower teams to move quickly, and I think it's more important to ship and iterate.

(00:30:42):
So we have this philosophy, we call iterative deployment, and the idea is we're all learning about these models together. So there's a real sense in which it's way better to ship something even when you don't know the full set of capabilities and iterate together in public. And we co-evolve together with the rest of society as we learn about these things and where they're different and where they're good and bad and weird. I really like that philosophy.

(00:31:12):
I think the other thing that ends up being a part of our product philosophy is the sense of model maximalism. The models are not perfect. They're going to make mistakes. You could spend a lot of time building all kinds of different scaffolding around them. And by the way, sometimes we do because sometimes there are kinds of errors that you just don't want to make, but we don't spend that much time building scaffolding around the parts that don't match that because our general mindset is in two months there's going to be a better model and it's going to blow away whatever the current set of limitations are.

(00:31:52):
So if you're building, and we say this to developers too, if you're building and the product that you're building is right on the edge of the capabilities of the models, keep going, because you're doing something right because you give it another couple months and the models are going to be great, and suddenly the product that you have that just barely worked is really going to sing. And that's how you make sure that you're really pushing the envelope and building new things.

Lenny Rachitsky (00:32:19):
I had the founder of Bolt on the podcast, StackBlitz is the company name, and he shared this story that they've been working on this product for seven years behind the scenes and it was failing. Nothing was happening. And then all of a sudden it was, sorry to mention a competitor, but Claude came out or a Sonnet 3.5 came out and all of a sudden everything worked and they've been building all this time and finally it worked. And I hear that a lot with YC, just like things that never were possible now are just becoming possible every few months with the updates to the models.

Kevin Weil (00:32:48):
Yeah, absolutely.

Lenny Rachitsky (00:32:50):
Let me actually ask this, I wasn't planning to ask this, but I'm curious if you have any quick thoughts just why is Sonnet so good at coding, and thoughts on your stuff getting as good and better at actual coding?

Kevin Weil (00:33:01):
Yeah. I mean, kudos to Anthropic. They've built very good coding models. No doubt. We think that we can do the same. Maybe by the time this podcast has shipped, we'll have more to say, but either way, all credit to them. I think intelligence is really multi-dimensional and so I think the model providers... It used to be that OpenAI had this massive model lead, 12 months or something ahead of everybody else. That's not true anymore. I like to think we still have a lead. I'd argue that we do, but it's certainly not a massive one. And that means that there are going to be different places where the Google models are really good or where Anthropic models are really good, or where we're really good and our competitors are like, "We got to get better at that." And it actually is easier to get better at a certain thing once someone's proved it possible than it is to forge a path through the jungle and doing something brand new.

(00:34:03):
So I just think as an example, it was like nobody could break 4 minutes in the mile, and then finally somebody did and the next year 12 more people did it. I think there's that all over the place and it just means that competition is really intense, and consumers are going to win and developers are going to win and businesses are going to win in a big way from that. It's part of why the industry moves so fast, but all respect to the other big model providers. Models are getting really good. We're going to move as fast as we can and I think we've got some good stuff coming.

Lenny Rachitsky (00:34:36):
Exciting. This makes me also think about, in many ways other models are better at certain things, but somehow ChatGPT is the... If you look at all the awareness numbers and usage numbers, it's like no matter where you guys are in the rankings, people seem to just think of AI ChatGPT almost as the same. What do you think you did right to win in the consumer mindset, at least at this point and awareness in the world?

Kevin Weil (00:35:02):
I think being first helps, which is one of the reasons why we're so focused on moving quickly. We like being the first to launch new capabilities. Things like deep research. Our models, they can do a lot of things. So they can take real-time video input, you have speech to speech, you can do speech to text and text to speech. They can do deep research. They can operate on a canvas, they can write code. So ChatGPT can be this one- stop-shop where all the things that you want to do are possible. And as we go forward in it, we have more agentic tools like Operator where it's browsing for you and doing things for you on the web, more and more you're going to be able to come to this one place to ChatGPT, give it instructions and have it accomplish real things for you in the world. There's something fundamentally valuable in that. So we think a lot about that. We try to move really fast so that we are always the most useful place for people to come to.

Lenny Rachitsky (00:36:04):
What would you say is the most counterintuitive thing that you've learned after building AI products or working at OpenAI, something that's just like, "I did not expect that?"

Kevin Weil (00:36:14):
I don't know, maybe I should have expected this, but one of the things that's been funny for me is the extent to which you're trying to figure out how some product should work with AI, or even why some AI thing happens to be true, you can often reason about it the way you would reason about another human and it works. So maybe a couple examples. When we were first launching our reasoning model, we were the first to build a model that could reason, that could, instead of giving you just a quick system one answer right away to every question you asked, it was the third Emperor of the Holy Roman Empire, here's an answer.

(00:36:59):
You could ask it hard questions and it would reason. The same way that if I asked you to do a crossword puzzle, you couldn't just snap fill in everything. You would be, "Well, okay. On this one across, I think it could be one of these two, but that means there's an A here. So that one has to be this, away, back track, step-by-step build up from where you are." Same way you answer any difficult logistical problem, any scientific problem. So this reasoning breakthrough was big, but it was also the first time that a model needed to sit and think. And that's a weird paradigm for a consumer product. You don't normally have something where you might need to hang out for 25 seconds after you ask a question.

(00:37:40):
So we were trying to figure out what's the UI for this? With deep research where the model's going to go and think for 25 minutes sometimes, it's actually not that hard because you're not going to sit and watch it for 25 minutes. You're going to go do something else. You're going to go to another tab or go get lunch or whatever, and then you'll come back and it's done when it's like 20, 25 seconds or 10 seconds, it's a long time to wait, but it's not long enough to go to do something else.

(00:38:09):
So you can think, if you asked me something that I needed to think for 20 seconds to answer, what would I do? I wouldn't just go mute and not say anything and shut down for 20 seconds and then come back. So we shouldn't do that. We shouldn't just have a slider sitting there. That's annoying. But I also wouldn't just start babbling every single thought that I had. So we probably shouldn't just expose the whole chain of thought as the model's thinking, but I might go like, "That's a good question. All right." I might approach it like that and then think. You're maybe giving little updates and that's actually what we ended up shipping.

(00:38:49):
You have similar things where you can find situations where you get better thinking sometimes out of a group of models that all try and attack the same problem, and then you have a model that's looking at all their outputs and integrating it and then giving you a single answer at the end. I mean, sounds a little bit like brainstorming. I certainly have better ideas when I get in a room and brainstorm with other people because they think differently than me. So anyways, there's just all these situations where you can actually reason about it like a group of humans or an individual human and it works, which I don't know, maybe I shouldn't have been surprised but I was.

Lenny Rachitsky (00:39:27):
That is so interesting because when I see these models operate, I never even thought about you guys designing that experience. To me, it just feels like this is what the LLM does. It just sits there and tells me what it's thinking. And I love this point you're making of let's make it feel like a human operating and well, how does a human operate? Well, they just talk aloud. They think, here's the thing I should explore. And I love that deep sequence to the extreme of that where they're just like, "Here's everything I'm doing and thinking." And people actually like that too, I guess. Was that surprising to you, "Maybe that could work too. People seem to like everything?"

Kevin Weil (00:40:02):
Yeah. We learned from that actually because when we first launched it, we gave you the subheadings of what the model was thinking about, but not much more. And then deep seek launched and it was a lot and we went, I don't know if everyone wants that. There's some novelty effect to seeing what the model's really thinking about. We felt that too when we were looking at it internally. It's interesting to see the model's chain of thought, but it's not... I think at the scale of 400 million people, you don't want to see the model babble a bunch of things.

(00:40:34):
So what we ended up doing was summarizing it in interesting ways. So instead of just getting the subheadings, you're getting one or two sentences about how it's thinking about it and you can learn from that. So we tried to find a middle ground that we thought was an experience would be meaningful for most people, but showing everybody three paragraphs is probably not the right answer.

Lenny Rachitsky (00:40:57):
This reminds me of something else you said at the summit that has really stuck with me, this idea that chat, people always make fun of chat is not the future interface for how we interact with AI, but you made this really interesting point that may argue the other side, which is, as humans we interface by talking and the IQ of a human can span from really low to really high and it all works talking to them and chat is the same thing and it can work on all kinds of intelligence levels. Maybe I just shared it, but I guess anything there about just why chat actually ends up being such an interesting interface for LLMs?

Kevin Weil (00:41:30):
Yeah. I don't know, maybe this is one of those things I believe that most people don't believe, but I actually think chat is an amazing interface because it's so versatile. People tend to go, "Chat. Yeah. We'll figure out something better." And I think it's incredibly universal because it is the way we talk. I can talk to you verbally like we're talking now. We can see each other and interact. We can talk on WhatsApp and be texting each other, but all of these things is this unstructured method of communication and that's how we operate.

(00:42:12):
If I had some more rigid interface that I was allowed to use when we spoke, I would be able to speak to you about far fewer things and it would actually get in the way of us having maximum communication bandwidth. So there's something magical. And by the way, in the past it never worked because there wasn't a model that was good at understanding all of the complexity and nuances of human speech, and that's the magic of LLMs. So to me, it's like an interface that's exactly fit to the power of these things. And that doesn't mean that it always has to be just like I don't necessarily always want to type, but you do want that very open-ended, flexible communication medium, it may be that we're speaking and the model's speaking back to me, but you still want the very lowest common denominator, no restrictions way of interacting.

Lenny Rachitsky (00:43:04):
That is so interesting. That's really changed the way I think about this stuff is that point that chat is just so good for this very specific problem of talking to superintelligence basically.

Kevin Weil (00:43:13):
By the way, I think it's not that it's only chat either. If you have high volume use cases where they're more prescribed and you don't actually need the full generality, there are many use cases where it's better to have something that's less flexible, more prescribed, faster to specific task, and those are great too, and you can build all sorts of those. But you still want chat as this baseline for anything that falls out of whatever vertical you happen to be building for. It's like a catch-all for every possible thing you'd ever want to express to a model.

Lenny Rachitsky (00:43:51):
I'm excited to chat with Christina Gilbert, the founder of OneSchema, one of our long-time podcast sponsors. Hi, Christina.

Christina Gilbert (00:43:58):
Yes. Thank you for having me on, Lenny.

Lenny Rachitsky (00:44:00):
What is the latest with OneSchema? I know you now with some of my favorite companies like Ramp, Vanta, Scale and Watershed. I heard that you just launched a new product to help product teams import CSVs from especially tricky systems like ERPs?

Christina Gilbert (00:44:15):
Yes. So we just launched OneSchema FileFeeds, which allows you to build an integration with any system in 15 minutes as long as you can export a CSV to an SFTP folder. We see our customers all the time getting stuck with hacks and workarounds, and the product teams that we work with don't have to turn down prospects because their systems are too hard to integrate with. We allow our customers to offer thousands of integrations without involving their engineering team at all.

Lenny Rachitsky (00:44:37):
I can tell you that if my team had to build integrations like this, how nice would it be to be able to take this off my roadmap and instead, use something like OneSchema and not just to build it, but also to maintain it forever.

Christina Gilbert (00:44:49):
Absolutely, Lenny. We've heard so many horror stories of multi-day outages from even just a handful of ad records. We are laser-focused on integration reliability to help teams end all of those distractions that come up with integrations. We have a built-in validation layer that stops any bad data from entering your system, and OneSchema will notify your team immediately of any data that looks incorrect.

Lenny Rachitsky (00:45:08):
I know that importing incorrect data can cause all kinds of pain for your customers, and quickly lose their trust. Christina, thank you for joining us. And if you want to learn more, head on over to oneschema.co. That's oneschema.co.

(00:45:23):
I want to come back to that you talked about researchers and their relationship with product teams. I imagine a lot of innovation comes from researchers just like having an inkling and then building something amazing and then releasing it, and some ideas come from PMs and engineers. How do those teams collaborate? Does every team have a PM? Is it a lot of research-led stuff? Give us a sense of just where ideas and products come from mostly.

Kevin Weil (00:45:49):
It's an area where we're evolving a lot. I'm really excited about it, frankly. I think if you go back a couple of years when ChatGPT was just getting started, obviously, I wasn't in OpenAI, but...

Kevin Weil (00:46:00):
Obviously I wasn't an Open AI, but... We were more of a pure research company at the time. Chat GPT, if you remember, was a low-key research preview.

Lenny Rachitsky (00:46:14):
For many years.

Kevin Weil (00:46:15):
Yeah. It wasn't a thing that the team launched thinking it was going to be this massive product.

Lenny Rachitsky (00:46:19):
Oh, Chat GPT. Yeah.

Kevin Weil (00:46:21):
And it was just a way that we were going to let people play with and iterate on the models. So we were primarily a research company, a world-class research company, and as ChatGPT has grown and as we've built our B-to-B products and our APIs and other things, now we're more of a product company than we were. I still think we can't... Open AI should never be a pure product company. We need to be both a world-class research company and a world-class product company, and the two need to really work together, and that's the thing that I think we've been getting much better at over the last six months. If you treat those things separately and the researchers go do amazing things and build models and then they get to some state and then the product and engineering teams go take them and do something with them, we're effectively just an API consumer of our own models.

(00:47:17):
The best products though are going to be, it's like I was talking about with deep research, it's a lot of iterative feedback. It's understanding the products you're trying to sell or the problems you're trying to solve, building evals for them, using those evals to go gather data and fine-tune models to get them to be better at these use cases that you're looking to solve. It's a huge amount of back and forth to do it well. And I think the best products are going to be ENG product design and research working together as a single team to build novel things. So that's actually how we're trying to operate with basically anything that we build. It's a new muscle for us because we're kind of new as a product company, but it's one that people are really excited about because we've seen every time we do it, we build something awesome, and so now every product starts like that.

Lenny Rachitsky (00:48:07):
How many product managers do you have at Open AI? I don't know if you share that number, but if you do.

Kevin Weil (00:48:11):
Not that many, actually. I don't know, 25. Maybe it's a little more than that. My personal belief is that you want to be pretty PM light as an organization just in general. I say this with love because I am a PM, but too many PMs causes problems. We'll fill the world with decks and ideas versus execution. So I think it's a good thing when you have a PM that is working with maybe slightly too many engineers because it means they're not going to get in and micromanage. You're going to leave a lot of influence and responsibility with the engineers to make decisions. It means you want to have really product-focused engineers, which we're fortunate to have. We have an amazingly product focused, high agency engineering team. But when you have something like that, you have a team that feels super empowered, you have a PM that's trying to really understand the problems and gently guide the team a little bit but has too much going on to get too far into the details, and you end up being able to move really fast. So that's kind of the philosophy we take.

(00:49:23):
We want Product ENG leads and product engineers all the way through. We want not too many PMs, but really awesome, high quality ones, and so far that seems to be working pretty well.

Lenny Rachitsky (00:49:36):
I imagine being a PM at Open AI is a dream come true for a lot of people. At the same time, I imagine it's not a fit for a lot of people. There's researchers involved, very product minded engineers. What do you look for in the PMs that you hire there for folks that are like, "Maybe I shouldn't go work there. I shouldn't even think about that."

Kevin Weil (00:49:54):
I think, I've said this a few times, but high agency is something that we really look for, people that are not going to come in and wait for everyone else to allow them to do something, they're just going to see a problem and go do it. It's just a core part of how we work. I think people that are happy with ambiguity, because there is a massive amount of ambiguity here, it is not the kind of place, and we have trouble sometimes with more junior PMs because of this, because it's just not the place where someone is going to come in and say, "Okay, here's the landscape, here's your area, I want you to go do this thing." And that's what you want as an early career PM. I mean, no one here has time and the problems are too ill-formed and we're figuring them all out as we go. And so high agency, very comfortable with ambiguity, ready to come in and help execute and move really quickly. That's kind of our recipe.

(00:50:55):
And I think also happy leading through influence because... I mean it's usual as a PM, people don't report to you, your team doesn't report to you, et cetera, but you also have the complexity of a research function, which is even more sort of self-directed and it's really important to build a good rapport with the research team. I think the EQ side of things is also super important for us.

Lenny Rachitsky (00:51:24):
I know at most companies, a PM comes in and they're just like, "Why do we need you?" And as a PM you have to earn trust and help people see the value, and I feel like at Open AI it's probably a very extreme version of that where they're like, "Why do we need this person? We have researchers, engineers, what are you going to do here?"

Kevin Weil (00:51:40):
Yeah, I think people appreciate it done right, but you bring people along. I think one of the most important things a PM can do well is be decisive. So there's a real fine line. You don't want to be making... I mean it's kind of like, I don't love the PM as the CEO of the product illusion all the time, but just like Sam in his role would be making mistakes if he made every single decision in every meeting that he was in. And he would also be making mistakes if he made no decisions in any meetings that he was in, right? It's understanding when to defer to your team and to let people innovate. And when there is a decision to be made that people either don't feel comfortable with or don't feel empowered to make, or a decision that has too many different disparate pros and cons that are spread out across a big group and someone needs to be decisive and make a call, it's a really important trait of a CEO.

(00:52:41):
It's something Sam does well, and it's also a really important trait of a PM kind of at a more microscopic level. So because there's so much ambiguity, it's not obvious what the answer is in a lot of cases, and so having a PM that can come in and... And by the way, this doesn't need to be a PM, I'm perfectly happy if it's anybody else, but I kind of look to the PM to say, if there's ambiguity and no one's making a call, you better make sure that we get a call made and we move forward.

Lenny Rachitsky (00:53:07):
This touches on a few posts I've done of just, where is AI going to take over work that we do versus help us with various work? So let me come at this question from a different direction of just how AI impacts product teams and hiring, things like that. So first of all, there's all this talk of LM's doing our coding for us, and 90% of code is going to be written by AI in a year. Dario at Anthropic said that. At the same time, you guys are all hiring engineers like crazy, PM's like crazy. Every function is dead, but you're still hiring every single one. I guess just, first of all, let me just ask this, how do you and the team, say engineers, PMs, use AI in your work? Is there anything that's really interesting or things that you think people are sleeping on in how you use AI in your day-to-day work?

Kevin Weil (00:53:52):
We use it a lot. I mean, every one of us is in Chat GPT all the time summarizing docs, using it to help write docs with GPTs that write product specs and things like that, all the stuff that you would imagine. I mean talk about writing evals, you can actually use models to help you write evals and they're pretty good at it. That all said, I'm still sort of disappointed by us, and I really mean me, in, if I were to just teleport my five-year-old self leading product at some other company into my day job, I would recognize it still. And I think we should be in a world, certainly a year from now, probably even more now, where I almost wouldn't recognize it because the workflows are so different and I'm using AI so heavily, and I'd still recognize it today. So I think in some sense, I'm not doing a good enough job of that.

(00:54:46):
Just to give an example, why shouldn't we be vibe coding demos right, left and center? Instead of showing stuff in Figma, we should be showing prototypes that people are vibe coding over the course of 30 minutes to illustrate proofs of concept and to explore ideas. That's totally possible today, and we're not doing it enough. Actually, our chief people officer, Julia, was telling me the other day, she vibe coded an internal tool that she had at a previous job that she really wanted to have here at Open AI and she opened, I don't know, Windsurf or something, and vibe coded it. How cool is that? And if our chief people officer is doing it, we have no excuse to not be doing it more.

Lenny Rachitsky (00:55:34):
That's an awesome story. And some people may not have heard this term vibe coding. Can you describe what that means?

Kevin Weil (00:55:40):
Yeah, I think this was Andrej's term.

Lenny Rachitsky (00:55:45):
Karpathy. Yeah.

Kevin Weil (00:55:46):
Andrej Karpathy. Yeah. So you have these tools like Cursor and Windsurf and GitHub Copilot that are very good at suggesting what code you might want to write. So you can give them a prompt and they'll write code and then as you go to edit it, it's suggesting what you might want to do. And the way that everyone started using that stuff was, give it a prompt, have it do stuff, you go edit it, give it a prompt, and you're kind of really going back and forth with the model the whole time. As the models are getting better and as people are getting more used to it, you can kind of just let go of the wheel a little bit. And when the model's suggesting stuff, it's just like, tap, tap, tap, tap, tap. Keep going. Yes, yes, yes, yes, yes.

(00:56:29):
And of course the model makes mistakes or it does something that doesn't compile, but when it doesn't compile, you paste the error in and you say, go, go, go, go, go. And then you test it out and it does one thing that you don't want it to do, so you enter in an instruction and say, go, go, go, go, go, and you just let the model do its thing. And it's not that you would do that for production code that needed to be super tight today yet, but for so many things, you're trying to get to a proof of concept, you're getting to a demo and you can really take your hands off the wheel and the model will do an amazing job, and that's vibe coding.

Lenny Rachitsky (00:57:05):
That's an awesome explanation. I think the pro version of that, which is, I think, the way Andre even described it as you talk, there's a step like whisper or super whisper or something like that where you're talking to the model, not even typing.

Kevin Weil (00:57:17):
Yeah, totally.

Lenny Rachitsky (00:57:19):
Oh man. So let me just ask, I guess, when you look at product teams in the future, you talked about how you guys should be doing this more, instead of designs, having prototypes, what do you think might be the biggest changes in how product teams are structured or built? Where do you think things are going in the next few years?

Kevin Weil (00:57:36):
I think you're definitely going to live in a world where you have researchers built into every product team. And I don't even mean just at foundation model companies because I think the future... Actually, frankly one thing that I'm sort of surprised about about our industry in general is that there's not a greater use of fine-tuned models. A lot of people... These models are very good, so our API does a lot of things really well, but when you have particular use cases, you can always make the model perform better on a particular use case by fine-tuning it. It's probably just a matter of time. Folks aren't quite comfortable yet with doing that in every case. But to me, there's no question that that's the future. Models are going to be everywhere just like transistors are everywhere, AI is going to be just a part of the fabric of everything we do, but I think there are going to be a lot of fine-tuned models because why would you not want to more specifically customize a model against a particular use case?

(00:58:37):
And so I think you're going to want sort of quasi researcher machine learning engineer types as part of pretty much every team because fine-tuning a model is just going to be part of the core workflow for building most products. So that's one change that maybe you're starting to see at foundation model companies that will propagate out to more teams over time.

Lenny Rachitsky (00:58:57):
I'm curious if there's a concrete example that makes that real, and I'll share one that comes to mind as you talk, which is, when you look at Cursor and Windsurf, something I learned from those founders is that they use a Sonnet, but then they also have a bunch of custom models that help along the edges that make the specific experience that's not just generating code even better like auto-complete and looking ahead to where things are going. So is that one or any other examples of which you... What is a fine-tuned model? Do you think teams will be building with these researchers on their teams?

Kevin Weil (00:59:29):
Yeah. I mean, so when you're a model, you're basically giving the model a bunch of examples of the kinds of things you want it to be better at. So it's, "Here's a problem, here's a good answer. Here's a problem, here's a good answer," Or, "Here's a question, here's a good answer times a thousand or 10,000." And suddenly you're teaching the model to be much better than it was out of the gate at that particular thing. We use it everywhere internally. We use ensembles of models much more internally than people might think. So it's not, "I have 10 different problems. I'll just ask baseline GPT four oh about a bunch of these things." If we have 10 different problems, we might solve them using 20 different model calls, some of which are using specialized fine-tuned models, they're using models of different sizes because maybe you have different latency requirements or cost requirements for different questions.

(01:00:32):
They are probably using custom prompts for each one. Basically you want to teach the model to be really good at... You want to break the problem down into more specific tasks versus some broader set of high level tasks. And then you can use models very specifically to get very good at each individual thing. And then you have an ensemble that tackles the whole thing. I think a lot of good companies are doing that today. I still see a lot of companies giving the model single, generic, broad problems versus breaking the problem down, and I think there will be more breaking the problem down using specific models for specific things, including fine tuning.

Lenny Rachitsky (01:01:15):
And so in your case, because this is really interesting, is that you're using different levels of Chat GPT, like a 1 0 3 and stuff that's earlier because it's cheaper.

Kevin Weil (01:01:24):
There'll be parts of our internal stack. I'll give you an example. Customer support, with 400 plus million weekly active users, we get a lot of inbound tickets. I don't know how many customer support folks we have, but it's not very many, 30, 40, I'm not sure, way smaller than you would have at any comparable company, and it's because we've automated a lot of our flows. We've got most questions using our internal resources, knowledge base, guidelines for how we answer questions, what kind of personality, et cetera. You can teach the model those things and then have it do a lot of its answers automatically, or where it doesn't have the full confidence to answer a particular question, it can still suggest an answer, request a human to look at it and then that human's answer actually is its own sort of fine tuning data for the model. You're telling it the right answer in a particular case.

(01:02:29):
We're using... At various places. Some of these places, you want a little bit more reasoning, is not super latency sensitive, so you want a little more reasoning, and we'll use one of our O series models. In other places, you want a quick check on something and so you're fine to use four oh mini, which is super fast and super cheap. In general, it's like specific models for specific purposes and then you ensemble them together to solve problems. By the way, again, not unlike how we as humans solve problems, a company is arguably an ensemble of models that have all been fine tuned based on what we studied in college and what we have learned over the course of our careers. We've all been fine tuned to have different sets of skills and you group them together in different configurations and the output of the ensemble is much better than the output of any one individual.

Lenny Rachitsky (01:03:20):
Kevin, you're blowing my mind. That sounds exactly correct. And also, different people, you pay them less, they cost less to talk to, some people take a long time to answer, some people hallucinating. This is...

Kevin Weil (01:03:38):
I'm telling you. This is a mental model but really does work in thinking...

Lenny Rachitsky (01:03:41):
Oh, right. Yeah. This is great. Some people are visual, they want to dry out their thinking, some people want to talk word cell. Wow, this is a really good metaphor. So again, coming back to your advice here because I love that we circled back to it, you're finding a really good way to think about how to design great AI experiences and LMs, I guess, specifically is think about how a person would do this.

Kevin Weil (01:04:01):
Well, it's maybe not always the answer is to think about how a person would do it, but sometimes to gain intuition for how you might solve a problem, you think about what an equivalent human would do in those situations and use that to at least gain a different perspective on the problem.

Lenny Rachitsky (01:04:18):
Wow, this is great.

Kevin Weil (01:04:22):
Because some of this really is talking to a model. There's a lot of prior art because we talk to other humans all the time and encounter them in all sorts of different situations, and so there's a lot to learn from that.

Lenny Rachitsky (01:04:34):
Okay, so speaking of humans, I want to chat about the future a little bit. So you have three kids, and a community member asked me this hilarious question that I think it's something a lot of people are thinking about. So this is Patrick [inaudible 01:04:47]. I worked with him at Airbnb. He says ask what he's encouraging his kids to learn to prepare for the future. I'm worried my 6-year-old by the year 2036 will face a lot of competition trying to get into the top roofing or plumbing programs and need a backup plan.

Kevin Weil (01:05:02):
That's funny. So our kids, we have a 10 year old and eight year old twins, so they're still pretty young. It's amazing how AI native they are. It's completely normal to them that there are self-driving cars. That they can talk to AI all day long. They have full conversations with Chat GPT and Alexa and everything else. I don't know, who knows what the future holds? I think things like coding skills are going to be relevant for a long time, who knows? But I think if you teach your kids to be curious, to be independent, to be self-confident, you teach them how to think, I don't know what the future holds, but I think that those are going to be skills that are going to be important in any configuration of the future. And so it's not like we have all the answers, but that's how Elizabeth and I think about our kids.

Lenny Rachitsky (01:06:02):
And do you find that AI... There's a lot of talk about AI tutoring. Is that something you guys are doing? I know they're using Chat GPT, I love all the photos you post where they're playing with prompts and stuff, but I guess is there anything there you're experimenting with or you think is going to become really important?

Kevin Weil (01:06:16):
This is something that... It's maybe the most important thing that AI could do. Maybe that's a grand statement. There are lots of important things that AI can do, including speeding up the pace of fundamental science research and discovery, which maybe is actually the most important thing AI can do. But one of the most important things would be personalized tutoring. And it kind of blows my mind that there is still... I know there are a bunch of good products out there. Khan Academy does great things. They're a wonderful partner of ours. Vinod Khosla has a non-profit that's doing some really interesting stuff in this space and is making an impact. But I'm kind of surprised that there isn't a 2 billion kid AI personalized tutoring thing because the models are good enough to do it now, and every study out there that's ever been done seems to show that when you have... Like, education is still important, but when you combine that with personalized tutoring, you get multiple standard deviation improvements in learning speed.

(01:07:31):
And so it's uncontroversial, it's good for kids, it's free. Chat GPT is free, you don't need to pay, and the models are good enough. It still just kind of blows my mind that there isn't something amazing out there that our kids are using and your future kids are using, and people in all sorts of places around the world that aren't as lucky as our kids to be able to have this sort of built-in, solid education. Again, Chat GPT is free. People have Android devices everywhere. I really just think this could change the world and I'm surprised it doesn't exist and I want it to exist.

Lenny Rachitsky (01:08:08):
This kind of touches on something I want to spend a little time on, which is a lot of people also worry a lot about AI, where it's going, they worry about jobs it's going to take, they worry about the super intelligence squashing humanity in the future. What's your perspective on that and just the optimistic case that I think people need to hear?

Kevin Weil (01:08:27):
I mean, I'm a big technology optimist. I think if you look over the last 200 years, maybe more, technology has driven a lot of the advancements that have made us the world and the society that we are today. It drives economic advancements, it drives geopolitical advancements, quality of life, longevity advancement. I mean, technology's at the root of just about everything, so I think there are very few examples where this is anything but a great thing over the longer term. That doesn't mean that there aren't...

Kevin Weil (01:09:00):
... a great thing over the longer term. That doesn't mean that there aren't temporary dislocations or where there aren't individuals that are impacted, and that matters too. So it can't just be that the average is good. You've got to also think about how you take care of each individual person as best you can.

(01:09:18):
It is something that we think a lot about and as we work with the administration, as we work with policy, we try and help wherever we can. We do a lot with education. One of the benefits here is that ChatGPT is also perhaps the best reskilling app you could possibly want. It knows a lot of things. It can teach you a lot of things if you're interested in learning new things.

(01:09:43):
These are very real issues. I'm super optimistic about the long run, and we're going to need to do everything we can as a society to ensure that we make this transition as graceful and as well-supported as we can.

Lenny Rachitsky (01:09:59):
To give people a sense of where things might be going. That's a big question in a lot of people's minds. So someone asked this question that I love, which is, "AI is already changing, creative work in a lot of different ways, writing and design and coding, what do you think is the next big leap? What should we be thinking is the next big leap in AI-assisted creativity specifically, and then just broadly, where do you think things are going to be going in the next few years?"

Kevin Weil (01:10:23):
Yeah. This is also an area where I'm a big optimist. If you look at Sora, for example. I mean we talked about ImageGen earlier and the absolute fount of creativity that people are putting across Twitter and Instagram and other places. I am the world's worst artist like the worst. Maybe the only thing I'm worse at than art is singing. Give me a pencil and a pad of paper and I can't draw better than our eight-year-old. But give me ImageGen and I can think some creative thoughts and put something into the model and suddenly have output that I couldn't have possibly done myself. That's pretty cool.

(01:11:09):
Even you look at folks that are really talented. I was talking to a director recently about Sora, someone who's directed films that we would all know, and he was saying, for a film that he's doing, take the example of some sort of sci-fi-ish, think of Star Wars, and you've got some scene where there's a plane zooming into some Death Star-like thing. And so you've got the plane looking at the whole planet, and then you want to cut to a scene where the plane's kind of at the ground level, and all of a sudden you see the city and everything else. How are we going to manage that cut scene? And that transition?

(01:11:51):
And he was saying, "In the world of two years ago, I would have paid a 3D effects company a hundred grand and they would've taken a month, and they would've produced two versions of this cut scene for me. And I would've evaluated them. We would've chosen one, because what are you going to do? Pay another 50 grand and wait another month. And we would've just gone with it. And it would be fine. Movies are great. I love them. And there've been..."

(01:12:25):
Obviously, we can do great things with the technology that we've had, but you now look at what you can do with Sora. And his point was, "Now, I can use Sora, our video model, and I can get 50 different variations of this cut scene just me brainstorming into a prompt and the model brainstorming a little bit with me. I've got 50 different versions. And then of course, I can iterate off of those and refine them and take different ideas. And now I'm still going to go to that 3D effects studio to produce the final one, but I'm going to go having brainstormed and had a much more creative approach with an outcome that's much better. And I did that assisted by AI."

(01:13:08):
My personal view on creativity in general is that it's no one's going to... You don't type into Sora like, "Make me a great movie." It requires creativity and ingenuity, and all these things, but it can help you explore more. It can help you get to a better final result. So, again, I tend to be an optimist in most things, but actually, I think there's a very good story here.

Lenny Rachitsky (01:13:31):
I know Sam Altman, I think it was him who tweeted recently, the creative writing piece that you guys are working on where it's... He is very bad at writing creative stuff, and he shared an example where it's actually really good. I imagine that's another area of investment.

Kevin Weil (01:13:43):
Yeah, there's some exciting stuff happening internally with some new research techniques. We'll have more to say about that at some point. But yeah, Sam sometimes likes to show off some of the stuff that's coming, which is smart. By the way, it's very indicative of this iterative deployment philosophy. We don't have some breakthrough and keep it to ourselves forever, and then bestow it upon the world someday. We kind of just talk about the things we're working on and share when we can and launch early and often, and then iterate in public. I really like that philosophy.

Lenny Rachitsky (01:14:22):
I love all these hints that a few things coming. I know you can't say too much. You talked about how there might be a coding leap coming in the near future maybe by the time this comes out. Is there anything else people should be thinking about, might be coming in the near future? Any things you can tease that are interesting? Exciting?

Kevin Weil (01:14:38):
Man, this hasn't been enough for you?

Lenny Rachitsky (01:14:41):
Only everything is getting better every day.

Kevin Weil (01:14:44):
Yeah. I'm like, man, I hope we get some of this stuff out before the episode launches so-

Lenny Rachitsky (01:14:49):
This is your new timebox.

Kevin Weil (01:14:50):
... I don't piss people off. The amazing thing to me is we were talking earlier about how far models have come in just a couple of years. If you went back to GPT-3, you'd be disgusted by how bad it was, even though Lenny of two years ago was mind-blown by how good these were. And for a long time, we were iterating every six to nine months on a new GPT model. It was like GPT-3, GPT-3.5, 4, and now with this o-series of reasoning models, we're moving even faster. Every roughly three months, maybe four months, there's a new o-series model, and each of them is a step up in capability.

(01:15:41):
And so the capabilities of these models are increasing at a massive pace. They're also getting cheaper as they scale. You look at where we were even a couple of years ago. I think the original, I don't know, what was it, GPT-3.5 or something was like 100 x the cost of GPT-4o mini today in the API. A couple of years, you've gone down two orders of magnitude in cost for much more intelligence. And so I don't know where there's another series of trends like that in the world. Models are getting smarter, they're getting faster, they're getting cheaper, and they're getting safer too. They hallucinate less every iteration.

(01:16:27):
And so the Morse Law and transistors becoming ubiquitous. That was a law around doubling the number of transistors on a chip every 18 months. If you're talking about something where you're getting 10 x every year, that's a massively steeper exponential. And it tells us that the future is going to be very different than today. The thing I try and remind myself is, the AI models that you're using today is the worst AI model you will ever use for the rest of your life. And when you actually get that in your head, it's kind of wild.

Lenny Rachitsky (01:17:08):
I was going to actually say the same thing, and that's the thing that always sticks with me when I watch this thing. You're talking about Sora, and I imagine many people hearing that are like, "No, no. It's not actually ready. It's not good enough. It's not going to be as good as a movie I see in the theater." But the point is what you just made that this is the worst it's going to be. It will only get better.

Kevin Weil (01:17:25):
Yeah, model maximalism. Just keep building for the capabilities that are almost there, and the model's going to catch up and be amazing.

Lenny Rachitsky (01:17:35):
Escape to where the puck is going to be.

Kevin Weil (01:17:36):
Yeah.

Lenny Rachitsky (01:17:38):
This reminds me, I was just using... I was duplifying everything the other day and I was just like, "What is taking so long."

Kevin Weil (01:17:38):
As one does.

Lenny Rachitsky (01:17:43):
Just like cut... What was that?

Kevin Weil (01:17:45):
I said, as one does.

Lenny Rachitsky (01:17:46):
As one does these days. I was just like, "It's taking a minute to generate this image of my family in this amazing way." Come on, what's taking so long. You just get so used to magic happening in front of you.

Kevin Weil (01:17:57):
Yeah, totally.

Lenny Rachitsky (01:17:59):
Okay, final question. This is going to go in a completely different direction. A lot of people asked about this. So famously, you led this project at Facebook called Libra, which is now called Novi. A lot of people always wondered, "What happened there? That was a really cool idea." I know some people have a sense there's regulation challenges, things like that. I don't know if you've talked about this much. So I guess, could you just give people a brief summary of just what is Libra? This project you working on, and just what happened, and how you feel about it?

Kevin Weil (01:18:26):
Yeah. I mean, David Marcus led it, and I happily work for him and with him. I think he's a visionary and also a mentor and a friend. Honestly, Libra is probably the biggest disappointment of my career. When I think about the problems we were solving, which are very real problems. If you look at, for example, the remittance space, people sending money to family members in other countries, it is maybe... I mean it's incredibly regressive, right? People that don't have the money to spend are having to pay 20% to send money home to their family. So outrageous fees, it takes multiple days, you have to go then pick up cash from... It's all bad.

(01:19:11):
And here we are with 3 billion people using WhatsApp all over the world, talking to each other every day, especially friends and family, and exactly the kind of people who'd send money to each other. Why can't you send money as immediately, as cheaply, as simply as you send a text message? It is one of those things when you sit back and think about it, that should just exist. And that was what we set out to try and do.

(01:19:41):
Now, I don't think we played all of our cards perfectly. If I could go back and do things, there are a bunch of things I would do differently.

(01:19:50):
We tried to get it all at once. We tried to launch a new blockchain. It was a basket of currencies originally. It was integration into WhatsApp and Messenger, and I think the whole world kind of went like, "Oh my God, that's a lot of change at once." And it happened also to be at the time that Facebook was at the absolute nadir of its reputation. And so that didn't help. It was also not the Messenger that people wanted for this kind of change. We knew all that going in, but we went for it.

(01:20:21):
I think there are a bunch of ways that we could do that that would've introduced the change a little bit more gently, maybe still gotten to that same outcome, but fewer new things at once and introduced the new things one at a time. Who knows? Those were decisions we made together. So we all own them. Certainly, I own them. But it fundamentally disappoints me that this doesn't exist in the world today because the world would be a better place if we'd been able to ship that product. I would be able to send you 50 cents in WhatsApp for free. It would settle instantly. Everybody would have a balance in their WhatsApp account. We'd be transact... I mean, it should exist.

(01:21:03):
I don't know. To be honest, the current administration is super friendly to crypto. Facebook's reputation, Meta's reputation is in a very different place. Maybe they should go build it now.

Lenny Rachitsky (01:21:13):
I was looking at the history of it, and apparently, they sold the tech to some private equity company for 200 million bucks.

Kevin Weil (01:21:19):
Yeah, yeah, and-

Lenny Rachitsky (01:21:21):
They had to buy it back.

Kevin Weil (01:21:23):
There are a couple of current blockchains that are built on the tech because the tech was open-sourced from the beginning. Aptos and Mistin are two companies that are built off of this tech. So at least all of the work that we did, did not die and lives on in these two companies, and they're both doing really well. But still, we should be able to send each other money in WhatsApp, and we can't today.

Lenny Rachitsky (01:21:49):
Hear, hear. Well, thanks for sharing that story, Kevin. Is there anything else you want to share or maybe a last negative advice or insight before we get to our very exciting lightning round?

Kevin Weil (01:21:58):
Ooh, the lightning round. Let's just go do that.

Lenny Rachitsky (01:22:01):
Let's do it. With that, Kevin, we reached our very exciting lightning round. Are you ready?

Kevin Weil (01:22:05):
Yeah.

Lenny Rachitsky (01:22:06):
Let's do it. Okay. What are two or three books that you find yourself recommending most to other people?

Kevin Weil (01:22:12):
Co-Intelligence by Ethan Mollick, a really good book about AI and how to use it in your daily life as a student, as a teacher. He's super thoughtful. Also, by the way, a very good follow on Twitter. The Accidental Superpower by Peter Zion. Very good if you're interested in geopolitics and the forces that sort of shape the dynamics happening. And then I really enjoyed Cable Cowboy, I don't know who the author is, but the biography of John Malone. Just fascinating. If you like business, especially if you want to get into... I mean the man was an incredible dealmaker and shaped a lot of the modern cable industry. So that was a good biography.

Lenny Rachitsky (01:22:53):
These are all first-time mentions, which is always a great,

Kevin Weil (01:22:56):
Oh, good.

Lenny Rachitsky (01:22:56):
Next question. Do you have a favorite recent movie or TV show that you really enjoyed?

Kevin Weil (01:23:02):
I wish I had time to watch a TV show, so I'm-

Lenny Rachitsky (01:23:06):
Just Sora videos.

Kevin Weil (01:23:07):
Yeah, right. I don't know. When I was a kid, I read the Wheel of Time series and now Amazon has it as they're in the third season of it, so I want to watch that. I haven't yet. Top Gun 2 was an awesome movie. I think that's no longer new.

Lenny Rachitsky (01:23:28):
That shows when the last time you watched a movie was.

Kevin Weil (01:23:31):
But I like the idea. I want more Americana. I want more being proud of being strong. And I thought Top Gun 2 did a really good job of that. Pride and patriotism, I think the US could use more of that.

Lenny Rachitsky (01:23:48):
Is there a favorite product that you've recently discovered that you really love, other than your super intelligence internal tool that you all have access to? I'm just joking.

Kevin Weil (01:23:56):
That's right. Internal AGR.

Lenny Rachitsky (01:23:57):
Yeah, that's right.

Kevin Weil (01:24:01):
Well, I think vibe coding with products like Windsurf is just super fun. I'm having a great time doing that. I still just love that our chief people officer vibe coded some tools. Maybe the other one is Waymo. Every chance I get, I'll take a Waymo. It's just a better way of riding, and it still feels like the future. So they've done an amazing job.

Lenny Rachitsky (01:24:24):
That's awesome. By the way, I had the founder of Windsurf on the podcast. It might come out before this or after this. And also Cursor's CEO is coming on the podcast either before or after this.

Kevin Weil (01:24:32):
Oh, cool. I have a ton of respect for what those guys are doing. Those are awesome products.

Lenny Rachitsky (01:24:36):
Just changing the way everyone builds product. No big deal.

Kevin Weil (01:24:38):
Yeah.

Lenny Rachitsky (01:24:40):
A couple more questions. Do you have a favorite life motto that you often repeat yourself, find really useful in work or in life?

Kevin Weil (01:24:47):
Yeah. So actually, this is interestingly enough, it is more of a philosophy, but then I thought Zuck encapsulated it one time on a Facebook earnings call. So I actually had this made into a poster. It sits in my room. But somebody was asking Mark. This is literally on an earnings call, so it's like an analyst on an earnings call asking him. It was some quarter when Facebook had grown a lot. This was back in the 20 teens sometime, I think. But he's like, "So what did you do? What was it that you launched? What was the one thing that drove all this growth for you?" And he said something to the effect of, "Sometimes it's not any one thing, it's just good work consistently over a long period of time." And that's always stuck with me.

(01:25:33):
And I think it is. I mean I run ultra marathons. It's like it's just about grinding. I think people too often look for the silver bullet when a lot of life and a lot of excellence is actually showing up day in and day out, doing good work, getting a little bit better every single day, and you may not notice it over a week or even a month. And a lot of people then kind of get dismayed and stop. But actually, you keep doing it. The gains keep compounding. And over the course of a year, two years, five years, it adds up like crazy. So good work consistently over a long period of time.

Lenny Rachitsky (01:26:13):
I love that. I got to make a poster of this now. That is-

Kevin Weil (01:26:15):
We'll get you one.

Lenny Rachitsky (01:26:15):
I so resonate with that. Okay, I'll take it. That is so good. Okay, final question. I'm going to ask if you have any prompting tricks, and I'm going to set it up first. But think about if you have a trick that you could recommend to people for prompting LLMs better. I had a guest, Alex Komorowski, come on the podcast. He's from Stripe and writes his weekly reflections on what's happening in the world. A lot of them are AI-related.

(01:26:36):
And he once described an LLM as a zip file of all human knowledge. All the answers are in there, and you just need to figure out the right question to ask to get the answer to every problem basically. And so it just reminded me how important prompt engineering is and knowing how to prompt well. You're constantly prompting ChatGPT. What's one tip, one trick that you found to be helpful in helping you get what you want?

Kevin Weil (01:27:00):
Well, I'll say, first of all, I want to kill the idea that you have to be a good prompt engineer. I think if we do our jobs, that stops being true. It's just one of those sharp edges of models that experts can learn. But then, just over time, you shouldn't need to know all that. The same way you used to have to get deep into, "What's your storage engine in MySQL? Are you using InnoDB 4.1?" There's still use cases for that if you're at the deep edge of MySQL performance. But most people don't need to care. And you shouldn't need to care about minute details of prompting if AI is really going to become broadly adopted.

(01:27:39):
But today, we're not totally there. I think by the way, we are making progress there. I think there is less prompt engineering than there had to be before. But in line with some of the fine-tuning stuff I was talking about and the importance of giving examples, you can do effectively poor man's fine-tuning by including examples in your prompt of the kinds of things that you might want and a good answer. So like, "Here's an example and here's a good answer. Here's an example, and here's a good answer. Now, go solve this problem for me." And the model really will listen and learn from that.

(01:28:15):
Not as well as if you do a full fine-tune, but much more than if you don't provide any examples. And I think people don't do that often enough.

Lenny Rachitsky (01:28:24):
That's awesome. One tip that I heard, I'm curious if this works is you tell it, "This is very, very important to my career." Make it really understand like, "Someone will die if you don't answer me correctly." Does that work?

Kevin Weil (01:28:36):
It's really weird. There's probably a good explanation for this. But you can also say things. So, yes, I think there is some validity to that. You can also say things like, "I want you to be Einstein. Now, answer this physics problem for me," or, "You are the world's greatest marketer, the world's greatest brand marketer. Now here's a naming question." And there is something where it sort of shifts the model into a certain mindset that can actually be really positive.

Lenny Rachitsky (01:29:10):
I use that tip all the time actually. I always... When I'm coming up with questions for interviews and I use it occasionally to come up with things I haven't thought of, I actually type, "You're the world's best podcast interviewer."

Kevin Weil (01:29:21):
Right.

Lenny Rachitsky (01:29:21):
I have Kevin Weil coming on the pod... Yeah, it actually works.

Kevin Weil (01:29:25):
By the way, back to our other point that we made a few times. You do do that sometimes with people. You sort of put them... You frame things, you get them into a certain mindset, and the answer is completely different. So I think there are human analogs of this one more time.

Lenny Rachitsky (01:29:42):
Kevin, this was incredible. I was just thinking about a way to end this. The way I feel like... I feel like not only are you at the cutting edge of the future. You and the team are kind of actually the edge that is creating the future. And so it's a real honor to have you on here and to talk to you and to hear where you think things are going and what we need to be thinking about, so thank you for being here, Kevin.

Kevin Weil (01:30:07):
Oh, thank you so much for having me. I get to work with the world's best team, and all credit to them, but really appreciate you having me on. It's been super fun.

Lenny Rachitsky (01:30:17):
I forgot to ask you the two final questions. Where can folks find you if they want to reach out, and how can listeners be useful to you?

Kevin Weil (01:30:24):
I am @kevinweil, K-E-V-I-N-W-E-I-L on pretty much every platform. I'm still a Twitter DAU after all these years. I guess an X DAU, LinkedIn, wherever. And I think the thing I would love from people, give me feedback. People are using ChatGPT. Tell me where it's working really well for you and where you want us to double down. Tell me where it's failing. I'm very active and engaged on Twitter. I love hearing from people, what's working and what's not, so don't be shy.

Lenny Rachitsky (01:30:56):
And I learned following you helps you figure out all the stuff that you're launching. You share all the things that are going out every day, or week, month, so that's also a benefit. And by the way, 400 million weekly active users all emailing you feedback. Here we go.

Kevin Weil (01:31:08):
Yes, let's do it.

Lenny Rachitsky (01:31:09):
It's going to work out great. Okay. Well, thank you, Kevin. Thanks for being here.

Kevin Weil (01:31:12):
All right, man, thanks so much. See you soon.

Lenny Rachitsky (01:31:13):
Bye, everyone. Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Unorthodox PM tips: Automating user insights, unselling candidates, decision logs, more | Kevin Yien
**Guest:** Kevin Yien  
**Published:** 2024-08-18  
**YouTube:** https://www.youtube.com/watch?v=xOTO98MXG9o  
**Tags:** product-market fit, growth, retention, roadmap, prioritization, user research, iteration, a/b testing, experimentation, analytics  

# Unorthodox PM tips: Automating user insights, unselling candidates, decision logs, more | Kevin Yien

## Transcript

Kevin Yien (00:00:00):
The PM job can become a little too internal, influencing my stakeholders and getting alignment and all these things. But if you can't sell or support your own product, I don't trust you to build the product.

Lenny Rachitsky (00:00:10):
You think every PM should keep a decision log?

Kevin Yien (00:00:13):
We all talk about product sense. To me, it's just a fancy way of saying you can make good decisions with insufficient data. PMs need as many reps as possible in making decisions, documenting the rationale behind those decisions, and then crucially seeing the outcome of them.

Lenny Rachitsky (00:00:28):
We have a lot of interesting approaches to hiring, including this idea of a unsell email.

Kevin Yien (00:00:31):
When you get to offer stage, I send an email and I say all the terrible things that are probably going to reinforce their fears. If you can tell them that upfront and they can read that whole email and still be equally excited to join you, find yourself a A+ hire.

Lenny Rachitsky (00:00:45):
I'm curious if you found any interesting uses of AI in your work.

Kevin Yien (00:00:49):
We are not even beneath the dust on the surface when it comes to what's going to change.

Lenny Rachitsky (00:01:00):
Today, my guest is Kevin Yien. Kevin leads product for merchant experiences at Stripe. Before that, he built the restaurant business and the ecosystem teams at Square, and most recently was head of product and design at Mutiny. He also makes ice cream and, as you'll hear in there conversation, was a pretty competitive eater for some part of his life.

(00:01:17):
In our conversation, Kevin shares a ton of unique and insightful perspectives on how to be a successful product manager, including how to get into product management, how to improve your relationship with your engineers and designers, bunch of advice on hiring, why you should keep a decision log, how to automate your customer research, plus a ton of really powerful stories around failure and AI and career.

(00:01:40):
This episode is for anyone looking to become a better leader, thinker, and builder of products. If you enjoy this podcast, don't forget to subscribe and follow in your favorite podcasting app or YouTube. It's the best way to avoid missing feature episodes, and it helps the podcast tremendously. With that, I bring you Kevin Yien.

(00:02:00):
Kevin, thank you so much for being here and welcome to the podcast.

Kevin Yien (00:02:04):
Thanks, Lenny. I am humbled to be here.

Lenny Rachitsky (00:02:05):
I've been a big fan of yours from afar. I've been following you on Twitter for a long time. You have a very distinct profile photo that I feel like you maybe haven't changed for a long time. How long have you had this profile?

Kevin Yien (00:02:16):
Oh gosh, probably 2011 or 2012. The story behind that is I was inspired actually by Chris Dixon's avatar at the time and I wanted something really similar to it, but I couldn't figure out how to. Luckily, I was dating a designer at the time, and so she made me that sort of custom pick that has been my profile since then, and she's now my wife.

Lenny Rachitsky (00:02:40):
Oh my god. Funny enough, I had a startup idea once where it's like a profile picture as a service business where there's these three tiers where it's like one has automated, one has someone illustrates, and one is a professional photo. It feels like everyone profile photos are so important.

Kevin Yien (00:02:54):
True.

Lenny Rachitsky (00:02:55):
But I never follow through. Probably not a good business anyway.

Kevin Yien (00:02:59):
Yeah, but a good idea, a good tool.

Lenny Rachitsky (00:03:00):
Good idea. Thank you. Thank you for making me feel better.

(00:03:03):
I've been looking forward to this conversation for a long time. As I said, I've been a big fan of yours for a long time. Something that I've noticed about you is you have a lot of really unique perspectives on a lot of different things, and in particular, product management, how to be successful as a PM, how to get into product management, things like that. So I thought it'd be fun to start there talking through some of these things that I've heard you talk about and then get into some very tactical stuff that you found to be useful in your product management career.

(00:03:29):
The first thing that I've heard you talk about is that you discourage people from going straight into product management. If they want to become product managers, you encourage them to start somewhere else first. Why is that? Where do you think people should start? Talk about this insight that you've had.

Kevin Yien (00:03:45):
Yeah, so follow me on the detour to science world temporarily. If we all remember high school science classes, there was this concept of potential and kinetic energy. There's so many different definitions for product management, but the one that I have come to myself that I really like is, when you are building a product, you have this team, engineers, designers, so much potential. The purpose of product management, not the person, but the practice, is to convert that potential into as much realized value for someone as possible, right? Minimum loss. When you're just getting started with a new product, the people that should be doing that are the people who are building it. That's an engineer, that's a designer, that's a sales person or a support person. They're the front line of the smallest loop possible to get something going, and it's through those practices that I think you're able to get the most exposure to what it takes to build a good product.

(00:04:50):
And then from there, that's your foundation. That's the unique perspective that you bring and allows you then to actually take on a "role" of product manager in a good, unique, insightful way. That's sort of like the foundation. There's a lot more to unpack behind that comparison, but that's where it comes from.

Lenny Rachitsky (00:05:06):
I love that. I'd love to unpack it further.

(00:05:10):
This episode is brought to you by BuildBetter.AI. Back in 2020 when AI was just a toy, BuildBetter bet that it could cut down on a product teams' operational BS. Fast-forward to today, 23,000 product teams use purpose-built AI in BuildBetter every day.

(00:05:28):
First, BuildBetter uses custom models to turn unstructured data like product and sales calls, support tickets, internal communications, and surveys into structured insights. It's like having a dedicated data science team. Second, BuildBetter runs those structured insights into workflows, like weekly reports about customer issues, context-aware PRDs, and user research document with citations. It even turns standups into action items that automatically get assigned and shared into your tools. Plus, with unlimited seat pricing on all plans, BuildBetter ensures everyone at your company has access to this knowledge. Truly, no data silos.

(00:06:05):
In a world of AI demos over promising and under delivering, see why BuildBetter has a 93% subscription retention. Get a personalized demo and use code LENNY for $100 credit if you sign up now at buildbetter.ai/lenny.

(00:06:22):
I'm excited to chat with Christina Gilbert, the founder of OneSchema, one of our longtime podcast sponsors. Hi, Christina.

Christina (00:06:30):
Yes, thank you for having me on, Lenny.

Lenny Rachitsky (00:06:32):
What is the latest with OneSchema? I know you now work with some of my favorite companies like Ramp, Vanta, Scale, and Watershed. I heard that you just launched a new product to help product teams import CSVs from especially tricky systems like ERPs.

Christina (00:06:47):
Yes, so we just launched OneSchema FileFeeds, which allows you to build an integration with any system in 15 minutes as long as you can export a CSV to an SFTP folder. We see our customers all the time getting stuck with hacks and workarounds. And the product teams that we work with don't have to turn down prospects because their systems are too hard to integrate with. We allow our customers to offer thousands of integrations without involving their engineering team at all.

Lenny Rachitsky (00:07:09):
I can tell you that if my team had to build integrations like this, how nice would it be to be able to take this off my roadmap and instead use something like OneSchema and not just to build it but also to maintain it forever.

Christina (00:07:21):
Absolutely, Lenny. We've heard so many four stories of multi-day outages from even just a handful of bad records. We have laser-focused on integration reliability to help teams end all of those distractions that come up with integrations. We have a built-in validation layer that stops any bad data from entering your system, and OneSchema will notify your team immediately of any data that looks incorrect.

Lenny Rachitsky (00:07:40):
I know that importing incorrect data can cause all kinds of pain for your customers and quickly lose their trust. Christina, thank you for joining us. If you want to learn more, head on over to oneschema.co. That's oneschema.co.

(00:07:54):
Every PM has their definition of what is product management, and I have one that I'm trying to find exactly what I wrote, but essentially, it's to marshal the resources of your team to solve customer problems and drive business impact most efficiently, something like that. And I feel like it's very aligned with your perspective, but I really love this view of it's unlocking the potential energy of the team. Not just marshaling the resources of a team, but it's there, and your job is to maximize their effort. And this is why when people say, "I hate product managers. I don't want any product managers at my team. We don't need product managers here," I feel like that's often because you've had a bad PM. Good PMs make you better and make your life better, allow you to do the work you want to do and they take all the stuff you don't want to do, make sure the stuff you're doing is worthwhile.

(00:08:38):
Is there anything more you want to add along those lines?

Kevin Yien (00:08:41):
To elaborate on that, I think the broader point is that truly not every team needs a product manager, but the activities, the outcome that one would drive needs to get done no matter what. And in some cases, this is why the prototypical companies that everyone references when they say, "They never had product managers, look at how successful they are," they're all building for themselves. Stripe, Twilio, Figma, designers for designers, engineers for engineers. When you are the customer, why the heck do you need someone else to help do the things that let you make decisions on what to build? But if you are not the customer, if you're working in a particularly complex space, if there's something that you, as the person that could build the product, feel you don't have, that's when you can essentially delegate that responsibility to someone else to say, "Hey, let me do the things I'm really good at and you do something that I need to get my job done."

(00:09:39):
So it's that sort of relationship that I think is often missing in the discourse. I think it would alleviate a lot of the, "We don't want PMs. PM is useless" or, "PM's one of the best thing since [inaudible 00:09:52]," which they're not. It's just a manifestation of that problem.

Lenny Rachitsky (00:09:55):
Yeah. Just to build on that, we're going on a tangent, but I think that's really interesting. I think there's another element of that, SNAP actually is another example where they waited, I think, until they had 200 people before they hired their first PM. To me, that's an example of other people were doing the PM job. As you said, there's PM activity, someone's doing them, lining people, prioritizing, making sure things are clear, making sure people aren't surprised, all these things PMs do. Someone's doing that, and my feeling is like, "Okay, your designers may love doing that, great. Let them do it." If your engineers that have a lot of product sense may want to do that, great.

(00:10:28):
But there's some point they either is like, "Forget it. I just want to code. I want to build that. I want to be sitting around in meetings all day," or they just aren't as good as things are scaling. And so it's kind of like, if your engineers, designers want to do it and are good at it, great. You don't need PMs for a long time. Oftentimes they're not good at it or they don't want to be sitting in doing all these PM things.

Kevin Yien (00:10:46):
Yep, precisely.

Lenny Rachitsky (00:10:48):
Okay, so going back to the question of... So your advice is don't go straight into product management if you want to become a great PM. Where do you think people should start if they can? What are some options you recommend?

Kevin Yien (00:10:58):
The best way to think about this, in my opinion, is who were the people that you would be taking the PM responsibilities from and then do those jobs? And so for me, the sort of foundational three are going to be engineer, designer or salesperson. I think sales also gets not a bad rep, but a misrepresented reputation in tech where all they care about is quota, it's just about numbers, et cetera. In reality, the best salespeople are the best listeners, the best people at understanding the problem that the customer is having and then translating that into what you can do for them. And so if you get really good at having those calls, getting told no a lot, and being able to translate that, I mean, why would you not want to start there and then eventually move into something like product? So that's the foundational three for me.

Lenny Rachitsky (00:11:56):
So your advice is essentially if you want to be a PM, start as a designer or an engineer or a salesperson. I was an engineer, so this is exactly the path I went on. And I think there's an element of you start there and then you realize you're never going to be as amazing as the other people at that role and you're like, "Okay, maybe I should explore this other thing," because I was like, "I'm never going to be an amazing engineer. I'm good enough."

Kevin Yien (00:12:18):
Totally.

Lenny Rachitsky (00:12:18):
I'm like, "I'm pretty good at this other stuff. Let's explore that."

Kevin Yien (00:12:21):
The one thing that I might tack on there, because this could lead to a negative perception, is, "Well, I'm never going to be a world-class engineer, world-class designer or et cetera, and so let me settle for being a PM." That could be the conclusion you arrive at, but I think a better way of framing it is, "I'm okay at those things. I'm potentially world-class at this other thing. Let me see what it feels like to double down on this area."

Lenny Rachitsky (00:12:44):
Absolutely.

Kevin Yien (00:12:45):
And I think that's just a good framing.

Lenny Rachitsky (00:12:47):
Okay, so let's talk about another insight and piece of advice that you have, is that you think that great PMs need to be great writers. I think a lot of people don't necessarily think this. I think people may probably think, "If I'm an okay writer, I can probably be really successful PM." Talk about why you think it's so important to be a really great writer to be a really great PM.

Kevin Yien (00:13:07):
It's actually shocking for me to hear that this isn't commonplace sort of acceptance, but the place that this comes from for me is, writing is clarity at scale, and a key component to a PM's job is creating clarity both internally and externally, but it is both sides of that that I think often get lost. A lot of times the PM job can become a little too internal, and it's about influencing my stakeholders and getting alignment and all these things. Don't get me wrong, all that's very important. You should write your PRDs, they should be super crisp, they should articulate things really well, but I'm not saying that every PM needs to be a marketer or a world-class copywriter, but you should be able to write really compelling messaging in the voice of the person that you're trying to serve. And I'm working backwards from the beliefs that, if you can't sell or support your own product, I don't trust you to build the product. And so that's where I think writing is the foundational component there.

Lenny Rachitsky (00:14:11):
There's a few quotes I say often on this podcast just because they always come to mind. One is by Joan Didion who said that, "I don't know what I think until I've written it down." And that's what I find with writing where I need to actually write it down for me to really understand what the heck I'm thinking to really crystallize it.

Kevin Yien (00:14:26):
Yeah, and I think writing is, it's both a mechanism for translating what you're trying to think into that thought into what you're actually trying to do, but then it needs additional revs to be properly consumed by everyone else. And that's I think the really hard part that a lot of folks don't do the extra mile effort to take on.

Lenny Rachitsky (00:14:50):
And this to your earlier point of a job of PM is to unlock this potential energy of your team, of the various resources you have and obviously having everyone aligned behind a very, like, "This is what we are doing and everyone understanding it" and it being very clear is really powerful there.

(00:15:06):
Okay. So this begs the question, how does one become a great writer? What helped you become a better writer? How do you feel about your ability to write at this point?

Kevin Yien (00:15:13):
Oh man.

Lenny Rachitsky (00:15:14):
Any advise on becoming better?

Kevin Yien (00:15:16):
I'll start with a slightly cheeky comment, which is, I think some of this is changing with the advent of large language models and the ability to actually just mimic someone else's tone. But I take inspiration from the camp of Anthony Bourdain, and he has, I'm going to butcher the exact quote but it's something like, "If you want to know how to make good food, you have to eat a lot of food, and you have to be willing to have a bad meal every now and again." And so for me, good writing comes from consuming as much good writing as possible. Sometimes you'll read something and say, "That was actually absolute fresh." But that's okay, you have to be willing to take on some of that stuff. But the more you index towards developing your own taste for what you think is good by consuming others, then you can shift into producing your own and then comparing them and riffing it off other people. So I think that's sort of the cycle that I've gone through.

Lenny Rachitsky (00:16:13):
I have a friend who's a very good writer and a poet and helped me develop my writing early on, Vanessa, and she said exactly the same thing. Just to become a better writer, read beautiful writing, and it just kind of infuses you or your brain. In your experience, is there anything you read, anything you found really effective? Anything that you think influenced the way you write or think that people can check out?

Kevin Yien (00:16:36):
I explicitly do not mean read a bunch of other PM artifacts. You're not going to become a better writer by reading PRDs or whatever it is or support articles. It needs to be writing that compels. That's the theme I would go back to because that's what you're trying to do at the end of the day.

(00:16:56):
And when I say compels, I mean it pushes you to action. Because if you read something and you're like, "Oh, that's interesting," that's not enough. You need to be able to give someone something that then allows them to do something differently. And so the things for me that have been best... Obviously there's all the Paul Graham essays, I think his writing is very succinct, very clear, that's not novel. I learned a lot by finding specific voices back in the day on Twitter, and it wasn't always what they were posting on Twitter, but if they wrote an essay or a post, that would be their crispus thinking. And so you can use these broadcast channels to find where their golden nuggets are, but then spend time with those instead and don't worry about all the additional noise that comes with it.

Lenny Rachitsky (00:17:46):
Paul Graham actually, you mentioned him, he has a great piece on how to become a good, that we'll link to, where basically his advice is, write the way you talk. Just keep it really simple and really regular. And so we'll link to that. Is there anything else along these lines of writing that you'd recommend for folks that are like, "Okay, I need to become a great writer. How do I do this?"?

Kevin Yien (00:18:02):
Actually along the lines of write how you talk, there's this concept of cadence that I think is really important when it comes to internal writing. There's probably some very good article about this, but it's the idea that if you only write in a monotonous cadence, either all really short sentences or all really long sentences, then your brain just tunes out eventually. And so you have to interrupt the pattern intentionally, and so you go short-long, long-short, whatever it is, but there's a few various specific things that you can do that allow someone to just roll through a post or something when you write that way.

Lenny Rachitsky (00:18:43):
Along those lines, there's a book that I just found to make sure I had the right title called Several Short Sentences About Writing that is really helpful along these lines. And the whole book is very short sentences and it teaches you to write very short sentences because once you're good at that, you can get better writing longer sentences. And so we'll link to that too. It's like a really good book that I have two copies around my house that I kind of poke at sometimes.

Kevin Yien (00:19:08):
Nice. I'll have [inaudible 00:19:09] too.

Lenny Rachitsky (00:19:10):
Okay. Another area that you have a really clever insight into is how the PM role fits with engineering design. We've talked about this a little bit, but you have a really clever way of just thinking about how these roles interact and who's responsible for what. Talk about that.

Kevin Yien (00:19:24):
So this description came from writing PRDs at Square. I think there was a lot of confusion from my team specifically when I joined them. For what it's worth, it was new product line, three engineers, three designers, there was nothing but a slide deck.

Lenny Rachitsky (00:19:41):
Three engineers and three designers?

Kevin Yien (00:19:43):
The best ratio ever. This is a whole other thing. Most people, I would say, under invest in design, point-blank. When you get to a certain scale, maybe things change, but truly I don't think most teams have experienced what it feels like to have a really high design ratio and what that actually does to the quality of the work and the quality of the thinking. So shout out to designers. We need more, is the short version. And I would rather hire an incremental designer than PM almost any day of the week.

Lenny Rachitsky (00:20:18):
Wow. I've never experienced this ratio. Incredible.

Kevin Yien (00:20:21):
Yes, I was very lucky. Shout out to Bruce Bell, who was my manager at the time, who was an ex designer, at the time, GM, and declared that starting ratio.

(00:20:31):
So anyways, with that setup, they all had sort of an opinion. They had seen PRDs in the past, they weren't quite sure what the purpose of it actually was because they had designs already. They had something to start from. And when I came in and talked to everyone and figured out where we needed to be in a year's time, I was like, "Okay, here's how I think it. Let me know if you agree." And this is a whole other concept, which is, the best way to get feedback from people is not by asking what they think, but to put something concrete in front of them and then have them react to it, right? So chewing fork.

(00:21:03):
And so my description is, PM should be doing everything in their power to draw the perimeter of the space, of the problem space. And it's within that, eng, design, everyone else that you're working with, they can go as crazy as they want, push up against the bounds and it's fill the box to its maximum capacity, but you've now applied the constraints that allow you to actually have productive conversations.

(00:21:26):
On the other end of the spectrum though, I think there's a lot of folks who think, "Oh, PMs are just strategy high in the clouds. All they do is kick things off." You need to be obsessed about the final deliverable and whether or not value is actually getting to the customer. I have a really trite example of this if you want to go down it.

Lenny Rachitsky (00:21:46):
Please.

Kevin Yien (00:21:46):
But the key point I want to make is, I think it is tempting when we think about engineering product and design to draw these really clear swim lanes and say, "You do X. I do Y. Don't tread on my area." But you need these murky overlaps in order to build something really good.

(00:22:07):
And so even if the engineers are going to build a better product than you and the designers are going to design something better than you, you need to come with a strong opinion and you need to do the legwork to get their trust so they actually care about your opinion in the first place.

(00:22:21):
So time for a mini story. So Square, we're building a point of sale for restaurants. If you've ever seen one of these in a restaurant, there's this sort of grid of tiles that they tap to enter your order when you're sitting down for dinner. We were developing one, and there's this concept of a menu group. So it's a little box, you tap on it and then it pops the screen in so you go to the next level of the hierarchy. So example would be you have a wine button, you tap it, and you see your reds, whites, et cetera.

(00:22:53):
If you think about the people that we were trying to serve, there's the restaurants that were coming from a really old legacy system. And if you've seen a bartender tap on one of these, I mean it is muscle memory to the max. They're not even looking at the thing and just punching in the order blindfolded, and it's rapid fast.

(00:23:12):
On the other hand, you have people who are entering the workforce the first time, they've never used a point of sale. And so we have to serve both of these equally. Well, how do you deal with that level of speed but also the ease of use that anyone can learn it for the first time? And so there was this interaction that we really cared about, which was, when you tap on a menu group, what's the animation to pop you into that next level? This seems like such a small thing, but it made the difference in how easy it was to adopt for a lot of the restaurants.

(00:23:41):
And so a designer and myself spent literally an entire week just fine-tuning how many milliseconds it would take to pop in and out so that it felt right. And we actually brought in servers and bartenders to play with the prototypes we had on iPads and be like, "Here's an order. Pop it in." And we would see where they would sort of flinch or hesitate because the animation was too slow and they thought, "I can't tap it yet," or something related to that.

(00:24:07):
And so it's easy, I think, for a PM to say, "That's not my responsibility. I define the requirements. Have a menu group that goes to the next level, design or engineer, figure it out." No way. That's fully on you, and you better be involved in those details.

Lenny Rachitsky (00:24:24):
I love this. There's two directions I want to go. So there's the drawing the perimeter, and then there's this paying attention to the final deliverable and keeping the borrow really high, which I love and I totally agree with both.

(00:24:34):
In terms of this animation, people hearing this, that our PMs are going to be like, "How do you have time to spend a week on animation for one little product? I have so much to do. I get to hit some goals, drive some numbers. I have people waiting for me." Maybe because Square is like this, once you deploy, it's harder to change and it's like a big deal to ship. But I'm curious if you have any advice or things you've learned about how to create space for that sort of thing to create time to spend a week on this animation? Or was it just obvious to everyone, "We need to spend as much time as we can"? Top down, everyone knew.

Kevin Yien (00:25:07):
I definitely don't think it was obvious to everyone, and I can definitely say that because we were given a pretty strict deadline that we needed to launch by and I pushed it out three times. That's not because of this one animation, but it's because of a series of decisions where we said, "This is what we believe we need to ship, and this matters much more than hitting some artificial external GA date."

(00:25:35):
There's this other aspect that I think PMs like to feel good about how busy they are and they're like, "I'm involved in so many processes and I have to talk to this person and talk to that person." All that might be true, but I think there needs to be a calibration or at least a spring-cleaning of, "What's everything I'm doing?" and how much do these things actually matter to getting value to a customer. Because as a company gets bigger, as teams get more complex, it's very easy and natural to spend more time on things that are internally-focused and not externally-focused. I think we just all have to have sensitive antenna to that so that we don't fall prey to, "Well, the way that my job is described is to do these things," but really it's the outcome again of put something in a customer's hands that's also a problem, and it's amazing.

Lenny Rachitsky (00:26:29):
Reminds me of your now colleague Jeff Weinstein's advice he got from one of the Coulsons where they came to him and they're like, "You're world-class at doing the second and third most important things and you're not focusing on the most important thing because it's so hard, and that's something you need to work on."

Kevin Yien (00:26:47):
Totally. I will say so one on that, the CEO at Mutiny, Charlie, she always repeated to me nonstop, "Keep the main thing the main thing" and would just say it ad nauseum, and I'm really glad that she did. The one excuse I don't want to give folks is, as you progress in your career, you have to walk and chew gum at the same time. You can't say, "Oh, I'm only focused on this thing over here, so other folks handle that." You do have to figure out how to do a little bit more at the same time, but prioritization does play a factor.

Lenny Rachitsky (00:27:25):
There's a framework [inaudible 00:27:27] suggested that I really like, the LNO framework. I forget exactly what the LNO stands for, but leverage something something. And we'll link to it in the show notes that gives you some advice on how to prioritize your time based on the stuff.

Kevin Yien (00:27:38):
Totally.

Lenny Rachitsky (00:27:38):
Okay. So I guess in the case of pushing back to create space, this was just you as a product leader recognizing, "This is really important to get right. I will convince people we need to make more time for that."

Kevin Yien (00:27:50):
I don't want to make it seem like it was me against everyone because that was definitely not the case. I think the starting engineers and designers on that team really cared about the quality of what they built too. That's a pretty structural DNA for a team as well. If you don't start with that, and as a comparison, you have a team that really prides themselves on shipping fast and meeting deadlines really prescriptively, you might end up in a different world or your role as a PM might be a little bit more challenging if you want to push on this stuff. So I do think you have to take into account what is the DNA of the team. And then can you exploit that? Which I was able to do. Or do you actually have some change management to put into effect if you believe that it's worthwhile?

Lenny Rachitsky (00:28:41):
Let's go back to the perimeter, drawing the perimeter concept to make that a little more real for people. So your advice here is the role of a PM, part of your main job, especially when it comes to engineers and design is to draw the perimeter for the team. Can you make that a little more real? What's an example of that maybe from something you worked on? What does that look like?

Kevin Yien (00:28:58):
Totally. The best word to describe the perimeter is just constraints. At the end of the day, you should be adding as many constraints as reasonable in order to let engineers and designers come up with the most creative solutions for whatever you're trying to do.

(00:29:15):
And so again, if we just stay focused on this point of sale example, one constraint would be, "Who the hell are we serving? Are we trying to go after sit-down restaurants that are serving five different courses and have a 200 item wine list? Or are we trying to serve the taco truck?" Those will lead to very different spaces. And if you leave both on the table, the lack of that constraint makes designing a good solution that much harder, that there instances where you actually can't apply that many constraints. But I bet that if you push on enough different axes, you eventually scope it down to a point where it feels really good for the team. It's just about how do you remove decisions, right? Because this I think is maybe a trite phrase, but the best decision is no decision. If you don't even have to think about the decision, the team is that much more effective.

Lenny Rachitsky (00:30:04):
So yo give people a few maybe even pointers of, "I need to create more constraints maybe for my team to help them go crazy, but within this box that we all agree on," so you mentioned make sure the user's clear of who you're designing for. Is there anything else, just thinking about maybe the PRD someone's trying to write to help create this constraint? What other maybe bullet points, sections would you imagine or do you find useful to add?

Kevin Yien (00:30:25):
So beyond customer segment/like-what-their-specific-role is, I think another one would be, we can loosely call it, jobs to be done, even though I know that's becoming an increasingly loaded term.

Lenny Rachitsky (00:30:35):
Yeah, it's great.

Kevin Yien (00:30:36):
But what's the thing they're trying to do and how many different pathways are you willing to entertain around it? That's another one that I would think about. Depending on what you're building, there's availability. So do you care about desktop web, mobile web, native mobile, et cetera? And maybe another one to think through just as an example would be, this is probably getting closer to what a lot of people think about in terms of principles, but what are the things that you want to be known for when you ship a product? One example there might be speed. And so if you say speed is more important than consistency of data, that's a huge tradeoff and constraint that you can give the team." Oh my god, if an engineer hears I don't need real time consistency of data, I can do so much cool stuff and easily accomplish that speed thing." And so that's just a very technical example maybe.

Lenny Rachitsky (00:31:35):
Awesome. Okay, I'm glad I followed up on that. There's a couple more things you mentioned that I want to come back to real quick. The first is this tuning fork idea. I completely agree, this point you made, that the best way to get feedback from your team is to take a first pass at it, and here's a rough quick draft. I find with design, especially if you design something ugly, designers are often like, "Let me make that better. We can't stand this thing." Is there anything else you want to add there? Just this idea of tuning fork as a feedback strategy.

Kevin Yien (00:32:03):
Okay, there's two areas we can go deeper on here. One is in how you get the feedback. So this is definitely a Square-ism, I think it was probably adopted from Amazon, which is around the silent read of documents. When you are all so busy and someone's like, "I wrote a doc," you send it into the Slack ecosystem and everyone goes, "Please give feedback." You have so much going on... You'll be lucky to maybe get a response. Maybe there's one or two people that chime in.

(00:32:35):
And so even though we hate meetings and we love asynchronous, there is a lot of value to saying, "I need 20 minutes of focused time to interrogate something that I've done. We're not going to talk. I'm literally going to force us into a room or Zoom. You're going to read this doc, I'm going to watch you comment on it in real time. I'm going to respond to your comments in real time. And at the end of this thing I'm going to have enough really good input that I can do a huge rub on this thing and get to the next phase."

Lenny Rachitsky (00:33:08):
I love that. So it's basically instead of, "Hey, I'm sending you this doc to go review, give me feedback," it's, "I'm going to schedule a meeting, and the meeting is for you to spend time reviewing this doc and giving me feedback and then maybe we could talk about it."

Kevin Yien (00:33:19):
Yep. And I think a lot of people are going to hate hearing that because like, "Oh my god, I have so many meetings already. Why do I want another meeting that isn't even a meeting?" But that's the best kind then, because it's actual work getting done, right? And maybe you carve out two minutes at the end for one really immediate discussion topic or something. But I don't think we give enough space in any type of meeting for people to actually think. And when you are just staring at a doc with your camera off and the only expectation is to engage with that thing, thoughts are a little bit better and crisper.

Lenny Rachitsky (00:33:55):
And I think with this idea, if someone says, "I want a meeting where you just sit and review this doc," you could always say, "Let me just review it asynchronously. I'll give you feedback, I promise. Give me 24 hours." Right? It's not like they have to come to this meeting.

Kevin Yien (00:34:07):
Although I would urge you to make them come to the meeting.

Lenny Rachitsky (00:34:10):
Okay, say more there, because you find that that's a lot more effective.

Kevin Yien (00:34:14):
I think there's two sneaky things hiding behind that. One is the, "Yeah, I'll get to this in the next 24 hours." Maybe they don't. Maybe you've really trust that person and they're the exception. But beyond that, there is something else to the real time interaction that can happen when you're commenting and responding on a dock at the same time. I think this is the part that often gets lost, which is the latency between a comments or question and a quick follow-up from the author just pushes that cycle speed really long in a way that doesn't need to be. And so when people are trying to find how do you move faster, this actually is one of those very good examples of moving slower to move faster.

Lenny Rachitsky (00:34:57):
It reminds me Claire Vo, I think it was her phrase of moving one clock speed faster, and just like that's the way you speed up a company is try to move one clock speed faster, which in this case is just reduce the time between feedback and iteration. I love it.

(00:35:13):
Okay, I want to shift to talking about a few very tactical things that you've found really helpful in your PM career and something you recommend to other product teams. The first is something you call a decision log. You think every PM should keep a decision log. Talk about what that is and why that's powerful.

Kevin Yien (00:35:32):
I will say there's two different decision logs we could talk about. We'll focus on the former though. The latter is just as you're making decisions within your job, you should document those within a PRD. Make sure everyone knows. It's just a silly, very small thing, but I think every PM should do it.

(00:35:48):
The other decision log though that I think is quite critical is if we zoom out for a second, every person has something that they can do to slightly increment in their craft. Sprinters have certain exercises that they do. There's something beautiful about pianists and piano scales where it doesn't matter if you are just learning the piano or you are a 30-year veteran, you're still doing your scales, and it's because it lays the foundation for everything else that you need to do.

(00:36:23):
And so we all talk about product sense. It's this super mystical thing that no one knows how to get better at. To me, it's just a fancy way of saying you can make good decisions with insufficient data, and the core of that is decisions. And so PMs need as many reps as possible in making decisions, documenting the rationale behind those decisions, and then crucially seeing the outcome of them. And so the natural followup would be, "Well, I only have to make X decisions in my job. How the hell do I make more of them?" Look around you. There's other teams that are making decisions. What would you do if you were in that position with the information you have? Great, write it down. Say why.

(00:37:06):
There's other companies that are doing crazy things. What are they doing? What would you do if you were responsible for the roadmap? Write it down. A year later, see what they've shipped. You can just do this for anyone. It's free, and no one takes the time to do it, but that's how I think you get better at actually making decisions, is just doing more of them.

Lenny Rachitsky (00:37:24):
Hearing you describe this, it feels like, "Obviously yes, why aren't we doing this? How else can we get better if we're not reflecting back on the decisions we've made? And realizing, "Hey, I made a bunch of bad decisions, but I'm always so confident in my decision still, maybe shouldn't be. So I guess first of all, do you actually do this? How often do you do this? And is there an example of you learning something from your own decision log?

Kevin Yien (00:37:50):
Many. And many of them because it was a wrong decision. But yes, I do keep a decision log. I have a separate sort of practice where it's just a daily log, which is everyone wants the perfect note-taking system. To me, the best note-taking system is inspired by... What is it called? big ass text file, BATF. There's a funny blog post from 2001 on it, but it's just, you write everything that happens to you in a day in a bolded list and it's all in one big note. That way you can command F it, do whatever you want. The way that I keep track of it is I do a little hashtag decision and then write things down just as I think about them. And then I'll have a reminder to comb back through on some cadence.

(00:38:36):
And so I'll first use a positive example, which is a funny one. So if you rewind to, I don't even know what year, but Shopify had just launched Shop app, their consumer application for what started as tracking your order when you bought something from a Shopify customer and then it's evolved into a full-blown Amazon competitor, where you can actually find merchants and buy things through it.

(00:39:03):
When they first launched it though, I was like, "Oh my God, this is so brilliant. They have completely hijacked this specific loop for consumer buying behavior via this very unassuming thing, which is package tracking." And so that morning I was like, "Whatever, I'm going to quickly draw a diagram of this flywheel that I think Amazon owns today. I'm going to show how Shopify is slowly planting their little seed to take over this and how Shop app fits into it." I tweeted out. And then I don't know, that day there must have been 60 Shopify employees that followed me. I was like, "What the hell is this guy talking about?"

(00:39:40):
And so funny enough, fast-forward, I've talked to some of the folks that worked on it and they're like, "Yeah, nailed it. Here's what we were thinking. Here's why." It's no longer secret sauce. But that was a really interesting example of both doing a decision log, putting my rationale down on paper. In this case, broadcasting it out, but then having that be a mechanism for it making its way back to me to actually better understand why did they make the decision versus what I thought, because the reasons were a little bit different, but the outcome was the same. So that's one interesting example.

Lenny Rachitsky (00:40:13):
It's an amazing story. You doing this explains why you've been so successful. I could see how this all connects now. I think for a lot of people, they would want to build this habit. Clearly there's a lot of value here, but they just don't because they got a lot of other things going on or it's just like this new thing they have to start doing. Is there anything that helped you adopt this practice of this daily log/decision log that you think might be helpful to folks to motivate them to give this a shot?

Kevin Yien (00:40:40):
This is probably just general advice on building any habit, which is start small and just force yourself to do it. And there's that old saying around, how do you start running as a hobby? You don't do it by saying, "I'm going to run a mile every day." You do it by putting your sneakers at the foot of your bed unless you take your shoes off inside, then you put it at the front door, you have your shorts ready to go and you're like, "I commit to putting on my shorts. And if I decide after getting dressed to go run, that I still don't want to go run. Okay, fine." But you build up to that thing.

(00:41:16):
I think decision logs are the lightest weight thing possible. And so you can start super easy by saying, "You know what? Every Sunday morning I'm going to scroll through Twitter, I'm going to check out Hacker News, whatever it is, I'm going to see something interesting and I'm going to make a bet. I'm going to place my decision on this thing." Write it down, and then set a calendar invite in X weeks, X months to see what plays out. And that's all it is, right? 10 minutes once a week, super easy. And then over time you can crank it up. And then eventually you're just constantly writing these decisions down and then it's like feeding its way back into you. It becomes second nature.

Lenny Rachitsky (00:41:52):
And you're touching on something that there's been a little bit of talk on this podcast and newsletter post about this idea of to get better product sense and product taste and also just decision making this case, one of the best strategies is to simulate other people's decisions and simulate what they're thinking through and predict what they're going to do, which is what you're describing here.

Kevin Yien (00:42:12):
Totally. I do want to apply a pretty severe caveat here though, which is, a decision log is not a replacement for building products. It's a additional complimentary thing that you can be doing on your own. But if you think that you can just sit back in your chair, look out at the market, make a bunch of calls and be like, "Look at how smart I'm getting without actually being hands-on with building a product," you're not actually going to get any better. So I just want to interject that

Lenny Rachitsky (00:42:42):
Amazing caveat, very important. Don't just sit and read Hacker News and think you're going to be become an amazing founder or product leader.

(00:42:49):
This episode is brought to you by Eppo. Eppo is a next generation A/B testing and feature management platform built by alums of Airbnb and Snowflake for modern growth teams. Companies like Twitch, Miro, ClickUp, and DraftKings rely on Eppo to power their experiments.

(00:43:05):
Experimentation is increasingly essential for driving growth and for understanding the performance of new features. And Eppo helps you increase experimentation velocity while unlocking rigorous deep analysis in a way that no other commercial tool does. When I was at Airbnb, one of the things that I left most was our experimentation platform, where I could set up experiments easily, troubleshoot issues, and analyze performance all on my own. Eppo does all that and more with advanced statistical methods that can help you shape weeks off experiment time and accessible UI for diving deeper into performance and out of the box reporting that helps you avoid annoying, prolonged and analytics cycles.

(00:43:42):
Eppo also makes it easy for you to share experiment insights with your team, sparking new ideas for the A/B testing flywheel. Eppo powers experimentation across every use case, including product, growth, machine learning, monetization, and email marketing. Check out Eppo at get eppo.com/lenny and 10X your experiment velocity. That's get eppo.com/lenny.

(00:44:07):
If someone wants to try this idea of a daily log, what is it exactly? Say decision log or daily log, is it just things that happen today and then hashtag, "Here's a decision I made, or here's a decision I think Shopify will make in the future"? Is that the format?

Kevin Yien (00:44:21):
Yeah, it depends on how far you want to go down productivity and notetaking as to rabbit holes, but let's start basic. This is not what I do, but I think it's the easiest place to start. Spin up a Google doc or a Notion page, just call it daily log and then bullet point out the date of today. And then as you're going through your day, you have a meeting, just type in the meeting name. If there's a takeaway, put it under there. If there's a decision you can make, do hashtag decision. And in this case, say, "Shopify launch Shop app. I think this is their way to take over the fulfillment to buying behavior loop. The reason for that is X, Y, Z." Follow up on this in six months and then set your calendar invite.

Lenny Rachitsky (00:45:02):
Awesome. So as motivation for listeners to try this sort of thing, just look at the success Kevin has had as in his career and how insightful he has been so far and will continue to be. And this is how these happen. This is how your mind learns to see things in a really unique, interesting way. So I know you're modest and aren't going to take any credit, but I'm just saying this is how you get better, is trying stuff like this.

Kevin Yien (00:45:24):
Footnote, correlation versus causation. It's all put out there.

Lenny Rachitsky (00:45:27):
Could be all genes. Could be completely unrelated to anything you've done entire life, I suspect.

Kevin Yien (00:45:33):
Could just be me being very lucky, I'll put that out there.

Lenny Rachitsky (00:45:35):
Could also be luck. Okay, so something I wanted to touch on with this decision log idea, and it's a segue to talking about hiring, is I think interviewing is also really good opportunity to try some like this. I feel like people interview lots of people. They think they know what they're looking for. They think they've made all these decisions. They think they have these amazing interview questions that are going to help them see really good signal, but you never actually go back and see, "Was I right? Should we have hired that person? Did this person work out? Was that question asked them at all inform? Was it at all a leading indicator of anything?" And I feel like this is a really good method for improving your interviewing abilities, is like, "Here's the questions asked. Here's what I decided. Here's what I think," and then a year later look back, "Was that actually right?"

Kevin Yien (00:46:16):
Yeah, totally. I think some of the best companies actually do have a practice around this where they have a 6, 12, 18 month check-in on new hires and they then compare their performance against level hired at and then review against the scorecards. It's a pretty laborious process. So startups aren't probably going to do it in the same amount of rigor, but it shows you so much about the holes in your interviewing process. So I definitely plus one of that one.

Lenny Rachitsky (00:46:50):
I love that. Oh my god, that puts all this pressure on your score, which is great. So that's actually a segue talking about hiring. There's a couple more tactics that I've seen you be really good at. So one is just hiring in general. You have a lot of interesting approaches to hiring, including this idea of a unsell email where you try to convince someone not to join your company. Talk about that and why you think that's effective and then anything else along the lines of hiring you've learned.

Kevin Yien (00:47:11):
I'll say the idea of the unsell email came from a place of failure, which is at Square I had shifted into a position where I had to hire a lot of people really quickly. And through that, as a fairly new hiring manager, you're like, "All right, great. I've been told the goal is to hire fast." Okay, you give me a metric, you're going to go after it. So you do your best to get as many people in the door as possible. When you're talking to your recruiting partner, they're incentivized to increase pass through rates, offer to close rates, all these other things, and so they're like, "Yeah, this person's really good." And you listen. "Yeah, they are pretty good, aren't they?" Even though there's a sneaking suspicion that maybe they're not the right fit, but you move forward anyways.

(00:47:54):
So fast-forward, there's a few folks I bring on, and within six months they come to me and they're like, "This is not at all what I thought I was going to do. This is not the environment I thought I was going to walk into. You didn't warn me about this, that and the other. I feel terrible. How do I prevent this?" And the reason it's bad is not just because they feel surprised, but because then, either one, they decide to leave, two, they're not performing because it's not the right role or environment for them, or three, maybe the company is still good, but that role isn't. And so they immediately try to do internal mobility or something to another team, which then leaves you with the same hole. So all of those bad outcomes. [inaudible 00:48:37] "How do I prevent this?" Well, I just got to front load all the gnarly stuff they're going to find out in their first six months.

(00:48:44):
And so the practice I started developing is you go through the whole interview process. During that period, you're collecting all these little concerns, fears, anxieties that they're not explicitly saying, but they're definitely hinting at. You got to be pretty honest with yourself about which ones are real. But then when you get to offer stage, I send an email with no more than eight bullet points and I say all the terrible things that are probably going to reinforce their fears. I'm pretty candid about, "This is what it's like here." Maybe one example would be, "Hey, I'm a parent and I'm worried about work-life balance." Maybe they don't say that explicitly in the interview process, but you get a feeling for it. And I get that as a parent too.

(00:49:31):
So if I'm at a startup, I'll be really clear and I'll say, "You know what? We are a series A startup. We are pushing really hard at product-market fit. The expectation here is going to be that you're online at 10:00, that you can occasionally hop on a meeting on a Saturday or Sunday." And if you can tell them that upfront and they can read that whole email and still be equally excited to join, you find yourself an A+ hire. But if they read that and they're like," I don't know anymore," it's way better to say, "Great, this is not a good fit. Let's go our separate ways" than have them leave after six months.

(00:50:08):
When I first instituted this, I lost 30% of candidates at offer stage.

Lenny Rachitsky (00:50:13):
Oh wow.

Kevin Yien (00:50:13):
Which drove my recruiting partners insane because they look terrible. Their manager is like, "What the hell are you doing? You're losing everyone at the very end." And so they ask, "Can you either not send this thing?" Or, "Can you send it at the very beginning?" And my answer is no, because I don't know what they're afraid of yet. I have to go through the whole process to actually understand the thing that's going to potentially make them say no, and that's really crucial I think.

Lenny Rachitsky (00:50:36):
But once you hear it again, this is such an obviously good idea, clearly not an easy thing to do. In this case where recruiters were upset, is it just get buy-in from folks above, like, "Okay, this sucks for them, but at a macro level, this is good for the business" and they're like, "All right, let's keep doing it"?

Kevin Yien (00:50:55):
At Square, at least, when I first started doing it, luckily I had a very good relationship with them. So that's a good starting point. This is maybe going to come across a little bit flippant, but they can't stop you from sending an email technically. So I'm just going to send the email. And if someone really wants to come and say, "This is bad for business," whatever it is, I have very strong reasons for why that's not the case. And now I've done it so many times, at least, that I can point to very clear proof points on why this is the right path.

Lenny Rachitsky (00:51:27):
In theory, the incentives would be aligned where the recruiter success matters. It's based on, did they actually have a good time? Did they stay? Did they have good impact?

Kevin Yien (00:51:35):
Totally.

Lenny Rachitsky (00:51:36):
But since they're not, obviously incentives aren't right.

Kevin Yien (00:51:39):
I think some companies have shifted on that, where recruiters and salespeople are compensated sometimes in similar ways in terms of quota and whatnot. And so they'll hold the recruiter accountable to six, 12 post offer tenure before they say, "Oh yeah, you successfully landed this role." So you can tweak the incentive structure a little bit, but not everyone does that.

Lenny Rachitsky (00:52:03):
Okay. So the advice here is to end up with better people that end up being successful and happy. Keep track of the things that will probably be painful for them at the company, and then craft an email that shares upfront, "Here's what made be a problem if you join, and I just want to be very upfront about it." I think you actually shared a template of one of these emails in one of your blog posts.

Kevin Yien (00:52:25):
Yep, that's right. I have a fairly real one in [inaudible 00:52:30].

Lenny Rachitsky (00:52:29):
Is there anything else hiring-wise? I know there's probably infinite things that you've done, but is there anything else you think might be worth sharing of things you've learned to be more successful at hiring awesome people?

Kevin Yien (00:52:39):
One final note I'll make on unsell email is it's not as if you just send the email and then they either say yes or no. Most of the time they will say, "Thank you. I am cool with six of these. This one freaks me out. Can we talk more?" Definitely. And I think this is where hiring managers have an incredible responsibility that sometimes isn't taken as seriously as it should, which is, when you are working with someone to get them to join or to offer, you need to bend to do whatever it takes for them. And so if they're like, "Hey, the only time I can talk is tonight at 11 o'clock after my kids go to bed."

(00:53:18):
"No problem. Here's my phone number, let's hop on. I will walk you through whatever you want to talk about." That sort of has to be the place you get to for really strong hires. So that's just one other thing I'll say.

(00:53:29):
The meta point around that is you need to be really invested in the candidates. This probably does change at a certain scale, like if you're "organization" is hiring a hundred engineers or whatever, you have process around it, you have pipelines, there's a machine at that point, but I do think the direct hiring managers have a responsibility to be really involved in every individual, because there's no one who's directly hiring a hundred people. It's always within a number that I think you can take on.

Lenny Rachitsky (00:54:01):
Okay, so this is the final tactic that I heard you're amazing at, which is automating user research. On the surface this sounds amazing. "I'm going to automate my user research. It's going to be amazing. So great." Talk about why you find this really powerful and important. And then how do you actually do this? How do you automate user research? How have you done this on your teams?

Kevin Yien (00:54:17):
Let's start from why this even matters. I think a lot of folks, going back to what is the point of product management, I think there's a similar overlap with UXR, like user experience research, and people will say, "Well, if they're doing research, what do I need to do? I should just be consuming what they're producing to help with that."

(00:54:39):
I know PM should settle for looking through bent glass in my opinion because whether it's a research report, whether it's something a salesperson is telling you, whether it's market research, don't care, it's been processed by someone, and PMs need direct exposure to raw material. End of story. And so that's where I think you just need to constantly be talking to or interacting with whoever is your customer. That's the foundation.

(00:55:08):
So okay, if we all agree on that, then the question is, "Well, I don't have time. It's so hard. How do I find them? My customer success manager says I can't talk to the client." If you are in a situation where the product manager is literally not allowed to talk to a customer, there is something structurally wrong and that needs to be fixed first. So I'm going to ignore that one for now just because that's a whole other rabbit hole, but you need to fix that in order to even get close to the next thing.

(00:55:38):
Okay, now the excuse is going to be, "Well, I don't have time. I don't want to run a program. I don't want to have to query and look up and send out emails every week." There's so many good resources out there right now, and I think that there are... I'll speak mainly from a B2B sense. I think B2C, slightly different story, I don't have as much experience there. But B2B, the two things I will say, one is, there's this thing called userinterviews.com. Shout out to them. They're pretty much user testing but explicitly focused on B2B and you can put in super clear criteria on the type of people you want to talk to. They do the heavy lifting and sourcing it, and then you just review and say, "Yes, yes. No, no," and you can have a steady stream of the exact ICP, you want to go after. ICP is ideal customer profile that you want to go after just coming to you automatically. Amazing.

(00:56:28):
The next one though, it depends on whether or not you have this tooling in place, but the broader theme behind this next category is your sales team is a research team, and if you don't view them that way, you are missing out on half the value. And so there's tools like Gong, which do call recordings, and you can set up filters and alerts for specific terms, phrases, competitors, whatever you want. I don't care what PM you are in the team. You can find the terms that are associated with what you care about the most. Those then get pushed automatically to a Slack channel or otherwise. And then you can set up workflows either via Zappy or something else to say, "Who was the customer? Pull their email, put that into a sequence, drop in my Calendly" and you just have interviews showing up automatically on your calendar. I will say I cannot take credit for this. Shout out to Beth Hills who was a PM that hired at Mutiny. She is the queen of automating customer research and built an amazing system around this.

Lenny Rachitsky (00:57:28):
So the way it works is you set a term for like, I don't know, POS, point of sale, something in Gong, and if somebody says that or has an issue there, talk about again how that schedules a meeting with you potentially.

Kevin Yien (00:57:42):
Yes. So Gong has an integration with Slack. You set up this alert, it posts to Slack the excerpt of the transcript where it was mentioned along with the user or customer name. So in this case, it'll be Lenny's Burger shop. lenny@lennysburgershop.com, and then you can set up a Zapier to take every new Slack post from that and then send using, I don't know, customer.io in email to that person using that field. And then in that template of the email, drop in your Calendly specifically for user research.

Lenny Rachitsky (00:58:21):
Wow, that is genius. I love that. There's another similar tactic that Teresa Torres shared on the podcast in one of the earlier episodes where you have a little popup on your homepage asking people, "Hey, do you want to talk? We'd love to hear feedback on our product. Click here if you want to give us some feedback," and then that schedules Calendly on the PMs.

Kevin Yien (00:58:41):
Totally.

Lenny Rachitsky (00:58:41):
PM's calendar. So you mentioned Gong, customer.io. There's some tools here. Zapier obviously. Is there anything else you find useful to help automate the sort of stuff?

Kevin Yien (00:58:52):
If I take a step back from the automation side or maybe straddle it, depending on the type of business you're in, there's ideally people talking about you somewhere, right? It's either happening on Reddit or Twitter or on some forum or your support forum. There is a community, there's a destination somewhere. And if there isn't, then I don't know, that's too bad. Maybe you don't have product-market fit. If you can take advantage of that, you can usually set up something. And if it's not a Gong or a Zapier, maybe it needs to be just a custom script that you write or you sit down with an engineer to say like, "How do we set up alerting around this thing so that I know when things are happening?"

(00:59:36):
I think you can't use the effort required to do that as an excuse to not be talking to your customers more frequently. Because again, if we go back to a product manager should be trying to convert this potential into kinetic energy, part of that understanding and part of knowing the constraints you can apply is just living in that world as much as possible.

(00:59:59):
The best comparison I can give is, there is a world of difference between reading a report about a lime cook and then standing with a lime cook. You will just pick up on so many ancillary aspects of what their life is like that cannot possibly be communicated in a report. You owe it to yourself as a PM to be exposed to those things all the time.

Lenny Rachitsky (01:00:27):
In my experience, every time I talk to a customer, I'm always reminded, "Why have I not been doing this more? How can I not be doing this? It's absurd that I haven't done this," like every time you actually do it. But until you do that, you're like, "No, no, I know what they want. I'm reading all the customer service talent issues, I'm reading their emails, I get it." Until you actually talk to them, you're like, "Oh wow, I had no idea."

(01:00:51):
I love that your advice is like, the tactics you're sharing aren't, "Here's how you get a bunch of feedback." From your users, it's like, "Here's how you actually get to talk to the right users." It's like in the end of the funnel talking to a potential customer. It's not just reading a cool... some feedback that they shared.

Kevin Yien (01:01:07):
That's right. I think just like the last point on this one is when you join a new team or start a new role, every PM is budding with energy to do this, "Of course I'm going to talk to my users." But then you reach a point where you go, "No, I know them inside and out. I don't need to talk to them anymore. I can write a PRD in my sleep. And I'm so busy doing both, product improvements, maintenance, annual planning, something else.I can use my intuition from the hundred interviews I've already done. I don't need to do one more interview." And that is a very tempting lie to tell yourself because the world is changing, their lives are changing, and you need to constantly be exposed to those little micro changes in their lives in order to build the product that they'll eventually need.

Lenny Rachitsky (01:02:00):
The best explanation I've heard of this is actually from your new boss, Patrick Collison, boss's boss's boss, I don't know how far away you're from him, where he talks about user research and where it fits in. And the way he described it is, instead of doing user research, talking to customers, informing what to build, it's talking to user, talking to customers informs your mental of what the customer needs and then that informs what to build.

Kevin Yien (01:02:23):
100%.

Lenny Rachitsky (01:02:24):
Beautiful way to think about it.

(01:02:26):
Okay, so I'm going to take us to a couple recurring themes of this podcast, a couple corners of this room that we have. First of all, I want to go to AI corner, so let's walk over there. Hello, AI corner. I'm curious if you've found any interesting uses of AI in your work or in your life.

Kevin Yien (01:02:46):
There's plenty in work. I don't know if any of them are interesting or novel. I feel like everyone's just figuring it out in real time together. So I'll actually take us in a slightly different direction. And this may be isn't directly useful to product managers, but I think it's a really good story.

(01:03:02):
So when Midjourney V1 was released, if we can remember that far back, it was at least I got beta access on a Saturday. And for what's worth, I have three daughters, one of them's seven years old, and so her and I were awake. We were waiting for the other two to wake up and I was like, "Oh, I have this cool new thing. Do you want to play with me?" And she goes, "Of course." So we log in, we create an account and I type in the first prompt, image gets generated, it's like a rainbow or something. And then I ask her, "Do you want to try it?" She goes, "Of course." So she types in unicorn prancing in a field and it generates this hideous looking demented unicorn with two rear ends and a demon flying over it. And I'm appalled at first thinking that she's going to feel really bad about what she got shown, but instead I look over and she's in awe. She is amazed.

(01:04:04):
And then she turns to me and she goes, "Did I draw that?"

(01:04:06):
"Yeah, I guess you did." And the thing that I got hung up on was that she used the word draw. She didn't say, "Oh, I enter a prompt and the LLM produced this thing," or whatever weird terminology that all of us use. It's like, "Did I draw that?" I don't know when it clicked for me, but at some point in time after that I was like, "The concept of these image generation models is the same as a crayon to her. There is no difference in her mind." And that is an insane change that I can't even comprehend. And so for me that's just been I think an experience that I go back to when I think about people asking, "What do you think AI is going to do and what's the next thing? And is it chat or is it something else?" I cannot comprehend what a child who grew up with a crayon of an LLM is going to think is a good product in 20 years. I need to start crying. But goddammit, I have no freaking clue.

(01:05:11):
And so I think I have a cheat code actually as a parent, because I get to see how they evolve and use these tools in real time. But all I can say is we are not even beneath the dust on the surface when it comes to what's going to change.

Lenny Rachitsky (01:05:29):
Wow, that is an amazing story, it gave me tingles. It makes me think a little bit about how we used to code in binary and then assembly and now it's Java, and then I don't know, all the languages, Python. And now it's like AI, LLM generating code and it's the same thing for drawing potentially. It used to be sticks on a cave and then became crayons and pens and iPads and all that stuff. And now it's again LLMs, so that's pretty bonkers. Amazing story. Thanks for sharing that. Useful to PMs and non PMs alike.

(01:06:06):
Okay, I'm going to take you to another recurring corner/segment of the podcast, fail corner. I'm curious if there's a story of failure that you can share of something that didn't go the way you wanted and still had a positive impact on your life or career?

Kevin Yien (01:06:25):
Well, there's countless stories of failure, but I'll choose the one that I think I've had to reference the most with people and has been to date the most difficult one to really talk about. I'm on the other end of it, and so now it's very easy, but it took several years to get there.

(01:06:44):
So context, I'm [inaudible 01:06:47] my way to PM, I land my first official, by title, PM job at a startup. I made it. I've arrived. I'm officially a product manager. And we go up, we go down, all the things happen. Fast-forward, the company is really struggling and so we go through a series of rolling layoffs and I'm round 4 something. At that point in time, my wife was nine months pregnant with our first child, and so I am freaking out. There is the personal side that I'm worried about, but then there's also my identity that has been completely crushed, because in the moment all I could think was, "I thought I was a product manager. This is evidence I am not," and I couldn't get past that.

(01:07:37):
And so for what it's worth, this is the one post I have on my website that I actually feel really, really proud of. It's called Finding Swagger. I can talk about why it's titled that way, but it's the thing that I really wrote more for myself because it's a good reminder to me every time I fall into this mentality again, because that may have been the first time that I really had the feelings of, "I'm not worth it" or, "I'm not meant to be this person," but it's recurred several times since then over the past decade. And when I read back through my mentality of how I got to the other end of it, it helps even myself sort of get back on the horse.

(01:08:28):
So okay, I get laid off, I'm distraught, I have no purpose, I'm nothing. And it was through a lot of reflection, a lot of conversation with friends and my wife where you eventually need to convince yourself that there is a difference between you not being good at something and a business or company not needing that thing at a particular moment in time, or you being very good at something but not in the way that a company needs.

(01:09:01):
And so I think once I was able to get to that, Square for me was the immediate subsequent role that I took on. And I went into that thing just full steam ahead, I'm going to prove myself. "I know I'm good," because I think I'm good, "and I am going to prove the hell out of that" mainly to myself, but ideally to other people too.

(01:09:24):
I think you shouldn't do things for other people for validation, but the initial success I got to see in launching a product, gaining the trust of my peers, having something that restaurants were texting me about, saying, "I can start my restaurant because of this. I didn't go down during rush hour because of this," that gave me the validation to say, "Okay, I am competent at this thing called product management." And then from there you can continue to build and continue to grow.

(01:09:53):
But I think right now, the market's weird, right? The market's wonky. There's a lot of really good talent that is just getting hit over sideways. I have a lot of friends that are having the same mental conversations around, "Well, I guess I'm just not worth it. I guess I wasn't cut out actually to do this job, do this role, be of this purpose." In some cases, maybe that's true and you can sort of have a career transition or a pivot in your life, but I think it's worthwhile to reflect on what are the things that were in your control that you can now change moving forward? And then what are the things that were truly out of your control that you can now apply to find a better fit? And that's one of the big things that I've been able to, I think, come around to.

(01:10:41):
And it's really hard because early on I think it's very tempting to associate a lot of different things with your identity. You're like, "I'm a startup guy. I'm a PM, I'm a fast whatever, I'm a fast thinker." And when an event happens that pokes at that part of your identity, the rest of it crumbles. And so long story short, I think it's really important for folks to use these moments where it feels bad and feels like a failure to reevaluate what parts are actually part of your identity and which parts are in your control to change in whatever you do next.

Lenny Rachitsky (01:11:23):
Wow, what an important and great story. As you mentioned, a lot of people are dealing with finding it hard to find a new gig and a bunch of layoffs. I think this is going to help a lot of people. The two categories you shared I think are especially powerful. So the advice here is just separate, "This company just doesn't need someone with my skills right now" from, "I'm not good at these skills." Can you just share those two kind of things that might be true that you may not be recognizing about why they maybe laid you off again?

Kevin Yien (01:11:52):
Totally. So one is the business just doesn't have a need for you. They got ahead of their skis and that's their fault. They probably admit that, but that's not up to you. The second one though is my skills and the way that company operates are not compatible. This one I think is really, really important because I've seen so many times where there's been a PM engineer, designer, whatever role, they cannot make it work at company A, and then you see them five years later just killing it in company B and you're like, "Did they change as a person? Did they get super good at what they were bad at before?" Maybe a little bit, but honestly it was just a change in environment. And when you find the right environment in the right role, you just flourish.

(01:12:40):
And I think this is actually... Sorry, we'll go back to hiring for just a moment or at least management.

Lenny Rachitsky (01:12:44):
Please.

Kevin Yien (01:12:45):
This is why performance conversations can always feel so difficult because it seems like you're telling someone you are bad, and as the recipient you're like, "I am bad." No one wants to hear that. But the reality is, you are not bad. It is that maybe the way that your environment is working, the machine that you exist as a part of, is not the kind that you thrive in. And so it's within your control to decide, "I'm going to change how I work to fit that environment" or, "I'm going to find a different environment that actually fits the way I work much better." And that's empowering.

Lenny Rachitsky (01:13:26):
I think that also applies a lot to interviewing. A lot of times you interview, don't get the job, and you exactly feel like, "Oh, I'm just not good enough." But really that company's way of working just may not gel with the way you operate. Like Uber operates very differently from Airbnb, operates very differently from Google. And so it's not that necessarily something you're doing wrong, they just don't think you're fit.

(01:13:46):
And this connects to something. I just had another guest on the podcast. He was a brain science dude, and he talks about how every company has this kind of habitat. What habitat are you creating for your employees to enable them to think differently or to be shut down and not feel like they can be creative or try big things or not? And basically, the way he just kind of to leverage that metaphor, like you may be a palm tree and you're trying to join Antarctica and it's not going to go well.

Kevin Yien (01:14:16):
Totally.

Lenny Rachitsky (01:14:17):
You got to find Palm Springs or some hard place. Kevin, this has been amazing. Okay, so before we get to very exciting lightning round, is there anything else that you think is important or valuable to share, leave listeners with? And if not, absolutely.

Kevin Yien (01:14:30):
I think we'll probably find ourselves on interesting detours to the lightning round, so let's roll in.

Lenny Rachitsky (01:14:35):
Kevin, with that, we've reached our very exciting lightning round. Are you ready?

Kevin Yien (01:14:39):
Hell, yeah. Let's do it.

Lenny Rachitsky (01:14:40):
Let's do it. Question one, what are two or three books that you've recommended most to other people?

Kevin Yien (01:14:46):
I'll start by saying the type of book by volume that I read and get the most joy from are autobiographies and memoirs. It is just the ultimate cheat code to spend time with people that you respect, are interested by, or want to learn from.

(01:15:05):
Could you imagine what it would take in real life to sit down with Albert Einstein for 50 hours and just have him talk to you about his life? Impossible. But you can read and pretty much get the same thing.

(01:15:21):
So anyways, strong requirement or a strong suggestion, go read autobiographies and memoirs of people that you respect, mostly for their mental model and way to approach thinking, less about specific things. But the one book that I read without fail every year has a very misleading title. It's called The Courage to Be Disliked. I think it's been mentioned previously on the podcast, but it covers... It's a very Socratic method style, so it's about a philosopher and a young person, and it tries to teach you the ways of Adlerian psychology, which is sort of counter to Jungian theory.

(01:15:56):
The reason I really like it is because it makes me uncomfortable. So the whole premise, in my opinion, behind the book and other in psychology is focus on what you control. That's the one line. Don't worry about everything else. Don't worry about what other people think. Don't worry about what other people do. You cannot control those. You focus on yourself and you focus on the actions you can take. And be the person that you think will attract other people, that you want to be around.

(01:16:29):
There's some really pointed notes in there that I'm like, "Ha-ha-ha-ha. I don't fully agree with that one," but it always pushes me to question something about what I believe. And so in every physical copy of a book I have, I write the date that I started reading it again. The front inside cover of this book, I think it's been seven or eight years at this point that I've read it every single year.

Lenny Rachitsky (01:16:55):
Wow. It's like a decision logging in another context almost.

Kevin Yien (01:16:59):
Yeah, a little bit. I would say the other book I was going to mention is The Paper Menagerie. This actually shout out to Sean Rose for... I've never met him, but I really appreciate Sean. He was one of the early, if not, first PMs of Slack, and he used to be really loud on Twitter in a very good way, and I think I learned a ton from stuff that he would post. But one of the things that he posted was this book. It is just the most beautiful collection of essays that span sci-fi and fantasy. And so if you're into that kind of stuff, if you like exhalation, then Paper Menagerie is even better.

Lenny Rachitsky (01:17:39):
Oh, shit. Guess I got to add this book to my list. I do love exhalation.

Kevin Yien (01:17:43):
There you go.

Lenny Rachitsky (01:17:45):
Oh, man, this job is tough. I get to learn all these amazing books and then I got to read them, but I don't have time. Hard.

(01:17:51):
Speaking of more time, next question. Do you have any favorite recent movies or TV shows that you really enjoyed?

Kevin Yien (01:17:57):
There's less time for either these days. I will say not novel, the Bear holds a very special place in my heart right now, both because I worked in restaurants and I got to build for them. And so seeing the details that they do actually gives me a lot of anxiety, but I really appreciate the craft they put into it.

(01:18:16):
The other show, actually, I think this is the first time, Physical 100. So this is a Netflix show. It's a Korean show about a hundred different bodybuilders, athletes, what have you, on who has the optimum physique or whatever. I don't really care about that part. The two things I love about the show are, one, it's ridiculous what people are capable of. You see what they can physically do and you're like, "Oh my God, that's amazing what they can put their minds to." The other part though, and this is maybe a trend of Korean shows that I've noticed, is the amount of respect they have in this competition is bar none. You have this guy who is historically famous, was the top champion in judo or something, and you have all these other athletes that are 15, 20 years younger, and they're bowing and just humble to compete against the guy. I kind of wish that more American Joes had that level of respect as opposed to just trying to find the most conflict. There's something that I really like about that.

Lenny Rachitsky (01:19:25):
That's beautiful. I've started that show, but I haven't continued it, so I'm going to revisit it.

Kevin Yien (01:19:30):
Cool.

Lenny Rachitsky (01:19:30):
Do you have a favorite product that you've recently discovered that you really like?

Kevin Yien (01:19:34):
We got a really old 2002 Jeep to work on with my daughters, just like a true junker. And as a result of that, we're repairing it. We're taking off the rust, replacing parts, and so there's these little magnetic trays that you can hold screws and nails and whatnot, so they don't go flying and rolling around everywhere. It's stupidly useful when you're working on a car. And the girls love it because they can use it for other things like collecting hair clips or whatever else. So magnetic trays, shout out.

(01:20:06):
And then selfishly, I will say my buddy Arjun Mahanti has an app called Circuit. If you search the app store for Circuit, like C-I-R-C-U-I-T, HIIT timer, it's such a delightful little app that lets you track Tabata sex or whatever else to just get a little workout in.

Lenny Rachitsky (01:20:24):
Super cool. Magnetic tray is not boring at all. That is extremely cool and it has a really cool story too. Do you have a favorite life motto that you often come back to and find useful to share with friends and family in work or in life?

Kevin Yien (01:20:36):
I think we've actually maybe touched on both of these. I'll cheat and I'll pull one from maybe each parent so that in case they see this, they don't feel like I'm favoring one of them.

(01:20:45):
So my mom's side, I think something that she would always repeat to me growing up is everything happens for a reason. I hated that growing up because she only said it when something bad would happen. Something bad happens, she goes, "Everything happens for a reason," and I'm like, "No, it doesn't. Life just sucks." And to no surprise at this point in the conversation, I've now grown to really, really appreciate that piece of advice because what it's actually trying to communicate is, when something happens, good or bad, frankly, don't dwell on it. That's the past. Focus on what you want to do and then just move towards that. And then in most cases, you'll be able to look back in one, five, 10 years and connect the dots in a way where the story makes sense in your mind. And so just having that shift in perspective I think has helped me a lot to not overreact to anything that happens in my life. So that's one side.

(01:21:46):
And then on my dad's side, so the funny origins of this, unsurprising to anyone with Asian parents, I'm a spunky little 7-year-old, I come home with my math test one day. I got 97%. I think that's pretty good. I go show it to my dad with beaming eyes and pride. He sort of stares down his nose at it, looks at me, "Where's my other 3%?"

Lenny Rachitsky (01:22:08):
Oh, my God.

Kevin Yien (01:22:10):
I'm just distraught and I sulk away. I'm very sad. I study hard. I do the next math test, I get 100% yes. All right, dad's approval, here we come. I come flying back, I put the test in his hands, he stares down his nose at it, looks at me, "Where's my other 3%?" I'm so confused. I'm like, "I got 100 out of 100. I have no clue what you're talking about." He just looks me down the eye and goes, "Who said a hundred is the most you can get?" At that age, I literally had no clue what he was talking about. And he had to reframe it for me in the moment around like, "Well, was there extra credit? Can you just write your own problems to challenge yourself more? Could you have given yourself another test? And maybe the teacher won't give you credit, but you give yourself credit for doing additional work."

(01:23:01):
I think I carry that theme forward where there's this weird transition we all go through from childhood to adulthood where we no longer receive homework, we're responsible for defining the work that we do. And when you do that, if all you do is the minimum of what defined the 100% of what your job requires, you'll never grow. And so it's up to you to actually find what is the additional 3%? There's always three more percent. So that's my dad's lesson.

Lenny Rachitsky (01:23:35):
Kevin, you're blowing my mind. There's so many great stories, you're just full of them. And I feel like this lesson also applies really well to product and building product and founding companies.

Kevin Yien (01:23:46):
Totally.

Lenny Rachitsky (01:23:46):
Just pushing further than people expect and making it a lot more delightful than the minimum bar.

(01:23:53):
Final question, speaking of things that maybe people don't expect and may not understand is possible, looking at you, nobody would've guessed that you're a competitive eater at some point in your life. As a final question, tell us about this part of your life. What did you eat? How does this work? How far did you get in this path?

Kevin Yien (01:24:12):
It's probably misleading to say that I was a true competitive eater. I wasn't on the circuit with a... I forget his name, but Johnny Chestnut.

Lenny Rachitsky (01:24:21):
[inaudible 01:24:21]. Oh yeah, Chestnut

Kevin Yien (01:24:22):
Back in the day, that's like the OG competitive eater on the hotdog circuit, I guess.

Lenny Rachitsky (01:24:25):
Right.

Kevin Yien (01:24:26):
For me it was more eating challenges. And so whenever I would travel, I would find the local eating challenge, whether it was time-based, volume-based, something else, and just try to see what I could push my body to do. I was blessed with a great metabolism, so I never really had to worry too much about anything else. And the origin, the first moment of this was when I was 14, my sister was going to college in Minnesota and there's this steakhouse up there called Manny's, which is where the Vikings Frontline goes to after every game. And they have this ridiculous 97 ounce order house. I don't know how many pounds that is, but it's too much meat for a human to consume.

Lenny Rachitsky (01:24:26):
97 ounce.

Kevin Yien (01:25:07):
97 ounces, yeah. And so I sit down, I order it thinking, "This is going to be great." They put it in front of me, it's a monster. You have to eat in under an hour. And so 45 minutes into it, I'm halfway through and about to die. And the catch is, if you finish it in under an hour, you get it for free. And so my dad again leans in and goes, "You can't afford not to finish this."

(01:25:39):
And so, "Message received, sir." Hunker down. I plowed the other half in 15 minutes. I then slept for I think three days afterwards. But after that I was like, "Oh my God, if I could do that, what else could I do?" And so, [inaudible 01:25:54] carried for, I don't know, nearly a decade of trying to do these interesting challenges.

Lenny Rachitsky (01:25:58):
Wow. I don't know how that's physically possible, but clearly you did it.

(01:26:02):
Kevin, this has been wonderful. I think there's so many lessons here for people in so many ways, life and work and parenting. Two final questions, where can folks find you online if they want to follow you and learn more from you over time? And how can listeners be useful to you?

Kevin Yien (01:26:17):
I'm on Twitter, just @kevinyien. Technically, I'm on LinkedIn. I don't post over there. I probably should. I hear it's very good. But that's where you can find me. Also, my website. I don't write that often, and I don't have an RSS feed, which has always been on my backlog, and I'm always too lazy to do. But one day I will add it.

(01:26:38):
One quick note, I'll actually make on websites. So on one hand, I love all the different website builders that exist. It's amazing what we've enabled anyone to be able to do. There is something really special about having your corner of the internet that you built sort of hand by hand, line by line. And so my website is, it's a GitHub page. It's hosts on GitHub pages, but it's just raw HTML, CSS, nothing fancy. I get so much joy every year just doing a slight tweak or cleaning of it. And so I really do recommend that for anyone with the curiosity and the desire to buy your domain, even if you're never going to write anything on it, you're never going to share it out, just own a little piece of the internet. It feels good.

Lenny Rachitsky (01:27:28):
I love that. I didn't know that about your website. And I could see it now as I go there. It's .html, which you don't see as much anymore.

Kevin Yien (01:27:35):
Exactly. [inaudible 01:27:37].

Lenny Rachitsky (01:27:36):
And then... Yeah, can listeners be useful to you.

Kevin Yien (01:27:39):
This is going to sound trite, and it has nothing to do with product necessarily, just be kind. Make for a nicer world, right? Say thank you a little bit more often. Hold the door open a little more often. Wave if you cut someone off in a car. I think there is a temptation and incentive structure to create conflict intention. And in most cases, the world would just benefit from a little bit more kindness.

Lenny Rachitsky (01:28:06):
What an incredibly beautiful way its ended. Kevin, this was so much fun. I'm so glad we did this. Thank you so much for coming on.

Kevin Yien (01:28:13):
Thank you for having me.

Lenny Rachitsky (01:28:14):
Bye, everyone.

(01:28:16):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Growth tactics from OpenAI and Stripes first marketer | Krithika Shankarraman
**Guest:** Krithika Shankarraman  
**Published:** 2025-05-25  
**YouTube:** https://www.youtube.com/watch?v=QaDsk4iH1aw  
**Tags:** growth, metrics, kpis, prioritization, user research, a/b testing, experimentation, funnel, conversion, pricing  

# Growth tactics from OpenAI and Stripes first marketer | Krithika Shankarraman

## Transcript

Krithika Shankarraman (00:00:00):
It seems like there's a playbook for everything, there is a framework for everything, but the reality is you have to spend the hours and the time to really understand your customer.

Lenny Rachitsky (00:00:09):
You were the first marketing hire at OpenAI. I believe ChatGPT is the fastest-growing product in history. Let me ask you this. A lot of people might be hearing like, "Oh, ChatGPT." It's like, why do you need marketing?

Krithika Shankarraman (00:00:18):
Everyone knew of ChatGPT, but when you clicked one zoom level further, the thing that came up was, "I don't know what to use it for." The work of marketing ended up becoming creating this sort of use case epiphany where people could say, "I had no idea ChatGPT can do that." A lot of marketing metrics tend to be vanity metrics about the number of clicks that you got, number of views, number of impressions. I think those are all bullshit numbers. What is that experience that you want your customers to come away with when they interact with your brand?

Lenny Rachitsky (00:00:45):
If your advice is, "Don't just copy what other companies do," what should people be doing?

Krithika Shankarraman (00:00:50):
Put together a four-step process that has served me pretty well. The first step here is...

Lenny Rachitsky (00:00:55):
Today my guest is Krithika Shankarraman. Krithika was the first marketing hire and VP of marketing at OpenAI, the first marketing hire at Stripe where she was the only marketing person for three years. She was also an early marketing leader at Retool and at Dropbox. She also did marketing for Android at Google. Currently, she is executive in residence at Thrive Capital where she supports their portfolio and founders on all things marketing and helps hire early marketing leaders for their startups.

(00:01:21):
In our conversation, we talk through all of the biggest lessons that she has learned about how to market your product from her time at OpenAI, Stripe, Retool, Dropbox and other places, including her four-step diagnostic approach to marketing, her anti-playbook playbook, what B2B companies can learn from consumer marketing, career advice for people looking to get into marketing, and also just what people that don't want to get into marketing should know about marketing to be successful.

(00:01:46):
A big thank you to Kevin Garcia and Kelly Sims for suggesting questions and stories to get into. If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. Also, if you become an annual subscriber of my newsletter, you get a year free of a bunch of world-class products, including Superhuman, Notion, Linear, Perplexity, and Granola and more. Check it out at lennysnewsletter.com and click Bundle. With that, I bring you Krithika Shankarraman.

(00:02:13):
This episode is brought to you by Eppo. Eppo is a next generation A/B testing and feature management platform built by alums of Airbnb and Snowflake for modern growth teams. Companies like Twitch, Miro, ClickUp and DraftKings rely on Eppo to power their experiments. Experimentation is increasingly essential for driving growth and for understanding the performance of new features, and Eppo helps you increase experimentation velocity while unlocking rigorous deep analysis in a way that no other commercial tool does. When I was at Airbnb, one of the things that I loved most was our experimentation platform. I could set up experiments easily, troubleshoot issues, and analyze performance all on my own.

(00:02:53):
Eppo does all that and more with advanced statistical methods that can help you shave weeks off experiment time, an accessible UI for diving deeper into performance, and out of the box reporting that helps you avoid annoying prolonged analytic cycles. Eppo also makes it easy for you to share experiment insights with your team, sparking new ideas for the A/B testing flywheel. Eppo powers experimentation across every use case, including product, growth, machine learning, monetization, and email marketing. Check out Eppo at geteppo.com/lenny, and 10 X your experiment velocity. That's geteppo.com/lenny.

(00:03:31):
This episode is brought to you by Airtable ProductCentral, the unified system that brings your entire product org together in one place. No more scattered tools. No more misaligned teams. If you're like most product leaders, you're tired of constant context switching between tools. That's why Airtable built ProductCentral after decades of working with world-class product companies. Think of it as mission control for your entire product organization. Unlike rigid point solutions, ProductCentral powers everything from resourcing to voice of customer, to road mapping, to launch execution. And because it's built on Airtable's no-code platform, you can customize every workflow to match exactly how your team works. No limitations. No compromises. Ready to see it in action? Head to airtable.com/lenny to book a demo. That's airtable.com/lenny. Krithika, thank you so much for being here and welcome to the podcast.

Krithika Shankarraman (00:04:29):
Thank you so much for having me. I'm excited to be chatting.

Lenny Rachitsky (00:04:32):
So you were an early and the first marketing hire at some of the most iconic companies in the world. What I want to do with our chat today is basically go through a lot of these companies that you've worked at and see what lessons we can extract about your time leading marketing at these companies. And I want to start with OpenAI. No big deal. You were the first marketing hire at OpenAI. Things seem to have gone really well over there. I believe ChatGPT is the fastest-growing product in history. Does that resonate?

Krithika Shankarraman (00:05:03):
It does. Not that I can take credit for it.

Lenny Rachitsky (00:05:05):
Well, we'll talk about that. Either way, nice job. Let me ask you this. A lot of people might be hearing like, "Oh, ChatGPT." It's like, why do you need marketing? It's like the most magical thing in the history of the world. How much value does anything add to making it as successful? Can you just talk about just the value that a marketing person adds to a product like that that's already incredible?

Krithika Shankarraman (00:05:25):
Yeah. When you think about all of the different stages of the funnel, awareness was clearly not the problem that ChatGPT or OpenAI had. Everyone knew of ChatGPT, but when you clicked one zoom level further, the thing that came up was, "I don't know what to use it for. I don't know what it replaces. Should I be using search for this? Should I be using ChatGPT for this? How can it even help me?" And so the work of marketing ended up becoming, creating this sort of use case epiphany where people could say, "I had no idea ChatGPT can do that. And yeah, maybe I should be using it for X, Y, Z reason in my own life." And so I think you have to be very diagnostic in terms of what can marketing be doing to help, rather than just going off of the typical top of funnel, and then middle of funnel and conversion-oriented tactics that end up being in a playbook.

Lenny Rachitsky (00:06:14):
So for folks that listen to this podcast, it's a lot of product managers, product builders. A lot of them don't have a lot of experience with marketing. I think it's an important insight there of just, this is a thing marketing can help you with is helping people understand how to use your product, understand use cases, understand examples, things like that. So I think as we go through this, I think this is useful for folks to understand of, here's what you may not be good at and may need marketing help with.

Krithika Shankarraman (00:06:38):
Yeah. When done right, product management and product marketing should be best friends, right? And you are working together at every stage of product development. Rather than thinking of it as a handoff at the end of the conveyor belt when the product's been built, you sort of hand it off to marketing to take it out the door. If you can think of it as sort of a three-legged race from the very beginning of product development, then you go to market with the right thing in the first place. You get these insights from customers, you hear the language that they're using, which can be the sort of cheat code for how to message and position the product in market. And of course, there's a creativity angle on how to differentiate your product in the market, but ideally, you're doing that in lockstep with the product management side.

Lenny Rachitsky (00:07:18):
The other element of ChatGPT's marketing success, I know that you spent a lot of time on the enterprise side, is just consumerish marketing tactics for enterprisey products. Can you just talk about that? And it feels like that's emerging more and more just like consumer tactics for enterprise products.

Krithika Shankarraman (00:07:35):
In typical organizations that I've been a part of and leading marketing for, the enterprise side of the house, the B2B side of the house usually fits the mold of demand generation where you're creating demand for the sales team and you're bringing new customers and prospects into the fold and into the orbit of the company. That again, was not the problem at OpenAI. When we turned on the contact sales form for ChatGPT Enterprise, which was one of my first launches at the company, our lead volume 40 X-ed overnight. It was unanticipated even beyond our wildest expectations. And so some of the things that I had to do are not typical to marketing at all. I sat down with ChatGPT and I coded up a Python script that ended up functioning as our first lead qualification, lead-scoring model. That was used in production for way too long, longer than I'd care to admit.

Lenny Rachitsky (00:08:25):
It's so funny. I think about when ChatGPT first launched and OpenAI just launched, everyone was just like, "How will you make money? How do you make money with something like this chatbot that's pretty smart, but sort of not that smart?" I remember there's a video of Sam Altman being asked, "How do you make money with something like this?" And I don't know if you just saw this, he just like, "At some point we will ask ChatGPT, how do we make money?"

Krithika Shankarraman (00:08:47):
Yes. And I think the reality is it's not a solved problem. And a lot of folks, a lot of companies in the AI domain are trying to figure out the right pricing model. And it's something that you've talked about in your newsletter and so on, but there is a value creation aspect to using AI that doesn't kind of neatly fit the mold of SaaS-based pricing or seed-based pricing, or even usage-based pricing. So, I think there are still some frontiers to figuring out where is the value, how do different types of organizations and companies and consumers find value? And again, it's not the typical sort of KPIs that you would typically try to optimize and maximize.

Lenny Rachitsky (00:09:27):
I will say, though, in terms of pricing, it feels like ChatGP, it works. It's just like a monthly fee, talk to it up to a certain limit. It's wild to think back now, there was a sense, "We don't have no idea how will this make money." Now it seems so obvious.

Krithika Shankarraman (00:09:41):
Truly was a research preview.

Lenny Rachitsky (00:09:44):
And I remember Sam Altman just launched, "Here, check out this chat thing that we are trying with," and then the fastest product growth in history. No big deal. I want to come back to this point you made about this playbook, anti-playbook kind of a thinking. You kind of pointed out that with ChatGPT and OpenAI, there was no playbook, and you find that often people following playbooks don't work. Talk about that insight.

Krithika Shankarraman (00:10:08):
In my current role in my career, I've spoken with a lot of founders, and typically, the founders reach out because I've worked at companies that they look up to and they're looking for that playbook. They're looking for, "Hey, just tell me how Stripe did it. Tell me how Retool did it. Tell me how OpenAI did it." And I really hesitate to share any such detail because there was a combination of context, competitive landscape, and the overall sort of zeitgeist of when the company's operating, how the company's operating, that really adds a lot of nuance to what works in the market.

(00:10:43):
And so doing the same things, like if you're just kind of copying the outcomes or the outputs of the strategy and trying to follow in the footsteps of the tactics, you're not paying enough attention to the inputs and, what were the variables and the deciding factors which led to that strategy in the first place? So what I like to do is try to unpack more of a framework for how do you get to become more of a diagnostician to understand the right strategy or tactic in the first place, rather than saying, "How do you copy something that led someone else to success?" Because those criteria may not apply to you at all.

Lenny Rachitsky (00:11:17):
So let's follow that thread because everyone's like, "Goddamn, I need a play. Just tell me how to do this." Okay, so there's no playbooks that you... If your advice is, "Don't just copy what other companies do that have done well," what should people be doing? How do they approach figuring out how to market their product and help it grow faster?

Krithika Shankarraman (00:11:35):
Yeah. So I was an engineer before I became a marketer, and so I have brought a little bit of an engineer's framework to the marketing side of the house. And so something that I've tried to do is put together a four-step process that has served me pretty well. The first step here is diagnosing. So, diagnosing the actual problem. Again, this usually means taking a zoom back when a founder comes and asks, "Hey, we really need to hire a demand gen leader. Who do you know in your network that we should be thinking about?" And I'm like, "Let's talk about your funnel. Do you have a lot of people coming in at the top of the funnel? And when they do come in at the top of the funnel and you start talking to them and having a sales conversation, how likely is it that you close them? How likely is it that you win that deal?"

(00:12:20):
That usually tells you very astutely, do you have product market fit? Once you're already in the room and people are converting, you have found that problem statement that is critical to them that is hurting them the most, and your solution is resonating as a solve to that problem. And so that means yes, probably throwing in more at the top of the funnel is a very good move to make at that time. But on the other hand, if you say, "Yeah. I mean, we get a lot of interest, but once they're in the room, they have a bunch of questions. They're asking about, how do you compare to X competitor and Y competitor? And why does it cost so much?" and et cetera, et cetera.

(00:12:59):
That probably means that there's more to be done in the product market fit zone rather than throwing in more at the top of the funnel because you have a leaky funnel at the bottom. And so hiring a demand generator may be the worst thing that you can do versus thinking about more of a product marketer who's thinking about the competitive differentiation, the positioning, the sales enablement that gets more people through at the bottom. So that's that diagnostic step at the top.

(00:13:24):
Second to me is analyzing your competitors' approaches. So to me, this is not about being super laser focused on your competition because that leads to these local maxima rather than thinking about face shift changes and breakthroughs that you can make as a company. But when you analyze your competitors' approaches, evaluating what others do in the space can kind of give you a useful baseline and identify opportunities and gaps and niches that your company can take in instead.

(00:13:51):
And then, this is the critical step. The next one is you have to intentionally take a different path than what everyone else is doing. And so driving a strategy that sort of sets the company apart is really critically important. I think it's so core to the discipline of marketing, ensuring that differentiation in the market. And you don't have to go into a cave to come up with these ideas and strategies. You can usually go and look at domains that are far outside of your own rather than your direct competitors and come up with some great ideas that you can cross apply and bring in and steal into your own domain or vertical instead.

(00:14:28):
And then the final piece is just experiment, test, validate all of that, and then scale what works and kind of discard what doesn't. So you really have to have a lot of that ability to throw away work when you might have spent a ton of calories on this wonderful piece of content. But if it's not working, don't double down on it. That bias of the sunk cause fallacy really comes into play, especially when you've poured your heart and soul into creating artifacts for marketing. So experiment, test, validate. Give people that psychological safety to fail, especially your teams and organizations. And then, yeah, once you find what works, really double down on it.

Lenny Rachitsky (00:15:06):
Let me summarize what you just shared here. So essentially if you think you're like, "I need help with marketing," or, "I have a problem and I think I need to hire a demand gen person or a paid growth person or a SEO person, or I don't know, content writer," something like that, before you do that, first of all, go through these four steps.

(00:15:24):
So step one is diagnose. Spend time understanding what's the specific problem you want to solve, then analyze. This is so interesting, I've never heard it this way. So then it's analyze what your competition is doing so that you can then, one, find inspiration and see where gaps exist. And then it sounds like the core part of it is just make sure you differentiate and choose a different path versus just try to be the better thing or the cheaper thing. And then the final piece is just like, "Okay, here's our path. Let's test run some small scale tests to see if this would work."

Krithika Shankarraman (00:15:54):
Yeah. I'm a marketer through and through now. So I mean you got diagnose, D. Analyze, A. Take a different path, T. And experiment for the E. So it's the DATE framework. I've just kind of coined it.

Lenny Rachitsky (00:16:05):
Oh, beautiful. Okay. We got a new framework hot off the presses. I love it. DATE, okay. So with differentiation, what's your thoughts on saying you're just a lot better or a lot cheaper?

Krithika Shankarraman (00:16:19):
Being cheaper is a race to the bottom, especially when you think about sort of scaling laws and how things are playing out. Every company is sort of becoming an AI company at this time. And so as models get cheaper and more capable, being cheaper is not going to be the thing that really is a durable approach in the market. And I think in terms of doing things differently, it's not just for the sake of it. I think it's really that novelty and that differentiation is something that people are craving for. They're not looking for yet another tool in the market. They are looking for something that aligns with their values, aligns with what their goals are. And so if you can be really crisp on understanding the user need, understanding what is the problem space in which they're operating, I think that one-two punch of a fantastic product experience, and then the marketing experience to match, can be a superpower for your company.

Lenny Rachitsky (00:17:11):
Awesome. Okay. So let's go through an example of a company you did this with, and then this may take us to another company you worked at in the stories there.

Krithika Shankarraman (00:17:19):
Yeah. One that comes to mind is definitely Retool. Retool was very different from both my experiences at Stripe and at OpenAI because both Stripe and OpenAI, for better or for worse, were inbound companies, right? There was so much latent demand that we were fighting off people breaking down the door trying to get to our products. With Retool, marketing was between the company and revenue. And we had fantastic product market fit with the enterprise space, with the developer community, but awareness was a challenge. And so how do we go out, not just wait inside of our house waiting for people to knock down the door, but rather step outside of our house and start introducing ourselves to the neighborhood?

(00:17:57):
So, thinking about outbound channels and building demand engines was the name of the game. And here, one of the ways to think about that is, "Hey, should we just scale the paid marketing channels that we already have working for us?" And that's when the diagnostic really came into play, which is, what are the leads that are coming through the funnel? Are they turning into sales-qualified opportunities? What kind of pipeline are they driving? A lot of marketing metrics, again, tend to be vanity metrics. They tend to be about the number of clicks that you got, number of views that a tweet got, number of impressions. I think those are all bullshit numbers.

(00:18:35):
Really, what you want to be looking at is your impact on either signups if you're a self-serve product, PLG, or in terms of a B2B company, sales leads and revenue that you're driving, pipeline and opportunity that you're driving. So we diagnosed that and we found that for the most part, our paid social channels were doing not much for us. And so we had to invest in net new engines. So that was the diagnostic. When we looked at some of the competitors, we saw that they were doing a lot of content marketing. They were doing a lot of events programming. And we could've kind of followed in those footsteps, but there was the ability to take a different path.

(00:19:13):
And so what we decided to do was double down on customer marketing and customer storytelling because the thing that differentiated Retool from a lot of the copycat competitors in the market was that we had terrific traction with true enterprises who were paying for the product, who believed in the product, who were expanding within the product. And so having them tell the stories on our behalf was so much more compelling, and no other company could replicate the kind of customers that Retool had in its bench. So, we wanted to make sure that we were using those logos, we were using those companies to the best impact possible, and then we experimented. We tried to put together webinars, different types of sales dinners, different types of event formats to see what actually worked best for us, and scaled the ones that worked and discarded the ones that didn't.

Lenny Rachitsky (00:20:02):
Okay, there's so much here. So in the diagnose step, I think in kind of a between-the-lines piece of advice here is look at what's already working. So you looked at, okay, maybe paid growth, maybe this, maybe that. And then it's like, "Okay, what seems to be working is people find us through maybe another logo, another customer that's fancy, and they're like, 'Oh, Netflix is using Retool. Oh, maybe I should check it out.'" So I think that's a really important lesson there is don't try to like, "Hey, we need to start expanding our top of funnel to all these different channels." There's one more-

Krithika Shankarraman (00:20:32):
And really litigate some of those channels, too, because on the surface they might be working, but are they actually driving pipeline and revenue?

Lenny Rachitsky (00:20:38):
Got it. So they may be showing vanity metrics. Numbers are nice at the top, but they're not sales qualified potential. They don't actually stick around. Okay. And then, the analyze competition is really interesting. So again, it's just like, "What are they doing? What can we be doing differently?" Does it ever make sense just to do what they're doing but do it better, or is that rarely a successful path?

Krithika Shankarraman (00:20:58):
You still have to do something a little bit different. I recall a very specific example at Stripe where our product, Stripe Connect, which was made for marketplaces like Uber and Airbnb, where not only are you accepting money as a platform, you're also paying out people on the seller side of the marketplace. The competition truly was to become a payment facilitator. So rather than using another off-the-shelf service, instead of using Stripe Connect, you might go off and become a PayFac yourself. And a lot of the services, organizations, the consulting groups that were helping companies become PayFacs, the things that they were doing was really leaning into that old school terminology, the jargon of the legacy systems and so on and so forth.

(00:21:43):
And Stripe kind of figured out, "Hey, we need to rank higher for the SEO terms that people are searching for. So how do we help rank for PayFac without actually talking about ourselves as a PayFac solution?" So we decided to kind of do a reverse RFP system where we created a piece of content that said, "Hey, if you want to be a payment facilitator, here's the secret playbook. Here's all the things that you have to do. And by the way, if this feels onerous or annoying, it is, and you should use Stripe Connect instead." So there was still a little bit of a zigging where others were zagging. Yeah, but I think if we had done the same thing in terms of becoming a consulting service to become a payment facilitator, Connect would be nowhere near the sort of run rate or revenue that it drives for the company.

Lenny Rachitsky (00:22:29):
Okay. And this is a great segue to Stripe, which, another company you were the very first marketing hire at. You were also, I believe, the only marketing person for three years at Stripe.

Krithika Shankarraman (00:22:38):
I do not recommend that to anybody.

Lenny Rachitsky (00:22:41):
There's a lesson there. Okay, so let's talk about Stripe. What are some of the biggest things you learned marketing at Stripe that you think might be helpful to other marketing people and founders?

Krithika Shankarraman (00:22:51):
Oh, man, there are so many things to choose from because I was Stripe for almost eight and a half years. Joining as the company's first marketing hire, building that marketing function from the ground up, it really gave me the privilege of working very closely with our founders, John and Patrick. I would say actually I was not the first marketer at Stripe, John and Patrick were the first marketers at Stripe because they were developers themselves. They truly understood the developer community. And when that audience for Stripe was squarely developers to begin with, they knew exactly how to authentically reach that audience.

(00:23:24):
And so I had to unlearn a lot of the things that I had learned at Google and Dropbox coming into Stripe in order to reach developers authentically. The experience really taught me the importance of deep product understanding as well. You couldn't really play act at understanding the product, especially when developers are trained to spot bugs, right? So not only do they spot those bugs in code, they spot those bugs in marketing and in blog posts.

(00:23:51):
And so if the marketing pieces are your first impression of the product, they're an extension of the product itself, you have to hold yourself to a very high bar in terms of how you communicate about the product. And so we did a lot of investment in design work, in polish in terms of how the marketing came together. And yeah, the value of creating marketing artifacts that were deeply integrated with the company's mission and the craftsmanship that went into the product was another lesson that I learned very deeply at Stripe.

Lenny Rachitsky (00:24:23):
So kind of along those lines, again, people may look at Stripe and be like, "Okay, it's the best thing ever for payments. Why do we need marketing? It's just like, engineers build it and integrate, it works." What is it that marketing most adds to a product like Stripe?

Krithika Shankarraman (00:24:40):
Across my time at Stripe, marketings are very different purposes. And so I kind of see it in different epochs or chapters of my time at the company. The first chapter when I joined, our head of partnerships at the time, Cristina Cordova, handed me a Hackpad at the time, which is like a notion-

Lenny Rachitsky (00:24:59):
I remember Hackpad.

Krithika Shankarraman (00:25:00):
Oh, yeah.

Lenny Rachitsky (00:25:00):
It turned into Dropbox Paper.

Krithika Shankarraman (00:25:02):
That's right. And so she had kept a Hackpad, a secret Hackpad away from the engineering team, which was all of the features and products that we had shipped but had never communicated to our customers about. And so the launch sort of ended with shipping the feature rather than communicating with the user. So the first chapter at Stripe was really just getting through that backlog and making sure that the ethos at the company changed to say, "Hey, your launch isn't complete if you're just code complete. You have to actually ship it to the customer and make them aware of it." So usage became the north star, engagement became the north star rather than just the binary, has it launched or not?

(00:25:41):
The second chapter at Stripe was really starting to expand what a launch meant, right? So, going from just putting out a blog post for people who were already subscribed to the RSS feed of the company versus thinking through, "Hey, how do we reach out to them through an email, through other channels? How do we really invest in this fanatical community that is getting so excited about the product experience?" So we pulled together developer experience as a function, built out developer relations to really have that community feeling and vibe.

(00:26:13):
And then it was about starting to think through the multi-product ecosystem. So Stripe went from a single-threaded payments processing company to one that had multiple different products and features for the audience and the user base. So then the work of marketing became, how do you help people understand and navigate potentially this multi-product ecosystem and platform to figure out what's the right set of features and solutions that they should be using for their needs?

Lenny Rachitsky (00:26:41):
And so this is, again, a good example of marketing can do a lot of different things and depends on the stage, depends on the needs. It almost starts again with diagnose. Where do we have a need for marketing and growth?

Krithika Shankarraman (00:26:53):
And especially in hyper-growth companies, I think you have to run that diagnostic every three months, every six months in order to stay adaptable and flexible because those top level goals do change. At some point, we really have to figure out how to scale our sales function. We have to figure out how to scale internationally. And so being adaptable to that meant constant reprioritization and making sure that you were also hiring people who weren't super deep in particular disciplines, but having a team structure that was T-shaped, people who could be flexible to those needs of the company.

Lenny Rachitsky (00:27:24):
Coming back to your point about how there's no playbooks, is Stripe another example where it's like, this has never been done before, we shouldn't copy what other payments companies have done in the past?

Krithika Shankarraman (00:27:34):
Yeah. If we did, we would still be talking about PCI compliance and payment gateways.

Lenny Rachitsky (00:27:40):
There's so much of what you share that reminds me of Raaz from Wiz, who also, you were an engineer originally, she was a product person. Yeah, I think. I don't know if she was an engineer, but a product person. So it's your-

Krithika Shankarraman (00:27:52):
Her first PM, actually. Yeah, Raaz is great.

Lenny Rachitsky (00:27:54):
Okay. And I think there's a few things that are so interesting here. One is you both have non-marketing backgrounds, you went from another function. And I think, you tell me, it gives you a whole new perspective on marketing, not just the traditional education of marketing. Is there anything there?

Krithika Shankarraman (00:28:09):
One thing it's definitely made me is very skeptical of most marketing channels and strategies and tactics. And so I would be one of the first people to say, "Is that really going to work? What developer is clicking on paid ads? Isn't a better thing that we could be doing for them telling them to install ad block?" So I think that skepticism means that you just have a higher bar for the quality of the content, the substance of the content. You want to make sure that the marketing is as substantive and as crafted as the product experience itself.

Lenny Rachitsky (00:28:40):
The other really interesting corollary here is she was very big on avoiding the generic acronyms and classic industry norms, I forget what they were, for cloud security. But it's just like, "We're not this thing. We're Wiz. Here's what we do."

Krithika Shankarraman (00:28:53):
They are definitely a company that zags when others zig. I still have my Wiz socks, which have these beautiful 8-bit characters on them. Their branding really stands out in the sea of sameness in SaaS conferences.

Lenny Rachitsky (00:29:05):
Okay. There's something I heard that you did at Stripe that I wanted to ask you about that worked really well. When you came into Stripe, you looked at all of the biggest customer support issues and you turned those into docs to help people serve themselves. Can you just talk about that insight and the power of doing something like that?

Krithika Shankarraman (00:29:22):
Yeah, and this was a great practice that existed at Stripe even before I joined, which is all new hires would do a support rotation just to build empathy with our customers. So, users first was a very core operating principle for the company, and we spent about 20% of our time collectively talking to customers, talking to users, talking to non-users to understand their needs, their gripes about the product. And that tradition, I think, continues to today. The support rotation specifically was such a fantastic fountain of understanding, "Hey, these are the areas that people are confused about."

(00:29:54):
Again, I kind of mentioned this sort of cheat code of talking to your customers and using the language that they use to describe their problems as a shortcut to fantastic product marketing and messaging, because it really tells you what are their pain points and how can you meet them where they are. You want them nodding their heads along as they're reading your landing pages. And so when I was doing the support rotation, there were thematic things that kept coming up. People were asking, "Hey, do you process subscription payments or recurring payments?" Or, "Can I pay people out with Stripe?" And I was like, "Of course you could, but there's no reason you should know that because we don't tell you anywhere."

(00:30:30):
And so that ended up being a stacked rank backlog of landing pages that we produce that just educated people. And this is really important when you have strong top of funnel demand, and potentially not as many people and you're not trying to scale your teams linearly. Having those educational resources, especially for developers, a fantastic marketing funnel sometimes doesn't look like talking to sales. It often never looks like talking to sales. It looks like a self-directed educational experience. Even the sales process ends up being very consultative typically with very technical folks on the other side. So yeah, that was a great way and a great program to figure out what content we should focus and prioritize.

Lenny Rachitsky (00:31:12):
These are really cool just little ways as a new marketing person. You can add value really quickly is kind of what I'm taking away.

Krithika Shankarraman (00:31:21):
Talking to customers is at the top of the list.

Lenny Rachitsky (00:31:24):
Today's episode is brought to you by LinkedIn Ads. One of the hardest and also most important parts of B2B marketing is reaching the right people. I'm constantly getting ads for products that I will never buy, and I almost feel sorry for the money that these companies are spending pitching me on their spend management software or some kind of cybersecurity solution that my one man business just does not need. When you're ready to reach the right professionals, use LinkedIn Ads. LinkedIn has grown to a network of over 1 billion professionals, including 130 million decision makers, and that's where it stands apart from other ad platforms. You can target your ad buyers by job title, industry, company, role, seniority, skills, even company revenue.

(00:32:08):
All the professionals that you need to reach in one place. Stop wasting budget on the wrong audience and start targeting the right professionals only on LinkedIn Ads. LinkedIn will even give you $100 credit on your next campaign so that you can try it for yourself. Just go to linkedin.com/podlenny. That's linkedin.com/podlenny. Terms and conditions apply. Only on LinkedIn Ads.

(00:32:32):
There's something else that I know that you're a big advocate of which is internal reviews and just making sure everyone's aligned, which I think a lot of people and especially startups try to avoid. Like, "Let's just move fast. We don't need to have all these meetings where people review stuff," but I know you're a big advocate of that. Talk about why that's so important.

Krithika Shankarraman (00:32:48):
Yeah, this is a hill that I would die on, which is that good process or sufficient process is actually something that speeds up a company rather than slow it down. It stems from this idea that we talked about a little bit, which is that marketing is an extension of your product. It's the first touchpoint your customers have with your product. And ideally, you're setting expectations there in terms of what they should expect once they sign up for the product or commit to a contract and start using it within their companies. And when I think about that, consistency is really, really important.

(00:33:20):
The other part, the other facet of why process is important is because especially as you're in hyper-growth companies, scaling teams is part and parcel like what you're trying to do. And when you bring in someone new, you want them to be just as self-sufficient as somebody who's been at the company for two years. So in your second week, can you be as successful as someone who's been at the company for two years? And the reason that I have that principle in mind is because it makes you kind of break out of your shell of, "I've been at this company for some time now. I understand the sort of unspoken rules of the organization. I've built up enough social capital that I can withdraw from to get something done. And I know which conference room to stand outside of to get the founder to review a piece of content before it goes out the door."

(00:34:09):
That is not scalable, that is not sustainable. And so if you want somebody to be successful and contributing member of the organization very, very quickly, setting up some of these processes with the intention of trying to help them navigate how to go from idea to execution can be very empowering and powerful. Nobody wants to do the wrong thing. They want the guardrails to understand what great looks like at the company.

Lenny Rachitsky (00:34:33):
Can you speak more about what this looks like? Say a startup wants to start implementing something like this.

Krithika Shankarraman (00:34:38):
Two simple processes that you could put into place today is, one, set up a forum called Marketing Review. This can be a live meeting that you host for an hour a week or it can be a Slack channel where people are posting things async, or even an email alias where things get sent to. Have that be transparent to the rest of the organization so anyone in the marketing team, anyone in the product organization can join that forum. What that does is it creates a fishbowl where you see sort of, what are the themes that come out when somebody reviews a piece of content? Are they looking at the strategy? Are they looking at the audience? Are they looking at the words? Are they looking at the sort of design approach? So you learn through osmosis of looking at some of these discussions.

(00:35:20):
And then I would say don't overdo it. I would say there are probably two checkpoints in a program that are really important to get aligned at. One is the 20% review. A 20% review is a strategy review. What are we trying to accomplish? Who are we trying to do it for, and what is the rough approach that we're going to take? If everyone feels comfortable with that, you come back at the 80% mark where you've done a lot of the work on the artifacts, the different types of teams that have to be involved and how do you take something to market it in the first place.

(00:35:49):
And the reason that I say 80% is sort of critical because if you come in at the 99% mark and you're just looking for a rubber stamp of approval, and you don't really have the slack in the system to be able to make any changes, then that review was worthless. So come in at the 80% mark where you can still make some substantive changes before it goes out the door. And that serves the purpose of consistency so that your brand is showing up in a consistent way to the audience. And two, it helps the rest of the organization learn from each other.

Lenny Rachitsky (00:36:19):
There's almost this unspoken element of what you're describing that I want to dig into a little bit, which is the need and value of having consistent and high quality marketing, communication. Why is that important? There's always this talk of just move fast break things. "We're going to be scrappy. We're not going to be obsessed with perfect quality of our, I don't know, websites and emails." Just, why is that important? Why do you value that? Why should companies maybe value that more?

Krithika Shankarraman (00:36:45):
It's funny because with the companies who value velocity actually do value their brand just as much, but oftentimes they think of these as two siloed separate initiatives that they have to put their headspace and calories towards. And I actually think they are not mutually exclusive. They are actually very interconnected. And so when you understand the consistency of your brand, it actually empowers the organization to move faster because you kind of understand how you want the brand to show up in the world. What is that experience that you want your customers to come away with when they interact with your brand?

(00:37:25):
And the brand is not just marketing artifacts, it is your product experience. It is how your customer support team talks to them, how they resolve tickets. Are you getting passed between a bunch of different teams or is someone just resolving your ticket right away? It's the experience that they have for candidates when they come to recruit your company. So all of these variety of touch points that touch so many different organizations and teams within your organization, they are the amalgamation that makes up your brand. And so if you think of these two things as separate silos, you are optimizing for entirely the wrong thing.

Lenny Rachitsky (00:38:02):
I've very viscerally learned the power of brand doing my newsletter. I so fear doing something very wrong in my newsletter. It's like, saying something that's completely off or having something broken, or sending an email by accident to everyone that's not ready. I just feel like once I break that, just there's so much power and trust that people have built for what I share and there's so much power that comes from that trust. If I launch a new podcast, people will assume it will be good if they trust what I do and I maintain high quality. And so it's just like a constant fear I have now of breaking that trust.

Krithika Shankarraman (00:38:40):
Yeah, I mean whether it's fear that drives you is questionable because I think it's also a commitment to your craft.

Lenny Rachitsky (00:38:51):
Yeah, yeah.

Krithika Shankarraman (00:38:51):
But I think that's exactly right. A brand is an expectation that you create within your audience.

Lenny Rachitsky (00:38:57):
And to what you said, if you have a strong brand that people trust, everything gets easier. You pitch them a new product. Like if Stripes like, "Oh, we have a new billing service."

(00:39:08):
"Oh. Oh, I bet it'll be awesome because it's Stripe." Or if OpenAI launches something. So it just makes life easier if your brand is strong, if there's trust.

Krithika Shankarraman (00:39:17):
Yeah, and you got to take that responsibility seriously because even with something like Stripe, we know that people are going to come try out things that we put out the door. And so we wanted to make sure that that met up to people's expectations. And same thing with OpenAI. When we launched something, even though we were trying to be first to market and that velocity was so important for the company, oftentimes it also came with sometimes putting the brakes on to kind of understand, how can we improve the quality of the experience? How can we make sure that it is safe? So there were different criteria at the two companies, but a similar ethos overall for the brand experience that we wanted people to experience.

Lenny Rachitsky (00:39:55):
Let's actually come back to OpenAI. How long were they around before you joined? It was like many, many years, right?

Krithika Shankarraman (00:40:01):
Many, many years. So OpenAI had been around for almost a decade as primarily a research organization. They had launched ChatGPT about a year before I joined. And so that was the first foray into saying, "Hey, our work is not just announcing research breakthroughs, it is about putting products into the market."

Lenny Rachitsky (00:40:19):
So there's a few questions I want to ask here. When is a time to bring in a Krithika? When is it like, "Okay, we need help here"? Or, "A bunch of smart people doing great work, people have the product, but I think we need a marketing person that knows what they're doing."

Krithika Shankarraman (00:40:33):
I think the first criteria is having tremendous product market fit, which is really important because you're throwing fuel on the fire, and you might be throwing different types of fuel on your particular fire. So one pillar for marketing that you have to think about is product marketing. So, if you have a high velocity engineering organization and product organization that is putting out a lot of different features and your customers aren't able to keep track, maybe the engagement's not so high for some of the newer features versus some of the core features that you had in the past, a product marketer can really help bring a discipline of launch excellence and customer engagement, differentiation in the market. How are you positioning the product?

(00:41:15):
The second pillar for me is demand generation. So if you have much more of a sales driven buyer journey in motion, how are you bringing the demand engines to bear so that your lead generation, your pipeline generation is staying really strong and solid? Or you might want to think about brand, right? You might want to think about community development as a big part of what you're doing as a company. So it really depends, but I think in all of these, you found a spark of product market fit before you're really going for it.

(00:41:43):
The second for me is that you're distinguishing enough between capital and marketing and lowercase and marketing. And there's an important distinction I've learned over the years, which is capital and marketing, the marketing team, the marketing function at the company is responsible for those channels and artifacts and engines that are driving the funnel for the company, but they are not the end all be all of the discipline of marketing.

(00:42:08):
And that's where the lowercase and marketing comes in, which is, what do you stand for as a company? What is the storyline that you're telling as a founder when you're talking to the press, to the larger business community? And then it really is a whole company motion where the product team is thinking about, "How are we going to market? What are we going to market with?" The sales team is figuring out, "What is the right ICP, the right customer profile that decision makers, that we need to be reaching?" And then it is this entire joining of the organizations to make that happen really effectively.

Lenny Rachitsky (00:42:47):
Yeah. I think along these lines, there's a reason Brian at Airbnb merged marketing, or product marketing and product management. However much of that actually happened or not, but the intention-

Krithika Shankarraman (00:42:58):
I would be so curious to see a follow-up a few years on on how that's been going.

Lenny Rachitsky (00:43:01):
Yeah. Okay, let's have Brian back to talk about that. That'd be really interesting. I wanted to actually ask, an interesting thing is happening with ChatGPT versus Claude, and it's so interesting. Claude is arguably better at many things at code, at least at this point. Things are always changing. It seems to be a better writer in a lot of ways. People prefer it for writing, but it's just like ChatGPT is just dominating. It's like, that's what people associate with AI now is just ChatGPT. It's just caught mindshare globally. What is it, do you think, that allowed ChatGPT just to be that? Is it just first mover advantage? Is it some kind of other element? Has it been better longer? Something really interesting is going on there.

Krithika Shankarraman (00:43:46):
One of the things that comes to mind is the orientation when it comes to large language models, and AI in general, is that we're just at the very beginning innings of this whole paradigm shift. And so every single week there is a new breakthrough in AI that comes out from some lab or the other. There's this one-upmanship on point changes and eval numbers and so on and so forth. But I think to customers, the users of the product, the things that make it delightful are the same things that make any product delightful. And there's a sense of loyalty that builds up over time when there is a shorter and smaller delta between your expectations and your reality.

(00:44:30):
And where those expectations are exceeded, it is accretive to the brand and your loyalty to the product. And where there is a negative delta, that tends to be something that it really detracts. I guess, long story short, what I'm trying to say is that all of these companies have to think in a much more long-term oriented fashion because it's not about a race of the best chatbot and the best outputs. It's about, how does AI become a positive force for humanity?

(00:44:58):
And so that's going to take a lot of change management and a lot of collaboration between a variety of different organizations rather than just the companies themselves and the product experience itself, because it's going to permeate every aspect of our lives. Our personal lives, our academic lives, our work lives. And so to make that transformation happen, my hope is these companies are not super focused on just their competition and one-upmanship, but rather thinking about the paradigm changes that need to happen for our society at large.

Lenny Rachitsky (00:45:31):
It does feel like they are taking that responsibility really seriously, but it is a massive responsibility. Before we leave OpenAI, it feels like it may be the most impactful, important company in the world right now just because they seem to be at the furthest edge of where AI is going. And so it's just such an interesting place to study. So let me ask you this. Just as a person working there, what's something people may not know that's a wonderful, positive element of how open AI works that's just like, "Oh, that's super interesting"? And then, what was maybe a challenge of working at OpenAI?

Krithika Shankarraman (00:46:08):
A surprising thing that surprised me at the company was just the warmth and intellectual curiosity of my peers and leaders at the company. And truly, the sort of commitment to the mission of making artificial intelligence that benefits all of humanity was not just lip service. It was something that was embodied day to day. The sort of questioning that happened, the sort of pressure testing that happened, the rigor with which products were developed, go-to market strategies were developed, was bar none.

(00:46:38):
And so that's something that I really admired, and it was a privilege to be a part of that organization. I think challenging, of course, is just being at the eye of the storm, right? The eye of the hurricane. So, all eyes are on OpenAI at all times, and I think that is a good thing because of the ramifications of the product. But it also really raised the stakes in terms of how we operated and with what scrutiny, everything that we did was looked at with.

Lenny Rachitsky (00:47:09):
Do you recommend that sort of experience for people? Because I imagine work-life balance wasn't great. I imagine there was a lot of stress and worry constantly. Who's the right... When in your career is this a sort of gig to take on versus not?

Krithika Shankarraman (00:47:25):
I'm a big believer of what Claire Hughes Johnson, who was COO at Stripe, used to share with us, which is there is a concept of a work-life blend and sort of making sure that you're working at a company that has three components. I think first and foremost is always people. So, are the people that you're surrounding yourself with ones that push your thinking, who are kind, who are genuinely interesting people to spend your hours with? Because you're spending a vast majority of your time with them.

(00:47:54):
The second to me is product, right? Do you go to sleep thinking about the product, waking up, wanting to put it into the hands of more people because you know it is going to be good for them or useful to them? I'm not one of those marketers who can pick up any product and market it. I have to have that conviction behind the product itself.

(00:48:15):
And then third is sort of potential, right? Not just potential for the company to do well, but potential for your discipline to have an impact on the trajectory of the company. And so when you have that kind of potent combination, it can really change your perspective on what's draining, what's energizing. But being very self-aware of what gives you energy is also very helpful to align with the needs of the company, also.

Lenny Rachitsky (00:48:41):
Let's shift to talking about Thrive, which is where you work now, and talk about what your role is. And what's interesting, I think, about this role is you get to work now with a bunch of different startups instead of go really deep with one. So share what you do there. And then, what are some things you've learned there so far from a perspective for marketing?

Krithika Shankarraman (00:48:59):
Yeah, surprisingly, more people know about Thrive these days than used to even just a few years ago. Thrive's a very unique type of investment company. And sometimes, when I made the leap, people used to ask me, "Oh, was this always in your ambition to make the leap into the investment side of the house?" And I can honestly say it wasn't. But I think being at a firm like Thrive really gives you a very different perspective and it strengthens your ability to be a stronger operator, whether that's in marketing or go-to market or strategic finance, or whatever other pillar within the company there is.

(00:49:32):
Yeah, Thrive's mission is to be the most meaningful partner to founders. And so there's a lot of high-concentration, high-conviction investments each year. And Thrive is also unique in that it's a network of builders, and so they are really pulling their investment strategies from having been founders themselves. So my role at the company is to help our entire portfolio with all of their marketing needs, so sometimes it means being interim CMO for some portion of time until they find a great leader to fill that seat. Sometimes it means pressure testing their strategy and making sure that their growth targets are ambitious enough. Sometimes it means looking at a Figma file for a landing page that's going out the next day and making sure the words are as good as they can be.

(00:50:14):
And that variety across a bunch of industries, a bunch of stages of companies, everything from a company that hasn't even been incorporated yet, all the way to Databricks and Stripe and OpenAI when it comes to the types of organizations that we work with. And in the end, the variety of domains can range from consumer to healthcare, to defense, to B2B SaaS, to AI. So it is a variety pack in the best way possible.

Lenny Rachitsky (00:50:43):
And so what are some things you've learned so far? Because I imagine this is a very different experience. I don't know, especially things that you've changed your mind on even, working with a bunch of companies, early stage versus, what can I say?

Krithika Shankarraman (00:50:57):
It's a really different method of operating. And so when you're in the leadership role for marketing within a single organization, you have at least a medium term north star in terms of what your teams are trying to drive for the company. And as much context switching as there might be, there is still one company, ideally one product, one buyer journey. That hasn't always been the case, especially with OpenAI and Stripe, but it can span B2C, B2B, B2D.

(00:51:27):
Thrive is very different in that if you want to be a meaningful partner to the founders, you cannot just jump from 30-minute call to 30-minute call to 30-minute call. You have to go deep to understand the context. And if anything, it's really underscored my ethos that you as a marketer, the best thing that you can bring to the table is your adaptability and flexibility. So, to really diagnose and not just try to spot patterns and themes and playbooks for these companies, but rather be very deep in the trenches with them to understand their unique context, their unique concerns, their unique characteristics, and their values and what they want to bring into the world.

(00:52:05):
The reason that they want to work with Thrive is not because we are bringing our past experiences to the table, but rather because they're trying to do something new that has never been done in the world. And so those are engagements that are the most exciting is that you are building and going into uncharted territory alongside these founders.

Lenny Rachitsky (00:52:26):
I bet they're all like, "Krithika, what is the playbook for growing this B2B SaaS company?" And you're like, "Nope."

Krithika Shankarraman (00:52:30):
And I say, "There is none."

Lenny Rachitsky (00:52:31):
Damn. But we got the framework that we talked about. Okay, I want to zoom out a little bit and talk about just career advice for marketing people, whether it's early stage or later stage. You have this concept, the chameleon CMO. Talk about that and why that's important for marketing folks to think about.

Krithika Shankarraman (00:52:48):
Yeah. The conventional wisdom for many CMOs is to be like a T-shaped marketer. And what that means is go deep in one of these pillars that we talked about, product marketing, demand marketing, brand marketing, and that kind of becomes your calling card in the world. If a company needs brand expertise, they go for this kind of flavor of CMO. Or if a company needs to really grow their pipeline or their demand gen or their consumer growth, they go for more of a demand and growth-oriented CMO. And I think this chameleon CMO concept is a bit of a novel one in that, again, I think modern marketing leaders have to be really good at a bunch of different things.

(00:53:30):
They have to be very analytical. They have to be best friends with the data science pod because they need to understand the impact of their marketing. They, of course, have to bring creativity, but it is in service to the buyer journey. It is in service to revenue goals and goals that they share with the sales team or the product team and so on, so marketing operating in a silo is no longer a real possibility. So the ability to diversify your interest, maybe going from T-shaped to comb-shaped is probably the right approach here so that you can go deeper in different domains when it is useful for the company through the diagnostic that you do.

Lenny Rachitsky (00:54:08):
That sounds very hard. I love this beneficial of the comb shape. It sounds like I have so much to learn, so many little skills to build.

Krithika Shankarraman (00:54:16):
Before AI can come in handy. Some of the most brand marketers can become very analytical with the support of a tool like ChatGPT. If your eyes glaze over when you look at giant dumps of CSVs, it's nice to have a partner that is nonjudgmental to kind of push your thinking and to help you understand the details of the data behind the brand work that you might be doing, or vice versa. If you're a very creative product marketer, a very analytical growth marketer, you can work with ChatGPT to be more of a brainstorm partner and really push your thinking on the creative side. So I think becoming a non T-shaped marketer is getting a little bit easier.

Lenny Rachitsky (00:55:00):
That's such a good point. A good segue to an AI question. Hey, we got to talk about AI. One of your former colleagues, Kevin Garcia, wanted me to ask you something. He suggested I ask you about taste and creativity in AI. So he said that you're one of the best writers that he's ever worked with. You combine technical backgrounds with creative taste. You do pottery, you should. And you're a voracious reader. And he wanted just to poke at what you think about just how taste and creativity and writing change in the era of AI.

Krithika Shankarraman (00:55:31):
I think it's going to become so much more important. First of all, I will say I am not a ChatGPT hyphen person. I was an em dasher well before it became a ChatGPT thing.

Lenny Rachitsky (00:55:41):
Me too. Me too. I hate that. But just for people don't know, people are filtering out em dashes, right? Because they think ChatGPT is the only thing using em dashes?

Krithika Shankarraman (00:55:49):
Yeah, and I don't know what to do about it because this is such a core part of my identity, but-

Lenny Rachitsky (00:55:55):
That's a big statement, the em dash.

Krithika Shankarraman (00:55:58):
To take a step back though, I think if anything, taste is going to become a distinguishing factor in the age of AI because there's going to be so much drivel that is generated by AI, can be generated by AI, that power is at anyone's fingertips. But truly, the companies that are going to distinguish themselves are the ones that show their craft. That they show their true understanding of the product, the true understanding of their customer, and connect the two in meaningful ways. If they can use AI to augment their efforts to make that happen, that's better than them subsuming their efforts. So to build taste, there's plenty of past episodes that you yourself have recorded that get into building that work. But to me, that is going to be a real differentiator for not only great marketers but great companies to stand out in the field.

Lenny Rachitsky (00:56:50):
There's a concept that I love that recently I learned from Guillermo at Vercel. He calls it exposure hours. That's when I asked him how to build taste, and that's kind of a value they have at their company is just increase your exposure hours to great stuff, because that is how you build taste. I love that. It's such a simple actionable thing you can do.

Krithika Shankarraman (00:57:09):
Yeah.

Lenny Rachitsky (00:57:09):
Yeah.

Krithika Shankarraman (00:57:10):
And at Thrive, we have this share channel, which is just sharing things that we're seeing out into the world. It's not particularly deal flow news or competitive news or anything like that, but it is things that we have seen that resonated with us for whatever reason.

Lenny Rachitsky (00:57:24):
Along these lines of not over-relying on ChatGPT, AI tools for writing and creativity, it feels like there's going to be a big issue with people just starting early in their career where they just never learn how to do the thing, and they just rely really heavily on ChatGPT and tools like that to write, to email, to communicate well. I guess, do you have any advice for folks that are early career, just how to find that balance of not over-relying but still leveraging these tools?

Krithika Shankarraman (00:57:53):
I think there's two schools of thought here. One is that sort of the domain, the discipline itself stays static and the way that you approach it changes over time, whether you're going at it in a manual way or an automated way or an AI augmented way. But I think the other school of thought, which I more believe in, is that the discipline itself is changing. And so what it means to market a product, what it means to show up as a fantastic operator is in and itself changing. So if you're not leveraging some of these tools, you will be putting yourself at a disadvantage. But understanding the underlying mechanics, this is why I would still be a very firm believer in STEM education, is that you understand the fundamental concepts. And then you can have a choice and optionality in how you decide to apply those concepts, but the concepts themselves have to be there in the foundations.

Lenny Rachitsky (00:58:46):
Yeah. Easier said than done because there's all these tools now and you're just like, "Hey, I need to write a report for school. I guess I could just, maybe this time I'll just ask ChatGPT to help me with this one."

Krithika Shankarraman (00:58:56):
Yeah, the mindset of learning has to be maybe the one that we have to really imbue as a value. Because being of that growth mindset, if you go to school just to earn the grades or to finish the coursework, it's a very different mindset than if you go to school to learn those concepts and to understand how to apply them.

Lenny Rachitsky (00:59:20):
That's something that stuck with me from my chat with Toby Lutke from Shopify. We were chatting about just what is the most important things to incubate in your child? And his answer I loved, which is just, "Curiosity."

Krithika Shankarraman (00:59:32):
I love that.

Lenny Rachitsky (00:59:33):
Yeah, and that's what you're kind of speaking to is just if you're curious about learning, you'll almost avoid some of these things or you'll use these tools in a really interesting way just to learn things more deeply.

Krithika Shankarraman (00:59:43):
And that stays with you into your career, right? Because you can either go into your career trying to get to that next ladder in the promotion rung or you can get there to bring a genuine curiosity to, what makes us different? What makes our customers tick? And how do we find those unique insights that can unlock something that nobody else has?

Lenny Rachitsky (01:00:04):
That reminds me. To sort of close out our conversation, I wanted to come back to pricing strategy. I have that in my notes here and I haven't gone back to it. So let's focus on the AI and pricing strategy. Just say someone is trying to figure out pricing for their product and they have some kind of AI product. What are some tips, some piece of advice to think this through? Any general frameworks you use?

Krithika Shankarraman (01:00:25):
Again, there's no playbook. I feel like it's such a non-answer, but I think the real answer is experimentation. And we found this firsthand multiple times at Stripe, but also at Retool. I think there was a very visceral example where we decided to bring our free product into the hands of more users and sort of what was available in the free plan. And then there was another one that we tested out as a pricing function where we decided to do something quite controversial, which is to take the thing that our sales team was gated on, a self-hosted version of Retool, and made that available self-serve to anybody who wanted it. They didn't have to talk to a salesperson. And that kind of blew up the funnel, right? Because the amount of pipeline that the sales team saw had diminished considerably, but it also helped them focus up market, on higher ACV deals.

(01:01:13):
And so that trade-off is really hard to make, so the only way we could do it was through experimentation and piloting to build conviction. So I would say AI is no different in that you kind of have to test the market to see what works. Is it a seed-based model? Is that where people are deriving value? Or is the way that they speak about the value of the product something quite different? Is it hours saved? Is it the amount of things that they could do now that they couldn't do before? And so there might be a metric there to go off of, and I don't think anyone solved it, especially with agents coming into play. How you pay for AI workers is going to be very different. What is that unit of completion for things like code generators? It's going to be a Wild, Wild West before we come up with something that is as internalized now as seed-based pricing or usage-based pricing.

Lenny Rachitsky (01:02:10):
Wild indeed. I want to actually follow this insight you had around Retool. That's really interesting. Yeah, so you opened up self-hosted Retool. What was the insight there, because this might be useful to people, that convinced you to play with that? Seems like a big deal change to how you price and do trials.

Krithika Shankarraman (01:02:30):
There were two guiding principles here. One is, do people actually want to talk to sales before they get a self-hosted thing? It's sort of like the SSO attacks, right? Is that really the thing that you want to gate your value on? So, that was one. And so we saw a lot of demand from smaller customers that still wanted self-hosted for a variety of reasons, because they worked in regulated industries or they worked with very private data and PII. And so it wasn't just something that was, "Hey, if you have 10,000 employees at your company and you're an enterprise, you want self-hosted." It was that for a variety of different reasons, regardless of your company size, you might want self-hosted. So that insight kind of led us to say, "Hey, where is the delineation here? Because the sales team should be talking to larger customers, landing larger deals." And so to align those two was one of the driving principles.

Lenny Rachitsky (01:03:19):
Awesome. Okay. Two final questions before we get to our very exciting lighting around. I'm going to take you to a couple of recurring segments on this podcast. The first is AI Corner. And with AI Corner, what I try to get to is some way that you have figured out to use an AI tool in your work to do better work or do faster work, to be more efficient. Is there something there that you could share? And if not, that's also totally cool.

Krithika Shankarraman (01:03:46):
Ooh, it is hard to pick because there's not many things I don't use AI for these days, and oftentimes it's a catalyst and an accelerant to the work that I'm already doing. But I think I can actually unlock my ability to talk to dozens of companies across the Thrive portfolio in any given week, and the ability to get deep on their context, their environment, their competitive landscape. We can do that because of the tools and the products that Thrive has invested in from an engineering perspective. So we have internal tools that are driven with AI that give us a lot of insights and access to expertise for these companies so we can show up as more meaningful partners in a day-to-day basis.

(01:04:29):
So I think the ability to mix AI tooling then accelerates work that you're already doing, and then AI-based tools that unlock superpowers that wouldn't otherwise be available to you unless you're going deep into Google Groups archives or talking to people across the organization to pull out things that are inside of their brain. That kind of institutional knowledge being made more accessible by AI is actually more powerful sometimes than the tools themselves. And in fact, even at OpenAI, it's one of the things that we advised most enterprises to invest in first is their own operational efficiency rather than just the AI magic dust they could sprinkle on top of their product experience for their customers.

Lenny Rachitsky (01:05:15):
Awesome. Okay. Final segment of the podcast we call Fail Corner. And the idea here is we have all these amazing guests, all these super successful people on the podcast, all these stories of epic wins and nothing but success. And I think in reality, that's not the case. And it's important for people to hear that things aren't always up and to the right and always win, win, win. Is there a story from your career you can share where things didn't work out and what you learned from that experience?

Krithika Shankarraman (01:05:44):
And again, this question's hard because there's so many things to choose from as potential examples here. And you're absolutely right, Lenny, in that most careers are not the sort of linear journeys that are reflected on somebody's LinkedIn profile. No, I'll talk about a fantastic success, which is called Stripe Relay, which you probably... Oh, I'm just kidding because nobody remembers it. It was ahead of its market. We launched it back in 2014. It was supposed to be the platform with which e-commerce companies would tap into social commerce. The buy buttons if you remember that. And it launched to a lot of fanfare, but then eventually failed. It didn't produce the sort of revenue or the numbers that we had expected.

(01:06:28):
And the understanding here was that as much as one side of the marketplace, or you might have some conviction that you need to put something into the market for a particular moment in time, the timing of the market really matters. And the timing of multiple parties coming together to make a platform work really matters. And so the learning here was we hadn't gone deep enough into the market dynamics. We hadn't done enough user research. Did people really want this? And if they did, what were their alternatives? What was the stacks that they were operating in? And would they adopt a net new tool versus one that integrated into existing systems directly like their e-commerce inventory management systems and so on? And so for that reason, I think, again, it was ahead of its market and ahead of its time, but a clear flop regardless of the effort that we put into that launch.

Lenny Rachitsky (01:07:22):
This reminds me of when Kevin Weil was on the podcast talking about Libra, which was his cryptocurrency project that Facebook ran, and he's just like, "Okay, that was a terrible time to launch something like that where people trusted Facebook the least in our history." And now may be a good time to try something like that. Basically, a cryptocurrency platform to send money internationally for free. What a dream that would be. Okay. Krithika, is there anything else you wanted to share or maybe something you wanted to remind people of from what we've talked about? Just to leave folks with a final nugget before we get to our very exciting lightning round.

Krithika Shankarraman (01:07:55):
If there's one thing that folks take away, I hope it is that they know that there isn't one clear answer to any of the marketing problems. It seems like there's a playbook for everything, there is a framework for everything, but the reality is the work is hard. You have to spend the hours and the time to really understand your customer, and there is no replacement for that, and there isn't going to be even with the advent of AI. And the other part of it is to deeply understand your product as well. What are you bringing to the table? And not just your product, but your company's values, your unique approach that you're bringing to the table. And really be intentional and thoughtful about that because in the absence of that, nothing is going to be a substitute to bring that combination of ingredients together.

Lenny Rachitsky (01:08:45):
With that, we've reached our very exciting lightning round. We have five questions for you. Are you ready?

Krithika Shankarraman (01:08:51):
Hit me.

Lenny Rachitsky (01:08:51):
Here we go. What are two or three books that you find yourself recommending most to other people?

Krithika Shankarraman (01:08:57):
On the professional side, one book that I recommend to most people is April Dunford's book on positioning called Obviously Awesome. She does a great job breaking down how to position a product from scratch if you've never had to do that, and she's just so great for her real talk. So, really highly recommend that. And then I love fiction, so I would say one of the best reads in the last couple years has been Madeline Miller's Circe, which is a retelling of a Greek myth. Lyrical prose, beautiful writing, highly recommend.

Lenny Rachitsky (01:09:32):
Love the combo. April Dunford, we're huge fans of her on the podcast. She's been on twice. I think her book is in my background. We'll link to her episodes.

Krithika Shankarraman (01:09:40):
And mine.

Lenny Rachitsky (01:09:41):
Oh, wow. Okay. So cool. Yeah, she's the best. Okay, next question. Do you have a favorite recent movie or TV show that you have really enjoyed?

Krithika Shankarraman (01:09:48):
I'm really late to the game, but I'm finally catching up on Severance. So, no spoilers, but I'm about halfway through the first season.

Lenny Rachitsky (01:09:54):
Wow, okay. It's hard to weigh the spoilers, but yeah, keep going. It's amazing. Do you have a favorite product you've recently discovered that you really love?

Krithika Shankarraman (01:10:03):
Granola for meeting notes because, all right, I love taking meeting notes as a way to stay engaged in the conversation and to pay a lot of attention, but I also know I'm furiously typing away. And so the ability to augment my notes and bullet points has been a game changer.

Lenny Rachitsky (01:10:20):
That's two guests in a row that said Granola, and I'll give a plug. You get a year free of Granola if you become an annual subscriber of my newsletter. For not just you, but your whole company up to some limit. Check out lennysnewsletter.com and click Bundle, and sign up and get Granola. So cool. I love that.

Krithika Shankarraman (01:10:36):
Happy to help, Lenny.

Lenny Rachitsky (01:10:38):
It's helping Granola, and me, I guess. Yeah, it's great. Okay, thank you. Two more questions. Do you have a favorite life motto that you find useful in work or in life?

Krithika Shankarraman (01:10:49):
My teams have now gotten tired of me saying this, but I say it all the time, which is the delta between expectations and reality is the function for unhappiness. And so it is much easier to change expectations than it is reality, so I tend to spend a lot of my energy making sure that expectations are set. Not just with customers when it comes to our external marketing, but internally with stakeholders, project partners, and even within the team so that they understand what are some of the trade-offs that we're making, or why we're making certain decisions. So I could not espouse that philosophy enough.

Lenny Rachitsky (01:11:25):
I love that this isn't, because I think when people first hear that it's about your own happiness, but I love that it's about other people perceiving how a something did and setting their expectations correctly. Final question. Okay, we've already talked about the em dash, but I want to ask you again. What I'm finding is, so the story here is basically people have discovered ChatGPT's using em dashes a lot, which are these long dashes that you have to use special couple letters on the keyboard to use. I'm a huge... I use these all the time, and people are starting to filter them out on Twitter because they're assuming it's generated by ChatGPT. There's content that has em dashes they assume isn't real. Will you continue using em dashes in spite of all this?

Krithika Shankarraman (01:12:06):
I have begrudgingly reduced my usage of em dashes-

Lenny Rachitsky (01:12:10):
Same.

Krithika Shankarraman (01:12:10):
... but you will not pry them out of my cold dead hands if you tried.

Lenny Rachitsky (01:12:15):
Oh, man, me too. I don't even know. It's like command, options, dash or something to even put it in there.

Krithika Shankarraman (01:12:20):
No, it's option, shift, minus.

Lenny Rachitsky (01:12:23):
Option, shift, minus.

Krithika Shankarraman (01:12:23):
Yeah.

Lenny Rachitsky (01:12:24):
I have to type it. I can't conceptualize in my head. Yeah, and then there's actual rules for when an em dash is the right thing versus, there's a middle-

Krithika Shankarraman (01:12:32):
Em dash and the Oxford comma, the two core tenets of my toolbox.

Lenny Rachitsky (01:12:36):
Is an Oxford comma where you add the comma at the end or you don't? Is that the-

Krithika Shankarraman (01:12:36):
You keep the comma at the end. You must.

Lenny Rachitsky (01:12:39):
Okay. I'm all for that, too. It looks so weird without it. But there's also another, like a shorter not em dash. I guess it's called something else, right? There's like-

Krithika Shankarraman (01:12:48):
The en dash, yeah.

Lenny Rachitsky (01:12:48):
En dash.

Krithika Shankarraman (01:12:49):
That's for ranges of numbers.

Lenny Rachitsky (01:12:51):
Okay, okay. I love that you know all this. Okay. Well, with that, Krithika, this has been so fun and so awesome. Thank you so much for being here. Two final questions. Where can folks find you online if they want to reach out, maybe work with you, and how can listeners be useful to you?

Krithika Shankarraman (01:13:05):
Krithix.com is where you'll find links to all my online presences. And one of my personal missions this year is to meet as many of the up-and-coming marketing talents in the world. So anyone that you know is earlier career, ambitious, but really showing their impact at their organization, please introduce them to me. I would love to chat.

Lenny Rachitsky (01:13:26):
And then what's the best way for them to reach out to you? Is it just on your website?

Krithika Shankarraman (01:13:29):
Yes, please.

Lenny Rachitsky (01:13:30):
Amazing. We'll link to that in the show notes. Krithika, thank you so much for being here.

Krithika Shankarraman (01:13:34):
Thank you for having me.

Lenny Rachitsky (01:13:35):
Bye everyone. Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## What sets great teams apart | Lane Shackleton (CPO of Coda)
**Guest:** Lane Shackleton  
**Published:** 2023-10-01  
**YouTube:** https://www.youtube.com/watch?v=XmgetFMgQZ0  
**Tags:** growth, retention, acquisition, activation, metrics, okrs, roadmap, iteration, experimentation, subscription  

# What sets great teams apart | Lane Shackleton (CPO of Coda)

## Transcript

Lane Shackleton (00:00:00):
Moments that stretch you or moments that you feel uncomfortable in or you find yourself saying, "Oh shit. I shouldn't be here," or, "I'm under qualified to be here," those are the moments you should be seeking out. Those are the moments that stretch you and give you a new foundation. So oftentimes you'll hear a career question like, "Hey, do you feel like you're growing in your role?" And that's a very ambiguous, in my opinion, way to ask this question. A much sharper way is like, "Hey, how many, oh shit moments have you had in the last six months, year, two years, and what are they?" I think if you ask yourself that question and the answer is, "It's been a really long time since I've been stretched in some meaningful way or I've felt like I'm under qualified to be there," then it may be worth digging into.

Lenny (00:00:51):
Welcome to Lenny's Podcast, where I interview world-class product leaders and growth experts to learn from their hard won experiences building and growing today's most successful products. Today my guest is Lane Shackleton. Lane is Chief Product Officer at Coda where he's held the role for over eight years. Before that, he was Group Product Manager at YouTube, a Product Specialist at Google, and as you'll hear, he started his career as an Alaskan mountain guide and then as a manual reviewer of Google AdWords ads. Lane is an incredibly deep thinker, very first principles oriented, and has built an incredible product team and culture at Coda. In part, he's done that by studying the principles and rituals of great product leaders and great product teams. In our conversation, Lane shares what he's learned, what he's found great PMs and great teams do differently. He shares a bunch of his favorite rituals and principles, how you can implement them on your own team, plus a really clever and unique way of understanding if you're making progress in your career, plus so much more. I could talk to Lane for hours, but we tried to keep this to under an hour and a half. With that, I bring you Lane Shackleton after a short word from our sponsors.

(00:01:55):
This episode is brought to you by Eppo. Eppo is a next generation AB testing platform built by Airbnb alums for modern growth teams. Companies like DraftKings, Zapier, ClickUp, Twitch and Cameo rely on Eppo to power their experiments. Wherever you work, running experiments is increasingly essential, but there are no commercial tools that integrate with a modern grow team stack. This leads to wasted time building internal tools or trying to run your own experiments through a clunky marketing tool. When I was at Airbnb, one of the things that I loved most about working there was our experimentation platform where I was able to slice and dice data by device types, country, user stage. Eppo does all that and more, delivering results quickly, avoiding annoying prolonged analytic cycles and helping you easily get to the root cause of any issue you discover.

(00:02:41):
Eppo lets you go beyond basic click through metrics and instead use your north star metrics like activation, retention, subscription and payments. Eppo supports tests on the front end, on the backend, email marketing, even machine learning claims. Check out Eppo at geteppo.com. That's geteppo.com and 10x your experiment velocity.

(00:03:03):
This episode is brought to you by Vanta, helping you streamline your security compliance to accelerate your growth. Thousands of fast-growing companies like Gusto, Calm, Quora and Modern Treasury trust Vanta to help build, scale, manage and demonstrate their security and compliance programs and get ready for audits in weeks, not months. By offering the most in-demand security and privacy frameworks such as SOC2, ISO 27,001, GDPR, HIPAA and many more, Vanta helps companies obtain the reports they need to accelerate growth, build efficient compliance processes, mitigate risks to their businesses, and build trust with external stakeholders. Over 5,000 fast-growing companies use Vanta to automate up to 90% of the work involved with SOC2 and these other frameworks. For a limited time Lenny's Podcast listeners get $1,000 off Vanta. Go to vanta.com/lenny. That's V-A-N-T-A.com/lenny to learn more and to claim your discounts. Get started today.

(00:04:04):
Lane, thank you so much for being here. Welcome to the podcast.

Lane Shackleton (00:04:07):
So glad to be here. Thanks for having me.

Lenny (00:04:09):
It's absolutely my pleasure. I've always really admired the way that you write about product, the way you think about product, and it feels like Coda has one of the strongest and also the most thoughtful product teams out there. And so I am really excited to have you on here and learn from what you've learned over the years. My first question is completely unrelated. I have to ask. Your last name's Shackleton. Any relation to a certain very famous Antarctic explorer?

Lane Shackleton (00:04:36):
Yeah. It's probably distant at best. I wish it was close. I wish I could claim it was my father or grandfather. But I definitely grew up with those stories and reading a lot about him as a kid. In high school we read Endurance, which is a great book if you haven't read it. It's an amazing story. Very inspiring how he put people first and brought back all of his men from this journey to the South Pole. So have taken a lot of lessons from that, but that's as close as I can come to the greatness of Ernest Shackleton.

Lenny (00:05:09):
Okay. So there's a connection. When I think of Shackleton, I also think of the ad that he ran for recruiting people to join his journey. Low chance of survival, incredibly hard, chance for glory if you succeed, something like that.

Lane Shackleton (00:05:23):
It's a wonderful ad. I think I had a mug of that when I was a kid. Yeah.

Lenny (00:05:28):
Amazing. Okay. So on that same topic, I noticed maybe your first job was a mountain guide in Alaska. Was that inspired by this legacy? And also why did you decide not to pursue that and get into product management? Completely different life.

Lane Shackleton (00:05:42):
Yeah. Yeah. Very, very different. Very different time. Didn't have kids back then. I think I was convinced at the time I wanted a career outside. Just loved spending time in the mountains and climbing, things like that. To be honest, I wasn't the best guide. There were a lot of amazing guides out there that just had ... They were almost invincible in terms of their ability to climb for 20, 30 hours. But I learned a lot from the experience and maybe the quick story on why I stopped guiding. I was on what is a dream trip for mountain guides, which is we were flown to a remote portion of southeast Alaska. It's an hour long flight. Mountain called Mount Fairweather. Beautiful 15,000 foot peak. And as a part of climbing on glaciers one of the things that you do for context is you're roped to another person. And the reason that you do that is because if someone falls in a crevasse, you want to be able to stop them or pull them out.

(00:06:48):
So I was roped to a very nice client that I was guiding and he fell pretty close to the top on our way down. And luckily we were able to self-arrest and arrest that fall. But I spent probably the next six hours walking down that mountain thinking the same thing over and over again, which is I really don't want to die roped to someone that I barely know and don't trust or love. So that was the last season that I guided. But tons of great memories and learnings and I think it impacted my life in a pretty significant way.

Lenny (00:07:29):
Damn. Software much lower stakes. I guess just while we're on this topic, is there any parallels or big lesson you learned from that experience that you bring to product?

Lane Shackleton (00:07:37):
One is just preparation. I think when you go climbing or when you guide climbing, you spend months and months preparing for usually a few days of climbing. So there's that kind of preparation. There's also just a million checklists. So before you go on an expedition, you may check a checklist of all your equipment, stuff like that a dozen times or more. So you ensure redundancy across all your systems. So that was definitely a parallel. The other thing I think about a lot is just how to stay calm in challenging or scary scenarios. We had another instance where I had a client pull a big chunk of rock off and break their feet and I was the junior guide on that particular instance and the more senior guide looked at me, looked at the situation and was like, "Okay, we're getting this guy out of here right now." Put him on his back and we basically took turns carrying him out for a couple miles I'll just never forget instances like that where the clarity of stay calm, assess the situation, prioritize, take action. There's a mini version of that when you're building software, I think. So experiences like that, I think, even though I only did it for a handful of summers, were pretty profound.

Lenny (00:09:06):
Yeah. What a very different life that life path would've been.

Lane Shackleton (00:09:11):
Pre kids. Yeah.

Lenny (00:09:12):
Oh, man. So you mentioned your writing, you mentioned that this is something you want to write about. Shifting to the core topic of our chat, it's very clear that you spent a lot of time studying how great product managers operate and how great product teams operate. You've been doing a bunch of writing on the principles of great product management and also the rituals of great teams. And so I want to spend a bunch of time trying to extract as much as I can from your learning so that listeners can learn. Essentially what are principles of great product managers, what are rituals of great teams and generally how do the best teams operate? And my first question is just why is this something that you started doing? What pulled you into spending so much time and effort trying to understand how the best teams and people operate?

Lane Shackleton (00:09:53):
Yeah. Yeah. I've been asking myself that question a little bit lately. There's a few reasons. One reason is I just found myself giving a similar set of advice in one on ones. And so I think anytime you find as a leader yourself repeating the same lessons, it should be a good flag to say like, oh, I should probably scale this in some way. And as you know, as soon as you write something down, you have to clarify your own thinking and so it becomes very useful for that. And I don't think I quite expected how useful it would be in that sense. Writing something down and then putting it out there, you start to get feedback back of where you might've been right or where you might not be right. And so for me it's been a good learning experience there as well. I think the second reason is I've always been pretty frustrated with career ladders. Most companies have career ladders with 10 or 15 levels and as soon as they hit some scale levels, there's levels between levels and I feel like I looked at the one at Google and you needed a PhD to decipher it and interpret how to operate within it.

(00:11:11):
And so that's one piece of the construct. If you think more broadly though, they aren't consistent across companies, so now you're in a situation where you're in your version of the rat race. And so I found that I basically wanted to have a broader set of principles that transcended level. So things that could be true when you are an ICPM starting your career and things that can also be true when you're the head of product or running a product team or things like that. That's one. I won't rant further on that but I think that's one piece of it.

(00:11:49):
And then I think the last reason I'll mention is I was pretty inspired by a talk that is by this guy named Brett Victor, who's like a prototyper thinker. May have heard of his work. He has this talk called Inventing on Principle. And in the early days of Coda, one of our first designers, this guy Jeremy Britten, showed this talk to the company and my mind was blown. And I think it was one of those examples of someone developing a clear view of what principles they should operate with and then following that principle. And it was just a meta example of how important it is and how impactful it can be when you decide on a principle and then follow it. And so ever since then I've been thinking what are my principles as it pertains to building software and other things. So those are the three reasons that led me to start writing these things down.

Lenny (00:12:49):
Amazing. We're going to find that talk and link to it in the show notes. I want to ask about what principles you've come to, but I also want to understand how you actually ended up doing ladders and performance review stuff at Coda. Would it be better to talk about that later after we go through some of these things or is there something you want to share first of just how you think about it at Coda?

Lane Shackleton (00:13:06):
When we were doing career ladders, first of all, we put it off for quite a bit of time and that was based on the advice of a lot of other leaders that said as soon as you introduce this, then the incentives flip from being company focused to being individual focused. So I think we delayed it for a good bit of time. There came a time where we decided, "Hey look, we really do need to provide better guidance here about what it means to grow and what it means to be great." And so about the same time we were doing the levels thing I started writing down some of the principles that I've been publishing. One of the things that I think about a lot when talking about levels is just how to keep everyone oriented toward their team and their company. And I think that we've done a really good job of that over the years. So levels aren't by any means at the forefront of any company discussion. In fact, we don't use titles that much.

Lenny (00:14:11):
You said that it's not specific to role. Do you mean the same leveling attributes are the same from design and product and engineering?

Lane Shackleton (00:14:19):
We basically have five levels and we call them role stages and they go from apprentice to principal. So apprentice is ... Rope analogy here is learns about rope. Practitioner is can tie basic knots, shown complex knots. Given a problem, they can do it. Career is you can calculate rope strength. You know a lot about knots. Principal is basically invented nylon. So the bar is really, really high for principal in these levels and I think that that's appropriate. It should be aspirational that the bar is exceptionally high at the highest level of our role stages. I find it's a pretty good process to draw maybe a little bit of contrast with other companies. I think most other companies, especially large companies have 10 to 15 levels. I think we've made a really conscious choice to have only five. I think the other bit of contrast I would draw is basically role stages are not visible across the whole company. We're not showing levels of any individual PM or designer, and that's partially because we just don't want to put a big focus on it. And then probably the biggest difference is we have a centralized compensation committee and that's who decides compensation and so it's not the manager that drives your compensation. So those are some differences.

Lenny (00:15:52):
Super cool. I've never seen it done this way before. I think it's an awesome example of first principles thinking, which I see a lot come out from your product team. And then just to make sure I heard you right, these five stages are roughly the same across role, so designers have the same five and they're described similarly.

Lane Shackleton (00:16:08):
That's right. They're described similarly at a high level, but then the specifics if you get into it are a little bit different.

Lenny (00:16:15):
Okay. I'm going to ask about what the principles are, or a few of them that you can share. But one other very tactical question. At what size of product teams, say just PMs, did you start to develop this framework?

Lane Shackleton (00:16:26):
We were probably at 20-ish PMs and designers when we did that.

Lenny (00:16:31):
Awesome. Okay. So let me just ask, what are some of these principles you've narrowed it on as principles of great product managers?

Lane Shackleton (00:16:38):
Maybe it's helpful to start with a little higher level context on the unifying thesis. I think the unifying thesis is the core job of a product person in general is to turn ambiguity into clarity. And if you think about the job of a product leader or a product manager, everything is ambiguous all the time. It's like what's my role on this team? What problem are we solving? Who's the target customer? What prototype is going to solve this particular problem? So it's literally everything. And so if you're going to do the job well, you really need to get good at spotting ambiguity and turning it into clarity. And so the obvious question that follows from that is okay, great, that sounds like a great Hallmark card, but how do you actually do that? And so I think the principles that I've been writing down are very personal. They're my take on how to do this.

(00:17:41):
So the first one that I wrote about was systems not goals. And one of the ways that I started this post ... I'm a big fan of getting inspiration from outside of tech and so one of the stories that I tell is basically the story of Jerry Seinfeld. If you haven't seen the documentary Comedian, it's amazing, it's definitely worth watching. But the story goes, he's done Seinfeld the show and he's got all this material from the last 15 years and he comes in one day and he says, "Look, I'm going to throw away all my material and I'm going to start fresh." And this is unheard of in comedy for someone to just throw away all their old material and start fresh. And so the question is what does he do next? And the thing that he does is he sets a goal, which is basically to build up to an hour of material again.

(00:18:34):
But the goal isn't that important. What's important here is the system. So the system that he uses is he writes for an hour every morning, doesn't write for more if he doesn't want to, and then he goes and performs at night. And so when you rinse and repeat that system, do it hundreds of times, that's how he builds up from five minutes to 15 minutes to 30 minutes of material. And so I think that I take a lot of inspiration from that and I think product people can generally, which is instead of being obsessed with the goal, be obsessed with the system that gets you there. And so the phrase I sometimes use is goals with good intentions don't work. I really need to give a common example. A really common example is teams that are trying to learn about customers or do research. And one thing I've observed is a team may have a goal like an OKR of talking to 10 customers this quarter and they may or may not hit that OKR. And then if you watch closely, the next quarter, they may not have a goal of talking to customers anymore. And so their learning is going up and down.

(00:19:49):
And to draw a contrast, that's just really different than a team that has some default on system for talking to customers. Every few times a week they're talking to customers for whatever reason. And the impact of that is really hard to see until you understand that the latter team tends to have really good product instincts or really good customer instincts. It's because they've just had this default on mindset of talking to customers. And in the early days of Coda, we actually did something similar. We had a time allotted on Fridays and it was basically, it was on the calendar a customer or a potential customer was coming in and so you knew that it was going to happen and you had to have something to show. And so sometimes we'd be scrambling the three hours before to have a prototype ready for a customer. Sometimes we would've had something that we've been baking for a while. But the point is that it was default on. And so the way that we developed good customer instincts was not the goal, it was really just the system behind it. So that's one that I'm passionate about and I think it also translates into a lot of the rituals that we talk a lot about.

Lenny (00:21:06):
There's so many directions I can go with this. I really like this one. It reminds me of something I did at Airbnb where we had a lunch with a host every Friday with the team and we had a community person find someone in San Francisco that's a host. And there's no agenda, it's just let's have lunch and meet the team. Curious what you're wondering.

Lane Shackleton (00:21:22):
Exactly.

Lenny (00:21:22):
And Airbnb hosts are always so nice and has such a pleasant experience. Also makes me think about this book, The Score Takes Care of Itself.

Lane Shackleton (00:21:30):
Yep.

Lenny (00:21:31):
Have you read that?

Lane Shackleton (00:21:31):
Yeah.

Lenny (00:21:31):
Where it's just do the fundamentals and you'll win?

Lane Shackleton (00:21:34):
Totally.

Lenny (00:21:34):
The other thing it reminds me of is I have this quote hanging in my office here. I Believe it's from the Rick Rubin book. And the quote is, "The object isn't to make art, it's to be in that wonderful state which makes art inevitable."

Lane Shackleton (00:21:48):
I love it.

Lenny (00:21:49):
I feel like you just changed art-

Lane Shackleton (00:21:51):
Yeah. Rick Rubin's amazing.

Lenny (00:21:52):
Oh my god, it's so good. Just every section is this quotable thing I want ... I need to hold onto this thing.

Lane Shackleton (00:21:58):
Yeah. He's got a great thing on listening. I really admire what he says about listening and I think that a lot of PMs could take that lesson, which is-

Lenny (00:22:10):
Yeah. What is that lesson?

Lane Shackleton (00:22:11):
The way he talks about it is essentially you want to listen and absorb every fragment of what that person is saying, including their body language and everything else, and try to turn off the side which is crafting your response or figuring out what you're going to say next or what the problem with their argument is or whatever. It's quite hard to do. Because your default mode is always the next step of the conversation. But I think if you can really challenge yourself, like he says, to pause and really try to internalize holistically what that person's saying, it's pretty powerful.

Lenny (00:22:55):
I was actually just reading that chapter and the next chapter is about this idea of the beginner's mind. I don't know if you remember that. I feel like people get sniped by Rick Rubin stuff. But anyway, I'm going to go down this thread. He talks about how AlphaZero or AlphaGo, the first AI thing that beat humans at Go and how there was this move it made, move 37 in the game that was just like ... The person the AI was playing walked out of the room. He's like, "I don't even know what just happened. This is out of anything I've ever imagined." And it won. And the lesson there it was trained not on what we've learned, but it trained itself and figured things out from first principles and then came up with this thing we've never even comprehended. And so it's a really good example of the power of coming from a beginner's mind and not being influenced by what's already been done.

Lane Shackleton (00:23:41):
Yeah. We have a walkthrough ritual that we do.

Lenny (00:23:45):
Tell me more.

Lane Shackleton (00:23:46):
The prompt is essentially put yourself in the shoes of someone who knows nothing about this topic whatsoever and have beginner's mind and then walk through with five or 10 people watching you and let's fix all the problems that we see.

Lenny (00:24:05):
Okay. I want to talk about rituals. We're getting ahead of ourselves a little bit. Is there any other principles that you can share either just on a high level or in depth that you've come across? And I know people can go to your Substack and read this. And by the way, what's your Substack URL for people that want to check it out?

Lane Shackleton (00:24:21):
Just lane.substack.com.

Lenny (00:24:24):
Sweet. We'll definitely link into it. Yeah. Any other principles?

Lane Shackleton (00:24:28):
I think the other one is cathedrals, not bricks, and then the other one is proactive, not reactive. Cathedrals, not bricks I think is a classic one. I think I had a moment of realization and talking to Shishir in a one-on-one when I was at YouTube bemoaning the fact that my team wasn't performing to the potential that I thought they had. And he had a very pointed and unexpected question, which is like, "Do they know their cathedral? Do they have a cathedral?" And I'm sitting there like, "Man, what are you talking about? We're talking about performing as a team and you're asking me about cathedrals." And then he explained the cathedral story, which I can talk about. In that-

Lenny (00:25:11):
What's the cathedral story?

Lane Shackleton (00:25:11):
It was quite clarifying.

Lenny (00:25:13):
Yeah. Do share.

Lane Shackleton (00:25:14):
Yeah. The cathedral story is basically you walk up to three people, they're laying bricks. You ask the first person, "What are you doing?" They say, "Well, I take the bricks from over here and I put them on that sack over there." You ask the second person, "What are you doing?" They say, "Well, I take this little cement and I put it on top of the brick that that person lays." You ask the third person, "What are you doing?" And they say, "Well, we're building a cathedral." And the core insight here is that you want your teams to feel like they're building a cathedral and not laying bricks. And I think it's really, really easy to do when PMs are really busy on a day-to-day to just be one task after the other, really execution oriented and maybe not take the time to help the team take a broader frame, open the aperture a little bit and have a view of what the cathedral is. And I think we've learned many times that one unexpected bit of this is that everybody needs to see a different facet of the cathedral.

(00:26:22):
So very often ... And I've made this mistake before plenty of times. Very often people will do a great writeup on vision or strategy or whatever it is and the result is people can't quite see their version of what this broader arc is or this broader cathedral is. And so one of the things that we have tried to do when we go through big planning cycles is show all the different sides of this. So instead of just having a writeup, we may have a writeup, we may couple that with a metric, we may couple that with directional mocks and what the billboard might look like or how our homepage may change. And really what we're trying to do is take the mystery out of the set of broader constraints or where we're headed. I think great product teams and great PM leaders tend to always orient their teams towards a broader cathedral as opposed to laying bricks.

Lenny (00:27:26):
Such a beautiful metaphor. Reminds me of this other quote I just looked up while you're chatting. "If you want to build a ship, don't drum up the men to gather wood, divide the work and give orders. Instead teach them to yearn for the vast and endless sea."

Lane Shackleton (00:27:39):
Classic. Classic. It's Antoine.

Lenny (00:27:42):
That is right. Antoine de St. Exupery. Okay. Something I was curious about as you were chatting also is for folks that want to develop their own principles and define how they want to think about products, is there anything you found to be useful in helping emerge these into principles that you can come to? Is it just sitting around thinking? Is there anything else you've done that has helped you define these things?

Lane Shackleton (00:28:06):
Probably two things. One is reading really broadly. So I think not just reading PM style literature. Like I said, I tend to get a lot of inspiration from outside of tech. I think that's one thing. I think the other thing is insofar as you get the opportunity to mentor other people, think about what you're saying to these people. Think about, okay, this person came to me with this challenge. What was my response? Why was that my response? Am I giving that response a lot of times? Okay, maybe this is a more deeply held belief. So I think noticing those instances was helpful for me.

Lenny (00:28:46):
Are there any books or topics or areas that you found most inspirational when you talk about reading and studying other non-product tech?

Lane Shackleton (00:28:53):
I mean definitely sports. I would say sports is really interesting to me. Team sports. I've always been a huge fan of everything team sports. Storytelling. Go look at some of the best storytellers in the world and they're actually out there on a stage telling stories. There's a book called Storyworthy that I really like.

Lenny (00:29:15):
I was just going to mention that. That book is so good. Somebody mentioned this on the podcast and I read it. It's the most useful practical book for how to tell stories.

Lane Shackleton (00:29:23):
It's so good. The insight is amazing. Just in case your listeners are interested, the insight is basically the nugget of a great story is five seconds of transformation. So if you just orient everything else around that moment of transformation, then you end up usually telling a reasonably good story. I had a conversation with the author right after I read that book because I was just totally enamored with it. And then we ended up bringing him into Coda and he gave a great talk. So yeah, big plug for Matthew Dicks.

Lenny (00:29:58):
The other thing that stuck with me also from that same ... We're just going on all kinds of tangents. From that same insight is, and I watch movies completely differently now, where basically the characters you meet at the beginning of the story, they're going to be completely opposite at the end of the story because of this transformation that takes place. So I'm watching movies with my wife now, I'm like, "Okay, she's very shy right now. She's going to be very extroverted by the end of this movie." Or, "They love each other. Oh, they're going to have a lot of problems." That's so interesting. Oh, that's such a good idea. Okay, I'm going to get this guy on hopefully. And he's a Moth champion basically.

Lane Shackleton (00:30:30):
Yeah. I would say as maybe a principal version of this, the way that you learn or the way that everyone including me learns new things is you go seek out the best at that given craft. So in this case, you go to the Moth StorySLAM you see some really good stories. If you ever watch these on YouTube. And then you just unpack what they're doing and how they're doing it. And then obviously I think the other way to learn quickly is to throw yourself in the deep end. So insofar as you can put yourself in situations that are uncomfortable or force you to do things like tell a story or force you to come up with a clear strategy, you should always opt into those, especially early in your career.

Lenny (00:31:18):
The first thing you said, that's basically the whole premise of this podcast. Find the best at all these things and learn from them, extract and share.

Lane Shackleton (00:31:24):
And the world is much better for it. This podcast is an amazing resource.

Lenny (00:31:29):
Thanks man.

Lane Shackleton (00:31:29):
You've done something very special.

Lenny (00:31:31):
I appreciate it. This podcast episode is already very special. The point you just made reminds me of something that I heard you talk about, which is this oh shit moment. I don't know if it's related to what you shared of just giving people a sense of whether they're making progress in their career. Can you talk about that?

Lane Shackleton (00:31:49):
Sure. Yeah. I think I picked this up originally from Seth Godin, the author, and it just totally stuck with me. The basic thesis is that moments that stretch you or moments that you feel uncomfortable in or you find yourself saying, "Oh shit, I shouldn't be here," or, "I'm under qualified to be here," those are the moments you should be seeking out. Those are the moments that stretch you and give you a new foundation. And so I have found that they turn out to be a pretty good way to calibrate whether someone is growing in their career. So oftentimes you'll hear a career question like, "Hey, do you feel like you're growing in your role?" And that's a very ambiguous in my opinion way to ask this question. And a much sharper way is like, "Hey, how many, oh shit moments have you had in the last six months, year, two years, and what are they?" I think if you ask yourself that question and the answer is, "It's been a really long time since I've been stretched in some meaningful way or I've felt like I'm under qualified to be there," then it may be worth digging into.

Lenny (00:33:04):
That is so good. Making me think about this podcast where I never wanted to do podcasts. I'm like I'm not a podcast person. I just want to sit there and type out newsletters. How cool is that? And I'm like, no, I got to do it because it's hard. And I'm glad I did it. It also reminds me of this quote that I love that I always think back to. "The cave you fear contains the treasure you seek."

Lane Shackleton (00:33:26):
Nice. That reminds me of ... Have you read the book The Obstacle is the Way?

Lenny (00:33:31):
No. Say More.

Lane Shackleton (00:33:33):
It's a great book by Ryan Holiday. And the core thesis is ... It's a bit about stoicism. But the core idea is essentially instead of running away from obstacles, you should be running toward them and that's where you experience either the most growth or the most profound moments of your life. He gives a lot of examples in that book of people throughout history who made that choice. And I think he's also given that talk to hundreds of sports teams. It's a good book. Worth reading.

Lenny (00:34:08):
It's so hard. It's so hard to do hard things, man. So we've been talking about principles of great product managers. You also spent a lot of time looking at the rituals of great product teams. And I know you're working on this handbook that I'm excited to learn more about. Can you just talk about ... I guess one, where this idea came from of studying rituals of great teams and also just how do you actually go about learning about these rituals? I know you have this really interesting process.

Lane Shackleton (00:34:31):
Yeah. In general, I'm a big believer in good design and good product starts with noticing. Tony Fadell has a great talk on this. So I think a bunch of us that are really obsessed with rituals, we just honestly try to be great at noticing. So see something happening with a customer, ask a few questions, get introduced to their team, hear about something interesting from a non-customer, ask for an intro, end up just probing and asking a lot of questions. And then in many cases nowadays with Coda, we're building new rituals alongside people. So someone has a creative idea about how to implement something and we're like partners or collaborators with them on that, which is honestly incredibly fun to just see people's creativity expressed in a tool and then by extension the social construct that they exist in. So that's a little bit about how we got started in that whole process. And then of course Shishir is writing a book called Rituals of Great Teams so we've been cataloging those. We've been hosting a bunch of rituals dinners where we basically get people together for a dinner and we usually have three or four presenters at those dinners. It's just a great chance to learn and think about how the engine runs in a lot of these companies.

Lenny (00:36:03):
What are some rituals that you've learned from these dinners and these and this research you've done that have really stuck with you?

Lane Shackleton (00:36:10):
There are so many. It's hard to choose. Maybe I'll choose two that are top of mind. One is Dharmesh Shah has this ritual from HubSpot called flash tags. Have you heard of this?

Lenny (00:36:24):
No.

Lane Shackleton (00:36:27):
We've all probably been in the situation where someone gives you feedback and you either under interpret it or over interpret it. And as an organization, I think the core principle here is like you want to be calibrated on how much to pay attention to a bit of feedback. And so he outlines four flash tags. He presented this in one of our dinners. And I absolutely love the phrasing of these as someone who's given a lot of feedback on product stuff in their career. So it ranges from ... I think it's FYI, suggestion, recommendation, plea. So FYI is basically like I had a thought, take it or leave it kind of thing. Suggestion is ... And he uses this hill dying metaphor. So is this a hill I'm going to die on? And FYI is there's no hill in sight. Suggestion is there's a hill. I'm not going to die on it but this is what I would do if I were you. You can take it or leave it. Recommendation is I'm climbing the hill. I'm not going to die here, but I've thought about this a lot, so don't ignore this.

(00:37:41):
And then the fourth one, plea, is hopefully rarely used in the organization. It's like, I don't like dying on hills. That's not what we do here. But this is a pretty good candidate for it. You should really trust me. And so we have ended up using that. I was actually just at an offsite and someone gave a lightning talk to our team on how valuable this has been just to calibrate, hey, we got 100 pieces of feedback and there's one plea. Okay, let's spend our time on that. Or there's a whole bunch of FYIs. I think we're fine. Let's keep going. No worries.

Lenny (00:38:20):
That's amazing. It's interesting none of them are just do it this way. I imagine that's very intentional.

Lane Shackleton (00:38:25):
Yeah. Honestly it's a sign of ... In Dharmesh's case, I don't know him super well, but it's a sign of a really experienced leader to know that scale. But every time I look at the scale and I'm weighing where I am between suggestion or recommendation, I have to giggle to myself.

Lenny (00:38:45):
And how do you actually use it? In the feedback you put a hashtag plea kind of thing?

Lane Shackleton (00:38:51):
The way gets used in code docs and the way I think other companies have made it a ritual is you'll have a feedback table and you'll write your feedback and then there'll just be a little select list and you can select between those four. And usually what people do is they include the description so you can as you're choosing it, think do I really feel that strongly about this? And honestly, it's good hygiene. Otherwise, every bit of feedback is taken the same. Which just fundamentally the impact of that is it slows everything down because now you're looking at a list of 100 pieces of feedback and you're going like, "Oh man, we got to address all this feedback." Whereas as soon as you distinguish between what's most important, it's much easier to sort through that.

Lenny (00:39:46):
What about if it's in person? Do you say this is a plea or this is a FYI?

Lane Shackleton (00:39:50):
Oh, I've definitely heard that in many meetings. Are you making a recommendation or are you making a plea?

Lenny (00:39:57):
Amazing.

Lane Shackleton (00:39:58):
And making the person think through that choice I think is just a very helpful shared language.

Lenny (00:40:04):
I imagine one of the other benefits of this is I think most leaders that rise up the ranks eventually realize anything they say in a meeting is going to be taken really seriously and the team's going to rush back and be like, "Oh, Lane told us to change this thing." I imagine it helps you just make it clear. No, you don't need to actually change this. It's just my thoughts.

Lane Shackleton (00:40:21):
Yeah. Exactly. Yeah.

Lenny (00:40:22):
Awesome. This episode is brought to you by Ezra, the leading full body cancer screening company. I actually used Ezra earlier this year unrelated to this podcast, completely on my own dime because my wife did one and loved it and I was super curious to see if there's anything that I should be paying attention to in my body as I get older. The way it works is you book an appointment, you come in, you put on some very cool silky pajamas that they give you that you get to keep afterwards. You go into an MRI machine for 30 to 45 minutes, and then about a week later you get this detailed report sharing what they found in your body. Luckily, I had what they called an unremarkable screening, which means they didn't find anything cancerous, but they did find some issues in my back, which I'm getting checked out at a physical next month. Probably because I spend so much time sitting in front of a computer. Half of all men will have cancer at some point in their lives, as will one third of women. Half of all of them will detect it late.

(00:41:21):
According to the American Cancer Society, early cancer detection has an 80% survival rate compared to less than 20% for late stage cancer. The Ezra team has helped 13% of their customers identify potential cancer early, and 50% of them identify other clinically significant issues such as aneurysms, disc herniations, which may be what I have, or fatty liver disease. Ezra scans for cancer and 500 other conditions in 13 organs using a full body MRI powered by AI and just launched the world's only 30-minute full body scan, which is also their most affordable. Their scans are non-invasive and radiation free. And Ezra is offering listeners $150 off their first scan with code Lenny150. Book your scan at ezra.com/lenny at E-Z-R-A.com/lenny.

(00:42:15):
Any other rituals that stand out as really interesting, either more recently you've learned or something you're just like, oh, wow, that was a genius?

Lane Shackleton (00:42:21):
I guess one that I get asked about a lot on our team is called Catalyst. And I guess maybe to set some context on this one, in most product teams, the review forum is just a really important part of the product development process. And the core insight for most review forums or product reviews or decision forums is that they generally suffer from two problems that are hard to spot unless you've sat through hundreds of them. The first is they have standing attendees, and the second is they're normally single-threaded, meaning they're normally one topic at a time. So maybe I'll talk about both of those because I think they're not exactly intuitive. So when you think about what happens with a standing set of attendees, you either have the situation where you have too many people in the meeting or you have not enough people in the meeting, and both of those can cause problems.

(00:43:25):
So if you've ever been in a meeting, I certainly have, where it's like, "Hey, do we have the salesperson who knows most about this or do we have the engineer who's actually implementing this here? Oh, great. They're not here? They're not a part of the standing set of attendees?" You either have to reschedule the meeting or worse, you just do the discussion without the person who's most knowledgeable, which seems crazy in retrospect. The second problem is single-threaded. So one topic at a time. So if you think about if a product development process is somewhat of a chaotic assembly line for a second, your review or your decision forum ends up being a big time bottleneck in many cases. And obviously you want to be in a situation where product people have a lot of autonomy and they can make most of the decisions themselves. And I'm a big believer in decentralized leadership and all of that, but there are things that cut across the company that need to get reviewed by a broader set of stakeholders.

(00:44:29):
And so what happens when those things are single threaded is either the meeting is really long, so it's a three-hour review meeting once a week, and by the end everyone is about to fall asleep, or it's really short and it's really hard to get on the calendar. You're like, "Oh, can we get on the calendar in two weeks?" And the downside of the not being able to get on the calendar is that now you've just slowed down the whole velocity of the company because the throughput of your review meeting is really slow. So we built Catalyst to really solve those two problems. And so the way it works is it's essentially three one hour blocks throughout the week, and the assumption is that the whole company is free. So you can get anyone in the company for those three hours. And each topic has essentially four roles. Driver, maker, braintrust, and interested. It's a very transparent system.

(00:45:28):
So a salesperson can say, "Oh, I'm interested in this product development review. I'm just going to mark myself as interested." And then the driver is the person who's actually going to drive the meeting, drive the decision, drive the outcome, things like that. And basically, this is all centralized in one doc. And what happens is the day before, that hold that's on calendar gets removed, and then you have specific topics that get added. So there may be three topics going all at the same time because they don't have overlapping attendees. And the impact of this, I think if you really watch it in progress is huge. You basically have many topics running all at the same time, so the throughput is much better and you have the right attendees every single time, and you have a clear set of drivers and roles in these meetings. So that means that we can review work much, much faster with the right people, and ideally that results in more value to our customers, more things getting shipped, just a higher velocity organization. So that's one that we get asked about a lot. And actually a couple of weeks ago, we spent a while remaking the template for that one.

Lenny (00:46:45):
I love that ritual. You actually wrote even in more depth in the post that we worked together on how Coda builds product, which we'll link to if folks want to try this out and you link to actual templates people can actually use it their companies. When someone's listening to this and they're like, "Oh, wow, this is extremely cool," how easy is it do you find for people to take a ritual from a company and implement it? How much is cultural and it's hard to transplant, or do you find people can take this Catalyst idea plug and play at a lot of companies?

Lane Shackleton (00:47:15):
Yeah. I think it depends a lot on what your role in the company is. Maybe to say the extremes for a second, if you're a brand new PM to an organization, you probably shouldn't go try to remake the whole product review cycle that the head of product is really passionate about and has crafted. But you can probably take a decision template or some interesting ritual that has facilitated a team in the past and use it with your team. Another one of my favorites there is a hundred dollar voting. We use that a lot in the context of planning, and I find that creative rituals like that are easy to pick up for teams because oftentimes it's like, okay ... And maybe I'll describe the ritual real quick.

Lenny (00:48:01):
Yeah. I was going to ask.

Lane Shackleton (00:48:02):
The ritual is essentially you can take any set of problems or solutions or themes or whatever you want to get people's input on, and you put those into a table and then people can basically vote with their dollars and usually you allocate $100. And so people will go through and say, "Oh, I want to allocate $10 to this and $20 to this and $50 to this because I think it's really important." And I have found that especially in planning processes, little rituals like this are great at getting the elephant in the room out. So it's like, "Oh wow, we have a huge spread on this one particular problem. You think it's a huge problem. I don't think it's a problem at all. Let's talk about it." Going back to the thesis of turning ambiguity into clarity, a lot of this is like we're trying to get the ambiguous stuff out there so that we can make it more clear.

(00:49:03):
And so I use that as an example because you can be a brand new PM, run a brainstorm, run a planning session like that, and you're probably going to get great feedback. People are probably going to go, "This is cool. I've never done this before." Now to go to the other side of the spectrum, we help a lot of companies that want to remake a whole process. They want to remake a review system like Catalyst or they want to remake their decision rituals. And so in that sense, we're usually talking to a head of product or director of product or VP of product and someone who tends to have a lot more agency over the way that the team works.

Lenny (00:49:48):
Coda is interesting in that it feels like you have pretty stable processes for planning and reviews. I find most companies just every six months rethink a lot of these things. I guess that's probably a sign that you found something that's really good and works and you don't have to redo it. How much are you radically changing the way you operate versus working in similar ways? How do you think about that percentage wise?

Lane Shackleton (00:50:11):
People are always coming up with new creative ways to make their teams run better, make decisions go smoother. And we're continuously adopting those, but there's definitely a backbone of the system. The backbone of the system is Catalyst and tag-ups and the concept called Bullpen. And then there'll be a lot of iteration on top of that. And even those systems went through a lot of iteration. I talked about how the calendar hold got removed and then individual topics got added. That took us launching automations and the ability to add things to calendar in order for that whole process to really work. So in the years prior to us launching that, we did it very manually. So I think there's still a lot of creativity that I see every day.

(00:51:06):
So I'll give one quick example. One of our PM leads on core product, this guy Nathan, he basically saw that a lot of decisions had a lot of different stakeholders because he's in the core product. And now he's leading the core product team so he's trying to figure out what guidance do I give to each of these PMs on who to involve in these decisions? Because every one of these with core product feels like they impact everybody. And so a very simple thing that he did probably in the last six months was he had a table of all the upcoming decisions and then at a tag-up ... Which I can explain if you want. But basically with a small set of stakeholders, he had all the upcoming decisions and then he let people hit a little reaction and say, "Oh, I don't need to be involved. Just notify me of the decision after." Or, "Hey, I have some opinions, but you can keep going." Or, "No, I really want to be heavily involved in this decision."

(00:52:10):
And it was such a pro move. It was such a, I've been through a million of these. I don't want to treat every one of them the same because if I do, it's going to slow down the velocity of this whole organization. And so instead, the majority of those, Shishir or I or Oliver, the head of engineering will say, "I may have some opinions, but keep going." That's often the default. And then there are plenty where we say, "Just notify us of the decision after." And in doing that, Nathan can now give better guidance to the PMs on his team and say, "Hey, you don't really need to involve as wide a group as you think, so just keep going and check in later." So I think those types of little iterations are usually based on a really good insight.

Lenny (00:53:02):
It sounds like a dream come true for a platform team to reduce how many people have to be involved in all your planning and decision making. And that process in which you call it tag-up, maybe just briefly explain it and then I want to talk about this handbook you're working on, which is going to I think, cover a lot of these things.

Lane Shackleton (00:53:17):
Tag-up is based on this insight that a lot of work and project work tends to get discussed in one-on-ones. And actually it's really an anti-pattern. It's a pattern you should try to avoid. So if you're talking to your manager about product work, what's not happening in that moment is your eng lead and your design lead, they're not hearing that. And so you end up with this big game of telephone where you'll have a conversation with your manager in a one-on-one, they'll go back and translate to their engineering and design lead, and of course the fidelity of the game of telephone, something is lost in all of those transmissions. And so the core idea is have a group one-on-one with the key stakeholders. And so we have this concept of braintrust that's modeled off after Pixar's braintrust.

(00:54:11):
And so we'll have a tag-up with a small set of people from a given team, or sometimes we have larger groups, and then they meet with their braintrust and it's once a week. It's the same mindset of a one-on-one. It's their time. So anything that they need to unblock a decision or to make progress, they should use that time for. And they often start by reviewing OKRs and metrics and things like that. But then we generally get into a table of topics. Anyone can add a topic. Those topics are up voted, so people will react and then the table will sort itself. And then we'll say, "Okay, this is clearly the topic on people's mind." And that's a version of what we call Dory, which I can talk about. But essentially the principle is you should discuss that project work with the whole group there. With the whole triad there. And oftentimes with the sales person there and with the marketer there and with everybody else. So I found that that is just a really good practice to try to move a lot of that work out of one-on-ones and into a small group setting.

Lenny (00:55:26):
Awesome. Okay. So you're working on a handbook that's collecting a lot of these rituals. Talk about that and then when can people maybe look for it?

Lane Shackleton (00:55:36):
One of the realizations I had the other day, probably a month or two ago when we started working on this thing, was I was talking to someone about Catalyst and a couple other concepts, and they were like, "I get it. I'm sold. I want to implement some of these things. Where do I look?" And so I found myself sending them a bunch of links to individual templates. So that cued us into the fact that we needed to have a better core handbook for teams that wanted to adopt some of these rituals and also learn from all the rituals that we have learned from and feel very fortunate to have partnered with so many customers on. And so what we did was started writing this handbook, and it's going to come out hopefully by the time this recording is done. And in it, we'll talk about everything from rituals like Catalyst to decision rituals to a lot of planning and strategy and roadmaps, that kind of stuff. And trying to pull out the most interesting patterns and also give people a pretty practical view of how to implement these things. I think that's what has been lacking sometimes.

Lenny (00:56:50):
Amazing. We'll definitely link to that. Hopefully it's live by the time goes out. We'll make it happen. I know also you said Shishir's working on a book that's related and basically rituals of great teams and Shishir was on the podcast and he talked about Dory, so we don't have to get into that. If people want to learn about Dory, they can watch that episode. It was one of the earliest episodes actually. One of the most popular.

Lane Shackleton (00:57:09):
Yeah. I remember that.

Lenny (00:57:11):
Okay. Cool. I have a bunch of random questions now. I'm just going to go in a few different directions. One is, you wrote this post that you call Learn by Making, Not Talking. Is that another principle by the way? Is that amongst your many principles?

Lane Shackleton (00:57:11):
Yes.

Lenny (00:57:24):
Okay. Awesome. So in that post, which we'll link to, you share this story of how you and the YouTube team came up with skippable ads, which I didn't realize it was such a controversial ... But in thinking about it, obviously letting people skip ads, I could see why people were not excited about that. Could you just tell that story? And basically it's like the story of how skippable ads on YouTube came about?

Lane Shackleton (00:57:46):
Yeah. So I moved over to YouTube shortly after the acquisition. It was an amazing tight-knit team. It definitely felt like the Wild West. We were getting sued by Viacom for a billion dollars when that was a lot of money. No advertiser wanted to talk to us. It was essentially viewed as a site of cat videos and dogs on skateboards and things like that. And then I guess the other context, the sales team was very nascent and all they wanted to sell was the homepage and for good reason. That was where you made your money as a salesperson. And so I had just been sponsored by Salar and Shishir to become a PM. It's a longer story that I'll leave out for now and we can go into. But on day one of being a PM, Shishir's like, "Great. You're the new guy. You get the project that nobody else wants and that's called skippable ads. And we've got this crazy idea that we can align the incentives of advertisers and viewers and creatives in this really clever way by putting a skip button on the ad and then charging people per views." And the latter part we hadn't quite cemented yet, but it was part of the core idea.

(00:59:04):
And so the thing I write about in this post is as a new PM, this feels like a really consequential decision. It's like we've got this new product idea. Nobody really wants it. Advertisers don't want it. The sales team doesn't want it. And it's a very unproven thesis. And so the thing I write about is these are the types of things that you can debate for months or years. And I was sitting in a one-on-one with this guy named Phil Farhi who's an amazing product leader and was my boss at the time. And we're trying to figure out what to do and how to handle all the different dynamics. And he just stops and he's like, "You know what? Just test the extremes. Start the experiment tomorrow. We'll figure it out." Essentially.

(00:59:49):
And I think his point was like, look, we can debate this forever. So I would rather us see the upper and lower bounds of how good this could be or how bad this is going to be immediately. And so we launched a set of experiments. This guy Jamie Kerns who's still there. Tiny little skip button on one experiment, giant skip button that covered the entire player on the other side of the experiment. And within a few weeks, I think we had developed some conviction based on some very directional data that we were onto something. And so the lesson that I took, this is many years ago and I've seen this proven out hundreds of times since, is stop talking about it and go make something. Go run an experiment. Go make a prototype, go write a doc, go make a mock. Just don't talk about it.

(01:00:49):
And I found that also as a leader, people really follow that concept. And I also found that it transcends level. I am not talking just to ICPMs. I'm talking to heads of product and CPOs and CEOs to some degree. You should always be out there trying to learn by expressing your ideas and putting them out there. And that's much more valuable in many cases than pontificating about it or having endless circular discussions on it.

Lenny (01:01:23):
It makes me think a little bit about Twitter where they spent years just thinking about the edit button or all these different changes. They're so scared, they did so much research and then now they're changing things left and right. Everything's fine. Everyone's still using it. It shows you that you don't have to be so delicate.

Lane Shackleton (01:01:39):
Yes. It's almost never as bad as you think it's going to be. So yeah, it's just a question of how much better it can be oftentimes.

Lenny (01:01:46):
You mentioned in your early career ... We talked about your Alaska guide phase. Something else I saw is that you were on the AdWords approval team. You basically were reviewing ads people submitted to run on AdWords and that's how you started in tech. So I guess first of all, is that true? And then second of all, how did you graduate from that phase and become this Chief Product Officer of one of the fastest growing, most interesting companies in the world?

Lane Shackleton (01:02:13):
That was a really memorable time. There's an amazing cohort of people that started in tech. I think there was 200 or 300 of us at that time and then eventually thousands that started in Sheryl Sandberg's organization. I guess maybe some quick context. Before running ads on google.com at that time, you had to have them manually approved by a human before that was handled by machine learning and outsourced to other countries. And so there was this process where basically an ad would show up on your screen, you would mark it family safe, non-family safe, porn. And then based on that, it would either run or it wouldn't. And actually, funny enough, some of my most successful friends were terrible at the approval event. They failed the rote task of approving ads. They just couldn't handle it and they went on to be really, really successful.

(01:03:08):
So after working on ad approvals, at that time, I moved to chat support. It was basically when AdWords was launching chat support. I remember very fondly having two chats, chatting with two advertisers at once. Moved on to phone support. That was eight hours a day of talking to AdWords customers. Really a total rollercoaster ride. It was basically one minute you would pick up the phone and it would be someone from a Fortune 100 company trying to spend millions of dollars on AdWords and then the next minute you would be on the phone with a psychic or a taxi driver that was warring with their compatriots over some really specific keyword. I think there were two lessons that I would draw from this. One is I had a mentor at the time and his advice when I was starting my career was basically you have to get customer facing from the very beginning because you're going to end up serving a customer your whole career. Even when you're the CEO of a company, you're going to be serving a customer. So you better get really good at being in any customer scenario and being able to handle it. And so I think that that turned out to be insanely good advice. And if I think about a piece of advice that I give out to people who are early in their career, I've definitely recycled that advice.

(01:04:29):
I think the other thing that I took away from that experience was it's just a great lesson in when people don't actually care about your product. So in AdWord's case, people did not care about AdWords. You were the expert on it and you're trying to tell them about ad groups and how this ad format works and blah, blah. And most of the time people are like, "Dude, I'm a small business owner. I'm trying to get people to come to my auto mechanic store." Or, "I'm trying to get people to come to my taxi service," or whatever it was. I don't care. Basically the product had to get out of the way and really just drive impact for the customer. It was like they just want more phone calls or they want more people in the store. So those are I think two pieces that I think about from those days still.

(01:05:21):
And then I worked in a variety of other roles. I worked in a role called product specialist, which is an awesome role back when there were 15 product specialists at Google. For me, that was an amazing time because I was getting to sit on seven or eight different core product teams. And in my observation, these days, most PMs don't get to sit on other people's core teams. And so I had these three or four years of just ... I call it a masterclass in PMing because I was getting to watch what was working for some PMs and what wasn't working for other PMs and just taking notes behind the scenes. So that was a really influential role. And then went on to various PM roles at Google and YouTube.

Lenny (01:06:09):
Coming back to noticing. It comes up again and again in our chat. This is so interesting because it feels like you basically came from the mail room of tech to the top of the product field. And so I think there's a lot of inspiration people can take from this journey. One quick question is how long was that journey from not being a PM, from I guess being at a tech company to getting your first PM role? Just to give people a sense.

Lane Shackleton (01:06:33):
Let's see. I probably worked for at least four, five years before being able to move to PM and I think that was a slightly harrowing journey because at the time, you had to have a computer science degree.

Lenny (01:06:46):
At Google. Right. Cool. So I think that's one takeaway too is give it time. It's not going to happen. There's a lot of people that are just like, "I need to become a PM immediately."

Lane Shackleton (01:06:55):
Totally.

Lenny (01:06:56):
I think that's a good example of it's not going to happen overnight. Coming back to your two lessons, I think they're really interesting and I'm curious if there's anything else that comes to mind of what you found was essential to you succeeding in this path? So the first lesson you shared as being customer facing. And in this case being in retail as customer facing, is your advice get in a tech company and work on something customers use or is even working at Starbucks or Abercrombie, does that count?

Lane Shackleton (01:07:24):
Yeah. I think maybe to relate it to what you just said, if I were to give advice to someone who really aspires to be a PM or trying to get into PM, I think in many cases if you're in a customer facing role, you are the expert on the customer and that is really, really valuable in tech organizations. And oftentimes it's undervalued. And so I think people who want to move into PM roles who are not currently in PM roles can often lever that experience and that knowledge of the customer in ways that are pretty profound for the organization and pretty insightful for the organization if they really are creative about it. And then I think the other thing is, regardless of where you are in the organization, you're always serving a customer. You can't just talk to one big enterprise customer and you can't just talk to the smallest customer. You have to have a diverse and continuous stream of customer interactions in order to have good intuitions about what to do next. And your engineers aren't going to really trust you unless you have good intuitions about where the customer's headed and what they want and stuff like that. And so the stakes I think are pretty high. The good news is it's easier than ever with all these tools to really get into the mindset of a customer.

Lenny (01:08:47):
My lesson touches on something a previous guest talked about, Paige Costello, where she was often the youngest person in the room and built a lot of respect and people really trusted her over time. And her lesson was know thy customer. If you know the most about what they need, and you can show, here's what I've heard again and again and again, people will just like, "Oh Lane, tell us more." And they bring you into conversation because providing value, you're not just there sharing opinions. Everyone's got opinions.

Lane Shackleton (01:09:15):
That's basically how both me and ... I had a friend named Bill Ferrell who transitioned into PM at the same time and that's essentially how we got the try at being a PM inside of Google was we knew the customer really, really well and we were often in conversations bridging the gap from here's what I think they're really saying, or here's what I think we should build based on what they said.

Lenny (01:09:41):
The other thing I wanted to mention, you talked about the product and how a lot of customers don't care about the product, they just care about just I need this thing done. It reminds me at Airbnb, we hired this guy, Chip Connolly, who was a hotelier. He created the Joie de Vivre hotel chain and just is steeped in hospitality. And he came to Airbnb and started doing this worldwide tour talking to hosts. And he's just like, "Guys, when you talk about product, you're telling hosts, 'Hey, the product's going to be updated. We're going to launch all these features.', they think their home is the product of Airbnb. They don't understand what you're talking about when you're talking about the online experience and the website. That's the last thing they think about. It's the experience of someone traveling on Airbnb and staying in their home." So I think it's a really good reminder of most people don't care about the product. They just have this problem and you just happen to be this website that'll help them solve it.

Lane Shackleton (01:10:30):
I think most people can be way more concise with their communication. Even internally, people don't care. You should assume that people don't care. Or if you're talking to customers, writing a blog post for customers, you should assume that they don't care. When you start with that assumption, you really force yourself to be a little bit sharper in your communication style.

Lenny (01:10:53):
And one final question before we get to our very exciting lightning round. I heard a story that at Coda there's this moment called Tim Ferriss Day that drove a lot of traffic. Can you share that story? Does that ring a bell?

Lane Shackleton (01:11:08):
Yeah. There's lots of memorable days at Coda. One of them was Tim Ferris Day. So I guess maybe for context, we had built this very nascent publisher motion where we were going out and helping people publish their rituals. And this is what you see in the Coda Gallery and a lot of what we talked about today. But we had this one person on that team, this guy Al Chen, Tim Ferriss fan, and also I think had been really tenacious with the people around Tim Ferriss and basically finally got an in to him and figured out a really neat way to implement one of his rituals and wrote a doc. And so none of us really knew this, but this was all happening. And anyway, we wake up one morning and traffic is just spiking through the roof, signups are spiking, no one knows what's going on.

(01:11:59):
I'm convinced this is all spam. I'm like, "Something's wrong with our data or something's going haywire." At the time, we were also in the China Basin office and the fire alarm went off. And so now we're outside on our laptops. We were in a war room trying to figure out what was happening and now we're outside trying to figure out what's going on. So anyway, make a long story short, data scientists investigate and we eventually figured out that we had been featured in Tim Ferriss' email newsletter and I think early on you hear this lesson or this adage of first time founder, build a great product, second time founder, build a great distribution. I think that was one of those early big cues to think about the importance of content distribution and the importance of these publishing flywheels. And it definitely made us double down. We're like, "Okay, if we can do this with Tim Ferriss, what's next?" And we definitely spent a few months trying to reach that high watermark that was set that day in traffic and sign-ups. So it was a fun memorable day and people for the subsequent one or two years would refer to it as Tim Ferriss Day.

Lenny (01:13:15):
So funny. I bet Tim Ferriss had no idea what he did.

Lane Shackleton (01:13:18):
No idea.

Lenny (01:13:19):
Hoping you have a Lenny's podcast day once this comes out. Everyone's going to be freaking out. What is going on here? Is there anything else you wanted to share before we get to our very exciting lightning round?

Lane Shackleton (01:13:30):
Maybe we're talking really briefly about two-way writeups.

Lenny (01:13:33):
Yeah, let's do it. I had that in my notes, but I skipped it, so I'm glad you mentioned it.

Lane Shackleton (01:13:37):
Cool. Yeah, I mean this is a concept that I wrote a bunch about and I often now get asked about, and I guess maybe the historical view of this, I got really obsessed with the history of how work gets discussed and decided upon and broke it down into three phases. And so the first phase was 1980s we had PowerPoint. It was this amazing tool. You could manipulate shapes on a screen and we were all using fancy clip art and it was really fun, but we've all had the experience of being in a really long PowerPoint presentation and someone's droning on in their slides and stuff like that. Second phase is in the early 2000s, two things converged. One was Google bought this company called Rightly that became Google Docs. So instead of having Word on your desktop and sending files around you now had online collaborative editing.

(01:14:35):
And the other thing was Jeff Bezos sent this very famous memo, which basically said no more PowerPoint at Amazon. And what that did was started in earnest their six pager ritual. You can read all about this in the book Working Backwards. It's a really good book. Colin Breyer's book. And so that started I think what I'll call the one-way writeup phase, which is you're writing down your ideas, you're expressing them clearly. It's in prose so you have to be really clear. That was a big step up I think from always presenting work and deciding on work via presentations. And then the thesis is that we're in the midst of a new phase, which is essentially two-way writeups and that's where it's more conversational and feedback and discussion is actually part of the content itself. So that's the broader historical arc. But if you think about it, PMs and product people are always at the brunt.

(01:15:31):
They feel this the most because they're the ones that are driving decisions and really the ones that are driving discussions oftentimes in companies. And so I think the problem with one-way writeups I felt very deeply at Google and YouTube. And just to name them, the first one is you would always be trying to figure out who's read your write-up. So I have many memories of sending a write-up out at 11:30 PM and then waiting patiently for the avatar of the SVP in my area to show up in there. And that was a sign that they had read it, which is just totally insane if you think about that behavior. The second one is you end up having a lot of the discussion in the comments itself. So this is a space that's really built for grammar and spell checking and things like that. And you're having these really meaningful discussions in this a hundred pixel right margin.

(01:16:30):
And part of that I think is there are all these questions that are being raised, and so you have really no idea what the most important question is. And so if you're facilitating those discussions in one way writeups, you're often going through the comments in the 20 minutes before that session trying to figure out which one of these do I want to address. And then the other behavior, and I don't know if you've ever seen this in a doc, but in one way writeups that you see a lot is there'll be just a mega comment thread on the title of the doc. And people are like, "I don't think we should do this," or you'll get into this 30 comment thread on the title because that's the best place to put your overall thoughts. And I saw this pattern all the time. So if you live that life, I think the world of two-way writeups and the way that I think a lot of our customers are doing it, and you can do this on other tools besides Coda too, I think is quite a bit better.

(01:17:26):
I guess the alternative to go down that list is you have a done reading button at the end of a writeup. So now you can say, oh, these are all the people that have read this. And I think even you see a pattern in some of our customers where if it's a particularly long writeup, you'll have three done reading buttons so you can see where everyone has gotten to. And then the second thing is making sure that you're actually addressing the most important question. So instead of pulling questions out of the comments and trying to figure out which one to address, just putting those in a table and then letting people upload those. And that's what we call Dory. And then I think probably the most valuable is sentiment or pulse, which is, well, how do you feel overall about this particular proposal?

(01:18:13):
And if you think about the contrast between a comment thread on the title and seeing a list of all the sentiment, how everybody feels about this proposal and really being inclusive to the entire audience is just wildly different. I think in my particular experience. I'll give you one example. I wrote this proposal, this is now a couple years ago. I thought it was going to sail through no problem. I thought it was going to get four out of five and five out of five smiley faces from everybody. That's sort of how the sentiment table works. And one of the lead designers basically said, "One smiley face. We shouldn't do this." And I was like, oh man. This particular person's not really vocal in meetings. And so I would not have heard that feedback. It was very unlikely I would've heard that feedback unless they had had a sentiment table, a place to add that. And so I think the punchline on all of this is I really authentically believe that this is where we're headed and hope that a lot of PMs and product teams adopt this in general.

Lenny (01:19:23):
I'm so glad that we touched on it and there's a template or an explanation of this that you wrote up that we'll link to. Yeah.

Lane Shackleton (01:19:31):
Great. Yeah.

Lenny (01:19:32):
Awesome. Is there anything else that you think that we should touch on that we haven't touched on?

Lane Shackleton (01:19:37):
Yeah. I think one thing that we've discussed before is just about strategy and planning and stuff like that. So it may be useful to touch on a couple of insights there. I think there's two insights in the strategy and planning thing. And this is again in the handbook that we're writing, but the first that I end up seeing a lot is just this idea that OKRs are not actually strategy. So I think the way that we plan and the way that our customers plan, the key point is it's critical to disconnect strategy discussions from OKR discussions. And it sounds really obvious, but it's I think a very common mistake. And I think a really simple question to ask yourself is do we have a separate strategy process or strategy ritual that is distinct from OKR setting and metric setting and goal setting? And I have found you can pick whatever strategy framework works for you, but I do think it's quite important to pull those two things apart.

(01:20:43):
The other rule that we live by on the planning side is what we call a 10% planning rule, which is essentially just ensure that you're not for a given time period planning for more than 10% of that execution period. And I think this is a really easy mistake to make. I mean, this is a hard fought rule because we've made that mistake before. But you end up getting bogged down in planning or saying, planning felt rushed and so we need to make it three weeks instead of one week or whatever. And the byproduct of that over the course of a lot of time is that you end up just planning way too much and oftentimes you really don't know what's ahead until you've launched or learned something. And so I think that's a pretty good rule to follow.

Lenny (01:21:32):
I love that rule. I found the same heuristic. 10%. If you're planning for a week, plan for half a day, planning for a month, maybe like three days. Yeah, I love it. With that, we've reached our very exciting lightning round. Are you ready?

Lane Shackleton (01:21:46):
I'm ready.

Lenny (01:21:47):
What are two or three books that you've recommended most to other people?

Lane Shackleton (01:21:51):
One that comes to mind is Turning the Flywheel. It's a little manuscript book. Jim Collins wrote it. It's really, I think a very succinct and very fast read about how flywheels work. We talked about Storyworthy. I recommend that book a lot. Good Strategy/Bad Strategy. Love that book. Very simple framework that I've reused a bunch. Maybe outside of tech, Waking Up is a book by Sam Harris on mindfulness that I really like. And then an old one that I really like is The Inner Game of Tennis by Timothy Galway, which is a kind of classic.

Lenny (01:22:27):
Amazing. On Good Strategy/Bad Strategy, I'm working on getting Richard Rumelt on the podcast. I'm in talks with his agent and they seem to be excited. So we'll hope that actually happens. And then you inspired me to try to get the Storyworthy guy on. So what a cast of characters we're going to get on here.

(01:22:43):
Next question. What is a favorite recent movie or TV show that you really enjoyed?

Lane Shackleton (01:22:48):
Yeah, it's a little bit hard with three kids and a job these days to watch a lot of TV. I would say I really enjoyed The Last Dance. I love any sports documentary. All those.

Lenny (01:22:59):
Have you seen Underrated, Steph Curry's new documentary?

Lane Shackleton (01:23:01):
No, I haven't. I got to watch that.

Lenny (01:23:03):
Ooh. It's really good.

Lane Shackleton (01:23:05):
I've been rewatching Arrested Development. That's also just a timeless classic.

Lenny (01:23:11):
Classic. I love that Michael Cera is in the Barbie movie, not to give any spoilers. That was a funny surprise.

(01:23:18):
Next question. What is a favorite interview question that you like to ask candidates?

Lane Shackleton (01:23:22):
There's two I really like. One is teach me something that I don't already know. I think it's just an awesome way of seeing if someone's going to lean in and really figure out what you don't know and then how passionate they are about pitching what they do know I think is really fun. And then Shishir and I have been asking a version of teleporter question and evolving it for many years now, so I like that question quite a bit.

Lenny (01:23:49):
Shishir shared that question in his episode and we make TikTok clips out of some of these conversations and that clip just went crazy. People love it. It's our most viewed clip, I think on TikTok. Or just like, what would your answer to that question, so we'll try to link to it in the show notes if you want to watch just that one interview question. I think you maybe gave it away, so maybe that's why you're evolving it.

Lane Shackleton (01:24:10):
Yeah. We-

Lenny (01:24:11):
Don't know if we screwed you.

Lane Shackleton (01:24:13):
I also recently wrote a post about my favorite ref check question, which I think I would love to learn other people's favorite ref check questions.

Lenny (01:24:20):
References check. Oh man. That's its own. Oh man, I'd love to do a podcast just on that. That is such an important skill. The first question you mentioned of asking people to teach you something, I heard the best version of that in a previous episode where Maya, the Head of Product for Spotify podcasts, asks what would your podcast be if you were to start a podcast?

Lane Shackleton (01:24:40):
I like that.

Lenny (01:24:42):
So feel free to steal it.

Lane Shackleton (01:24:45):
I sometimes do a version of making them explain it two different ways after, and making the candidate explain it two different ways and saying, "Okay, now you have to explain that to your grandparent." And then now you just told me about sewing or some hobby of yours. Now sell it in its most technical form to someone who knows everything about this particular topic. And so it's kind of fun to also see the range that people can operate.

Lenny (01:25:13):
Awesome. What is a favorite product that you've recently discovered that you really love? Either digital or physical, anything that comes to mind?

Lane Shackleton (01:25:21):
A few. I'm becoming a real sleep nerd, so those eye masks that cup around your eyes, I love. Obviously in the tech world, ChatGPT. I got really obsessed with tennis during the pandemic. There's a product called Swing Vision that's really good. It basically cuts up your match into different ... All of your forehands or all the longest rallies or all that and uses AI to do that. There's a corresponding meditation app to the book Waking Up that I really like. That one's a very good one.

Lenny (01:25:57):
We live not so far from each other, so we got to play some tennis and I could check out this very cool product.

Lane Shackleton (01:26:01):
Yeah, let's do it.

Lenny (01:26:03):
You're on. That'll be our sequel. Just our game. Next question. What is a favorite life motto that you either repeat to yourself often, like to share with people around you, share with your kids maybe?

Lane Shackleton (01:26:16):
I don't know if it's as motto as much as it's just a way of being. It's essentially the present moment is all that we have. Realizing that our attention is very often on the past or the future and in so many ways the present is where it should be always. And so I think that that is something I think about a lot. I think maybe more broadly, I had a mentor who roughly said a version of make things happen, and so I really try to apply that to anything that I do. If that's work or life or sports, I try to be the person who creates momentum and positive change and progress. And so I think that that's generally a good motto to live by.

Lenny (01:26:58):
Beautiful. What is the most valuable lesson that your mom or your dad taught?

Lane Shackleton (01:27:03):
My mom's a psychologist and a professional counselor so certainly active listening. Maybe the tech version of that or the modern version of that is steal manning someone's argument, being able to repeat back to someone what they said in a better form, more clear form. So yeah, she's an amazing woman. Taught me a lot about listening.

Lenny (01:27:28):
Final question. You were a guide in Alaska helping people climb. If someone were to pursue climbing, is there a tip or a lesson or something that you think people should know to get better at this or to know before they go down this route?

Lane Shackleton (01:27:43):
There's a saying, which is the safest climber is the one who knows when to come down essentially. And I think that there are many times that you have to put your ego in check and come off a mountain or come out of a climb because it's not quite as safe as you thought it was. So I think that's maybe one. I think the other is it's probably not a one-way door. So I think in many ways you can do climbing and you can do some of these outdoor pursuits on the side, or you can always come back from them. So it's maybe not as big of a choice as some people think it is.

Lenny (01:28:24):
Lane, I said at the top of this episode, Coda has one of the most thoughtful product teams out there, and I think it'll be clear to people after listening to this why that's the case and where it trickles down from. Thank you so much for being here. Two final questions. Where can folks find you online if they want to reach out and ask you any other questions? And how can listeners be useful to you?

Lane Shackleton (01:28:42):
I'm on LinkedIn and Twitter and I have a Substack. We'll be releasing that handbook for product teams that I will probably post on Substack. And in terms of useful to me, yeah, give Coda a try. Give us feedback. I love hearing from product people all over. It's one of the bright spots in my day to hear all the creative rituals that come from this community. You've created just a legendary community of people and so they always give very thoughtful feedback so I'm very open to all of that. And yeah, thanks for having me.

Lenny (01:29:22):
Awesome. Lane, thank you again so much for being here.

Lane Shackleton (01:29:25):
Thanks.

Lenny (01:29:26):
Bye everyone.

(01:29:29):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Career frameworks, A/B testing, onboarding tips, selling to engineers |  Laura Schaffer (Amplitude)
**Guest:** Laura Schaffer  
**Published:** 2023-03-09  
**YouTube:** https://www.youtube.com/watch?v=UMAmj1bciww  
**Tags:** growth, retention, activation, onboarding, churn, metrics, prioritization, mvp, iteration, a/b testing  

# Career frameworks, A/B testing, onboarding tips, selling to engineers |  Laura Schaffer (Amplitude)

## Transcript

Laura Schaffer (00:00:00):
... Like the dead of the night. And by that, I mean 7:00 PM or something on. I'm pretty sure it was a Friday. We just asked for forgiveness and put these questions into the silent flow and ran as Navy test with a small group. And I'm fully expecting, "Okay, this is going to hurt our numbers, but maybe it won't be so bad and I'm going to be prepared to advocate the power of this data that we're getting." And I was totally geared up thinking about written, started to write the framework for how I wanted to surface this. And we start to get the data for this thing. I'm not kidding, an improved conversion. There's no personalization, nothing past it, just the questions. An improved conversion by like 5%, just improved signups. And it was one of those like, "What? Okay, what is going on here?"

Lenny (00:00:50):
Welcome to Lenny's Podcast where I interview world-class product leaders and growth experts to learn from their hard one experiences building and growing today's most successful products. Today my guest is Laura Schaffer. The week we recorded this chat turned out to be Laura's first week in a new gig as head of growth for Amplitude taking over for a previous legendary guest, Elena Verna. Prior to Amplitude, Laura was VP of product and growth at a company called Rapid. Before that, she spent over seven years at Twilio as Head of Growth and PM lead of the growth platform and experimentation platform at Twilio. In our conversation, we dig into Laura's career growth framework and the importance of carving your own path versus waiting for one to be carved for you. We also get into a bunch of tactical and surprising advice around running experiments, making decisions on gut versus data, developing your growth strategy and how to sell your product to developers. Laura has a wealth of wisdom and I learned a lot from our conversation. With that, I bring you Laura Schaffer after a short word from our wonderful sponsors.

(00:01:55):
This episode is brought to you by public.com who want to tell you about their new treasury accounts, which earn a 4.8% yield on your cash. That is higher than a high yield savings account, while still being backed by the full faith and credit of the US government. Treasure yields are at a 15-year-high. But buying US treasuries is super complicated. If you go to a bank or navigate an ancient government website, or at least that was the case. Now you can move your cash and the US treasuries with the flexibility of a bank account. You can access your cash whenever you want, even before your treasury bills hit maturity. There are no hold periods, no settlement days. Just a safe place to park your cash and earn a reliable yield. Public will automatically reinvest your treasury bills at maturity so you don't have to do anything to continue growing your yield. And you can manage your treasuries alongside stocks, ETFs, crypto, and any alternative assets. Do all your investing in one place and earn 4.8% a higher yield than a high yield savings account only with a treasury count at public.com/lenny.

(00:03:02):
This episode is brought to you by Eppo. Eppo is a next generation AB testing platform built by Airbnb alums for modern growth teams. Companies like Netlify, Contentful, and Cameo rely on Eppo to power their experiments. Wherever you work, running experiments is increasingly essential, but there are no commercial tools that integrate with a modern grow team stack. This leads to waste of time building internal tools. We're trying to run your experiments through a clunky marketing tool. When I was at Airbnb, one of the things that I loved about our experimentation platform was being able to easily slice results by device, by country, and by user stage. Eppo does all that and more delivering results quickly, avoiding annoying prolonged analytics cycles and helping you easily get to the root cause of any issue You discover. Eppo lets you go beyond basic click through metrics and instead you turn north star metrics like activation, retention, subscriptions and payments. An Eppo supports test on the front end, the back end e-mail marketing and even machine learning clients. Check out Eppo at geteppo.com, get E-P-P-O.com and 10 x your experiment velocity.

(00:04:15):
Laura, welcome to the podcast.

Laura Schaffer (00:04:18):
Thanks, Lenny, it is so great to be here. Thanks for having me.

Lenny (00:04:21):
It's great to have you. So I asked Elena Elena, Elena, I'm not even sure how to pronounce her name, maybe. What is it?

Laura Schaffer (00:04:21):
Elena. You got it.

Lenny (00:04:27):
Elena. Okay. Okay. I think I've said it wrong all the time. All this time. Okay, Elena. So I asked Elena Ferna, who's a popular guest on this podcast who I should have on this podcast and you are the first person that immediately came to mind. And so I'm really excited that we're doing this and that you agreed to be on.

Laura Schaffer (00:04:42):
Well, she's the best and I'm really happy that she referred me because I'm just stoked to be here. So thanks for listening to her guidance.

Lenny (00:04:50):
Absolutely. And it's a cool time to be chatting. You're the newly minted head of growth at Amplitude and so congrats, first of all.

Laura Schaffer (00:04:57):
Thank you. Appreciate that. Yeah, this is my day two and a half here. So very [inaudible 00:05:04].

Lenny (00:05:06):
Wow, you're a veteran.

Laura Schaffer (00:05:06):
Yeah, right.

Lenny (00:05:06):
I love it. Some companies, there's a little percentage of that shows you how many people have joined before you and I wonder what that percentage already is [inaudible 00:05:12].

Laura Schaffer (00:05:12):
We had that in Twilio and I got pretty, pretty high up there after a while. We had a stack rank and a spreadsheet. Yeah, but it is funny. So wherever that thing exists in Amplitude, I am right fresh there at the very bottom.

Lenny (00:05:25):
So what was the number you got to Twilio? Any, do you remember?

Laura Schaffer (00:05:28):
Yeah, no, I was very proud to crack the top 50. That was my claim the same because as people left, you move up. Right?

Lenny (00:05:36):
Right. Yeah, it's bittersweet.

Laura Schaffer (00:05:39):
Well, yeah, right. On one hand it's like, "Ooh, very cool." And one of the OGs on the other hand, it's like, "Oh my gosh, this person's [inaudible 00:05:47]. Bummer." It's a shift, but I'm excited about it for sure.

Lenny (00:05:51):
So you have this new exciting role and I thought it'd be fun to start to chat about career growth and just how you think about career growth. I know you have a framework of how you think about your own career growth and clearly it's worked out, so I'm curious to hear about it and see how it could be helpful to folks that are listening. So yeah, can you just tell us about how you think about career growth?

Laura Schaffer (00:06:11):
Career growth is definitely not a straight lineup, but there's definitely some frameworks and methods that have worked really well for me. And I think to dive into it, it's first good to just talk about the one that I most typically see people use to try to grow their career and why that can be a little problematic, which is that I see most people try to work really hard the job that they have within the role that they have at a company. Do whatever you can to grow there, show your manager all these things. I see people keep spreadsheets, it wins. So it can come up with performance reviews. Maybe you try to get better advocating for yourself, maybe try to get peers to notice or your manager's peers. And that's all good. It's all stuff.

(00:06:52):
But the problem with it is that you're limited to what your manager's ability is to advocate for you, to promote you. And you're also limited by the explicit trajectory of your role at that company and where the there's room for that or not at the company. And then often that perception can sometimes be a little bit in contrast to what your perception is. And also other things that happen, your manager leaves and then you have to restart with someone else. So the method that I use tries to take that power back a little bit. And something that I learned really early on in my career, I was very lucky to learn by accident, was at a company called Bandwidth, which is my first real job. And Bandwidth is now a public company and they've done all kinds of crazy amazing things.

(00:07:38):
But I joined when it was just 50 people and I actually joined in sales and I was just hungry to make it succeed and grow and bright eyes and everything, first real job. But I realized after a few months of being in sales that I was often repeating the same thing over again, using the same thing to sell over and over again. And it's like, gosh, this isn't ideal for the customer because [inaudible 00:08:04] call me and ask these questions and get these answers and all this stuff. And it's not ideal for the company because they're paying commission on this every time. That's not going to be efficient for our growth. And because we were small, I was able to catch our GM and I was just like, "Hey, I've noticed this pattern where I'm repeating things over and over again and they're asking the same thing.

(00:08:29):
I think we should put that online. I think we should make that available so they can just see it and then buy it," because we had an online checkout process. And I was expecting him to be like, "Oh, well, I know it's important but for this [inaudible 00:08:46] another, we need to do it this way, and obviously you've thought all about it." And thinking, "Oh, I'm going to come in this new person, he's just going to help me understand what I'm missing here." There's a little bit of that that I was expecting. And he goes, "Wait a minute, tell me more about that. What do you mean?" And by the end of the conversation he was like, "Hey, why don't you go do that? Why don't you go build that experience? Why don't you put that stuff in a self-serve flow?"

(00:09:06):
And we called it e-commerce manager and it was like got a growth before this growth, this is like 2010. And that moved me into a totally new position. And the main learning that I had from that was, which really took life at Twilio and absolutely worked for me there and I'm happy to talk about that too. But the core that learning was, your executive team and executive teams at companies are often very sharp, but the nature of their day-to-day just does not link them with customers.

(00:09:34):
And that means that over time, especially as a company grows, they often lose access to some of the best insights and in the heartbeat of the people who they're providing value to in contrast to folks that are closer to the problem. And so that means that your superpower is in really pulling those insights in and bringing them to life, staying close to the customer. There's not a single leader or executive that isn't going to be stoked to hear about valuable customer insights that highlight problems they might not be seeing. And there's a lot of those. So especially when they align to North Star metrics, those ones are the powerful ones. That was the way that I grew my career at Phil and I'm happy to share that journey too.

Lenny (00:10:18):
Yeah, it'd actually be cool to hear maybe another example of that. But I think an interesting thing that comes up for me here is sometimes you may have an awesome idea and it may not immediately happen. It may not be like, yes or let's move on, that's right, immediately. And I think it's important to just recognize they're not going to follow all your ideas, but they're always looking for better ideas. And to your point, they may not have the information that will lead to an idea that you will have because you're on the ground dealing with real problems, day-to-day. So I think it's important to recognize you're not going to always get your way and that's normal.

Laura Schaffer (00:10:52):
Yeah, totally. And it's almost like building up your individual brand a little bit. And I think one of the most powerful and accessible ways is learning about your customers. There's always those people at companies who's like, "Oh, well, she just knows our customers or he just knows our customers, they just know our customers. They just know." And it's like, "Well, how?" "They just know. Let's ask that person. Let's get their feedback." And those people often have a good amount of brand recognition of powers within the company and they're often thought of when the company needs to do something new or different or if someone is hiring, maybe they're thinking about that person for a cross team thing.

(00:11:31):
So it's one of the ways that you can build that brand. And again, I think it's a sweet spot because it's something that is very valuable to everyone, all the way up to the most senior leaders, which we can talk about here in a minute. And so it's going to be valuable for you in a valuable tool no matter where you're at in your career. And that's not always an immediate payoff, but it often does give you a trajectory outside of just your role and just your manager. It gives you something a little bit broader.

Lenny (00:12:05):
So maybe a simple way of describing to mirror back what you're saying is carve your own path. Don't necessarily assume your managers will give you the path that makes most sense for you or even give you the biggest opportunity. Just propose, "Hey, I think this might be a better opportunity and I'd love to pursue it." I'd love to hear the Twilio example if that's generally-

Laura Schaffer (00:12:25):
Yeah. So when I joined Twilio, there was no growth team at all, not even a breath of it. I joined in product marketing and I was leading our product marketing for our messaging lines, but I followed the same guy that I just mentioned. I made it my own personal policy to like, hey, I'm going to do my job. And I'm going to do well, I'm going to keep notes of things I'm doing well and all that stuff because it's good, but I'm also going to get to know our customers. And I'm going to get to know our customers really well and I'm going to pay attention when I'm connecting with them, not just about the space I'm in, but just broadly what are some of the pain points and things they're articulating that are relevant to the business and what we're trying to get done.

(00:13:00):
And one of the things that came up was that users were struggling and folks were struggling to get started and use Twilio. And that contrasted so deeply to some of the things that our executive team was saying and had high conviction in our company had high conviction, which is that Twilio was so easy to use. In fact, it was top three things about Twilio that we were really trying to get out of their brand. Were so easy. Developers love us, they say we're so easy. And there were tweets coming all the time, developers saying like, "Oh my gosh, they got started in a couple of minutes." So there's all these things that made that compound and made that conviction stick. But as I was talking to customers, I was hearing a very different story and it made sense as we were penetrating new markets, adding more products, we were adding complexity and we were pulling in folks who were a little bit less motivated and those things contributed to people saying this is difficult.

(00:13:55):
And so at the time, this wasn't a 50 person in where I could just go to the floor and go to someone and be like, "Hey, there's this thing I heard about, I think we should do something." But there was another tactic that I could take, and I just started sharing a voice of the customer report. I started sharing my insights, started writing down and just sharing them. And it became with digest and eventually people were like, "Hey, can you share it with me? Can you share with me? Can you get on your list? Can share with me?" And this was in a few months of me joining, I was doing this. And then that turned into, "Hey, you should host a quarterly voice to the customer session or for all of product." And this was a request that was coming from some of the senior leaders at the company.

(00:14:33):
And when our Jeff Lawson is our CEO at the time heard about, he started attending too. So now in the session I started pulling in other people's insights too, because now they had a forum for this. I could do that and have people send that to me and I could compile it and all of these things. So then this established me as that person who knows about the customer even after short tenure. And then when came time to do annual planning that year, and I joined in 2014 at the end, so this is 2015, I pitched this idea, "Hey, we think that it's easy. It is not. Here's data that I have, the information that I have and I think that we need to start a growth team here and that needs to be a core focus." And I was able to bring in a really critical partner to that and other folks who could support that because I had built up some of that trust.

(00:15:28):
So by the time I was making that pitch, I had someone on Andre Crow who was the seventh hire at Twilio and got to number three on that spreadsheet or whatever who was really close to the CEO being like, "Yeah, we desperately need this." I'm seeing this. He led a website, he basically created the Twilio brand and he led all the website stuff and he is like, "Yeah, we definitely need this." So not only did I have that little bit of trust from the executive team, but I also had folks who were just trusted on their own advocating and supporting this that I was doing. And so it was approved just almost very easily. I put stuff together for it, but it was the meeting before the meeting had already been done by this other thing. So it helped me create the growth engineering, growth product team at Twilio.

Lenny (00:16:14):
I love just how proactive your advice is here. There's a lot of people that don't do well and then just like, "Oh, I never had the opportunity or I kept got looked over all this time." And I love that there's all this just like, here's things you can be doing to get in front of people to provide value, to just create opportunity for yourself. Any other advice along the lines of just like, here's the things you could do for yourself versus waiting for someone to come and give you opportunity?

Laura Schaffer (00:16:42):
Yeah, I think that's the most easily actual because to do all of our jobs, we need to know customers, we need to know about customer insights, product, we need to know. But then also customer facing teams, social, those want to crack into product. Your insights are extremely valuable. You're talking to customers every day more about their problems and their pain than a lot of other people do. And so that is by far and away to me the most powerful and accessible by anyone in any role in any space. But I'll also say that that broader concept of just, hey, there's things that, and things of value that you know that others can benefit from at your company and building your brand as someone that is supportive, smart, creative, able to solve problems, make sure that you're sharing that. And so maybe you're really freaking good at communicating with brevity.

(00:17:35):
I suck at that by the way. So more powered anyone that can do that, I'm actively working on it. So share that. Go to your general Slack channel or whatever and just be like, "Hey, just wrote some tips for how to do it, some ways that I am good at this." And those kinds of things can really go a long way towards people starting to view you as an SME and not just the space that you're in, but in broader areas. And that can always present open doors for you and other people are looking up to you and seeing you, someone who's strong in ways outside of just the role that you're in.

Lenny (00:18:07):
SME is a Subject Matter Expert, is that right?

Laura Schaffer (00:18:10):
Yes. Thank you for unpacking my acronyms. That's another thing that I am actively working on.

Lenny (00:18:16):
I got you. I'll be on the lookout.

Laura Schaffer (00:18:16):
Yes.

Lenny (00:18:19):
Maybe one last question along these lines is do you have any advice for framing the proposal, framing an opportunity to your manager, higher ups that you see has worked best broadly?

Laura Schaffer (00:18:34):
Yeah. Yeah. And one thing I want to say too is with this stuff, I don't think that it necessarily does counter to what your manager's doing. It's more supporting them. I've done this stuff and then it's helped my manager promote me. So it's not necessarily, "Oh, we'll do this if your manager's failing you." Or they are not the boarding you or they can't support you. It's more like do this because this is going to be an accelerator for yourself irrespective of your manager.

(00:18:55):
But then also it'll be an accelerator for your manager in supporting you because one of the things that comes into play a lot when managers figure out promotions and doing those things is they'll sit in a room, often calibrations and with a bunch of people, and it makes it a lot easier when those people have had some access or exposure or whatever to you in a positive light. So these things can all run with your manager and not against, but it's just another way of you taking back the ability to build that momentum instead of relying on all of that going through one single other person.

Lenny (00:19:33):
And what I like about your second example is you just did it. You just started doing that tenant report for the company. It wasn't like, "Hey, I have a proposal, here's what I think you should do. Should we do it?"

Laura Schaffer (00:19:42):
Exactly.

Lenny (00:19:42):
It's just like, yeah, just do it.

Laura Schaffer (00:19:44):
Yeah, ungate your knowledge I think is the buzzword that I'm hearing.

Lenny (00:19:52):
Mm. Never heard that.

Laura Schaffer (00:19:52):
I think that's an Elena, see how many times we can bring her up. But you can do that within your own company. Everybody is skilled at things that they aren't explicit to their role or their space. And I think that ungating that opens opportunities. And if you're not sure, then go to my favorite go-to, which is talk to customers, get insights. Those are incredibly valuable. So rarely do people share those when they find them. So be the person that does that.

Lenny (00:20:21):
Another area I want to chat about is experimentation and growth and data, which makes sense if strong perspectives is on being the new head of growth amplitude. So maybe we start with experimentation. You mentioned that there's a really interesting surprising result in an experiment you ran at Twilio that maybe changed your perspective on experimentation and what you think might work and not work.

Laura Schaffer (00:20:45):
A hundred percent. Yeah, I'm through a fortune of two mind-blowing experiments that really shifted the way that I think about growth. So one of them, one of my favorite ones happened very early on at Twilio. So after I created this growth team, one of the things that I saw as to me an issue was that under signup flow, we just asked people for a username and an e-mail, like a password, and that was it. And that's actually relatively common at the time. This is a while ago now, everybody is [inaudible 00:21:16]. But we didn't, and actually there was a lot of existing conviction around that. I was like, "Hey, we retarding developers. Developers, they just want to do, they just want to get their hands on things. Don't put anything in their way, it's going to be disastrous. We don't want any shenanigans here with these folks, let's just let them in the gates."

(00:21:33):
But to me this was a really big assumption to make and a very costly one. It's like, okay, if that's the case, we're not going to know anything about anyone. And we didn't know who was signing up, we didn't know what they wanted to do. And that hurt our ability to understand how people were performing from a quantitative perspective. We were a little bit lost with prioritization. There's a number of implications here, but it's obviously a very contentious space. So this is the very first thing that I did and the first experiment that I ran. I did some research to understand say, okay, what are the most important questions to answer? What would I do really, really need to know? And it was stuff like what language are you coding in, what's your use case? What product you want to use?

(00:22:14):
And then there's one around, are you developer at all or were you use something else? Because there is rumors that we're having, not just developers sign up, which is this whole other interesting story. And I think of these questions that would also potentially be things that our developers signing up would understand why we're asking that it would feel natural. But anyway, again, adding anything to the signup was very contentious, but I really just wanted to get a little bit of data on it. So I wanted to run a test. I didn't have a team, I didn't have an engineering team yet and none of that stuff had built out. It was just me, myself and I. But like I said, I had started to build a little bit of trust and [inaudible 00:22:50], Andre, who I mentioned earlier who, because he was early employee and he had access to everything, one of those people, and he also was supportive of this and had similar haunches.

(00:23:03):
And so like the dead of the night, and by that, I mean 7:00 PM or something, I'm pretty sure it was a Friday. We just asked for forgiveness and put these questions into the signup flow and ran as Navy test with a small group. And I'm fully expecting, "Okay, this is going to hurt our numbers, but maybe it won't be so bad and I'm going to be prepared to advocate the power of this data that we're getting." I was totally thinking with written... Started to write the framework for how I wanted to surface this. And we start to get the data for this thing. I'm not kidding, an improved conversion. There's no personalization, nothing past it, just the questions. It improved conversion by 5%, just improved signups. And it was one of those like, "What? Okay, what is going on here?" And I actually dug into it, and what I found from just talking to a few customers once through the flow, I'm just learning about [inaudible 00:24:00] about it.

(00:24:01):
It was actually for folks, it was comforting. When you think about it, when users are signing up for your product for the very first time, it's new. This is new, that means it's scary. They're expecting it to be difficult. They're anticipating that there's going to be friction and challenges and that they're not going to figure it out. Almost like looking for the bogeyman. And that's the headspace. It's often the headspace that any of us are in when we're doing something new for the first time like ooh, this could be very challenging. And so by putting in these questions it's like, what's your language? It's like, "Oh, I do. I code a JavaScript and I can select that." Well, that's something I'm uncomfortable with. That would make my journey easier. Like "Yeah, bingo. That's my use case. Okay, I'm in the right place here."

(00:24:51):
It was actually giving folks something comforting and challenging the notion that this was going to be difficult, just the questions because it was aligning to some of the things that they were organically thinking about, which is what if they don't support my language? Or can I even do this use case I want to do? And so it was just a really interesting, the takeaway for me for this, the really interest takeaway was the psyche of the user is so, so critical. That's just as important as understanding your product and the broader market you're applying to and all those things. Just the psyche of users, new people doing things for the first time in your user flow, understanding that is powerful. And the simple catchy thing I say is that ultimately the learning here is, bad friction is bad, and good friction is good. There's no such thing as it being simple. It's just all friction is bad, which is what I had assumed going into this.

Lenny (00:25:50):
I love that you were new to Twilio and you just year-load an experiment to production.

Laura Schaffer (00:25:55):
Year-load. Yeah.

Lenny (00:25:56):
That's a big move.

Laura Schaffer (00:25:58):
It ended up being very helpful for everyone. I shared the insights from it and all these things. I've shared the [inaudible 00:26:05].

Lenny (00:26:05):
And [inaudible 00:26:05] conversion.

Laura Schaffer (00:26:08):
But for sure, use such processes with caution for sure. Yeah.

Lenny (00:26:08):
I love it. It's amazing.

Laura Schaffer (00:26:15):
That the right way to do [inaudible 00:26:15] advocating for the engineers here is the right way to make any changes in production is through or with the approval of engineering, but it was the right move overall and definitely helped business, so yeah.

Lenny (00:26:33):
Yeah, I love it. No, that's great. I like that move. I think we need more of that probably. I want to dig into what you actually... So what is it you changed, you added how many questions and then what were the questions?

Laura Schaffer (00:26:37):
There was a question around what language are you coding in? And then as an option to that, it was like, "Oh, I'm actually not coding, I'm not a developer." So for us, it actually gave us two really, really interesting data points. One was how many developers versus people who are not coding or in our flow? And then what language of the coding, which was massively helpful not just for growth and onboarding, but our documentation team, dos team. Would that end up being a critical way for us to gauge trends over time and catch things before whatever reports would come out at the end of the year, what people are doing, you start to see it. And then also product. What product are you interested in using? That was very critical for knowing the basics of how to organize someone's onboarding. Are you doing SMS? You're doing voice? To 281 or whatever. And then use case in use cases, you're doing a appointment reminders or are you doing a autoresponder or are you doing anonymous communications for a dating app or something. Right? So those were the very first questions.

Lenny (00:27:39):
Wow, okay. So it was four dropdown questions and that increased conversion. I love these examples where friction and increased conversion... There's so few of them. You hear about this could work and it's rare. And so what did you take away? What's the pattern you took from this? There's the idea, it's good friction, but is there something that you're like, what is a sign of this is going to be good friction?

Laura Schaffer (00:28:02):
There's still alleviated a problem. They alleviated the problem they had where they're coming in and worried that it was going to be difficult or that they weren't going to be able to figure it out, they weren't going to be able to get their footing. And I'd say that that's not unique to Twilio. That's something that I think users experience at any front door, at any company, any signup beginning the signup loads, it's like, "Here we go, buckle up." Especially when it's in a work context and there might be extra pressure on you to succeed or for you to make as an accurate assessment. So I think that psyche of, "Okay, am I in the right place? Is it's going to do what I need it to do? Can I figure it out? Am I capable?" These are extremely common things for people to feel when they're signing up.

(00:28:48):
And so certainly, that I think can carry out to any place. I'd encourage absolutely everybody to be putting those experiences within their early onboarding, not just for you selfishly, so you can learn and segment them appropriately, but also so the user can feel more confident as they get going and like, "Hey, I'm in the right place. This is going to do what I needed to do." But I think that the carry over there is just the psyche of the user and just being so aware that it's not so cookie cutter as, "What is the problem my market experience is and what can my product do to help them?" There's also this other thing in the room which is so important to people's success, their ability to succeed with your products and your self-serve experiences, which is, what is the mentality and the psyche of the person at the various stages in your journey?

(00:29:37):
And if you're not incorporating that or addressing that, you will absolutely miss things or things will fail and you'll be very confused as to why. We had a great experiment that I'm happy to talk about where same concept, a totally different situation, which is later in onboarding. One of the things that we tried to do over time to make Twilio less complex was to offer steps like, [inaudible 00:30:08] onboarding, welcome step one, here's what you want to build. Great, we all know that now, "Okay, step one, go do this thing. Step two, go to this thing. Three, this thing. Four, this thing. Five, bam, you're live, congratulations, aha," all these things. So we shipped that, got that out there and I was like, yeah, it was improved conversion. It wasn't like that great. It's like, man. We went from there being absolutely nothing, "Choose you're adventure, figure it out, go figure it out. Good luck." To this prescriptive thing. And it wasn't converting [inaudible 00:30:37].

(00:30:38):
So to talk to some users and there wasn't anything particularly obvious that was coming out as to what the issue was. It was like, "Oh yeah, Let's go to step one." And we did mock the people. "Okay, now I know, I do step two." But there was one thing that I was hearing that was coming out that feels like something, and that was the telephone number, the telecom part. Developers when they were coming into Twilio, it was things that were familiar to them. APIs, the language they're coding in, code samples, documentation, things like the bogeyman, the things that would psychologically trip them up, telecom, phone numbers. These things that just were completely out of the zone of anything that they'd ever worked with before, especially earlier on in Twilio's journey.

(00:31:28):
But even now, right? Telecom's very different beast for most developers. And guess what was step one? Get a phone number because that's step one. Anytime that anyone's trying to teach one to use Twilio one-on-one, always going to sit down, ask and be like, "Okay, here we're going to go get a phone number and configure it." And that's what anyone every time will do. However, in a self-serve experience, when you don't have that safe person sitting next to you being like, "Don't worry, it's going to be okay, I'm going to take you through this crazy telecom journey." They're on their own, but that's psyche telling is them like, "Oh my god, telecom. Well, I can't do that. That sounds scary. We're getting a phone number configured. Whoa, I'm out of my debt."

(00:32:01):
And so what did we do to test this out? Test out whether that was the issue? Actually, and it's first we're in the MVP. They kicked them out of the portal entirely and put them into a docs page where we could manufacture an experience where the first thing they saw was code and they're in the docs safe place, the language that they're coding in and then snuck in there.

(00:32:26):
It was like, "Oh, get a phone number, let's go configure it." Not as step one, not as the leading thing, but embedded. And the analogy I have for this is pilling a hot dog. So if anyone's got a dog or an animal you have to feed a pill to, it's like you can't just feed the pill to the animal, it's never going to happen. But if you shove it inside of a hot dog, which looks good and that's exciting, then you can get them to consume it more easily. And so this was-

Lenny (00:32:53):
Yeah. We do peanut butter, that's [inaudible 00:32:55].

Laura Schaffer (00:32:55):
Yeah, exactly, right? Yeah, hot hotdog, peanut butter, all that. You bury it. You embed the scary unpleasant thing. And so that's what you said with the phone number stuff, that telecom stuff. And guess what? Even though we're a good amount of the console and they're going off and we had no easy return button, it converted better because we were addressing the big problem that was there at the time, which is their psyche. They were not ready to come in and immediately thrown into a phone number experience. That was letting the bogeyman and out to party and that's not what was going to work. We needed to put that bogeyman pill and the hotdog.

(00:33:31):
And so then once that validated, then we can actually go through the business of putting that into the onboarding float correctly and then that could be even better. But so again, the psyche of your user is such a critical thing to be thinking about. And if something very logical isn't converting well sometimes, it means that you're battling against the psyche of a user and you want to take a step back and think about and learn about where someone is psychologically in your space.

Lenny (00:33:59):
Feels like you had this experiment that was a complete redesign of the onboarding flow and that didn't work. And then your second attempt was a different approach that's like a full onboarding flow. And I'm curious, do you have a take on just when you run experiments? And it's something we dealt with a lot at Airbnb in other places is like, do you just redesign the whole thing or is it better to iteratively work from where you're today and just experiment piece by piece towards some future much better experience?

Laura Schaffer (00:34:26):
Here's what I would say to this is that from a high level, it's always going to be better to be iterative. And the reason that it's better is that roughly 80% of the times, ORs in the time are hypotheses and the things that we believe will be true [inaudible 00:34:42]. And this is amazing. There's an amazing article out there I'm happy to share with you so you can put in the show notes.

Lenny (00:34:48):
Yeah, absolutely.

Laura Schaffer (00:34:49):
That really takes a scientific approach to proving that out. Companies like Netflix and Microsoft, there's over and over again 80 plus percent. Some companies say 90% of things fail. And so the closer you get to something that you go bear your head in the sand or go into an attic and build something for six months and ship it, the more likely it is that you are going to ship the 80% wrong stuff.

(00:35:17):
Whereas the more iterative you are, the more likely that you're going to catch it sooner. And failure doesn't have to be a wall, it can be a compass, it can be the thing that leads you to the right thing. And so you always want to as best you can, get stuff in front of customers so that you can get that compass and get that compass activated, know where to go.

(00:35:40):
So that means doing ugly things. I tell my teams all the time, if it's not embarrassing, you've gone too far. Got to be embarrassing. The first thing, that was embarrassing, kicking people out, onboarding, spend all this money and whatever to get them into your center flow, and then the first thing we do, get out of here. That's nuts. But if it hadn't validated, that would've been a very cheap but very valuable learning. Instead, it was a very powerful cheap learning in the other direction. Okay, now we know we can invest in it. We know that's the right thing to do. So always better to be iterative so that you are letting failure work for you instead of having it be a trap that you fall into.

Lenny (00:36:22):
I know that you just shared as per experiment, you're probably wrong 80% of the time. In my experience, launching a halt redesign is as negative a hundred percent of the time. I've grown weary to avoid that as much as possible, which is like, you know that, you're taught that as you go into growth and product, but you're just like, "Nah, come on, let's just make it awesome. Just redesign this whole thing." Especially your designers is always like, "No, let's start again. Let's make it amazing." But it always ends up being negative and you're like, "Okay, well, it's too late now we got to launch this thing, we don't have time to start again."

Laura Schaffer (00:36:52):
Well, it's funny, in the articles, and you'll see it was written by somebody from Microsoft who built Implementation platform and did all these cool things, as he went into actually trying to apply a scientific method of figuring out how often people are wrong about their hypotheses and what they're planning to do. He's like, "I wonder if that applies to us here at Microsoft." Even for him, that question of [inaudible 00:37:16]. And I think it's challenging when there's a lot of smart people in this space doing things and it's very difficult to think, "Gosh, am I really wrong? 80 plus, 90% of the time?" But when you think about it, makes total sense because what has to happen for something to be successful? You have to understand the problem perfectly. You have to then understand who's having the problem perfectly, the customer. At what time they're having the problem.

(00:37:43):
Then you've got to put the right solution in front of them to solve that problem. Maybe you've got the problem, all that stuff, but your solution something off. Or maybe your solution is right, but maybe it's just not presented, it communicated in the right way. You could have any one of those things off and it's not going to succeed. It's not going to have the metric impact you're expecting it to have. So in that context, it's almost like incredible. We do succeed 20 to 10% of the time given everything that has to line up. And so I think it's one of those things where you really want to go into it embracing that, "Okay, this isn't about how smart I am or how good my team is or any of that stuff. It's just the logic of this is challenging to get it right and let's embrace that and let's lean into that knowledge and make it a part of our strategy," instead of finding against it.

Lenny (00:38:39):
Have you found anything that helps you increase those odds or is just, this is the way of the world and you probably can't significantly increase the chances your experiment works out?

Laura Schaffer (00:38:51):
So here's the thing, I think there's very little that we can do to make that space easier. All those things have to be figured out. And so I definitely think that everybody is going to be in a space where their original ideas, untested ideas are going to be around that hit rate. However, the way that you go about validating those can be totally different and you can be very fast about validating those ideas and that's the key. And AB testing is one of the most expensive kinds of ways to validate an experiment. It often requires design and engineering and the PM or growth person or marketing person who's crafting it. All these things are investments that take a lot of time even for simple thing. And then you have the time factor, how long's the thing I have to run to have an impact?

(00:39:47):
So all of that is extremely expensive. And so I think the key is to just think through, "Okay, what are the things I can do to quickly validate what these ideas are that we [inaudible 00:39:59]?" And you can do that with painted doors, which is where you test rate the concept and the idea before it exists versus the actual experience. You can do mocks. If you've got a designer, create those mocks for that experience, put it in front of people, see how they engage with it. That can be so powerful.

(00:40:16):
You could invalidate tons of hypotheses at that state. The only things you want to get to that deep AB testing environment or ones that have been vetted along the way. And that way, you reduce your fail rate, because you're failing faster by using other methods. So I think I more advocate for that side. Let's fail fast by using those tools rather than figuring out a way that you can rise above where everyone else is operating and figure out ways to solve all that complex stuff better because that's going to be challenging, but you can always get better at experimenting and validating things faster.

Lenny (00:40:59):
This episode is brought to you by Writer. How much hype have you been hearing about generative AI? So much. But how do you take it from a shiny toy to an actual business tool that helps you do your actual job? Writer is an enterprise grade generative AI platform built specifically for the needs of businesses and already widely deployed at world-class brands like Uber, Spotify, HubSpot, and UiPath. With writer, you can break through content bottlenecks across your organization from marketing webpages to sales e-mails in product messages to creating high quality on-brand content at scale.

(00:41:34):
And unlike other AI applications, writers' training happens securely on your data and your style and brand guidelines that you provide specific to your organization. The result is that you get consistent content in your brand voice at scale. Get AI that your people will love for a limited time. Listeners to Lenny's podcast and get 20% off if they go to writer.com/lenny, that's writer.com/lenny.

(00:41:59):
Where do you find the best ideas come from for driving meaningful lift? Is it gut instinct type and experience bucket or is it data telling you like, "Hey, or here's a huge opportunity," in your experience?

Laura Schaffer (00:42:15):
I'm a very data-driven person. I self-describe and think of myself that way. In large part because of that, I feel you have to be constantly checking yourself and data is a really great way to do that. But I definitely think that I would be described as someone who's going more by their gut when looking at date end results just because of the way that I approach it, which is I'm very comfortable and very common in using qualitative responses and things like that and supplement to quantitative data to make a decision and that puts less of a burden on the quantitative to really make an assessment of whether something was working or not.

(00:42:51):
One of the things I see, I think sometimes goes against what other folks do, although I'm seeing things shift a little, is that 95% confidence rate. My background in college, I was in a lab running experiments or really publishing two journal and stuff and we had to have that 95% confidence rate, had to because the things that were coming out of the lab and being published were influencing things like how we do education and how we understand how bias works and when it shows up and therefore how we can combat it.

(00:43:23):
Things were wrong. And sending a bunch of bologna, that can cause some significantly bad things like false positive, false negatives in that context can be very dangerous, for lack of a better word. And you think of other pharmaceuticals, the 95% confidence rate belongs in some companies and some industries because the risk of failure on the impact of a false success is very high.

(00:43:47):
But those of us converting users and trying to upsell folks, we are very fortunate to not have that level of burden on us and we can take advantage of that. And so there are definitely times where I will advocate for and I will push for and I will myself use lower confidence intervals and 95%, especially if that doubles amount of experiments that you can run in a year. End of the day, these are all methods that we use to try to validate the hypotheses that we have. And if you're doing a 95% confidence in a role, you're still accepting a 5%, some amount of false success, do that a little bit more, challenge you to do that a little bit more. And then run way more experience. If you look at the net of what your team is doing over the course of year, what you're doing over the course of a year, you will be positive.

Lenny (00:44:42):
Wow, that is a big idea. Idea of releasing the P-value confidence interval for experimentation and data teams. Everyone would be excited about this. Probably maybe not some data scientists on teams. Do you do that? How do you act? Is that how you operate on your teams? Just like we don't need 95% competence?

Laura Schaffer (00:45:03):
So I'll say this, this is actually very critically important. You must have this game plan set before you run something. Failure mode that I see so many teams fall into is they'll run the experiment or whatever it is and then they'll make the data fit the hypothesis. Or sometimes they'll go without a hypothesis and just be like, "This is going to do better things for our metrics," but not a core reason as to why or what exactly are we testing here. And so this is another area we could absolutely fall into that trap. "Let's [inaudible 00:45:36] on good 80. I think it's good. That Laura person said it was cool. So I think that that's fine." That will always be a trap. So it needs to be very deliberately thought of in advance as a way of like, "Hey, here's how we're going to validate this." And always, always, always, if you're going to accept more risk of a false success or false positive, false negative, you want to then be really thinking about how you're going to harden your validation of a hypothesis.

(00:46:03):
For example, let's take that when we talked about with Twilio where we are kicking people out and we're sending them to the pilling hotdog experiment, and we're sending people to that experience to hide the phone number. Now in that case, let's say that we were going to accept a lower confidence interval. I would very much want to see qualitative feedback to confirm that that hypothesis was true. I want to be looking at the qualitative data from the ones where people were thrown into the existing flow and one's put into the dogs that one of them felt more confident and more like this was really easy to get through and they felt out of a territory and things like that. And I'd be wanting to hear from the ones who were in the other one, things like, "Oh, I got stuck on that [inaudible 00:46:48]." Like, "Figure this out, but it feels like it's that amount of my depth."

(00:46:52):
I would want to be looking for other things to corroborate the hard data that I'm seeing. And yes, it opens the door to whenever you open the door to more risk acceptance, you are going to have some false successes there. But all of these things together can overall make it more likely that you're shipping more things that are going to positively influence the customer. And again, I can't say it enough. It is a huge risk in and of itself to not ship as much as you possibly could in a year. That is a huge risk given that very high fail rate. So to those data scientists, and I've chatted with a few of my time, what I try to explain is that that article, that data that the 80%, that's hard data about what a detriment it can be if you don't run an enough experiments.

(00:47:51):
If you just run 10 in a year on there, maybe two around impact, two of a course of an entire year if you take that approach. So data scientists can understand, "Hey, if we do this, if we run this down, we can double or triple whatever it is, the number of experiments where we can run and overall net that's going to result in more successes that will overall net us to a positive place." You can still tell a data story to the data scientist about why you're doing this. Again, this is why when you asked that question identify, as a very data-driven person. But I think some of the methods that I use can sound at the service level as more like, "Oh, I'm going by my gut." But again, very data driven is just embracing the reality of some of the hard data that I don't think we all embrace or are even aware of sometimes about that fail rate.

Lenny (00:48:42):
This is awesome. This is a big idea. Have you written about this anywhere for folks that maybe want to try this approach at their company? And if not, you should.

Laura Schaffer (00:48:50):
I appreciate that. It's funny, it's like all my general life to do is just start writing some of this down. I have three children, one of whom is five months old, and then I have two and four. And so sometimes I'll start to write and then one of them will crawl across the keyboard. And by one of them, I mean all of multiple times. But eventually, yeah, I'll be very happy to do that if folks would be interested. I'm always happy to do whatever I can to help folks, help empower folks with knowledge to do better because none of this is secret sauce really. It's just learn from experience and it's always better to learn from others' experience than your own. It's faster. So yeah, I would definitely [inaudible 00:49:35] is that, I think that's the best that I can say, but eventually my kids will get older. I hear this and maybe I can do so.

Lenny (00:49:42):
Hopefully. Cool. So maybe if you're watching us on YouTube, leave a comment and if you want Laura to write in depth about this idea and spread it to your company. Okay, I want to talk about growth, but I have one last question just along the lines of experimentation. Is there any other just, I don't know, big lessons or takeaways of running experiments that would be interesting to share?

Laura Schaffer (00:50:02):
I think we got into this one a little bit, but I just really want to exclamation point, underline it, which is that notion of making the data wrap to fit a concept. I think a lot of teams feel and are under a lot of pressure to show progress and, "What did you do this month? Where did the metrics move?" And it can cause folks to feel like they have to do that, where it's like, "Oh gosh, this experiment." Everyone's got the experience where you run an experiment and you're like looking at the data, refresh, refresh, refresh, oh my gosh, and actually perform worse. Or it's not the same and, "Gosh, we got everyone really excited about this thing that we all worked on really hard. Like, oh my god, what are we going to say in the QBR or the monthly report?" Whatever it is that the results come to light.

(00:50:55):
And to this, I'd say this, that it's incredibly important for growth teams to educate out and for folks outside of growth and leading growth, especially to understand that the best way for a growth team to succeed, the only way really for them to succeed is to embrace the fact that they're there to validate, to understand what the biggest opportunities are and to go after them.

(00:51:24):
And that is not something that can be done on a weekly timeline, sometimes even a monthly, depending on the space you're in and what's known and unknown. And so any growth team that's beholden to short timeline wins and improvement is always going to be dangerous. That's an environment that's conducive to vanity Metric usage and massaging the data [inaudible 00:51:47]. And ones that are more successful are ones that are reporting over longer periods of time. Because I think growth team, given enough time to fail, enough time to learn the right thing to do is absolutely going to show success, real success. Not that, "Okay, we're going to make this data fit." But real moving the metrics success.

(00:52:03):
And so definitely educating out. If you find yourself in a position where you are beholden to that, share that 80% fail rate. Just math, statistics, data. You cannot be successful in an environment, but over time you can be. And so that's one thing I definitely would draw on. I end up spending a decent amount of my pie chart at Twilio and then also at Rapid where I was after that and I'm sure I'll spend some time at Amplitude as well. Just helping folks understand what is the healthiest ecosystem, most powerful ecosystem for a growth team to operate in. And time and expectations over time is a big part of that.

Lenny (00:52:46):
When you say pie chart, it's like the pie chart of your time like a big chunk of your time goes to this?

Laura Schaffer (00:52:46):
Yeah.

Lenny (00:52:50):
That's awesome. I like that. I use white charts a lot as to describe that same idea. Just to be a little more concrete there, what is the timeframe you think is the minimum for a growth team to be thinking across?

Laura Schaffer (00:53:01):
I think it's good, especially for newer teams, but even teams in general. Commit to something that you can do over the course of a year and low, medium, high is always helpful in that space. A lot times-

Lenny (00:53:01):
What do you mean by that, by low, medium, high?

Laura Schaffer (00:53:17):
Low, medium high, more like, "Hey we've got a few bets that we have or few core hypotheses." And if they take off that's going to be our high bucket like, wow [inaudible 00:53:26]. We think these things could become lightening on a bottle here, but they could also be a bunch of [inaudible 00:53:31] missed. But until we run in, we're not going to know. And if those bear out though, then yeah, that's our high. And hey, we've got a few things that we think are safer. Maybe it was validated a bit in the previous year, what have you. And these looking really the metrics this amount.

(00:53:45):
So it's helpful to give people though that construct, it deviates from it very hard deviates from this notion of like, here's the single number that we're going to hit. Just things that help people understand that space a little bit better and what to expect. And because of that it can be a little bit lumpy. There were some things that you released. Truly for the most number of years, can be easiest to talk about in this construct here, but there's one thing that we did that generated tens of millions of dollars in the pipeline, was really, really powerful and took, sometimes navigate and validate. Other times we did that onboarding stuff that I was talking about catching those things. That could happen on a little bit of a faster clip but still took some time to validate and understand. But yeah, over the course of a year you should generally be able to commit to movement. But help people understand the methods there so that they're not coming at you on a weekly basis being like, "And what did you do these past couple days?"

Lenny (00:54:44):
Okay, I got to follow up on a couple of these things. What was that big change of Twilio that lead to tens of millions of dollars?

Laura Schaffer (00:54:50):
This is part of the course that I teach at Reforge.

Lenny (00:54:55):
Oh, amazing. You get to work for Reforge with [inaudible 00:54:57].

Laura Schaffer (00:55:04):
I'm actually interested in retention, I think is my part. Right now, I'll give you links so we can [inaudible 00:55:05] in the show notes. But yeah, the high level version, this was deeper into my journey at Twilio. This is fast-forward a few years, build up this team and some cool things going on. But I was really looking for what's the next big thing for us to do? What could that be? And I noticed, remember that question very back of the day when I asked about the developer versus not developer folks [inaudible 00:55:34]?

Lenny (00:55:33):
Mm. Yeah.

Laura Schaffer (00:55:35):
We saw that little non-developer little dude ad was growing. We were actually the number of people in the ecosystem who were identifying themselves as not a developer were in the space.

(00:55:46):
But very interestingly they were, as we got more refined in our understanding of those folks, a lot of them wanted to build with Twilio. There was a hypothesis of like, "Oh well maybe they're lost, maybe this want pricing, maybe they [inaudible 00:56:00] mistake." And I was like, "Nope, they're here to build, they won't build." And they struggled through the developer on onboarding and some of them would succeed and some would... But anyway, it was all about identifying what did they need to succeed. If we were made them successful, could it contribute to dollars? One of the core learnings I'd heard from sales at the time was, "Hey, it's very challenging for us to get the folks when a developer's not involved yet to go from zero to one to get something off the ground. But man, if we can get them to do that, if I can get them in $1 and spend, I can get them to five. If I get them to five, and get them to 50, like 10,000, then I can get them to hundred thousand."

(00:56:39):
This whole long journey like, "Hey, Laura, if your team could just get them off the ground, man, we can do so much." So yeah, the journey is all about, okay, what were the things that were missing in the experience we were offering and ultimately was they couldn't write code from scratch. That was really difficult. And also we're going to stand up a server. That was difficult. But we ended up iteratively experiencing a way to validate those hypotheses and what's the right way to do this and yeah, that was great. It's called quick deploy on code exchange. Anyone can go there and deploy an app without having to write code and get an aha moment there with Twilio.

Lenny (00:57:16):
That is awesome. So basically it's like a low code Twilio app?

Laura Schaffer (00:57:20):
Yeah, it ended up being, we had a lot of pet names, nicknames for it. I think probably the one that most succinctly describes it as just, it ended up being a create your own demo experience which made you talk about the psyche of people. We talked about how developers telecom until can be intimidating. We'll talk about the non-development, sometimes the buyers or the people who are instantly buying decisions, for them, it was not only was it telco, but it was the developer stuff was inaccessible but they still wanted to jump in and they wanted to have that experience. And so this was a way for us to give them momentum, give them comfortable. Geez, I can get this running my development team, I'd definitely do it. And so it was a very powerful moment where we could really address the psyche of those users, get them excited about Twilio, and then give sales the ability to give something powerful to those non-engineering buyers and folks they're talking to.

Lenny (00:58:17):
So genius, looking back seems like an obvious win. One of my readers suggested that I start a series of the story of a feature and walk through the discovery ideation development iteration and this feels like a really interesting example of that. But anyway. I got just a couple more questions. I know we've been going for an hour now. But I have questions, I don't want to let you go just yet, and they're on growth. So one question is just you worked at Twilio, which is very product led growth. You're now Amplitude, which is more sales driven and I know you're trying to go more product led. I know Elena talks a lot about this, how every company needs to have product led motions, otherwise they're going to be disrupted by someone that comes product led. And I don't know what hires, which blanket would they fall into?

Laura Schaffer (00:59:05):
Between the AI like SLG and PLG. Yeah, for me they're two sides of the same coin. Product growth and sales. It's all to me, very thematically the same stuff. The difference is that with growth, you are selling with your product, and with sales you're selling with person like one-to-one. And so companies need to be employing both of those forces to optimally convert their audience. We're in a world where people are expecting both. They're expecting to be sold by your product and sold at the enterprise level. And large companies buy by human beings. It's going to listen to their specific needs and really break it off for them. And if you only have one, you're going to miss stuff. So absolutely, I think you want those two forces together working well. And obviously there's different stages, things work differently in different spaces, but I think when it comes to Amplitude, I think there's a huge opportunity here.

(01:00:06):
I think the key is, and that the challenge for companies that have done the sales thing and are trying to crack into the PLG thing really comes down to how you fundamentally are approaching that space. And again, your users and where they're at and the psyche of where they're at, I think a lot of companies will say, "Well okay, hey, we're going to do this PLG stuff. Let's take that sales enterprise whatever offering that we have and let's chop it up a bit and cut access here and cut out this feature here and we're going to slap this plan out and we're going to put a price on it and we'll maybe have hours of debates over whether it's like 10 99 or $104 or 75, and eventually someone will win that battle and slap it on and then [inaudible 01:00:54]." And anyway, the discussion of the focus is a lot around the product.

(01:00:58):
What are we going to do with this product? How are we going to crack it open and shift shift it in and then give it to these people, these users, these visitors? And what it's missing, I think is, and a lot of times it's easy to miss, is that when we're doing PLG and we're shifting from sales to PLG, we need to reset. We need to recognize that, again, this is sales, sales via the product. What does a good sales rep do when they're engaging? They understand what the problem is of the person in the space they're talking to. So we need the same thing here. What are the unique problems of people who are coming into our self-serve space? And I think when it comes to a company like Amplitude, a lot of the folks that will be looking to address via the PLG motion, there's a number of things we want to achieve there, but one of the primary things is to tap into the SMV market market and really give them a really startups and give them a space to land and to grow.

(01:01:57):
And again, you have to think what are the challenges and unique problems that they have because we're going to be using our product to settle them. We need to meet them where they're at with the problems that they've got. And I think one of the things that I've observed from being in all these startups and advising some startups is I very rarely... I don't think I've ever come across a startup where they have the right number of analysts for their needs. In fact, a lot of them don't have any. And so what that means is that the CEO is being an analyst to create their dashboards for the board and the product manager is being an analyst to figure out what the heck's going on and creating their boards for their product.

(01:02:34):
And that's happening all over the place is that people are in their roles and they have to be an analysts too. And I think that that's a problem that especially younger companies and early stage companies have. And so when they connect their psyche, what are they caring about? What are they thinking about when they're sending it for product analytic product or something? They're looking for something that's going to help them feel reassured they're going to be able to actually get to the bottom of the right metrics, create the reports that show things the right way. What's the best way to show churn? There's got to be a best way so many people are doing it. Guess what? Yes, there are some really good ways to do it and there are some really successful ways to set up dashboards for the board. People have done that too.

(01:03:16):
There's a lot of that knowledge that exists in one of those frameworks that exist, benchmarking. Are these numbers even good? And so, one of the hypotheses that I have is that if we take that perspective and we understand that that is the problem, that there's a number of things that we can do to really change the way that self-serve experience works to help convert people and show them how Amplitude can make them that powerful. But the thing that I think sticks across all companies, not just amplitude making the shift, is just that, that when you're doing this, do not think this is a copy paste, but chop it for parts thing. Don't start with your product when you're building at your strategy, start with your customers, your users, your prospects, the people who are going to be coming into yourself or flow. Make sure you are understanding how their problems differ because they do from the people that you're addressing at the sales led side. And then make sure that you're orienting your experience of product around those people.

Lenny (01:04:12):
It's interesting that you almost have to start again as a product company, as a product because you may need to solve completely different problems that eventually lead to the same place. But it's interesting what you're saying that you may end up targeting analysts or PMs. I know Amplitude or has always focused on PMs, but-

Laura Schaffer (01:04:32):
Yeah, it's right. And there's always nice thing about it is it's in some ways, it does feel like you're starting fresh because you do need to start with the customer again and what's their problem. But in a lot of ways, you can carry over a lot of the same knowledge. At that point you know what's working well. Amplitude for example, does have a ton of knowledge around what some of the best ways artists set up reports. There's a lot of things that they have the momentum going, like where do you choose that momentum and how do you put that and curate that in front of users and make sure that they're getting the right things. There's a ton of momentum already there. It's just a little bit about harnessing it and understanding like, yeah, where are the gaps because there are going to be gaps.

(01:05:08):
But anchoring in a customer problem as I think the way that you start any new product, any new thing that you're releasing, should always think about the customer and the pain point. So no different than when you're doing PLG for the first time or cracking into it. You need to be thinking again, starting again with the problem, the problems they have, the psyche that they have coming to your space so that you can build something that is going to effectively make them feel like, "Oh you can solve my problem, you get me." And show them how your product's going to do that.

Lenny (01:05:42):
Final question, and this is around developers. You worked at Twilio, obviously Twilio sold developers. I think Rapid where you work right before Amplitude also sold developers. Selling to developers feels like such a hot space right now. There's so many startups that are just building developer tools, such a huge market. Used to be not. Used to be like there's not a market in developers. They're not going to spend money, there's not enough of them. And now it is a big popular spot. And so I'm curious, what have you learned about building a startup and a product that sells to developers? I imagine a lot of founders building search tools would be really curious.

Laura Schaffer (01:06:16):
The first is that developers are just a very different audience from any others. I've seen so many people who have come in strong on growth really well or product really well with other audiences and like, "Oh, I'm going to take all those learnings, I'll pivot into serving developers." And as it being a very steep climb because developers are so different. And let me give you a couple just fun facts that make them really different. And some of these have some interesting stories. One is developers, almost two, one, do not look at your marketing website at all. They go straight to your signup flow. So what that means is all that beautiful context that you're setting and the product aid pricing, all that stuff, very often they're skipping all of it context free and going straight to your signup. And so anytime you make an assumption like, "Oh, well, they probably know this coming in to signup." Or like, "Well, we don't need to include, that's on the marketing website." None of that's going to apply to this group of people.

(01:07:15):
They're there. The analogy I have for this group is they're the IKEA buyers who when IKEA package comes, they're not opening up the instruction manual and reading in and then starting to go through, they're in there tearing open the bags and starting to pull the pieces together and trying to build it. They'll come up for context and steps and such when they get stuck if they're motivated. So that's one thing. And then another one is just the aversion to talking to sales. And I think hearing that, some they're like, "Oh yeah, well, I hate sales too." When I'm sent out and get bombarded by sales, that's the worst. I totally get that. But developers are on this whole other level. There was a fang company sign up for Twilio, built a POC, launched to production, all this, and operated in that space for months without engaging once with sales.

(01:08:12):
I was trying to reach them and I ended up being the one that talked to them first because they reached out to support because there was something about their delivery that was off ,there missing a feature and they did not want to talk to sales. They ended up talking to me when I was in product marketing. And that was my first exposure of like, these people not want to talk to sales. And then there's another one where a giant retail company where the engineering team signed up with their personal e-mail addresses so they wouldn't get bombarded by sales. It was only later that we found out. Anyway. But the thing that's most important, these are fun facts, but the thing that I would say is the most important, the thing to leave with listeners here is what makes them so different?

(01:08:54):
Why? What's the deal here? And it stems from their charter and their responsibility. So if we put ourselves in developer's shoes for a minute, a developer, if a developer is required to use your product, especially if they're the primary user, the primary builder, it's really important to recognize that they're responsible for that. If your service goes down, that's their responsibility. Not just for themselves but their team. If the pager wakes up someone because the service they bought from you goes down, that's on them. If, oh, it turns out that doesn't work with the systems that they said it was, well, that's on them. Doesn't integrate with the data the way that everyone wanted it to? That's on them. Everyone lives to developer when it's not working right and it cannot work right. In so many ways, that's their failure, it can cost them their job, it could cost them the trust to their team.

(01:09:50):
It cost them their reputation. And that means that the stakes are very high for them every time that they're adopting something new. So they can't afford to take someone's word for it. Especially a sales rep who might have some other motivations from their perspective, they can't afford to trust your content or someone's word. They must do it. They must prove it themselves. And so that's why, for developers to be bought in, they need to do something, build something, a proof of concept at the very least, if not moving further than that. And so that means they're going to be pretty darn deep in their self-serve experience with you before they're ready to commit. And so if you are a company that is providing, that requires developers to build, you must invest in self-serve experiences in order to effectively convert your audience. And you should be thinking of them. Something akin your self-serve function and growth folks, someone akin to Salesforce because your developers are not going to accept sales coming in and trying to convert them at that stage.

Lenny (01:11:00):
I love that you always come back to the psyche of the user and how in this case, developers like, here's why they're responsible for this thing. Salespeople are going to convince them this is going to work. And it's not. That's a really interesting tool and that's a really cool takeaway.

(01:11:16):
Is there anything else that we didn't cover before we get to our very exciting lightning round?

Laura Schaffer (01:11:20):
Plenty. I think we covered it all, man.

Lenny (01:11:22):
You got all my questions and more. So with that, welcome to the very exciting lightning round. I've got six questions for you. Are you ready?

Laura Schaffer (01:11:30):
I am so ready.

Lenny (01:11:31):
What are two or three books that you recommend most to other people?

Laura Schaffer (01:11:35):
I'm a big believer in happiness. Not just being crunchy or we should all be happy, but also because it helps us do our best work and we're more creative and all this. So one is Simple Path to Wealth by JL Collins. I don't ignore the data, that money is something that often gets in the way of our happiness. I know so many smart people that just have not figured out the whole managing their finances thing. And this book will cover all of your basics. It's very easy to read. He's got an audiobook that he narrates himself. Simple Path to Wealth by JL Collins, he's fantastic.

Lenny (01:12:12):
What's a recent movie... Oh wait, wait, there's more?

Laura Schaffer (01:12:12):
Oh, there's one more.

Lenny (01:12:18):
Oh, let's do it. Let's do it.

Laura Schaffer (01:12:18):
[inaudible 01:12:18] Happiness, which is Atomic Habits by James Clear. If you ever want to change something about yourself or something's not quite working for you, this guy will give you a framework to change it. Guaranteed.

Lenny (01:12:30):
I really enjoyed that book. That guy's killing it. He was on Tim Ferris, he had a great interview. Folks that don't want to read it, they could listen to that. There's a lot of cool tips there. Favorite recent movie or TV show?

Laura Schaffer (01:12:39):
Unabashedly, the Great British Baking Show. I love that show. I love that show for all the reasons everyone loves that show. It's heartwarming and makes you feel good and uplifts you. But also because it is a competitive show. They're trying to be the best baker and they're out there helping each other. They're like a big family. Most reality competitive TV shows that I see, all of them are like cutthroat, they're sabotaging. So I'm just endlessly fascinated also by the psychology of what's happening here. I want somebody to do a research paper on it, get to the bottom of why they're all helping each other. It's wonderful though. Wonderful to watch.

Lenny (01:13:18):
Interesting. I always comes back to psychology with you.

Laura Schaffer (01:13:24):
I know. I know. I feel like I'm really, really sinking deep in there. And it's true though. It's very interesting to me, and I love that show.

Lenny (01:13:30):
What's a favorite interview question that you like to ask in interviews?

Laura Schaffer (01:13:34):
I love asking about a ship or release that is not cherry-picked by the person you're talking to. You can get it a lot of different ways. The thing is, everyone has a big success story. Everyone does. It really doesn't actually tell you very much to ask someone like, "What's a great thing you released?" Because everyone could tell that. Instead, take that away. What's the most recent ship is a really easy one because recency, time. But there's other things you can do to take that out. Just give them specific parameters for a ship that they've shared or whatever, and that will allow you to listen more and learn more about their frameworks versus the outcomes. Because if you're picking a random ship, odds are it probably wasn't fantastic. So they're going to want to talk more about how they approach getting there and that's what you want to know about to know if they're going to succeed, what their frameworks to how they approach things.

Lenny (01:14:24):
That is cool. I've never heard that one. That is a really clever idea. What are five SaaS products that you use in your day-to-day work? Can't say Amplitude.

Laura Schaffer (01:14:33):
I know, right? Still learning which ones we have here. But yeah, I'll just share the ones that I like a lot that I've used elsewhere. So one is Hotjar. Hot Jar [inaudible 01:14:44] also works. Just anything that allows you to put some quick little thing in front of customers, get that qualitative feedback we talked about. It's a critical, critical supplement to quantitative data to understand what's really causing the change or not causing the change [inaudible 01:14:58]. So that's important. I will say Amplitude is a fantastic tool that I have used and I would've said that if I hadn't just joined Amplitude so I got to use it... I know. I got to use it for the first time at Amplitude and it was awesome. So again, like asterisk, because I'm like working there now, but I do actually like it. And Slack, it's boring, everyone says Slack, but I just have to hand it to them.

(01:15:26):
It makes life so much easier and just nod their way. And then Builder, which I'll also put in asterisk on that one, but I really want to serve this. A lot of people don't know about it and it's really helpful. I do advise them so I'm in their corner. But this is another one I also say would be a powerful one. I think a lot of team gets stuck. They're relying on too much in their engineers to make changes. Again, we talk about rapid experimentation, getting these out, out, out. And Builder makes it really easy for folks to do that. Also, a headless CMS, you can drag and drop headless CMS so they do make it easy for non-engineers to make changes. So especially if you're trying to figure out how to get around that 80% [inaudible 01:16:11] that I mentioned, this builder would be a good way.

(01:16:14):
And then yeah, if you want one more, I'll give you Chat GPT, which is really boring and everyone's saying that, but I think I'll just say I don't have any crazy things to say about it except that I do think we all need to figure out how we pull that in to [inaudible 01:16:28] put people who don't do that are probably going to lose out or smart AI whatever bots. But that would be it for you, Lenny. But if you ask me in a few months after I've actually been an Amplitude for a bit, I'm sure I'd give you a different answer.

Lenny (01:16:42):
That's a good time to plug lennybot.com. And I wrote a newsletter or Dan Shipper who created the bot wrote a newsletter post about how he built this thing. And so you could go ask me questions using the content of my newsletter as answers. And it's very cool. Lennybot.com or lennysbot.com.

Laura Schaffer (01:17:00):
Amazing.

Lenny (01:17:01):
There we go.

Laura Schaffer (01:17:03):
I didn't know about that. Well, there you go. I've changed my answer. It's that.

Lenny (01:17:05):
Yeah, there we go. That's all I need.

(01:17:09):
Two more questions. What is something relatively minor you've changed in your product development process that has had a lot of impact on your team's ability to execute?

Laura Schaffer (01:17:17):
Yeah, the be embarrassed thing, like I mentioned earlier, be Embarrassed by the first iteration. If you are not embarrassed, you've gone too far. That really speeds up ships and helps people celebrate the unpolished as opposed to feel embarrassed about it. So just embracing that.

Lenny (01:17:35):
Awesome. And final question. I know you just started Amplitude, but do you have a favorite pro-tip for how to use Amplitude or maybe Hidden Feature people may not know about?

Laura Schaffer (01:17:44):
You tell me [inaudible 01:17:45], but I'll say one thing that was super cool actually that someone put together on my team at Rapid, literally before I left, he put together a video of how powerful Amplitude could be when linked up and integrated with other things like in this case Hotjar and Segment. There was a Amplitude report that someone had created and there was something that was an anomaly happening there. Users were using something in a way we didn't expect and Amplitude one of the reports surface it, but Al Kirsten, we want to know why is that happening. And so we could find out what the event is and then using by Segment, find out what that name was and look at Hotjar and actually go in and get screencasts of people doing that exact event.

(01:18:30):
And from that, we were able to form some really concrete hypotheses about what actually was causing it. And so obviously talking to customers is very powerful, but in this case, just that simple use of connecting and threading those technologies together could really get a good picture of that without needing to engage customers. So the tip would be how you can really amplify when you get an amplitude when you use it with.

Lenny (01:18:59):
Amazing. Laura, we covered a lot of ground, career experimentation, growth, embarrassment, psychology. Thank you so much for being here. Two final questions, where can folks finding online if they want to reach out, learn more, maybe send you an appreciation or two? And two, how can listeners be useful to you?

Laura Schaffer (01:19:17):
Yeah, find me on LinkedIn. I don't post a lot. Yeah, I'll blame my three children. Eventually, I promise that I will. But I'm pretty good about responding to messages, so definitely link with me there.

(01:19:29):
And then what listeners can do, I think I'm always happy to hear feedback, suggestion, all that, but I'll just say I also know that it's a little bit crazy out there right now, especially folks working in tech. So I'm also cognizant what I might be able to do to help all of you. I know there's a few places I advise and rapids hiring. I know of a few folks that are hiring growth, strong growth people and product folks. So if you are interested in learning more about that, don't hesitate to hit me up. I want to make sure that I help as many people as I can in that respect because it's trying times and I'm sure you've heard it and read it, but if you're laid off, this is not about you, it's not your fault. It's this crazy world we're in. Things will get better. And I would be feel very lucky if I could help even one person land. So feel free to hit me up about that too.

Lenny (01:20:21):
Awesome. And maybe if you share some links, we could include links to open roles in the show notes.

Laura Schaffer (01:20:26):
Yes. I know there's a few that don't have JDs open yet. They're that hot off the press, but I'm happy to surface a few things there for sure because I know that makes it easier for people to know.

Lenny (01:20:37):
Awesome. We will do our best with the show notes then. Laura, thank you again for being here.

Laura Schaffer (01:20:43):
Yeah, thanks so much for having me. This was awesome and so much fun.

Lenny (01:20:47):
Bye everyone.

(01:20:49):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcast, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Mastering onboarding | Lauryn Isford (Head of Growth at Airtable)
**Guest:** Lauryn Isford  
**Published:** 2023-02-12  
**YouTube:** https://www.youtube.com/watch?v=dLku0AiGPVA  
**Tags:** growth, retention, acquisition, activation, onboarding, churn, metrics, kpis, roadmap, prioritization  

# Mastering onboarding | Lauryn Isford (Head of Growth at Airtable)

## Transcript

Lauryn Isford (00:00:00):
An activation rate that falls in a lower percentage range, maybe for most companies five to 15%, is better than one that falls in a higher percentage range because it means that there's likely much higher correlation with long-term retention and you're really working hard to get most of your users to reach a state that they're not reaching today.

Lenny (00:00:24):
Welcome to Lenny's Podcast where I interview world-class product leaders and growth experts to help you get better at the craft of building and growing products. Today my guest is Lauryn Isford. Lauryn was most recently head of growth at Airtable. Before that, she was a product growth lead at Facebook, working on user growth, internet.org, and growth of Facebook at India. Before that, interestingly, she led growth for Blue Bottle's e-commerce business. In our conversation, we dive deep into Lauryn's favorite topic, onboarding, why it's one of the biggest and most undervalued growth levers, what she's learned about optimizing onboarding flow through her work redoing Airtable's onboarding flow, what she's seen work and common pitfalls around onboarding, plus a ton of advice around figuring out your activation metric. I could talk all day with Lauryn about growth, but we had to cut this off to keep this to a reasonable length. Enjoy my conversation with Lauryn Isford after a short word from our wonderful sponsors.

(00:01:19):
This episode is brought to you by public.com, who want to tell you about their new treasury accounts which earn a 4.8% yield on your cash. That is higher than a high yield savings account while still being backed by the full faith and credit of the US government. Treasure yields are at a 15-year high, but buying US Treasuries is super complicated if you go to a bank or navigate an ancient government website, or at least that was the case. Now you can move your cash into US Treasuries with the flexibility of a bank account, you can access your cash whenever you want, even before your Treasury bills hit maturity. There are no hold periods, no settlement days, just a safe place to park your cash and earn a reliable yield. Public will automatically reinvest your Treasury bills at maturity so you don't have to do anything to continue growing your yield, and you can manage your treasuries alongside stocks, ETFs, crypto, and any alternative assets. Do all your investing in one place and earn 4.8%, a higher yield than a high yield savings account only with a Treasury account at public.com/lenny.

(00:02:24):
Today's episode is brought to you by Miro, an online visual whiteboard that's designed specifically for teams like yours and mine. I have a quick request, head on over to my board at miro.com/lenny and let me know which guest you'd love for me to have on in 2023, and while you're on the Miro board, feel free to play around with the tool. It's a great shared space to work closely with your colleagues to capture ideas, get feedback, and iterate quickly and easily on anything you're working on. For example, in Miro, you can build out your product strategy by brainstorming with sticky notes, comments, live reactions, voting tool, even an estimation app to scope out your team sprints. Your whole distributed team can come together around a wireframe and draw ideas with a pen tool or even put mocks right into the Miro board. And with one of Miro's ready-made template, you can go from discovery and research to product roadmap to customer journey flows, final mocks, you get the picture. Head on over to miro.com/lenny to leave your suggestions. That's M-I-R-O.com/lenny.

(00:03:27):
Lauryn, welcome to the podcast.

Lauryn Isford (00:03:28):
Thank you. I'm so excited to be here.

Lenny (00:03:31):
We've chatted a bunch over Slacks, like all these different Slacks we're in and Twitter and emails, but we've never actually chatted real time, and so I have a million questions that I want to ask you. So, thank you again for being here.

Lauryn Isford (00:03:42):
We have never chatted real time, so everybody's getting the first conversation and I'm really looking forward to it.

Lenny (00:03:48):
I know that you have this pretty spicy contrarian take on experimentation and that I think you believe people run experiments too often and maybe not everything should be an experiment. Can you talk about that?

Lauryn Isford (00:04:00):
Yes. So, experimentation is a really big part, growth culture, growth hacking culture, PLG culture, growth marketing culture, any kind of growth, at least in my sphere, and sometimes teams can be really, really dependent on experimentation when trying to grow a business. A great example of this would be consumer growth at scale. Think your classic big social company. I worked at one of them. I am a former employee of Meta back when it was called Facebook. When you're at scale trying to grow a social app, experimenting can feel second nature. It can feel like a necessary step in your product development process that you want to drive more signups or you want to drive better activation with new customers. So, you change some buttons, change a design, and A/B test it, and then see if numbers go up or down, and then make your ship decision based on it.

(00:04:56):
I find that there's generally two reasons why a grow team wants to experiment, and one of them is to understand more precisely the metric impact of what they're building and what they're putting in front of customers, and the other is risk mitigation where you're making so many big dramatic changes that there's some risk that while this could be really great for the business, it could also be really bad and it would be good to understand that before everybody's experiencing that in production. So, with that framework in mind, sometimes you don't need to experiment. Sometimes if the business, let's say activation, right, activation rates go up 6% versus 7%, that precision actually doesn't help all that much beyond being able to say in your performance review, "Hey, I increased activation by 7%." So, it also is expensive to have folks on the ground, be it engineers, analysts, product managers, spending time understanding the results of an experiment that could otherwise be spent on road mapping, on foundational analysis, on shipping things. So, experiments can be expensive.

(00:06:09):
So, with all that said, generally my advice is to experiment when you need to and to primarily see it as a risk mitigation tactic when you're making dramatic changes and to let the product development process do more work. So, spend more time with customers, be more rigorous in understanding precisely what problem you're solving, get mocks in front of people and see how they react, and hopefully have more conviction than you otherwise would when you ship something that it's okay if every customer sees it tomorrow and that the experiment doesn't actually matter as much.

Lenny (00:06:44):
It's so interesting hearing that from a head of growth person. Working at Airbnb for a long time, and you talked about this, there's so much value put into the amount your experiment moves the metric is so important to, like you said, your performance review, your team's status, your team's ability to show they were successful. People look at like, you drove this metric 14%, which oftentimes you add up from experiments you've ran. How do you work in a culture like that, or is it just in that culture you may as well run experiments because that's the only way you get credit for the work you do, or is there a way to just be like, "Wow, that is how we measure it, but it's still maybe not worth running everything as an experiment"? How do you kind of find that balance?

Lauryn Isford (00:07:29):
It feels to me like that is the default culture, especially as growth teams become organizations and as those organizations grow with companies into growth stage public company territory and beyond. However, I do think you can build a different culture, and the only way to escape the trap of experimenting everything is to have a very intentional culture about doing right by customers and doing the right thing for the business. A growth team or a growth org exists in service of improving the business and delivering results for the business, and whether or not you measure those precisely in an A/B test, you still shipped them or you didn't.

(00:08:09):
So, the rigor around your process was either there or it wasn't. This means though that there have to be other ways to motivate, reward, retain, and develop really good talent. So, a culture around the impact you had on customers as measured by qualitative feedback or as measured by deals that were closed or deals that weren't lost, or other kinds of indicators that you did the right thing for customers is important and there shouldn't be, especially in engineering within the world of growth, a culture around having to point to numbers to demonstrate your impact because if there is, then the team will biased experiments all the time, and that's not necessarily the right thing for the business. It's a very expensive cost.

Lenny (00:08:50):
Wow. It's so wild hearing this from, again, a head of growth, someone that's so analytical like you. Is there an example of something you launched that maybe most people would've run an experiment and you decided not to for one of these reasons?

Lauryn Isford (00:09:01):
There is a feature, a product really, that Airtable offers called Airtable Forms. It's possible you've used it. I'm not sure if you have, but-

Lenny (00:09:10):
No, I don't think so, but I will go check it out.

Lauryn Isford (00:09:12):
You can check it out. There are some new features I'm about to tell you about, so maybe that will entice you.

Lenny (00:09:16):
There we go. Scoops.

Lauryn Isford (00:09:18):
So, Airtable Forms is much like other forms products. You can create a form and then send it to anybody to submit. The people who submit your form don't need to be a user of Airtable.

Lenny (00:09:30):
Oh yeah, I have used that. Okay. It's just like the turn an Airtable into a form. Yes, I've used it. Okay.

Lauryn Isford (00:09:35):
Exactly. So, something we noticed is that there was a gap in feature parity for Airtable Forms where the submitter could not request a copy of their submission. So, I might send my T-shirt size to Lenny for a form around ordering swag for the company and then I might want to remember which T-shirt size that I ordered and get a copy of that in my email. We created that feature which as a result was gated on creating an account with Airtable, and we just turned it on and wanted to see what would happen because we knew from rigor of a wonderful product team doing robust customer analysis and also doing the data work that this is something that people wanted, that it was a feature that would bring value to customers, and that even if it didn't move certain metrics like a signup percentage, even if it might affect the mix shift of activation rate from folks who signed up, it would be net good for customers who were using forms and who were submitting them.

(00:10:35):
So, we did roll that one out without an A/B test. It did have a big enough impact on our signup metrics that we saw at top line and didn't need the A/B test to see what was happening. And we also were able to use attribution to make some analysis possible after we rolled it out so we could learn from what was happening to the base afterward.

Lenny (00:10:53):
Fascinating. That's a really good example, and I imagine that helps a lot when the head of growth is encouraging the team not to run as an experiment versus a PM on a subteam, like, "Nah, we don't need to run this as an experiment," because in that case you're already acknowledging that team, "You did a great job, look at this metric. Clearly this one moved. Clearly customers want it." So, to your point, basically this kind of stuff has to come top down probably for it to work well.

Lauryn Isford (00:11:15):
I think it does, and it also cannot be an excuse for rigor around building well and being precise in what customers need, but overall, if you can be a results-oriented organization that just wants to do the right thing and move with urgency, then in my opinion, that's the way that you can have the most impact.

Lenny (00:11:33):
Cool. Okay. I didn't expect to spend that much time on that question, but there's so much there. That was really interesting. What I want to spend the bulk of our time on is onboarding. Something that I found myself, and I think you agree with a lot of this but I'll confirm, is that I've done a lot of research into the growth stories of the most successful startups, and what I find, one, is that retention ends up being the thing you got to crack. If you can't crack retention, nothing else matters. And then, two, more interestingly, onboarding ends up being one of the biggest levers to increasing retention which basically A then B equal C, onboarding ends up being one of the biggest areas of opportunity for growth teams both early on and late stage. And so, I guess the first question, would you agree with that general sentiment that onboarding is this huge opportunity and often undervalued?

Lauryn Isford (00:12:22):
Yes, I definitely agree. It depends of course on the shape of business. Not every business should prioritize onboarding first, but if you have some sort of self-serve element of your product, if someone can give your product a try, maybe you have a playground or a sandbox demo, if there's a premium element to your pricing scheme, if you maybe offer things totally for free and don't even have monetization yet, onboarding is that first really important choke point that from which downstream of onboarding so many important metrics and results flow for the business, from converting someone to a paid customer to closing a deal to growing, how many people in an organization are using your product. So, all of that really comes back to onboarding and if you can get that right, lots of good things will follow.

Lenny (00:13:13):
Okay, great. I'm glad we agreed. I already know this, but you spent a lot of time on Airtable's onboarding flow.

Lauryn Isford (00:13:20):
Yes.

Lenny (00:13:21):
And so, I'm curious just to learn about what did you do over the time that you spent optimizing Airtable's onboarding experience, what kind of impact did you see through the work that you did there, and then just any big kind of general takeaways that either you think people should know or that you'll take with you to future opportunities around optimizing an onboarding experience?

Lauryn Isford (00:13:43):
We could talk about onboarding all day. This is one of my favorite things to chat about recently. So, we did have a wonderful activation team rebuild Airtable's onboarding flow over the past 12 to 18 months. This included many projects, including several big ones. So, what you've probably experienced if you signed up for Airtable recently or what you might experience if you create a new account soon is we've built an immersive wizard that we called Guided Onboarding that helped guide you through setting up your first workflow on Airtable, and in doing that reduced the cognitive load of getting started, helped you make more progress faster, and created scaffolding that more than 90% of customers would benefit from to be able to get up and running on a product that's pretty complicated. That was the first piece.

(00:14:39):
We also then introduced some personalization to use case on top of that. So, instead of helping you build something generic, having you build something that's relevant to you. And then we also worked on ongoing education. So, once you're in a workflow, once you've built something, how do we help you level it up to go from beginner to intermediate to advanced? One funny anecdote about this is that we actually called that project The Mole, M-O-L-E, because the design pattern in product looks like a mole. It pops up from the bottom of the screen and gives you tips as you're exploring. So, those are some of the biggest changes we made. We did retire a bunch of our tooltips which were a big part of onboarding for a really long time. So, happy to chat more about that, and then also did a bunch of more incremental optimizations as well. In general, tried to take a portfolio approach to what we did.

Lenny (00:15:36):
Cool. Okay. A few questions real quick.

Lauryn Isford (00:15:38):
Yeah.

Lenny (00:15:38):
What were the three buckets real quick? So personalization, ongoing education, what was the first one?

Lauryn Isford (00:15:38):
The first one was guided onboarding.

Lenny (00:15:38):
Guided onboarding.

Lauryn Isford (00:15:38):
Exactly.

Lenny (00:15:46):
What was the impact of this work, just to give people a sense of the kind of impact you can have on conversion and then whatever other metrics you looked at there?

Lauryn Isford (00:15:53):
We were working on activation for a few years before I arrived at Airtable. There was already an awesome activation team, hard at work. Overall, the investments we made in onboarding over about a six to eight month period that included the wizard, The Mole with ongoing education, and also some personalization together drove a 20% lift in activation rate for Airtable.

Lenny (00:16:20):
Wow. That sounds quite impactful, especially at a company at that scale.

Lauryn Isford (00:16:24):
It's awesome. I would say celebrate any clear statistical significant improvement in activation rate. It's a big victory, and credit goes to the team that really spent many, many hours with customers and designing precisely to build something that could have that big of an impact. I think it speaks to the importance of really understanding what a user needs to be onboarded well, which is not the same as what your business wants the user to be onboarded to. So, delineating those and building carefully is really what made it successful.

Lenny (00:16:57):
Which of these three buckets would you say had the biggest impact? Because I want to kind of get a couple levels deeper to get to what exactly did you do that worked really well.

Lauryn Isford (00:17:05):
I would say that the guided onboarding wizard which is the immersive wizard that helps you figure out how to get started was the most impactful thing we did.

Lenny (00:17:14):
And it's interesting that you had tooltips and this feels like a tooltip-y thing. What is it conceptually? What's the simple way to think about the onboarding wizard versus a bunch of tooltips telling you like, "Hey, Lauryn, click here, next go here, and then check this thing out"?

Lauryn Isford (00:17:26):
Totally. Imagine being in a step-by-step guide where you are asked question, for example, pick which kind of project you're working on, pick what kinds of things you'd like to track for this project, and then as you select from beautiful, easy-to-click buttons that require very little work on your part, something is visualized for you on the right half of the screen. So, you can see your workflow visually come to light as you do the work on the left half of the screen, and all of this is done for you in a very guided and instructive way.

Lenny (00:17:59):
Are there any generalized learnings from that experience of just how to do a great onboarding experience? It sounds like probably avoid tooltips, instead just kind of ask questions and show them progress as they're going through it in kind of like an immersive experience versus here's the product, check out all the cool features.

Lauryn Isford (00:18:18):
I think there is something to be said for reducing reliance on tooltips, but I'm not sure I would go so far as to say the tooltip is dead, as much as I maybe would like to because there are too many of them out there. The reason for this is that I do believe Airtable's customers had a very specific need which was that the effort required to build basic scaffolding was too much and they needed more support, guardrails, bumpers to help them through that, and this kind of guided or immersive wizard was the best mechanism we could come up with to reduce that effort required and to make them feel more supported in their journey. I'm not sure that this pattern is one that works for every product. I think it's one that works well for a complicated product, where figuring out where to go next and how to get started is actually very challenging or has a high cognitive load.

(00:19:14):
So, I would keep that in mind, but in this case, it did work really well for us. I have seen some other products in the wild adopt similar patterns which gives me confidence that it is transferrable beyond Airtable and that there's probably something to it. That's definitely a big learning. I think one other big learning for us was that we had to meet users where they are. We have some awesome advanced features of really cool stuff you can do with Airtable, automations being a great example. However, users don't necessarily need to get that started on day one. They don't need to learn about the advanced stuff when they haven't even looked at a workflow before. So, we really worked hard to prioritize what the user actually needed and to consider what was necessary education versus what could be ongoing education and building it up.

Lenny (00:20:06):
Can you talk a bit more about what that was? What did you actually do to understand the type of user, and then what did you change for them? Because we actually did something like this at Airbnb, and it was a tiny bit successful for host onboarding but it wasn't anything big. And so, I'm curious what it is you specifically did. Did you ask them a few questions and then grouped them in a group and then changed the way the rest of the flow went, or, yeah, what'd you do there?

Lauryn Isford (00:20:31):
Good question. So, at the very, very beginning, we sort of said new users broadly need help. Who are they? What do we know about them? How can we help them? We spoke to a bunch of customers and also watched them get started and looked for patterns in behavior and also clusters. So, someone who is familiar with databases, somewhat technical and prefers to and has experience in building things might have a different need from onboarding than someone who is exploring a tool that was recommended to them for a project minute. With that in mind, there were some clear segments of personas or buckets of users that we could split out to give different experiences. Now that said, when we rolled out the guided onboarding wizard, it was actually just one generic onboarding that was one-size-fits-all, and while escape patches are great, we felt like we could solve, as I think I referenced earlier, more than 90% of use cases or users needs with one generic onboarding to start and then we could personalize from there.

(00:21:34):
When we started to personalize, generally we found bucketing customers by their learning style and their building style was more effective than more classic segmentation, like do you work in marketing, do you work in product management, do you work in operation. The reason for this is that there are many different types of building or workflows that are possible in Airtable. Some are sophisticated for use at work, some are simple for use at work, some are somewhere in between and are for a hobby use case or a consulting use case. Knowing how someone would go about building was more effective than what do you actually want to see on the other side.

(00:22:19):
This means that something like a template which can give you an example of how to build a use case for project management can be helpful for inspiration but might not actually be the best way to teach you how to use a product like Airtable, when instead, we could learn that you're someone who needs more familiarity with databases to be able to get to the next level, or who might need a more visual learning experience instead of a more data-forward learning experience. So, we tried to segment the experience that way and found that that yielded better results on activation than some of the more traditional segments.

Lenny (00:22:52):
And how did you decide which segment that a user was in? Was it a question you asked them right at the beginning?

Lauryn Isford (00:22:57):
We had a really awesome research team that would do some surveys and conversations with customers away from our production experience and away from individual projects. So, we had a really robust read going in to the project of who these different personas were, different building types, different learning types. That said, we do also ask folks when they sign up some questions and depending on who you are or what we might think we know about you or want to know about you, we might ask you different questions and that's in service of helping you get started.

(00:23:27):
I had some big ideas for how we might bring this to life even further that might come to life in the future, such as if somebody's there to just help out, if they're may be a teammate rather than a builder, if they're just there to work with someone else because Lenny invited Lauryn to work on her table because he needed Lauryn to do something or update a sprint, whatever. Lauryn needs really different onboarding than Lenny. So, actually getting that data in the flow is really useful because then we can route customers to a fully different experience. It's amazing how much low-hanging fruit there is to personalize and segment that onboarding experience in so many products that are out there. You just need to be really detail-oriented and precise on who you're working with.

Lenny (00:24:11):
You talked about this experience as activation, and so just digging a little bit further into that idea. One of the important kind of metrics, milestones you got to figure out when you're working on onboarding is what is an activated user, what's the activation milestone, what's the activation metric. I know you have some strong opinions and some really interesting insights into activation milestones based on your experience at Airtable. Can you chat a bit about that and just share what Airtable's activation metric ended up being?

Lauryn Isford (00:24:37):
Yes. So, overall, every growth team needs a north star metric. It's so important to have singular focus on what the business results are that you are working to drive in your team. On our activation team, which as I mentioned focused on onboarding, though in theory there could be other ways that you want to focus on driving activation, we had one north star metric which was what we called our team activation metric. So, this representative, a team of people were activated on Airtable's product and using it in a way that suggested they would be long-term retained. For us, that was week four, multi-user, meaning in the fourth week, more than one person on that team is active and contributing to a workflow on Airtable.

(00:25:23):
This metric is something that our wonderful analytics team determined to be highly correlated with long-term retention. It's also a metric that holds a relatively high bar, so it requires a number of things to be true, that something of substance has been built, that people persist and continue to collaborate, that they're collaborating on a weekly cadence, and also holds a relatively high bar on exactly how they're contributing, meaning that the sum total of this is somewhat hard to achieve which means that we have a hard job and also a high bar as an activation team to achieve that for as many customers as possible.

(00:25:58):
In general, I think an activation rate that falls in a lower percentage range, maybe for most companies five to 15%, is better than one that falls in a higher percentage range because it means that there's likely much higher correlation with long-term retention and you're really working hard to get most of your users to reach a state that they're not reaching today.

Lenny (00:26:22):
I really like that heuristic. So, the idea there is when you're picking an activation metric, you want it to be in the single digits potentially because you're saying that's more likely to be correlated with retention because retention's probably pretty low long term. Is that kind of the rough idea?

Lauryn Isford (00:26:38):
That's a rough idea. Of course, the metric should be correlated with retention no matter what, but if 40% of your customers are still active at week four maybe with a metric that would be week four active rate, then only a fraction of those are still going to be active in month 12, in month 18, and month 24, and I would much prefer to pick a more specific, more precise metric that maybe only 5% of users reach, but know that those 5% of users will be with us for the long haul, and if we could get that 5% even to 6% or 7%, it would have huge downstream effects on long-term metrics for the business. So, that's why I would opt for a more specific metric.

Lenny (00:27:22):
Okay. So, this activation metric, week four multi-user active is a really interesting metric. Can you talk a bit about how you actually operationalize this and put this to work on your team to help people understand what to work on and make sure they're moving the right sorts of numbers?

Lauryn Isford (00:27:39):
Totally. So, one of the first things that we did when me and my team started to revisit week four multi-user active right before we started to rebuild onboarding is break that metric down into all of its component. So, if you really think about what goes into that number, how many teams sign up as a team versus as an individual, how many of them make it to week four, how many of them have more than two people invited versus more than two people who've ever been active, versus more than two people who were active in the fourth week, maybe they have one person active in the fourth week, and then what does active mean, and what are the different kinds of behaviors that constitute contribution or being active. Doing that really detailed work on the metric helped us understand what levers we could pull to have a really big impact on activation overall.

(00:28:34):
Additionally, we actually started using more metrics. So, we didn't just use our activation rate metric week four multi-user active to make all of our decisions. We introduced a few more, and one of them with purely a retention metric for an individual. Are you week two retained? Are you week four retained? The other was what we called Build with a capital B, and this was roughly a sophistication score. So, for someone who's building something, have they reached sort of intermediate levels of use of Airtable? The reason why we added these metrics is we were building new mechanisms for onboarding that were helping users build more effectively and find more value in Airtable, but sometimes those treatments helped users become more sophisticated but didn't help them invite more teammates, or sometimes those new mechanisms made someone more interested in giving us a shot for a few more weeks, but what they built was actually not any more impressive than if they had done it on their own.

(00:29:38):
So, this group of metrics actually really set us free. It gave us those constraints where we could actually measure success in a few different ways and think about activation as being more complicated than just a single metric and celebrate anything we could do to help on a couple of dimensions. So, I know it's a little unconventional to have a few metrics that you work with, but we did find that that was really helpful when we were making big changes.

Lenny (00:30:04):
That is actually really interesting. So, it makes it feel like the core activation metric you talked about was more of an output metric and you kind of realized here's the things we could actually be moving directly. Is that roughly how you thought about it?

Lauryn Isford (00:30:15):
Exactly. It also helped us grapple with some of the tensions we felt which I know a lot of teams working on activation and onboarding feel, which is picking one metric doesn't paint the whole picture of what you're trying to achieve when you help a user onboard to your product and when you educate them about what's possible. So, in having sophistication and retention and an element of team use all as part of the fabric of how we talked about activation, it made us much more well-rounded as a team.

Lenny (00:30:46):
That connects a bit to, so we worked on this post together about how to choose an activation metric and you shared part of this story for that post, and there's a little bit of a debate amongst folks that contributed their opinion on how to decide an activation metric, where it's a debate between is it okay to have a workspace activation metric where it's like how many boards somebody creates, how many Airtables somebody has created versus a user action, like user has created 10 tables or user using it two times a week. I think you're on the side of workspace is maybe a more interesting metric for a collaboration tool, and it's interesting that you end up with both in the end which I think is kind of where folks landed. You probably look at how's the company using this tool and then per user, are they using it consistently. So, I guess the question is just what's your take on user specific activation metric versus workspace level activation metric?

Lauryn Isford (00:31:39):
I really like this question. I agree it is a great debate. I'm not sure there's a clear answer because it does depend on your product. In the case of Airtable, which is a product that has seat-based pricing and generally horizontal adoption, it totally makes sense to have a workspace activation measure because you want to understand in an account, in an organization how many folks are actually using a product and finding value. That can be different for tools that might look like Airtable but have different mechanisms for growth or different pricing or different vertical personas that tend to adopt it. So, I do think there is some variance. I do have a reaction to share with you that's a little spicy-

Lenny (00:32:19):
Please.

Lauryn Isford (00:32:20):
... is that it's important that growth teams are agile and this means that north stars, key metrics, focus metrics will change, and if you're working on the same metric forever, there's probably some inefficiency in actually chasing the biggest impact for the business. So, I would be open-minded about if a workspace or team or account activation metric is always the right thing to focus on. Team activation looks really healthy because your growth team did some really amazing work on it, maybe user retention is the right place to focus next year. Maybe it's more about conversion. Maybe it's more about some other signal for long-term retention, and I would be open to being dynamic and changing that metric over time. Stability in metric is great, it helps with momentum, it helps with building expertise, but sometimes we overfocus on picking the perfect north star metric and by the time you feel like you've found the perfect one, it's actually time to move on to something different and work on a different opportunity.

Lenny (00:33:24):
This episode is brought to you by Eppo. Eppo is a next generation A/B testing platform built by Airbnb alums for modern growth teams. Companies like Netlify, Contentful, and Cameo rely on Eppo to power their experiments. Wherever you work, running experiments is increasingly essential, but there are no commercial tools that integrate with a modern grow team stack. This leads to wasted time building internal tools or trying to run your experiments through a clunky marketing tool. When I was at Airbnb, one of the things that I loved about our experimentation platform was being able to easily slice results by device, by country, and by user stage. Eppo does all that and more, delivering results quickly, avoiding annoying prolonged analytics cycles, and helping you easily get to the root cause of any issue you discover. Eppo lets you go beyond basic click-through metrics and then set you to north star metrics, like activation, retention, subscriptions, and payments, and Eppo supports test on the front end, the back end, email marketing, and even machine learning clients. Check out Eppo at geteppo.com, get E-P-P-O.com and 10x your experiment velocity.

(00:34:34):
Is there an example of that that comes to mind when you talk about being a little stuck on a metric? Is that something you went through at Airtable or anywhere else you worked?

Lauryn Isford (00:34:43):
I've gone through it plenty of times. We actually at the organizational level on the Airtable growth award changed our north star metric a couple times which is a big deal that manifests for several teams. Roughly the arc of that change for us was shifting from being a growth org focused on revenue to a growth organization focused on user growth and customer growth. This for us was a really important moment where we decided that it was most essential in our work to grow the business to bring millions more people onto the platform, using the product and finding value in the product, because we were taking a decade's long view that they could always become monetized or converted customers later, and there wasn't really a rush. We felt that focusing on revenue led us to make some decisions that were a bit more short-term oriented than would be ideal.

(00:35:39):
There's also a dynamic here where in the world of enterprise SaaS, the world of B2B SaaS, there's a new theme called product-led sales that's very hot right now, and this means that often in a PLG company there's some ideal end goal of handing off certain customers to have a sales conversation or to close an enterprise contract. In that case, you might actually prefer to delay revenue for months or quarters or years to manifest it later, and when that's the case, your growth team should be fully aligned in lockstep with sales and with go-to-market team and focusing on user growth is actually the right call. So, that's an example of a big pivot that we made, and in doing that, we felt more strategic clarity and were able to move faster.

Lenny (00:36:25):
That is an awesome story. How long did that process take and any advice for folks that might be going through a similar journey of maybe we should rethink our north star metric not and not be revenue? Any advice there?

Lauryn Isford (00:36:36):
In general, I would say having stability in north star metric for at least six months feels like table stakes to me and that's for the reasons that I cited before, for building momentum, for building domain expertise, and also for compounding impact in areas where you see success, where you notice growth flywheels that you can optimize. However, if you're reaching a point where that north star metric feels like it's old news, maybe you're outgrowing it, maybe you want to work on different things, I think that's great. Be open-minded about changing it up. I would generally try to start with the mechanics of the business and what you think you might be able to drive in terms of metric impact with the resources you have on your growth team. That can look different for every growth team because some of them have marketing, some are more product and engineering, some are kind of a mix of both or even something different than that.

(00:37:27):
So, I would start with what impact do we think we could have? Where do we think the biggest opportunity is to chase? You can literally draw a funnel on a whiteboard and map it out and brainstorm together, do some analysis on the side, and when you see what opportunity feels like the most important thing to chase, try to build a north star metric that reflects the output of that work, rather than drives all of your decision-making from the beginning. A north star metric should really be a measure of what you plan to do, the strategy you plan to deliver is delivering results for the business on the other side, rather than the other way around.

Lenny (00:38:05):
So, you mentioned trials and freemium at one point and I want to spend a little time on this, and I know you also have some strong opinions about this kind of debate. Another debate people have, there's always debates in growth, between offering a trial or offering a freemium product, self-serve, and I think your perspective is you should do both, and I think maybe you call it a reverse trial because I was doing some research. So, I guess is that true?, Is that how you see the world, and then just generally, why do you believe that that is the right approach?

Lauryn Isford (00:38:31):
What is it about all these growth people with their strong opinion?

Lenny (00:38:34):
Right?

Lauryn Isford (00:38:35):
I guess I have so many of them. You're educating me on my own perspectives today. Freemium and free trials. So, to get on the same page with definitions for all of our wonderful listeners, a free trial is when you can use the product for free for a limited time and then your only option beyond that limited time is to pay for use of the product. Freemium would be when there are multiple options for how to use the product and one of those options is an infinitely free version of the product. So, you can use Airtable for free forever or you can pay some amount and have access to premium features.

(00:39:14):
So, with all that in mind, personally I'm in the camp of offering a reverse trial. Funky name, but what that means is offer a trial but also offer freemium. Do both. The reason why I like this is you get an opportunity when somebody shows up and says, "Hey, I'm going to give your product a try today," to show them everything that's possible. Onboarding is a huge component of that. Help somebody get started, have those aha moments and experience initial value, but also this is your moment to showcase everything that can be done with your really cool product, and you have some limited number of days, maybe seven days, 14 days, 30 days, to showcase all of the cool things that your company is building for your customers. That is the beauty of a free trial. It's not just that someone can try your product without paying. It's that they can try even more of the product, all of the premium, amazing advanced offerings that could be possible if they decide they want to settle on a premium plan.

(00:40:17):
When you are deciding if this is something you want to do, I would actually take a big step back from looking at competitive pricing pages and getting into the details and reading blogs and just think about what your philosophy is as a business on monetizing customers. The reason for this is generally the reason to offer a free plan or a free trial but really a free plan, the freemium type of pricing model is if you value letting millions, tens of millions of customers give your product a try, even if they never pay you a dollar. That shows to me prioritization and value of user grab, brand awareness, and exposure of your product more than just revenue. And if that's the case, a freemium pricing structure can be really great for your product, and it give you the space to see if your product can become that household name that everybody is familiar with and can give a try and get some early value and even experience some aha moments.

(00:41:24):
On top of that, you can offer a free trial to show what's possible with premium value and then that really can just be focused space for you to say, "Hey, look what's possible if you pay us $5 a month, $10 a month," and you might even get some extra conversion out of that and some more paid customers. So, in general, that's how I think about it. I like the reverse trial because user growth is important and if you're in a long game where you're trying to grow a business for a decade or more, ideally you're trying to get millions of people onto your product and you can always have that monetization conversation later, but you only get a couple moments where you can say, "Hey, pull out your credit card or let's get on the phone and talk about an enterprise contract," with a customer before you lose trust or lose patience. And so, that focus on helping them discover value and build loyalty to you is much more important.

Lenny (00:42:13):
I really like this concept, a super cool name too. I'm also thinking back to some of the SaaS tools I've used that have had this where I go straight into the pro plan and then I'm like, "Oh, I don't want to lose all these features," and then I actually end up buying it. So, when I'm hearing this, it sounds to me like it's a better version of the freemium approach. I imagine there's still many SaaS tools that are very enterprise-y, take handholding, maybe this goes away. I know Elena Verna who's been on the podcast is just a huge proponent of everyone will be product-led, self-serve eventually, but until that day they're still like, I don't know, I think of Retool I think is very hands-on, handhold-y, front I think is like that. There's all these tools that people don't get really quickly.

(00:42:57):
And so, I guess do you still think there's a need for some of these tools that need sales and customer success involvement to stick with just trial at least for now, or do you think they should all kind of find a way to get to self-serve and a reverse trial?

Lauryn Isford (00:43:12):
I do really agree with what Elena said. I really look forward to the day when self-serve and freemium are possible for every product, but I also recognize that that can be really expensive to build and implement and is not for everyone. So, that's cool too. There are other options. In general, I think freemium and also free trials tend to be most effective when there's something that the person who signed up can actually do on their own without being handheld. It doesn't have to be full functionality. It can be exploring a sandbox or a demo or something they can poke around in and experience value, see that aha moment. That's great. That's a moment where you can give value to that person who's chosen to spend time with your product. If that's not possible, there are different ways to be creative that don't require having premium pricing. You can think about how to use concepts related to PLG and related to top of funnel adoption in different ways.

(00:44:16):
So, maybe you can create custom landing pages or experiences that help showcase value without a full signup or free plan or free trial experience. Maybe you give folks the ability to sign up and while they've sort of signed up as an interested customer, they're not fully experiencing things, they might not even have the option to pay for something yet, but they can learn. There's some resources. There's some education for them to experience. Or, maybe you can think about top of funnel adoption or traffic as being most helpful for extension within customers you already. So, if you've signed contracts with a couple really large Fortune 500 companies and somebody wants to join and signs up on your website from the same email domain, then you can provide an experience for them that might feel like it helps them learn the mechanics that's actually only available to folks who are part of organizations that already have contracts with you.

(00:45:19):
It's a different way of thinking about PLG and not necessarily something you would offer for free, they're already an enterprise customer, but some of those concepts can still have a lot of value and help you grow the footprint of an account in an organization, and those are definitely awesome things to try if you can't offer something self-serve.

Lenny (00:45:36):
So, what I'm hearing is find ways to make things some component of it self-serve so that you don't need to necessarily talk to someone immediately. They can start to understand some element of it on maybe an interactive planning page or some very simple part of the product.

Lauryn Isford (00:45:50):
Exactly. I think the key is to figure out what it would be like for someone to experience value when there's no human sitting next to them, and that value doesn't have to be full functionality of the product.

Lenny (00:46:02):
Awesome. Coming back to onboarding, and this is my last onboarding question, I have another topic I wanted to touch on. Do you have any just general pieces of advice, either probably this will work if you're working on onboarding/things that probably won't work and are common traps that people fall into when they're trying to optimize onboarding activation flows in general?

Lauryn Isford (00:46:26):
I do see a very common trap that I would love to caution against, which is that employees of a company build onboarding for customers, but they build what they think customers want rather than what customers actually want, and that manifests in an onboarding experience that's not very helpful. So, there are two patterns that I typically see. One is naming features. So, imagine you're using Airtable for the first time and you see a tooltip and it says, "This is automations," and it explains what automations is to you. That's not that useful for a user who doesn't really know what's going on yet because they aren't sure if automations are relevant to them, if they're suited to their use case, what exactly the word automation entails. We've named a feature, but it's really sort of an announcement of something awesome that Airtable built, rather than an application that can help educate the user on how they'll receive more value from that feature. Try not to name features. It can be very tempting in practice, even though it sounds easy in theory.

Lenny (00:47:32):
Before you move on, what have you learned about how to actually name things in such a way people understand? Is there some you do there?

Lauryn Isford (00:47:39):
Ooh, naming things in a way people understand.

Lenny (00:47:41):
Versus the feature name, like you just said.

Lauryn Isford (00:47:43):
So, instead of that, I think what would be more useful, given the constraints of using a tooltip that's pushing someone to try an automation would be to explain how the automation is relevant to them, or even better, to enable a one-touch turn-on of the automation feature or set up an automation to complete your workflow where we actually do some of the work and if you click into here, we will show you what value is possible and help you get it to the finish line. So, really focusing on that contextual application or helping to drive towards an outcome, rather than just educating on a name.

Lenny (00:48:23):
And there's an element of smart defaulting, just like starting to do it for them versus do you want this or not.

Lauryn Isford (00:48:29):
Exactly. There's also an element here of segmentation or personalization where you should be sensible about if everybody needs to know what an automation is or if there are only certain folks who actually need to learn about it and others might not need to know.

Lenny (00:48:42):
Awesome. All right. Back to your other suggestions.

Lauryn Isford (00:48:46):
Oh yes, there is one other suggestion which is if you're working on a SaaS product, especially a freemium product, there's probably some pricing and packaging scheme that explains which features are available for free, which features are not, how many you get, and sort of maps out usage of the product, both for free users if you offer a free plan, and then for premium users if you offer premium plans. I find sometimes teams working on onboarding will map onboarding to that pricing or packaging. So, for example, maybe automations, to use the same example of the same feature, is something that's generally premium, that if somebody uses automations they're more likely to be a paying customer. It can be tempting then for an onboarding team to try to push automations to people when they're getting started because of course, we'd prefer if customers use premium features because then they might be more likely to become premium customers, but that is not in the best interest of educating a user on how to get started.

(00:49:44):
So, I do think it's very important to be careful that you are rooted in the customer need and rooted in helping that customer achieve maximum value, rather than sitting in the priors of what your packaging scheme might suggest or what might be in the best interest of the company.

Lenny (00:50:02):
As a growth leader, how do you operationalize that? Is it set some drag metrics? Is it just philosophically, let's make sure we're optimizing the right metric? What's worked to actually avoid that problem?

Lauryn Isford (00:50:15):
I think north star metrics help because a team can be singularly focused on the most important result for their roadmap and their charter. However, guardrail metrics are equally important. So, an onboarding team that builds amazing onboarding that causes a 10% drop in revenue would need some sort of guardrails to make sure that they knew that that might not be the right trade for the business, and importantly, should have the rigor and passion to go deep and understand what caused that drop in revenue and figure out what it was about that onboarding that ultimately caused a guardrail metric to suffer. So, with that in mind, I think guardrail metrics can be very useful and are important to choose wisely. I love working with strong analytics partners on a growth team because rigor and education around how to think about guardrail metrics is something that we should always be thinking about, whether you are a data analyst in functional specialty or a PM or an engineer or a designer.

(00:51:19):
So, that's how I kind of like to think about it. I do think guardrail metrics help and then just being well reasoned and thinking about what's best for the business and speaking about your work as being what's best for the business and the customer overall, rather than being too narrow in your own swim lanes of what you work on.

Lenny (00:51:35):
Great advice. I want to shift to a different topic and this will be much shorter. You have this really cool framework for thinking about the PLG funnel, product-led growth, and interestingly kind of trickles down to the team you build, metrics you choose, and things like that. So, can you just briefly talk about just this framework that you use to think about PLG growth in the PLG funnel?

Lauryn Isford (00:51:55):
When I think about how to grow with PLG in a business that has some element of PLG, self-server, freemium, I usually start with a funnel that roughly maps to the same scaffolding, regardless of business. Whether I've worked on the business, whether I'm supporting the business as an advisor, I love starting with this framework. The first step is join, the second is evaluate, the third is upgrade, and the fourth is expand. This funnel represents the journey of a customer in a PLG product as they advance and develop in their lifetime of using the product. It starts with becoming a part of the account that's using the product or signing up, and you might join because you found Airtable on Twitter or you might join because Lenny invited you to use Airtable. So, there are different ways that you can join that product in the first place.

(00:52:55):
Then importantly, you evaluate if it's right for you, and that word choice of evaluate is deliberately not onboard or activate because it's about what the user needs to see that they are going to get the value that they want in using your product and in building a habit around it. Next is upgrade. Ideally, someone has gone from beginner to intermediate or even advanced in their ongoing education and in getting to know your product over some amount of time and they see premium value and raise their hand and say, "I will convert to it." Now if you offer self-serve premium plans, that's awesome. They can do it with a credit card right in the product. Sometimes this means raising their hand to talk to sales and that's great too, but they upgrade to some sort of premium experience or to more value than what they have when they got started.

(00:53:43):
And finally expand, and vertical says this can be nuanced but with more horizontal tools. Ideally, a few folks, maybe one, maybe a few are using a tool in an organization and then many more adopt it over time, and that expansion drives net dollar retention, it drives brand awareness, it drives more usage in more pockets of the company, it is awesome for renewal rates if you're working with enterprise contracts, and ultimately then also brings new referrals into the product that loop all the way back to the beginning at join.

Lenny (00:54:19):
I love it. And what's cool is upgrade and expansion kind of bake in retention. You're not going to upgrade, you're not going to expand if you're not retained. Can you talk a little bit about how you use this framework? Do you bucket? Do you have these four teams on your growth team that focus on each of these stages? Is it more of a conceptual framework? Do you come up with KPIs for each of these steps? How do you actually operationalize this concept?

Lauryn Isford (00:54:40):
I think this framework is a step to abstract to represent exactly how you should structure your teams or to be represented with four metrics, for KPIs. However, it's a really good conceptual way of grounding your team or your organization in the mechanics of how machine that is the business you work on run. From there, it can become much easier to communicate with each other on where you see opportunity on specific pockets of the product that might be impactful. So, for example, you might be working on a strategy related to landing pages and be able to name that that's going to help drive joins in new organization, and that's a really awesome way to communicate why you might invest there versus investing in something related to onboarding that would help with evaluate.

(00:55:32):
So, I love this framework because it helps everyone communicate clearly and also you can derive from it more specifically what are the opportunities that are relevant to us with this framework in mind, and then revisit it over time to gut check if you feel like maybe what you're investing in now is a bit outdated and needs a refresh, or if there are other pockets of the business that need more attention that you might be able to work.

Lenny (00:55:58):
Can you talk a bit about how you structured the growth team potentially based on this framework and just generally how you thought about building the growth team at Airtable?

Lauryn Isford (00:56:06):
We had what I think is a pretty relevant set of teams. If you're thinking about building out a few in your own product or organization that focuses on sort of a PLG shape of business, we had one team working on acquisition and they were really responsible for the join. So, they mapped actually really well to this funnel. One team working on activation and they mapped pretty closely to evaluate. It wasn't a full representation of what's possible in evaluate. We were pretty focused on the self-serve business and that was different than, for example, helping an enterprise customer evaluate the right offering for them, but that activation team was most closely tied to that second step in the funnel.

(00:56:50):
And then we had a monetization team that worked on monetization and pricing and they mapped really closely to the upgrade part of the funnel. They did touch some other things as well. So, they worked on churn prevention and downgrades. They worked on some billing related projects, but in general, they were most thematically aligned with that upgrade step of the funnel. One area that is more emerging that's interesting is expand. So, when we got started on Airtable growth, we didn't have a team dedicated to that expand piece and it became increasingly interesting to us over time as we started to notice that larger companies were using the product. This meant that there was a bigger opportunity than there had been before to really help drive expansion and get more folks using the product in those accounts. That's an area that emerged later. That's a really good example of revisiting your priors and being resilient or agile in your org structure because it wasn't something we set out to work on initially, but it became a really clear opportunity later.

Lenny (00:57:53):
You mentioned that Airtable is thinking a little bit more about B2B growth versus just kind of B2C where I think it's been historically. Can you talk about that and just how you're thinking about that?

Lauryn Isford (00:58:04):
B2B growth is an emerging space for growth practitioners and hobbyists like me because the playbook hasn't been written the same way that B2C growth or consumer social growth has been. It's a new space, and there are quite a few companies that are really excited about exploring B2B growth and how to apply the DNA and the mechanics of a growth organization to more of that B2B motion or to working with more upmarket customers or enterprise customers. So, it's very top of mind for me. It's a active conversation in the growth community, especially in San Francisco. Overall, I'm really excited to see what we can do by applying this approach to growing businesses, to new types of businesses. It will require some differences in execution model. So, in B2C or in consumer social as two examples, you can experiment at large volumes or you can make changes that impact thousands or millions of people pretty easily.

(00:59:15):
In B2B growth, generally you're working with a much smaller set of customers and also the risk profile can be very different because smaller numbers of customers that represent larger percentages of your company's total revenue must be treated with absolute care, as opposed to a world where you might have millions of folks coming through your product every day and small changes might not have as big of an impact. In an enterprise organization, it's important to be very careful and rigorous and to prioritize that customer's needs all the time. This means that rigor, that customer conversations, that beta testing, that live prototypes and demos are significantly more important and that face time with the customer is significantly more important than it is in B2C growth. So, we'll see what happens. I'm really excited to see more folks who have given growth a try in B2C or in consumer spaces try applying it to B2B because it will become increasingly common in the industry.

Lenny (01:00:19):
Well, with that, we have reached our very exciting lightning round. I've got six questions for you. I'll go through it pretty fast. Are you ready?

Lauryn Isford (01:00:27):
I'm ready.

Lenny (01:00:28):
All right. First question, what are two or three books that you recommend most to other people?

Lauryn Isford (01:00:34):
Ride of a Lifetime by Bob Iger. I give this to new reports on my team. Great book to read when you're thinking about your leadership style, and Rocket Men, really fun story. I love a good story about ambition and achieving awesome things.

Lenny (01:00:50):
What's a favorite other podcast, other than the one you're currently on?

Lauryn Isford (01:00:54):
I like Fifth & Mission which is a local San Francisco podcast on local politics.

Lenny (01:01:01):
Favorite recent movie or TV show that you have watched that you've really enjoyed?

Lauryn Isford (01:01:05):
I really like the White Lotus Season 2. White Lotus was very fun to watch. I also, on the movie front, I'm in a habit of watching Best Picture nominees every year and last year there were a couple movies I really enjoyed, one of them was Belfast.

Lenny (01:01:22):
Oh man, that was an intense movie. I watched that recently. And also, if we should turn this into a drinking game, every time someone mentions White Lotus, we drink. It's an amazing show, but it's definitely comes up often. So interesting.

Lauryn Isford (01:01:35):
Comes up too much.

Lenny (01:01:37):
It deserves to come up often. I love it.

Lauryn Isford (01:01:39):
That's true.

Lenny (01:01:41):
It's great, but that'd be okay. We're going to do a drinking game from now on and I'll have a shot here. Love White Lotus. Favorite interview question that you like to ask people?

Lauryn Isford (01:01:50):
Tell me about a time that you delivered something that was impactful.

Lenny (01:01:58):
What do you look for in an answer when you ask that question? What's your kind of a good sign and what's maybe a bad sign?

Lauryn Isford (01:02:02):
I'm looking for someone to help me understand how they define impact and what it means to them. I think a good answer for growth practitioner is intrinsic motivation about having an impact on the business.

Lenny (01:02:19):
Hear, hear. What are five SaaS products that you use day to day, and you can't say Airtable?

Lauryn Isford (01:02:25):
Figma, Miro, Slack, Gmail, and my fifth one, I need to think about it.

Lenny (01:02:36):
It's because I cut out Airtable. I got you.

Lauryn Isford (01:02:39):
I know, I always say Airtable. Airtable's definitely number five.

Lenny (01:02:42):
Okay. Probably number one. Okay, final question. Speaking of Airtable, what's the coolest use of Airtable you've seen?

Lauryn Isford (01:02:48):
There was a great embedded view, which is the internal term for when you put Airtable on your website in an embedded way so people can check out cool stuff, related to finding COVID vaccine when they came out, which was really awesome. I also appreciated that a similar use of Airtable has become quite popular this year in support of facilitating folks who've been laid off to help them find new opportunities.

Lenny (01:03:15):
Lauryn, this was amazing. I learned a ton. We got through everything I was hoping to get through which I did not expect. Two final questions, where can folks find you online if they want to reach out and learn more and to reach out to you, and then two, how can listeners be useful to you?

Lauryn Isford (01:03:28):
You all can find me on Twitter. I'm @laurynisford. I love hearing about how folks with all different kinds of cool products are thinking about growth. In general, I find all of us are better at growing businesses when we study the awesome wins and learnings of others. So, please, my DMs are open. Send me cool things you're working on. I'd love to learn about it.

Lenny (01:03:51):
Amazing. Lauryn, thank you. Let's go drive some growth.

Lauryn Isford (01:03:54):
All right.

Lenny (01:03:57):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Leveraging growth advisors, mastering SEO, and honing your craft | Luc Levesque (Shopify, Meta)
**Guest:** Luc Levesque  
**Published:** 2023-06-15  
**YouTube:** https://www.youtube.com/watch?v=Xf_ZXIGCQb0  
**Tags:** growth, retention, acquisition, activation, onboarding, metrics, prioritization, a/b testing, experimentation, analytics  

# Leveraging growth advisors, mastering SEO, and honing your craft | Luc Levesque (Shopify, Meta)

## Transcript

Luc Levesque (00:00:00):
We talk about the 10X engineer and we don't really talk about the 10X growth advisor or 10X growth person, but the same dynamic applies. You could argue it applies even more because the right growth advisor can have literally company changing impact. Something I've experienced several times in hindsight when you're like, "Okay, here's the needle in the haystack." And then it's implemented and you can see hundreds of percentages, sometimes over a thousand percent lift when you get it right. It's one of those weird disciplines where the right person at the right time can literally say a sentence that changes the trajectory of your company. You can't say that for a lot of different disciplines, but this is one of them.

Lenny (00:00:36):
Welcome to Lenny's Podcast, where I interview world-class product leaders and growth experts to learn from their hard one experiences building and growing today's most successful products. Today my guest is Luc Levesque. Luc is currently the chief growth officer at Shopify. Before this, he was recruited personally by Mark Zuckerberg to help grow Facebook Messenger, Instagram and WhatsApp. He's also VP of Growth and a GM at Tripadvisor. He's also been a growth advisor to companies like Twitter, Pinterest, Patreon, Thumbtack, and Canva.

Lenny (00:01:05):
In our conversation, Luc shares advice on how and when to think about getting a growth advisor, including how to structure the relationship and what to look for in an advisor. We also spent a ton of time on SEO, how to think about this as a growth channel, who it's well suited for, and how everything is about to change in SEO with Bard and ChatGPT. Plus Luc shares a ton of really interesting advice around the value of self-reflection, building routines, cold plunges, also a couple of amazing stories about working with Zuck and what you learned from him. This is such an insight rich episode and I know you'll love it. With that, I bring you Luc Levesque after a short word from our sponsors.

Lenny (00:01:43):
This episode is brought to you by Mixpanel. Get deep insights into what your users are doing at every stage of the funnel at a fair price that scales as you grow. Mixpanel gives you quick answers about your users from awareness to acquisition through retention. And by capturing website activity, ad data, and multi-touch attribution right in Mixpanel, you can improve every aspect of the full user funnel. Powered by first party behavioral data instead of third party cookies, Mixpanel is built to be more powerful and easier to use than Google Analytics. Explore plans for teams of every size and see what Mixpanel can do for you at mixpanel.com/friends/lenny. And while you're at it, they're also hiring. So check it out at mixpanel.com/friends/lenny.

Lenny (00:02:31):
This episode is brought to you by Attio, a new type of CRM that's powerful, flexible, and built around your data. Traditional CRMs were built for a different era with totally different speed, scale, and data demands. Attio is different. It allows you to quickly build a CRM that matches your unique workflows and data structures. Within minutes of connecting your email and calendar, you'll have a CRM that's already set up complete with customer profiles and automatic data enrichment. You'll also have real-time dynamic reporting at your fingertips. No more slow deployments, outdated user experiences, or tedious manual data input. With Attio, you can build and adapt your CRM on the fly no matter your business model or company stage. Attio is the CRM for startups. Get started today and get 15% off your first year at attio.com/lenny. That's A-T-T-I-O.com/lenny.

Lenny (00:03:31):
Luc, welcome to the podcast.

Luc Levesque (00:03:34):
Thank you. Good to see you.

Lenny (00:03:36):
It's good to see you too. I want to start with a story that you shared once when we were hanging out in the past and something that I'll never forget, and it's about the time that you just joined Facebook and apparently you had some kind of big presentation you had to give to the entire company or the executive staff. And then I just love the way it kind of unfolded and it kind of gives you a glimpse into what it's like to work with Zuck and at Facebook. Can you share that story if that rings a bell?

Luc Levesque (00:04:00):
If remember the story, well, basically I had just started at Facebook about... I'll use those two interchangeably. I remember it as Facebook and I always will. I was three months in and was working on a new area for me. So I came in, started putting together our thoughts on a strategy and was asked to do a presentation in front of the company with Mark on the strategy. So I whipped up a draft strategy, put together some plots and plans, presented in front of the company and went well. And then every six months there's something called the [inaudible 00:04:32] Team Review of Facebook and basically product area leads will go in and present their strategy, how it's going. Again, I just joined three months before, so I walk in no idea what to expect. I am sitting at a table. You can kind of envision it's a big room, a really big room with a bunch of tables set up in a big square with a little microphone.

Luc Levesque (00:04:50):
So I sit in there, there's Mark and all the executives sitting on the other side. And I sit down and it's quiet for what felt like five minutes. I'm sure it was not, but it was quiet for a while, just sitting there waiting for what's going to happen now. And at some point Mark kind looks over, says, "Hey, we saw your presentation, saw your strategy. Now when are we going to start seeing results?" And that was my introduction to Facebook. It was kind of my introduction to working with Mark and was a pretty kind of intense thing to go through. Again, I just joined. The strategy was very much a draft at that point, but I think what it highlights is something that Facebook does really, really well, which you get very quickly when you join Facebook and it's why they're such an execution machine and can build a lot of great product. It's because they focus exclusively on that magic word, which is impact.

Luc Levesque (00:05:44):
And that was kind of my first introduction to working with Mark and just that laser focus on, "All right, got it. Now when are we going to start seeing impact and kind of moving from there?" So it's something that is very much in the culture there and something that is so important. It's something of course that we focus on a lot at Shopify, but it's that difference between, "I don't care how hard you've worked. I don't care what you're working on, what the activities are. What are the outcomes? What is the impact you're having?" I actually really love that word impact and focusing on it because it's vague enough that it covers off any work that is impactful towards the mission and it's precise enough to know what does that mean when you say, "Are you having impact? Or what is the impact we're having?" So it's a great way to approach things. That was my first experience there within a few months. And yeah, we jumped in and started focusing on having a lot of impact from there.

Lenny (00:06:36):
I love that story. There's a couple things there. One is, if I were in your shoes, I'd poop my pants sitting there for five minutes waiting for what do you guys-

Luc Levesque (00:06:45):
That did not happen. I had a report.

Lenny (00:06:47):
Okay. How did it go? How did you deal with it? Or I guess how did you respond?

Luc Levesque (00:06:51):
Well, we had, funny enough, already started having impact, so I was able to at least respond with, "Hey, we've kind of already started in a few ways" and walk through where we were having impact and just focus on the strategy, what our plans forward were and where we wanted to go from there. So I think that's how I responded.

Lenny (00:07:08):
Okay, great work. So something I've started doing actually on this podcast is I've started to keep a little Post-it of, here it is, of themes that continue to recur across companies that are most successful. And impact comes... It's number one on my Post-it here, is just impact comes up so often as something that the best companies continue to come back to and focus on and put a lot of emphasis on. I guess I don't know what the question is exactly, but is that just what you find in the work that you do with all the companies you work with? Just how important it's to come back to impact as maybe the primary thing?

Luc Levesque (00:07:42):
Yeah, I mean I think it's easy for a lot of leaders and companies to get caught up in how hard are people working, what did they do, and recognizing and rewarding activity. I mean, everybody wants to have impact. The companies that truly focus on that are the ones that break through and really make a lot of progress towards the mission. So that seems obvious I think when I say it out loud, but being in that culture and having it really ingrained in everything you do whether it's performance reviews or strategies or these reviews with the executive team, it all gravitates around impact. And I think it's that laser focus on it that matters so much. But I mean I've certainly seen it going other ways where it's more about working long hours. And certainly there's a correlation, to be clear, between working hard and impact, but I find it's just such a precise way to think about how people are performing or what you're doing in terms of is your strategy working? Is the direction you're moving in having the intended outcomes that you want? And yeah, I do think it's all about that.

Luc Levesque (00:08:46):
Being a growth leader where everything's so measurable, impact is something that can be very clearly measured and you know whether you have it or not. So the most important thing that we work on constantly is reviewing what's our strategy, what are we working on? Is that driving towards the top level north star outcome we want? Is that having the impact? And then basically doing everything around that singular north star. So it's very, very important. I think it's more profound than it might seem just from the outside. But if you've worked in different companies, you've probably experienced different versions of this too.

Lenny (00:09:20):
Yeah. I want to spend more time on this, but before we move on, you also have another Zuck story. Correct me if I'm wrong, but Zuck recruited you personally to join Facebook/Meta. Is that true? And then if true, what was that like to be recruited by Zuck personally?

Luc Levesque (00:09:35):
It was an interesting experience, very intense, but also one of the reasons for it was I was living in Canada and my family was there and I had some strong personal reasons why I couldn't leave Canada. But yeah, we had a lot of discussions with Mark. I won't get into the micro details of it, that's more Mark's story to tell than mine. But a few takeaways from going through that experience. As a leader, hiring is the most important thing as we all know. It's a craft and a skill that I'm always working on refining. I have my own playbook that I'm constantly tweaking, testing out different approaches, trying to find the best talent and assessing them and trying to close them and bringing them on board. So I learned a lot through that experience with Mark.

Luc Levesque (00:10:15):
A couple things that stood out were the first one would be that Mark really involved the entire executive team. It wasn't just me talking to recruiting or talent or HR or just Mark, it was the entire executive team. That's something that I think a lot of leaders don't take advantage of. I've seen leaders, I've certainly done this at times where you go it alone or you're working with recruiting, but the reality is all the leaders, all the execs in the company know how important it's to bring in talent and they're always more than happy to help. So that's something that I think more leaders should do is really recruit all of their peers and their leaders in the company to help close. And that's certainly something that happened when I was in discussions with Mark and Facebook about joining.

Luc Levesque (00:10:55):
The second one, which I had I suppose never experienced before, was that they made it very personal. I had these reasons why I couldn't leave. So initially I was excited by the opportunity, but I couldn't see myself moving to California for personal reasons. And through discussions, Mark basically involved my wife, involved my spouse in this, Andrea. We flew down, had dinner with him and Priscilla, his wife. Andrea had ended up meeting with many of the executives at Facebook and really talking through what was holding us back, why we couldn't come, potential options and ideas for how we could come down.

Luc Levesque (00:11:33):
But involving somebody's spouse and family I think is a really good idea because it's a very personal decision to change company. It involves more than just that person you're talking to, it involves the whole family. So that was something that I think is an important thing to have in your kind of playbook for hiring, is really think about the whole person's family and involve them if you can. In fact, Toby did this as well at Shopify. He flew down here with Fiona and we had breakfast with Andrea and them and reviewed a few offers when I joined Shopify.

Luc Levesque (00:12:03):
And then the third thing is just to be absolutely relentless and don't give up and don't let momentum drop. It took seven months for me to go from, "This is amazing, exciting, but there's no way I can make this work" to, "Okay, let's move to Palo Alto." And Mark, the execs, a variety of leaders there were in discussions for months and months and months and never letting the momentum die. That's something that I think is really important. No doesn't necessarily mean no, and in this case it definitely wasn't the case. I had the same experience with Toby at Shopify where we've been talking about working together for over 10 years now. And then finally the timing was right and I was able to join the company.

Luc Levesque (00:12:45):
So just be relentless, involve the family, involve the spouse if you can, and recruit some help from other executives in the company. Those were some of the things that stood out through my experience. But yeah, it was a pretty wild time in my life.

Lenny (00:13:00):
Relentless is actually another word. I wasn't necessarily I'm supposed to yet, but I feel like it's another trend to cross. The most impactful and successful founders is just this like, "I will not give up. I will keep at it."

Luc Levesque (00:13:09):
[inaudible 00:13:10].

Lenny (00:13:10):
And so that's a really interesting example of that in action. I was going to talk about this later, but maybe it's a good time to talk about it now, which is around hiring. So you talked about you have this playbook for how to hire. You mentioned to me that you kind of find that as you scale as a leader, hiring ends up being like the most important skill maybe, maybe one of the most important skills. I'd love to hear your take on just what you found about hiring as you've grown as a product leader.

Luc Levesque (00:13:33):
Well, I think you reach a point in your career where you realize that hiring is the skill you now need to become world-class at because you're not no longer doing the work yourself. You're still of course involved and doing some of the work and getting your hands dirty, but the bulk of your team's success now will be the quality of the hires you make and you truly need to be world-class at that. So yeah, I built this playbook out. I was in Canada in Ottawa when I sold that company, Tripadvisor, and really started growing my team and becoming more Leaning into leadership at the time through that experience.

Luc Levesque (00:14:07):
One of the benefits of being in Ottawa and kind of off the grid if you will, is it's a curse and a benefit as that you don't have a ton of people you can learn from. So it does mean you need to go to first principles and think things through from the ground up. It takes a little longer, but you come up with your own playbooks on how to do things. I think you've seen my blueprint, which is a good example of that where I have this blueprint I put together. When new people join the team, I show them my blueprint, which is basically a list of my quirks so we can really quickly align. That's something that just being in Ottawa and trying to figure out how to be a leader and avoid mistakes, I was like, "Wouldn't it be nice if you had a blueprint? When somebody joined, you can just tell them all of your quirks and you can just quickly calibrate on how it is to work together versus through awkward long discussions over the course of a year."

Luc Levesque (00:14:51):
My hiring playbook's a similar thing. I think of it in three different chapters, if you will. There's finding talent, assessing talent, and closing talent. In terms of finding talent, I do believe that the best predictor of future performance is past performance. So I'm looking for what I call signs of excellence. So I want to know the top people generally have done multiple amazing things in their life, repeated success, not just once. Maybe it was work related, maybe not work related. But generally speaking, if you think back to the stars you've worked with, they've done some amazing things. And that's why I always start when I interview or when I chat with people, I started talking about just trying to understand, "What has been your path? What have you done professionally and not professionally?" And generally, stars going to stand out. It's very rare that there's not something obvious that comes through.

Luc Levesque (00:15:39):
So for myself personally, I'm looking for kind of three different signs of excellence to tell me that it doesn't have to be three. The mental model I have is as you're talking to them, you're getting pluses and negatives. There's red flags you're hearing and there's really great things. And then at the end you can make an opinion of how good this person is.

Luc Levesque (00:15:56):
Another great sign of excellence, and this was just through reflecting on stars on the team and thinking what makes them unique, what about them. One of them is when somebody's boss leaves the company and then comes back to poach them, that is such a strong signal because if you think of what just happened, the leader who knows exactly how good this person you're talking to is, they have the most knowledge of the performance of this individual, they left the company. They've come back to poach them, putting their own reputation at risk by coming back depending on the situation. And they would never do that unless this person was really, really good.

Luc Levesque (00:16:37):
So you don't want to over pivot on one signal, you want to look at the full picture. But those are the types of things I look at to bring in top talent. And I've got this whole playbook, mistakes I've made that I've learned from, things to avoid. And over the years, yeah, I've put together this playbook that I try to follow and I'm always running little experiments to try to make it better.

Lenny (00:16:56):
Were going to that blueprint that you mentioned. A lot of which you're talking about is probably more relevant to senior executive type people because you're looking for... Or maybe not because you're looking for say three.

Luc Levesque (00:17:06):
[inaudible 00:17:06].

Lenny (00:17:06):
Okay. So people early in their career could also have three, say, moments of excellence?

Luc Levesque (00:17:12):
Yeah, I mean just thinking off the top, it depends on the type of person you're hiring, but are they a founder? Have they tried to do something? Did they win an award somewhere? Are they a gold medalist at something? Have they done something that others have not that shows grit, that shows drive, that shows the ability to succeed? And I've seen that you can apply that to any candidate you're hiring.

Lenny (00:17:36):
The implication there is, without that, they're probably not going to be stars, that there's a strong correlation between having signs of excellence and them performing really well in this role.

Luc Levesque (00:17:45):
Correct, exactly. Yeah, I mean I suppose it's possible, but it would be pretty rare that somebody would come in without some sign that they stand above the crowd. And again, I'm talking about you generally want to hire the top 1% of candidates. So when you're looking for the best of the best, you definitely are looking for those signals.

Lenny (00:18:01):
Awesome. Okay, so I'm going to bring us back on the agenda that I had for myself, which is I want to start with talking about advisorships and advising and growth advisors. You've been a growth advisor for a long time to some of the most amazing companies out there, Twitter, Pinterest, Patreon, Canva, Thumbtack. I'm sure there's others that you don't list that are more informal. Now you work at Shopify. And so what I think about here is a lot of founders often think about, "Should I bring on an advisor? What should I look for an advisor? I've heard stories of advisors being useless sometimes. People tell me I don't need advisors." So I guess the question here is just what's your take on when it makes sense to bring on and consider bringing on a growth advisor and what should people look for when they're exploring and talking to a potential growth advisor?

Luc Levesque (00:18:47):
A few thoughts. In terms of when, I don't think you can probably come into early. It's probably harder to find really good ones than it is to time it. But generally speaking, I would say you don't want to focus too much on growth until you have product market fit. So make sure you have a product that users love that's either showing strong signs of retention or has some good loop that you can see that you can start thinking about growth.

Lenny (00:19:08):
Let me follow on that thread real quick because I find some founders still want to have someone come help them with growth even though they know they don't have product market fit, even though this tip comes up every single time when I'm talking to growth person, like, "Wait till you have product market fit before doing growth stuff." So could you just add a little bit of why that's important while we're on that topic?

Luc Levesque (00:19:27):
Growth advice is generally always applicable. And if you can start thinking about how to build your product early, even if it's pre-product market fit, you're not going to do any damage, but you may be wasting some capital on an advisor or a growth person too early. The problem that I see is if you start growing a product that doesn't have product market fit, you're actually doing more damage than good because you have a product that is now being exposed to the market through growth levers and through optimization that is giving a bad experience with your product. And you want that product that you know is tight and you know has product market fit to start building the flywheel and start growing. You don't want it to be growing if it doesn't satisfy that need that you're trying to build out for. So I can see it having more damage than good because when somebody tries something, they're unlikely to try it again. And so that's the dangerous game you can get into. So you're better off with a good product that's satisfying a need and then growing from there.

Luc Levesque (00:20:20):
I will say to kind of play devil's advocate with myself and something that I've done actually in one of the products, I've built several consumer products and grown them, is that sometimes to know if you have a product, you need users to use it. So there's like some subtlety in here, but I would say if you are trying to get users in to start playing with it at scale, I mean try to focus in on a market that is maybe off the grid. Like pick some English-speaking country that's a bit off the grid that you can isolate your marketing to so you can start getting dozens or a couple hundred people per day coming in and giving you feedback.

Luc Levesque (00:20:58):
I've seen that work too. So I'd say wait till you have product market fit. If you do start growing your product early because you need that signal from people actually using it beyond just focus groups and friends or small numbers of people, try to do it off the grid in smaller markets that you can get kind of contain the growth and get what you're really trying to get, which is that signal on is it working or not.

Lenny (00:21:19):
Awesome. Okay, I threw us off track. Let's get back on track. So we're talking about when it makes sense to find a growth advisor and then what to look for and so on that you might want to work with.

Luc Levesque (00:21:27):
I mean, what makes a great growth advisor is somebody who really understands what to do but also why certain growth levers work. It's that kind of deep understanding of levers of onboarding or whatever area they're focusing on that really makes growth advisor stand out. So when you're looking for a growth advisor, you want to have those discussions to see like, "How much depth does this person have? Have they seen a playbook and they're just good at repeating the playbook or are they evolving, are they growing?" The best way to get to know that is to start really asking them questions about growth and growth advising and the certain things that they've done and why they think those have worked.

Luc Levesque (00:22:09):
This can be tricky if you don't yourself know growth. So I think one thing that I have not seen a lot of founders do that I would advise is if you have an advisor already... Because this applies to finding growth advisors, but it also applies to hiring good growth talent. So if you have somebody you know whether it's already an advisor or somebody who knows growth, you can solicit their help in trying to flesh out whether somebody you're trying to hire is of high talent. So if you have an advisor, you can make that one of their roles is vet out any new talent coming in. And if you're looking for an advisor, try to find somebody that you know and trust who can do that first pass. Because for somebody who knows growth that you trust, it's actually not a lot of work for them to vet out how talented someone else's. It's an easy ask to make and something that if you have that person in your network or that worked with you that you can leverage for.

Luc Levesque (00:23:01):
But I haven't seen that too often where founders kind of take advantage of people they know or existing growth advisors to help recruit and vet talent because it can be quite hard if you don't know the growth space to know if somebody's good or not.

Lenny (00:23:15):
That's a really interesting idea and it could be where you find someone that's too busy to work with you, but maybe you could just ask, "Hey, could you just easily help me vet people?" And it takes a lot less time.

Luc Levesque (00:23:26):
Yeah, I've never been asked that, which is, I mean I don't know if I'll start getting asked this now, but it does seem like that's a really simple way to add a ton of value. And as a founder, I mean even if you have to pay this person or whatever you have to do, but it's such an important hire to get right. We talk about the 10X engineer and we don't really talk about the 10X growth advisor or 10X growth person, but the same dynamic applies. You could argue it applies even more because the right growth advisor can have literally company changing impact where they're either building or helping to ideate or helping to implement a growth loop that literally changes the company. As we know, you need a great product and you need a great growth loop. And it's usually just one loop that you need to get right. Most companies have gotten to where they are just off of one really strong channel that they've just dominated, so it's important to get right.

Lenny (00:24:17):
Is there an example of that sort of impact that you've seen in your advisorship or other people's of just an impact from one conversation or a little bit of a help?

Luc Levesque (00:24:25):
Definitely. And I think what I would point to is the advantage of a growth advisor is it takes a long time to understand a channel. Certainly people have to know their stuff, they have to be very good at their craft, their growth craft, but also they have to be exposed to a large set of experiments or an environment where they've just seen what works and what doesn't. So no matter how good somebody is, if they haven't been exposed to an environment where there's a lot of experimentation, a lot of learning, it's very hard for them to internalize that. So once a growth advisor has that, it's takes years to learn it, but it literally can take seconds literally to communicate that. So I've worked with some companies that you've mentioned and certainly have had impact very quickly.

Luc Levesque (00:25:09):
I mean, one example would be a company that I worked with. Now, a public company. At the time, they weren't. On day one, walked in, they presented their strategy, their plans, their funnels and their landing pages. I could see very quickly that there was something they were doing that was a little off and I asked them, "Well, why are you doing it that way?" And they said, "Well, we think it just looks better that way." And I said, "Well, just do it this other way." I remember this because it was such a short conversation and then three weeks later we connected and I heard they had rolled it out and it was a large impact that they had from this one change. This has happened many times with the companies I've worked with, but it's a good example that once you know it, it's not hard to recognize it if you deeply understand it to give advice, but it takes a long time to get the base knowledge.

Luc Levesque (00:26:02):
So I don't do these too often anymore, but when I do advise, I take them very seriously. I focus exclusively on having impact. I think that's really important because like you say, there's a lot of advisors out there. Some of them are great, some of them different qualities, and you really want to make sure that if you are an advisor, you want to be in the camp of when this person comes in, they have a lot of impact and it takes time and focus and energy and alignment and there's a bunch of things we can talk about that that helps to drive that alignment. But having impact is the most important thing, whether you're an advisor or if you're hiring because it's one of those weird disciplines where the right person at the right time can literally say a sentence that changes the trajectory of your company. You can't say that for a lot of different disciplines, but this is one of them.

Lenny (00:26:49):
There's that word impact again,

Luc Levesque (00:26:51):
Impact. Impact.

Lenny (00:26:52):
The point you just made about how one conversation can have a ton of impact is a reminder of why sometimes the price of an advisor feels absurd where like, "For one hour it's like thousands of dollars," but it's because obviously they spent a decade learning a thing and one conversation is all of that work they put into it crystallized for you in the moment.

Luc Levesque (00:27:13):
Exactly. It's something I've experienced several times in hindsight when you're like, "Okay, here's the needle in the haystack" and then it's implemented and you can see hundreds of percentages, sometimes over a thousand percent lift when you get it right. It's exhilarating. It's great. I have something I used to say, which is, you want your impact to be so big there's a slide in the next board deck on try to explain what happened. That can happen when you are advising companies because you're able to share a very quickly insights. But one way to drive alignment is not everybody can do this, not all advisors do it this way, but I personally love just when I do these, which is not that frequent, just purely doing equity because I love the alignment in outcomes where the founder will be successful and you will be successful. So the incentives are really good to drive the right performance and the right outcomes that you want as a founder.

Luc Levesque (00:28:09):
So if you can do it, I would definitely advise founders to bring advisors in for equity if you can. I think the same applies for your internal growth team. You want to make sure that the teams are incentivized not on activities, on doing stuff, because there's a lot of stuff to be done in growth, but really driving the outcomes that you want. And equity's just a great way of saying, "Hey, we're in this together. We're on the same side of the table. Let's go grow this company."

Lenny (00:28:36):
I was actually about to ask you what kind of structure you recommend for an advisorship. Is there anything else you can share about just what you'd recommend a founder do in terms of compensation for an advisor?

Luc Levesque (00:28:45):
There's a couple things. I'm a big fan of equity because of the alignment of incentives. You should think about, without getting into too much detail of the actual structure of the deals, but think about how you vest the equity. The last thing you want is an advisor holding back on sharing knowledge. The ideal engagement would be an advisor comes in, delivers as much value as possible quickly, and then trains your team. And then maybe it's a one-year engagement and hopefully they've learned because the advisor has been incentivized to share as much as possible and to train the team as much as possible. And then ideally you don't need them anymore after. So there's something there about structuring equity vesting. I'm a big fan of vesting earlier rather than later. So think about in terms of structure you're vesting, commensurate with the value you want, which is very much front loaded.

Luc Levesque (00:29:35):
I'm also a big fan of three month cliffs. Something I've done, I always do actually, is listen, in the first three months you'll know both sides if it's working or not. And you want to de-risk that on both sides because it really should be seen as a partnership between the advisor and the founder. If the founder thinks you're not adding value in the first few months, I think they should just tear it up and both sides move on. It's not good for the founder to continue the deal and it's not good frankly for the advisor because they're not, for some reason, able to add value in that environment. So I love a three-month cliff at the beginning where if it's not working in the first three months, you tear up the deal and both parties walk away and de-risk the entire thing, and again, drives incentives in the right way where the advisor is 100% incentivized at as much value as fast as possible. And so that's another thing that I tend to do and I've done it for a long time.

Lenny (00:30:28):
That's a really good tip. Basically don't do it for a year if you're vesting for advisors, probably not even to a year, but yeah.

Luc Levesque (00:30:33):
There's a bunch of ways to do it. Honestly, it's hard enough to find growth advisors that have capacity, so you got to also say like, "What can you do that the advisor's comfortable with?" But yeah, I mean just to be candid, I think you want to structure in a way where you're not dependent on the advisor over time. They're adding a ton of value, they're helping teach the team, they're probably bouncing around because your company's changing, your team's changing, your leaders are changing. But over time, and that can be years, but it shouldn't be indefinite. You shouldn't need an advisor forever.

Luc Levesque (00:31:04):
I've seen a scenario where there's desire to keep the advisor on almost as insurance, like, "If something goes wrong, I just wanted to be able to pick up the phone." That can make sense. But I do think a good growth advisor is incentivized to share as much as possible, as fast as possible to have impact to train your team. And then whether you want to keep them on or not long term as an insurance policy or just to answer questions as things change, that should be a choice and not because, "If we lose the advisor. We're completely screwed." That would be a bad place for you to be in as a founder.

Lenny (00:31:35):
You said it's hard to find a good advisor, 100% agree. Any advice for people to help them find an advisor that might be the right fit?

Luc Levesque (00:31:43):
Yeah, I would say there's more of them these days than there were even just five years ago or 10 years ago. Depending on your situation, if you're a founder, I would start with your investors. I think VCs have an amazing network of advisors. I get, I don't know, a couple requests a week that I'm not taking right now. But that from my experience and what I've seen, that's probably especially the high end VCs, the very talented VCs will have this network. And frankly, it's a great partnership as an advisor for you to have. You can help the companies, you can help the VCs and it helps you. So everybody wins, just asking other founders that had good experience, much like hiring.

Luc Levesque (00:32:21):
The third advice I would give is to find companies that are world-class at what you're trying to grow, what channel or skill you're looking at, and then reach out and see if there's a way to help that way. That's actually how I got started. I was at Tripadvisor and a prominent VC reached out. One of the companies they were working with needed some help on SEO. I was still in Canada at the time, got connected with them, had a phone call, had a significant impact through that one phone call. And rather than joining as an advisor, I essentially helped them out pro bono in exchange for, "Hey, I want to get connected in the Valley." So I was in Canada, I wanted to start another company, I wanted to get connected. So through that tactic where they reached out to a company that was known to be world-class at SEO, I think that was really smart on this VC's part.

Luc Levesque (00:33:13):
And then maybe some advice to up and coming growth advisors would be that first one, I didn't take a single shred of equity or money and just tried to have as much impact as possible and to help out this company as much as possible and then make sure that I was able to get connected to other people that I wanted to meet in the Bay Area. And then kind of things snowballed from there.

Lenny (00:33:33):
I definitely want to chat about how to become a growth advisor because I think people listening here might be like, "Oh, that sounds pretty good. Someday maybe I'll become a growth advisor." But before we get to that, what are things that an advisor are best suited for versus finding someone full-time versus no one? What are the ideal kind of problem sets for an advisor versus say, full-time hire person?

Luc Levesque (00:33:57):
I would say your preference should always be to have somebody in-house. I'll start there because you want to have that as part of the culture. There's so much more that they can do when they're in-house. That being said, if you can't find somebody in-house, then bring on an advisor... Even if you bring on an advisor, some advice to founders would be you want to surround your team or at least one person that you've identified who's just a amazing world-class doer, even if they don't know growth, with a set of growth advisors so that they're learning, that's being put through the culture of the company and that knowledge stays inside of the company. So I'd say I would prefer to go internal, surround these people with great advisors and then take it from there. That would be how I approach it.

Lenny (00:34:41):
Okay. So two thoughts here. One is I feel like this podcast is becoming an interesting way to discover awesome growth advisors. I think over time I'm building this directory of who are awesome, smart growth people that are open to advising. So that could be an interesting opportunity to just look through the folks on this podcast and-

Luc Levesque (00:34:59):
Yep, there's some great people that have been on here. Definitely.

Lenny (00:35:02):
Totally working my way through all the amazing least smart growth people and product leaders. The other is I've noticed they're a lot of the best growth advisors have worked with the same sorts of companies. I find Miro comes up a lot, Canva comes up a lot, Pinterest. All these people that have worked with say Pinterest that I hear about are just awesome. Casey comes to mind, Melissa Tan who's coming out with a podcast, I think she worked with them. Dropbox. Anyway, so maybe one idea, see who these companies work with as advisors and that can maybe point you to people that are worth exploring.

Luc Levesque (00:35:34):
I mean, that's a good idea. It kind of goes back to something I mentioned earlier, which is companies that have a lot of traffic and that have a lot of users are a great learning ground for growth people and for advisors, because no matter how smart you are, you need the reps. You got to go to the growth gym and put in the reps, which is experiments. You've got to try things, things that are going to work, things that aren't going to work. There's a discipline of when something doesn't work, you can learn almost as much as when something works. But you need that traffic, you need that environment. And that's why certain companies have these great people coming out like Casey at Pinterest and other people that have been at these companies that have the traffic, have the culture to support it, to support growth. I don't think that's a coincidence why some of these companies have some great people coming from them.

Lenny (00:36:20):
The other tip I just thought about as you were talking is everyone's launching a Substack newsletter that is doing any sort of advising because there's a lot of power in building an audience and creating kind of awareness of what you do. So I wonder if another tip is search Substack's directory of newsletters for specific things you're dealing with, like say, go to PLG or sales and you might find someone there."

Luc Levesque (00:36:39):
I haven't done that, but that seems like a reasonable way to do it.

Lenny (00:36:42):
That's where we're all heading.

Luc Levesque (00:36:44):
I'm not saying that the people on Substack have this. But as advice to the people listening, is when you're vetting for a growth advisor or growth talent, don't just wait it on the public halo of somebody. That's a common mistake I've seen where maybe somebody's done presentations at a conference or somebody's done... I don't know, but their Twitter following is broad. They can be excellent. That's not a disqualifier immediately, but just make sure not to make the hire just exclusively on that. I've made that mistake a few times and it's a common one to get into. So make sure you're vetting properly, even if somebody with a large following on Substack or Twitter. That's I think an important thing to keep in mind.

Lenny (00:37:25):
1000% agree. I always say that the best product leader is the best growth. People don't have time to sit on Twitter and tweet and write newsletters. They're doing the job, working, building, growing, and maybe eventually they get out of that and start writing. But I 1000% agree, there's a lot of people-

Luc Levesque (00:37:40):
Well, not to disqualify all the people on Twitter.

Lenny (00:37:43):
Absolutely.

Luc Levesque (00:37:43):
Some of them are tweeting [inaudible 00:37:45], but my point is just don't over pivot on the halo. Just look at their past performance. What teams have they been on? What environment do they have? Do they really know growth? And sometimes they do, but I think it's a common mistake to say, "Oh yeah, they have a large following, let's hire this person." That's poorly.

Lenny (00:38:03):
1000% agree. Rarely does a celebrity hire that seems really genius on Twitter and Substack end up being as amazing as you think.

Luc Levesque (00:38:12):
Yeah, it does happen, but yeah.

Lenny (00:38:13):
It does happen. Absolutely. One last question around this topic. People listening might want to become growth advisors, I'd mentioned this earlier. Is there any other advice you want to share? Just like, "If you want to become a growth advisor someday, here's what you should think about."

Luc Levesque (00:38:26):
Yeah, I think the right mental model as a growth advisor is around the same one as an investor. So the most important thing an advisor can do aside from having impact and knowing their craft is picking which companies to work with, especially if you're working for equity. So I'll only speak to that, but you're basically putting in your time, you're picking likely a smaller number. You only have so many hours in the day of companies to work with and you want to make sure there's a likely exit in the future. So for me personally, I have a spreadsheet, like most big decisions that I make in my life. Over the years I've just added criteria and questions to ask myself about the company and then reflect on, "Okay, is this kind of checking all the boxes for a likely outcome?" Because you don't just need to be successful, you need to be successful and for the company to be successful and for there to be liquidity of that.

Luc Levesque (00:39:17):
So you need to put yourself in the shoes of an investor and look at it as an investment. That is arguably the most important thing because you can go and do a great job and then wait many years and potentially not see any reward for it. And I think that's the nice thing about the equity structure in that you're tied in the same incentives with the founder, which is just great in terms of any relationship to have the same incentives, but you want to make sure that there's a good likelihood of a decent outcome down the road.

Luc Levesque (00:39:49):
If I can throw another one in.

Lenny (00:39:49):
Yeah, absolutely.

Luc Levesque (00:39:50):
The other piece of advice I would give is it can take a long time for some of these companies to be successful. That's okay. You should expect that. In fact, you should just go in with that mindset. When I'm deciding to work with a company, I'm in there for 10 years and I know that and I say that. And I say, "I'm in. We're in this together if I choose to work with the company." But it does mean that the structure of the deal needs to reflect that. So you need to have a long tail at the end.

Luc Levesque (00:40:15):
So if you're taking options or RSUs and it's pure of the equity, make sure you have the time for that to happen. There would be nothing worse than putting your heart and soul having impact and then waiting, I don't know, a couple years and then your equity expires. So you make sure there's a long tail. I mean, it can literally take over 10 years for these companies to exit. And you should be okay with that. I think that's okay. You're taking some risks. They're taking some risk on you and that's a great partnership, but you'll just need the time for that. So advice to growth advisors, make sure to ask for a long tail so that you don't end up in a bad spot in the end. And that incentives, again, are perfectly aligned between the founder and the advisor.

Lenny (00:40:52):
This episode is brought to you by Eppo. Eppo is the next generation A/B testing platform built by Airbnb alums for modern growth teams. Companies like DraftKings, Zapier, ClickUp, Twitch and Cameo rely on Eppo to power their experiments. Wherever you work, running experiments is increasingly essential, but there are no commercial tools that integrate with a modern grow team stack. This leads to waste of time building internal tools or trying to run your own experiments through a clunky marketing tool. When I was at Airbnb, one of the things that I loved most about working there was our experimentation platform where I was able to slice and dice data by device types, country, user stage. Eppo does all that and more delivering results quickly, avoiding knowing prolonged analytic cycles and helping you easily get to the root cause of any issue you discover. Eppo lets you go beyond basic click-through metrics and instead use your north star metrics like activation, retention, subscription and payments. Eppo supports test on the front end, on the backend, email marketing, even machine learning claims. Check out Eppo at geteppo.com. That's geteppo.com and 10X your experiment velocity.

Lenny (00:41:59):
So I want to segue to a different topic, SEO. You're kind of the... You tell me, but it feels like you're one of the earliest SEO people in tech. You helped grow Tripadvisor many years ago and it was mostly SEO-driven. I think you innovated a lot of SEO tactics and strategies. And then you helped Pinterest, Thumbtack, other companies that are very SEO-driven. You talked about how many companies grow through one channel and these are all very SEO-driven companies. I imagine Shopify has a lot of SEO work that's happening right now with you there. And so I want to chat about SEO. So I guess broadly SEO is like... It's like this amazing growth channel. It's basically free. It continues to work after you stop doing any work on it for a while. Many founders think about, "Should we invest in SEO? How do we approach SEO?" So maybe just as a first question, what are signs that your product and company is a good fit for SEO being potentially a huge channel for growth?

Luc Levesque (00:42:55):
Yeah, I've been doing SEO for a really long time. It's a lot of fun and certainly being a supervisor was a great learning ground for that, that we were able to really innovate and try new things there. In terms of the playbook that we built out. That was a lot of fun, those years.

Luc Levesque (00:43:11):
Couple thoughts. The first one would be I do think there's an SEO play in any company. Maybe at a different extent, but Google is such a large funnel of existing demand for your product or your product area that there's usually an angle to get some SEO traffic there. So I do think it applies to most companies. I would say if you're an early product that the world's never seen, it's a brand new thing, there might be some creation, some demand creation you need to do, but most of the time there's existing demand in Google where you can harvest demand or there's queries that are related to your topic that you can start ranking for to start building brand awareness. So there's always some angle.

Luc Levesque (00:43:52):
And then I kind of divide websites or online products into two categories. There's the ones which are smaller sites, small number of pages, very targeted at your product and don't have this kind of loop of creating new pages automatically. Most eCommerce sites actually have would a number of pages around the products and about us, those types of pages. That's one type of sites. Let's say they have dozen pages. And then there's other ones with thousands, tens of thousands, hundreds of thousands, millions of pages which are either user generated content like Tripadvisor and Pinterest and others, or marketplaces like Thumbtack and other types of websites like that. Those are generally easier to see a huge amount of impact very quickly because there's such a large optimization surface and ideally it's growing and generating traffic automatically.

Luc Levesque (00:44:40):
I've always thought of LinkedIn as just such a great example of this where you have this viral loop where if you recall when it was just starting, everybody was getting these invites from LinkedIn. Those come and go. You get an invite, you register, you don't. That happens. But the byproduct is when people join, they create this beautiful lightning page, which is your profile that gets indexed. It's kind of like a viral loop feeding an SEO loop that continues to grow. So that's a good example of use generated content which kind of feeds on itself and grows. So there's those two categories. Going back to the first category, if you only have a small handful of pages, the way to think about that is you certainly want to optimize those pages, then you want to start creating content that speaks to your audience beyond that. So you need a content strategy, whether it's a blog or creating new parts of your site that address questions that your audience might have. But generally speaking, I think there's an SEO play in any company and there's just different tactics, strategies, and approaches to get there.

Lenny (00:45:40):
Awesome. I never thought of it that way, that there's kind of these two buckets. So the first bucket is like you don't have a ton of pages that naturally are generated as a part of your experience. And the second is you do. I guess in the second bucket I think of Reddit and Glassdoor and Quora, Tripadvisor, a great example, Pinterest. In the first bucket is the way to generate pages. Basically, it's editorially write content and have people write things for you. Is that generally the strategy?

Luc Levesque (00:46:07):
There's different ways of doing it, but a good content strategy is a kind of tried and true approach. Definitely.

Lenny (00:46:13):
And in that bucket of you don't naturally have a ton of pages, can you primarily grow through SEO? Or is SEO always going to be this minority channel and you have to find something else?

Luc Levesque (00:46:24):
No, it can be a big channel. This is also about creating content, but it's not your users creating the content. You have to go create the content and have some high quality answer to a question that's being asked on Google. I think one thing to keep in mind with SEO is entire industries are based off of single keywords. I remember when I was in the travel industry that literally companies were bought and sold based on one keyword rank. So it's not like, "Oh, it's a little bit of traffic." And I think this is a bit unintuitive with growth. A lot of people, they'll think of growth as linear or it's another channel, it's another thing. I mean, growth done right is exponential. It literally is company changing.

Luc Levesque (00:47:00):
When you're talking specifically about SEO, keep in mind the world is searching for that thing, targeted on that one keyword and likely you're clicking the number one search result. So getting that number one spot is not like, "Oh, that's a little bit of traffic." You can literally build an entire business around that first spot. So don't think that's... Well, maybe it is commonly known, I'm not sure, but it's definitely something that is non-obvious or intuitive I think to most people. And if you have an entire SEO team working on one keyword, I don't think that's crazy because a small number of keywords can define an entire industry or a business.

Lenny (00:47:37):
Is there an example of that sort of situation when keyword's building a massive company?

Luc Levesque (00:47:41):
Yeah, I mean there's a lot I'm sure. I can speak to my own company that I sold to Tripadvisor. It was called TravelPod. It was a travel blogging website where you can think WordPress, but for travel, which I started earlier. It was the first site to do that. I made the mistake of not knowing SEO or growth before I sold the company. And so that was a great learning for me. When I went in, this is a story where we're looking to acquire another site and I thought the product was pretty poor. I remember talking to the founder and thinking... He'd asked me if we'd want to acquire it, and, "The product's terrible. Why would I want to acquire that?" He's like, "Yeah, they're 10 times bigger than you." And, "What?" That was when I realized, "Okay, we've been building a great product and great engineering culture and it is important, but you really need to know this growth stuff." So that's actually the moment I shifted to, "All right, we have to really know these growth levers."

Luc Levesque (00:48:34):
In that space, the number one keyword was Travel Blog. And so owning that was a big deal and we did not own it. I think we ranked number two for a really long time. I can't remember if we got it in the end, but that's just one example where... And there was many, many travel businesses where I always loved looking at a business and trying to figure out, "What's their growth loop? How did they do that?" And it's not like, "Oh, it's a great business. It just grew." Most of the time it's price line crushed it at SEM. Facebook crushed it at a viral loop where you got tagged in a photo, you got an email and you had to go register because there's a photo of you somewhere you really want to see. Tripadvisor did a great job at SEO. In [inaudible 00:49:14], it's just one really strong channel that propelled the company forward. And in this case, it can literally come down to one keyword like we had at TravelPod.

Lenny (00:49:20):
So maybe it's a good time just to give a people a mental model of the different channels/loops that exist. So you've talked about SEO is one, paid search is one. What's the collection for people to think about? Usually as you said, one of the use is the primary source of growth for a company.

Luc Levesque (00:49:38):
Yeah, there's a variety of them. I think you have to look at where the intent is right now. It does change over time, but you have social channels like TikTok, Instagram. Influencers are a great area to engage with there. You have SEO, you have search. I think ChatGPT is another upcoming one that we might want to talk about a little bit where I do think we've never seen that kind of growth for search before and that's a platform that we have to start thinking about how do we optimize for it. Google just announced there are recent changes. They're going to be putting in an AI box at the top, the searchers also, how do you optimize in a world where it's not so much about optimizing for the platform, but teaching the AI what you do and why you're the best in the world at it. So that's another whole area that we could talk about, but that's a big channel I think that that's growing.

Luc Levesque (00:50:29):
Viral loops are always a powerful thing if you can get them to work. That's more about psychology and channel optimization, where you want people to be incentivized to share the product that you have with their friends and then to have their friends come back and register. So you can have one viral loop, you can have secondary viral loops, you can bolt viral loops on your existing products. There's different ways of doing this. And then just backing up. When I think about growth, I don't think about a specific... It's not growth equals SEO and Instagram. For me, growth equals whatever it takes to move the needle. So I get this question all the time, "How do you build a growth team? What does a growth team do?" And I say whatever it takes. That could be zero to one building a new product. It could be M&A, it could be SEO, it could be social, it could be onboarding.

Luc Levesque (00:51:15):
I think that's a better framework to look at. And then if you look at it through that lens, then partnerships easily folds into that where I've seen a lot of businesses get very big on just really clever partnerships, either strategic or broad kind of affiliate based partnerships. So there's a lot of channels. I definitely wouldn't restrict the scope of a growth team to just a small subset, but have a very wide funnel or at least strategy in terms of just test a lot of different things and go after the channels that work and pivot when it does, and then really lean into the one or two or three that really work because sometimes that's all it takes for business.

Lenny (00:51:50):
Well, you definitely nerd sniped me with the ChatGPT, so let's just spend some time there. I think this relates to just the general sense that SEO is always changing and it feels like this is an SEM I guess in this case too. And ChatGPT and Bard, I guess, is maybe the latest change. So what should we know there?

Luc Levesque (00:52:05):
Yeah, I think we're all still trying to figure it out. I was at Google IO last week or the week before. As soon as I saw the search result with the big box of AI, answers at the top, having done this for so long, I immediately knew the impact that I think is about to come. I've seen this play out in travel where Google acquired ITA and did flight search and hotel search. Generally, it's great for users and great for Google and the search engines, but makes it a little bit difficult for the publishers and the sites that are adding value to the ecosystem through being ranked in search results.

Luc Levesque (00:52:42):
So what we're about to see is basically Google, what they showed was a big box on top of the search results that answers the query directly. So if you think about that, that means that there's a lot of queries right now that users are clicking through down on the organic links and getting their answer there, which will be answered directly in the search result. We've seen this play out over the last five to 10 years where more and more answers are being shown at the top. Every time something changes, entire industries are disrupted or are changed. And I think that's going to happen again.

Luc Levesque (00:53:14):
So there's different types of keywords. There's transactional ones like e-commerce keywords with purchase intent. There's navigational ones where you're trying to get somewhere. And there's informational keywords, which is, "I have a question. I'm looking for an answer." It's pretty broad. It's a big area. I think that last category of keywords is particularly at risk. So if anybody listening to this is currently getting traffic on those, you should start thinking about what does that mean when things start changing. And I think the changes will be... We'll probably start seeing things shift to paid. You have to pay for that free traffic.

Luc Levesque (00:53:47):
The second one is there may just be a case where those keywords just don't get many clicks anymore. You might drop down to a very small number of clicks, if at all, because questions will get answered directly in the search results. So it's a big shift. We have to see how things land, but that's, I think over the next 12 to 24 months, if history repeats itself, we'll see that channel change. We've seen this play out in all the different channels. They kind of evolve generally. You can't blame the companies are doing what they have to do. ChatGPT is now 50% of my daily searches and not Google. So I think Google has to react and this is what we'll see. So from a growth perspective, definitely something to start to think about.

Lenny (00:54:25):
Super fascinating. I think about my newsletter and now Google suck it all up and just tell you all the answers. Great. Good news for me.

Luc Levesque (00:54:33):
[inaudible 00:54:34].

Lenny (00:54:39):
Yeah. Yeah. And change is great. Things don't-

Luc Levesque (00:54:41):
It's exciting. It's exciting. I'm just geeking out on growth a little bit, we haven't had a big platform change in a long time. So I'm like, "All right, cool. Let's go see what we can do here. How do you optimize this? How do you get listed if you can?" We're not sure where the placements will be, but that will be the new game.

Lenny (00:54:58):
Yeah, there's actually a lennybot.com that is a GPT bot trained on my content that there's a newsletter post about how it was all built so you could build your own. And so I think my new goal is going to have to convince people to go to lennybot.com instead of Google. Wish me luck.

Luc Levesque (00:55:15):
Hey, you got to lean into it. Yeah, we have a shop.ai, this great AI-based shopping engine. And I'll tell you, I bought so much on it. It's so good. The more you use these technologies, the more you realize how good they are. And that's something biggest coming. It's not just, "Oh yeah, there's another change." I was summarizing the Google change is to some people and originally was thinking this is the biggest change in the last 10 years. And then when I reflected on the last 10 years, I thought this is actually the biggest change since the inception of Google actually. I don't think we've seen something as profound as what's coming. And you really need to get ready for it.

Lenny (00:55:52):
Yeah, I've been using ChatGPT for helping me with interview questions actually, and once in a while there's like a really good one.

Luc Levesque (00:55:59):
Oh, that's cool.

Lenny (00:56:00):
So thank you ChatGPT, bringing me good things also. Maybe one more question along these lines around kind of connecting advisorship in SEO. Would you suggest when you're starting to think about SEO, starting to invest in SEO, you might be listening to this feeling like, "I got to think about SEO," does it make sense to bring on, say, SEO advisor like you? I know you're not available currently, but other folks like you or are an agency that is really good at this stuff or bring on someone full time? Do you have any kind of frameworks for thinking about which direction to go?

Luc Levesque (00:56:30):
It's hard for an agency or a pure advisor without internal help to do a really good job without internal talent at the center. So I would say I would start with just hire somebody internally and give them the mandate and incentivize them correctly to go and own this channel. Even if they don't know SEO, my advice would be get an engineer, get somebody who is just a relentless doer who wants to learn this and surround them with great advisors that I've just seen that work really well.

Luc Levesque (00:56:59):
There are some good agencies out there. Agencies will be working with multiple companies, so it's a little bit harder to get the same impact from an agency. It can work sometimes. But my preference is generally a last resort would be an agency. And I'd much rather have somebody who's internal who knows the business, who knows the keywords, who can have the knowledge internally inside the company permanently and help grow a team around them and have succession in place and a proper team so that you're not too dependent on this one person. But that would be my go-to. And then if you're really stuck, you can use agencies, but my default would be having somebody internal supplemented with agencies if you have to. Sorry, SEO is very specific. I mean, it's a very tight channel that knowing certain things about it can have a big impact. I think you do want people that have that experience that can bring that in from the outside to augmenting internal teams. It'll take a really long time to learn it.

Lenny (00:58:01):
Awesome. I was going to ask that. So you ideally want to find someone that's done it before that isn't just a relentless learner, but is that plus, has done SEO in the past?

Luc Levesque (00:58:08):
Oh, yeah. Ideally, you hire an amazing SEO person who can bring internal. Second would be somebody amazing who can get things done, surround them with advisors. And then in my stack rank, the third would be agencies.

Lenny (00:58:20):
Awesome. And then the other kind of common issue with SEOs, it takes a long time to show impact. Do you have just a rule of thumb of just give them this much time to see if they can make an impact?

Luc Levesque (00:58:29):
I'd say a few things. I'd say if you already have content and pages that are pretty good and getting a decent amount of traffic, it doesn't necessarily have to take a long time. So that would be my first reaction. It can take a long time. Generally, it takes a long time when you have to build new content. So the way to think about Google is it is going to take your content, it's going to show it to its users, people that are searching, and it's going to determine which piece of content is the best to ranked highly. It's not just about little tricks and links and keyword ratios. Those days are over. Those do matter, but it's not purely about that. And if you have a new piece of content, it takes time for Google to build enough trust to say, "Okay, I'm going to start showing this to users now" and then start collecting user feedback and then rank it appropriately. That can take some time.

Luc Levesque (00:59:14):
But if you have existing pages that are ranking eight and they're already on the first page, it doesn't always happen. But I've certainly seen it, in fact more common than not that you could have sometimes hundreds of percentages of lift very quickly. And it depends what you're starting with, is probably the right way to think about it. So if I'm trying to summarize it, I would say 12 months is probably max. If you can't see impact in 12 months, there's something wrong. If you have existing content, it could happen pretty early. It could happen on day one. Actually I've seen that happen. If you have to build new parts of the site, it can take months. I've seen that happen in companies I've worked with where I think it would be like a quarter, we had to wait till we saw a big lift. So it's somewhere between three to 12 months.

Lenny (01:00:05):
Awesome. That's really helpful. Okay, so final topic/final question. You've had a truly incredible career. You've worked with incredible companies, incredible leaders. I'm looking at your site here in a site window and you're like, here's a picture of you and Zuck. Here's a picture of you and Toby from Shopify, and there's more. I'm curious what you believe has been key to your success and your career success that you suggest listeners who want to have some measure of similar success do.

Luc Levesque (01:00:36):
It's probably a bunch of things we could talk about here. Yeah, this is the obvious thing is I think you've just got to love what you do. You got to work hard. You have to have impact. Certainly at the end of the day in growth, that's all that will matter. If I think back to specific things that I do though to pick one thing that's been very important for me throughout my journey is the art of self-reflection. And coaches. I've had coaches my whole career. But the macro theme is you're constantly iterating, experimenting, and becoming the best you can be in your career also as a dad and as a husband, and of course for your own personal health. But that reflection is so important. I've leveraged many, many different coaches over the years and now do a lot of self-reflection through a morning routine that I have and that I've been doing for quite some time that has been a big unlock for me.

Luc Levesque (01:01:32):
The biggest, most important part of that morning routine is dedicating an hour aside to really think about, "What's going well? What's not going well? What am I screwing up? Well, why am I screwing it up?" Which is often more important than, "What am I screwing up?" And of course, "What am I going to do about it?" But as long as you're learning and iterating every day, then you're just making constant progress towards your goals. It's something I do that I love doing. I love thinking. So I literally can just sit there and think for hours actually. I have a dashboard on all the areas that I'm focusing on with red, yellow, green, and just constantly revving on what am I working on improving, what am I doing, what experiments am I running and where am I doing well and where am I not doing well and how can I be better in all areas of my life, including being a leader. There's a lot of different things to it, but I think that's really important and something that I've learned over the years that is probably the most valuable to have as a skill.

Lenny (01:02:32):
I definitely want to spend more time on this. So you said you sit for an hour reflecting on what's going well, what's not going well. Is there more you can share about how you accomplish that, how you find time to do this for an hour?

Luc Levesque (01:02:43):
Yeah, it sounds crazy when you say it, but I do. So I wake up at 5:00. I work out. So I do cardio, I do some exercise. There's this great book called Spark, which is all around the neuroscience of exercise and I really learned a lot from that in terms of having this great morning routine that really boots you up. I kind of call it my bootloader. When I start in the day, if I go through my bootloader, I have just a much better day.

Luc Levesque (01:03:09):
So exercise, stretching, meditation, and then I do a cold plunge now. So I do a bunch of different things. But then I do some reading, but I do carve aside one hour where I go through... And this is probably important and it's where I've landed, but structured self reflections. That's why I have this dashboard. I have certain areas that I think about what's going well, what's not. I track all the experiments I'm writing. I'm just really passionate about if you're going to do something, try to do it as best as you can. This is a habit that has allowed me to sharpen my skills in certain areas.

Lenny (01:03:47):
What are some of these things you're working on? If you can share what's on this dashboard, how can people imagine what this might be?

Luc Levesque (01:03:53):
So there's a lot of personal stuff on it, but it literally is broken down between being a better friend, better husband, better dad, and then better leader. And so on the personal side, I've been known to work a lot of times. Balance is always hard to find. From being a dad and then thinking about how to be better there, I realized about six months ago that I've never actually asked for feedback on how I'm doing. So I asked my kids six months ago, I asked both of them independently, "What's one thing I can do to do more of or do less of to be a better dad?" And they were kind of caught off guard by it. My son's 15 and my other son is 12. And I said, "Take some time to think about it." And after about a month, my son came back and said, "Dad, I got one." He said, "I want to spend more time with you."

Luc Levesque (01:04:53):
So that was very helpful for me to hear. I'm big on routines and habits to make sure that things that you want to do are repeatable and it's not one-off things. So ever since that day, I've now have a daddy date if you want to call it. But every two weeks we do one-on-one time together with each of the boys. They get to pick what we do just so we have that consistent, whether it's dinner or play basketball in the front. But it's all about feedback. So that's one example on the personal side.

Lenny (01:05:27):
This reminds me of a tweet I just saw where someone said that the only people that are going to remember that you worked late for many nights is your kids.

Luc Levesque (01:05:37):
Wow. Wow. That's deep. I like that a lot.

Lenny (01:05:43):
As a soon to be parent, that's going to stick with me.

Luc Levesque (01:05:46):
Wow, I like that a lot. So it's tough, right? It's tough to balance it all out. It's very difficult because you want excel at everything you do in life. So that reflection helps, be it check-in as well of how am I doing in all these areas? And that I find the color coding is helpful for that too, of just doing a bit of a gut check and asking for that feedback.

Lenny (01:06:06):
So it also makes me think about, I was watching a Jeff Bezos interview and ask him what his morning routine was and he said that he just likes to putter around. he likes to just sit around, talk to his kids, read the newspaper. He doesn't book any meetings in the morning. He just finds he just needs a little flex time at the beginning.

Luc Levesque (01:06:22):
Totally. Before I became a dad, I read somewhere that one of the most impactful things you can do as a father is just be there for dinner every night. So I have been there for 15 years every single night. But it was a good reminder it's not enough. Having dinner is important with your family, but in our case there's more you can do. And just getting that feedback and doing some reprioritization is always important.

Lenny (01:06:46):
Speaking of dinners, and maybe just as a last question, I know you do this really interesting thing where you have dinners with interesting people. You just kind of invite them to your house. I don't know if interesting is the right way to describe it, but just kind of interesting people, prominent people. Can you just talk about what that is and what you think about and the benefits of doing something like that?

Luc Levesque (01:07:04):
I think interesting is the right way to think about it.

Lenny (01:07:05):
Okay.

Luc Levesque (01:07:07):
I started this when I was in Ottawa with a bunch of founders there. It's become one of my favorite things to do. Honestly, it's like the bright spot in my month that, I call them guilds. So the word guild is with the builders. That's how it originally started. So Guild Night is what I call it. The idea is basically all interesting people doing interesting things actually want to spend time with each other. That's why I'm actually surprised more people don't do this. But I'll basically have interesting people come, usually five or six. We'll sit around talking about specific topics. So I do one for consumer product, I do one for SEO, I do one for growth leaders and just have really smart, interesting people come and we'll talk about different topics that are relevant.

Luc Levesque (01:07:57):
Sometimes we'll pick a topic, so we'll have a group and then we'll say, "Hey, we want to talk about AI." So one of the advantages of being in the Bay Area is you can find three or four people that likely wrote some of the core code in Google or in AI, and then they'll join. People want to meet. People want to get together and have these conversations. So it's very exhilarating. I learn a ton. It's a lot of fun. I don't know why more people don't do it. And it's a bit of work to organize, but it's also just tactically been a great way to meet fascinating people. It's helped a lot for recruiting, for if you need a back channel. Now you know all these people that are in different industries. But business aside, they're very valuable business wise, but they're just a lot of fun and they've become some of my favorite things that I do.

Luc Levesque (01:08:43):
I'm really surprised why more people don't do it because I think especially now that everybody's remote and we're working from home, or most people are, it's more valued than ever. So it's something I'm looking forward to continuing and always actually through my morning reflection, thinking about what are new ones I can spin up who are interesting people that we want to break bread with. I do think it's important that it's done at your house. If anybody's thinking of starting this, you can do it at a restaurant, but there's something about being in your home or being in somebody's home, five or six people having a great conversation about a topic that's mutually interesting. I think everybody values it and it adds a lot of spice to life. I think it's really important.

Lenny (01:09:23):
Any other tactical tips for making one of these happen? So you do it at your home, you cater. How many people? How long? Anything else you want to share there?

Luc Levesque (01:09:31):
Yeah, so I think the most I've done is 10. That's a bit too much. Six seems to be perfect, six to eight, eight at the max. I do get a catered so you don't have to worry about cooking. The topic, something like a topic that it's common so that everybody can rally around. I do think it's important, like I mentioned, doing it at home. Usually we start around 6:00, we go till 9:00 or 10. It's just been a really good thing that I've learned over time is a really good thing to do to just make for a better life, frankly. Make richer life with some great friends.

Lenny (01:10:08):
And when we say cater, it's just ordering in basically, right? It's not that-

Luc Levesque (01:10:11):
Yeah, you can just DoorDash some food so you don't have to worry about cooking. I'm sure there's other things. I've never really deeply thought about it, but in terms of what are the specific things, I've evolved it over time, but I don't cook anyways, so it would be terrible if I cooked. So this is much easier to do it this way. And as long as you're inviting kind of interesting people, everybody's going to want to come and spend some time and bring some bread.

Lenny (01:10:33):
Well, with that, we've reached our very exciting lightning round. I've got six questions for you. Are you ready?

Luc Levesque (01:10:39):
I think so.

Lenny (01:10:40):
I think you are. Well, question one. What are two or three books that you've recommended most to other people?

Luc Levesque (01:10:47):
So there's one that I've already mentioned, which is Spark. It's the neuroscience of exercise. That's a great book. It's not one of these exercise to stay fit and to live longer. This is really about, frankly, if you exercise and do it in a specific way, they have a kind of blueprint they lay out, it's good for just cognition and kind of horsepower and performance. So that's been a really important one and has been a big part of me building on my morning routine. The second one is when I picked up I think about a year ago or six months, and I recommended it, gee, I don't know, at least to a couple hundred people now because I recommended it to my team. It's called Smart Brevity. Have you heard of this one?

Lenny (01:11:31):
No, but I love the sound of it.

Luc Levesque (01:11:33):
I've always been big on writing crisply and being very tight and not having three-page memos that you're sending off. Especially now that we're remote and we're all doing slack and email and different ways of messaging, how tightly you communicate, how crisp your communication is really important for frankly you getting your point across and also for the other person who's probably digesting a hundred of these messages. So this book is... It's a book on how to do that. It breaks down how to write crisply and the different parts of it. I've definitely seen improvements in the team since I've passed around. So that's a great book frankly for anybody, work or personal because we're writing so much and communication is so key. So that's the second one. The third one is a golden oldie. It's one that I've read many, many times and I recommend from a growth perspective. This one youlikely heard of, it's Influence by Cialdini.

Lenny (01:12:28):
I got it back on my bookshelf there.

Luc Levesque (01:12:30):
Yeah, it's a great book, and it's because it's really the underpinning of so many different product and growth principles that you can apply. So that's just a classic that is good to reread at least once a year. So those are three books.

Lenny (01:12:42):
I'm going to extend this a little bit. I'm going to add two books that are building on your two books, or the first two books, I guess. One is Peter Attia just wrote a book called Outlive. That is-

Luc Levesque (01:12:50):
I've got to read it.

Lenny (01:12:51):
Okay. And it's exactly the same kind of premise of just how important exercise is. I think there's a quote in there of just the only thing proven to help you live longer is exercise. And then Smart Brevity, there's another book that I'd recommend if people want more on though on this topic called Nobody Wants to Read Your Shit.

Luc Levesque (01:13:07):
[inaudible 01:13:08].

Lenny (01:13:08):
And it's by the guy that wrote the War of Art and Bagger Vance. I forget his name off the top of my head, but it's like, "Nobody wants to read your shit. Here's what you need to do for people to want to read anything you're writing."

Luc Levesque (01:13:23):
Yeah. We want to scan. We want to read. Yeah, that's great. I'll pick that one up. Nobody Wants to Read Your Shit.

Lenny (01:13:27):
Exactly. What a title.

Luc Levesque (01:13:29):
That's a great title.

Lenny (01:13:31):
All right, back on track. What is a favorite recent movie or TV show that you've really enjoyed?

Luc Levesque (01:13:36):
I don't watch TV much and I haven't really watched any movies in a while. But I do watch a lot of podcasts on YouTube. Andrew Huberman has got, of course, a great series. I've watched I think everyone he puts out, so I don't know if that counts, but that's-

Lenny (01:13:49):
Absolutely

Luc Levesque (01:13:50):
Okay. So I watched that. And then of course the All-In Podcast is always fun, so I make sure to watch those when they come out as well. A lot of fun and informative. So those are my two, I would say.

Lenny (01:14:01):
Great picks. What is a favorite interview question that you like to ask?

Luc Levesque (01:14:06):
Teach me something about growth that I don't already know. Because... and you could apply this to engineering product, any other area, because it really gives you a sense of what this person thinks is the top of the stack in terms of the smartest thing they know. Whether you know it or not is irrelevant. But sometimes you actually do end up learning some stuff. But it's my favorite question because you can really engage in a conversation around, "Okay, the thing you think is so unique that maybe you've come up with this learning yourself or you've created this tactic and then it gives you a sense of how much they know the craft." So that's my favorite question.

Lenny (01:14:42):
What is a favorite product that you've recently discovered that you just really love?

Luc Levesque (01:14:46):
I've got a cold plunge that I bought that I love. So it's called the Renew Cold Plunge. It's cold but super convenient and I do that every morning and I just love it.

Lenny (01:14:58):
Any advice for cold plunging? That sounds very painful and hard.

Luc Levesque (01:15:01):
I usually start going... I go in a hot tub to warm up, then I go in the cold plunges and back in the hot tub. That's an easy way to get started. But I will say I jumped in yesterday and today without going to hot tub. It was very painful, but I felt so much better after. So I might be changing up my approach, but I'm just kind of experimenting with different things. But that would be some advice. And then just go slow. Start it not too cold, and then slowly make it cold over time. But I think it's a pretty good thing to add in so far.

Lenny (01:15:31):
How long have you spent in the cold plunge?

Luc Levesque (01:15:33):
It varies. Right now I'm doing five minutes. Five minutes at, I think it's 53 degrees. So I've started at 60, slowly bringing it down. But you do have to go slow because I brought it down even further and kind of caught me off guard and got a little dizzy. So you got to find your sweet spot.

Lenny (01:15:53):
Damn. Very Huberman inspired. I imagine this-

Luc Levesque (01:15:57):
Definitely it was part of the source there.

Lenny (01:15:59):
I know people would hear a lot about cold plunges. I guess what have you seen as a benefit just while we're on this topic for people to seriously consider doing this?

Luc Levesque (01:16:06):
So a couple things. Mood afterwards is so much better. You get this great multi-hour boost from doing it. Especially like I mentioned, not doing warm before or waiting 10 minutes and waiting 10 minutes after before you warm up, after you get out, great mood boost. It also helps a lot with sleep. So if you do it at night, which is a little bit difficult, it helps a lot with sleep. Those are probably the two biggest things. And you do get to a point, I'm there now where I kind of look forward to it because you know how good you'll feel afterwards. So when I'm thinking about it, I know it's painful, it doesn't make it easier, but I do look forward to it now. It's a pretty cool thing.

Lenny (01:16:44):
Oh man. I got to get one now.

Luc Levesque (01:16:46):
Yeah. [inaudible 01:16:49].

Lenny (01:16:49):
Okay, two more questions. What's something relatively minor that you've changed in your product development process that has had a big impact on your team's ability to execute?

Luc Levesque (01:16:56):
One change that comes to mind is it's common to hear discussion around you need to experiment, you need to have rigor, you need to look at results, iterate based on those results. That's pretty much common knowledge is how all good companies that execute growth that do it. I think the subtlety is that experiments are great, but they can be slow. You have to look at the results. You have to analyze how things went. You have to learn what's going on. You have to build the experiment. So there's a cost to an experiment and not everything needs to be experimented. And that's not something that I generally hear growth teams talk about. It's usually, "Hey, we need to experiment."

Luc Levesque (01:17:40):
So one thing that we're definitely focused more on lately is this idea of sometimes you just need to YOLO it because it's a better product experience or you just kind of know it's going to work. And if you're YOLO-ing 40 things and three of them work and you can look at pre-post, you can look at holdouts, there's ways of making sure you don't cause major damage, but the speed can outweigh the cost and time it takes to do experiment. So that's one change we've recently implemented. That's been pretty impactful.

Lenny (01:18:09):
Final question. So we met actually a long time ago in Montreal, or maybe it was in Ottawa, in Canada somewhere. I think it was through an organization called C100 when I was starting my company back in the day. And so my question is, what is your favorite Canadian food?

Luc Levesque (01:18:24):
It's funny. My favorite Canadian food, I'm from Ottawa and there's a lot of shawarma, Lebanese shawarma everywhere. I know it's not traditionally Canadian, but Canada's so multicultural, so I'll make this count. I love a good shawarma and it's so hard to find a good shawarma in the Bay Area. We've still been looking here. But my favorite Canadian food or pseudo Canadian is shawarma. If I had to pick one purely Canadian food, and this is related to Montreal where we first met, it's got to be a Montreal smoked meat sandwich.

Lenny (01:18:58):
Excellent choices. You're making me very hungry. I'm going to go get some shawarma, buy me a cold plunge. Luc, this was amazing. We talked through everything I was hoping to talk through. Advisorships, SEO, hiring, building habits, cold plunges. Two final questions. Where can folks find you online if they want to reach out and learn more? And how can listeners be useful to you?

Luc Levesque (01:19:18):
You can find me online at luclevesque.com. So first name, last name.com. And how can they be useful to me? Listen, we're always looking to hire the best of the best. So if you want to work at an amazing company with an amazing team doing very impactful work and learn the craft of growth, please reach out. We're always looking to bring on amazing talent. So that would be the woodway.

Lenny (01:19:40):
Awesome. Luc, thank you again so much for being here.

Luc Levesque (01:19:43):
Thanks. It's great to chat.

Lenny (01:19:45):
Bye everyone.

Lenny (01:19:48):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

## Mastering product strategy and growing as a PM | Maggie Crowley (Toast, Drift, TripAdvisor)
**Guest:** Maggie Crowley  
**Published:** 2023-11-05  
**YouTube:** https://www.youtube.com/watch?v=4LjddcccYIo  
**Tags:** growth, metrics, okrs, roadmap, prioritization, user research, a/b testing, experimentation, data-driven, monetization  

# Mastering product strategy and growing as a PM | Maggie Crowley (Toast, Drift, TripAdvisor)

## Transcript

Maggie Crowley (00:00:00):
If you ever find yourself saying something like, that's not my job, that's probably a thing you should do. And you know what? It probably isn't your job and it probably is someone else's job and you can spend your life getting frustrated at that or you can just get over and get the work done. And people who are willing to just get the work done will move faster. Their products will be more successful and they probably aren't carrying around all that anger and crappy emotion because as a PM, for better or for worse, and maybe this is not how we all want it to be, but you're oftentimes the emotional center of the team and it's your job to keep people motivated, keep people excited, keep them bought into the project, and you just have to keep that optimism going and it's hard work and part of it can be just like, you know what? Let me take that on. I'll do this thing. I'll hop on this sales call, I'll implement this with the customer. You just have to do whatever it takes.

Lenny (00:00:57):
Today my guest is Maggie Crowley. Maggie is currently vice president of Product at Toast. Prior to this, she was VP and head of product at Charlie Health, senior director of product at Drift, director of product at BevSpot, a product manager at TripAdvisor. She's also got an MBA from Harvard Business School. She was also an Olympic speed skater, which is insane and incredibly cool. And in our conversation we discuss the three most common threads across the best product managers that she's worked with, hired and managed how to very tactically write out a product strategy to share with your team and manager why being data-driven is a red flag for product thinking. Why product content you find online can be dangerous. Her best advice for how to break into product management. Also, the impact writing online has had on her career and so much more. Maggie is amazing.

(00:01:44):
I'm excited for you to learn from her like I did. With that, I bring you Maggie Crowley after a short word from our sponsors. This episode is brought to you by Productroadmap.ai and ignition Productroadmap.ai is the first AI roadmapping suite. It helps ensure roadmaps drive revenue by instantly aligning product with your sales and marketing teams to capture upsell opportunities. Built by early leaders from Rippling and Craft, it automatically identifies feature gaps from your CRM data and your customer conversations, adds them to shareable roadmaps, easily prioritized by revenue impact, and then seamlessly closes the loop with sales reps via targeted notifications when feature gaps are closed. As part of Ignition's broader go-to market operating system, Productroadmap.ai can also help create better handoffs and collaboration with product marketing teams by giving both teams the tools to research, plan, orchestrate and measure the process of building products and going to market. Packed with integrations, AI automation and communication tools. It's truly a one-stop shop for product and marketing to bring things from concept to launch. To sign up, go to productroadmap.ai and use promo code Lenny to get 75% off your first year.

(00:03:00):
This episode is brought to you by Composer, the AI powered trading platform now with retirement accounts, algorithmic trading has historically been reserved for the hedge fund elite. Now with Composer, you can automate your trading with a library of over 1,000 strategies that are easy to understand and tweak using an AI assistant and visual editor. Composer is the first ever algorithmic trading platform where you don't need any coding experience. It includes a full range of trading indicators for you to get creative and a Discord community of 2,500 traders to discuss your ideas with. Composer also has a powerful backtester to see the historical performance of your strategies and you can then invest with a single click. Once you invest, composer will automatically trade for you based on the logic of your strategy. With $1 billion in trading volume and over 1 million trades executed Composer already has many big time investors using the platform regularly. Head to composer.trade and use the code Lenny for an extra week of free trial on your composer membership. That's composer.trade.

(00:04:06):
Maggie, thank you so much for being here. Welcome to the podcast.

Maggie Crowley (00:04:10):
Thanks for having me. I'm super excited.

Lenny (00:04:12):
You put out so much content across podcasts, blogs, tweets, I'm sure there's other things I haven't even seen. And so what I've done is I've scoured all of your content as much as I could to find topics that we could dig into in our conversation today. And I thought it'd be fun to start with how to become a successful product manager and what it takes to be a successful product manager, especially long-term in your career. You've worked with a bunch of PMs, you've hired a lot of PMs, you've managed a lot of PMs, and so I guess the question is just what are some common threads you've seen across the best product managers?

Maggie Crowley (00:04:50):
Yeah, it's an interesting question mostly because I've worked in startups, zero to one, scaling stage startups, enterprise, all that kind of stuff. And there's a lot of content out there I think on how those roles are different and how PMs are different across those different types of companies. But what I've seen is that there are some standard things that are the same across the role no matter whether you're a consumer, B2B or startup or a large company and in particular about what sets PMs apart from one another. And the things that I look for when I'm hiring or when I'm looking to promote people or when PMs stand out, even when you're not looking are three things.

(00:05:31):
First, I think the best PMs are really good at breaking things down and simplifying things. So, finding at any moment what is the really truly the only thing you need to do, especially in a big company, there are 8 million priorities, there's 700 OKRs, there's 25,000 projects you could work on, and teams will get bogged down in that complexity. Similarly speaking at a startup, you might think that it's easy to find the one thing to do, but at the same time there's so many fires that are happening and so many things you could do in such a world of opportunity that even just picking one and sticking with it is really difficult. And so the best PMs not only can find the one thing to work on, but they can stay with that one thing long enough to actually finish it.

Lenny (00:06:15):
I think that's a really interesting point, because it sounds simple. Also, just this idea of simplifying, but I think there's so much up there partly because within simplifying is prioritizing and you can almost boil down the job of the PM as they're just prioritizing and telling people what is next. And so I think that's a really powerful point you're making.

Maggie Crowley (00:06:33):
Prioritization is a tough word because there's so much wrapped up in that and what it means to prioritize. And I've worked for people who wanted to understand the formula for prioritization and why this thing and how can you prove that this is the right thing to work on and not that thing. And then a week goes by and then they want to reevaluate the priority and they want to re-litigate the priority. And so it's so much more than just a moment in time deciding, but it's the ability to stay with it and to make sure that it continues to be the most important thing, that you finish it and actually see that it works and that you can get people to continue to stay excited and engaged in that project.

(00:07:13):
Because I think a lot of when we talk about product, it's like, oh, what should you build? What should you ship? But then you actually have to ship that and that can take a week, a month, three months, six months, a year. And so as a PM, your job is to stay on that and be the person who's beating that drum over and over again, and the best PMs are the ones who can do that and have the resilience and the energy to stay with it.

Lenny (00:07:38):
Energy. That's a really important part of that. I'm going to ask you how you suggest people get better at these things. So, either we can go into how you found you get better at simplifying or we go through all three and then we can come back, however you prefer.

Maggie Crowley (00:07:51):
Let's just do all three really quick and then we can dig in.

Lenny (00:07:54):
Sounds great.

Maggie Crowley (00:07:55):
So, yeah, first one, simplifying. I think the second one has to do with this point about sticking with something and it's following up on results. So many people in the spec or the one pager or something will say, okay, here's the metric that I care about. Here's what I want to move. Awesome. Maybe they'll even write a SQL query, get a dashboard going, figure out what the number is today, that gets you some extra points, but the really, really good PMs remember to follow up. Because especially when you're in management, couple layers up in management, I'm not going to remember to follow up on that feature, but if a PM comes back to me and says, "Hey, remember we did that thing, here's what happened." I can't tell you how rare that is and how many times as a leader you might have to ask for that and for the people you don't have to ask that of is one of the best things when I'm looking at PMs and it's easy.

(00:08:43):
It's not hard to do that, especially if you've set up metric tracking or you know how to pull that information or you have somebody who can help you get that. It's pretty easy to do and it's really high value activity. And then the third thing, and I think maybe we'll talk about this later too, is that a phrase actually we were talking about David Cancel before we started carrying the water, and this was a big theme when I joined Drift, and this is about how you can't be a good PM if you're not willing to do the hard boring unglamorous work of customer support, sales, marketing, writing, copy, project management, you have to do that stuff. It's your job. No one else is going to do it, because at the end of the day, you're responsible for outcomes and results. So, you're the person that has to do that, and if you're willing to do that work, that's what's going to make your product successful, which is what makes you successful.

Lenny (00:09:33):
It's such an interesting list because when you ask most people what you need to get better at to become a great product manager, it's always communication skills, collaboration skills, vision, strategy, and it feels like these are input metrics to what it's normally what people think about.

Maggie Crowley (00:09:50):
Those things to me, communication, super important, analytical ability, really, really important. The ability to look at a, especially if you're doing something that has a user experience component, the ability to look at that and understand if it's going to work and build up intuition around that, also really important. Those are things that I would see as sort of basics of the role. These are the things that make you great at the role and strategy to me, and hopefully we'll talk about strategy in a bit. It's one tiny slice. You do a strategy, but it's 5% of the work that you do. Yes, it's important because you want to get your strategy and you need to pick the right products, but at the end of the day, the person who has a good strategy will not be as successful as the PM who ships more stuff, gets more reps and has the ability to actually create impact. So, to me, you could be great at strategy, but if you're not good at this stuff and your stuff isn't getting out the door, you're never going to be that great at the job.

Lenny (00:10:48):
And impact is the other one. Everyone's always like, what makes a great PM? Oh, drive a lot of impact. And again-

Maggie Crowley (00:10:52):
But they never say how.

Lenny (00:10:54):
Right, exactly.

Maggie Crowley (00:10:54):
It's like, cool, let's do a strategy, let's have impact. Then when I was starting off as a PM, I was hearing this advice and reading about it and I was sitting there saying, awesome, I want to create impact. And I'm looking at my job thinking, now what? Yeah, impact. Let's do it. Where is it? How do I find it? Someone help me.

Lenny (00:11:14):
I love it. Okay, so let's go back to these three and I'm curious just what you found helps you become better at these things and also just an example if you can share. So, say what's simplifying? How does one build that muscle?

Maggie Crowley (00:11:27):
This is a tough one because some people, a broad generalization that I think comes up in things like when you're interviewing PMs for a job and you say things like are they a simplifier or are they complexifier? Do they make things complicated? And so some of it's a little bit of just who you are and how you think. But having said that, there's one tool that I use that I actually learned from my dad when I was in grade school, which is when you write something, for example, and a lot of what we do as PMs is written, when you write something, read it out loud, literally just read the thing you wrote out loud and half the time you'll realize it's way too complicated, it doesn't make sense. Or what happens is when someone comes to me and they say, okay, I'm working on this thing, check it out, can you read it?

(00:12:10):
I read it and then I put it down and I say, "What are you trying to say?" And 99% of the time they say, "Oh, users are really struggling with this problem. We found this in research and we think that the way to solve it's to do X", but that's not what the document says. And so my reaction is always, and if anyone who I've worked with is listening to this, they're going to laugh is always, "Just say that. Just say that thing. The thing that you said to me in conversation is the thing you should write." There's no reason why your pros in a document has to be a certain way. We're not in school. Our goal is to get things done. So, those are just some simple tricks that I've used to help simplify what I've already been working on.

(00:12:54):
And as for how to boil things down and really find the most important thing to do, which is another part of simplification, I think the best thing you can do is just get as many reps in as you can, have people review your work and listen to them. There's a thing that happens I think with PMs where you join a company and then all of a sudden it's like my boss doesn't know what they're doing and the highest paid person's opinion and the founder wants to swoop in and mess everything up, but those people had an insight on the market that you're in that made the company worth founding and they probably know more than you and so you might want to listen to them. And so find people who can review your work, listen to them and ask them to help you simplify.

Lenny (00:13:39):
I'll share a couple other things that came to mind as you were talking, because this is a very hard thing to teach and you kind of have to do it again and again and honestly, I have this one manager who taught me to simplify in my writing and strategy docs one-pagers and things like that, and I think that actually had a big impact on my newsletter success is learning just to strip down as much as you can and anything that isn't necessary. So, there's a couple things that I'll share real quick. One is there's this book I read called On Writing Well, that is one of the most impactful books for writing for me, and the whole book is like, I don't know, 20 chapters and every chapter is more things you should cut from your writing and they show all these examples of like, here's a before and here's an after.

(00:14:18):
And all these words were cut and nothing changed. They're completely necessary. So, I think that book can help and partly it's just like what is not necessary? You think all these adjectives are important. Another thing I found really helpful is the rule of thirds, I guess the rule of three, of just always having three. Try not to go beyond three when you're giving strategy bets or priorities or things like that. Just try to keep things under three.

Maggie Crowley (00:14:44):
Yeah, it's a very sort of business school ex-consultant point of view that I do agree with and share, which is there's always three things or fewer, never more than three things. You have to have a nice round couple and if you have a fourth, you've got to figure out how to squish it in there because it just doesn't look right if there's four.

Lenny (00:15:02):
Agree. Yeah, even though I've been guilty of more than three, try hard to avoid it.

Maggie Crowley (00:15:07):
Yeah, you're using notion and you have your three bullets expanding and there's sub bullets, but at least you have that top line.

Lenny (00:15:13):
That's right. The other thing is I think that there's just a focus you need to get good at just like, people often want to lump together a bunch of ideas and then every time you do that it just dilutes everything. So, I think there's just a lot of power and pick the thing, pick the thing that's going to have the most impact and cut other stuff that may have some impact but is much less important.

Maggie Crowley (00:15:31):
I think again, simplification is something and prioritization, which is sort of the same thing, gets tossed around a lot as a thing you have to get good at, but it's really challenging. Getting to the one thing you should do is extremely difficult and being able and having the gumption to say no to all those other things is really hard, because there's probably at any given time, 10 things you should do, but you can't do 10 things, you'll never be successful if you do that in a number of things. And so you have to pick one.

(00:15:59):
And so it's both figuring out how to get confident in your decision and then B, having the willingness, and maybe I should have added this to my what makes great PMs list, the willingness to make the bet and be responsible for it. And that's what I think separates the PM role from a lot of other roles and why it's such a challenging job when done right is because you have to be willing to take responsibility and it's your job to pick the thing and it's your job to be accountable to your team for picking the thing so you better get it right.

Lenny (00:16:32):
Ownership such an important part of just being a PM. Again, coming back to this interview I just did with an ex Amazon guy, that's one of their principles at Amazon is just leaders, basically ownership, feeling like you have ownership of what you're working on.

Maggie Crowley (00:16:46):
I agree, but to me at least the word ownership doesn't have the same oh shit feeling as you're making a bet. You make a bet, that means you know that there's a chance that the thing you're working on is not going to work out and you still have to be the one to do the thing, jump off the ledge, drop in on the ski run. So, ownership to me never signaled that risk that I think comes with being a PM.

Lenny (00:17:10):
Good point. On the simplify concept, it reminds me at Airbnb, one of the core values at Airbnb for time was simplify. Is this idea that we should always try to be simplifying, and then it turned out the founders realized we're not actually great at this and it's unfair for us to say this is a value for not doing it. So, they actually cut it as a core value because their feeling was we shouldn't have aspirational values, we should reflect who we actually are, and they actually cut two different values to be more clear, even though they still want to simplify, they're just like, we're not actually good at this, so why are we pretending like we are.

Maggie Crowley (00:17:45):
I think maybe I'm good at it on paper, but there's been many times where I've been in situations where things are not simple and you just have to keep fighting for it.

Lenny (00:17:54):
Someone's trying to think about, okay, I want to become better as a PM and I'm going to try to start simplifying. What are examples of simplifying? Is it reduce your email length? Is it one pager focus? What are these buckets of things? And then also if there's an example of something you've simplified that comes to mind

Maggie Crowley (00:18:12):
On what to simplify and more specifics, I would say anything can be simplified and shortened. Maybe another way to say shorten it. Definitely emails. I read them sometimes don't love them. Make them short. The Minto principle is something that I would recommend everyone do, which is put the headline, the full conclusion first and then you're supporting argument second.

Lenny (00:18:36):
I have a newsletter post about that exact concept that people that I will link in the show notes that gives you-

Maggie Crowley (00:18:41):
Fantastic.

Lenny (00:18:42):
The Minto Pyramid principle.

Maggie Crowley (00:18:42):
Yes, everyone should do that. A lot of new PMs fall into the trap of thinking that they should have some sort of buildup. Don't do that. Just tell me whatever the thing is, everyone will thank you. Doing things like that, things like you said, limiting your strategy docs, your conclusions, your next steps to three things maximum. I would generally say a rule of thumb would be pretty much every doc you write, you can delete the first two paragraphs that you've written. You don't need them. My dad, again, to go back to my dad when I would write, and this sounds cruel, but I promise it wasn't. When I would write a paper for school, he would just, and this is we didn't really have computers, whatever, he would just take away the first page and he'd be like, just start here. He would go, "Everything on the first page is crapola, don't use it."

(00:19:30):
And he wouldn't even read it, which would drive me crazy. He would just like, "Oh, it's crap. I don't care about that." So, I would do that and then just get other people, there's probably somebody around you that's good and find people to edit your work and to look at it. I have a little Slack workspace that has three people in it, me and two other women who are product leaders, and we oftentimes send each other our work still and we say, "Hey, I'm struggling with this. Can you read it? Help me make it simpler. Can you help me fix this up?" And we do that for each other. So, find a peer maybe who's in a non-competitive space who can do that for you. I mean I still use those people to help me.

Lenny (00:20:10):
That is extremely cool. Can you talk more about this group that you have?

Maggie Crowley (00:20:15):
Yeah, I don't know if it's a group. It's like three friends. Shout out Alexa and Daphne. Yeah, I mean the three of us all worked together when we were at Drift. We've stayed in touch and I've just found that in order to be good at your job continuously, you need people who can help give you feedback, and the more senior you get, the harder that is. And so having people who can give you another point of view who maybe you can vent to if it's not appropriate as a leader who can give you other experiences that they're going through has been incredibly valuable. And so we just have a little group chat that is focused on product.

Lenny (00:20:49):
That is so cool. Is there a tip you could share for someone that wants to create something like this? Is it important for you to have worked with them before? Is Slack a good way to communicate? Anything there that's just like, oh yeah, here's a cool tip.

Maggie Crowley (00:21:00):
Slack just worked for us where we are during the day, and I think having easy access to it was important. You could probably use WhatsApp or a literal group text. There are small community, there's one, I worked in healthcare for a year and a bit, and there's a Slack community that somebody organized for heads of products and healthcare startups that is similar to those really, really powerful and a really great space to be in. And so you just have to kind of suss out where these things are. You work with amazing people and there's people around you who are going to become your friends, and so keep an eye out for them and keep in touch with them when you leave a job because you never know when they might become your little Slack workspace.

Lenny (00:21:39):
Oh, I love it. Okay, I'm glad we talked on that. Okay, back on track. The second bucket you described as following up on results, is it just do that. Is there anything more you can add there?

Maggie Crowley (00:21:49):
I put reminders in my calendar. I mean, yeah, it's just do that. But if you're launching a product, usually you release something and you have that initial push of a couple of weeks where you're finding bugs and you're maybe you're pulling metrics and everyone remembers it, then I would remember two weeks after that, a month after that, six months after that, put a reminder in your calendar to check your dashboard or check the metrics or check whatever it is that you were doing, and you won't forget and then share them with whoever might care about it. And it's as simple as that.

Lenny (00:22:20):
And is the reason this is one of the three things you think are most consistent across great PMs, that it helps your manager see you like, wow, Maggie's so on top of everything, or is it more that you learn from that experience and drive more impact or is it both?

Maggie Crowley (00:22:36):
It's definitely both. I'm not going to pretend like if you're just great at your job quietly that you're going to get what you want. Just if you're toiling in the background, doing a great job getting results. If you have a great manager, maybe you'll be successful. Great managers are few and far between, and I am of the opinion that I never wanted to rely on someone else to get what I wanted. And so I would always make sure to share that, always make sure to share my progress because I didn't want to leave it up to chance that someone would notice. So, I would suggest doing it for both reasons. And that's one of those things that people want to pretend that everything's perfect and we're all great and we're always going to get what we want and always going to get that promotion, but you have to work for it.

Lenny (00:23:22):
I love that point. It reminds me what I find one of the most important traits of a great product manager is they create this aura that they've got this, they put something on their plate and they're not going to drop it, that the threads are not going to be forgotten. And this connects to me there. They feel like Maggie's going to tell me what happened with this experiment. I don't have to think about it as a manager.

Maggie Crowley (00:23:45):
Yeah, that's a really good point. And then you mentioned this a little bit ago, the side benefit is that you learn more. You will go back and learn why something happened or why it didn't happen, and the more that you follow up on what you've been doing and the more you learn, the better you get every time you ship something. To me, the other answer of what makes a great PM is family shipped a lot of stuff. The more you ship, the more you learn. And that's why it can take years to build up expertise because you just have to ship a lot of stuff.

Lenny (00:24:19):
There's a lot of people that are always frustrated. They're not getting promoted quickly enough as a PM. They're not moving off the ladder like, oh my god, I've been a PM for two years. I'm not a senior PM yet. Can you speak more to just that thought and just how long it takes to get actually good? I guess I'll share briefly in my experience, it took me four years to actually know what the hell I was doing as a PM and then things started to really take off. What's your experience?

Maggie Crowley (00:24:40):
I would say similarly, it took a lot of years to feel confident that I knew what I was doing. My first PM job was a product management rotation job at TripAdvisor. I had no PM background. It was after business school and I left those two years thinking, yeah, I've worked on four different teams over the two years. I've shipped all this stuff, I'm good. Went to a startup, there was another product person there, they left and I was the only product person at the startup. And I realized really quickly, I had no idea what I was doing. I had no one to learn from. I had only had two years of experience and I was not ready for that job. I didn't feel confident in the decisions I was making. That's why I joined Drift is because that team had all these really incredible product thinkers on it and they were shipping all sorts of stuff. They had all this momentum and I thought, okay, that's where I'm going to go to learn.

(00:25:29):
And so then two more years. So, that's five years until I really felt like I knew what I was doing. And that's because it takes a long time to ship stuff. And so to people who want to progress, you can progress by job hopping, you can progress by going in and out of startups. But to me staying at that, when I was at Drip, I was there for almost four years. I got to see two or three cycles of the same product and I learned more from that than I did out of the year or so I spent doing other things each at a time because you got to see the consequences of your decisions and that's rare. And people, myself included, of course you want to get promoted, of course you want to move up. I'm ambitious. Lots of people are ambitious, but for better or for worse, spending the time is really helpful and I think allowed me to move faster later because I had just spent the time grinding it out for a while in order to be better later.

Lenny (00:26:31):
So, is that advice you often give of go deep into a company or a product versus just bounce and track a bunch of different companies or depends?

Maggie Crowley (00:26:39):
It depends. There are lots of really good reasons to bounce. I've done it, many people have done it, but I was surprised at how much I value that experience of having stuck around for a while and how much I learned from it was something I hadn't expected going into it, especially because you don't hear that point of view as much or as I wasn't hearing that point of view as much when I was thinking about the sort of arc of my career, but I'm glad that I did it. And then of course people always want to get promoted, always ask that question and my answer is always create impact and that can take time.

Lenny (00:27:16):
At my first job, I was there for nine years and then I started a company for a year and a half and then we sold to Airbnb, and then I was at Airbnb for seven years. So, I'm very much on that train of just, not that I intended for that to happen, but I definitely went deep and I think there's pros and cons, but there's so many pros to that, so many reasons. Okay. Let's talk about the last part, which is the third point you made, which is carrying the water, I think is how you described it.

Maggie Crowley (00:27:42):
Yeah. This one, there's no tips and tricks. It's just do the work. If you ever find yourself saying something like, that's not my job, that's probably a thing you should do. And you know what? It probably isn't your job and it probably is someone else's job and you can spend your life getting frustrated at that or you can just get over and get the work done. And people who are willing to just get the work done will move faster, their products will be more successful and they probably aren't carrying around all that anger and crappy emotion.

(00:28:17):
Because we touched on this earlier as a PM for better or for worse, and maybe this is not how we all want it to be, but you're oftentimes the emotional center of the team and it's your job to keep people motivated, keep people excited, keep them bought into the project, and you just have to keep that optimism going. And it's hard work. It's really hard work to stay positive and to keep people amped for that thing. And part of it can be just like, you know what? Let me take that on. Let me grab that, whatever. I'll do this thing. I'll hop on this sales call, I'll implement this with the customer. You just have to do whatever it takes.

Lenny (00:28:55):
It reminds me of one of your lessons that you shared, in one of your podcast episodes. It was one of your PM lessons of 2021, and the lesson was, when in doubt it's your job as a PM, which I think relates very much to which it just shared. Can you speak to that?

Maggie Crowley (00:29:12):
It might actually make sense to put this in the context of the other roles that are part of the team. So, as an engineer, your job is to write the code to really reduce this down and build the thing and make it work to spec. As a designer, maybe your job is to design the thing, design the solution, design the user experience. Obviously there's lots more complexity in that role. Design your amazing engineering, your amazing TLDR, caveat, whatever. But as a PM, you don't have that thing, right?

(00:29:41):
It's not like, oh, my job is just to write the one-pager. That's not true. Your job isn't just to pick the problem. Your job is to deliver a business result. And so you're uniquely positioned to have to fill in all the gaps because no one else is incentivized to do that. As an engineer, you can finish your work and hand it off and say, I did it, and the good ones care, but you don't have to care. As a PM, you're not going to do your job unless that problem gets solved for the customer or the user at the end of the day. And so your job is to make sure everything happens for that product.

Lenny (00:30:17):
It reminds me of another interview you did where you talked about how a lot of the PM job sucks. It's not as glamorous as people often think, and most of the job is these really boring, annoying things. I guess, is there anything you want to add there of just a lot of people want to get into PM, they're like, oh, I'm going to run the show. It's going to be so great. I'm going to be a product manager and tell people what to do. But that's not how it is.

Maggie Crowley (00:30:41):
It's just one of those things that people, and when I joined product, it was just sort of becoming a cool job. It wasn't the hot job on campus when I was in business school. That was more private equity, venture capital. And now there's a sense of cachet around it. But again, it comes back to that earlier point, which is you do get to do cool stuff. You get to decide what gets built. That's cool. You have a lot of ownership like we talked about. You could see it as you have a lot of power, but at the same time you're responsible.

(00:31:12):
And so with that comes this responsibility to get it right, to make the right bets, ship the right products, get them out the door. And so there's a lot of bullshit work you have to do. Again, project management is one everyone hates on. QA is a really good one. You should QA your products. That's great if you have a QA team, you should QA them. You should know how they work. You should implement with your customers, you should be able to sell them, you should be able to find users. All that stuff is stuff that you should be able to do, and none of it is above you.

Lenny (00:31:42):
If someone is listening and they're not a PM and they are not convinced to not get into product manager, they still want to become a PM, what is your best advice for selling that is trying to get into product management of how to actually break into product management?

Maggie Crowley (00:31:55):
I thought about this one a lot and I consulted the Slack workspace team. Because it's been a long time since I've tried to get into product. And so I didn't know what was going on these days because it's hard and I don't know if things have changed. I went to business school and that's how I got in. There was a program that took MBA students. I think there are some entry-level programs out there, big tech companies, if you can get them, I think they're really hard to get because they're very few and far between. And so the most common two paths that I've seen are people who switched laterally within a company. Again, challenging but can be done. Or people who joined startups. So, when I was at my last startup, I did hire someone who was coming out of business school who hadn't been into product into a PM role. And I can't say I wouldn't do it because it was awesome and she was amazing, but it takes a lot of work.

(00:32:49):
The reason why people don't do it is because as a manager, it takes a lot of work because there's so much that these people need to learn. And what we ended up doing is she and I spent four months working together in a WeWork in person to help her onboard really quickly into the role, which was so rewarding. And I loved every second of it, and I wish I could do that again and again and again. But to get that, she basically just hounded me. Christina, if you're listening, you emailed me a lot. We talked a lot and we waited until the time was right and then you finally convinced me to do it. So, I don't know. I don't if there's a reliable path that I can say this is what my advice would be other than try a startup network. See what you can do.

Lenny (00:33:33):
And you've made up this point elsewhere, which I think is an additional key piece is once you have a PM title on your resume, everything gets easier. As a hiring manager, I'm just like, I look at a resume like, oh, they've never been a PM. This isn't the role. It's rarely that someone wants someone that's never been a PM.

Maggie Crowley (00:33:51):
Yeah. And I tell people, I do unsurprisingly talk to lots of people who either are in product or want to be in product. And that's one of the things I always tell them because if they're deciding between roles and they have an opportunity to do something, and my advice is always, if you can get someone to stamp you with the product manager role, take it. Because to your point, it's what we screen on. It's for better or for worse, it's just like you have to get that first job. And then once you get that first job, it all gets easier. You can get in and then you can talk about your experience because then the second question I have is, what have you shipped? So, it's like, have you been at PM before? What have you shipped? And it's fascinating how quickly people can't answer that question. And the people who can are always several steps ahead of the people.

Lenny (00:34:36):
Let's shift topics and talk about product strategy. Many people are told you need to get better product strategy. You're not great at strategy. A lot of people are also just confused, what is strategy? How do I get better at strategy? How do we describe a strategy? And you have a really great explanation and overview of how to think about this stuff. So, I'd love to hear your take on just how do you actually write out and describe a strategy.

Maggie Crowley (00:35:04):
Sure, yeah. And another thing that happens, and I'll give the outline, but another thing I hear, especially as you get further in your career, and unfortunately if you're maybe an underrepresented person in tech, is that you need to be more strategic. And so that's feedback that almost always happens, especially if you're a woman in product, in tech who's knocking at the door of a leadership role. You've probably gotten that feedback. And so I made it my mission to figure out what the heck is this thing? How do I do it? How can I do it in a way that is demonstrable so that I'm never getting that feedback that's like, oh, she's not strategic. And so what I did was something that I kind of did in the background because I had an engineer who I worked with who really wanted to understand why we were doing what we were doing, and he was not satisfied with sort of a surface level answer.

(00:35:57):
And he was just pushing and pushing and pushing. And so what I did was I just wrote out a Google doc and I started with like, okay, and not fancy, these are just bullets. What is the mission? What is the point of the company? What are our goals? Maybe we have some sort of high level framing of what we're working on. And then I had this big section that was just the landscape. And in that section I put in what's going on with our business? What's happening with our products? What's our point of view on the market? Who are our competitors? A SWOT analysis, key risks that we might be facing. Just dump that all on paper. Then what are the current quarters business goals or however you do planning, what are the current things that your company's working on? Then I put in, all right, that's sort of the context that we're operating in.

(00:36:44):
Then I wanted to understand where are we. So what is an honest accounting of the current state of your product, the business overall, and then the specific area that you're working in. What works, what doesn't work? What are your customers saying? Bottoms up feedback, users, customers, teams, what are your support tickets? Get that all out on paper. And then really importantly, where are your technical hurdles? What are the big pieces of tech debt? What are your engineering and technical teams always harping on that they want to invest in? Are there some big things coming down the pipe that you need to think about? Just get everything on paper. And then usually in the process of writing all that down, you'll start to see, okay, I kind of get where we are. I kind of get what the challenge is. And then you write a section that's like, what's the opportunity?

(00:37:34):
From all of that, what's going to bubble up as the top one or two opportunities for your team? Where do you want to play? Where can you win? Where's the unique? Based on your unique competitive advantage, where do you think you all should be and why? And then based on that opportunity, what are the challenges? So, what's going to be the hardest about taking advantage of that? What has to be, another way to frame it is what has to be true about the world for that to work? That's a one that's been helpful. And then what would you do? Take a swing at writing down your solution, what you would need to build, how might it work? Anything that you have, this is where I would say three bullets, maybe what you might want to do and then a plan. If no one else had an opinion, how would you go about it?

(00:38:26):
How would you sequence it? What would you do? How might you get the team to work on it? What would your team have to look like? How much would it cost to do it? All that you can start to layer in all that kind of stuff. And then I just share the doc. Share it with everybody. There should not be any secret. And you should be able to walk all the way from your company's mission down to the individual priority on your team and see the logic chain and why you got there. And if anyone doesn't agree with it, they can call out where their disagreement lands in that landscape. But at least then you've put everything on paper, you understand how you got to where you're going, and then you can have an argument about the different pieces and points of data and feedback that you're getting, but at least people understand how you got where you got. And then it doesn't become like, I don't agree with you. It becomes, I don't agree with this point.

Lenny (00:39:18):
This is such a cool way of doing it. By the way, is there a template that we can point people to that has this sort of-

Maggie Crowley (00:39:23):
There's not, I've only ever done it in a loose Google doc and then it just grows and changes. I can maybe try to write up those bullets, but it's just like I just make headers and then I just start dumping content in it.

Lenny (00:39:36):
Yes, that's all people need. If you end up creating that before this comes out, we'll throw it in the show notes. And if not, people can just bother you on Twitter and ask Maggie, where's that template that we talked about?

Maggie Crowley (00:39:44):
Yeah, I'm happy to write it on a piece of paper and take a photo of it and send it around.

Lenny (00:39:49):
There you go. Just make it really grainy and an artifact. We found Maggie's template. This is awesome. So, I've never heard of a version of this with so much depth into the landscape, and I think that's so smart because so much of conflict and disagreement comes from you just don't have the same information or the manager, exec or whatever doesn't think you have the information. So, if you just lean into, here's everything that I know and here's what's happening, and if you disagree with this goal, tell me, and then it'll change the plan.

Maggie Crowley (00:40:17):
Right.

Lenny (00:40:18):
And yeah.

Maggie Crowley (00:40:18):
Part of it's also that typically speaking, when you're doing a strategy, you're doing it at a higher level. So, I don't think every product needs a strategy. Every feature doesn't need a strategy for example, you don't need to do this if you're working on a tiny slice of a product and you have user feedback, don't overcomplicate it, just do the stuff that makes sense. But especially as I've gotten more senior in my career, the questions are bigger and the impact is broader and the timelines are longer. And honestly, it was also because I wanted to get it right. I didn't want to make a bet on something and put a bunch of resources against a problem and get it wrong. And so this was also homework that I wanted to do for myself to know that I was going to do the right thing. For some reason, I'm always paranoid that other people have more information or doing it better than I'm doing it.

(00:41:11):
So, I was like, okay, I have to write it all down and then make sure I got it right and share it with everyone and make sure that they agreed with me so that I didn't screw this thing up. And it just was such a useful exercise that I kept doing it. And of course people don't read it. People only read a tiny section. You'll run into the same problems you run in with everything else, but at least I knew that I had done the work and if people cared to engage with it was there.

Lenny (00:41:33):
So, along those lines, I was going to actually ask, how long do you find this should be depending either on the timescale, say you're doing a quarterly strategy or a year, how many pages should this doc be as any guide?

Maggie Crowley (00:41:46):
It's long. It gets real long.

Lenny (00:41:48):
What is long?

Maggie Crowley (00:41:53):
The actual content, I end up writing a summary to go back to the Minto principle. I end up doing the whole thing, then putting a summary at the top so that there's one, within the first, above the fold, if you will. You can kind of get the point and the suggestion on what I think we should do or what the strategy should be, should be customizable in that section. But it can go 20 pages just because if you really want to get deep in a competitor or there's interesting market dynamics, interesting technological changes that are happening. Sometimes I'm screenshotting other companies marketing websites and dumping that in there. And that might be some interesting comments. So, it doesn't have to just be words or it can be all kinds of different things that you might want to put in there.

Lenny (00:42:37):
And you made the point that it's not like you expect people to read this whole thing. There's the summary that gives them a conclusion and in theory if they want to really dig into it, they can. But I guess how do you find that balance of writing everything and making it so long that no one's ever going to read it to like this is actually going to be useful to someone and plus here's a summary.

Maggie Crowley (00:42:58):
It comes back to the reason why I write the document in the first place. And that's for me. So, it's my homework to do my job effectively. I just make sure to share it. And I find that my, especially my engineering and design counterparts, if you're working in a true triad, will almost always engage really deeply on the doc because they're pretty much also on the line and they want to make sure that when they sign their teams up to do whatever it is that they believe in the thing that you're working on.

(00:43:28):
And so I find that those people will engage pretty deeply. Sometimes you'll have more junior folks on the team that'll just be interested and they'll get really into it too. And then there's some people that'll skim the upfront part and either say, yeah, that looks great, or You're dumb, I hate this. And okay, sure. There's always those people. So, it never really mattered to me that people read the whole thing. It was more I knew I had to do it to be confident in my own decisions and then I could facilitate a conversation, so it didn't really matter.

Lenny (00:43:58):
This episode is brought to you by Eppo. Eppo is a next generation A/B testing and feature management platform built by alumni of Airbnb and Snowflake for modern growth teams. Companies like Twitch, Miro, ClickUp and DraftKings rely on Eppo to power their experiments. Experimentation is increasingly essential for driving growth and for understanding the performance of new features. And Eppo helps you increase experimentation velocity while unlocking rigorous deep analysis in a way that no other commercial tool does. When I was at Airbnb, one of the things that I left most was our experimentation platform where I could set up experiments, easily, troubleshoot issues, and analyze performance all on my own.

(00:44:38):
Eppo does all that and more with advanced statistical methods that can help you shave weeks off experiment time and accessible UI for diving deeper into performance and out of the box reporting that helps you avoid annoying prolonged analytic cycles. Eppo also makes it easy for you to share experiment insights with your team, sparking new ideas for the A/B testing flywheel, Eppo powers experimentation across every use case, including product growth, machine learning, monetization, and email marketing. Check out Eppo at getepo.com/lenny and 10X your experiment velocity. That's getE-P-P-O.com/lenny. Is there an example of a strategy you were thinking about recently or that you worked on in the past just to give people something concrete of like here's what Maggie thinks of as a question she's going to develop a strategy around?

Maggie Crowley (00:45:28):
Yeah, I think, obviously this is where product content gets really challenging because obviously I can't really talk about the stuff I'm currently working on.

Lenny (00:45:36):
Just tell us all of the secrets. And that [inaudible 00:45:38] know.

Maggie Crowley (00:45:38):
The toast PR department would be really unhappy with me. It's questions like, if you're a director of product somewhere, maybe you're running a section of a business and it's annual planning. We're in Q4. What are you going to do next year? How do you answer that question? How do you back up your choices for that? You use a doc like this. Maybe you are realizing that the product that you're working on doesn't really matter, it's not really making an impact. You're kind of treading water. I would use this as a tool to figure out, okay, well what else could you do? So, yeah, quarterly planning, annual planning. If you feel like your team needs to make a pivot or if you think that there's a really interesting new opportunity that your business or your team should go after, is another time I might use something like this.

Lenny (00:46:30):
Awesome. This reminds me a little bit of, I keep mentioning this chat with Bill Carr that I had who is an early Amazon exec and how the narrative approach at Amazon, one of the benefits of that and the reasons they go there is partly for you to realize this is a bad idea before anyone even needs to give you feedback. And that's why they force you to write six pages in depth about your idea and then it goes in these concentric circles through the company. And idea is like, here's okay, and this is just not a good idea. Here's all the reasons why. So, I think there's a lot of similarities there.

Maggie Crowley (00:47:00):
Yeah, there are many, many times when if you combine this artifact and process with the point about simplification where through that process you just start cutting so many things because then what happens is, let's say you've gone through this exercise and you're like, okay, I know exactly what my three things are that I want to work on. Then there's a moment where you take the strategy and then you look at your roadmap and they're never the same. And the roadmap is just bloated with all of this random stuff that like, oh, well, we have to do that because of this, or we have to do that because of that.

(00:47:37):
This thing we're still working on, this is like six months delayed, so we're still going to do the thing. And then all of a sudden you've got 90% of your resources committed to things that don't track against your strategy. And it's a really interesting moment as a leader especially to sit there and go, well, what do we do? What do you do when you have that problem? And especially if you're a PM, you probably don't have the agency to say, scrap the entire roadmap and work on my new strategy. But at least it allows you to think about critically about whether you should be doing what you're doing and allows you to evaluate whether those things are still the most important things to work on.

Lenny (00:48:09):
I'm going to summarize the template real quick, and then I'm going to have another question kind of along the lines. So, if you're trying to create your own little template, you start with the mission of the business, and then I imagine you also share the mission of your team because oftentimes it's a little more specific, if you're working on it like a product team strategy. Then there's a landscape of what's happening. So, you include competitive, SWOT analysis of competition risks, product state, business state, things like that.

(00:48:38):
And then you share the current goals of what you're trying to achieve as a team slash business. And there's an account, honest accounting of what's happening in the product and technical hurdles and things like that that'll keep you from moving, I guess, achieving some of these goals. And then you share, here's the opportunity I see, how we win and how we actually achieve this opportunity where we place bets and things like that, or we could place bets. Then challenges of doing this, what needs to be true for this to be possible? And then you finally get to, here's what I think we should do, essentially the solution, ideally three bullet points, and then the plan. And I imagine the plan is step one, get sign off from exec. Step two, resource the team. Step three, start on this design research sprint.

Maggie Crowley (00:49:26):
Pretty much.

Lenny (00:49:26):
Awesome. All right. Amazing. Somebody will create this template if you don't end up doing it.

Maggie Crowley (00:49:30):
Yeah.

Lenny (00:49:32):
There's another-

Maggie Crowley (00:49:32):
I hope somebody does.

Lenny (00:49:34):
Okay. That'd be awesome. If they do, I will tweet it and we put it in the show notes.

Maggie Crowley (00:49:34):
Great.

Lenny (00:49:39):
So many promises already from this podcast. Along the same lines, you also have a one-pager template and process that I think people find really useful. So, how about we chat about that one briefly and then I'm going to go in a whole different direction.

Maggie Crowley (00:49:52):
Okay. Yeah, I don't think I have much to say about this. That has not been said by many people many times, but whether it's a spec, a PRD, a one pager, I don't even know what else people call it. It's the document that you use to define the thing that you're doing as a product team, and that means product design, engineering, your little squad. And what I think is really useful about this process is that it's the PM's artifact. So, designers produce designs, engineers write code. What do PMs do? A lot of people might say nothing. In theory, we write at least this document and it can be a pain. I've seen lots of ways where it hasn't been done very well, but when I think it's done really well and when it's really effective is it's a tool that allows the PM to start with why. And if you structure it correctly, the most important section in my opinion in the document is the first part, which is like what is the background and context?

(00:51:00):
What is the problem, why does it matter and why does it matter now? And if you get those things right, the rest gets really easy, but it gives you a chance as a PM to center the team around the problem, why that problem exists, whether it's created by your own product or it's something the user is experiencing and why that problem is worth solving. That's a part that I think people sometimes forget to think about and why it's we're solving right now versus all the other problems you could be solving and then it can become the home base of the decisions that you make along the way. So, I think it's best when you have those sections and then also best when you write down on this day, we made this decision or we decided not to do this or we decided only to solve this part of the problem, not this part of the problem. Keeping a running list of that and a link off to all the different artifacts and research and things is helpful for a team.

Lenny (00:51:52):
So, just to summarize, what would be the headings again, just if someone's taking notes and wants to create the rule template?

Maggie Crowley (00:51:57):
I don't think these templates have to be really complicated. It's like background and context. The problem. I would literally write why this problem matters and why this problem matters now. Don't make it complicated, just answer those questions and if you can do that, and then again, it's only really helpful if then you bring that document before you go any further to your team and you use it to have a conversation and you get the smart people around you to take shots at it. I should have mentioned this earlier with the strategy. The first person I go to is typically speaking my engineering counterpart and I say, shred this, go through it, rip it apart, vomit comments on it, tear this down how it gets better. And as a PM you can't be precious about your work. You need people to poke holes in it.

Lenny (00:52:48):
The why this matters now point is so interesting. I don't often hear that and I think it's such an important part of specs and plans and strategies because there's so many things you can do and there's certain things that are perishable that you can only do now. That if you don't do now you miss up the opportunity. And so I think that's a really interesting element that most people don't include and it reminds me of, I think I've done enough podcast episodes now where I'm just connecting all these things as people are talking. [inaudible 00:53:16] the John Nash thing happening where Karri, the founder of Linear talked about this concept of side quests as a founder. Because he's so good at staying focused and I was just like, "How do you stay focused and just get stuff done when you have so many people coming out?" He's just like, "There's the main quest and then there's the side quests and side quest I don't need to do right now. There's the main quest which is build up really successful business." And I feel like this is a good example of that in action.

Maggie Crowley (00:53:39):
Yeah, I love his take on quality and taste too.

Lenny (00:53:43):
Yeah. What a gem.

Maggie Crowley (00:53:44):
Yeah, big fan of that. But yeah, I mean it's really hard to stay disciplined, it's hard to stay focused and to your point, there's a million things you could do at any given time, especially if you work at a bigger company. And so the why now is an important question to answer because if not, somebody's going to ask you. So, you may as well think about it.

Lenny (00:54:02):
Yeah, it's interesting why now comes up a lot in investing in startups but rarely in product building and it feels like it should. Although I will say in the research I've done, why now ends up not being that important for startups being successful or not. So, I think there's a two sides to that coin. Anyway, I'm going to move on to a different topic and this might become a new thing that we do and I'm going to call it contrarian corner. I asked you if you have contrarian opinions about things before we started recording this episode and you had some really good ones. So, there's a couple topics I'm going to chat about and we'll see if this becomes a recurring theme and you're laughing and nodding your head, what are you thinking as I say this?

Maggie Crowley (00:54:39):
I'm thinking about when I had a podcast, you would do a show on a topic and we would click the end recording button and then every single guest would be like, I had no idea what I was doing. I made it all up, it was waterfall. None of that matters. I didn't know what I was ... People would say the wildest stuff and I would sit there as a PM and just think what. We just talked about this framework, we just talked about this thing and that's how you're supposed to do it. And then they would get off the official part and just say, yeah, it's wild. Nothing goes the way you want it to go. We're all just kind of making it up as we go. And so I hope that you get more of those takes in this part of the show.

Lenny (00:55:18):
I'm very sensitive to that point right now because someone just tweeted about how they're just finding that many of my newsletter posts about how companies write product are the ideal version of what they do and I rarely or they rarely share, here's all the challenges we're having, which I think there's truth to that, but I also get into a lot of failures on this podcast. Actually, I think the podcast is a lot more of just here's things that go wrong versus the newsletter. So, I'm just like shit, I need to do more of that. So, I love that you mentioned that and let's see what we can get into. But I guess maybe before we get there, is there an example of something that didn't go just along the lines of some sort of failure slash mistake?

Maggie Crowley (00:55:59):
I might be foreshadowing, but a question I ask in every product interview is what's the worst product you've ever shipped? And that's because I don't think you're a good PM if you haven't shipped something that's really shitty, you just haven't had enough reps, you haven't done it enough time. And it's not only that you've done it but that you can admit it and which one it is. That's so important. And I remember, it was so dumb, I'm still so mad about this, that we did this. I won't name which team, which company, I'm not going to call that out, but we decided we needed to do a rewrite, red flag number one of a existing product and engineer who I'd worked with many times. We had a really good relationship and this person was like, yeah, yeah, it's going to take six months, no problem.

(00:56:47):
Core part of the product been around for forever. One of those things that the code is still, it's still the code written by the founders kind of thing. It didn't take six months, it took two and a half years. It still wasn't done. It almost never, it went on for so much longer than it should have. It took us forever to get to feature parody. It was the worst project. So, many people rotated in and out of it. Everyone thought it was dumb, sunk cost fallacy, just the worst. And it's because A, we got arrogant and we thought we could do it. B, we skipped discovery. We didn't really write a one-pager, we just went for it. We didn't do enough technical and design research into what the requirements would actually have to be. And there you have it.

Lenny (00:57:34):
And did not work out or was it a huge success in the end and it changed the trajectory of the business?

Maggie Crowley (00:57:39):
Absolutely not. But you know what, I didn't get fired, so it's fine.

Lenny (00:57:43):
I feel like I've gone through those experiences and then three, four years later it's like another, maybe this rewrite and redesign may work because we haven't updated this thing in a long time.

Maggie Crowley (00:57:52):
Just don't do it. Don't rewrite. If anyone ever tells you to do a rewrite, don't do it. A side by side re-write, nope.

Lenny (00:57:59):
Yeah, what I run into is once you get too far down a redesign slash rewrite everyone's building in that new world and then you launch an experiment's negative and then it's just like, oh, we just got to launch it. We're going to claw back. We're going to get figure out how to get back to neutral someday.

Maggie Crowley (00:57:59):
Yeah.

Lenny (00:58:15):
Yeah.

Maggie Crowley (00:58:15):
Yeah. Don't do that.

Lenny (00:58:16):
Good times. Okay, well maybe we'll start a failure corner. That could be a new segment. We may have a little sound and theme music, but this time we have contrarian corner and you have a couple contrarian opinions about a couple topics. The first is product management. What is something that you believe about product management that maybe other people are less convinced by?

Maggie Crowley (00:58:39):
The one I like to have in this area is that people who are really excited about being data-driven, to me that is oftentimes a red flag for their product thinking, especially if it's an executive who's saying things like, oh, so we make all our decisions with our dashboards. To me that says that the team is over-emphasizing quantitative data at the expense of qualitative data and they're not using good judgment. They probably don't do a lot of direct user research. They don't really understand the humans who are using the thing, what they need, what they care about, and they're managing via a dashboard. And maybe if they got really, really good at picking metrics, it would be fine. And oftentimes maybe it is fine. Maybe you have a high volume business that's really easy to run experiments on and that works for you. But most PMs, most jobs, most products, you're going to be better off talking to 10 users and you'll get more and better insights out of why things are happening than you would with any dashboard.

Lenny (00:59:51):
So, the takeaway there is just be careful when someone is saying they're super data-driven. Our team is super data-driven or company company's super data-driven.

Maggie Crowley (01:00:00):
Yeah, and maybe it's true and that's great. I am not saying that you don't need data. You absolutely do need to instrument your products and understand if it's working at scale, but you can't forget that, you need to know why. It won't tell you why anything is happening. If you don't understand why it's happening, I don't think you can come up with good insights about what you should do next. One quick story on this. I remember really early on in my career, Adam Medros, who was a VP [inaudible 01:00:24] at TripAdvisor, we were in a room, just had this meeting called product review that was amazing when I first joined and someone was justifying this project and he just, I hope he is okay with me saying this because this is my memory of this moment.

(01:00:38):
He was just like, this is an obviously better thing. Just do it. Stop. Stop it. Stop doing all the stuff that you're doing. Stop with these numbers, whatever it was that they were doing, if it's obviously better, if it's logically better, use your good judgment and do that thing and let's move on. And I've always thought about that, but you can just do the obviously better thing.

Lenny (01:00:58):
Yeah, I love that I pull that card sometimes, but I think you almost have to do it that way of just like, okay, everyone, this one's just obviously a good idea. Let's just do it. Enough research. Okay, another topic that you have some interesting opinions about his product content very close to our hearts, both my heart and your heart. Do share.

Maggie Crowley (01:01:20):
Really if you're going to make good content, you have to sanitize and frameworkize the thing that you're working on. And then slowly, I think for a lot of people who are reading it and looking at it, their thinking starts to become, well look how well I did this framework. Look how well I implemented this thing. And they lose touch with the point which is creating impact. And so all of this content makes it really noisy and then makes people think that, oh, if I just do these things that I'll get what I want. And now I'll just check off my list and then I checked it off and then I should get my promotion at the end of the day. But it's like the best PMs have built up so many different frameworks and they can apply them in different ways. And then sometimes they throw them out and they say, nothing I have in my toolkit makes sense for this moment, but I know what to do because I have intuition and I have data and I've talked to users or whatever.

(01:02:16):
And so content sometimes can get in the way of the impact because you're trying to apply it and you think that the point is the framework and the point is the one pager or whatever it is that you're doing when it's not. And then if you're a leader and maybe if you've had the good and ill fortune of having published content, someone comes to you and says, well, you said in that one podcast episode that you don't believe in roadmaps, so why are you asking me for a roadmap? And then you're the who's sitting there being like, well, it's a little more complicated than that. And that was a fun take that I had, but I actually need to understand what we're doing because planning and I need to figure out what my budget is, blah, blah, blah.

Lenny (01:02:52):
That's so funny that I didn't think about you as a leader having put stuff out that people put back at you. And I think your point about one for you, for people to consume content online about how to do product management, you have to really distill it. And to your point, it often loses the nuance. Because if you had all the ones, no one's going to even read it so complicated and long. And then the other point of there's also just it has to be interesting. So, if it's another just like, here's how a roadmap really is successfully and it's like what everyone's already done, no one's going to read it. So, you always have to have a new take. And with that comes, it's not actually always true. I just wanted people to react to this idea.

Maggie Crowley (01:03:32):
Yeah, I mean it's helpful. I think there's some people who create, I mean there's many things at my last role, we all had your newsletter and we listened to the show and then people would bring, I should have found a clip, but I can't remember, there were a couple of moments where we would listen to a piece of it or find an article and say, oh, this could help. Or what if we did it that way? I think there was a newsletter article about Figma and they had some templates. They're like product review template for FigJam. Love that one. Use that one all the time.

Lenny (01:04:06):
Amazing.

Maggie Crowley (01:04:06):
So, yeah, I mean the stuff's really useful. It's just like you have to be smart about when you apply it. And then if you're a leader and there's all this content available, you have to know why you're not following the rules.

Lenny (01:04:18):
If they're just like, hey, look at this newsletter post letting you write, we should be doing it this way. Versus I think people assume these are the one way to do it or innately will work at your company. And I really like your point, which maybe counter to what I do, but I think it's an important nuance that I feel like I should add to every newsletters. This isn't necessarily going to work at your company. Sometimes the culture is different and this won't fit or this isn't a complete version. As much as I try to give people, here's everything you need to do this thing well, there's always a little bit missing

Maggie Crowley (01:04:55):
And I think if you don't have that context, it can be a little demoralizing like, well, how am I ever going to do that thing that they get to do at this magical company? But again, if you view it as more like here all the tools that you can add to your toolkit and you pull them out when you're in a situation from which they can be useful, that's how I think about it. Versus this is the one way to do it like you said, the only way you can write a one page or the only way you can write an experiment, it's more like you can do it in many different ways.

Lenny (01:05:19):
And I find myself, I'm not actually, I rarely tell people here's the way to do it. Usually what I try to describe is here's how the best companies do it, as much as I can get into and leave it to the reader to decide is this going to be a fit for me, should I try to implement it? But still, I think there's an implication. This is the way to do research, here's the way to do roadmap, here's the way to prioritize. But I think it's interesting that you also, yourself create a lot of content and you actually found a lot of value from being, let's not call you content creator because I don't like being labeled as a creator myself.

Maggie Crowley (01:05:55):
Someone one's called me a product influencer and I'll died like a little bit.

Lenny (01:05:59):
That's how I feel. I'd love to hear just the impact you've seen from spending time creating podcasts and blog posts and tweeting about really great stuff because a lot of people are thinking about investing in this stuff.

Maggie Crowley (01:06:11):
Yeah, it's probably the best thing I've ever done for my career and I am so grateful for the people whose idea it was, who supported me and especially at Drift, when that became such a part of what we were doing at that time. And it's been helpful for a couple of reasons. One is just networking and access. I probably wouldn't be here today if I hadn't done that and if a friend of a friend had read the thing, it's like it just creates so many more connections. And so access to people and networking is one of the first benefits.

(01:06:51):
Also building a personal brand is really helpful if you want, one of the things that I always wanted to do with my career is try to make it so that I'm always employable. I just didn't want to, I'm an 08 grad not to put my age out there, and it was a hard time. And so I've always had this in the back of my mind, you want to be able to have a solid career. And so I thought that investing in my personal brand would be a way to help me get access to roles. It helps in recruiting as well when I'm trying to hire people. Because a lot of my job now is bringing people in and because I've been vocal about how I like to work and who I am, a lot of people and they will send me a note and say, I want to work with you, or I want to work on a team like that.

(01:07:35):
And that's huge because if my job is to hire people, then that's great and people can get a sense of who I am without needing to be on the phone with me. My favorite benefit outside of those things has been that it's helped me learn more from the work I've done than I otherwise would've been able to. Because in order to make content, you have to think through what you did, you have to summarize it, process it, make it interesting for people. And then especially if it's in a podcast meeting, talk to somebody about it. And the process of doing that means that you're paying attention to what you're learning along the way. And so often we don't do that because we're busy working, we have our lives, things are happening. And that to me is, I think what's made me a better product person faster is because I spent the time to think about what I was doing in a way that I wouldn't have if I didn't have to write something down.

Lenny (01:08:28):
Something that comes across in your content that you've somehow figured out is to avoided being cringy and very thirsty for followers. And I think when a lot of people here build a personal brand, it's like, I don't want to.

Maggie Crowley (01:08:44):
I know. It makes me ill even saying that, it's like too gross.

Lenny (01:08:47):
I never thought of it or wanted to think of it that way. And I'm just curious what advice you'd give to people that want to go down this route without feeling, I guess one, is just feeling like they're being cringey, and two, avoiding content people be like, oh my God, I can't believe this stuff [inaudible 01:09:02].

Maggie Crowley (01:09:02):
Yeah, the clickbait tweet thread situation. I think the step one's going to be cringe. Your first 10, 20, however many posts are going to be bad. I would imagine if you went back and listened to your first episode, you would be cringing just because you've learned so much since then. Right?

Lenny (01:09:02):
Yeah.

Maggie Crowley (01:09:22):
It's natural.

Lenny (01:09:23):
Although randomly the first episode ever is the most popular episode. So, with [inaudible 01:09:29], which I could see why it was so popular.

Maggie Crowley (01:09:30):
So, it went really hot with your first guest.

Lenny (01:09:34):
That's right. That's right.

Maggie Crowley (01:09:35):
So, yeah, first get over the fact that it's going to be cringe. It's going to be cringe. Like anything, you just have to get started and it'll fade away eventually and you don't have to think about it. Two B, this is such gross advice, but you have to be authentic. It has to be real. And I think what came through in the show that I did was those were my real questions that I was really working on.

(01:09:59):
So, we joked about how we would turn off the recording and then we would get the real story, but I would turn the recording off and I would say, okay, we talked about this thing. Here's actually happening in my job today, what would you do? And so those were real questions that I had, real processes that I was working on and real advice that I needed at that time. And I think that's why it was valuable is because I was actively a PM and the way that I'm still actively in product, that was always something that I wanted because it meant that the content had to be relevant for me and wasn't just for likes and share.

Lenny (01:10:34):
I think there's some two really important points there that stood out to me. One is your stuff's going to be terrible if you don't actually have any background or experience in the things, you're just pretending. It's like you're acting like someone that knows about this thing, but you don't actually. And so I think that's an incredibly important part of this is don't try to become an online creator person if you haven't done the thing, because people will see that you don't know what you're really talking about and you'll run out of stuff and it'll be like, okay, well I did it for two months and I have nothing more to say.

Maggie Crowley (01:11:03):
Right.

Lenny (01:11:05):
And then the other piece is there's a guest who shared this quote that has stuck with me from Einstein, which is something like, "Seek not to be successful but of value." And I find that that's a really good framing for sharing stuff is just share things that are interesting to you and useful and come at it from this is useful, not from, I'm trying to build a following. Because people can tell if that's the-

Maggie Crowley (01:11:30):
Yeah, people can absolutely tell. And the other thing is there's a little bit of too cool for school mixed in here and there are definitely people who will tell you your content is cringe or make fun of you or whatever because that's what they want to do. And I'm not even going to get into psychology of that, but people will do that. And I've always been of the mind that the really interesting people out there, people who are unashamedly interested in stuff and who are like, yeah, I'm nerding out about this and I'm sharing it because I'm interested in it. And for better for worse, I love working in product. I love the job.

(01:12:08):
Even all the gross stuff you have to do, it's super interesting. You meet really cool people, you get to ship stuff, you get to see the stuff get used by people and solve problems. It's a really cool job and I've always been interested in how to do it better and it doesn't matter to me that some people might think that's cringe because that's cool, but this is what I do all day long, so I'd like to get better at it.

Lenny (01:12:26):
I think that's such a big part of it. I didn't even mention that. Just it needs to feel really authentic and clearly for you is just like, there's just stuff I want to share because it's really interesting to me.

Maggie Crowley (01:12:37):
Yeah.

Lenny (01:12:37):
The way I actually started writing was exactly the two reasons you just shared. One is I wanted to learn the thing and so writing helped me figure things out. And then two is I just thought it was interesting and I found it useful and I just assumed other people might find it useful. So, I did also learn, and I wonder if you found this too, is that you think the things are not going to be that interesting or useful to people, so basic for you, but people find the most basic stuff so interesting. Because there's always more to learn about how to roadmap, how to prioritize, how to hire, how to talk, to have difficult conversations, performance review.

Maggie Crowley (01:13:15):
All of that is absolutely true. And I think one of the first pieces of content that I was really happy with was I was working with somebody and they were making a PowerPoint presenter slides or whatever, and I just wrote out in my notebook like, okay, here's how I do that. I start with an outline on paper and then I draw little boxes for the slides and I write out the headline of the slides. And then once I have a tight outline and I have the literal text that will go across the top of each of those things, then I sketch out how I want the slides to go. And then I go into Google Docs and I actually make the slide.

(01:13:51):
And it was like some silly little thing and this person sat there and said, holy, you just totally changed the way I did this and this took me 75% less time than it would've taken me otherwise. And I was like, I may do this dumb drawing. Why is this a big deal? And yeah, that's when I realized that the stuff that's easy for you might be a stuff that is most interesting because it's something that maybe you're really good at that you don't realize.

Lenny (01:14:13):
I think people need to really internalize that point. If there's something that you're doing that you consistently find useful and works often, that is going to be really useful for someone to hear. So, that could be a good place to start. Maggie, we've gone through everything that I was hoping to get through and more, which is awesome.

Maggie Crowley (01:14:32):
Great.

Lenny (01:14:32):
Before we get to a very exciting lightning round, is there anything else that you want to share or touch on think might be useful to leave folks with?

Maggie Crowley (01:14:41):
My hope is always that people listen to stuff like this and realize that it's messier than you think you can fail a lot and still be successful and that they should have fun. I think that gets missed in a lot of the product content is like, have fun, enjoy it. People are weird, people do weird stuff and you build stuff for people, which it makes it all very entertaining. So, I've always found a lot of joy in the job.

Lenny (01:15:04):
And to your point of carrying the water as a PM where you're kind of doing all the things, it's like you can create that fun. You can make the team your own fun and change the culture, create the culture. I find that so underappreciated for PM.

Maggie Crowley (01:15:16):
Absolutely.

Lenny (01:15:17):
Okay, well with that, we've reached our very exciting lightning round. Are you ready?

Maggie Crowley (01:15:21):
I'm ready.

Lenny (01:15:22):
Maggie, what are two or three books that you've recommended most to other people?

Maggie Crowley (01:15:27):
First, most common one is probably the Presentation Secrets of Steve Jobs, the little tiny one, really great way to improve your speaking skills and your presentation skills and to get distracted executives to agree with the point you're making. So, that's one. Thinking in Bets by Annie Duke is the second one. Coming back to the point about being able to make bets, I think that one's a really interesting one. And then bonus third one, this is more like a desk reference that I now have on my desk, the Scaling People book by Claire Hughes Johnson. I really enjoyed the way that one is working and it just sits on my desk and I reference it every once in a while, especially as manager.

Lenny (01:16:11):
I have it both under my laptop right where I'm sitting and then also way behind there and it's one of the most popular episodes I've done with Claire, so if folks haven't listened to that one. Highly recommend. She's incredible. Great choice. What is a favorite recent movie or TV show you've really enjoyed?

Maggie Crowley (01:16:27):
Okay, so my husband is in the industry, as we say here in LA, and so we watch a lot of good and bad shows in TV, but I think my favorite one that I've watched recently was Slow Horses. Gary Oldman is incredible. Highly recommend.

Lenny (01:16:43):
Wow, I haven't heard that one yet. Good tip. What is a favorite interview question you really like to ask which I think you already gave away, but let's touch on it again.

Maggie Crowley (01:16:51):
I did. Yeah, it is what is the worst product that you've ever shipped? I think the best answers are ones, and I don't even care if someone listens to this and then I do this in an interview, people immediately laugh a little bit. They remember the horrible thing they did and then they share that horrible thing with you. And it tells me you have some humor, you're humble and you can point out when you've made a mistake. You've done enough to be able to confidently say, of course I've made a mistake. Because none of us are perfect. And you know how to spot those mistakes and you can learn from them. And I've always found that those conversations are the most interesting.

Lenny (01:17:29):
What is a favorite product you've recently discovered that you really like?

Maggie Crowley (01:17:33):
One because I've seen you on Twitter, you're a future fit guy.

Lenny (01:17:36):
Yeah, I'm.

Maggie Crowley (01:17:37):
Is that correct?

Lenny (01:17:37):
I use it three times a week. I love it.

Maggie Crowley (01:17:39):
Yes. I was also a future fit person. I think it's great. It's a great product. I'm now on Ladder Fit.

Lenny (01:17:46):
I've heard of that.

Maggie Crowley (01:17:47):
And personally, I love not being, I don't have to talk to the coach every day. I don't need the accountability, so that's not a thing that I needed as an ex athlete. So, for me, that didn't serve me and I like the anonymity of it and it comes with a totally unhinged group chat for your whole team. It's fantastic. I'm really enjoying it.

Lenny (01:18:07):
Sweet.

Maggie Crowley (01:18:08):
So, that's one more of a funny one. And the second one, not to get real niche, but I think good products are products that are focused. They do one thing incredibly well and they're not, to your point about side quest, there's no side quests. I'm a new mom. There's this app called Pump Log. I have never seen an execute so well on one problem. There's not a single thing where I think, oh, I wish it did this. It does it. It's like I paid $14 for it. I've never paid for an app like that in my life.

Lenny (01:18:40):
Okay, I'm downloading it right after we finish. Do you have a favorite life motto that you either repeat yourself, often like to share with folks, find useful, and just kind of living life?

Maggie Crowley (01:18:51):
I'm sure there's mottos' I could say that would be aspirational mottos', but the real one is if it's worth doing, it's worth doing well. And again, from being in sports to going to school to being in product, in my opinion, if you're going to do something, do it to the best of your ability because that's what you do with your day. You spend so much time working, you may as well be good at it or trying to get good at it. And that's always how I've lived my life.

Lenny (01:19:20):
I so love that message. I always think about that. Final question, you are an Olympic speed skater, which I don't think people would know necessarily. That's insane. My question is there some bad speed skating that would surprise people that would be like, what?

Maggie Crowley (01:19:38):
Ooh, that is one I've never been asked before. The whole experience, I've obviously learned a ton from it, and I think what might surprise people about being a small sport athlete is that you have to think in four or eight year chunks. And so it's one of those things where you grind for so long in a dark corner and then you get a chance to get the light to shine on you and you learn how to love the process. Especially for speed skating, I was a long track speed skater, it's a 400-meter rink.

(01:20:15):
You just are always turning left and going in a circle. There's not a lot going on. It's just you and your thoughts and you just really, really learn how to get good at perfecting something over and over again, and you learn how to grind, you learn how to focus, and I think it's also cool you get to go superfast. But yeah, I don't know if that would surprise people about speed skating, but I think just about being a small sport elite athlete, it's really about years and years and years of toiling and silence to get maybe one shot at something great.

Lenny (01:20:46):
So, much of what you just said would apply 100% to product management and I love that. Maggie, you are awesome. Two final questions. Where can folks find you online if they want to reach out and maybe ask you any follow-up questions, and then two, how can listeners be useful to you?

Maggie Crowley (01:21:00):
You can find me on Twitter for sure. By LinkedIn, but just speaking of cringe, I just can't get into LinkedIn posting.

Lenny (01:21:09):
LinkedIn's gotten better, I'd give it a shot. It's actually pretty interesting now, which sound weird to say.

Maggie Crowley (01:21:16):
Thinking about it, I better go back to work in a couple of weeks and thinking about LinkedIn. But yeah, Twitter for sure, LinkedIn for sure, and I've always tried to be helpful to other people, so I don't have an answer for how people can be helpful to me, my goal is really to share what I've been doing, the rooms that I get to be in, the access to the content and the people and the learning that I've had. So, hopefully I can find ways to keep sharing that.

Lenny (01:21:39):
Maybe check out Toast and use Toast when they're at restaurants.

Maggie Crowley (01:21:42):
Oh yes, Plug, Toast. Come work with us. We're the best. I get to work with John Cutler. It's phenomenal.

Lenny (01:21:50):
Legendary, previous guest. Are there roles you're hiring for just for folks that are listening and just like, hey, maybe I should go do that.

Maggie Crowley (01:21:56):
There are always roles that are open. I don't know what the most open roles are right now, but yeah, check it out. It's a great place.

Lenny (01:22:01):
Willing to the careers page.

Maggie Crowley (01:22:03):
Awesome.

Lenny (01:22:03):
Maggie, thank you again so much for being here.

Maggie Crowley (01:22:05):
Thank you, Lenny. It was awesome.

Lenny (01:22:07):
Bye everyone. Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

---

